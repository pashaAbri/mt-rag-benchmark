{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00550-7-2005","score":21.1244087219,"text":"\nGrouping related documents together in IBM Cloudant \n\nTraditionally, e-commerce systems are built with relational databases. These databases typically use a number of tables joined to record sales, customer details, purchased products, and delivery tracking information.\n\nRelational databases offer high consistency, which means that application developers can build their applications to a database's strengths. This practice includes joins between collections, enumerations to record the state of an object, and database transactions to guarantee atomic operations.\n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae favors availability over consistency. It's a high-availability, fault-tolerant, distributed database that is eventually consistent. A distributed database means the customer's shopping service is always available and scalable enough to cope with many users who make purchases at the same time. With that in mind, your application can leverage IBM Cloudant's strengths and not treat it like a relational database.\n\nThis discussion outlines some of the factors that are involved in building an e-commerce system that takes advantage of IBM Cloudant's strengths. IBM Cloudant uses concepts that are applicable to many other domains, such as:\n\n\n\n* Using multiple documents to represent the state of a purchase, rather than frequently updating a single document.\n* Storing copies of related objects in order instead of joining to another collection.\n* Creating views to collate documents by order_id to reflect the current state of a purchase.\n\n\n\nFor example, you might create a purchase document that includes details such as the items ordered, customer information, cost, and delivery information.\n\nSee the following example document that describes a purchase:\n\n{\n\"_id\": \"023f7a21dbe8a4177a2816e4ad1ea27e\",\n\"type\": \"purchase\",\n\"order_id\": \"320afa89017426b994162ab004ce3383\",\n\"basket\": [\n{\n\"product_id\": \"A56\",\n\"title\": \"Adele - 25\",\n\"category\": \"Audio CD\",\n\"price\": 8.33,\n\"tax\": 0.2,\n\"quantity\": 2\n},\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant"},{"document_id":"ibmcld_00612-7-2163","score":19.9061431885,"text":"\nMigration overview \n\nThe [IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae](https:\/\/www.ibm.com\/cloud\/cloudant) database-as-a-service offering is a JSON document store that runs on multi-tenant clusters. The service is available with a choice of geographical locations with predictable costs, scalability, and a service-level agreement (SLA).\n\nYou can migrate to an IBM Cloudant Lite or Standard plan instance on IBM Cloud from one of the following plans:\n\n\n\nTable 1. IBM Cloudant migration paths\n\n Plan Description \n\n IBM Cloudant Enterprise Dedicated, single-tenant clusters \n Apache CouchDB The self-hosted, open source database on which IBM Cloudant is based. \n\n\n\n\n\n Benefits of the IBM Cloudant Lite and Standard plans \n\nWith the Standard plan, you can reserve throughput capacity for your database service, that is, to specify how much throughput your application's database is going to need to handle demand. The Standard plan also charges for the amount of storage you use. Capacity is measured with the following metrics:\n\n\n\nTable 2. Capacity metrics\n\n Metric Description \n\n Reads per second The rate when simple document fetches are performed, for example, retrieving a document by its _id, or querying against a partitioned database that uses a partition key. \n Writes per second The rate when data is written to the database. API calls dealing with document creation, update, or deletion count as \"writes\". \n Global Queries per second The rate when the database is queried by global indices, typically by accessing the _find endpoint, secondary MapReduce, or search indices. \n Storage The amount of disk space occupied by your JSON data, attachments, and secondary indices. \n\n\n\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"},{"document_id":"ibmcld_06994-7-1971","score":19.8537883759,"text":"\nDatabase \n\nCrawl documents that are stored in a database that supports the Java Database Connectivity (JDBC) API.\n\nIBM Cloud Pak for Data\n\nIBM Cloud Pak for Data only\n\nThis information applies only to installed deployments.\n\n\n\n What documents are crawled \n\n\n\n* Each row in the database is crawled and added to the collection as one document. The columns are indexed as metadata.\n* The crawler attempts to crawl and index content, such as BLOB\/BINARY, that is stored in the database. File types that are supported by Discovery are indexed. For more information, see [Supported file types](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collectionssupportedfiletypes).\n* When a source is recrawled, new documents are added, updated documents are modified to the current version, and deleted documents are deleted from the collection's index.\n* All Discovery data source connectors are read-only. Regardless of the permissions that are granted to the crawl account, Discovery never writes, updates, or deletes any content in the original data source.\n\n\n\n\n\n\n\n Data source requirements \n\nIn addition to the [data source requirements](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collection-typesrequirements) for all installed deployments, your database data source must meet the following requirements:\n\n\n\n* Discovery supports the following data source versions:\n\n\n\n* Data Virtualization on IBM Cloud Pak for Data 1.8.0, 1.8.3 which use Db2 11.5\n* IBM Db2: 10.5, 11.1, 11.5\n* Microsoft SQL Server: 2012, 2014, 2016, 2017\n* Oracle Database: 12c, 18c, 19c\n* PostgreSQL: 9.6, 10, 11\n\n\n\nSupport for Data Virtualization was added with IBM Cloud Pak for Data 4.5.x releases\n* You must obtain any required service licenses for the data source that you want to connect to. For more information about licenses, contact the system administrator of the data source.\n\n\n\n\n\n\n\n Prerequisite step \n\n\n\n* Decide which database tables you want to crawl.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-database-cp4d"},{"document_id":"ibmcld_00513-7-2197","score":19.7475395203,"text":"\nDatabase overview \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases contain JSON objects. These JSON objects are called [documents](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documentsdocuments).\n\nAll documents must be contained in a database. For more information, see [partitioned databases](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databasespartitioned-databases-database).\n\nThe [Grouping related documents together in IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudantgrouping-related-documents-together-in-ibm-cloudant) guide provides an example of how documents for an e-commerce application might be used within an IBM Cloudant database.\n\n\n\n Partitioned databases \n\nIBM Cloudant supports two types of databases:\n\n\n\n* Partitioned\n* Nonpartitioned\n\n\n\nA partitioned database offers significant query performance and cost advantages but requires you to specify a logical partitioning of your data. The partitioning is specified as part of each document's ID. A partitioned database provides both global and partition queries. Partition queries target queries at a single, given document partition, meaning they need to process less data to return results. Therefore, partition queries offer significant performance advantages, and also often provide cost advantages over global queries. Global queries target the entire database, which leads to extra complexity, slower performance, and increased cost, but offers results that draw from all data.\n\nAlternatively, a nonpartitioned database might be created. This type of database can be less complex to work with since no partitioning scheme needs to be defined, but you can create only global secondary indexes.\n\nIBM Cloudant strongly encourages you to use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nThe partitioning type of a database is set at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databases"},{"document_id":"ibmcld_00512-1696-3972","score":19.6256713867,"text":"\nDocuments with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database. All documents are assigned to a partition, and many documents are typically given the same partition key. A partition's primary JSON data and its indexes end up colocated, meaning that the database can query data within a partition more efficiently.\n\nA partitioned database offers both partitioned and global querying. Partitioned querying takes advantage of the data layout within the database cluster to deliver improved and more scalable query performance. Partition queries are also often cheaper than global queries.\n\nAs partitioned databases offer the advantages of both global and partition querying, IBM Cloudant recommends that new applications take advantage of them.\n\n\n\n\n\n What makes a good partition key? \n\nIf you're thinking of using IBM Cloudant's new partitioned database feature, then the choice of a partition key is important. A partition key must have:\n\n\n\n* Many values - lots of small partitions are better than a few large ones. A million partitions are perfectly fine, but keep each partition under 10 GB in total size.\n* No hot spots - avoid designing a system that makes one partition handle a high proportion of the workload. If the work is evenly distributed around the partitions, the database performs more smoothly.\n* Repeating - If each partition key is unique, one document per partition exists. To get the best out of partitioned databases, multiple documents per partition must exist - documents that logically belong together.\n\n\n\nLet's look at some use cases and some good and bad choices for a partition key.\n\n\n\nTable 1. Good and bad choices for a partition key\n\n Use Case Description Partition Key Effectiveness \n\n E-commerce system - orders One document per order order_id Neutral - one document per partition is fine, but it doesn't provide the benefits of Partition Queries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00526-7-1750","score":19.4926795959,"text":"\nOverview \n\nDocuments are [JSON objects](https:\/\/en.wikipedia.org\/wiki\/JSONData_types.2C_syntax_and_example). Documents are also containers for your data, and are the basis of the IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae database.\n\nIf you're using an [IBM Cloudant service on IBM Cloud\u00ae](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicibm-cloud-public), documents are limited to a maximum size of 1 MB. Exceeding this limit causes a [413 error](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes).\n\nIBM Cloudant uses an [eventually consistent](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cap-theoremcap-theorem) model for data. If you use the eventually consistent model, it's possible, under some conditions, to retrieve older document content. For example, older content is retrieved when your application writes or updates a document that is followed immediately by a read of the same document.\n\nIn other words, your application would see the document content as it was before the write or update occurred. For more information about this model, see the topic on [Consistency](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cap-theoremcap-theorem).\n\n\n\n Document fields \n\nAll documents must have two fields:\n\n\n\n* A unique _id field. The _id field is detailed in the next section.\n* A _rev field. The _rev field is a revision identifier, and is [essential to the IBM Cloudant replication protocol](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-document-versioning-and-mvccdocument-versioning-and-mvcc).\n\n\n\nIn addition to these two mandatory fields, documents can generally contain any other content that can be described by using JSON, subject to some caveats detailed in the following sections.\n\n\n\n Document IDs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documents"},{"document_id":"ibmcld_12897-7-1911","score":19.4646892548,"text":"\nDocument versioning and MVCC \n\n[Multi-version concurrency control (MVCC)](https:\/\/en.wikipedia.org\/wiki\/Multiversion_concurrency_control) is how IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases ensures that all of the nodes in a database's cluster contain only the [newest version](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documents) of a document.\n\nSince IBM Cloudant databases are [eventually consistent](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cap-theorem), it is necessary to prevent inconsistencies from arising between nodes as a result of synchronizing between outdated documents.\n\nMulti-Version Concurrency Control (MVCC) enables concurrent read and write access to an IBM Cloudant database. MVCC is a form of [optimistic concurrency](https:\/\/en.wikipedia.org\/wiki\/Optimistic_concurrency_control). It makes both read and write operations on IBM Cloudant databases faster because the database locks on either read or write operations isn't necessary. MVCC also enables synchronization between IBM Cloudant database nodes.\n\n\n\n Revisions \n\nEvery document in an IBM Cloudant database has a _rev field that indicates its revision number.\n\nA revision number is added to your documents by the server when you insert or modify them. The number is included in the server response when you make changes or read a document. The _rev value is constructed by using a combination of a simple counter and a hash of the document.\n\nThe two main uses of the revision number are to help in the following cases:\n\n\n\n1. Determine what documents must be replicated between servers.\n2. Confirm that a client is trying to modify the latest version of a document.\n\n\n\nYou must specify the previous _rev when you [update a document](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documentsupdate) or else your request fails and returns a [409 error](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvcc"},{"document_id":"ibmcld_00580-4796-6846","score":19.4336566925,"text":"\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.\n\n\n\n* The first example shows a person object, storing strings, booleans, and an array of tags.\n* The second example shows brief attribute names to save on storage and represents a web event such as click a website.\n* The last example shows how the document may itself contain subjects.\n\n\n\nA note on dates. JSON has no native Date type, so dates are usually stored in 30-October-2018 or similar formats. We return to dates later.\n\nNow, for your first practical exercise, visit www.ibm.com\/cloud. Register an account with the IBM Cloud, if you don't have one already.\n\nOnce registered, you can click services, search for the Cloudant database, and provision a new service.\n\nThe IBM Cloudant Lite service provides a free plan to allow users to try IBM Cloudant in a limited capacity while in development. Its bigger brother, the Standard Plan, is a paid-for service where you specify the number of reads, writes, and queries per second for your application and that capacity is reserved for you. You pay for the capacity you provision and your data storage usage.\n\nThe Lite plan operates in a similar way. It has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00576-6036-7924","score":19.3423633575,"text":"\nFor more information, see [IBM Cloud Databases for PostgreSQL](https:\/\/www.ibm.com\/cloud\/databases-for-postgresql).\n* Data warehouse for ad hoc querying. For more information, see [IBM\u00ae Db2\u00ae Warehouse on Cloud](https:\/\/www.ibm.com\/products\/db2-warehouse).\n* A queue. For more information, see [IBM MQ](https:\/\/www.ibm.com\/uk-en\/products\/mq).\n\n\n\nFor more information, see the [Best and worst practice](https:\/\/blog.cloudant.com\/2019\/11\/21\/Best-and-Worst-Practices.html) blog.\n\n\n\n\n\n Organizing documents and databases \n\nIBM Cloudant data is organized in a hierarchy of databases and documents. A document is a JSON object with a unique identifier: its _id. A database is a collection of documents with a primary index that allows documents to be retrieved by _id. It also has optional secondary indexes that allow documents to be queried by other attributes in the object.\n\nWhen developers start a project, they sometimes struggle with the following questions:\n\n\n\n* How much data can I put into a single object?\n* Must I store different document types in the same collection or one database per document type?\n\n\n\nIt is important for a document to include all the data about an object that is modeled by your application, for example, a user, an order, or a product. This practice ensures you fetch the entire object from the database in one API call. IBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00580-26901-28959","score":19.2953968048,"text":"\nIf we want to fetch a single document back from the database, then documents sit one level beneath the database in the hierarchy of the URL.\n\nSo acurl $URL\/books\/id means \"get document ID from the database books from the IBM Cloudant service at the supplied URL\".\n\nNotice the hierarchy: service, database, and document.\n\nSo far we only used the GET HTTP method, which is the default one for curl and the one used when you enter a URL into your web browser.\n\nIBM Cloudant's API often uses the HTTP method as a verb to describe the action that is asked of the database: GET for fetching data.\n\nWith curl, we can specify the method that we want to use with the -X command-line option.\n\nSo to write a new document to our books database that uses the API, we're going to use the POST method, massing a document as the body of the HTTP request.\n\nacurl -X POST specifies we're using the POST HTTP method. -d specifies the document that we want to write, which is sent as the body of the request, and finally, the URL we are writing to which is $URL\/books - the books database.\n\nAlternatively, we can use the PUT method, if we are supplying the ID of the document that is being written. The URL becomes $URL\/books\/ followed by the ID we want to write.\n\nBoth write methods yield identical responses. OK: True to show that the write was successful. ID being the document ID written, and rev being the revision token that was generated by the database.\n\nTo modify a document, we can use the PUT method to write the new body to the URL that points to the document ID we want to overwrite. -d supplies the new document body, and the URL not only contains the database and ID of the document, but critically the rev - the revision of the document we intend to mutate.\n\nIf we forget and omit the rev parameter, we get an error response.\n\nHTTP response codes show whether a request succeeds or not. Responses in the 200 range are successful. Responses in the 400 range are user errors (for example, invalid parameters), and responses in the 500 range are server-side errors.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2640681226,"ndcg_cut_10":0.2640681226}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00472-19526-21520","score":21.8664340973,"text":"\nIt differs from using \"fieldname:value\" in the q parameter only in that the values aren't analyzed. [Faceting](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-searchfaceting) must be enabled for this parameter to function. No JSON A JSON array that includes two elements: the field name and the value. Yes \n group_field Field by which to group search matches. Yes String A string that includes the name of a string field. Fields that include other data such as numbers, objects, or arrays can't be used. No \n group_limit Maximum group count. This field can be used only if group_field is specified. Yes Numeric No \n group_sort This field defines the order of the groups in a search that uses group_field. The default sort order is relevance. Yes JSON This field can have the same values as the sort field, so single fields and arrays of fields are supported. No \n highlight_fields Specifies which fields to highlight. If specified, the result object includes a highlights field with an entry for each specified field. Yes Array of strings Yes \n highlight_pre_tag A string that is inserted before the highlighted word in the highlights output. Yes, defaults to <em> String Yes \n highlight_post_tag A string that is inserted after the highlighted word in the highlights output. Yes, defaults to <\/em> String Yes \n highlight_number Number of fragments that are returned in highlights. If the search term exceeds the fragment size, then the entire search term is returned. Yes, defaults to 1 Numeric Yes \n highlight_size Slice up field content into number of characters, so-called fragments, and highlights matches only inside the specified fragments. Yes, defaults to 100 characters Numeric Yes \n include_docs Include the full content of the documents in the response. Yes Boolean Yes \n include_fields A JSON array of field names to include in search results. Any fields that are included must be indexed with the store:true option. Yes, the default is all fields. Array of strings Yes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search"},{"document_id":"ibmcld_00623-7-1781","score":21.7507266998,"text":"\nWorking with IBM Cloudant Query \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query is a declarative JSON querying syntax for IBM Cloudant databases. You can use a json or text type of index with IBM Cloudant.\n\nIn the following cases, you can specify how the index is created by making it of type json:\n\n\n\n* You know exactly what data you want to look for.\n* You want to keep storage and processing requirements to a minimum.\n\n\n\nBut for maximum flexibility when you search for data, you typically create an index of type text. Indexes of type text have a simple mechanism for automatically indexing all the fields in the documents.\n\nWhile more flexible, text indexes might take longer to create and require more storage resources than json indexes.\n\n\n\n Creating an index \n\nYou can create an index with one of the following types:\n\n\n\n* \"type\": \"json\"\n* \"type\": \"text\"\n\n\n\n\n\n Creating a type=json index \n\nTo create a JSON index in the database $DATABASE, make a POST request to \/$DATABASE\/_index with a JSON object that describes the index in the request body. The type field of the JSON object must be set to json. A JSON index can be partitioned or global; this option is set by using the partitioned field.\n\nSee the following example that uses HTTP to request an index of type JSON:\n\nPOST \/$DATABASE\/_index HTTP\/1.1\nContent-Type: application\/json\n\nSee the following example of a JSON object that creates a partitioned index that is called foo-partitioned-index for the field called foo:\n\n{\n\"index\": {\n\"fields\": [\"foo\"]\n},\n\"name\" : \"foo-partitioned-index\",\n\"type\" : \"json\",\n\"partitioned\": true\n}\n\nSee the following example of a JSON object that creates a global index that is called bar-global-index for the field called bar:\n\n{\n\"index\": {\n\"fields\": [\"bar\"]\n},\n\"name\" : \"bar-global-index\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query"},{"document_id":"ibmcld_00580-41116-43256","score":21.0394058228,"text":"\nThe queries that we executed in the previous part were not optimal: to get the answer, IBM Cloudant had to spool through every document in the database in turn to see whether it met with the search criteria.\n\nTo make queries that are run in a performant and scalable way, we need Indexing.\n\nWith IBM Cloudant, you can specify any number of Indexes (or indices).\n\nAn index is a secondary data structure that is built from the document list. It contains data that is sorted by the fields you specify, for example, books that are sorted by date and title. If you perform a query that asks for data that matches a document's date and title, the indexed data structure can be used to speed up the query process. Instead of scanning through every document in turn, IBM Cloudant can jump to the relevant part of the index (say, the section on 20th century books) and retrieve the data much more quickly.\n\nIBM Cloudant Query indexes include two types of indexes: type=json and type=text. These indexes are backed by two underlying indexing technologies that we meet in subsequent parts of this course.\n\nAn index is defined when you POST some JSON to a database's _index endpoint.\n\nThe index object contains a fields array, which specifies which document attributes to index. Usually, the fields that need indexing are equivalent to the attributes used in the selector of a query you're going to use to retrieve the data. That is, if you need to query by the date field, we need to index the date field.\n\nAlthough the name of an index is optional, it's good practice and we follow this convention. It's good to ask IBM Cloudant a question and specify the name of the index you intend it to use. This practice saves IBM Cloudant from having to choose which index to use from the available ones, and it makes it easy for you to remember which index is which.\n\nLet's create an index on our books database from the dashboard. Select the database, then choose the Design Documents tab and Query Indexes from the menu.\n\nAny existing indexes are listed on the side: A special index must exist that represents the primary index, based on the document's _id.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00639-7-2032","score":20.8794956207,"text":"\nSelector syntax \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query language is expressed as a JSON object that describes documents of interest. Within this structure, you can apply conditional logic by using specially named fields.\n\nThe IBM Cloudant Query language has some similarities with MongoDB query documents, but these similarities arise from a commonality of purpose and don't necessarily extend to equivalence of function or result.\n\n\n\n Selector basics \n\nElementary selector syntax requires you to specify one or more fields, and the corresponding values needed for those fields. The following example selector matches all documents that have a director field that contains the value Lars von Trier.\n\nSee the following example of a simple selector:\n\n{\n\"selector\": {\n\"director\": \"Lars von Trier\"\n}\n}\n\nIf you created a full text index by specifying \"type\":\"text\" when the index was created, you can use the $text operator to select matching documents. In the following example, the full text index is inspected to find any document that contains the word Bond.\n\nSee the following example of a simple selector for a full_text index:\n\n{\n\"selector\": {\n\"$text\": \"Bond\"\n}\n}\n\nYou can create more complex selector expressions by combining operators. However, for IBM Cloudant Query indexes of type json, you can't use \"combination\" or \"array logical\" operators such as $regex as the basis of a query. Only the equality operators such as $eq, $gt, $gte, $lt, and $lte - but not$ne - can be used as the basis of a more complex query. For more information about creating complex selector expressions, see [Creating selector expressions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-selector-syntaxcreating-selector-expressions).\n\n\n\n\n\n Selector with two fields \n\nIn the following example, the selector matches any document with a name field that contains Paul, and that also has a location field with the value \"Boston\".\n\nSee the following example of a more complex selector:\n\n{\n\"selector\": {\n\"name\": \"Paul\",\n\"location\": \"Boston\"\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-selector-syntax"},{"document_id":"ibmcld_00539-2548-4016","score":20.8005752563,"text":"\n\"type\": \"json\"\n}\n\n\n\n\n\n Can I sort in reverse order? \n\nYes! IBM Cloudant Query supports sorting the result set in ascending or descending order, but not a combination of the two. For example, a query that sorts some fields in ascending order, and a query where descending is not allowed.\n\nThis query returns documents that match firstname and surname and sorts by surname\/firstname\/date descending:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\n{ \"firstname\": \"desc\" },\n{ \"surname\": \"desc\" },\n{ \"date\": \"desc\" }\n],\n\"limit\": 10\n}\n\nA suitable index must be present that contains the selector fields and the sort fields. Otherwise, IBM Cloudant refuses to execute the query. A suitable index definition for the previous query is shown next:\n\n{\n\"index\": {\n\"fields\": [\n\"firstname\",\n\"surname\",\n\"date\"\n]\n},\n\"ddoc\": \"jsonindexes\",\n\"name\": \"byNameAndDate\",\n\"type\": \"json\"\n}\n\nThe previous index is suitable for both ascending and descending sort order.\n\n\n\n\n\n How can I tell if an index is backing a query? \n\nThe [POST \/{db}\/_explain](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=javapostexplain) API endpoint when passed a JSON object that is usually sent to the [POST \/{db}\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) endpoint, explains how such a query is handled and which indexes, if any, might be used.\n\nIf the index object in the response indicates that \"all_docs\" is being used, a full database scan is required to service the query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_00555-7-1930","score":20.4772567749,"text":"\nHow JavaScript Object Notation (JSON) works \n\nMost requests and responses to and from IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae use [JSON](https:\/\/en.wikipedia.org\/wiki\/JSON) for formatting the content and structure of the data and responses.\n\nIn IBM Cloudant databases, the JSON object is used to represent various structures, including all documents in a database.\n\nParsing JSON into a JavaScript object is supported through the JSON.parse() function in JavaScript, or through various [libraries](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-client-librariesclient-libraries) that perform the parsing of the content into a JavaScript object for you. Libraries for parsing and generating JSON are available for many major programming languages.\n\nJSON is used because it's the simplest and easiest solution for working with data that uses a web browser. As a result, JSON structures can be evaluated and used as JavaScript objects within the web browser environment. JSON also integrates with the server-side JavaScript used within IBM Cloudant. JSON documents are always UTF-8 encoded.\n\nBe careful to follow these guidelines:\n\n\n\n* Your JSON structures are valid.\n* You normalize strings in JSON documents retrieved from IBM Cloudant.\n\n\n\nJSON supports the same basic types that are supported by JavaScript: numbers, strings, Booleans, arrays, and objects.\n\n\n\n Numbers \n\nNumbers can be integer or floating point values.\n\n\n\n Example of a number in JSON format \n\n123\n\n\n\n\n\n\n\n Strings \n\nStrings must be enclosed by double quotation marks. Strings support Unicode characters and escaping a backslash.\n\n\n\n Example of a string in JSON format \n\n\"A String\"\n\n\n\n\n\n\n\n Booleans \n\nA true or false value.\n\n\n\n Example of a boolean in JSON format \n\n{\n\"value\": true\n}\n\n\n\n\n\n\n\n Arrays \n\nA list of values enclosed in brackets. The values that are enclosed can be any valid JSON.\n\n\n\n Example of an array in JSON format \n\n[\n\"one\",\n2,\n\"three\",\n],\ntrue,\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-json-works"},{"document_id":"ibmcld_13493-1220-3010","score":20.3963890076,"text":"\n* If the format of the input objects is CSV and a delimiter other than the default , (comma) is used, you must specify the delimiter by using the FIELDS TERMINATED BY option of the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause. All single Unicode characters are allowed as delimiters.\n* By default, it is assumed that CSV input objects have a header line that specifies the names of the input columns. If the objects don't have a header line, you must specify NOHEADER in the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause.\n* By default, it is assumed that JSON input objects consist of a single JSON record per line. If individual records span multiple lines, you must specify MULTILINE in the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause.\n* If required, you can use JOIN constructs to join data from several input URIs, even if those URIs point to different instances of Cloud Object Storage.\n* Use the INTO clause of a [query](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencechapterSQLQueryStatement) to specify the output [URI](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-runningunique), that is, the location to which the result is to be written and the wanted result format.\n\n\n\n2. The Target location field displays where the result is stored. An initial bucket in one of your Object Storage instances is automatically created for you when you open the UI. It is then chosen as your default location, if your query does not specify an INTO clause. To ensure the automatic setup of an initial bucket, do the following steps in advance:\n\n\n\n* You must create an Object Storage instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-running"},{"document_id":"ibmcld_00580-6386-8382","score":20.3704204559,"text":"\nIt has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.\n\nDevelopers like this flexibility because they can design their data in their code, turn it into JSON, and write it to the database.\n\nIt's still important to think about the shape of your data, especially in terms of how you are going to query and index it, as we see later.\n\nData design is still required, but strictly speaking that database doesn't need to know about your schema.\n\nLet's say we want to create a database of US presidents. We can simply devise our \"model\" of the data in our app, turn it into JSON, and write it to the database. In this case, we are using a common CouchDB convention: the \"type\" field indicates the data type of the document.\n\nIf at a future date we decide we want to add more data to our \"schema\", we can simply write a new object to the database with no complaints from IBM Cloudant. We could decide to add the \"address\" object only to the following documents:\n\n\n\n* Documents that are created from now on.\n* Only documents that we have addresses for.\n\n\n\nIn other words, documents of the same type can have fields present or missing.\n\nYour database's schema can evolve over time to match your application's needs. You don't (necessarily) need to tell the database about the schema change - write new documents in the new format.\n\nWe can even store multiple document \"types\" in the same database. In this case, people, books, and places reside in the same database. We know which is which because of the \"type\" field (this field is a convention and not something that means anything to IBM Cloudant).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00579-1483-3406","score":20.3156089783,"text":"\nSince the index does not store the document, you can access any field without thinking ahead about what to store in the index.\n* The disadvantage is that getting the document back is more costly than the alternative of emitting data into the index itself. First, the database has to look up the requested key in the index and then read the associated document. Also, if you\u2019re reading the whole document, but need only a single field, you\u2019re making the database read and transmit data that you don\u2019t need.\n\n\n\nThis example also means that a potential race condition exists here. The document might change, or be deleted, between the index and document read (although unlikely in practice).\n\nEmitting data into the index (a so-called \u201cprojection\u201d in relational algebra terms) means that you can fine-tune the exact subset of the document that you need. In other words, you don\u2019t need to emit the whole document. Emit a value that represents only the data you need in the app that is a cut-down object with minimal details, for example:\n\nemit(doc.indexed_field, {name: doc.name, dob: doc.dob});\n\nIf you change your mind on what fields you want to emit, the index needs rebuilding.\n\nIBM Cloudant Query\u2019s JSON indexes use views this way under the hood. IBM Cloudant Query can be a convenient replacement for some types of view queries, but not all. Do take the time to understand when to use one or the other.\n\n\n\n* IBM Cloudant Query [docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query)\n* IBM Cloudant guide to using [views](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsusing-views)\n* Performance implications of using [include_docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsmulti-document-fetching)\n\n\n\n\n\n\n\n Never rely on the default behavior of IBM Cloudant Query\u2019s no-indexing \n\nIt\u2019s tempting to rely on IBM Cloudant Query's ability to query without creating explicit indexes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00580-4796-6846","score":20.2501773834,"text":"\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.\n\n\n\n* The first example shows a person object, storing strings, booleans, and an array of tags.\n* The second example shows brief attribute names to save on storage and represents a web event such as click a website.\n* The last example shows how the document may itself contain subjects.\n\n\n\nA note on dates. JSON has no native Date type, so dates are usually stored in 30-October-2018 or similar formats. We return to dates later.\n\nNow, for your first practical exercise, visit www.ibm.com\/cloud. Register an account with the IBM Cloud, if you don't have one already.\n\nOnce registered, you can click services, search for the Cloudant database, and provision a new service.\n\nThe IBM Cloudant Lite service provides a free plan to allow users to try IBM Cloudant in a limited capacity while in development. Its bigger brother, the Standard Plan, is a paid-for service where you specify the number of reads, writes, and queries per second for your application and that capacity is reserved for you. You pay for the capacity you provision and your data storage usage.\n\nThe Lite plan operates in a similar way. It has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00510-7123-9213","score":20.0411071777,"text":"\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1. IBM Cloudant is expensive as a block store.\n2. IBM Cloudant\u2019s internal implementation is not efficient in handling large amounts of binary data.\n\n\n\nSo, slow and expensive.\n\nIBM Cloudant is acceptable for small assets and occasional use. As a rule, if you need to store binary data alongside IBM Cloudant documents, it\u2019s better to use a separate solution more suited for this purpose. You need store only the attachment metadata in the IBM Cloudant document. Yes, that means you need to write some extra code to upload the attachment to a suitable block store of your choice. Verify that it succeeded before you store the token or URL to the attachment in the IBM Cloudant document.\n\nYour databases are smaller, cheaper, faster, and easier to replicate. For more information, see the following websites:\n\n\n\n* IBM Cloudant docs on [attachments](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments)\n* Detaching IBM Cloudant attachments to [Object Storage](https:\/\/medium.com\/codait\/detaching-cloudant-attachments-to-object-storage-with-serverless-functions-99b8c3c77925)\n\n\n\n\n\n\n\n Fewer databases are better than many \n\nIf you can, limit the number of databases per IBM Cloudant account to 500 or fewer. While this particular number is not magic (IBM Cloudant can safely handle more), several use cases exist that are adversely affected by large numbers of databases in an account.\n\nThe replicator scheduler has a limited number of simultaneous replication jobs that it is prepared to run. As the number of databases grows, the replication latency is likely to increase if you try to replicate everything contained in an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_07232-3248-5115","score":19.7798881531,"text":"\nPNG, TIFF, and JPEG images embedded in PDF, Word, PowerPoint, and Excel files are also scanned, and any text is extracted.\n\nView the following table to see the objects that a data source can crawl and which data sources support crawling new and modified documents during a refresh:\n\n\n\nTable 1. Data sources that support crawling new and modified documents during refresh and objects that can be crawled\n\n Data source Crawls new and modified documents during refresh? Compatible objects that can be crawled \n\n Box (Application level access) No Files, folders \n Box (Enterprise level access) Yes Files, folders \n Salesforce Yes Any default and custom objects that you have access to, accounts, contacts, cases, contracts, knowledge articles, attachments \n Microsoft SharePoint Online Yes SiteCollections, websites, lists, list items, document libraries, custom metadata, list item attachments \n Microsoft SharePoint OnPrem Yes SiteCollections, websites, lists, list items, document libraries, custom metadata, list item attachments \n Web Crawl No Websites, website subdirectories \n IBM Cloud Object Storage Yes Buckets, files \n\n\n\n\n\n\n\n Available data sources \n\nYou can use Discovery to crawl from the following data sources:\n\n\n\n* [Box](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sourcesconnectbox)\n* [Salesforce](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sourcesconnectsf)\n* [Microsoft SharePoint Online](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sourcesconnectsp)\n* [Microsoft SharePoint OnPrem](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sourcesconnectsp_op)\n* [Web Crawl](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sourcesconnectwebcrawl)\n* [IBM Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sourcesconnectcos)\n\n\n\nYou can connect to a data source using the Discovery tooling or the API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sources"},{"document_id":"ibmcld_00556-10831-12062","score":19.1601524353,"text":"\nThe content must be provided by using [BASE64](https:\/\/en.wikipedia.org\/wiki\/Base64) representation, as shown in the example.\n\nA full list of media types is available in the [media types](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types) article.\n\nSee the following example JSON document that includes an inline attachment of a jpeg image:\n\n{\n\"_id\":\"document_with_attachment\",\n\"_attachments\":\n{\n\"name_of_attachment\": {\n\"content_type\":\"image\/jpeg\",\n\"data\": \"iVBORw0KGgoAA... ...AASUVORK5CYII=\"\n}\n}\n}\n\n\n\n\n\n Performance considerations \n\nWhile document attachments are useful, they do have implications for application performance. In particular, having too many attachments can have an adverse performance impact during replication.\n\nFor example, if your application requires storage for multiple images as attachments or includes large images, you must use an alternative [BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object) storage mechanism to store the images. You might then use IBM Cloudant to keep the image metadata, such as URLs to the BLOB store.\n\nYou might find it helpful to do performance testing for your specific application to determine which approach works best for your circumstances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_00556-7-1696","score":18.8838272095,"text":"\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image\/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) or [_users](https:\/\/cloud.ibm.com\/apidocs\/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID\/$ATTACHMENT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_00576-7385-9302","score":18.1771259308,"text":"\nIBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether. Otherwise, separate databases, for example, users, orders, products, might be better so that secondary indexes are specific to each object type.\n\nIf you're storing arrays of objects within a document, consider whether the array items must really be their own document. For example, a product and each product review must be stored in separate documents, but a user and each of that user's orders must have their own document.\n\nIf you have an ever-growing data set, then you probably don't want to store data in a single, ever-growing database. Data is best stored in time-boxed databases that allow older data to be archived and deleted cleanly. Deleting an IBM Cloudant document leaves a tombstone document behind, so don't rely on deleting documents to recover disk space. Instead, you must rely on deleting whole databases.\n\nJSON doesn't offer a native way to store dates or timestamps. Choose your [date format](https:\/\/blog.cloudant.com\/2018\/05\/24\/Date-formats.html) carefully if you intend to query it later.\n\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00518-7-1546","score":18.0888729095,"text":"\nDesign document management \n\nThe scalable JSON data store for IBM Cloudant has several querying mechanisms, all of which generate indices that are created and maintained separately from the core data.\n\nArticle contributed by Glynn Bird, Developer Advocate at IBM Cloudant, [glynn@cloudant.com](mailto:glynn@cloudant.com).\n\nIndexing isn't performed immediately when a document is saved. Instead, indexing is scheduled to happen later, providing a faster, non-blocking write throughput.\n\n\n\n* MapReduce views are indexes into the data set with key value pairs that are stored in a BTree for efficient retrieval by key or range of keys.\n* Search Indexes are constructed by using Apache Lucene to allow free-text search, faceting, and complex ad hoc queries.\n\n\n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae's [search indexes](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search) and [MapReduce views](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreduce) are configured by adding design documents to a database. Design documents are JSON documents that include the instructions about how the view or index is to be built. Let's take a simple example. Assume that you have a simple collection of data documents, similar to the following example.\n\nSee an example of a simple data document:\n\n{\n\"_id\": \"23966717-5A6F-E581-AF79-BB55D6BBB613\",\n\"_rev\": \"1-96daf2e7c7c0c277d0a63c49b57919bc\",\n\"doc_name\": \"Markdown Reference\",\n\"body\": \"Lorem Ipsum\",\n\"ts\": 1422358827\n}\n\nEach data document includes a name, a body, and a timestamp.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-design-document-management"},{"document_id":"ibmcld_00576-1572-3411","score":18.0724010468,"text":"\nIn most cases, the information is returned in the form of a JSON document.\n\nHEAD\n: The HEAD method retrieves the HTTP header of a GET request without the body of the response.\n\nPOST\n: Upload data. In IBM Cloudant's API, the POST method sets values, uploads documents, sets document values, and starts some administration commands.\n\nPUT\n: Used to \"store\" a specific resource. In IBM Cloudant's API, PUT creates new objects, including databases, documents, views, and design documents.\n\nDELETE\n: Deletes the specified resource, including documents, views, and design documents.\n\nCOPY\n: A special method that copies documents and objects.\n\nIf the client (such as some web browsers) doesn't support the use of HTTP methods, POST can be used instead with the X-HTTP-Method-Override request header set to the actual HTTP method.\n\n\n\n Method not allowed error \n\nIf you use an unsupported HTTP request type with a URL that doesn't support the specified type, a [405](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) error is returned. The error that lists the supported HTTP methods, as shown in the following example.\n\n\n\n Example error message in response to an unsupported request \n\n{\n\"error\":\"method_not_allowed\",\n\"reason\":\"Only GET,HEAD allowed\"\n}\n\n\n\n\n\n\n\n\n\n JSON \n\nIBM Cloudant stores documents that use JSON (JavaScript Object Notation) encoding, so anything encoded into JSON can be stored as a document. Files that include media, such as images, videos, and audio, are called BLOBs (Binary Large Objects). BLOBs can be stored as attachments associated with documents.\n\nMore information about JSON can be found in the [JSON Guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-json-works).\n\n\n\n\n\n Distributed systems \n\nBy using IBM Cloudant's API, you can interact with a collaboration of numerous machines, called a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_06968-15099-17180","score":17.9556121826,"text":"\n[checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/icons\/checkmark-icon.svg) \n\n\n\n\n\n* PDF files that are secured with a password or certificate are not supported. Vector objects, including SVG images and vectorized text, are not supported. Only images of the supported image file types that occur in the PDF are rendered.\n* Only single-page image files are supported.\n* Files within compressed archive files (ZIP, GZIP, TAR) are extracted. Discovery ingests the supported file types within the archive; it ignores all other file types. The file names must be encoded in UTF-8. Files with names that include Japanese characters, for example, must be renamed before they are added to the ZIP file.\n* Discovery supports MacOS ZIP files only if they are generated by using a command such as: zip -r my-folder.zip my-folder -x \".DS_Store\". ZIP files that are created by right-clicking a folder and clicking Compress are not supported.\n* PDF files that you upload as part of an archive file are not displayed in the advanced view for a query result that you open from the Improve and customize page. If you want the file to be viewable from the advanced view, reimport the PDF file separately from the archive file.\n\n\n\nWhen you add files to a Document Retrieval for Contracts project type, any file types that support SDU and OCR are processed with a pretrained Smart Document Understanding model and Optical Character Recognition automatically.\n\n\n\n\n\n Document limits \n\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_00474-7885-8455","score":17.6060714722,"text":"\nSummary \n\nToday, we combined two IBM Cloud services to optimize cost and user experience: IBM Cloudant as a document store and query engine and Databases for Redis as a content cache. Cached documents can be retrieved more quickly and more cheaply, but the tradeoff is that your application might be showing old data to your users for a time.\n\nIf you followed this tutorial, you must deprovision your resources to stop incurring charges. You can deprovision from the terraform directory on your terminal by typing the following command, terraform destroy --auto-approve.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-combine-ibm-services"},{"document_id":"ibmcld_10864-9002-10059","score":17.4036598206,"text":"\nIBM Cloud Object Storage can be used in addition to IBM Cloudant, where video and image metadata are stored in IBM Cloudant, and the media files are stored in IBM Cloud Object Storage.\n\n\n\n\n\n Event processing with Kafka or Event Streams \n\nCloud Functions is ideally to be used in combination with Kafka, IBM\u00ae Event Streams for IBM Cloud\u00ae (Kafka based), and other messaging systems. The event driven nature of those systems requires an event driven runtime to process messages. The runtime can apply business logic to those messages, which is exactly what Cloud Functions provides, with its feeds, triggers, and actions. Kafka and Event Streams are often used for high and unpredictable workload volumes, and require that consumers of those messages need to be scalable on a moment's notice. This situation is, once again, ideal for Cloud Functions. Cloud Functions has built-in capability to consume messages as well as publish messages that are provided in the [Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streams) package.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-use_cases"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12904-23555-25450","score":25.5075759888,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00558-23465-25360","score":25.5075759888,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00581-0-1268","score":24.1739959717,"text":"\n\n\n\n\n\n\n  Limits \n\nLimits that pertain to the usage of IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases are shown in the following tables.\n\n\n\n  Databases \n\n\n\nTable 1. Limits for databases\n\n Description     Limit                                                                             \n\n Database size   Consult the IBM Cloudant team if your database is likely to exceed 5 TB in size.  \n Partition size  10 GB                                                                             \n\n\n\n\n\n\n\n  Indexes \n\n\n\nTable 2. Limits for indexes\n\n Description                  Limit     \n\n Number of global indexes     Unlimited \n Number of partition indexes  10        \n\n\n\n\n\n\n\n  Request payload \n\n\n\nTable 3. Limits for request payload\n\n Description         Limit \n\n Total request size  10 MB \n Document size       1 MB  \n Attachment size     10 MB \n\n\n\n\n\n\n\n  Request timeouts \n\n\n\nTable 4. Limits for request timeouts\n\n Description     Limit      \n\n Default         60 seconds \n _partition\/*    5 seconds  \n\n\n\n\n\n\n\n  Query \n\n\n\nTable 5. Limits for query results\n\n Description                    Limit     \n\n Default                        Unlimited \n _partition\/* default           2000      \n _search                        200       \n _find by using text index      200       \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-limits"},{"document_id":"ibmcld_00510-5537-7566","score":22.7781906128,"text":"\nInstead, keep orders separate as their own document type, referencing the customer ID. Now the model is immutable. To add an order, I create a new order document in the database, which cannot generate conflicts.\n\nTo be able to retrieve all orders for a specific customer, we can employ a view, which we cover later.\n\nAvoid constructs that rely on updates to parts of existing documents, where possible. Bad data models are often hard to change after you\u2019re in production.\n\nThe previous pattern can be solved efficiently by using partitioned databases, which are covered in greater detailed later.\n\nFor more information, see the following documentation:\n\n\n\n* IBM Cloudant guide to [data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq)\n* [Database partitions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning)\n\n\n\n\n\n\n\n Keep documents small \n\nIBM Cloudant imposes a max doc size of 1 MB. This limit does not mean that a close-to-1-MB document size is a good idea. On the contrary, if you find you are creating documents that exceed single-digit KB, you probably need to revisit your model. Several things in IBM Cloudant become less performant as documents grow. JSON decoding is costly, for example.\n\nLet's look at the following sections: Documents must group data that mostly changes together and Keep documents small. It\u2019s worth stressing that models that rely on updates have a maximum volume limit of 1 MB, the cut-off for document size. This size isn\u2019t what you want.\n\n\n\n\n\n Avoid using attachments \n\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_12748-0-2435","score":20.6587753296,"text":"\n\n\n\n\n\n\n  Limits \n\nIBM Cloud\u00ae Security and Compliance Center has the following known limits that might impact your experience.\n\n\n\nTable 1. Security and Compliance Center limits\n\n                            Limit                                                        \n\n Custom rules               500 per enterprise account  <br>100 per stand-alone account  \n Rule description           256 characters                                               \n Rule size                  4096 characters                                              \n Target                     1 per rule                                                   \n Condition                  16 per rule                                                  \n Property                   24 per condition                                             \n Label                      32 per rule                                                  \n Custom libraries           10 per enterprise account  <br>5 per stand-alone account     \n Library name               64 Characters                                                \n Library description        256 characters                                               \n Library size               Less than 1 MB                                               \n Profile name               64 characters                                                \n Profile description        256 Characters                                               \n Profile size               Less than 1 MB                                               \n Custom profiles            20 per enterprise account  <br>5 per stand-alone account     \n Control                    1200 per library  <br>600 per profile                        \n Control name               64 characters                                                \n Control description        256 characters                                               \n Specification              100 per control per library  <br>400 per control per profile \n Specification description  256 characters                                               \n Assessment                 10 per specification per library or profile                  \n Attachment                 50 per account                                               \n Exclusion                  8 per attachment                                             \n Scan                       1 per attachment - at any time                               \n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-service-limits"},{"document_id":"ibmcld_00500-14708-16372","score":20.5457420349,"text":"\nWe limit documents to a maximum size of 64 MB.\n\n\n\n\n\n No JavaScript reducers when options.partitioned is true \n\nDesign documents with options.partitioned set to true can't contain JavaScript reduce functions, only built-ins Erlang reducers such as _stats.\n\n\n\n\n\n\n\n Storing the view definition \n\nEach view is a JavaScript function. Views are stored in design documents. So, to store a view, IBM Cloudant simply stores the function definition within a design document. A design document can be [created or updated](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-design-documentscreating-or-updating-a-design-document) just like any other document.\n\nTo store a view definition, PUT the view definition content into a _design document.\n\nIn the following example, the getVerifiedEmails view is defined as a map function, and is available within the views field of the design document.\n\nUse the PUT method to add a view into a design document:\n\nPUT $SERVICE_URL\/$DATABASE\/_design\/$DDOC HTTP\/1.1\nContent-Type: application\/json\n\nThe following sample adds a new getVerifiedEmails named view function to the allusers design document with view definition:\n\n{\n\"views\": {\n\"getVerifiedEmails\": {\n\"map\": \"function(user) { if(user.email_verified === true){ emit(doc.email, {name: user.name, email_verified: user.email_verified, joined: user.joined}) }} \"\n}\n}\n}\n\nSee the request examples:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X PUT \"$SERVICE_URL\/users\/_design\/allusers\" --data '{\n\"views\": {\n\"getVerifiedEmails\": {\n\"map\": \"function(user) { if(user.email_verified === true){ emit(doc.email, {name: user.name, email_verified: user.email_verified, joined: user.joined}) }}\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreduce"},{"document_id":"ibmcld_00556-7-1696","score":20.0232696533,"text":"\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image\/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) or [_users](https:\/\/cloud.ibm.com\/apidocs\/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID\/$ATTACHMENT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_01234-7-2066","score":19.7051887512,"text":"\nGetting started with File Storage for Classic \n\nIBM Cloud\u00ae File Storage for Classic is persistent, fast, and flexible network-attached, NFS-based File Storage for Classic. In this network-attached storage (NAS) environment, you have total control over your file shares function and performance. File Storage for Classic shares can be connected to up to 64 authorized devices over routed TCP\/IP connections for resiliency.\n\nFor more information about using File Storage for Classic with the IBM Cloud\u00ae Kubernetes Service, see [Storing data on classic IBM Cloud File Storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-file_storage).\n\n\n\n Before you begin \n\nFile Storage for Classic volumes can be provisioned from 20 GB to 12 TB with two options:\n\n\n\n* Provision Endurance tiers that feature pre-defined performance levels and other features like snapshots and replication.\n* Build a high-powered Performance environment with allocated input\/output operations per second (IOPS).\n\n\n\nFor more information about the File Storage for Classic offering, see [What is IBM Cloud File Storage](https:\/\/www.ibm.com\/products\/file-storage).\n\n\n\n\n\n Step 1: Provisioning considerations \n\n\n\n Block size \n\nThe IOPS value for both Endurance and Performance is based on a 16-KB block size with a 50\/50 read and write, 50\/50 random and sequential workload. A 16-KB block is the equivalent of one write to the volume.\n\nThe block size that is used by your application directly impacts the storage performance. If the block size that is used by your application is smaller than 16 KB, the IOPS limit is realized before the throughput limit. Conversely, if the block size that is used by your application is larger than 16 KB, the throughput limit is realized before to the IOPS limit.\n\n\n\nTable 1 shows examples of how block size and IOPS affect the throughput. Average IO size x IOPS = Throughput in MB\/s.\n\n Block Size (KB) IOPS Throughput (MB\/s) \n\n 4 1,000 4 \n 8 1,000 8 \n 16 1,000 16 \n 32 500 16 \n 64 250 16 \n 128 128 16 \n 512 32 16 \n 1024 16 16 \n\n\n\n\n\n\n\n Authorized hosts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-getting-started"},{"document_id":"ibmcld_16727-1271119-1273166","score":19.6570968628,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1268470-1270517","score":19.6570968628,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12904-23555-25450","score":19.4624137878,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00558-23465-25360","score":19.4624137878,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00581-0-1268","score":17.841627121,"text":"\n\n\n\n\n\n\n  Limits \n\nLimits that pertain to the usage of IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases are shown in the following tables.\n\n\n\n  Databases \n\n\n\nTable 1. Limits for databases\n\n Description     Limit                                                                             \n\n Database size   Consult the IBM Cloudant team if your database is likely to exceed 5 TB in size.  \n Partition size  10 GB                                                                             \n\n\n\n\n\n\n\n  Indexes \n\n\n\nTable 2. Limits for indexes\n\n Description                  Limit     \n\n Number of global indexes     Unlimited \n Number of partition indexes  10        \n\n\n\n\n\n\n\n  Request payload \n\n\n\nTable 3. Limits for request payload\n\n Description         Limit \n\n Total request size  10 MB \n Document size       1 MB  \n Attachment size     10 MB \n\n\n\n\n\n\n\n  Request timeouts \n\n\n\nTable 4. Limits for request timeouts\n\n Description     Limit      \n\n Default         60 seconds \n _partition\/*    5 seconds  \n\n\n\n\n\n\n\n  Query \n\n\n\nTable 5. Limits for query results\n\n Description                    Limit     \n\n Default                        Unlimited \n _partition\/* default           2000      \n _search                        200       \n _find by using text index      200       \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-limits"},{"document_id":"ibmcld_09386-0-672","score":17.5042572021,"text":"\n\n\n\n\n\n\n  Limits when sending logs \n\nThere are limits when you send send logs to an IBM\u00ae Log Analysis instance.\n\nBody size\n:   Maximum size of 10 MB at ingestion.\n\nMessage size\n:   Maximum size of 16 KB at ingestion. After 16K, the ingested data is truncated.\n\nMetadata size\n:   Maximum size of 32 KB.\n\nHostname length\n:   Maximum size of 256 characters.\n\nApp name length\n:   Maximum size of 512 characters.\n\nLog Level\n:   Maximum size of 80 characters.\n\nTags\n:   Maximum size of 80 characters.\n\nDepth of nested fields\n:   The maximum number of nested fields that are parsed at ingestion is 3.\n\nNumber of unique fields\n:   A maximum of 500 fields are indexed per day.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-ingest_limits"},{"document_id":"ibmcld_16727-1271119-1273166","score":17.2079391479,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1268470-1270517","score":17.2079391479,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_00510-5537-7566","score":16.7683448792,"text":"\nInstead, keep orders separate as their own document type, referencing the customer ID. Now the model is immutable. To add an order, I create a new order document in the database, which cannot generate conflicts.\n\nTo be able to retrieve all orders for a specific customer, we can employ a view, which we cover later.\n\nAvoid constructs that rely on updates to parts of existing documents, where possible. Bad data models are often hard to change after you\u2019re in production.\n\nThe previous pattern can be solved efficiently by using partitioned databases, which are covered in greater detailed later.\n\nFor more information, see the following documentation:\n\n\n\n* IBM Cloudant guide to [data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq)\n* [Database partitions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning)\n\n\n\n\n\n\n\n Keep documents small \n\nIBM Cloudant imposes a max doc size of 1 MB. This limit does not mean that a close-to-1-MB document size is a good idea. On the contrary, if you find you are creating documents that exceed single-digit KB, you probably need to revisit your model. Several things in IBM Cloudant become less performant as documents grow. JSON decoding is costly, for example.\n\nLet's look at the following sections: Documents must group data that mostly changes together and Keep documents small. It\u2019s worth stressing that models that rely on updates have a maximum volume limit of 1 MB, the cut-off for document size. This size isn\u2019t what you want.\n\n\n\n\n\n Avoid using attachments \n\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_12748-0-2435","score":16.7639026642,"text":"\n\n\n\n\n\n\n  Limits \n\nIBM Cloud\u00ae Security and Compliance Center has the following known limits that might impact your experience.\n\n\n\nTable 1. Security and Compliance Center limits\n\n                            Limit                                                        \n\n Custom rules               500 per enterprise account  <br>100 per stand-alone account  \n Rule description           256 characters                                               \n Rule size                  4096 characters                                              \n Target                     1 per rule                                                   \n Condition                  16 per rule                                                  \n Property                   24 per condition                                             \n Label                      32 per rule                                                  \n Custom libraries           10 per enterprise account  <br>5 per stand-alone account     \n Library name               64 Characters                                                \n Library description        256 characters                                               \n Library size               Less than 1 MB                                               \n Profile name               64 characters                                                \n Profile description        256 Characters                                               \n Profile size               Less than 1 MB                                               \n Custom profiles            20 per enterprise account  <br>5 per stand-alone account     \n Control                    1200 per library  <br>600 per profile                        \n Control name               64 characters                                                \n Control description        256 characters                                               \n Specification              100 per control per library  <br>400 per control per profile \n Specification description  256 characters                                               \n Assessment                 10 per specification per library or profile                  \n Attachment                 50 per account                                               \n Exclusion                  8 per attachment                                             \n Scan                       1 per attachment - at any time                               \n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-service-limits"},{"document_id":"ibmcld_12904-22084-23929","score":16.1948928833,"text":"\nAs the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3. The instance drops back to 9.5 GB for the next 10 minutes of hour 02:00, then increases to 108 GB for the next 25 minutes of hour 02:00. Finally, your instance finishes the hour and indeed the rest of the month by dropping down to 28 GB.\n\nThis pattern means the maximum number of GB more than the plan allocation was 88 GB during hour 2 of day 3. From hour 03:00 of day 3, and for the rest of the month, your instance was 8 GB more than the plan allocation.\n\nTherefore, from hour 02:00 of day 3, your bill includes an overage based on 88 GB x 1 hour = 88 GB hours.\n\nFrom hour 03:00 of day 3 to the end of day 3, your bill includes an overage based on 8 GB x 21 hours = 168 GB hours.\n\nFrom hour 00:00 of day 4 until the end of the month (of 30 days), your bill includes an overage. The overage is based on 8 GB x 24 hours x 27 days = 5184 GB hours.\n\nThe total overage bill for the month is based on a total of 88 + 168 + 5184 = 5440 GB hours.\n\n\n\n\n\n\n\n Request and document size limits \n\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00558-21994-23839","score":16.1948928833,"text":"\nAs the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3. The instance drops back to 9.5 GB for the next 10 minutes of hour 02:00, then increases to 108 GB for the next 25 minutes of hour 02:00. Finally, your instance finishes the hour and indeed the rest of the month by dropping down to 28 GB.\n\nThis pattern means the maximum number of GB more than the plan allocation was 88 GB during hour 2 of day 3. From hour 03:00 of day 3, and for the rest of the month, your instance was 8 GB more than the plan allocation.\n\nTherefore, from hour 02:00 of day 3, your bill includes an overage based on 88 GB x 1 hour = 88 GB hours.\n\nFrom hour 03:00 of day 3 to the end of day 3, your bill includes an overage based on 8 GB x 21 hours = 168 GB hours.\n\nFrom hour 00:00 of day 4 until the end of the month (of 30 days), your bill includes an overage. The overage is based on 8 GB x 24 hours x 27 days = 5184 GB hours.\n\nThe total overage bill for the month is based on a total of 88 + 168 + 5184 = 5440 GB hours.\n\n\n\n\n\n\n\n Request and document size limits \n\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00547-7-1654","score":23.6391563416,"text":"\nGetting started with IBM Cloudant \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Getting started tutorial demonstrates how to use the IBM Cloud\u00ae dashboard to create an IBM Cloudant service instance and obtain service credentials to connect to it. Finally, it guides you through the creation of a simple, locally hosted web application that uses your IBM Cloudant database.\n\n\n\n Objectives \n\n\n\n* Create a service instance.\n* Create an IBM Cloudant service credential.\n\n\n\n\n\n\n\n Step 1: Creating a service instance \n\n\n\n1. Log in to your IBM Cloud account, and click Create resource.\n\nZoom\n\n![IBM Cloud Dashboard, which includes Build tile, Monitor your resources tile, Create and deploy an application tile, API Connect tile, Integrate Watson with anything tile, and Watson starter kits tile.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/\/tutorials\/images\/img0001.png)\n\nFigure 1. IBM Cloud Dashboard\n\nThe IBM Cloud Dashboard can be found at: [https:\/\/cloud.ibm.com\/](https:\/\/cloud.ibm.com\/). After you authenticate with your username and password, you're presented with the IBM Cloud Dashboard.\n2. Type Cloudant in the Search bar and click to open it.\n3. Select an offering and an environment.\n4. Type an instance name.\n\nZoom\n\n![Create the IBM Cloudant service name and credentials.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/tutorials\/images\/img0005b.png)\n\nFigure 2. IBM Cloudant service name and credentials\n\n(In this example, the instance name is Cloudant-o7.) Verify that the resource group and authentication methods are correct. Add a tag if you like.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant"},{"document_id":"ibmcld_04650-5479-6774","score":23.1782798767,"text":"\nThis file will get used ONLY when the app is running locally. When running in IBM Cloud, the credentials will be read from the VCAP_SERVICES environment variable.\n\n\n\n1. Create a file called .env in the get-started-go directory with the following content:\n\nCLOUDANT_URL=\n2. Find your app in the IBM Cloud [resource list](https:\/\/cloud.ibm.com\/resources). On the Service Details page for your app, click Connections in the sidebar. Click the IBM Cloudant menu icon (\u2026) and select View credentials.\n3. Copy and paste just the url from the credentials to the CLOUDANT_URL field of the .env file and save the changes. The result will be something like:\n\nCLOUDANT_URL=https:\/\/123456789 ... bluemix.cloudant.com\n4. Run your app locally.\n\ngo run main.go\n5. View your app at: http:\/\/localhost:8080. Any names that you enter into the app are added to the database.\n\n\n\nYour local app and the IBM Cloud app share the database. View your IBM Cloud app at the URL listed in the output of the push command. Names you add from either app show in both apps when you refresh the browsers.\n\nIf you don't need your app live, stop it so you don't incur any unexpected charges.\n\n\n\n\n\n Next steps \n\n\n\n* [Samples](https:\/\/ibm-cloud.github.io)\n* [Architecture Center](https:\/\/www.ibm.com\/cloud\/architecture\/architectures)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-getting-started-go"},{"document_id":"ibmcld_05499-1332-3032","score":22.8557357788,"text":"\nYou can create one [from the console](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) or by using CLI commands. In addition, create service credentials that you can pass to your application.\n\n\n\n1. Create an IBM Cloudant service instance, follow the steps in [Getting started with IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant). Name your instance CloudantFruitCounter. Be sure to complete the task by creating your service credentials.\n2. Open the IBM Cloudant dashboard for your instance and click Create database.\n3. In the Create database window, enter the database name fruitcounter.\n4. Do not select the Partitioned option, and click Create.\n\n\n\n\n\n\n\n Step 2: Test your application locally \n\nBefore you create your code as an application in Code Engine, test your code locally to make sure that it is functioning correctly.\n\n\n\n1. Retrieve the IBM Cloudant service credentials from the IBM Cloudant dashboard. For more information about retrieving credentials, see [Creating service credentials](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudantcreating-service-credentials).\n2. Set environment variables with the values from the service credentials.\n\nexport CLOUDANT_URL=<your_url>\n\nexport CLOUDANT_APIKEY=<your_key>\n\nexport DBNAME=\"fruitcounter\"\n3. Clone the fruit-counter repository, change to this directory, and then install and start the dependencies.\n\ngit clone https:\/\/github.com\/IBM\/CodeEngine\ncd CodeEngine\/fruit-counter\nnpm install\nnpm run start\n4. Open a browser and go to [http:\/\/localhost:8080](http:\/\/localhost:8080).\n5. Pick your favorite fruit and submit your choice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-tutorial-cloudant-local"},{"document_id":"ibmcld_04650-7-1596","score":22.3075218201,"text":"\nGetting started with Go \n\nIBM\u00ae Cloud Foundry is deprecated and no longer supported as of 1 June 2023. For more information, see the [deprecation details](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-deprecationdep_details).\n\nCongratulations, you deployed a Hello World sample app on IBM Cloud\u00ae! To get started, follow this step-by-step guide. Or, [download the sample code](https:\/\/github.com\/IBM-Cloud\/go-cloudant) and explore on your own.\n\nBy following this getting started tutorial, you'll set up a development environment, deploy an app locally on IBM Cloud\u00ae, and integrate an IBM Cloud database service in your app.\n\nThroughout these docs, references to the Cloud Foundry CLI are now updated to the IBM Cloud CLI! The IBM Cloud CLI has the same familiar Cloud Foundry commands, but with better integration with IBM Cloud accounts and other services. Learn more about getting started with the IBM Cloud CLI in this tutorial.\n\n\n\n Before you begin \n\nYou'll need the following:\n\n\n\n* [IBM Cloud account](https:\/\/cloud.ibm.com\/registration)\n* [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli)\n* [Git](https:\/\/git-scm.com\/downloads)\n* [Go](https:\/\/golang.org\/dl\/)\n\n\n\n\n\n\n\n Step 1: Clone the sample app \n\n\n\n1. First, we'll set up the local environment by ensuring all GO environment variables are set properly. For example:\n\nmkdir $HOME\/work\nexport GOPATH=$HOME\/work\nexport PATH=$PATH:$GOPATH\/bin\n2. Change path to $GOPATH\/src\n\nmkdir $GOPATH\/src\ncd $GOPATH\/src\n\nNow you're ready to start working with the simple Go hello world app.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-getting-started-go"},{"document_id":"ibmcld_04652-5588-7168","score":22.2146587372,"text":"\nIn the get-started-node directory, create a file called vcap-local.json with the following content:\n\n{\n\"services\": {\n\"cloudantNoSQLDB\": [\n{\n\"credentials\": {\n\"url\":\"CLOUDANT_DATABASE_URL\"\n},\n\"label\": \"cloudantNoSQLDB\"\n}\n]\n}\n}\n2. Find your app in the IBM Cloud [resource list](https:\/\/cloud.ibm.com\/resources). On the Service Details page for your app, click Connections in the sidebar. Click the IBM Cloudant menu icon (\u2026) and select View credentials.\n3. Copy and paste just the url from the credentials to the url field of the vcap-local.json file, replacing CLOUDANT_DATABASE_URL.\n4. Run your app locally.\n\nnpm start\n\nView your local app at http:\/\/localhost:3000. Any names you enter into the app will now get added to the database.\n\n\n\nAvoid trouble: IBM Cloud defines the PORT environment variable when your app runs on the cloud. When you run your app locally, the PORT variable is not defined, so 3000 is used as the port number. See [Run your app locally](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-hints) for more information.\n\nYour local app and the IBM Cloud app are sharing the database. Names you add from either app will appear in both when you refresh the browsers.\n\nRemember, if you don't need your app live on IBM Cloud, stop the app so you don't incur any unexpected charges.\n\n\n\n\n\n Next steps \n\n[Manage your Node.js app](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-nodejs_runtime). Some example tasks include configuring caching and integrating third-party services.\n\nCheck out the following resources:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-getting-started-node"},{"document_id":"ibmcld_04654-5723-7203","score":21.8783531189,"text":"\nWhen running in IBM Cloud, the credentials will be read from the VCAP_SERVICES environment variable.\n\n\n\n1. Create a file called vcap-local.json in the get-started-python directory with the following content:\n\n{\n\"services\": {\n\"cloudantNoSQLDB\": [\n{\n\"credentials\": {\n\"username\":\"CLOUDANT_DATABASE_USERNAME\",\n\"password\":\"CLOUDANT_DATABASE_PASSWORD\",\n\"host\":\"CLOUDANT_DATABASE_HOST\"\n},\n\"label\": \"cloudantNoSQLDB\"\n}\n]\n}\n}\n2. Find your app in the IBM Cloud [resource list](https:\/\/cloud.ibm.com\/resources). On the Service Details page for your app, click Connections in the sidebar. Click the IBM Cloudant menu icon (\u2026) and select View credentials.\n3. Copy and paste the username, password, and host from the credentials to the same fields of the vcap-local.json file replacing CLOUDANT_DATABASE_USERNAME, CLOUDANT_DATABASE_PASSWORD, and CLOUDANT_DATABASE_HOST.\n4. Run your app locally.\n\npython hello.py\n\n\n\nView your app at: http:\/\/localhost:8000. Any names you enter into the app will now get added to the database.\n\nYour local app and the IBM Cloud app are sharing the database. View your IBM Cloud app at the URL listed in the output of the push command from above. Names you add from either app should appear in both when you refresh the browsers.\n\nRemember, if you don't need your app live, stop it so you don't incur any unexpected charges.\n\n\n\n\n\n Next steps \n\n\n\n* [Samples](https:\/\/ibm-cloud.github.io)\n* [Architecture Center](https:\/\/www.ibm.com\/cloud\/architecture\/architectures)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-getting-started-python"},{"document_id":"ibmcld_04649-2847-4956","score":21.8720397949,"text":"\nClick Public Applications to select Region and Runtime.\n4. Type a unique name for your app and click Create. The app name must be unique in the whole IBM Cloud environment.\n\n\n\nOnce created, a Getting started page is added to the left navigation pane. Follow the instructions in that page to download the starter code of your app, modify, and deploy it.\n\nThe app is created with one instance and 512 MB memory quota by default. You can increase the memory, or add more instances to get high availability of your app, for example, three instances with 1 GB memory per instance. Click Overview to specify your app instances and memory quota. For example, type 3 for instances and 1 GB for memory quota, and click Save. You can also see the files, logs, and environment variables to troubleshoot your problems.\n\n\n\n Binding a service by using IBM Cloud console \n\nAfter creating your app, connect to a database with your app. You can store and retrieve the app data by using a database query language. In this scenario, you decide to use the IBM Cloudant service that is provided by IBM Cloud.\n\nTo use IBM Cloud with your Cloud Foundry app, create a service instance and bind your app to the service instance:\n\n\n\n1. In the IBM Cloud catalog, select the IBM Cloudant service. Add a unique name for your IBM Cloudant service and click Create. In the Cloudant Manage panel, launch the service by clicking Launch.\n2. Click Connections. Then, click Create connection.\n3. Click Connect next to your app.\n4. The Restage App window is displayed. Click Restage.\n\n\n\nNow your app is bound to the IBM Cloudant service. The <VCAP_SERVICES> environment variable contains the data that is required for the app to communicate with the service instance. Because IBM Cloud hosts several apps on the same virtual machine, multiple apps cannot use the same HTTP port number to receive incoming requests. To avoid conflicts, each app is given a unique port number. This port number is available in the <VCAP_APP_PORT> variable.\n\nFollow these steps to see the list of <VCAP_SERVICES> values associated with your app in the console.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-getting-started"},{"document_id":"ibmcld_00616-7-1788","score":21.6704044342,"text":"\nUsing the IBM Cloudant Dashboard \n\nBy using the IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Dashboard, you create an IBM Cloudant database, populate the database with data, and retrieve data by using queries or API endpoints. For more information about API endpoints, see the [API and SDK reference](https:\/\/cloud.ibm.com\/apidocs\/cloudantintroduction).\n\n\n\n Objectives \n\n\n\n1. Open the IBM Cloudant Dashboard.\n2. Create a database.\n3. Add JSON documents to the database and run a query.\n4. Replicate a database.\n5. Monitor active tasks.\n6. Monitor with IBM Cloudant.\n\n\n\n\n\n\n\n Before you begin \n\nCreate a service instance in IBM Cloud before you start this tutorial. You can follow the instructions in the [Getting started](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) tutorial to create one.\n\n\n\n\n\n Step 1: Opening your service instance on IBM Cloudant Dashboard \n\nOpen your IBM Cloudant service instance by following these steps:\n\n\n\n1. Go to the IBM Cloud Dashboard.\n2. Click Services in the Resource list.\n3. From the Services section, click the Cloudant-o7 instance that you created in the Getting started tutorial, and click Launch Dashboard. The IBM Cloudant Dashboard opens.\n\n\n\nNow, you can create a database and run queries against it.\n\n\n\n\n\n Step 2: Creating a database \n\nIn this exercise, you create the dashboard-demo[database](https:\/\/cloud.ibm.com\/apidocs\/cloudantputdatabase), which is the database that you use in this tutorial.\n\n\n\n1. From the IBM Cloudant Dashboard, click Create database.\n\nThe Create database window opens.\n2. Enter the database name dashboard-demo.\n3. Select Non-partitioned, and click Create.\n\nThe dashboard-demo database opens automatically.\n\n\n\nNow, you can create some documents.\n\n\n\n\n\n Step 3: Adding documents to the database","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-navigate-the-dashboard"},{"document_id":"ibmcld_04655-3982-5887","score":21.659614563,"text":"\nSearch for IBM Cloudant, and select the service.\n3. For Available authentication methods, select Use both legacy credentials and IAM. You can leave the default settings for the other fields. Click Create to create the service.\n4. In the navigation, go to Connections, then click Create connection. Select your app, and click Connect.\n5. Using the default values, click Connect & restage app to connect the database to your app. Click Restage when prompted.\n\nIBM Cloud will restart your app and provide the database credentials to your app using the VCAP_SERVICES environment variable. This environment variable is available to the app only when it is running on IBM Cloud.\n\n\n\nEnvironment variables enable you to separate deployment settings from your source code. For example, instead of specifying a database password in your source code, you can store it in an environment variable that you reference in your source code.\n\n\n\n\n\n Step 6: Use the database \n\nWe're now going to update your local code to point to this database. We'll create a .env file that will store the credentials for the services the app will use. This file will get used ONLY when the app is running locally. When running in IBM Cloud, the credentials will be read from the VCAP_SERVICES environment variable.\n\n\n\n1. Create a file called .env in the get-started-ruby directory with the following content:\n\nCLOUDANT_URL=\n2. Find your app in the IBM Cloud [resource list](https:\/\/cloud.ibm.com\/resources). On the Service Details page for your app, click Connections in the sidebar. Click the IBM Cloudant menu icon (\u2026) and select View credentials.\n3. Copy and paste just the url from the credentials to the CLOUDANT_URL field of the .env file and save the changes. The result will be something like:\n\nCLOUDANT_URL=https:\/\/123456789 ... bluemix.cloudant.com\n4. Run your app locally.\n\nrails server\n\nView your app at: http:\/\/localhost:3000.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-getting-started-ruby"},{"document_id":"ibmcld_04108-0-1506","score":21.4832000732,"text":"\n\n\n\n\n\n\n  Accessing your Cloudant database through CIS \n\nFollow these steps to access your Cloudant database through IBM Cloud\u00ae Internet Services (CIS).\n\n\n\n  Before you begin \n\nThese instructions assume you have already added a domain to CIS as outlined in the [Getting started](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-startedgetting-started) page.\n\n\n\n\n\n  Step 1: Add your CIS domain to the Cross-Origin Resource Sharing (CORS) \n\n\n\n*  Navigate to your Cloudant database and open the Account > CORS page.\n*  Add your CIS domain to the origin domains input field. For example, https:\/\/cloudant.test.foo.com.\n\n\n\n\n\n\n\n  Step 2. Configure CIS to point to your Cloudant database \n\n\n\n*  Navigate to the CIS dashboard and create a load balancer or DNS record that points to your Cloudant database hostname. For example, https:\/\/cloudant.test.foo.com -> 111-222-333-444-555-test.cloudant.com.\n*  Enable proxy for the DNS record or load balancer.\n\n\n\n\n\n\n\n  Step 3. Create a page rule to set the Host Header Override \n\n\n\n*  In the CIS dashboard, navigate to Performance > Page rules.\n*  Create a page rule for the URL you want, for example, https:\/\/cloudant.test.foo.com\/.\n*  Select the Rule Behavior setting Host Header Override.\n*  Set as the Cloudant database hostname, for example, 111-222-333-444-555-test.cloudant.com.\n\n\n\nTo learn more about Cloudant, see the [Cloudant documentation](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudantgetting-started-with-cloudant).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-access-cloudant-through-cis"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12904-1535-3460","score":23.723482132,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00558-1499-3456","score":23.6470222473,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-7-1919","score":23.5096187592,"text":"\nPlans and provisioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Standard is IBM Cloudant's most feature-rich offering, receiving updates and new features first. Pricing is based on provisioned throughput capacity that is allocated and data storage that is used, making it suitable for any required load.\n\nThe free [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) includes a fixed amount of throughput capacity and data for development and evaluation purposes. The paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan) offers configurable provisioned throughput capacity and data storage pricing that scales as your application requirements change. An optional [Dedicated Hardware plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicdedicated-hardware-plan) is also available for an extra monthly fee to run one or more of your Standard plan instances on a dedicated hardware environment. The dedicated hardware environment is for your sole use. If a Dedicated Hardware plan instance is provisioned within a US location, you can optionally select a [HIPAA](https:\/\/en.wikipedia.org\/wiki\/Health_Insurance_Portability_and_Accountability_Act) -compliant configuration.\n\n\n\n Plans \n\nYou can select which plan to use when you [provision your IBM Cloudant service instance](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioning-a-cloudant-nosql-db-instance-on-ibm-cloud). The available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-20515-22569","score":22.8848419189,"text":"\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00558-20425-22479","score":22.8848419189,"text":"\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00558-7-1874","score":22.8792095184,"text":"\nPlans and provisioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Standard is IBM Cloudant's most feature-rich offering, receiving updates and new features first. Pricing is based on provisioned throughput capacity that is allocated and data storage that is used, making it suitable for any required load.\n\nThe free [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) includes a fixed amount of throughput capacity and data for development and evaluation purposes. The paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan) offers configurable provisioned throughput capacity and data storage pricing that scales as your application requirements change. An optional [Dedicated Hardware plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicdedicated-hardware-plan) is also available for an extra monthly fee to run one or more of your Standard plan instances on a dedicated hardware environment. The dedicated hardware environment is for your sole use. If a Dedicated Hardware plan instance is provisioned within a US location, you can optionally select a [HIPAA](https:\/\/en.wikipedia.org\/wiki\/Health_Insurance_Portability_and_Accountability_Act) -compliant configuration.\n\n\n\n Plans \n\nYou can select which plan to use when you [provision your IBM Cloudant service instance](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioning-a-cloudant-nosql-db-instance-on-ibm-cloud). The available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00609-0-1350","score":21.8677692413,"text":"\n\n\n\n\n\n\n  Migrating from a Lite plan to a Standard plan \n\nMigrating from the free Lite plan to the Standard plan by completing the following tasks.\n\n\n\n  Step 1: Authenticate with IBM Cloud Dashboard \n\n\n\n1.  Go to the [IBM Cloud\u00ae Dashboard](https:\/\/cloud.ibm.com\/).\n2.  Authenticate with your username and password. The IBM Cloud Dashboard opens to the Resource list.\n\n\n\n\n\n\n\n  Step 2: Select your IBM Cloudant instance \n\n\n\n1.  Under Services, open the IBM Cloudant instance that you want to migrate.\n2.  Select Plan.\n3.  From the list of pricing plans, select Standard.\n\nZoom\n\n![Standard plan is a serverless scaling of throughput and storage. Includes 20 GB of free data storage, more storage metered. Users can adjust provisioned throughput capacity in blocks of 100 reads\/sec, 50 writes\/sec, 5 global queries\/sec. Max JSON document size of 1 MB. $1.00 USD\/GB of data storage. $0.25 USD\/Read capacity. $0.50 USD\/Write capacity. $5.00 USD\/Global Query capacity.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/migrate3.png)\n\nFigure 1. Standard plan\n\n\n\n\n\n\n\n  Step 3: Upgrade to the Standard plan \n\n\n\n1.  Click Upgrade. All your existing data is kept.\n2.  Adjust your capacity by using the Throughput Capacity slider to increase or decrease capacity as needed.\n\n\n\nNow, you're ready to go.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan"},{"document_id":"ibmcld_00612-7-2163","score":21.7394866943,"text":"\nMigration overview \n\nThe [IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae](https:\/\/www.ibm.com\/cloud\/cloudant) database-as-a-service offering is a JSON document store that runs on multi-tenant clusters. The service is available with a choice of geographical locations with predictable costs, scalability, and a service-level agreement (SLA).\n\nYou can migrate to an IBM Cloudant Lite or Standard plan instance on IBM Cloud from one of the following plans:\n\n\n\nTable 1. IBM Cloudant migration paths\n\n Plan Description \n\n IBM Cloudant Enterprise Dedicated, single-tenant clusters \n Apache CouchDB The self-hosted, open source database on which IBM Cloudant is based. \n\n\n\n\n\n Benefits of the IBM Cloudant Lite and Standard plans \n\nWith the Standard plan, you can reserve throughput capacity for your database service, that is, to specify how much throughput your application's database is going to need to handle demand. The Standard plan also charges for the amount of storage you use. Capacity is measured with the following metrics:\n\n\n\nTable 2. Capacity metrics\n\n Metric Description \n\n Reads per second The rate when simple document fetches are performed, for example, retrieving a document by its _id, or querying against a partitioned database that uses a partition key. \n Writes per second The rate when data is written to the database. API calls dealing with document creation, update, or deletion count as \"writes\". \n Global Queries per second The rate when the database is queried by global indices, typically by accessing the _find endpoint, secondary MapReduce, or search indices. \n Storage The amount of disk space occupied by your JSON data, attachments, and secondary indices. \n\n\n\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"},{"document_id":"ibmcld_00540-7-1622","score":20.5695667267,"text":"\nFinding your IBM Cloudant plan \n\nYou can subscribe to different IBM Cloudant plans, including the Lite, Standard, or Enterprise plans.\n\n\n\n Step 1: Finding your plan \n\nThe following steps show where you can see the type of plan that you selected.\n\n\n\n1. Go to the [IBM Cloud Dashboard](https:\/\/cloud.ibm.com\/).\n2. Authenticate with your username and password.\nThe IBM Cloud Dashboard opens to the Resource list.\n3. Click an instance to find more information.\n4. Click Plan. A checkmark indicates the plan that you use as shown in the following screen capture. For more information, see the [Migration FAQ](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-migration).\n\nZoom\n\n![Standard dashboard includes a serverless scaling of throughput and storage. Includes 20 GB of free data storage, extra storage metered. Users can adjust provisioned throughput capacity in blocks of 100 reads\/sec, 50 writes\/sec, 5 global queries\/sec. Max JSON document size of 1 MB. $1.00 USD\/GB of data storage. $0.25 USD\/Read capacity. $0.50 USD\/Write capacity. $5.00 USD\/Global Query capacity.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/ibmcloud_instance_standard_plan.png)\n\nFigure 1. Standard dashboard\n\nIf the Plan tab indicates that you're on the Standard plan, you don't need to read any further. You're already on a paid SLA-backed IBM Cloudant service. No further action is required.\n\n\n\n\n\n\n\n Step 2: Finding your legacy Enterprise plan \n\nYou can find your Enterprise plan in the IBM Cloudant Dashboard by following these steps.\n\n\n\n1. Open the IBM Cloudant Dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan"},{"document_id":"ibmcld_00580-4796-6846","score":20.5628356934,"text":"\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.\n\n\n\n* The first example shows a person object, storing strings, booleans, and an array of tags.\n* The second example shows brief attribute names to save on storage and represents a web event such as click a website.\n* The last example shows how the document may itself contain subjects.\n\n\n\nA note on dates. JSON has no native Date type, so dates are usually stored in 30-October-2018 or similar formats. We return to dates later.\n\nNow, for your first practical exercise, visit www.ibm.com\/cloud. Register an account with the IBM Cloud, if you don't have one already.\n\nOnce registered, you can click services, search for the Cloudant database, and provision a new service.\n\nThe IBM Cloudant Lite service provides a free plan to allow users to try IBM Cloudant in a limited capacity while in development. Its bigger brother, the Standard Plan, is a paid-for service where you specify the number of reads, writes, and queries per second for your application and that capacity is reserved for you. You pay for the capacity you provision and your data storage usage.\n\nThe Lite plan operates in a similar way. It has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.530721274,"ndcg_cut_10":0.530721274}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07103-31052-33321","score":15.8152980804,"text":"\nYou cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments\n: Relevance and confidence scores are displayed for NLU enrichments that are returned by search. For example, when you open the JSON view of the document preview from a query result, you can see confidence scores for Entities mentions and relevance scores for Keyword mentions.\n\n\n\n\n\n 9 September 2021 \n\nNew location for Plus plan\n: The Plus plan is now available from the Sydney location. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product. For more information, see [Getting the most from Discovery](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nChange to Lite and Advanced plans in most locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 26 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_07103-13283-15511","score":15.42831707,"text":"\nYou cannot create new service instances that use the Lite plan type in any location, including London. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 22 September 2022 \n\nPlus plan supports more entity extractors\n: The maximum number of entity extractors that you can create with a Plus plan increased from 3 to 6.\n\nYou cannot apply a Smart Document Understanding model to Microsoft Excel files\n: The quality of structural analysis that can be produced for Excel files is not sufficient. Starting on 22 September 2022, you cannot apply an SDU model to Excel files. This change does not impact Excel files in collections where an SDU model was applied before 22 September 2022.\n\n\n\n\n\n 16 September 2022 \n\nIn-context document preview is now available for PDF files that are crawled\n: When you click to view a passage from a search result that is extracted from a PDF document, a document preview page is displayed that shows the returned passage in the context of the original PDF page. The in-context view is available for PDF files to which a Smart Document Understanding model is applied.\n\n\n\n\n\n 15 August 2022 \n\nSDKs were updated to reflect the latest API changes.\n: The following [Discovery v2 API](https:\/\/cloud.ibm.com\/apidocs\/discovery-data) changes are now reflected in the SDKs:\n\n\n\n* Use the new document classifier API to get, add, update, or delete a document classifier.\n* A new document status API is available. You can use it to get a list of the documents in a collection and to get details about a single document.\n* You can now get, add, and remove a stop words or expansion list for a collection.\n* A smart_document_understanding field is returned with the Get collection method. This new field specifies whether an SDU model is enabled for the collection and indicates the model type.\n* A similar parameter is available from the Query method. Use it to find documents that are similar to documents of interest to you.\n* The suggested_refinements parameter of the Query method is deprecated. The suggested_refinements parameter was used to identify dynamic facets from Premium plan data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_07578-1076793-1078629","score":13.9187021255,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":13.9187021255,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07103-32746-34817","score":13.4981517792,"text":"\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments. Use answer finding when you want to return a concise answer to a question. For more information, see [Answer finding](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parametersanswer-finding).\n\n\n\n\n\n 16 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the Frankfurt and Tokyo locations, in addition to Dallas.\n\nChange to Lite and Advanced plans in some locations\n: Lite and Advanced plans are no longer offered. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, or Tokyo locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 27 July 2021 \n\nImproved document size limit\n: Document size limit is increased. For Premium plan collections, you can now upload files that are up to 50 MB in size instead of 32 MB. For more information, see [Document limits](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collectionscollections-doc-limits).\n\n\n\n\n\n 23 July 2021 \n\nImproved SharePoint Online connector\n: The Microsoft SharePoint Online data source connector now accepts any valid Azure Active Directory user ID syntax; the format of the user ID doesn't need to match the <admin_user>@.onmicrosoft.com syntax. For more information, see [Microsoft SharePoint Online](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-sharepoint-online-cloud).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_16727-45749-47752","score":13.1896629333,"text":"\nYou must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n* What is the price for using the Speech to Text Plus plan?\n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:\n\n\n\n* Users who recognize 1 to 999,999 minutes of audio in a given month pay $0.02 (USD) per minute of audio for that month.\n* Users who recognize at least 1,000,000 minutes of audio in a given month pay $0.01 (USD) per minute of audio for that month.\n\n\n\nThe Plus plan is intended for small businesses. It is also a good choice for large enterprises that want to develop and test larger applications before considering moving to a Premium plan. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text).\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-45764-47767","score":13.1896629333,"text":"\nYou must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n* What is the price for using the Speech to Text Plus plan?\n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:\n\n\n\n* Users who recognize 1 to 999,999 minutes of audio in a given month pay $0.02 (USD) per minute of audio for that month.\n* Users who recognize at least 1,000,000 minutes of audio in a given month pay $0.01 (USD) per minute of audio for that month.\n\n\n\nThe Plus plan is intended for small businesses. It is also a good choice for large enterprises that want to develop and test larger applications before considering moving to a Premium plan. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text).\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_07103-29564-31587","score":12.9426088333,"text":"\nPreviously, the list included fields that were not valid choices.\n\n\n\n\n\n 14 October 2021 \n\nNew Discovery home page\n: A new home page is displayed when you start Discovery and gives you quick access to a product overview video, and tours. You can collapse the home page welcome banner to see more projects.\n\nNew plan usage section\n: Stay informed about plan usage and check your usage against the limits for your plan type from the Plan limits and usage page. From the product page header, click the user icon ![User icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/user--avatar.svg). The Usage section shows a short summary. Click View all to see usage information for all of the plan limit categories.\n\nChange to spelling settings in Search\n: The spelling correction setting changed from being enabled automatically in new projects to being disabled by default. If you want to alert users when they misspell a term in their query, turn on Spelling suggestions. For more information, see [Customizing the search bar](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-bar).\n\nImproved Guided tours availability\n: The Guided tours button is now available from the product page header, which make them accessible from anywhere. Previously, it was available from the My Projects page only.\n\n\n\n\n\n 1 October 2021 \n\nChange to Lite and Advanced plans in all locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_00558-1499-3456","score":12.9353628159,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_01029-0-4062","score":12.9150400162,"text":"\n\n\n\n\n\n\n  Free Lite plan \n\nThe IBM\u00ae Db2\u00ae on Cloud Lite plan provides basic resources for you to develop or learn about Db2 without charge.\n\nThere is no time limit on the Lite plan, but users must re-extend their Lite plan every 30 days.\n\nOnly community support is available.\n\n\n\n  Architecture \n\nUnlike other Db2 on Cloud plans, the free Db2 on Cloud Lite plan runs on a multi-tenant system.\n\nThe Lite plan uses one database schema.\n\nFor more information about the free Db2 on Cloud Lite plan, see the [FAQ](https:\/\/ibm.biz\/db2oc_free_plan_faq).\n\n\n\n\n\n  Regional availability \n\nThe Lite plan is available in the Dallas and London regions. If you do not see the Lite plan listed in the catalog, select either Dallas or London region.\n\n\n\n\n\n  Restrictions \n\nIt is recommended that you use an enterprise-level service plan rather than a Lite service plan for mission-critical or performance-sensitive workloads.\n\nThe following table contains Db2 on Cloud Lite plan restrictions:\n\n\n\nTable 1. Db2 on Cloud Lite plan restrictions\n\n Category                Item                                                                   Restriction                                                                                              \n\n Resources               Storage                                                                200 MB of storage per user                                                                               \n                         Connections                                                            15 connections per user                                                                                  \n                         Performance                                                            Performance might fluctuate due to workloads run by other users on the multi-tenant system               \n Features & functions    Federation                                                             Not supported                                                                                            \n                         Oracle compatibility                                                   Not supported                                                                                            \n                         User-defined extensions (UDFs)                                         Not supported on any Db2 on Cloud plans, including the Lite plan                                         \n                         User management                                                        User not given administrative authority                                                                  \n                         Row and column access control (RCAC)                                   Not supported                                                                                            \n                         IBM InfoSphere Data Replication for use in loading data                Not supported                                                                                            \n Networking environment  IBM Cloud Integrated Analytics                                         Not supported                                                                                            \n                         IBM Cloud Dedicated                                                    Not supported                                                                                            \n Security compliances    Health Information Portability and Accountability Act of 1996 (HIPAA)  Not supported. Refer to your Service Description.                                                        \n                         EU General Data Protection Regulation (GDPR)                           Not supported. Refer to your Service Description.                                                        \n Account management      Reactivation                                                           Reactivation required every 30 days. If not reactivated, Lite plan services are deleted 60 days later.   \n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-free_plan"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1412669729}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00099-7-1786","score":17.0574550629,"text":"\nUsing the Python SDK \n\nThe IBM Analytics Engine SDK can be installed by installing the library iaesdk from the Python Package Index.\n\nType the following command into a command line:\n\npip install --upgrade \"iaesdk>=1.1.1\"\n\nSource code can be found at [GitHub](https:\/\/github.com\/IBM\/ibm-iae-python-sdk). The iaesdk library provides complete access to the IBM Analytics Engine API.\n\nYou need to provide the service endpoints and the API key when you create a IBM Analytics Engine service resource or a low-level client.\n\nThe service instance ID is also referred to as a instance GUID. You can retrieve the service instance ID when you create service credentials or through the CLI. See [Retrieving service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverless).\n\nTo use the iaesdk library, you need the following values:\n\n\n\n* IAM_API_KEY: The API key generated when creating the service credentials. You can retrieve by viewing the service credentials on the [IBM Cloud dashboard](https:\/\/cloud.ibm.com\/resources).\n* instance_guid: The value in resource_instance_id generated when the service credentials are created. You can retrieve by viewing the service credentials on the [IBM Cloud dashboard](https:\/\/cloud.ibm.com\/resources).\n* IAE_ENDPOINT_URL: The service endpoint URL including the https:\/\/ protocol. See [Service endpoints](https:\/\/cloud.ibm.com\/apidocs\/ibm-analytics-engineservice-endpoints).\n\n\n\n\n\n Code samples using iaesdk \n\nGetting started with the Python SDK after you have installed it, involves sourcing credentials to the IBM Analytics Engine service, invoking the service and then issuing different cluster commands as shown in the following sample code snippets. The code examples are written for Python 3.7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-python-sdk-serverless"},{"document_id":"ibmcld_12343-7-1769","score":16.0839653015,"text":"\nPython \n\nGiven its ease of use and adoption for data science applications, [Python](https:\/\/www.python.org\/) support is imperative to increase adoption of your IBM Cloud service. Supporting Python applications using [Flask](https:\/\/github.com\/pallets\/flask), [Django](https:\/\/www.djangoproject.com\/), [Jupyter](https:\/\/jupyter.org\/), and functional programming paradigms introduces special considerations that need to be observed by your SDK.\n\n\n\n Environment support \n\n\n\n* Your Python SDK should be written to support all [Python >=3.5](https:\/\/www.python.org\/downloads\/) releases.\n* Ensure your SDK is compatible with data science usecases, such as [Jupyter Notebooks](https:\/\/jupyter.org\/).\n\n\n\n\n\n\n\n Publishing \n\nAll Python SDKs should be publicly available on an [IBM GitHub organization](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributionopen-source). The releases of these SDKs should be published on [PyPI](https:\/\/pypi.org\/).\n\nYour SDK should follow the [semantic versioning best practices](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributionsemantic-versioning).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [PEP8 style guide for Python](https:\/\/www.python.org\/dev\/peps\/pep-0008\/), with a few modifications, like four spaces instead of tabs for indentation.\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-developer-tools) for Python to check style and code coverage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-python"},{"document_id":"ibmcld_09702-5331-6744","score":15.9896020889,"text":"\nalert_found = False\n\nfor alert in res['alerts']:\nif alert['name'] == alert_name:\nalert_found = True\nif 'notificationChannelIds' in alert:\nalert['notificationChannelIds'] = alert['notificationChannelIds']\nupdate_txt = '(changed by update_alert)'\nif alert['description'] != update_txt:\nalert['description'] = alert['description'] + update_txt\nalert['timespan'] = alert['timespan'] * 2 Note: Expressed in seconds * 1000000\nres_update = sdclient.update_alert(alert)\n\nif not res_update:\nprint(\"Alert update failed\")\n\nif not alert_found:\nprint('Alert to be updated not found')\nShow more\n\n\n\n\n\n Deleting an alert (DELETE) \n\nTo delete an existing alert, you need the ID of that alert.\n\nThe following code shows the structure of a Python script that you can use to delete an alert:\n\n Reference the Python client\nfrom sdcclient import IbmAuthHelper, SdMonitorClient\n\n Add the monitoring instance information that is required for authentication\nURL = <MONITORING-ENDPOINT>\nAPIKEY = <IAM_APIKEY>\nGUID = <GUID>\nibm_headers = IbmAuthHelper.get_headers(URL, APIKEY, GUID)\n\n Instantiate the Python client\nsdclient = SdMonitorClient(sdc_url=URL, custom_headers=ibm_headers)\n\nres = sdclient.get_alerts()\nif not res[0]:\nprint(\"Failed to fetch existing alerts\")\n\nfor alert in res['alerts']:\nif alert['name'] == alert_name:\nprint(\"Deleting alert\")\nres = sdclient.delete_alert(alert)\nif not res:\nprint(\"Alert deletion failed\")\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_python"},{"document_id":"ibmcld_13497-3036-4974","score":15.5738220215,"text":"\nDecember 2020 \n\nSupported regions\n: Data Engine is available in Chennai, India. When you provision new instances, you can select whether it is being provisioned in Dallas, Frankfurt, or Chennai.\n\nIBM Cloud Object Storage\n: IBM Cloud Object Storage web console discovers SQL-queryable objects and folders and directly starts the Data Engine web console with a prefilled SQL statement for seamless interactive data exploration.\n\n\n\n\n\n November 2020 \n\nModify location of Hive partitions\n: The location of Hive partitions can be modified by using the [ALTER TABLE SET LOCATION](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencechapterAlterTableSetLocation) feature.\n\n\n\n\n\n October 2020 \n\nIndex management\n: Data Engine index management, also referred to as data skipping is generally available with full production support.\n\nNew samples category Reference data statement\n: IBM Cloud\u00ae Data Engine comes with open data out of the box, including geolocation, and demographic data that can be used as reference data to combine with your own data sets. It is based on open data from US Census, Eurostat Census, UNdata, OpenStreetMap, and Natural Earth. Explore it by using the new category Reference data statements in SAMPLES.\n\nTime series functions\n: Data Engine time series functions: The anchor functions are deprecated and replaced by the new and more powerful expression creation functions.\n\nPython SDK\n: The [ibmcloudsql](https:\/\/pypi.org\/project\/ibmcloudsql) Python SDK significantly expanded in functionality for even more powerful Python analytics with SQL. Take a tour of the functions in the [Data Engine Starter Notebook](https:\/\/dataplatform.cloud.ibm.com\/exchange\/public\/entry\/view\/e82c765fd1165439caccfc4ce8579a25?context=cpdaas). The Python SDK also comes with a dedicated [online documentation](https:\/\/ibm-cloud.github.io\/sql-query-clients\/intro.htmlibmcloudsql).\n\nUsage of legacy SoftLayer endpoints discontinued","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-query-relnotes"},{"document_id":"ibmcld_09735-13304-14716","score":15.4111623764,"text":"\nsdclient = SdMonitorClient(token=SYSDIG_TOKEN,sdc_url=URL)\n\n Show the list of dashboards\nok, res = sdclient.get_dashboards()\n\n Loop through all fetched dashboards\nfor dashboard in res[1]:\n Delete dashboard if it matches the pattern (one or many)\nif DASHBOARD_NAME in dashboard['name']:\nprint(\"Deleting \" + dashboard['name'])\nres = sdclient.delete_dashboard(dashboard)\nShow more\n\n\n\n\n\n Download custom dashboards \n\nYou can use Python to download custom dashboards.\n\nWhen you download dashboards, you only download custom dashboards.\n\n\n\n\n\n Download custom dashboards in the default team \n\nThe following code shows the structure of a Python script to download a custom dashboard from the default team.\n\n!\/usr\/bin\/env python3\n\nimport os\nimport sys\nsys.path.insert(0, os.path.join(os.path.dirname(os.path.realpath(sys.argv[0])), '..'))\nfrom sdcclient import IbmAuthHelper, SdMonitorClient\n\n Parse arguments.\ndef usage():\nprint('usage: %s <endpoint-url> <apikey> <instance-guid>' % sys.argv[0])\nprint('endpoint-url: The endpoint URL that should point to IBM Cloud')\nprint('apikey: IBM Cloud IAM apikey that will be used to retrieve an access token')\nprint('instance-guid: GUID of an IBM Cloud Monitoring with monitoring instance')\nsys.exit(1)\n\nif len(sys.argv) != 4:\nusage()\n\ndef zipdir(path, ziph):\n ziph is zipfile handle\nfor root, dirs, files in os.walk(path):\nfor file in files:\nziph.write(os.path.join(root, file))","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-dashboard_python"},{"document_id":"ibmcld_13481-7434-8879","score":15.3648643494,"text":"\nThe SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine-spark-integration-1.4.51.jar)\n* [spark-dataengine-python](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine_spark-1.4.51-py3-none-any.whl)\n\n\n\nAn example of how to use the Python helper can be found in the [Watson Studio Notebooks section](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastoreusage_watson_notebooks).\n\nUse the following example to get started with IBM\u00ae Analytics Engine (IAE) or Spark runtimes in Watson Studio when using Scala. Submit the following application using a notebook or the spark-submit command:\n\npackage com.ibm.cloud.dataengine\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.SparkSession.{Builder => SessionBuilder}\nimport SparkSessionBuilderAddOn._\nobject SparkSessionBuilderHMSConfigTest {\ndef main(args: Array[String]) = {\nval spark = SparkSession\n.builder()\n.appName(\"Spark DataEngine integration\")\n.enableDataengine(args(0), args(1), \"public\")\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\")\n.config(\"fs.stocator.scheme.list\", \"cos\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_09771-7-1671","score":14.9882593155,"text":"\nExtracting metrics from an instance by using the Monitoring Python client \n\nYou can extract metrics from an IBM Cloud Monitoring instance through REST API operations that you can run by using a Python client or by using a cURL command.\n\n\n\n Get metrics by using a Python client \n\nTo learn how to use the Python client, see [Using the Python client](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-python-client).\n\nThe following code shows the structure of a Python script that you can use to retrieve metrics from a Monitoring instance:\n\n Reference the Python client\nfrom sdcclient import IbmAuthHelper, SdMonitorClient\n\n Add the monitoring instance information that is required for authentication\nURL = <MONITORING-ENDPOINT>\nAPIKEY = <IAM_APIKEY>\nGUID = <GUID>\nibm_headers = IbmAuthHelper.get_headers(URL, APIKEY, GUID)\n\n Instantiate the Python client\nsdclient = SdMonitorClient(sdc_url=URL, custom_headers=ibm_headers)\n\n Specify the ID for keys, and ID with aggregation for values\nmetrics = [\n{\"id\": \"cpu.used.percent\", \"aggregations\": {\"time\": \"timeAvg\", \"group\": \"avg\"}}\n]\n\n Add a data filter or set to None if you want to see \"everything\"\nfilter = None\n\n Time window:\n - for \"from A to B\": start is equal to A, end is equal to B (expressed in seconds)\n - for \"last X seconds\": start is equal to -X, end is equal to 0\nstart = -600\nend = 0\n\n Sampling time:\n - for time series: sampling is equal to the \"width\" of each data point (expressed in seconds)\n - for aggregated data (similar to bar charts, pie charts, tables, etc.): sampling is equal to 0\nsampling = 60\n\n Load data\nok, res = sdclient.get_data(metrics, start, end, sampling, filter=filter)\nif ok:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-metrics_python"},{"document_id":"ibmcld_02602-1716-3243","score":14.892118454,"text":"\n2. To view summary usage help for all the toolkit commands, enter the following command:\n\napic\n3. To view usage help for any command, use the --help option. For example:\n\napic validate --help\n\n\n\n\n\n\n\n\n\n Installing LoopBack connectors \n\nBefore you can use a LoopBack data source to access data in a backend system such as a database, you must install the data source connector. The In-memory and email connectors are built in to LoopBack, so you don't need to install them.\n\n\n\n Prerequisites \n\nThe Oracle, DB2, and SQLLite connectors require C compiler tools to build and install binary extensions. The exact requirements depend on your operating system as described in the following list.\n\nLinux\n\n\n\n* Python v2.7 (v3.x is not supported)\n* make\n* A C\/C++ compiler toolchain, for example GCC version 4.2 or later.\n* On Debian and Debian-derived distributions (Ubuntu, Mint etc), use the command: apt-get install build-essential\n\n\n\nMac OS X\n\n\n\n* [Python Releases for Mac OS X](https:\/\/www.python.org\/downloads\/mac-osx\/)\n* [Xcode](https:\/\/developer.apple.com\/xcode\/?cm_mc_uid=46449280653414622613810&cm_mc_sid_50200000=1459433716)\n\n\n\nWindows\n\n\n\n* [Microsoft .NET Framework 4](https:\/\/www.microsoft.com\/en-us\/download\/details.aspx?id=17851)\n* [Visual Studio](https:\/\/visualstudio.microsoft.com\/downloads\/)\n* [Python v2.7.10](https:\/\/www.python.org\/downloads\/release\/python-2710\/)\n* [Microsoft Windows SDK for Windows 10](https:\/\/developer.microsoft.com\/en-us\/windows\/downloads\/windows-10-sdk)\n* npm version 3: See the following note.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-creating_apis"},{"document_id":"ibmcld_05088-19478-20735","score":14.8665599823,"text":"\ncos_cli = ibm_boto3.client(\"s3\",\nibm_api_key_id=COS_API_KEY_ID,\nibm_service_instance_id=COS_SERVICE_CRN,\nconfig=Config(signature_version=\"oauth\"),\nendpoint_url=COS_ENDPOINT)\n\nmore_results = True\nnext_token = \"\"\n\nwhile (more_results):\nresponse = cos_cli.list_objects_v2(Bucket=bucket_name, MaxKeys=max_keys, ContinuationToken=next_token)\nfiles = response[\"Contents\"]\nfor file in files:\nprint(\"Item: {0} ({1} bytes).\".format(file[\"Key\"], file[\"Size\"]))\n\nif (response[\"IsTruncated\"]):\nnext_token = response[\"NextContinuationToken\"]\nprint(\"...More results in next batch!n\")\nelse:\nmore_results = False\nnext_token = \"\"\n\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to retrieve bucket contents: {0}\".format(e))\nShow more\n\nSDK References\n\n\n\n* Classes\n\n\n\n* [S3.Client](https:\/\/ibm.github.io\/ibm-cos-sdk-python\/reference\/services\/s3.htmlclient)\n\n\n\n* Methods\n\n\n\n* [list_objects_v2](https:\/\/ibm.github.io\/ibm-cos-sdk-python\/reference\/services\/s3.htmlS3.Client.list_objects_v2)\n\n\n\n\n\n\n\n\n\n\n\n Using Key Protect \n\nKey Protect can be added to a storage bucket to encrypt sensitive data at rest in the cloud.\n\n\n\n Before You Begin \n\nThe following items are necessary in order to create a bucket with Key-Protect enabled:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_09702-6488-7328","score":14.7490797043,"text":"\nres = sdclient.get_alerts()\nif not res[0]:\nprint(\"Failed to fetch existing alerts\")\n\nfor alert in res['alerts']:\nif alert['name'] == alert_name:\nprint(\"Deleting alert\")\nres = sdclient.delete_alert(alert)\nif not res:\nprint(\"Alert deletion failed\")\nShow more\n\n\n\n\n\n Get all user alerts (GET) \n\nThe following code shows the structure of a Python script that you can use to get information about all the alerts:\n\n Reference the Python client\nfrom sdcclient import IbmAuthHelper, SdMonitorClient\n\n Add the monitoring instance information that is required for authentication\nURL = <MONITORING-ENDPOINT>\nAPIKEY = <IAM_APIKEY>\nGUID = <GUID>\nibm_headers = IbmAuthHelper.get_headers(URL, APIKEY, GUID)\n\n Instantiate the Python client\nsdclient = SdMonitorClient(sdc_url=URL, custom_headers=ibm_headers)\n\njson_res = sdclient.get_alerts()\nprint(json_res)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_python"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16295-7-1721","score":19.5122699738,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_02855-7-2041","score":19.4086227417,"text":"\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03196-30333-32476","score":18.9443740845,"text":"\nIn the Message before link to web chat field, edit the introductory message to display to the user (in the originating channel) before the link that initiates the transfer. By default, this message is OK, click this link for additional help. Chat will continue on a new web page.\n3. In the URL to web chat field, type the URL for your website where the web chat widget is embedded.\n\n\n\nIn the integration that processes the Channel transfer response, the introductory message is displayed, followed by a link to the URL you specify. The user must then click the link to initiate the transfer.\n\nWhen a conversation is transferred from one channel to another, the session history and context are preserved, so the destination channel can continue the conversation from where it left off. Note that the message output that contains the Channel transfer response is processed first by the channel that initiates the transfer, and then by the target channel. If the output contains multiple responses (perhaps using different response types), these will be processed by both channels (before and after the transfer). If you want to target individual responses to specific channels, you can do so by editing the response using the JSON editor. For more information, see [Targeting specific integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-target-integrations).\n\n\n\n\n\n Adding an Image response type \n\nSometimes a picture is worth a thousand words. Include images in your response to do things like illustrate a concept, show off merchandise for sale, or maybe to show a map of your store location.\n\nTo add an Image response type, complete the following steps:\n\n\n\n1. Choose Image.\n2. Add the full URL to the hosted image file into the Image source field.\n\nThe image must be in .jpg, .gif, or .png format. The image file must be stored in a location that is publicly addressable by an https: URL.\n\nFor example: https:\/\/www.example.com\/assets\/common\/logo.png.\n\nIf you want to display an image title and description above the embedded image in the response, then add them in the fields provided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_16365-8408-10508","score":18.8410587311,"text":"\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16384-7-2422","score":18.8131999969,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16326-3092-4450","score":18.324596405,"text":"\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed. Any login, splash, cookie, or warning screens might be captured in the image.\n\nTo enter a URL:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Enter URL, then click Continue.\n3. Enter the path of your website URL, for example, https:\/\/www.example.com or example.com.\n4. Click Continue.\n\n\n\n\n\n\n\n Uploading an image \n\nYou can upload an image of your organization's website. Images are stored for 24 hours. Maximum file size is 1 MB. Supported file types are JPEG and PNG.\n\nTo upload an image:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Upload an image, then click Continue.\n3. Drag a file or click to upload, then click Change background.\n\n\n\nImages are stored for 24 hours. A warning message might appear on the Preview page about the time limit expiration. To clear this message:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Clear background setting, then click Continue.\n3. Click Remove background to finish.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"},{"document_id":"ibmcld_03330-1656-3789","score":18.0036201477,"text":"\nMake your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/arch-detail.png)\n\n\n\n* Customers interact with the assistant through one or more of these channels:\n\n\n\n* An existing social media messaging platform, such as Slack, Facebook Messenger, or WhatsApp\n* A phone call or text message\n* A web chat that you embed in your company website and that can transfer complex requests to a customer support representative.\n* A custom application that you develop, such as a mobile app or a robot with a voice interface\n\n\n\n* The assistant receives a message from a customer and sends it down the appropriate resolution path.\n\nIf you want to preprocess incoming messages, this is where you would use webhooks to inject logic that calls an external service that can process the messages before the assistant routes them. Likewise, you can process responses from the assistant before they are returned to the customer.\n* The assistant chooses the appropriate resolution from among these options:\n\n\n\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_16365-12876-14604","score":17.9317779541,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16389-0-2061","score":17.8866214752,"text":"\n\n\n\n\n\n\n  Configuring style and appearance \n\nOn the Style tab, you can configure the overall appearance of the web chat widget. You can make the following changes:\n\n\n\n*  Set the assistant name. Click Assistant's name as known by customers to specify the name that is displayed in the header of the chat window. The name can be up to 64 characters in length.\n*  Change the colors used in the web chat widget. You can set the following colors:\n\n\n\n*  Primary color: The color of the web chat header.\n*  Secondary color: The color of the customer input message bubble.\n*  Accent color: The color of interactive elements such as the following:\n\n\n\n*  Web chat buttons such as the suggestions button and the \"send message\" button\n*  The border around the input text field (when in focus)\n*  The markers that appear beside the assistant\u2019s messages\n*  The borders that appear around buttons and drop-down lists when customers select from options\n*  The home screen background\n\n\n\n\n\nEach color is specified as an HTML hexadecimal color code, such as FF33FC for pink and 329A1D for green. To change a color, type the HTML color code you want to use, or click the dot next to the field and choose the color from the interactive color picker.\n*  Enable or disable the Built with IBM Watson watermark that is displayed in the web chat widget. To disable the watermark, click to toggle the IBM Watermark switch to the off position. (The watermark cannot be disabled on the Lite plan.)\n*  Provide an avatar image to represent your assistant or organization in the web chat header. Click Add an avatar image to add an image, or Change avatar image to change an image you have previously added.\n\nSpecify the URL for a publicly accessible hosted image, such as a company or brand logo or an assistant avatar. The image file must be between 64 x 64 and 100 x 100 pixels in size.\n\n\n\nStyle changes you make are immediately reflected by the web chat preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style"},{"document_id":"ibmcld_03080-7-1901","score":17.8841781616,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.4776237035,"ndcg_cut_10":0.4776237035}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16295-7-1721","score":25.8004760742,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_02855-7-2041","score":25.3657646179,"text":"\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16389-0-2061","score":24.2475147247,"text":"\n\n\n\n\n\n\n  Configuring style and appearance \n\nOn the Style tab, you can configure the overall appearance of the web chat widget. You can make the following changes:\n\n\n\n*  Set the assistant name. Click Assistant's name as known by customers to specify the name that is displayed in the header of the chat window. The name can be up to 64 characters in length.\n*  Change the colors used in the web chat widget. You can set the following colors:\n\n\n\n*  Primary color: The color of the web chat header.\n*  Secondary color: The color of the customer input message bubble.\n*  Accent color: The color of interactive elements such as the following:\n\n\n\n*  Web chat buttons such as the suggestions button and the \"send message\" button\n*  The border around the input text field (when in focus)\n*  The markers that appear beside the assistant\u2019s messages\n*  The borders that appear around buttons and drop-down lists when customers select from options\n*  The home screen background\n\n\n\n\n\nEach color is specified as an HTML hexadecimal color code, such as FF33FC for pink and 329A1D for green. To change a color, type the HTML color code you want to use, or click the dot next to the field and choose the color from the interactive color picker.\n*  Enable or disable the Built with IBM Watson watermark that is displayed in the web chat widget. To disable the watermark, click to toggle the IBM Watermark switch to the off position. (The watermark cannot be disabled on the Lite plan.)\n*  Provide an avatar image to represent your assistant or organization in the web chat header. Click Add an avatar image to add an image, or Change avatar image to change an image you have previously added.\n\nSpecify the URL for a publicly accessible hosted image, such as a company or brand logo or an assistant avatar. The image file must be between 64 x 64 and 100 x 100 pixels in size.\n\n\n\nStyle changes you make are immediately reflected by the web chat preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style"},{"document_id":"ibmcld_03166-4-2012","score":23.0347633362,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https:\/\/medium.com\/ibm-watson\/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16365-12876-14604","score":22.9840869904,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03196-30333-32476","score":22.1617565155,"text":"\nIn the Message before link to web chat field, edit the introductory message to display to the user (in the originating channel) before the link that initiates the transfer. By default, this message is OK, click this link for additional help. Chat will continue on a new web page.\n3. In the URL to web chat field, type the URL for your website where the web chat widget is embedded.\n\n\n\nIn the integration that processes the Channel transfer response, the introductory message is displayed, followed by a link to the URL you specify. The user must then click the link to initiate the transfer.\n\nWhen a conversation is transferred from one channel to another, the session history and context are preserved, so the destination channel can continue the conversation from where it left off. Note that the message output that contains the Channel transfer response is processed first by the channel that initiates the transfer, and then by the target channel. If the output contains multiple responses (perhaps using different response types), these will be processed by both channels (before and after the transfer). If you want to target individual responses to specific channels, you can do so by editing the response using the JSON editor. For more information, see [Targeting specific integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-target-integrations).\n\n\n\n\n\n Adding an Image response type \n\nSometimes a picture is worth a thousand words. Include images in your response to do things like illustrate a concept, show off merchandise for sale, or maybe to show a map of your store location.\n\nTo add an Image response type, complete the following steps:\n\n\n\n1. Choose Image.\n2. Add the full URL to the hosted image file into the Image source field.\n\nThe image must be in .jpg, .gif, or .png format. The image file must be stored in a location that is publicly addressable by an https: URL.\n\nFor example: https:\/\/www.example.com\/assets\/common\/logo.png.\n\nIf you want to display an image title and description above the embedded image in the response, then add them in the fields provided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_16368-7-2072","score":22.1294193268,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16374-0-2178","score":21.9908771515,"text":"\n\n\n\n\n\n\n  Supporting global audiences \n\nYou can build an assistant that understands customer messages in any of the languages that are supported by the service. The responses from your assistant are defined by you and can be written in any language you want.\n\nHowever, some of the phrases that are displayed in the web chat widget are part of the web chat itself and do not come from the assistant. By default, these hardcoded phrases are specified in English, but you can apply a different language by adding lines to the embedded web chat script.\n\nThe hardcoded phrases used by the web chat widget are specified in language pack files. The web chat provides language packs that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1.  To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2.  To change only the language of the hardcoded English phrases, use the instance.updateLanguagePack() method.\n\nFor more information, see [Instance methods](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslanguages).\n3.  To change the text direction of the page from right to left, use the direction method. For more information, see [Configuration](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-global"},{"document_id":"ibmcld_16365-8408-10508","score":21.8588600159,"text":"\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03166-4588-6408","score":21.7216701508,"text":"\nIf you don't want to use a home screen, go to the Home screen tab and toggle the switch to Off.\n8. Optional: To configure support for transferring conversations to a service desk agent, click the Live agent tab. For more information, see [Adding service desk support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa).\n9. Optional: The web chat gives your customers a way to reset the conversation if they get stuck by showing them a list of suggestions. Suggestions are enabled automatically. You can control how often suggestions are displayed and what they include. Click the Suggestions tab. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n10. Optional: To secure the web chat, click the Security tab. For more information, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security).\n11. Click the Embed tab.\n\nA code snippet is displayed that defines the chat window implementation. You will add this code snippet to your web page. The code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site. The code creates an instance of a widget that communicates with the assistant. The generated code includes a region and unique integration ID. Do not change these parameter values.\n12. Copy the script HTML element. You add this script to your website in the next section, [Deploy your assistant in production](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-snippet).\n13. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16368-7-2072","score":18.0959796906,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_02855-13982-15842","score":16.7784843445,"text":"\nFor more information about rich response types, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n Extending the web chat \n\nA developer can extend the capabilities of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html).\n\nIf you choose to use the provided methods, you implement them by editing the code snippet that was generated earlier. You then embed the updated code snippet into your web page.\n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-set-context%7D)\n* [Adding user identity information (if you don't enable security)](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid)\n\n\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_02855-12369-14489","score":16.5054244995,"text":"\nThe text in the Option label field has two functions:\n\n\n\n* The text is shown in the suggestions list as an option for customers to select.\n* When selected by a customer, the text is sent to your assistant as a new message. The label must be able to function as input that your dialog understands and knows how to handle.\n\n\n\nBy default, the option label Connect with agent is used. Change the option label to a message that helps your customers reach whatever form of support you do offer. If you offer a toll-free support line, you might add Get the support line phone number. Or if you offer an online support request form, you might add Open a support ticket.\n\nWhether you use the default option label or add your own, make sure your dialog is designed to recognize the message and respond to it appropriately. For more information, see [Connecting customers with support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support).\n\n\n\n\n\n\n\n Dialog considerations \n\nThe rich responses that you add to a dialog are displayed in the web chat as expected, with the following exceptions:\n\n\n\n* Connect to human agent: This response type is ignored.\n* Option: If your option list contains up to four choices, they are displayed as buttons. If your list contains five or more options, then they are displayed in a drop-down list.\n* Pause: This response type pauses the assistant's activity in the chat. However, activity does not resume after the pause until another response is triggered. Whenever you include a pause response type, add another, different response type, such as text, after it.\n\n\n\nFor more information about rich response types, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n Extending the web chat \n\nA developer can extend the capabilities of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html).\n\nIf you choose to use the provided methods, you implement them by editing the code snippet that was generated earlier.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16384-7-2422","score":16.0490474701,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16384-1889-3334","score":15.7539920807,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_02855-6718-8435","score":14.6044273376,"text":"\nSubmit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nYou can apply more advanced customizations to the style of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration). For example, the text that is displayed in the chat window uses the fonts: IBMPlexSans, Arial, Helvetica, sans-serif. If you want to use a different font, you can specify it by using the instance.updateCSSVariables() method.\n\n\n\n\n\n Adding a home screen ![Beta](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/beta.png) \n\nCustomers often don't know how to interact with your assistant at first. They aren't sure how to format a question or what types of things they can ask. Don't make them guess. Show them by adding a home screen to the web chat window.\n\n![An example of the home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/home-screen.png)\n\n\n\n1. From the Home screen tab, turn the home screen feature On.\n2. Add a greeting that is engaging and invites the user to interact with your assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16385-7-2272","score":14.3677358627,"text":"\nOverview: Securing the web chat \n\nIf you enable security, you can configure the web chat to authenticate users, protect private data, and restrict access to your assistant.\n\nAll messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS), which protects sensitive data as it travels through the network. However, there are still potential security exposures that you might need to protect against. By enabling the web chat security feature and updating your website code appropriately, you can add the following protections:\n\n\n\n* You can prevent unauthorized websites from sending messages to your assistant, even if they copy your web chat embed script. (The unique identifiers in the embed script, such as the integration ID and service instance ID, are visible to anyone who has access to your website.)\n* You can securely authenticate customers in order to control access to features of your assistant that require authorization.\n* You can encrypt sensistive data so that customers cannot see it, while still allowing your assistant to access it.\n\n\n\nWeb chat security uses JSON Web Tokens (JWTs), which are data objects that are sent with each message from your website to the Watson Assistant service. Because a JWT is digitally signed using a private encryption key that only you have, it ensures that each message originates with your website. The JWT payload can also be used to securely authenticate users and carry encrypted private data.\n\nFor detailed information about JSON Web Tokens, see the [JWT specification](https:\/\/tools.ietf.org\/html\/rfc7519)).\n\nEnabling web chat security involves making the following customizations:\n\n\n\n* Implementing web application server code that generates a JWT signed with your private encryption key\n* Customizing the web chat configuration to provide the generated JWT\n* Enabling security in the web chat security settings\n\nAfter you enable web chat security, any message received by the web chat integration that is not accompanied by a properly signed JWT will be rejected.\n\n\n\nFor detailed information about how to complete these steps, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security"},{"document_id":"ibmcld_03422-14609-15163","score":14.2084331512,"text":"\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Security measures \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has. Only serve content over HTTPS, use Content Security Policy (CSP), and implement other basic web security precautions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security"},{"document_id":"ibmcld_16365-8408-10508","score":14.1190395355,"text":"\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16365-10062-12114","score":14.0079212189,"text":"\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support \n\nBy default, the web chat displays hardcoded labels and messages in English, but support is built in for all of the languages supported by Watson Assistant. You can also choose from a wide selection of locales to customize the display of strings like dates and times for global audiences.\n\nIn whichever language you are using, you can also customize the text of any hardcoded strings.\n\nFor more information, see [Supporting global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-global).\n\n\n\n\n\n Security \n\nBy default, all messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS). You can enable the web chat security feature if you need more robust protection.\n\nThe web chat embed script that you include on your website contains unique identifiers (such as the integration ID and service instance ID) that enable the web chat to connect with your assistant. These identifiers are not considered secret, and are visible to anyone who has access to your website. Anyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.67973105,"ndcg_cut_10":0.67973105}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16298-6367-7794","score":19.1440181732,"text":"\nFor more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n\/\/ Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n\/\n* Returns a signed JWT. Optionally, adds an encrypted user_payload in stringified JSON.\n\/\nfunction mockLogin(userID, userPayload) {\nconst payload = {\nsub: userID, \/\/ Required\niss: 'www.ibm.com', \/\/ Required\nacr: 'loa1' \/\/ Required","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-zendesk"},{"document_id":"ibmcld_03188-4819-6738","score":19.1126079559,"text":"\nFor more information about how to pass data, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nTo access the payload data, you can reference the context.integrations.chat.private.user_payload object from the dialog node condition.\n\nYou must know the structure of the JSON object that is sent in the payload.\n\nFor example, if you passed the value \"mvp:true\" in the JSON payload, you can add a dialog flow that checks for this value to define a response that is meant for VIP customers only. Add a dialog node with a condition like this:\n\n\n\nPrivate variable as node condition\n\n Field Value \n\n If assistant recognizes $integrations.chat.private.user_payload.mvp \n Assistant responds I can help you reserve box seats at the upcoming conference! \n\n\n\n\n\n\n\n Web chat: Accessing web browser information \n\nWhen you use the web chat integration, information about the web browser that your customer is using to access the web chat is automatically collected and stored. The information is stored in the context.integrations.chat.browser_info object.\n\nYou can design your dialog to take advantage of details about the web browser in use. The following properties are taken from the window object that represents the window in which the web chat is running:\n\n\n\n* browser_name: The browser name, such as chrome, edge, or firefox.\n* browser_version: The browser version, such as 80.0.0.\n* browser_OS: The operating system of the customer's computer, such as Mac OS.\n* language: The default locale code of the browser, such as en-US.\n* page_url: Full URL of the web page in which the web chat is embedded. For example: https:\/\/www.example.com\/products\n* screen_resolution: Specifies the height and width of the browser window in which the web page is displayed. For example: width: 1440, height: 900\n* user_agent: Content from the User-Agent request header.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"},{"document_id":"ibmcld_16385-7-2272","score":19.0434761047,"text":"\nOverview: Securing the web chat \n\nIf you enable security, you can configure the web chat to authenticate users, protect private data, and restrict access to your assistant.\n\nAll messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS), which protects sensitive data as it travels through the network. However, there are still potential security exposures that you might need to protect against. By enabling the web chat security feature and updating your website code appropriately, you can add the following protections:\n\n\n\n* You can prevent unauthorized websites from sending messages to your assistant, even if they copy your web chat embed script. (The unique identifiers in the embed script, such as the integration ID and service instance ID, are visible to anyone who has access to your website.)\n* You can securely authenticate customers in order to control access to features of your assistant that require authorization.\n* You can encrypt sensistive data so that customers cannot see it, while still allowing your assistant to access it.\n\n\n\nWeb chat security uses JSON Web Tokens (JWTs), which are data objects that are sent with each message from your website to the Watson Assistant service. Because a JWT is digitally signed using a private encryption key that only you have, it ensures that each message originates with your website. The JWT payload can also be used to securely authenticate users and carry encrypted private data.\n\nFor detailed information about JSON Web Tokens, see the [JWT specification](https:\/\/tools.ietf.org\/html\/rfc7519)).\n\nEnabling web chat security involves making the following customizations:\n\n\n\n* Implementing web application server code that generates a JWT signed with your private encryption key\n* Customizing the web chat configuration to provide the generated JWT\n* Enabling security in the web chat security settings\n\nAfter you enable web chat security, any message received by the web chat integration that is not accompanied by a properly signed JWT will be rejected.\n\n\n\nFor detailed information about how to complete these steps, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security"},{"document_id":"ibmcld_16365-12876-14604","score":18.1617565155,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16388-7-1918","score":17.6339988708,"text":"\nEncrypting sensitive data \n\nBy using the public key that is provided by IBM, you can add another level of encryption to hide sensitive data you send from the web chat.\n\nTo use this method for encrypting data, you must first enable the web chat security feature. For more information, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nUse this method to send sensitive information in messages that come from your website, such as information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from actions. Information passed to your assistant in this way is stored in a private context variable. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for a standard customer. You do not want non-VIPs to know that they are categorized as such, but you must pass this information to your action so it can change the flow of the conversation. To do this, you can pass the customer MVP status as an encrypted variable. This private context variable is available for use by the action, but not by anything else.\n\n![development icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/development-icon.png)Tutorial: For a tutorial that shows an example of using web chat security to authenticate users and protect sensitive data, see [Tutorial: Authenticating a user in the middle of a session](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-security).\n\nTo encrypt sensitive data:\n\n\n\n1. On the Security tab of the web chat integration settings, click the Generate key button.\n2. Copy the public key that displays in the IBM-provided public key field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-encrypt"},{"document_id":"ibmcld_03080-5624-7473","score":17.4624843597,"text":"\nFor more information about how to customize it, see [HTML content](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-renderhtml).\n\n\n\nThe web chat is embedded directly on your page, not inside an iframe. Therefore, the cascading style sheet (CSS) rules for your website can sometimes override the web chat CSS rules. The web chat applies aggressive CSS resets, but the resets can be affected if your website uses the !important property in elements where style is defined.\n\n\n\n Passing values \n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-set-context)\n* [Adding user identity information (if you don't enable security)](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-userid)\n\n\n\nFor a tutorial that describes how to set context values from the web chat, see [Setting context](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-setting-context).\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_02855-22154-24172","score":17.41147995,"text":"\nWhen you enable security, your assistant takes an additional step to verify that messages originate from the web chat that is embedded in your website only.\n\nThe web chat uses an RSA signature with SHA-256 to encrypt communication. RS256 cryptography is a sophisticated type of RSA encryption. An RSA key pair includes a private and a public key. The RSA private key is used to generate digital signatures, and the RSA public key is used to verify digital signatures. The complexity of the RSA algorithm that is used to scramble the message makes it nearly impossible to unscramble the message without the key.\n\nYou can implement the following security measures:\n\n\n\n* Ensure that messages sent from the web chat to your assistant come from your customers only\n* Send private data from the web chat to your assistant\n\n\n\nFor more information about security, see [Security](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=key-conceptssecurity).\n\n\n\n Enable security \n\nThe process you use to add the web chat to your website is simple. Its simplicity also means it can be misused. That's why it's important to verify that the messages sent to your assistant are coming from authorized users only.\n\nAfter you enable security, users cannot submit messages through the web chat unless you take steps to prove their origin. Do not enable it until you have support for authentication in place.\n\nBefore you enable security, complete the following steps:\n\n\n\n1. Create a RS256 private\/public key pair.\n\nYou can use a tool such as the OpenSSL command line or PuTTYgen.\n\n\n\n* For example, to create the key pair: openssl genrsa -out key.pem 2048\n\n\n\n2. Use your private key to sign a JSON Web Token (JWT). You will pass the token with the messages that are sent from your website as proof of their origin.\n\nThe JWT payload must specify values for the following claims:\n\n\n\n* iss: Represents the issuer of the JWT. This value is a case-sensitive string.\n* sub: Represents the principal that is the subject of the JWT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_02855-16710-18404","score":17.2618484497,"text":"\nThe next response has a more generic greeting.\n\n![Shows multiple conditioned responses in a dialog node, one of which references the ismember context variable](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/web-chat-use-context-var.png)\n\nIf you enable security, you can encrypt the data that you pass to your dialog. For more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-encrypt).\n\nRemember that a session ends if there's no interaction with the user after 1 hour (or whatever inactivity timeout setting you specify, which can be up to 7 days). Any contextual information that you pass or collect is reset after the inactivity time period is passed. For more information, see [Changing the inactivity timeout setting](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-settings).\n\n\n\n\n\n Adding user identity information \n\nIf you do not enable security, and you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration.\n\nIf you do enable security, you set the user ID in the JSON Web Token instead. For more information, see [Authenticating users](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-authenticate).\n\nChoose a non-human-identifiable ID. For example, do not use a person's email address as the user_id.\n\nUser information is used in the following ways:\n\n\n\n* The user_id is used to measure the number of monthly active users who interact with the web chat integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03180-5630-7213","score":17.0748119354,"text":"\nEnabling visitor authentication also enables support for cross-domain traffic and cross-browser identification. For more information, see the [Zendesk documentation](https:\/\/support.zendesk.com\/hc\/en-us\/articles\/360022185314-Enabling-authenticated-visitors-in-the-Chat-widget).\n\nBefore you can secure the Zendesk connection, complete the following required tasks:\n\n\n\n1. Secure the web chat. For more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n\/\/ Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n\/\n* Returns a signed JWT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"},{"document_id":"ibmcld_16387-7-1890","score":17.0416622162,"text":"\nEnabling web chat security \n\nTo enable web chat security, you must make changes to your web application server code and the web chat embed script, as well as the web chat integration settings.\n\n\n\n Before you begin \n\nBefore you enable security, you must create an RS256 public\/private key pair. You can use a tool such as OpenSSL or PuTTYgen.\n\nFor example, to create the key pair at a command prompt using OpenSSL, you would use the command openssl genrsa -out key.pem 2048.\n\nSave the generated key pair in a secure location.\n\nMake sure these keys are accessible only by your server code. Never pass them to a client browser through your website.\n\n\n\n\n\n Generating a JWT \n\nTo use web chat security, you must configure the web chat on your website to send a JSON Web Token (JWT) with each message to the assistant. The JWT is used to verify the origin of messages sent from your website, and optionally to carry additional encrypted data. Your website will need to be able to generate a new JWT at the beginning of each session, and also whenever an existing JWT expires.\n\nDo not hardcode a JWT in your website code or share JWTs between users.\n\nOn your server, implement a function that generates and returns a JSON Web Token (JWT) that is signed with your private key. You will use this token to verify the origin of messages sent from your website, and optionally to carry additional encrypted data.\n\nMost programming languages offer JWT libraries that you can use to generate a token. To validate signed JWTs, the web chat integration uses the [jsonwebtoken](https:\/\/www.npmjs.com\/package\/jsonwebtoken) library with the RS256 algorithm.\n\nThe JWT payload must specify the following claims:\n\n\n\n* sub: A unique user ID that identifies the customer who is interacting with the web chat. This can be either a generated unique identifier (for anonymous users) or an authenticated user ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.3065735964}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16315-9405-10024","score":14.3652591705,"text":"\n* Journeys currently do not meet accessibility requirements.\n* Journeys are not supported if you are using the [element configuration option](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationoptionselement) to render the web chat in a custom DOM element.\n* When the customer starts a journey, the web chat window temporarily closes, but will reopen when the journey finishes. If you are using the window:close event to trigger the display of a post-chat form, your code should check the value of the new event.reason parameter of the event and verify that it is not set to open_tour.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-journeys"},{"document_id":"ibmcld_16365-1312-3051","score":13.6626834869,"text":"\nFor more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n![An example of the initial launcher](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-icon.png)\n\nAfter 15 seconds, the launcher expands to show a greeting message to the user. In this expanded state, a customer can still click the launcher to open the web chat. (If the customer reloads the page or navigates to a different page before the launcher has expanded, the 15-second timer restarts.)\n\nThe appearance of this expanded state differs slightly depending on whether the customer is using a desktop browser or a mobile browser:\n\n\n\n* For desktop browsers, the expanded launcher shows two primary buttons the customer can click to open the web chat, and a Close button that closes the launcher.\n\n![An example of the desktop launcher](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/desktop-launcher.png)\n\nThe expanded launcher remains in its expanded state even if the customer reloads the page or navigates to a different page. It stays in its expanded state until the customer either opens it by clicking on either of the two primary buttons, or closes it, at which point it returns to its initial small state for the rest of the session.\n* For mobile browsers, the launcher shows only a single primary button.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03166-1557-3458","score":13.4879741669,"text":"\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) For environments where private endpoints are in use, keep in mind that the web chat integration sends traffic over the internet. For more information, see [Private network endpoints](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-securitysecurity-private-endpoints).\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Assistant's name as known by customers: The name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 64 characters in length.\n* Primary color: The color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: The color of the user input message bubble.\n* Accent color: The color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16375-1468-2933","score":13.020565033,"text":"\n\/\/ A UUID like '1d7e34d5-3952-4b86-90eb-7c7232b9b540' included in the embed code provided in Watson Assistant.\nintegrationID: \"YOUR_INTEGRATION_ID\",\n\/\/ Your assistants region e.g. 'us-south', 'us-east', 'jp-tok' 'au-syd', 'eu-gb', 'eu-de', etc.\nregion: \"YOUR_REGION\",\n\/\/ A UUID like '6435434b-b3e1-4f70-8eff-7149d43d938b' included in the embed code provided in Watson Assistant.\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE_ID\",\n\/\/ The callback function that is called after the widget instance has been created.\nonLoad: function(instance) {\ninstance.render();\n},\nshowLauncher: false, \/\/ Hide the web chat launcher, you will open the WebView from your mobile application\nopenChatByDefault: true, \/\/ When the web chat WebView is opened, the web chat will already be open and ready to go.\nhideCloseButton: true \/\/ And the web chat will not show a close button, instead relying on the controls to close the WebView\n};\nsetTimeout(function(){const t=document.createElement('script');t.src=\"https:\/\/web-chat.global.assistant.watson.appdomain.cloud\/versions\/\" + (window.watsonAssistantChatOptions.clientVersion || 'latest') + \"\/WatsonAssistantChatEntry.js\";document.head.appendChild(t);});\n<\/script>\n<\/body>\n<\/html>\nShow more\n\nIn your app, make sure you include logic to hide your web chat launching mechanism when the device is offline. If the device goes offline in the middle of a conversation, appropriate error messages and retries occur.\n\n\n\n\n\n Using a JavaScript bridge","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-mobile"},{"document_id":"ibmcld_16380-1665-3330","score":12.8067274094,"text":"\n<div id=\"WebChatContainer\"><\/div>\n2. Get a reference to your custom element so you can reference it in the web chat configuration. To get a reference, use whatever mechanism makes sense for the library you are using. For example, you can save the reference returned from document.createElement(), or you can use a query function to look up the element in the DOM. This example looks up the element using the ID we assigned to it:\n\nconst customElement = document.querySelector('WebChatContainer');\n3. In the web chat embed script, set the element property, specifying the reference to your custom element.\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE_ID\",\n\n\/\/ The important piece.\nelement: customElement,\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n4. Make sure that the main web chat window is hidden by default. You can do this in the onLoad event handler, after render has been called. You must also add handlers to listen for the window:open and window:close events so the customer can open and close the web chat after the page loads. In our example, we are using a CSS class called HideWebChat to do this (see the [full example](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/blob\/master\/integrations\/webchat\/examples\/custom-element\/client\/javascript-animation\/index.html) for the definition of this class):\n\nfunction onLoad(instance) {\ninstance.render();\ninstance.on({ type: 'window:close', handler: closeHandler });\ninstance.on({ type: 'window:open', handler: openHandler });\ninstance.elements.getMainWindow().addClassName('HideWebChat');","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-size-position"},{"document_id":"ibmcld_16334-17373-19365","score":12.6150255203,"text":"\n* Home screen: The web chat home screen has been updated to have a more modern look. For more information about the home screen, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-configweb-chat-configure-home-screen).\n* Agent events: New events are now fired by the web chat when interacting with a human agent using a service desk integration. If you are using a custom service desk integration based on the [starter kit](https:\/\/github.com\/watson-developer-cloud\/assistant-web-chat-service-desk-starter), you can use these events to create a pre-chat form before the agent escalation occurs, to create a post-chat form after the agent conversation ends, or to specify what happens if an agent isn\u2019t available (like create a ticket submission form). For more information, see [Agent events summary](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventssummary).\n* Markdown support: The web chat now fully supports common Markdown formatting in messages received from an assistant. You might need to review existing assistant output that contains strings that might be recognized as Markdown. (For example, a line of text that begins with a greater-than (>) character is interpreted as a block quote.)\n* Time zone: The time zone set in the context by the web chat no longer overrides any time zone set by the assistant.\n* Locale: Any locale configured for the web chat is now sent to the assistant as part of the context.\n* Window open events: The window:pre:open and window:open events now fire any time the chat window is opened, regardless of the reason. In previous releases, these events only fired if the window was opened by the customer clicking on the built-in launcher. Other methods of opening the chat window, such as session history or custom launchers, did not fire these events.\n\nThe event data passed to the listener has a new reason property that indicates the reason the window was opened.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_16377-7-1723","score":12.4254522324,"text":"\nTutorial: Displaying a pre-chat or post-chat form \n\nThis tutorial shows how you can display pre-chat form before the web chat opens, or a post-chat form that opens after the web chat closes.\n\nFor a complete, working version of the example described in this tutorial, see [Pre and post-chat forms for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/pre-post-chat-forms).\n\nIf you want to gather information from your customers before starting a chat session, you can display a pre-chat form before opening the web chat. Similarly, you might want to display a form after the web chat closes (for example, a customer satisfaction survey). You can use the same approach for either situation.\n\nWhen the web chat is opened or closed, it fires an [event](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-events) that you can subscribe to. In your event handler, you can use the [custom panels](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-rendercustompanel) feature to open a panel with custom content.\n\nBy returning a promise that is resolved when the custom panel closes, you can pause the process of opening or closing the web chat until after the customer completes the form.\n\nThis example shows how to create a pre-chat form. To create a post-chat form, follow the same steps, but subscribe to the window:pre:close event instead of the window:open event.\n\nTo display a pre-chat form, follow these steps:\n\n\n\n1. Create a handler for the [window:open](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventswindowpreopen) event, which is fired when the web chat opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-pre-chat"},{"document_id":"ibmcld_03080-7-1901","score":12.397611618,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16380-7-2028","score":12.3710441589,"text":"\nTutorial: Customizing the size and position of the web chat \n\nThis tutorial shows how you can change the size and position of the web chat by rendering it in a custom element.\n\nFor a complete, working version of the example described in this tutorial, see [Custom elements for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/custom-element).\n\nBy default, the web chat interface on your website is rendered in a host div element that is styled to appear in a fixed location on the page. If you want to change the size or position of the web chat, you can specify a custom element as the host location for the web chat. This host element is used as the location for both the main web chat interface and for the web chat launcher (unless you are using a custom launcher).\n\nWhen you use a custom element, you also take control of showing and hiding the web chat when it is opened or closed (such as when the customer clicks the launcher icon or the minimize button). This gives you the opportunity to apply additional effects, such as opening and closing animations. You can control showing and hiding the main window by using the [addClassName() and removeClassName()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodselements-get-main-window) functions.\n\nTo use a custom element, follow these steps:\n\n\n\n1. In your website code, define the custom element where you want the web chat to be rendered. There are many ways of doing this, depending on the framework you are using. A simple example is to define an empty HTML element with an ID:\n\n<div id=\"WebChatContainer\"><\/div>\n2. Get a reference to your custom element so you can reference it in the web chat configuration. To get a reference, use whatever mechanism makes sense for the library you are using. For example, you can save the reference returned from document.createElement(), or you can use a query function to look up the element in the DOM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-size-position"},{"document_id":"ibmcld_16295-7-1721","score":12.293211937,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1480409555}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03422-14609-15163","score":15.3577528,"text":"\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Security measures \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has. Only serve content over HTTPS, use Content Security Policy (CSP), and implement other basic web security precautions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security"},{"document_id":"ibmcld_16334-35243-37326","score":15.0684814453,"text":"\n* Bug fix: Fixing a bug that prevented the web chat integration preview from working after security was enabled.\n\n\n\n\n\n\n\n 3.2.0 \n\nRelease date: 26 October 2020\n\n\n\n* Security improvement: If you enable security, you no longer need to include the identityToken property when the web chat is loaded on a web page. If a token is not initially provided, the existing identityTokenExpired event will be fired when the web chat is first opened to obtain one from your handler.\n* Starter kit update: The starter kit now allow you to customize the timeout that occurs when the web chat integration checks whether any service desk agents are online.\n\n\n\n\n\n\n\n 3.1.1 \n\nRelease date: 22 October 2020\n\n\n\n* Accessibility improvement: Changed how the announcement text is generated to prevent announcements from being duplicated. Announcement text is hidden text that is provided for use by screen readers to indicate when dynamic web page changes occur.\n\n\n\n\n\n\n\n 3.1.0 \n\nRelease date: 8 October 2020\n\n\n\n* Suggestions now allow for trial and error: If customers select a suggestion and find that the response is not helpful, they can open the suggestions list again and try a different suggestion.\n\n\n\n\n\n\n\n 3.0.0 \n\nRelease date: 22 September 2020\n\n\n\n* Choose when a link to support is included in suggestions: The Suggestions beta feature has moved to its own tab. Now you can enable suggestions even if your web chat is not set up to connect to a service desk solution. That's because now you can control if and when the option to connect to customer support is available from the suggestions list. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n* Search result format change: To support the ability to show more than 3 search results in a response, the search skill response type format changed. If you are using pre:receive or receive handlers to process search results, you might need to update your code. The results property was replaced by the primary_results and additional_results properties.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_16365-7-1700","score":14.9907045364,"text":"\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16376-7-1787","score":14.9206857681,"text":"\nTutorial: Interacting with the host web page \n\nYou can use custom responses and events to enable the web chat to interact with the web page where it appears.\n\nFor example, your customers might use your assistant to find information they need to complete a form. Rather than expecting the customer to then copy this information manually to the form, you can have the web chat automatically fill in the information.\n\nFor a complete, working version of the example described in this tutorial, see [Page interactions for Watson Assistant web chat](https:\/\/github.com\/watson-developer-cloud\/assistant-toolkit\/tree\/master\/integrations\/webchat\/examples\/page-interaction).\n\nThis example uses a custom response to render a button in the web chat that populates a form field with the customer's account number:\n\n\n\n1. Create a handler for the [customResponse](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventscustomresponse) event. This handler renders a custom button and creates a click handler for it. The click handler uses the Document.querySelector() method to interact with the DOM and fill in a form field with the customer's account number.\n\nThis example uses the hardcoded account number 1234567. In a typical production assistant, your assistant would retrieve this value from a session variable or query it from an external system.\n\nfunction customResponseHandler(event) {\nconst { element } = event.data;\n\nconst button = document.createElement('button');\nbutton.type = 'button';\nbutton.innerHTML = 'Fill in account number';\nbutton.addEventListener('click', () => {\n\/\/ Look for the account number element in the document and fill in the account number.\ndocument.querySelector('account-number').value = '1234567';\n});\n\nelement.appendChild(button);\n}\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-page-interaction"},{"document_id":"ibmcld_16365-10062-12114","score":14.8596544266,"text":"\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support \n\nBy default, the web chat displays hardcoded labels and messages in English, but support is built in for all of the languages supported by Watson Assistant. You can also choose from a wide selection of locales to customize the display of strings like dates and times for global audiences.\n\nIn whichever language you are using, you can also customize the text of any hardcoded strings.\n\nFor more information, see [Supporting global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-global).\n\n\n\n\n\n Security \n\nBy default, all messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS). You can enable the web chat security feature if you need more robust protection.\n\nThe web chat embed script that you include on your website contains unique identifiers (such as the integration ID and service instance ID) that enable the web chat to connect with your assistant. These identifiers are not considered secret, and are visible to anyone who has access to your website. Anyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03042-4126-5526","score":14.8317956924,"text":"\nFor more information about UUIDs, see [RFC 4122](https:\/\/tools.ietf.org\/html\/rfc4122.html).\n\n\n\n* For web chat, if you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user.\n\n\n\n\n\n\n\n\n\n Service API versioning \n\nAPI requests require a version parameter that takes a date in the format version=YYYY-MM-DD. Whenever we change the API in a backwards-incompatible way, we release a new minor version of the API.\n\nSend the version parameter with every API request. The service uses the API version for the date you specify, or the most recent version before that date. Don't default to the current date. Instead, specify a date that matches a version that is compatible with your app, and don't change it until your app is ready for a later version.\n\nThe current version for both V1 and V2 is 2020-04-01.\n\nFor API usage information, see the API reference documentation. Links for v1 and v2 are available from the table of contents.\n\nFor an example of using the API, see [Testing the search skill by using the API](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-test-via-api).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-services-information"},{"document_id":"ibmcld_16384-7-2422","score":14.8000793457,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_07578-5954-7906","score":14.5417795181,"text":"\nYou can add these to your skill and start using them immediately. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks). \n Variable A variable is data that a customer shares with the assistant, which is collected and saved so it can be referenced later. In an actions skill, you can collect action and session variables. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actions-overviewactions-overview-step-variables). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat). \n Webhook A mechanism for calling out to an external program during a conversation. For example, your assistant can call an external service to translate a string from English to French and back again in the course of the conversation. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview). \n\n\n\n* I can't log in\n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-5954-7906","score":14.5417795181,"text":"\nYou can add these to your skill and start using them immediately. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks). \n Variable A variable is data that a customer shares with the assistant, which is collected and saved so it can be referenced later. In an actions skill, you can collect action and session variables. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actions-overviewactions-overview-step-variables). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat). \n Webhook A mechanism for calling out to an external program during a conversation. For example, your assistant can call an external service to translate a string from English to French and back again in the course of the conversation. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview). \n\n\n\n* I can't log in\n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16364-110490-112399","score":14.484662056,"text":"\nFor more information, see [Configure the search](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-addskill-search-add-configure).\n\n\n\n\n\n 25 August 2020 \n\nGive the web chat integration a try!\n: You can now use the web chat integration with a Lite plan. Previously, the web chat was available to Plus or higher plans only. For more information, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\n\n\n\n\n 12 August 2020 \n\nv2 Logs API is available\n: If you have a Premium plan, you can use the v2 API logs method to list log events for an assistant. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs) documentation.\n\n\n\n\n\n 5 August 2020 \n\nEnable your skill to improve itself\n: Try the new autolearning beta feature to empower your skill to improve itself automatically over time. Your skill observes customer choices to understand which choices are most often the best. As its confidence grows, your skill presents better options to get the right answers to your customers with fewer clicks. For more information, see [Empower your skill to learn over time](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-autolearn).\n\nShow more of search results\n: When search results are returned from the search skill, the customer can now click a twistie to expand the search result card to see more of the returned text.\n\n\n\n\n\n 29 July 2020 \n\nThe @sys-location and @sys-person system entities were removed\n: The @sys-location and @sys-person system entities are no longer listed on the System entities page. If your dialog uses one of these entities, a red Entity not created notification is displayed to inform you that the entity is not recognized.\n\nSkill menu actions moved\n: The menu that was displayed in the header of the skill while you were working with a skill was removed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02748-4-2059","score":22.3002567291,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Managing users \n\nWith Cloud Directory, you can manage your users in a scalable registry by using a pre-built functionality that enhances security and self-service.\n\nA Cloud Directory user is not the same thing as an App ID user. Users can sign up for your app by using the different identity provider options that you configured, or you can add them to your directory. The users that are mentioned in the following sections are the users who are associated with Cloud Directory as an identity provider.\n\n\n\n Viewing user information \n\nYou can see all the information that is known about all your Cloud Directory users as a JSON object by using the APIs or by using the dashboard.\n\n\n\n Viewing user information with the UI \n\nYou can use the App ID dashboard to view details about your app users.\n\n\n\n1. Go to the Cloud Directory > Users tab of your App ID instance.\n2. Look through the table or search by using an email address to find the user that you want to see the information for. The search term must be exact.\n3. In the overflow menu in the user's row, click View user details. A page opens that contains the user's information. Check out the following table to see what information you can see.\n\n\n\nTable 1. The details that you can see about your users by looking in the App ID dashboard\n\n Detail Description \n\n User identifier The user identifier is dependant upon the type of user sign-up that you configured. For example, if you have an email and password flow, the identifier is the user's email. If you use the username and password flow, the identifier is the username that is given at sign-up. \n Email The primary email address that is attached to the user. \n First name and surname Your user's first name and surname as they provided during the sign-up process. \n Last Login The timestamp of the last time that the user logged in to your application. Note: If you added your user through the dashboard, the login is blank until the user themselves signs in to your app. When sign-in occurs, they also become an App ID user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-users"},{"document_id":"ibmcld_02774-5358-7120","score":21.6614627838,"text":"\nA user's predefined attributes are empty until their first authentication. Although they're empty, the user is still fully authenticated. You can use their profile ID just as you would someone who has already signed in. For instance, you can modify, search, or delete the profile.\n\n\n\n Before you begin \n\nBefore you get started, you must have the following information:\n\n\n\n* Which identity provider that the user will sign in with.\n* The email of the user that you want to add or their [unique identifier](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregisterpreregister-idp-provide).\n* The [custom attribute](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-profiles) information that you want to assign.\n\n\n\n\n\n\n\n With the GUI \n\nYou can add a future user and their custom attributes by using the GUI.\n\nThe ability to add future users is disabled for the user name and password configuration of Cloud Directory.\n\n\n\n1. Go to the User Profiles tab of the App ID dashboard.\n2. Click Future users. If you already have future users, you see a table with a list of the user's that you already added. To add another user, click Build a profile. If you don't have any users yet, click Get Started. A screen opens.\n3. Enter your user's email.\n4. Select the identity provider that they sign in with from the Identity Provider drop down.\n5. Add custom attributes by entering the information in a JSON object as shown in the following example.\n\n{\n\"food\": \"Pizza\",\n\"preference\": \"Vegetarian\",\n\"points\": \"37\"\n}\n6. Click Save. The table displays and the user is assigned an identifier.\n\n\n\n\n\n\n\n With the API \n\nYou can add a future user and their custom attributes by using the API.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Find your IAM token by running the following command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregister"},{"document_id":"ibmcld_02798-4-2051","score":21.3129692078,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Managing profiles \n\nWith IBM Cloud\u00ae App ID, you can compile information about the individual users of your application into a profile. The information in the profile can be learned about your users by the way that they interact with your app or added by you on their behalf. By storing the information, you can access it to help create personalized experiences of your app for your users.\n\nLooking for information about your Cloud Directory users? Check out [managing users](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-users).\n\n\n\n Viewing user profiles with the UI \n\nTo see the data that is available for your app users, you can use the App ID UI.\n\n\n\n1. Navigate to the User Profiles > Profiles tab of your App ID instance.\n2. Look through the table or search by using an email address to find the user that you want to see the information for. The search term must be exact.\n3. In the overflow menu of the user's row, click View user profile. A page opens that contains the user's information. Check out the following table to see what information you can see.\n\n\n\nTable 1. User details as shown in the App ID dashboard\n\n Detail Description \n\n IdP identifier The IdP identifier is issued by the provider that your user chose to sign in to your application with. \n Email The primary email address that is attached to the user. \n Name Your user's first and surname as issued by the identity provider. \n Identity provider The provider that your user chose to sign in with. \n ID The ID that is assigned to the user by App ID. \n Custom attributes Custom attributes are additional information that is added to their profile or that is learned about the user's as they interact with your application. \n Summary All the information that is associated with that user shown as a JSON object. \n\n\n\n\n\n\n\n\n\n Viewing user profiles with the API \n\nYou can use the App ID API to view details about your app users.\n\n\n\n1. Obtain your tenant ID from your instance of the service. You can find the ID in your service or application credentials.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-user-admin"},{"document_id":"ibmcld_02766-3003-4951","score":20.7252750397,"text":"\nAn identity provider creates and manages information about an entity such as a user, a functional ID, or an application. The provider verifies the identity of the entity by using credentials, such as a password. Then, the IdP sends the identity information back to App ID, which authorizes the user and then grants access to your app.\n\n\n\n1. Navigate to your service dashboard.\n2. In the Identity Providers section of the navigation, select the Manage page.\n3. On the Identity Providers tab, set the providers that you want to use, to On.\n4. Optional: Decide whether to turn off Anonymous users, or leave the default, which is On. When set to On, user attributes are associated with the user from the moment they begin interacting with your app. For more information about the path to becoming an identified user, see [Progressive authentication](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymousprogressive).\n\n\n\nApp ID provides default credentials to help with your initial setup of Facebook and Google+. You are limited to 20 uses of the credentials per instance, per day. Because they are IBM credentials, they are meant to be used only for development. Before you publish your app, update the configuration to your own credentials.\n\n\n\n\n\n Adding redirect URIs \n\nYour application redirects users to App ID for authentication. After authentication completes, App ID redirects users back to your application. In order for App ID to be able to redirect users back to your app, you need to register the redirect URI. During the sign-in flow, App ID validates the URIs before it allows clients to participate in the authorization workflow, which helps to prevent phishing attacks and grant code leakage. By registering your URI, you're telling App ID that the URI is trusted and it's OK to redirect your users.\n\n\n\n1. Click Authentication Settings to see your URI and token configuration options.\n2. In the Add web redirect URI field, type the URI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idp"},{"document_id":"ibmcld_16382-7-1870","score":20.1787128448,"text":"\nManaging user identity information \n\nWatson Assistant charges based on the number of unique monthly active users (MAU).\n\nIf you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user. And you are charged only once when the same anonymous user interacts with your assistant multiple times in a single month.\n\nIf you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration. Choose a non-human-identifiable ID. For example, do not use a person's email address as the user ID.\n\nIn addition, the ability to delete any data created by someone who requests to be forgotten requires that a customer_id be associated with the user input. When a user_id is defined, the product can reuse it to pass a customer_id parameter. (For more information about deleting user data, see [Labeling and deleting data](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-securingsecuring-gdpr-wa).)\n\nBecause the user_id value that you submit is included in the customer_id value that is added to the X-Watson-Metadata header in each message request, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nTo support these user-based capabilities, add the [updateUserID() method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdateuserid) in the code snippet before you paste it into your web page.\n\nIf you enable security, you set the user ID in the JSON Web Token instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid"},{"document_id":"ibmcld_02777-7-2007","score":19.7953681946,"text":"\nStoring and accessing attributes \n\nWith IBM Cloud\u00ae App ID, you can compile information about the individual users of your application into a profile. The information in the profile can be learned about your users by the way that they interact with your app or added by you on their behalf. By storing the information, you can access it to help create personalized experiences of your app for your users.\n\n\n\n Understanding profiles \n\nA user profile is all the information that is known about a specific user - compiled into one JSON object and stored by App ID. There are two types of information, or attributes, that can be obtained and stored in a profile: predefined and custom. Predefined attributes are specific to the identity of your user and are returned by an identity provider when your user signs in to your app and can include information such as their name or age. Custom attributes are used to store additional information about your users. They can be set by you or learned about the user as they interact with your app. Custom attributes might include an assigned role, a food preference, or a preferred aisle seat on an airplane.\n\nZoom\n\n![App ID user profiles](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/user-profile-makeup.png)\n\nFigure 1. User profile information flow\n\nYou can store up to 100 KB of information for each user.\n\n\n\n How do I get the user profile information? \n\nSeveral different ways exist in which you can access user information, and several different reasons why you would want to. The endpoint that you choose to call can vary depending on your use case.\n\nNot sure which one works best? Join our [Slack channel](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/get-help-with-ibm-cloud-app-id-related-questions-on-slack) and get advice directly from our development team.\n\nIf you need to work with an API, check out the following image and corresponding information to see how the information is pulled.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-profiles"},{"document_id":"ibmcld_02855-17972-19576","score":19.4901828766,"text":"\nFor more information, see [Authenticating users](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-authenticate).\n\nChoose a non-human-identifiable ID. For example, do not use a person's email address as the user_id.\n\nUser information is used in the following ways:\n\n\n\n* The user_id is used to measure the number of monthly active users who interact with the web chat integration.\n* The ability to delete any data created by someone who requests to be forgotten requires that a customer_id be associated with the user input. When a user_id is defined, the product can reuse it to pass a customer_id parameter. See [Labeling and deleting data](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-information-securityinformation-security-gdpr-wa).\n\n\n\nBecause the user_id value that you submit is included in the customer_id value that is added to the X-Watson-Metadata header in each message request, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nTo support these user-based capabilities, add the updateUserID() method in the code snippet before you paste it into your web page.\n\nIn the following example, the user ID L12345 is added to the script.\n\n<script>\nwindow.watsonAssistantChatOptions = {\nintegrationID: 'YOUR_INTEGRATION_ID',\nregion: 'YOUR_REGION',\nserviceInstanceID: 'YOUR_SERVICE_INSTANCE',\nonLoad: function(instance) {\ninstance.updateUserID(L12345);\ninstance.render();\n}\n};\nsetTimeout(function(){\nconst t=document.createElement('script');","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03080-9575-11239","score":19.0795536041,"text":"\nIf you do enable security, you set the user ID in the JSON Web Token instead. For more information, see [Authenticating users](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security-authenticate).\n\nChoose a non-human-identifiable ID. For example, do not use a person's email address as the user_id.\n\nUser information is used in the following ways:\n\n\n\n* User-based service plans use the user_id associated with user input for billing purposes.\n\n\n\n\n\n* The ability to delete any data created by someone who requests to be forgotten requires that a customer_id be associated with the user input. When a user_id is defined, the product can reuse it to pass a customer_id parameter.\n\nBecause the user_id value that you submit is included in the customer_id value that is added to the X-Watson-Metadata header in each message request, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\n\n\nTo support these user-based capabilities, add the [updateUserID() method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdateuserid) in the code snippet before you paste it into your web page.\n\nIn the following example, the user ID L12345 is added to the script.\n\n<script>\nwindow.watsonAssistantChatOptions = {\nintegrationID: 'YOUR_INTEGRATION_ID',\nregion: 'YOUR_REGION',\nserviceInstanceID: 'YOUR_SERVICE_INSTANCE',\ncloudPrivateHostURL: 'YOUR_HOST_URL',\nonLoad: function(instance) {\ninstance.updateUserID('L12345');\ninstance.render();\n}\n};\nsetTimeout(function(){\nconst t=document.createElement('script');","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_01890-7-1963","score":19.002204895,"text":"\nIAM condition properties \n\nDynamic rules and trusted profiles both use conditional IAM statements that you specify to automatically add federated users to access groups or trusted profiles. When users log in with a federated ID, the data from the identity provider (IdP) dynamically maps them to an access group based on conditions that you set. For more information, see [Creating dynamic rules for access groups](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rules) and [Creating trusted profiles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-trusted-profile).\n\nYou can also assign conditional IAM access policies to designate temporary access to resources in your account or allow access to resources during specific time windows. For more information, see [Limiting access with time-based conditions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-time-based) and review the section [Conditions in \/v2\/policies access policies](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-condition-properties&interface=uipolicy-condition-properties).\n\n\n\n Rule and profile details \n\nEach dynamic rule and trusted profile trust relationship has the following properties:\n\nName\n: Enter a custom name that helps you remember what type of users you are adding to an access group or trusted profile.\n\nIdentity provider (IdP)\n: The dynamic rule or trusted profile is evaluated only if the user who is logging in authenticates by using the enterprise IdP with this issuer URI. Your IdP URL is displayed in the console for you to copy and paste when you create a dynamic rule or trusted profile. For example, https:\/\/w3id.sso.ibm.com\/auth\/sps\/samlidp2\/saml20. You can also view th IdP by clicking View identity provider (IdP) data. For IBMid, the IdP is the SAML \"entityId\" field, sometimes referred to as the issuer ID, and is part of the federation configuration when you are onboarding with IBMid. For AppID, equivalent syntax is the \"realm ID\".","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-condition-properties"},{"document_id":"ibmcld_11474-5244-7072","score":18.9259223938,"text":"\nOpen the App ID instance page from the [resource list](https:\/\/cloud.ibm.com\/resources) Services and software section.\n2. Go to Manage Authentication \u2192 Cloud Directory \u2192 Users, and click Create User. Enter the user details.\n\n\n\n\n\n\n\n Step 6: Create or modify users' project assignments \n\nIf the IDP administrator will assign users to projects, you can define project values in the user's attributes.\n\n\n\n1. Open the App ID instance page from the [resource list](https:\/\/cloud.ibm.com\/resources) Services and software section.\n2. Go to Manage Authentication \u2192 Cloud Directory \u2192 Users, and click a user to open it.\n3. Scroll down to Custom Attributes, and click Edit.\n4. Enter a key value pair that can will checked by the dynamic rules of the access groups, then click Save. You can add several values in the same string (for example, {\"project\":\"ml finance\"}); the contains qualifier of the dynamic rule detects a match of a substring. For our example, add:\n\n{\"project\":\"ml\"}\n\nThe value project corresponds to the convention defined in the planning section. ml is the project that the user belongs to.\n\nThis check is done on every login, so changes in the ID provider user attributes will be effective when a user next logs in.\n\n\n\n\n\n\n\n User flow \n\n\n\n1. A user is sent the ID provider URL for the IBM Cloud account.\n\nThe administrator can always go to [Manage \u2192 Access (IAM) \u2192 Identity providers](https:\/\/cloud.ibm.com\/iam\/identity-providers) to look up the ID provider URL.\n2. To work with Qiskit Runtime serive instances, users must create an API key by going to ([Manage \u2192 Access (IAM) \u2192 API keys](https:\/\/cloud.ibm.com\/iam\/apikeys)).\n3. For further information, users can review [Getting started, Step 2](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-get-startedinstall-packages).\n\n\n\n\n\n\n\n Example scenario","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-appid-org"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1934264036}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16384-7-2422","score":23.9339179993,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16365-7-1700","score":23.3031520844,"text":"\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03422-14609-15163","score":20.2651958466,"text":"\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Security measures \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has. Only serve content over HTTPS, use Content Security Policy (CSP), and implement other basic web security precautions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security"},{"document_id":"ibmcld_02855-7-2041","score":19.8278694153,"text":"\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16365-8408-10508","score":19.6782970428,"text":"\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03418-4-2127","score":19.5890674591,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Web chat overview \n\nLearn more about the web chat that you can add to your company website.\n\nWeb chat is a code snippet that you can immediately embed in your website.\n\nWhen you build a custom user interface for your assistant, you spend a lot of time and effort writing code to solve typical UI problems. For example, you must keep up with browser support changes, manage scrolling behavior, validate input, and design the layout and styling. The time you spend designing and maintaing a UI can be better spent building a quality assistant instead. When you use the web chat integration, you can rely on us to manage the user interface, so you can focus on designing conversational exchanges that address the unique business needs of your customers. Cutting-edge functionality from IBM Design and Research is incorporated into the web chat to deliver an exceptional user experience.\n\nFor more information about how to deploy the web chat, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Global audience support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basics"},{"document_id":"ibmcld_02855-20684-22621","score":19.3617553711,"text":"\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1. To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2. To change only the language of the hardcoded English phrases, use the instance.updateLanguagePack() method.\n\nFor more information, see [Instance methods](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslanguages).\n3. To change the text direction of the page from right to left, use the direction method. For more information, see [Configuration](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Securing the web chat \n\nConfigure the web chat to authenticate users and send private data from your embedded web chat.\n\nAll messages that are sent from the web chat are encrypted. When you enable security, your assistant takes an additional step to verify that messages originate from the web chat that is embedded in your website only.\n\nThe web chat uses an RSA signature with SHA-256 to encrypt communication. RS256 cryptography is a sophisticated type of RSA encryption. An RSA key pair includes a private and a public key. The RSA private key is used to generate digital signatures, and the RSA public key is used to verify digital signatures.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16295-7-1721","score":19.0389537811,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16385-7-2272","score":19.0323390961,"text":"\nOverview: Securing the web chat \n\nIf you enable security, you can configure the web chat to authenticate users, protect private data, and restrict access to your assistant.\n\nAll messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS), which protects sensitive data as it travels through the network. However, there are still potential security exposures that you might need to protect against. By enabling the web chat security feature and updating your website code appropriately, you can add the following protections:\n\n\n\n* You can prevent unauthorized websites from sending messages to your assistant, even if they copy your web chat embed script. (The unique identifiers in the embed script, such as the integration ID and service instance ID, are visible to anyone who has access to your website.)\n* You can securely authenticate customers in order to control access to features of your assistant that require authorization.\n* You can encrypt sensistive data so that customers cannot see it, while still allowing your assistant to access it.\n\n\n\nWeb chat security uses JSON Web Tokens (JWTs), which are data objects that are sent with each message from your website to the Watson Assistant service. Because a JWT is digitally signed using a private encryption key that only you have, it ensures that each message originates with your website. The JWT payload can also be used to securely authenticate users and carry encrypted private data.\n\nFor detailed information about JSON Web Tokens, see the [JWT specification](https:\/\/tools.ietf.org\/html\/rfc7519)).\n\nEnabling web chat security involves making the following customizations:\n\n\n\n* Implementing web application server code that generates a JWT signed with your private encryption key\n* Customizing the web chat configuration to provide the generated JWT\n* Enabling security in the web chat security settings\n\nAfter you enable web chat security, any message received by the web chat integration that is not accompanied by a properly signed JWT will be rejected.\n\n\n\nFor detailed information about how to complete these steps, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security"},{"document_id":"ibmcld_16375-7-1735","score":18.9097194672,"text":"\nAdding the web chat to your mobile application \n\nIf you have a mobile application built on a mobile framework such as iOS, Android, or React Native, you can use a WebView with a JavaScript bridge to communicate between your app and the Watson Assistant web chat.\n\nUsing WebViews with a JavaScript bridge is a common pattern with a similar implementation for all mobile frameworks.\n\n\n\n Including the web chat as a WebView \n\nYou can include the web chat interface as part of a page of your mobile app, or as a separate panel that your app opens. In either case, you must host an HTML page that includes the web chat embed script, and then include that page as a WebView in your app.\n\nIn the embed script, use the showLauncher option to hide the web chat launcher icon, and the openChatByDefault option to open the web chat automatically when the page loads. In most cases, you will also want to use the hideCloseButton option and use the native controls of your app to control how the web chat page or panel closes. For more information about the configuration options you can specify in the embed script, see the [Web chat API reference](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration).\n\nThe following example shows an embed script that includes these configuration options:\n\n<html>\n<head>\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n<\/head>\n<body>\n<script>\nwindow.watsonAssistantChatOptions = {\n\/\/ A UUID like '1d7e34d5-3952-4b86-90eb-7c7232b9b540' included in the embed code provided in Watson Assistant.\nintegrationID: \"YOUR_INTEGRATION_ID\",\n\/\/ Your assistants region e.g. 'us-south', 'us-east', 'jp-tok' 'au-syd', 'eu-gb', 'eu-de', etc.\nregion: \"YOUR_REGION\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-mobile"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.7122630665,"ndcg_cut_10":0.7122630665}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10596-11475-13230","score":22.199256897,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-11142-12906","score":22.0352401733,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_06160-10037-11653","score":19.3894462585,"text":"\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-9883-11854","score":18.4453964233,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-5350-7330","score":17.6182823181,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-8533-10577","score":17.3240890503,"text":"\n* Check any Calico or Kubernetes network policies that are applied to the cluster and make sure that they do not block traffic from the worker node to the cluster apiservice, container registry, or other critical services.\n\n\n\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see if the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. Check the status of your worker nodes. If they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n6. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_06160-12611-14167","score":17.0153312683,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\nkubectl describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) . Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.\n\nkubectl get mutatingwebhookconfigurations\n\nkubectl get validatingwebhookconfigurations\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_06277-1333-2534","score":16.9383125305,"text":"\nYour Flow Logs for VPC gathers information from the VPC, VPC subnet, or VPC load balancer level. However, you can use the flow logs to gather information that is specific to your worker nodes. Separate flow log files are created for ingress and egress traffic.\n\n\n\n1. In the CLI, find the ibm-cloud.kubernetes.io\/instance-id label value for the worker node.\n\nkubectl describe node <worker_node_ip> | grep instance-id\n\nExample output.\n\nibm-cloud.kubernetes.io\/instance-id=1010_a1aa1010-a1a0-1010-a1aa-aa1a1-a1-aa1\n2. In the IBM Cloud UI, click your IBM Cloud Object Storage instance in the Resource list.\n3. Click the bucket where your flow logs are collected.\n4. Download and decompress the flow log object.\n5. Open the file and navigate through the file directory until you reach directories that begin with instance-id=.\n6. Find the file directory that contains the instance ID found in the first step. The ID is included at the end of the file directory name. Example.\n\ninstance-id=crn%3AV1%...%3Ainstance%3A1010_a1aa1010-a1a0-1010-a1aa-aa1a1-a1-aa1\n7. In the instance=id= directory, locate the record-type=ingress and record-type=egress files. Your ingress and egress traffic logs are located here.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-flow-log"},{"document_id":"ibmcld_10394-7-1848","score":16.8688869476,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_10203-7710-9453","score":16.7436332703,"text":"\nFor example, to verify that the app pod deployed to a worker node on a specific VLAN, view the VLAN that the worker node is on by running ibmcloud oc worker get --cluster <cluster_name_or_ID> --worker <worker_ID>.\n4. In the output, verify that the worker node with the private IP address that you identified in the previous step is deployed in this worker pool.\n\n\n\n\n\n\n\n\n\n Deploying an app on a GPU machine \n\nIf you have a [GPU machine type](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes), you can accelerate the processing time required for compute intensive workloads such as AI, machine learning, inferencing and more.\n\nIBM Cloud VPC worker nodes with GPUs are available for allowlisted accounts only. To request that your account be allowlisted, see [Requesting access to allowlisted features](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help). Be sure to include the data centers, the VPC infrastructure profile, and the number of workers that you want use. For example 12 worker nodes in us-east-1 of VPC profile gx2-16x128xv100.\n\nIn the following steps, you learn how to deploy workloads that require the GPU. You can also deploy apps that don't need to process their workloads across both the GPU and CPU.\n\nIn the following steps, you learn how to deploy workloads that require the GPU. You can also deploy apps that don't need to process their workloads across both the GPU and CPU. After, you might find it useful to play around with mathematically intensive workloads such as the [TensorFlow](https:\/\/www.tensorflow.org\/) machine learning framework with [this Kubernetes demo](https:\/\/github.com\/pachyderm\/pachyderm\/tree\/master\/examples\/ml\/tensorflow).\n\nBefore you begin","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10394-7-1848","score":28.4354839325,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_05891-121193-123094","score":25.3833007812,"text":"\nClassic infrastructure\n\nUpdate worker nodes to apply the latest security updates and patches to the operating system, and to update the Kubernetes version to match the version of the Kubernetes master. You can update the master Kubernetes version with the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). Remember that your worker nodes can be only up to two versions behind the master version (n-2). The worker node IP address remains the same after the update operation.\n\nTo update a worker node in a VPC cluster, use the [ibmcloud ks worker replace command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clicli_worker_replace) instead.\n\nRunning ibmcloud ks worker update can cause downtime for your apps and services. During the update, all pods are rescheduled onto other worker nodes, the worker node is reimaged, and data is deleted if not stored outside the pod. To avoid downtime, [ensure that you have enough worker nodes to handle your workload while the selected worker nodes are updating](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\nYou might need to change your YAML files for deployments before you update. Review this [release note](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) for details.\n\nibmcloud ks worker update --cluster CLUSTER --worker WORKER_ID [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster where you list available worker nodes.\n\n-w, --worker WORKER","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_10642-16753-18268","score":25.2855110168,"text":"\nOptional: Verify the events that are triggered by the config map and any validation errors that occur. The events can be reviewed in the Events section of your CLI output.\n\noc describe -n kube-system cm ibm-cluster-update-configuration\n9. Confirm that the update is complete by reviewing the Kubernetes version of your worker nodes.\n\noc get nodes\n10. Verify that you don't have duplicate worker nodes. Sometimes, older clusters might list duplicate worker nodes with a NotReady status after an update. To remove duplicates, see [troubleshooting](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_duplicate_nodes).\n\n\n\nNext steps:\n\n\n\n* Repeat the update process with other worker pools.\n* Inform developers who work in the cluster to update their oc CLI to the version of the Kubernetes master.\n* If the Kubernetes dashboard does not display utilization graphs, [delete the kube-dashboard pod](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_dashboard_graphs).\n\n\n\n\n\n\n\n Updating classic worker nodes in the console \n\nAfter you set up the config map for the first time, you can then update worker nodes by using the IBM Cloud console.\n\nTo update worker nodes from the console:\n\n\n\n1. Complete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker-up-prereqs) and [set up a config map](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) to control how your worker nodes are updated.\n2. From the [IBM Cloud console](https:\/\/cloud.ibm.com\/) menu !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-19911-21816","score":24.8941059113,"text":"\nAs security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_updateportworx_vpc_up).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud ks worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the VPC worker node to the same patch by using the ibmcloud ks worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_06209-8154-10055","score":24.8495426178,"text":"\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_05602-31736-32765","score":24.3666973114,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.23.15_1556\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages N\/A N\/A N\/A \n Ubuntu 20.04 packages N\/A N\/A N\/A \n Kubernetes N\/A N\/A N\/A \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.23.15_1556, released 19 December 2022 \n\nThe following table shows the changes that are in the worker node fix pack 1.23.15_1556. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.23.14_1554\n\n Component Previous Current Description \n\n Containerd 1.6.10 1.6.12 See the [1.6.12 change log](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.6.12), the [1.6.11 change log](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.6.11), and the security bulletin for [CVE-2022-23471](https:\/\/www.ibm.com\/support\/pages\/node\/6850799).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_123"},{"document_id":"ibmcld_05603-45298-46323","score":24.3641242981,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.24.9_1548\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages N\/A N\/A N\/A \n Ubuntu 20.04 packages N\/A N\/A N\/A \n Kubernetes N\/A N\/A N\/A \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.24.9_1548, released 19 December 2022 \n\nThe following table shows the changes that are in the worker node fix pack 1.24.9_1548. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.24.8_1546\n\n Component Previous Current Description \n\n Containerd 1.6.10 1.6.12 See the [1.6.12 change log](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.6.12), the [1.6.11 change log](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.6.11), and the security bulletin for [CVE-2022-23471](https:\/\/www.ibm.com\/support\/pages\/node\/6850799).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_124"},{"document_id":"ibmcld_06209-18717-20364","score":24.3625545502,"text":"\nComplete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker-up-prereqs) and [set up a config map](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) to control how your worker nodes are updated.\n2. From the [IBM Cloud console](https:\/\/cloud.ibm.com\/) menu ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg), click Kubernetes.\n3. From the Clusters page, click your cluster.\n4. From the Worker Nodes tab, select the checkbox for each worker node that you want to update. An action bar is displayed over the table header row.\n5. From the action bar, click Update.\n\n\n\nIf you have Portworx installed in your cluster, you must restart the Portworx pods on updated worker nodes. For more information, see [Portworx limitations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_planportworx_limitations).\n\n\n\n\n\n\n\n Updating VPC worker nodes \n\nYou notice that an update is available for your worker nodes in a [VPC infrastructure cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers). What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_05604-45054-46079","score":24.3409557343,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.25.5_1526\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages N\/A N\/A N\/A \n Ubuntu 20.04 packages N\/A N\/A N\/A \n Kubernetes N\/A N\/A N\/A \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.25.5_1526, released 19 December 2022 \n\nThe following table shows the changes that are in the worker node fix pack 1.25.5_1526. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.25.4_1524\n\n Component Previous Current Description \n\n Containerd 1.6.10 1.6.12 See the [1.6.12 change log](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.6.12), the [1.6.11 change log](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.6.11), and the security bulletin for [CVE-2022-23471](https:\/\/www.ibm.com\/support\/pages\/node\/6850799).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_125"},{"document_id":"ibmcld_10673-11610-12993","score":24.2757854462,"text":"\nf8b95e43-a408-4dc8-a489-ed649fc4cfec pgw-18a3ebb0-b539-11e9-9838-f3f4efa02374 available 169.XX.XXX.XX prod us-south-1\n2ba9a280-fffa-4b0c-bdca-7970f09f9b8a pgw-73b62bc0-b53a-11e9-9838-f3f4efa02374 available 169.XX.XXX.XX prod us-south-2\n057ddef6-631f-4b22-89eb-1e99982a54fa pgw-64c5cae0-0be2-11ea-8f26-e1565e79a36c available 52.XX.XXX.XXX prod us-south-3\n4. Add the public gateway IP addresses to your service's allowlist or your on-premises allowlist for inbound traffic.\n5. Repeat these steps for each cluster that you want to allow traffic to or from.\n\n\n\n\n\n\n\n Allowing egress to a cluster from another service \n\nTo permit egress to your cluster from another service, modify that service's allowlist or your on-premises allowlist.\n\n\n\n1. Get the worker node subnets or the worker node IP addresses.\n\n\n\n* Worker node subnet CIDRs: If you anticipate changing the number of worker nodes in your cluster frequently, such as if you enable the [cluster autoscaler](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-scaling-classic-vpc), you might not want to update your allowlist for each new worker node. Instead, you can add the VPC subnets that the cluster uses. Keep in mind that the VPC subnet might be shared by worker nodes in other clusters.\n\n\n\n1. Get the Worker Zones and VPCs that your cluster is created in.\n\nibmcloud oc cluster get -c <cluster>\n\nExample output\n\n...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-firewall"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10642-7855-9754","score":28.6169452667,"text":"\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.\n\nIn addition, you can create a Kubernetes config map that specifies the maximum number of worker nodes that can be unavailable at a time, such as during an update. Worker nodes are identified by the worker node labels. You can use IBM-provided labels or custom labels that you added to the worker node.\n\nThe Kubernetes config map rules are used for updating worker nodes only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-8154-10055","score":27.0276508331,"text":"\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10642-6354-8294","score":27.0230751038,"text":"\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10394-7-1848","score":26.924577713,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_06209-6757-8643","score":25.9943294525,"text":"\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_06209-19911-21816","score":25.2164669037,"text":"\nAs security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_updateportworx_vpc_up).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud ks worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the VPC worker node to the same patch by using the ibmcloud ks worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10395-7-1827","score":22.5899562836,"text":"\nUpdating VPC worker nodes that use OpenShift Data Foundation \n\nVirtual Private Cloud\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc"},{"document_id":"ibmcld_10290-113594-115347","score":22.4642734528,"text":"\nibmcloud oc worker reload --cluster my_cluster -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1 -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w2\n\n\n\n\n\n\n\n ibmcloud oc worker replace \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nDelete a worker node and replace it with a new worker node in the same worker pool.\n\nThe replacement worker node is created in the same zone and has the same flavor as the old worker node, but might be assigned new public or private IP addresses. You might replace a worker node if you can't reload or update the worker node, such as if it enters a troubled state.\n\nYou can also use this command to update the Kubernetes version of the worker node to match the major and minor version of the Kubernetes master by including the --update option. If you don't include the --update option, patch version updates are applied to your worker node, but not major or minor updates. To see the changes from one major, minor, or patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) documentation. Remember that your worker nodes can be only up to two versions behind the master version (n-2).\n\nWhen you replace a worker node, keep in mind the following considerations.\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Multiple worker nodes are replaced concurrently: If you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_10642-20176-22071","score":22.4161720276,"text":"\nFor more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud oc worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the VPC worker node to the same patch by using the ibmcloud oc worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload, such as by [resizing your worker pools](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersresize_pool).\n\nWhat happens to my worker node during an update?\n: Your VPC worker node is replaced by removing the old worker node and provisioning a new worker node that runs at the updated patch or major.minor version. The replacement worker node is created in the same zone, same worker pool, and with the same flavor as the deleted worker node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_05891-114821-116448","score":22.2700443268,"text":"\nibmcloud ks worker reload --cluster CLUSTER --worker WORKER_ID [--skip-master-healthcheck] [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-w, --worker WORKER\n: Specify a worker node ID. To reload multiple worker nodes, use multiple options, such as -w worker1_id -w worker2_id.\n\n--skip-master-healthcheck\n: Skip a health check of your master before reloading or rebooting your worker nodes.\n\n-f\n: Optional: Force the command to run with no user prompts.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example worker reload command \n\nibmcloud ks worker reload --cluster my_cluster -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1 -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w2\n\n\n\n\n\n\n\n ibmcloud ks worker replace \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nDelete a worker node and replace it with a new worker node in the same worker pool.\n\nThe replacement worker node is created in the same zone and has the same flavor as the old worker node, but might be assigned new public or private IP addresses. You might replace a worker node if you can't reload or update the worker node, such as if it enters a troubled state.\n\nYou can also use this command to update the Kubernetes version of the worker node to match the major and minor version of the Kubernetes master by including the --update option. If you don't include the --update option, patch version updates are applied to your worker node, but not major or minor updates.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.703918089,"ndcg_cut_10":0.703918089}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09410-3448-5457","score":15.0943508148,"text":"\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.\n* [hash] represents the digest (manifest) of the container image. It is a unique SHA-256 hash.\n\n\n\nThe following table outlines the tagging convention adopted and the agent update behavior:\n\n\n\nTable 1. logging agent tags explained\n\n Tag Logging agent auto-update enabled More info \n\n X YES The logging agent auto-updates when a new minor version releases. <br>The logging agent does not update to a new major version, as these updates may require configuration changes. \n X.Y YES The logging agent auto-updates when a new patch version is released. \n X.Y.Z YES The logging agent auto-updates when a new vulnerability fix is released. The agent code does not change, but the included libraries have vulnerability fixes. \n X.Y.Z-<date>.[hash] NO The logging agent never updates. If you use this tag, make sure you are watching for new agent releases that have vulnerability fixes. \n\n\n\nDepending on the tag that you use, you must consider upgrading the logging agent image in your DevOps maintenance plan, to resolve vulnerabilities and apply agent enhancements and agent bug fixes. For example:\n\n\n\n* In a development environment, you can use a tag X and let auto-updates happen as new minor versions are released.\n* In a staging environment, you might consider using a tag X.Y so auto-updates happen when a new patch is released.\n* In a production environment, you can use the tag X.Y.Z so that auto-updates happen when a new vulnerability fix is released.\n* For highly regulated environments, you should use the tag X.Y.Z-<date>.[hash]. Notice that you will have to check periodically for vulnerability fixes, patches, and minor version releases to keep the agent free of issues.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_16471-73103-74976","score":14.3091144562,"text":"\n* [and mapping from <mapping table name>]\n\nSpecifies the name of an AQL table that maps raw part-of-speech tags such as \"NOUN\" to combinations of high-level parts of speech and flags. While the optional mapping table can have variable names, a part-of-speech mapping table is required to have these column names:\n\n\n\n* tag\n\nThe column that holds a Multilingual tokenizer part-of-speech tag.\n* basetag\n\nThe column that holds the corresponding internal tag.\n* flagstr\n\nThe column that holds a comma-delimited list of flags that are associated with the indicated part of speech.\n\n\n\nThe mapping table must be defined by using the create table statement in the same module as the extract part_of_speech statement that uses it. It cannot be an imported table, and it cannot be an external table.\n\ncreate table POSMapping_EN(tag Text, basetag Text, flagstr Text)\nas values\n('CCONJ','CONJ','coordinating'),\n('SCONJ','CONJ','subordinating');\n* <input column>\n\nSpecifies the column of the input view from which to extract part-of-speech information.\n* <output column>\n\nSpecifies the name of the column where the spans of the tokens with the indicated parts of speech are sent.\n* <input view>\n\nSpecifies the input view from which to extract part-of-speech information.\n\n\n\n\n\n\n\n Usage notes \n\n\n\n* Part of speech extraction works only when is using the Multilingual tokenizer. If the system uses the Standard tokenizer, a part_of_speech extraction generates an error.\n\n\n\n\n\n\n\n Parts of speech tags for languages \n\nFor all supported languages, the Multilingual tokenizer uses the part-of-speech tags that are listed in the following table.\n\n\n\n Tag Descriptions \n\n ADJ adjective \n ADP adposition \n ADV adverb \n AUX auxiliary \n CCONJ coordinating conjunction \n DET determiner \n INTJ interjection \n NOUN noun \n NUM numeral \n PART particle \n PRON pronoun \n PROPN proper noun \n PUNCT punctuation","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_16471-71623-73502","score":13.2119312286,"text":"\non CW.word as capswords\nfrom CapitalizedWords CW;\n\nExample 2: Extract blocks of words within a token range\n\nThe following code identifies blocks of exactly two capitalized words within five tokens of each other.\n\ncreate view TwoCapitalizedWords as\nextract blocks\nwith count 2\nand separation between 0 and 5 tokens\non CW.word as capswords\nfrom CapitalizedWords CW;\n\n\n\n\n\n\n\n Part of speech \n\nUse the part-of-speech extraction specification to identify locations of different parts of speech across the input text.\n\n\n\n Syntax \n\npart_of_speech\n'<part of speech spec>'\n[and '<part of speech spec>']\n[with language '<language code>']\n[and mapping from <mapping table name>]\non <input column> as <output column>\nfrom <input view>\n\n\n\n\n\n Description \n\n\n\n* '<part of speech spec>'\n\nIdentifies the parts of speech to extract from the input text. The '<part of speech spec>' is one of the following strings:\n\n\n\n* A string that contains a comma-delimited list of part-of-speech tags that are generated by the Multilingual tokenizer\n* A combination of an internal part-of-speech name and flags, as defined by a mapping table\n\n\n\n* [and '<part of speech spec>']\n\nIdentifies the additional parts of speech tags for extraction.\n* [with language '<language code>']\n\nSpecifies the language to be used in the extraction. The <language code> is a two-letter, lowercase language code, such as 'en' or 'ja'. If this argument is omitted, the language for part-of-speech extraction is assumed to be English\n* [and mapping from <mapping table name>]\n\nSpecifies the name of an AQL table that maps raw part-of-speech tags such as \"NOUN\" to combinations of high-level parts of speech and flags. While the optional mapping table can have variable names, a part-of-speech mapping table is required to have these column names:\n\n\n\n* tag\n\nThe column that holds a Multilingual tokenizer part-of-speech tag.\n* basetag","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_16471-74601-76664","score":12.402425766,"text":"\nFor all supported languages, the Multilingual tokenizer uses the part-of-speech tags that are listed in the following table.\n\n\n\n Tag Descriptions \n\n ADJ adjective \n ADP adposition \n ADV adverb \n AUX auxiliary \n CCONJ coordinating conjunction \n DET determiner \n INTJ interjection \n NOUN noun \n NUM numeral \n PART particle \n PRON pronoun \n PROPN proper noun \n PUNCT punctuation \n SCONJ subordinating conjunction \n SYM symbol \n VERB verb \n X other \n\n\n\n\n\n\n\n Examples \n\nExample 1: Using a part of speech tag directly in an extract statement\n\nThe view EnglishNoun extracts English nouns (singular or mass) or proper nouns (singular).\n\ncreate view EnglishNoun\nas extract parts_of_speech 'NOUN' and 'PROPN'\nwith language 'en' on D.text\nas noun from Document D;\n\n\n\n\n\n\n\n Sequence patterns \n\nUse the pattern extraction specification to perform pattern matching across an input document and other spans extracted from the input document.\n\n\n\n Syntax \n\nThe general syntax of a sequence pattern is to first specify the pattern to be matched in the text, and then to specify what is to be returned by the extractor. The final part of the sequence pattern specifies what is the input to the pattern; it might be a column from a previously defined view, or it might be the entire document text.\n\npattern <pattern specification> [return clause] [with inline_match on <viewname.colname>]\n\n\n\n\n\n Description \n\n\n\n* <pattern specification>\n\nA <pattern specification> is composed of multiple Atoms. An individual Atom can be a column from an already-defined view, a fixed string, or a regular expression. You can specify your Atoms to be optional and repeating, and specify token gaps between Atoms.\n\nThe pattern specification is part of a larger AQL statement, which includes an extract clause.\n\nHere is a simple example of how to create a view that contains three adjacent matches from earlier defined views. In this example, the entire combination is returned, which is what group 0 refers to:\n\ncreate view Money as\nextract pattern <C.match> <N.match> <Q.match>\nreturn group 0 as match","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_05256-31524-33025","score":12.0016832352,"text":"\n--__.. 0-128 (NOT start with periodOrDash) \n IMAGEID a-z 0-9 : (startwith sha256: noOtherColon) \n\n\n\nThe parts of the image name must meet the following criteria.\n\n\n\n* REGISTRY must be 253 characters or fewer and can contain lowercase or uppercase letters, numbers, periods (.), hyphens (-), and underscores (_). Do not use a dash (.) as the last character. Do not use more than 127 periods (.) and the labels between them can be between 1 and 63 characters long.\n* NAMESPACE must be between 4 and 30 characters and must begin and end with a lowercase letter or number. NAMESPACE can contain lowercase alphanumeric characters, hyphens (-), and underscores (_).\n* DOCKERUSERorDOCKERORG can be used for Docker registries instead of NAMESPACE. Specify your Docker username or Docker organization. Your Docker username and organization must be between 4 and 30 characters and contains only lowercase alphanumeric characters or numbers.\n* REPOSITORY must be between 2 and 255 characters and must begin and end with a lowercase letter or number. REPOSITORY can contain lowercase alphanumeric characters, forward slashes (\/), periods (.), hyphens (-), and underscores (_).\n* TAG must be between 0 and 128 characters and can contain lowercase or uppercase letters, numbers, periods (.), hyphens (-), and underscores (_). The TAG must not begin with a period or dash. If you do not include a TAG, do not include the colon either.\n* IMAGEID is prefixed with sha256: and can contain lowercase letters and numbers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registry"},{"document_id":"ibmcld_02237-4-2121","score":11.6886692047,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Working with tags \n\nUse tags to organize, track usage costs, and even manage access to your resources and service IDs. You can tag related resources and view them throughout your account by filtering by tags from your resource list.\n\nTo see a full list of tags in your account, go to Manage > Account in the IBM Cloud\u00ae console, and select Tags.\n\nYou can apply user tags to organize your resources and service IDs and easily find them later. User tags can also help you with identifying specific team usage or cost allocation. By creating access management tags, you can control access to your resources and service IDs without requiring updates to your IAM policies.\n\n\n\n Tagging rules \n\nTags are not case-sensitive, and the maximum length of a tag is 128 characters. The permitted characters are A-Z, 0-9, spaces, underscore, hyphen, period, and colon. The only supported format for access management tags is key:value. The use of a colon formats the tag into a string that isolates two logical parts, like a env:dev pair. A comma separates multiple tags and can't be used within the tag name itself.\n\nTags are visible account-wide and can be replicated across geographic regions. Since tags are not regulated information, avoid creating tags that use personal information, such as your name, address, phone number, email address, or other identifying or proprietary information.\n\n\n\n Sample tags and syntax \n\nYou can apply tags to help you organize and manage your resources, service IDs, and access policies. Consider writing tags as key:value pairs to help coordinate your development environments, projects, compliance, and optimization throughout your organization. See the following table for some examples of tags that you might want to use.\n\n\n\nTable 1. Tag syntax\n\n Tag Description \n\n env:dev, env:test, env:stage, env:prod Use to identify or even manage access to your development environment \n project:lw-wizard, app:poc-app Use to identify or even manage access to a project \n dataresidency:germany, compliance:hipaa, compliance:pii Use to define compliance requirements","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-tag&interface=ui"},{"document_id":"ibmcld_02361-12527-14703","score":11.2024860382,"text":"\n* Colons turn the tag into a string where you can isolate two logical parts, like a key:value pair. You can't use a colon in a tag without creating this pairing.\n* A comma separates tags and can't be used within the tag name itself.\n\n\n\nIf you add PII information in the name, you might be disclosing sensitive data to others in the same account.\n\nWhen you define your tags, do not add sensitive information in the tag name.\n\nTags are visible to all members of an account.\n\nTo control tag visibility, circulate tagging guidelines, and let users know that tags are visible account-wide.\n\n\n\n\n\n\n\n Define the IAM strategy \n\nUse IBM Cloud\u00ae Identity and Access Management (IAM) to securely authenticate users and service IDs, and to control access to all cloud resources and data consistently in the IBM Cloud.\n\nIf you add PII information in the name or description of IAM resources, you might be disclosing sensitive data to others in the same account.\n\nWhen you define your IAM resources, do not add sensitive information in their names and descriptions.\n\n\n\n Access groups \n\nYou can assign permissions to work with the IBM Cloud Activity Tracker service within the context of the service, a resource group, or an access group.\n\nUse access groups to organize a set of users and service IDs into a single entity that makes it easy for you to manage IAM permissions.\n\nYou can create multiple access groups.\n\nDefine a minimum of 4 access groups:\n\n\n\nTable 2. List of access groups\n\n Access group Description \n\n Administrators Users in this group should have permissions to fully manage the service and grant other users in the account permissions to work with the service in the IBM Cloud. \n Managers Users in this group should have permissions to fully manage the service in the IBM Cloud. \n Advanced service users Users in this group should have permissions to run advanced service tasks. \n Users Users in this group should have permissions to run basic tasks. \n\n\n\n\n\n\n\n Policies \n\nA policy determines the full set of actions that a user or service ID can perform.\n\nFor each access group, define a policy for each resource group that defines the level of access to that resource group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_01603-4-2403","score":11.1920852661,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Granting users access to tag resources and service IDs \n\nAs the account owner, you might want to delegate some of the responsibility of tagging resources and service IDs. For users to attach tags to a resource or service ID, you must grant them the appropriate access. Use IBM Cloud\u00ae Identity and Access Management (IAM) access policies to grant users access to resources in a resource group.\n\nTags are visible account-wide and can be replicated across geographic regions. Since tags are not regulated information, avoid creating tags that use personal information, such as your name, address, phone number, email address, or other identifying or proprietary information.\n\n\n\n Tagging permissions \n\nAny user in an account can view tags. When a resource is tagged, all users that have read access to the resource can view the tag. To attach or detach a tag on a resource or service ID, certain access roles or permissions are needed depending on the resource type and tag type. See the following table to understand what role is needed for each resource type.\n\n\n\nTable 1. Required roles for attaching and detaching tags\nThis is a simple data table.\n\n Resource Type Role \n\n IAM-enabled To attach or detach user tags, editor or administrator on the resource <br>To attach or detach access management tags, administrator on the resource <br>To view the assigned policies on the resource that has an access management tag that is attached, viewer role \n Bare metal on classic infrastructure View hardware details and access to a specific set of services or all bare metal servers \n Dedicated Hosts on classic infrastructure View virtual dedicated host details and access to a specific set of services or all dedicated hosts \n Virtual Server on classic infrastructure View virtual server details and access to a specific set of services or all virtual servers \n Cloud Object Storage S3 on classic infrastructure Storage manage permission \n File Storage on classic infrastructure Storage manage permission \n Evault backup on classic infrastructure Storage manage permission \n Content Delivery Network on classic infrastructure Manage CDN account permission \n Direct Link on classic infrastructure Account member \n Hardware Firewall Manage Firewalls \n FortiGate Security Appliance Manage Firewalls \n IBM Cloud Load Balancer Manage Load Balancers \n Gateway Appliance Manage Network Gateways","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-access"},{"document_id":"ibmcld_01608-4-2403","score":11.1920852661,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Granting users access to tag resources and service IDs \n\nAs the account owner, you might want to delegate some of the responsibility of tagging resources and service IDs. For users to attach tags to a resource or service ID, you must grant them the appropriate access. Use IBM Cloud\u00ae Identity and Access Management (IAM) access policies to grant users access to resources in a resource group.\n\nTags are visible account-wide and can be replicated across geographic regions. Since tags are not regulated information, avoid creating tags that use personal information, such as your name, address, phone number, email address, or other identifying or proprietary information.\n\n\n\n Tagging permissions \n\nAny user in an account can view tags. When a resource is tagged, all users that have read access to the resource can view the tag. To attach or detach a tag on a resource or service ID, certain access roles or permissions are needed depending on the resource type and tag type. See the following table to understand what role is needed for each resource type.\n\n\n\nTable 1. Required roles for attaching and detaching tags\nThis is a simple data table.\n\n Resource Type Role \n\n IAM-enabled To attach or detach user tags, editor or administrator on the resource <br>To attach or detach access management tags, administrator on the resource <br>To view the assigned policies on the resource that has an access management tag that is attached, viewer role \n Bare metal on classic infrastructure View hardware details and access to a specific set of services or all bare metal servers \n Dedicated Hosts on classic infrastructure View virtual dedicated host details and access to a specific set of services or all dedicated hosts \n Virtual Server on classic infrastructure View virtual server details and access to a specific set of services or all virtual servers \n Cloud Object Storage S3 on classic infrastructure Storage manage permission \n File Storage on classic infrastructure Storage manage permission \n Evault backup on classic infrastructure Storage manage permission \n Content Delivery Network on classic infrastructure Manage CDN account permission \n Direct Link on classic infrastructure Account member \n Hardware Firewall Manage Firewalls \n FortiGate Security Appliance Manage Firewalls \n IBM Cloud Load Balancer Manage Load Balancers \n Gateway Appliance Manage Network Gateways","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-access&interface=api"},{"document_id":"ibmcld_01617-7-2160","score":11.0585403442,"text":"\nControlling access to resources by using tags \n\nThis tutorial guides you through the steps to centrally manage access to the resources in your account at scale. By completing this tutorial, you learn how to create an access management tag, add the tag to selected resources, and define a policy to assign access to resources based on the tags on those resources.\n\nAccess management tags are metadata that are added to resources to help organize access control relationships. They create flexible and easy to administer resource groupings. When you use tags to control access to your resources, your team's projects can grow without requiring updates to IAM policies.\n\nLet's assume you are the lead of a project for your team that needs an IBM Cloud\u00ae Object Storage instance for storing sensitive, project-specific data for analytics. You only want the members of this project to have access to the service instance and work with the project data.\n\nThis tutorial applies to IAM-enabled resources only. You need to have an administrator role on the tagging service to create and delete access management tags. To attach and detach access management tags, you need at least an administrator role on the resources to which the tag is added.\n\n\n\n Before you begin \n\nIf you are new to using IAM, check out the following resources to learn more about the features, concepts, and components of the access management system:\n\n\n\n* See [What is IBM Cloud Identity and Access Management?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamoverview) for an overview of the service.\n* See [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles) for a description of how access management works by using access policies.\n* Watch the video about [controlling access by using tags in IBM Cloud](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account_setuptwo-teams-projects) for an overview of how to use access management tags.\n\n\n\n\n\n\n\n Step 1: Create an access management tag \n\nBefore you can add an access management tag to your Object Storage, you need to create it first.\n\n\n\n1. Go to Manage > Account in the IBM Cloud console, and select Tags.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-access-tags-tutorial"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.5294362295}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06160-11142-12906","score":21.2019710541,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-11475-13230","score":20.9834499359,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_03970-6841-9069","score":19.8037414551,"text":"\nIf you import a bulk data transfer of nodes and do not also import identities, you will have to perform the separate step of associating identities with the nodes. There are a few ways to procure an identity that can operate a node. For more information about, see [Gathering certificates or credentials](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-import-nodesibp-console-import-start-here). Regardless of the process used to acquire the identity, after the bulk import has been completed you will need to click on each imported node. For peers and ordering nodes, a box on the left of the screen will say Identity not associated with (peer or ordering node), depending on the node in question. After clicking on this box, you will be able to associate the relevant identity by selecting it from your Wallet. Note that this process is distinctly different than the process for importing individual nodes, where you will be asked to associate an identity as part of the import process.\n\nYou will also need to associate an admin identity for the CA. This process is similar to the peer and ordering node process except that after you click on the imported CA you will see a separate screen asking you to associate an identity rather than a box on the left.\n\nFor cases where bulk data transfers are impractical or inadvisable, you can follow the steps below to export and import components and identities one at a time.\n\n\n\n\n\n Gathering certificates or credentials \n\nBecause identities contain private keys, be careful when exporting them to ensure they are handled securely. If a private key is compromised, it can be used to perform malicious actions.\n\nEach IBM Blockchain Platform component is deployed with the signing certificate of an administrator inside. When actions requiring the permission level of an admin are performed against the component, the signing certificate of the entity attempting the action is checked against the signing certificate inside the node. If they don't match, the action is denied. In this way, these certificates, which are also known as \"keys\", allow the administrator to operate their components.\n\nIf you intend to operate an imported node, you have two options:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-import-nodes"},{"document_id":"ibmcld_03071-3000-4820","score":18.4279327393,"text":"\nYou have successfully enabled the @sys-date, @sys-time, and @sys-number system entities. Now you can use them in your dialog.\n\n\n\n\n\n Step 3: Add a dialog node with slots \n\nA dialog node represents the start of a thread of dialog between your assistant and the user. It contains a condition that must be met for the node to be processed by your assistant. At a minimum, it also contains a response. For example, a node condition might look for the hello intent in user input, and respond with, Hi. How can I help you? This example is the simplest form of a dialog node, one that contains a single condition and a single response. You can define complex dialogs by adding conditional responses to a single node, adding child nodes that prolong the exchange with the user, and much more. (If you want to learn more about complex dialogs, you can complete the [Building a complex dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial) tutorial.)\n\nThe node that you will add in this step is one that contains slots. Slots provide a structured format through which you can ask for and save multiple pieces of information from a user within a single node. They are most useful when you have a specific task in mind and need key pieces of information from the user before you can perform it. See [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots) for more information.\n\nThe node you add will collect the information required to make a reservation at a restaurant.\n\n\n\n1. Click the Dialogs tab to open the dialog tree.\n2. Click the More icon ![More options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) on the #General_Greetings node, and then select Add node below.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots"},{"document_id":"ibmcld_06160-10037-11653","score":17.2756919861,"text":"\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-9883-11854","score":16.5573348999,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-5350-7330","score":16.4957389832,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_02882-1568-3546","score":16.3082866669,"text":"\nFor example, if you add open_account here, it means that you want the response that you will specify in this node to be returned to the user if the user input indicates that the user wants to open an account.\n\nAs you begin to define a condition, a box is displayed that shows you your options. You can enter one of the following characters, and then pick a value from the list of options that is displayed.\n\n\n\nCondition builder syntax\n\n Character Lists defined values for these artifact types \n\n `#` intents \n `@` entities \n `@{entity-name}:` {entity-name} values \n `$` context-variables that you defined or referenced elsewhere in the dialog \n\n\n\nYou can create a new intent, entity, entity value, or context variable by defining a new condition that uses it. If you create an artifact this way, be sure to go back and complete any other steps that are necessary for the artifact to be created completely, such as defining sample utterances for an intent.\n\nTo define a node that triggers based on more than one condition, enter one condition, and then click the plus sign (+) icon next to it. If you want to apply an OR operator to the multiple conditions instead of AND, click the and that is displayed between the fields to change the operator type. AND operations are executed before OR operations, but you can change the order by using parentheses. For example: $isMember:true AND ($memberlevel:silver OR $memberlevel:gold)\n\nThe condition you define must be less than 2,048 characters in length.\n\nFor more information about how to test for values in conditions, see [Conditions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-conditions).\n4. Optional: If you want to collect multiple pieces of information from the user in this node, then click Customize and enable Slots. See [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots) for more details.\n5. Enter a response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_10596-12943-14509","score":16.2363834381,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\noc describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) and the [Openshift Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool). Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-12611-14167","score":16.2277927399,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\nkubectl describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) . Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.\n\nkubectl get mutatingwebhookconfigurations\n\nkubectl get validatingwebhookconfigurations\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06320-2897-4555","score":22.7032375336,"text":"\n[NodeSync](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs. Traditional repairs are unnecessary, as the automation ensures that NodeSync handles the repairs for you.\n\nWhile the automation enables NodeSync, you can also manually create tables with NodeSync enabled so that the service can repair the tables' data when necessary:\n\nCREATE TABLE myTable (...) WITH nodesync = { 'enabled': 'true'};\n\nFor more information, see [enabling the NodeSync service](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/enablingNodesync.html).\n\nNodetool is unsupported. Manual repairs that are issued against any table that is enabled with the NodeSync service [are ignored](https:\/\/docs.datastax.com\/en\/opscenter\/6.5\/opsc\/online_help\/services\/opscNodeSyncService.htmlNodeSyncServiceversusRepairService). See error:\n\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https:\/\/github.com\/nosqlbench\/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_10858-7-1759","score":16.1761837006,"text":"\nNode.js action is failing \n\n What\u2019s happening \n\nA Node.js action does not seem to run to completion reliably.\n\n Why it\u2019s happening \n\nIf your Node.js action involves asynchronous calls to other services, your code might return from the main() function prematurely, which causes the action runtime to be stopped before your action is completed.\n\n How to fix it \n\nThe main() function of a Node.js action is a synchronous function, which expects your action to be complete when you return from the main() function. In case you are using asynchronous calls, for example, when fetching data from Cloud Object Storage or Cloudant instances, it is unpredictable as to when the main() function fully completes its work. To ensure that the action runs to completion, use a Promise. A Promise in Node.js is a stand-in for an object. Using a promise allows you to return the object from a synchronous function immediately, but the actual result becomes available at a later point in time, when the promise is fulfilled.\n\nThe IBM Cloud\u00ae Functions Node.js runtime container supports promises that are returned from the main() function. If you prefer working in a more synchronous fashion, you can also declare your main() function as an async function, which allows you to wait for asynchronous calls to complete before the function continues.\n\nExamples:\n\nfunction main() {\nreturn new Promise((resolve, reject) => {\n...doGet(callback => {\nresolve(); \/\/ <-- this terminates action execution, as the Promise got resolved\n});\n...\ntry {\n...some synchronous code...\n} catch(e) {\n...log error...\nreject(e); \/\/ <-- this also terminates the execution, but reports the failure back to the runtime\n}\n});\n}\n\nasync function main() {\n...some synchronous code...\nawait doGet(....)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-ts_action_nodejs_fails"},{"document_id":"ibmcld_06320-4083-5561","score":15.0554008484,"text":"\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https:\/\/github.com\/nosqlbench\/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration. For more information, see [DSBULK documentation](https:\/\/docs.datastax.com\/en\/dsbulk\/doc\/dsbulk\/reference\/dsbulkCmd.html).\n\n\n\n\n\n\n\n Resource configurations \n\n\n\n* The recommended configuration for a node is:\n\n\n\n* 16 CPUs\n* 32 GB to 64 GB RAM\n* 16 K disk IOPS (16 k IOPS == 1.6 TB disk)\n\n\n\n\n\n\n\n\n\n\n\n Next steps \n\nDetailed information on CQL, the Cassandra Query Language, can be found by consulting [CQL for DSE Documentation](https:\/\/docs.datastax.com\/en\/dse\/6.0\/cql\/).\n\nLooking to administer your deployment? Consult DataStax's documentation on using the [stand-alone CQLSH client](https:\/\/docs.datastax.com\/en\/astra\/docs\/connecting-to-databases-using-standalone-cqlsh.html).\n\nYou can manage your deployment with [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli), the [Cloud Databases CLI plug-in](https:\/\/cloud.ibm.com\/docs\/databases-cli-plugin?topic=databases-cli-plugin-cdb-reference), or by using the [Cloud Databases API](https:\/\/cloud.ibm.com\/apidocs\/cloud-databases-api).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_10841-18745-20127","score":14.3066129684,"text":"\n[winston](https:\/\/www.npmjs.com\/package\/winston) A multi-transport async logging library for Node.js. \"CHILL WINSTON! ... I put it in the logs. \n [ws](https:\/\/www.npmjs.com\/package\/ws) ws is a simple to use, blazing fast, and thoroughly tested WebSocket client and server implementation. \n [xlsx](https:\/\/www.npmjs.com\/package\/xlsx) Parser and writer for various spreadsheet formats. \n [xml2js](https:\/\/www.npmjs.com\/package\/xml2js) Simple XML to JavaScript object converter. It supports bidirectional conversion. \n [xmlhttprequest](https:\/\/www.npmjs.com\/package\/xmlhttprequest) node-XMLHttpRequest is a wrapper for the built-in HTTP client to emulate the browser XMLHttpRequest object. \n [yauzl](https:\/\/www.npmjs.com\/package\/yauzl) Yet another extract library for node. For zipping. \n [yazl](https:\/\/www.npmjs.com\/package\/yauzl) Yet another extract library for node. For zipping. \n\n\n\nFor more information about Node.js 12 packages, see [(Details on GitHub)](https:\/\/github.com\/ibm-functions\/runtime-nodejs\/blob\/master\/nodejs12\/package.json).\n\nFor more information about Node.js 10 packages, see [(Details on GitHub)](https:\/\/github.com\/ibm-functions\/runtime-nodejs\/blob\/master\/nodejs10\/package.json).\n\n\n\n\n\n\n\n Python runtimes \n\nBy default, all Python actions are executed in a Python version 3.9 environment.\n\n\n\nTable 4. Python versions\n\n Kind Python version Description Change log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-runtimes"},{"document_id":"ibmcld_01020-1436-3077","score":14.2564373016,"text":"\n[Forcing a failback to the primary site](https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-dr_gendr_force_failback)\n\n\n\n High Availability vs. Disaster Recovery \n\nDb2 on Cloud High Availability plan offers Db2 HADR SYNC and ASYNC nodes technology to deliver superior availability and reliability, within the same region. When required, failover to the HA nodes is managed seamlessly and automatically by IBM using automatic client reroute (ACR). HA plans reside within a single MZR or SZR region.\n\nWith the introduction of Geo-Replicated Disaster Recovery nodes, you are now able to extend that availability to an entirely different region by adding an on-demand Disaster Recovery node. This ability ensures that you can still access your data in the unlikely event of an outage in your primary region. For example, primary instance: Dallas; DR node: London.\n\n\n\n\n\n Enterprise and Standard HADR plans \n\nDR nodes are now available for Enterprise and Standard HADR plans only. DR nodes are currently not supported in single node plans or in EU-Cloud.\n\n\n\n Creating a DR node \n\n\n\n1. Select Administration from the left menu, then select the Disaster recovery tab.\n\nZoom\n\n![View of the Disaster Recovery page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/2a59ee244ed61eb35ab50e45757b42d22f720132\/Db2onCloud\/images\/dr_1_v2.jpg)\n\nFigure 1. View of the DR page\n2. Select a data center for the DR node and click Enable disaster recovery.\n\nZoom\n\n![Select a DR data center](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/2a59ee244ed61eb35ab50e45757b42d22f720132\/Db2onCloud\/images\/dr_2_v2.jpg)\n\nFigure 2. Select a data center for the recovery node\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-dr_gen"},{"document_id":"ibmcld_02642-7-1423","score":14.0816450119,"text":"\nInstalling the API Connect V5 Toolkit \n\nDuration: 15 mins\nSkill level: Beginner\n\n\n\n Prerequisites \n\n\n\n1. Node.js: An asynchronous, event-driven JavaScript runtime that is used to build and run scalable network applications.\n2. Node package manager (npm): A JavaScript package manager and software registry.\n3. IBM\u00ae API Connect for IBM Cloud\u00ae Lite: A free version of API Connect that is hosted on your laptop.\n\n\n\n\n\n\n\n Install node.js \n\n\n\n1. Download and install node.js from one of the following sources:\n\n\n\n* [https:\/\/nodejs.org\/en\/download\/](https:\/\/nodejs.org\/en\/download\/) (Note: Download the LTS version for your platform, not the latest, or you might experience errors.)\n* [https:\/\/developer.ibm.com\/node\/sdk\/v6\/)](https:\/\/developer.ibm.com\/node\/sdk\/v6\/)\n\n\n\nInstalling node.js also installs the npm (Node Package Manager).\n2. Make sure that node.js is in your PATH. ![verify-path.png](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/tutorials\/images\/verify-path.png)\n3. Update npm by running the following commnad: npm install -g npm Setting npm --engine-strict or npm config set engine-strict true prevents the installation from completing.\n4. Check the installed version and path. ![screenshot_install_apic-1.png](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/tutorials\/images\/screenshot_install_apic-1.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-tut_prereq_install_toolkit"},{"document_id":"ibmcld_12341-2467-4426","score":13.7657613754,"text":"\nUse a well-defined, well-documented request library that includes browser support, like [axios](https:\/\/github.com\/axios\/axios), [superagent](https:\/\/github.com\/visionmedia\/superagent), or [node-fetch](https:\/\/github.com\/node-fetch\/node-fetch).\n\n\n\n\n\n Objects for arguments \n\nThe methods in your SDK should take a JSON object as an argument. This object will contain the options for the requests, instead of using positional parameters in the function definition.\n\n\n\n\n\n Async architecture \n\nAll network calls from your SDK should be asynchronous. All asynchronous calls should be handled using Promises, not callbacks.\n\n\n\n\n\n Standard features \n\n\n\n\n\n Authentication \n\nYou are not required to use a particular library to provide the authentication for your service.\n\nYour SDK must support all of the authentication methods for your service.\n\n\n\n\n\n Configuration \n\nIn the interests of making your SDK easy to consume and cloud native, you should provide the ability to read in environment variables. Abstracting the application logic from the environment logic allows your users to focus on using your service capabilities their applications.\n\nIf you build this capability into your SDK, you must document this mechanism clearly with examples.\n\n\n\n\n\n Using node-sdk-core \n\n[IBM node-sdk-core](https:\/\/github.com\/IBM\/node-sdk-core) provides configuration and authentication support. You can use the existing functionality provided by this dependency in your SDK.\n\n\n\n\n\n Documentation \n\nYour SDK is not useful if your audience cannot understand how to consume it in order to do the basic operations for your service. Your SDK needs to contain the following resources to help your users:\n\n\n\n* README.md\n* NPM metadata\n* [Contributor guidelines](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentationsdk-contributor-docs)\n* Code Samples\n* [Service documentation](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentation)\n\n\n\n\n\n\n\n Samples","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-node"},{"document_id":"ibmcld_06320-1330-3318","score":13.7612791061,"text":"\nAfter you click Create, the system displays a message to say that the instance is being provisioned, which returns you to the Resource list. From the Resource list, you see that the status for your instance is, Provision in progress.\n8. When the status changes to Active, select the instance.\n\n\n\n\n\n\n\n Step 3: Set your admin password \n\n\n\n* [Set the Admin Password](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-admin-password) for your deployment.\n\n\n\nReview the [Getting to production](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-best-practices) documentation for general guidance on setting up a basic IBM Cloud\u00ae Databases for DataStax deployment.\n\n\n\n\n\n Step 4: Connect with DataStax drivers \n\nDrivers are a key component to connecting external applications to your Databases for DataStax deployment. Review the information on [Connecting an external application](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-external-app) for details on compatible drivers. Further details on specific drivers, including upgrade guides, can be found at [Developing applications with Apache Cassandra and DataStax Enterprise](https:\/\/docs.datastax.com\/en\/devapp\/doc\/devapp\/aboutDrivers.html).\n\nOnly DataStax drivers that are explicitly listed in the [Connecting an external application](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-external-app) table function correctly for connecting to Databases for DataStax.\n\n\n\n\n\n Step 5: Node repairs with NodeSync \n\n[NodeSync](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_14951-1651-3719","score":13.5533847809,"text":"\n* [Node SDK change log](https:\/\/github.com\/IBM\/vpc-node-sdk\/blob\/master\/CHANGELOG.md)\n* [Python SDK change log](https:\/\/github.com\/IBM\/vpc-python-sdk\/blob\/master\/CHANGELOG.md)\n* [Go SDK change log](https:\/\/github.com\/IBM\/vpc-go-sdk\/blob\/master\/CHANGELOG.md)\n\n\n\n\n\n Upcoming changes \n\nInstanceTemplate response schema change. In an upcoming release, future methods of creating instances, and therefore creating instance templates, may not require a primary network interface. To accommodate this, the primary_network_interface property is now optional in the instance template response model.\n\nAt this time, all instances, and therefore all instance templates, continue to require that a primary network interface be specified. Therefore, existing instance templates are unaffected. Additionally, new instance templates will continue to include a primary network interface until further notice. However, to ensure your clients will not be affected in the future, verify that they are tolerant of the primary_network_interface property not being included when consuming InstanceTemplate responses.\n\nInstance response schema change. In an upcoming release, volume attachments returned in the boot_volume_attachment and volume_attachments[] properties of an instance will not include the volume sub-property if the volume has not yet been provisioned. Such volumes are currently represented with empty crn, id, and href properties along with an undocumented sentinel value for name.\n\nTo prepare for this change, verify that your client checks that the volume property exists for a volume attachment before attempting to access its crn, id, href, or name sub-properties.\n\nAsynchronous DELETE response code change. In an upcoming release, the response code output for asynchronous DELETE operations will change from 204 to 202. A response code of 204 implies the action is completed, which could be misleading for operations that are still processing. A response code of 202 is more appropriate. This behavior change will occur only for an API version date after its release.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-api-change-log"},{"document_id":"ibmcld_09658-1587-3854","score":13.5012254715,"text":"\n* Always On availability groups provide the ability to keep a discrete set of databases highly available across one or more cluster nodes and work at the database level. Availability groups consist of one primary replica and up to a maximum of eight secondary replicas, and use synchronous or asynchronous data replication. In this deployment:\n\n\n\n* synchronous replication ios used between the two AZs in the primary MZR.\n* asynchronous replication is used between the MZRs.\n\n\n\n* Distributed Network Names is a name resource in WSFC and Always On availability groups, used for name resolution of the cluster resources.\n\n\n\nA file share witness is not required in this deployment because there are an odd number of nodes and Node Majority quorum mode will be used\n\n\n\n Windows Server Failover Cluster \n\nDeploying Always On availability groups for HA on Windows requires a Windows Server Failover Cluster (WSFC). Each availability replica of an availability group must reside on a different node of the WSFC. To simplify security configuration for the availability databases, it is recommended that the SQL server instances (the service accounts) run under a domain service account.\n\nWindows Server Failover Cluster (WSFC) is a Windows Server feature and each server that acts as a cluster node must have this feature enabled. WSFC relies on quorum votes to prevent \"split-brain\" syndrome, and there are a number of quorum modes:\n\n\n\n* Node Majority \u2013 Active cluster nodes determine the quorum. At least half of the possible votes must be affirmative for the cluster to maintain a healthy state.\n* Node and File Share Majority \u2013 A remote file share acts as a voting witness for the active nodes involved in a quorum vote. As with Node Majority, at least half of the possible votes must be affirmative for the cluster to maintain a healthy state.\n* Node and Disk Majority \u2013 A shared disk acts as a voting witness, along with the active nodes involved in a quorum vote.\n* Disk Only \u2013 A shared disk acts as a witness and quorum is determined by which nodes can access the disk. There is no minimum number of possible votes required.\n\n\n\nThe Microsoft recommendation for SQL server are as follows:\n\n\n\n* Use Node Majority quorum mode when there is an odd number of voting nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/microsoft?topic=microsoft-mssql-dualmzr"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10510-17837-19983","score":22.3341522217,"text":"\nWorker nodes carry the deployments and services that make up your app. When you host workloads in the public cloud, you want to ensure that your app is protected from being accessed, changed, or monitored by an unauthorized user or software.\n\n\n\n Who owns the worker node and am I responsible to secure it? \n\nThe ownership of a worker node depends on the type of cluster that you create and the infrastructure provider that you choose.\n\n\n\n* Classic clusters: Worker nodes are provisioned in to your IBM Cloud account. The worker nodes are dedicated to you and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n* VPC clusters: Worker nodes are provisioned in to an IBM Cloud account that is owned by IBM to enable monitoring of malicious activities and apply security updates. You can't access your worker nodes by using the VPC dashboard. However, you can manage your worker nodes by using the IBM Cloud Kubernetes Service console, CLI, or API. The virtual machines that make up your worker nodes are dedicated to you and you are responsible to request timely updates so that your worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n\n\n\nFor more information, see [Your responsibilities by using Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iks).\n\nUse the ibmcloud oc worker update[command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_update) regularly (such as monthly) to deploy updates and security patches to the operating system and to update the Red Hat OpenShift version that your worker nodes run. When updates are available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the ibmcloud oc clusters ls or ibmcloud oc workers ls --cluster <cluster_name> commands. Worker node updates are provided by IBM as a full worker node image that includes the latest security patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_06063-18145-20200","score":22.0111217499,"text":"\n* VPC clusters: Worker nodes are provisioned in to an IBM Cloud account that is owned by IBM to enable monitoring of malicious activities and apply security updates. You can't access your worker nodes by using the VPC dashboard. However, you can manage your worker nodes by using the IBM Cloud Kubernetes Service console, CLI, or API. The virtual machines that make up your worker nodes are dedicated to you and you are responsible to request timely updates so that your worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n\n\n\nFor more information, see [Your responsibilities by using IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks).\n\nUse the ibmcloud ks worker update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_update) regularly (such as monthly) to deploy updates and security patches to the operating system and to update the Kubernetes version that your worker nodes run. When updates are available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the ibmcloud ks clusters ls or ibmcloud ks workers ls --cluster <cluster_name> commands. Worker node updates are provided by IBM as a full worker node image that includes the latest security patches. To apply the updates, the worker node must be reimaged and reloaded with the new image. Keys for the root user are automatically rotated when the worker node is reloaded.\n\n\n\n\n\n How does my worker node setup look? \n\nThe following image shows the components that are set up for every worker node to protect your worker node from malicious attacks.\n\nThe image does not include components that ensure secure end-to-end communication to and from the worker node. For more information, see [network security](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork).\n\nZoom\n\n![Worker node setup in IBM Cloud Kubernetes Service excluding network security.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_06079-10297-12436","score":21.9135913849,"text":"\nWorker node With IBM Cloud Kubernetes Service, the virtual machines that your cluster manages are instances that are called worker nodes. These worker nodes virtual machines and all the worker node components are dedicated to you only and are not shared with other IBM customers. However, the underlying hardware is shared with other IBM customers. For more information, see [Virtual machines](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesvm). You manage the worker nodes through the automation tools that are provided by IBM Cloud Kubernetes Service, such as the API, CLI, or console. Unlike classic clusters, you don't see VPC compute worker nodes in your infrastructure portal or separate infrastructure bill, but instead manage all maintenance and billing activity for the worker nodes from IBM Cloud Kubernetes Service. Worker nodes include the same [components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-archworker-components) as described in the Classic architecture. Community Kubernetes worker nodes run on Ubuntu 18.04 x86_64, 16.04 x86_64 (deprecated). \n Cluster networking Your worker nodes are created in a VPC subnet in the zone that you specify. By default, the public and private cloud service endpoints for your cluster are enabled. Communication between the master and worker nodes is over the private network. Authenticated external users can communicate with the master over the public network, such as to run kubectl commands. You can optionally set up your cluster to communicate with on-prem services by setting up a VPC VPN on the private network. \n App networking You can create a Kubernetes LoadBalancer service for your apps in the cluster, which automatically provisions a VPC load balancer in your VPC outside the cluster. The load balancer is multizonal and routes requests for your app through the private NodePorts that are automatically opened on your worker nodes. For more information, see [Exposing apps with VPC load balancers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-lbaas). Calico is used as the cluster networking policy fabric.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch"},{"document_id":"ibmcld_10208-27425-28322","score":21.8549098969,"text":"\nIf you disable or delete the root key, your worker nodes enter a critical state until you restore the root key and [reboot](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_reboot) the worker nodes.\n\n\n\nThe encryption for the disks of the worker nodes in your worker pool are now managed by the root key in your KMS provider. If you created a cluster, the worker pool is the default worker pool.\n\n\n\n\n\n Satellite worker nodes \n\nSatellite: The encryption of the OS disk and secondary disk is managed at the IAAS layer of the platform Satellite is deployed on. The encryption of persistent storage volumes utilized within the cluster is managed at the persistent storage plug-in level and backing storage device level. For more information about encryption for storage devices or plug-ins, see the device provider documentation or the storage plug-in documentation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-encryption"},{"document_id":"ibmcld_06079-4312-6353","score":21.7962970734,"text":"\nOut of the box, your worker nodes are set up with an IBM-managed container runtime, separate compute resources, networking, and a volume service. The built-in security features provide isolation, resource management capabilities, and worker node security compliance.\n\nThe worker nodes and all the worker node components are dedicated only to you, and are not shared with other IBM customers. However, if you use a worker node virtual machine, the underlying hardware might be shared with other customers depending on the level of hardware isolation that you choose. For more information, see [Virtual machines](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesvm).\n\nModifying default worker node components such as the kubelet is not supported and might cause unexpected results.\n\nThe following tables describe the components of a worker node.\n\n\n\n\n\n kube-system namespace \n\nibm-master-proxy\n: The ibm-master-proxy forwards requests from the worker node to the IP addresses of the highly available master replicas. In single zone clusters, the master has three replicas on separate hosts with one master IP address and domain name. For clusters that are in a multizone-capable zone, the master has three replicas that are spread across zones. As such, each master has its own IP address that is registered with DNS, with one domain name for the entire cluster master.\n\nkonnectivity-agent\n: The Konnectivity agent works with the Konnectivity server to securely connect the master to the worker node. This connection supports apiserver proxy calls to your pods and services, and kubectl exec, attach, and logs calls to the kubelet.\n\nkubelet\n: The kubelet is a pod that runs on every worker node and is responsible for monitoring the health of pods that run on the worker node and for watching the events that the Kubernetes API server sends. Based on the events, the kubelet creates or removes pods, ensures liveness and readiness probes, and reports back the status of the pods to the Kubernetes API server.\n\ncoredns","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch"},{"document_id":"ibmcld_06010-7-1853","score":20.8059101105,"text":"\nPlanning your worker node setup \n\nIBM Cloud\u00ae Kubernetes Service provides different worker node flavors and isolation levels so that you can choose the flavor and isolation that best meet the requirements of the workloads that you want to run in the cloud.\n\nA worker node flavor describes the compute resources, such as CPU, memory, and disk capacity that you get when you provision your worker node. Worker nodes of the same flavor are grouped in worker node pools. The total number of worker nodes in a cluster determine the compute capacity that is available to your apps in the cluster.\n\nWant to save on your classic worker node costs? [Create a reservation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-reservations) to lock in a discount over 1 or 3 year terms! Then, create your worker pool by using the reserved instances. Note that autoscaling can't be enable on worker pools that use reservations.\n\nTrying to plan how many worker nodes your need in your cluster? Check out [Sizing your Kubernetes cluster to support your workload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing) to find information about the default worker node setup and how you can determine the resource requirements of your workloads.\n\n\n\n Available hardware for worker nodes \n\nThe worker node flavors and isolation levels that are available to you depend on your container platform, cluster type, the infrastructure provider that you want to use, and the IBM Cloud Kubernetes Service location where you want to create your cluster.\n\nZoom\n\n![Hardware options for worker nodes in a standard cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/cs_clusters_hardware.png)\n\nFigure 1. Hardware options for worker nodes in a standard cluster\n\n\n\n What flavors are available to me?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodes"},{"document_id":"ibmcld_10510-20784-22884","score":20.7439804077,"text":"\nWorker node setup in Red Hat OpenShift on IBM Cloud excluding network security\n\nCIS-compliant RHEL image\n: Every worker node is set up with a Red Hat Enterprise Linux operating system that implements the benchmarks that are published by the Center of Internet Security (CIS). The user or the owner of the machine can't change this operating system to another operating system. To review the current RHEL version, run oc get nodes -o wide. IBM works with internal and external security advisory teams to address potential security compliance vulnerabilities. Security updates and patches for the operating system are made available through Red Hat OpenShift on IBM Cloud and must be installed by the user to keep the worker node secure. Red Hat OpenShift on IBM Cloud uses a Red Hat Enterprise Linux kernel for worker nodes. You can run containers based on any Linux distribution in Red Hat OpenShift on IBM Cloud. Check with your container image vendor to verify that your container images can run on a Red Hat Enterprise kernel.\n\nContinuous monitoring by Site Reliability Engineers (SREs)\n: The image that is installed on your worker nodes is continuously monitored by IBM Site Reliability Engineers (SREs) to detect vulnerabilities and security compliance issues. To address vulnerabilities, SREs create security patches and fix packs for your worker nodes. Make sure to apply these patches when they are available to ensure a secure environment for your worker nodes and the apps that you run on them.\n\nCIS Kubernetes worker node benchmark\n: To configure Red Hat OpenShift on IBM Cloud, IBM engineers follow relevant cybersecurity practices from the Kubernetes worker node benchmark that is published by the [Center of Internet Security (CIS)](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/). You can review the compliance of worker nodes against [CIS Kubernetes benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmarkcis-worker-test) and [Red Hat OpenShift benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmark-comparison) standards.\n\nCompute isolation","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_10596-7-2100","score":20.5915279388,"text":"\nTroubleshooting worker nodes in Critical or NotReady state \n\nCluster worker nodes go into a Critical or NotReady state when they stop communicating with the cluster master. When this occurs, your worker nodes are marked as Critical in the IBM Cloud UI or when you run ibmcloud oc worker commands, and as NotReady in the Red Hat OpenShift dashboards and when you run oc get nodes. There are several reasons why communication stops between worker nodes and the cluster master. Follow these steps to troubleshoot worker nodes in these states.\n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n Check the common causes of worker node failures \n\nThere are several reasons why communication stops between worker nodes and the cluster master. Check whether the following common issues are causing the disruption.\n\nThe worker was deleted, reloaded, updated, replaced, or rebooted\n: Worker nodes might temporarily show a Critical or NotReady state when they are deleted, reloaded, updated, or replaced. If any of these actions have been initiated on your worker node, whether manually or as part of an automation setup such as cluster autoscaler, wait until the actions are complete. Then, check the status of your worker nodes again. If any workers remain in the Critical or NotReady state, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers.\n: If a worker node was reloaded or replaced and initially works correctly, but then after some time goes back into a Critical or NotReady state, then it is likely that some workload or component on the worker is causing the issue. See [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-kube-nodes) to isolate the problem workload.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-7-2098","score":20.5761508942,"text":"\nTroubleshooting worker nodes in Critical or NotReady state \n\nCluster worker nodes go into a Critical or NotReady state when they stop communicating with the cluster master. When this occurs, your worker nodes are marked as Critical in the IBM Cloud UI or when you run ibmcloud ks worker commands, and as NotReady in the Kubernetes dashboards and when you run kubectl get nodes. There are several reasons why communication stops between worker nodes and the cluster master. Follow these steps to troubleshoot worker nodes in these states.\n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n Check the common causes of worker node failures \n\nThere are several reasons why communication stops between worker nodes and the cluster master. Check whether the following common issues are causing the disruption.\n\nThe worker was deleted, reloaded, updated, replaced, or rebooted\n: Worker nodes might temporarily show a Critical or NotReady state when they are deleted, reloaded, updated, or replaced. If any of these actions have been initiated on your worker node, whether manually or as part of an automation setup such as cluster autoscaler, wait until the actions are complete. Then, check the status of your worker nodes again. If any workers remain in the Critical or NotReady state, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers.\n: If a worker node was reloaded or replaced and initially works correctly, but then after some time goes back into a Critical or NotReady state, then it is likely that some workload or component on the worker is causing the issue. See [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-kube-nodes) to isolate the problem workload.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_06063-19752-21803","score":20.4760665894,"text":"\nThe following image shows the components that are set up for every worker node to protect your worker node from malicious attacks.\n\nThe image does not include components that ensure secure end-to-end communication to and from the worker node. For more information, see [network security](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork).\n\nZoom\n\n![Worker node setup in IBM Cloud Kubernetes Service excluding network security.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/cs_worker_setup.png)\n\nFigure 2. Worker node setup in IBM Cloud Kubernetes Service excluding network security\n\nCIS-compliant Linux image\n: Every worker node is set up with an Ubuntu operating system that implements the benchmarks that are published by the Center of Internet Security (CIS). The user or the owner of the machine can't change this operating system to another operating system. To review the current Ubuntu version, run kubectl get nodes -o wide. IBM works with internal and external security advisory teams to address potential security compliance vulnerabilities. Security updates and patches for the operating system are made available through IBM Cloud Kubernetes Service and must be installed by the user to keep the worker node secure. IBM Cloud Kubernetes Service uses an Ubuntu Linux kernel for worker nodes. You can run containers based on any Linux distribution in IBM Cloud Kubernetes Service. Check with your container image vendor to verify that your container images can run on an Ubuntu kernel.\n\nContinuous monitoring by Site Reliability Engineers (SREs)\n: The image that is installed on your worker nodes is continuously monitored by IBM Site Reliability Engineers (SREs) to detect vulnerabilities and security compliance issues. To address vulnerabilities, SREs create security patches and fix packs for your worker nodes. Make sure to apply these patches when they are available to ensure a secure environment for your worker nodes and the apps that you run on them.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"}],"retriever_scores":{"recall_1":0.2,"recall_3":0.4,"recall_5":0.4,"recall_10":0.4,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.5087403079,"ndcg_cut_10":0.5087403079}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10495-9135-10569","score":21.8965244293,"text":"\n(https:\/\/cognitiveclass.ai\/courses\/docker-essentials)\n\n\n\n\n\n What is Red Hat OpenShift? \n\nRed Hat OpenShift is a Kubernetes container platform that provides a trusted environment to run enterprise workloads. It extends the Kubernetes platform with built-in software to enhance app lifecycle development, operations, and security. With Red Hat OpenShift, you can consistently deploy your workloads across hybrid cloud providers and environments. For more information about the differences between the community Kubernetes and Red Hat OpenShift cluster offerings, see the [comparison table](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\n\n\n\n\n What compute host infrastructure does the service offer? \n\nYou can create clusters on Classic or IBM Cloud\u00ae Virtual Private Cloud infrastructure. You can also bring your own hosts by using Satellite.\n\nFor more information, see [Supported infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers).\n\n\n\n\n\n Related resources \n\nReview how you can learn about Kubernetes concepts and the terminology.\n\n\n\n* Familiarize yourself with the product by completing the [Creating clusters tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Learn how Kubernetes and Red Hat OpenShift on IBM Cloud work together by completing this [course](https:\/\/cognitiveclass.ai\/courses\/kubernetes-course).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview"},{"document_id":"ibmcld_10154-7-1896","score":21.8622245789,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10214-1438-3413","score":21.8396663666,"text":"\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n\n\n\n\n\n What container platforms are available for my cluster? \n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform. If you want to use multiple container platforms, create a separate cluster for each.\n\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https:\/\/kubernetes.io\/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_04644-7-1968","score":21.7661628723,"text":"\nRed Hat OpenShift on IBM Cloud \n\nIBM\u00ae Cloud Foundry is deprecated and no longer supported as of 1 June 2023. For more information, see the [deprecation details](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-deprecationdep_details).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae is a managed offering to create your own OpenShift cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. The managed OpenShift offering combines the built-in industry leading OpenShift capabilities including RHEL-based infrastructure, enterprise hardened Kubernetes, validated integrations, integrated container registry, developer workflow tools, and easy access to services through service brokers with the operational cluster lifecycle excellence from IBM Cloud SRE.\n\nAs a managed offering, IBM deploys the compute, networks, and storage based on the customer's requirements through the UI, CLI, API, or automation through IBM Cloud Schematics. Additionally, IBM provides the tooling for updates including OS patches, vulnerability remediation, and updates to any component in the stack with the customer determining when they should upgrade. Red Hat OpenShift on IBM Cloud supports HA masters, multi-zone clusters, compute isolation choices including bare metal worker nodes, customer managed keys using IBM Key Protect or industry leading HyperProtect Crypto Services using FIPS 140-2 Level 4 encryption, and secure access to IBM Cloud services to enhance your application's capabilities including Watson, IoT, and Analytics.\n\n\n\n Resources \n\nThe following resources are available to help you learn more about the OpenShift on IBM Cloud:\n\n\n\n* [IBM information page](https:\/\/www.ibm.com\/cloud\/openshift)\n* [Overview](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview)\n* [IBM Cloud service creation](https:\/\/cloud.ibm.com\/kubernetes\/overview?platformType=openshift)\n* [Documentation](https:\/\/cloud.ibm.com\/docs\/openshift)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-deprecation_openshift"},{"document_id":"ibmcld_08006-1379-2960","score":21.663318634,"text":"\nEven though it is shown in the diagram as an option, it is not required to put Red Hat OpenShift on IBM Cloud in your management VPC.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud concepts \n\nRed Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift on IBM Cloud cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\nRed Hat OpenShift on IBM Cloud extends the Kubernetes platform with built-in software to enhance app lifecycle development, operations, and security. The master nodes are entirely IBM's responsibility, while there is shared responsibility for the worker nodes.\n\nFor IBM Cloud for Financial Services, you should provision Red Hat OpenShift on IBM Cloud in a VPC only and not in classic infrastructure.\n\nFor more information, see [Understanding Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview).\n\n\n\n\n\n Next steps \n\n\n\n* [Setup environment for deployment and configuration](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-deployment-setup-environment).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-openshift"},{"document_id":"ibmcld_10495-7-2029","score":21.4101676941,"text":"\nUnderstanding Red Hat OpenShift on IBM Cloud \n\nLearn more about [Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift), its capabilities, and the options that are available to you to customize the cluster to your needs.\n\nReview frequently asked questions and key technologies that Red Hat OpenShift on IBM Cloud uses.\n\n\n\n What is Red Hat OpenShift on IBM Cloud and how does it work? \n\nRed Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\n\n\n\n\n What is Kubernetes? \n\nKubernetes is an open source platform for managing containerized workloads and services across multiple hosts, and offers management tools for deploying, automating, monitoring, and scaling containerized apps with minimal to no manual intervention.\n\nZoom\n\n![Kubernetes certification badge](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/openshift\/images\/certified-kubernetes-color.svg)\n\nFigure 1. This badge indicates Kubernetes certification for IBM Cloud Container Service.\n\nThe open source project, Kubernetes, combines running a containerized infrastructure with production workloads, open source contributions, and Docker container management tools. The Kubernetes infrastructure provides an isolated and secure app platform for managing containers that is portable, extensible, and self-healing in case of a failover. For more information, see [What is Kubernetes?](https:\/\/www.ibm.com\/topics\/kubernetes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview"},{"document_id":"ibmcld_14497-1215-3210","score":21.4071006775,"text":"\n[VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.\n\nThe operating system of the nodes is Red Hat\u00ae Enterprise Linux\u00ae CoreOS, which is the container host version of Red Hat Enterprise Linux (RHEL) and features an RHEL kernel with SELinux enabled by default. RHEL CoreOS includes kubelet, which is the Kubernetes node agent, and the CRI-O container runtime, which is optimized for Kubernetes. In Red Hat OpenShift 4.7, you must use RHEL CoreOS for all control plane machines, but you can use Red Hat Enterprise Linux (RHEL) as the operating system for compute, or worker machines. If you choose to use RHEL workers, you must perform more system maintenance than if you use RHEL CoreOS for all of the cluster machines.\n\nThe reference architecture and this build process use RHEL CoreOS. The nodes must have direct Internet access to complete the following tasks.\n\n\n\n* Access the Red Hat OpenShift Infrastructure Providers page to download the installation program.\n* Access quay.io to obtain the packages that are required to install the cluster.\n* Obtain the packages that are required to perform cluster updates.\n* Access Red Hat\u2019s software as a service page to perform subscription management.\n\n\n\nIn the reference architecture, the following components are installed and configured in the build process:\n\n\n\n* Bastion node - This RHEL VM acts as a \"jump-server\" on the overlay network to enable the build process. It is accessed by using SSH through the private network. It also hosts a webserver to help the build process of the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_14492-7-1792","score":21.3583621979,"text":"\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_16727-396949-399109","score":21.2944450378,"text":"\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-396975-399135","score":21.2944450378,"text":"\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.9010126104}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14913-0-1238","score":24.0779380798,"text":"\n\n\n\n\n\n\n  About virtual network functions over VPC \n\nNetwork Function Virtualization (NFV) is the network infrastructure behind virtualizing network services (such as routers, firewalls, and load balancers) that were traditionally run on proprietary hardware. These services, called Virtual Network Functions (VNFs), are packaged as virtual machines (VMs) on commodity hardware, which allows service providers to run their networks on standard servers instead of proprietary ones. This third-party software interacts with the IBM Software-Defined Networking (SDN) controller to offer easy configuration, centralized management, and lower operational costs.\n\nWorking along with IBM Cloud\u00ae Schematics (Infrastructure as Code) and the IBM Content catalog, customers are able to instantiate best-in-network solutions to manage their workload.\n\nBenefits include:\n\n\n\n*  Instantiating virtual network services and modifying configurations without the need to deploy new network hardware.\n*  Rapid service delivery with the agility to scale well above physical hardware.\n*  Centralized policy control.\n*  Using the same routers, firewalls, load balancers, and VPNs in IBM Cloud that were used in physical hardware or other cloud providers.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vnf"},{"document_id":"ibmcld_16026-0-358","score":19.1927719116,"text":"\n\n\n\n\n\n\n  VNF limitations \n\nHigh Availability (HA) Virtual Network Function (VNF) deployments have the following known limitations.\n\n\n\n*  The Virtual Network Function (VNF) must share one subnet with the Network Load Balancer (NLB).\n*  Routing public internet \"ingress\" traffic to a VNF is not supported.\n*  Auto-scaling with the VNF is not supported.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vnf-limitations"},{"document_id":"ibmcld_15151-0-569","score":18.37707901,"text":"\n\n\n\n\n\n\n  Configuring security groups \n\nThe Virtual Network Function (VNF) data network interface is attached to a VPC security group. Ensure that the security group has inbound rules that allow traffic on the pool health port that is set up between the NLB and the VNF. For example, if the health check is set up for TCP on port 80 (HTTP), then create an inbound rule for that security group. Additionally, you can create rules to allow or restrict data traffic.\n\n\n\n  Next step \n\n[Deploying a supported VNF](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-deploy-vnf)\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-configure-security-groups"},{"document_id":"ibmcld_14282-7-2547","score":17.950553894,"text":"\nVMware vSphere NSX overview \n\nVMware NSX\u00ae is a software networking and security virtualization platform that delivers the operational model of a virtual machine for the network. Virtual networks reproduce the Layer2 - Layer7 network model in software, allowing complex multitier network topologies to be created and provisioned programmatically in seconds, without the need for extra IBM Cloud private networks. NSX also provides a new model for network security. Security profiles are distributed to and enforced by virtual ports and move with virtual machines.\n\nNSX supports the VMware software-defined data center strategy. By extending the virtualization capabilities of abstraction, pooling and automation across all data center resources and services, the software-defined data center architecture simplifies and speeds the provisioning and management of compute, storage, and networking resources through policy-driven automation. By virtualizing the network, NSX delivers a new operational model for networking that breaks through current physical network barriers and enables VMware and IBM Cloud to achieve better speed and agility with reduced costs.\n\nNSX includes a library of logical networking services - logical switches, logical routers, logical firewalls, logical load balancers, logical VPN, and distributed security. You can create custom combinations of these services in isolated software-based virtual networks that support existing applications without modification, or deliver unique requirements for new application workloads. Virtual networks are programmatically provisioned and managed independent of IBM Cloud networking constructs. This decoupling from hardware introduces agility, speed, and operational efficiency that can transform data center operations. Benefits of NSX include the following features:\n\n\n\n* Data center automation\n* Self-service networking services\n* Rapid application deployment with automated network and service provisioning\n* Isolation of development, test, and production environments on the same bare metal infrastructure\n* Single Account multi-tenant clouds\n\n\n\nNSX can be configured through the vSphere Web Client, a command line interface (CLI), and REST API. The core network services that are offered by NSX are:\n\n\n\n Logical switches \n\nA cloud deployment or a virtual data center might have various applications across multiple tenants. These applications and tenants require isolation from each other for security, fault isolation, and avoiding overlapping IP addressing issues.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmware?topic=vmware-nsx-overview"},{"document_id":"ibmcld_14549-16227-18518","score":17.5108795166,"text":"\nConfiguration is required for access to the internet and the IBM Services network. The five public addresses are used for public facing vApps for inbound and outbound public internet traffic.\n\nThe service address is used for access to a number of IBM Cloud infrastructure services on the IBM Cloud internal private network. The list includes the following services:\n\n\n\n* NTP\n* Windows operating system licensing and updates\n* Red Hat operating system licensing and updates\n* Cloud Object Storage\n\n\n\nTwo types of Organization virtual data center networks are available in the VMware Shared virtual data center: routed and internal.\n\n\n\n Routed network \n\nAccessible only by the same Organization virtual data center. Only VMs in this Organization virtual data center can connect to this network. This network also provides controlled access to an external network. An organization administrator can configure Network Address Translation (NAT), firewall, and VPN settings to make specific VMs accessible from the external network.\n\n\n\n\n\n Internal or isolated network \n\nAccessible only by the same Organization virtual data center. Only VMs in this Organization virtual data center can connect to and see traffic on the internal Organization virtual data center network.\n\nThe isolated Organization virtual data center network provides an Organization virtual data center with an isolated, private network that multiple VMs and vApps can connect to. This network provides no connectivity to VMs outside the Organization virtual data center. VMs that are outside of the Organization virtual data center have no connectivity to VMs that are in the Organization virtual data center.\n\n\n\n\n\n Creating a network \n\nFrom the tenant portal, use the following procedures to create a sample network topology that includes: configuring DHCP services, defining Source NAT (SNAT) and Destination NAT (DNAT) rules, and creating firewall rules on the edge gateway to allow access to the internet. Complete these procedures from the tenant portal Data Centers tab.\n\nZoom\n\n![IBM Cloud for VMware Solutions network topology](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/vcd-sample-topology.svg)\n\nFigure 1. IBM Cloud for VMware Solutions network topology","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_vcd-ops-guide"},{"document_id":"ibmcld_14282-1986-4283","score":16.8359909058,"text":"\n* Isolation of development, test, and production environments on the same bare metal infrastructure\n* Single Account multi-tenant clouds\n\n\n\nNSX can be configured through the vSphere Web Client, a command line interface (CLI), and REST API. The core network services that are offered by NSX are:\n\n\n\n Logical switches \n\nA cloud deployment or a virtual data center might have various applications across multiple tenants. These applications and tenants require isolation from each other for security, fault isolation, and avoiding overlapping IP addressing issues. The NSX logical switch creates logical broadcast domains or segments (VXLAN vWires) to which an application or tenant virtual machine can be logically wired. This feature allows for flexibility and speed of deployment while still providing all the characteristics of a physical network's broadcast domains (VLANs) without physical Layer 2 sprawl. Logical switches allow for thousands of tenant networks to be provisioned onto a single IBM Cloud private network (VLAN). A logical switch is distributed and can span arbitrarily large compute clusters, even across pods within the same data center. This distribution allows for virtual machine mobility within the data center without limitations of physical Layer 2 (VLAN) boundaries across pods.\n\n\n\n\n\n Logical routers \n\nDynamic routing provides the necessary forwarding information between Layer 2 broadcast domains (VXLAN, vWires, Logical Switches). This routing decreases Layer 2 broadcast domains and improve network efficiency and scale. NSX extends this intelligence where the workloads reside for providing East-West routing functions. This extension allows more direct virtual machine to virtual machine communication without the costly or timely need to extend hops. NSX also provides North-South connectivity inbound and outbound of IBM Cloud data centers, thus enabling tenants to access public networks securely and efficiently.\n\n\n\n\n\n Logical firewall \n\nLogical firewall provides security mechanisms for dynamic virtual data centers. The Distributed Firewall component of an NSX Logical Firewall allows users to segment virtual data center entities (virtual servers), vCenter objects (data centers and hosts), and traditional networking attributes like IP addresses and VLANs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmware?topic=vmware-nsx-overview"},{"document_id":"ibmcld_10916-84867-86483","score":16.5428409576,"text":"\nvirtual server \n\nA server that shares its resources with other servers to support applications. See also [virtual machine](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2043165).\n\n\n\n\n\n VLAN \n\nSee [virtual local area network](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2438470).\n\n\n\n\n\n VM \n\nSee [virtual machine](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2043165).\n\n\n\n\n\n volume \n\nA fixed amount of physical or virtual storage on a data storage medium.\n\n\n\n\n\n VPC \n\nSee [virtual private cloud](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx4585403).\n\n\n\n\n\n VPN \n\nSee [virtual private network](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2043188).\n\n\n\n\n\n VPN as a service \n\nA private connection between two endpoints, which remains private and can be encrypted even when the data is transferred across a public network.\n\n\n\n\n\n\n\n W \n\n\n\n WAR \n\nSee [web archive](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2116506).\n\n\n\n\n\n WAR file \n\nSee [web archive](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2116506).\n\n\n\n\n\n web app \n\nSee [web application](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2116500).\n\n\n\n\n\n web application (web app) \n\nAn application that is accessible by a web browser and that provides some function beyond static display of information, for instance by allowing the user to query a database. Common components of a web application include HTML pages, JSP pages, and servlets. See also [app](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx4281528).\n\n\n\n\n\n web archive (WAR)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossary"},{"document_id":"ibmcld_14418-1648-3598","score":16.0125789642,"text":"\nDeployed as virtual machines (VMs) in mirrored pairs, the service mesh consists of the following components:\n\n\n\n* Interconnect Appliance (HCX-IX) - The interconnect appliance creates encrypted tunnels that support vMotion and replication (bulk migration) traffic.\n* WAN Optimizer Appliance (HCX-WAN) - HCX includes an optionally deployed Silver Peak\u2122 WAN optimization appliance. It is deployed as a VM appliance. When deployed, the CGW tunnel traffic is redirected to traverse the WAN Optimizer. Since the WAN optimizer significantly decreases traffic across the WAN (typically 3:1 to 6:1 observed) while it increases connection reliability, it is recommended to deploy the WAN optimizer with the CGW. The added benefit of deploying the WAN optimizer is extended to limiting the WAN bandwidth used by VM migration traffic. The WAN optimizer management interface is not configured by default.\n* Network Extension (HCX-NE) - Provides the Layer 2 network extension capabilities, enabling migrations between the on-premises location and the vSphere environment with the need to reassign IP addresses to the VMs.\n* Proxy ESXi host - Whenever the HCX-IX is configured to connect to the cloud side HCX site, a proxy ESXi host appears in the vCenter Server outside of any cluster. This ESXi host has the same management and vMotion IP address as the corresponding HCX-IX appliance. As a result, the vSphere environment at both the client and the cloud side work as if it performs a local vMotion.\n\n\n\nThis method has the following benefits:\n\n\n\n* The management IP ranges on either side might be overlapping with no loss in functionality.\n* The cloud side has no vSphere visibility into the client side, which makes it more secure.\n\n\n\n\n\n\n\n HCX user portals \n\n\n\n* Client web user interface \u2013 The HCX client web portal is the main user interface for HCX. After the client-side HCX Manager is installed, it shows up as a snap-in to the vCenter web user interface.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-hcxclient-components"},{"document_id":"ibmcld_15152-0-891","score":15.9755249023,"text":"\n\n\n\n\n\n\n  Configuring VPC resources \n\nBefore you start deploying a High Availability (HA) Virtual Network Function (VNF), complete the following tasks:\n\n\n\n1.  Create a VPC. For more information, see [Creating a VPC and subnet](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-the-ibm-cloud-console&interface=clicreating-a-vpc-and-subnet).\n2.  Create a subnet that is to be shared between the VNF's data traffic interface and the Network Load Balancer (NLB).\n3.  If the VNF requires a subnet for management traffic, create the subnet. This subnet can be shared between multiple VNFs to support clustering.\n4.  Create any additional subnets that might be required for the virtual server instance's workloads that are to be routed through the NLB and VNFs.\n\n\n\n\n\n  Next step \n\n[Configuring security groups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-configure-security-groups)\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-configure-vpc-resources"},{"document_id":"ibmcld_16030-7-2126","score":15.9628505707,"text":"\nVPC behind the curtain \n\nThe following information presents a detailed conceptual picture of what's happening \"behind the curtain\" in VPC networking. Learn about network isolation, address prefixes, Cloud Service Endpoint source addresses, data packet flows, external IP address lifecycle, and Classic infrastructure access. Readers are expected to have some networking background.\n\n\n\n Network isolation \n\nVPC network isolation takes place at three levels:\n\n\n\n* Hypervisor - The virtual server instances are isolated by the hypervisor. A virtual server instance can't directly reach other virtual server instances that are hosted by the same hypervisor if they are not in the same VPC.\n* Network - Isolation occurs at the network level by using virtual network identifiers (VNIs). These identifiers are assigned to each subnet and scoped to a single zone. A VNI is added to all data packets that enter any zone of the VPC: entering either from the hypervisor, when sent by a virtual server instance, or entering the zone from the cloud, when sent by the implicit routing function.\n\nA packet that leaves a zone has the VNI stripped off. When the packet reaches its destination zone, entering through the implicit routing function, the implicit router always adds the proper VNI for that zone.\n* Router - The implicit router function provides isolation to each VPC by providing a virtual routing function (VRF) and a VPN with MPLS (multi-protocol label switching) in the cloud backbone. Each VPC's VRF has a unique identifier, and this isolation allows each VPC to have access to its own copy of the IPv4 address space. The MPLS VPN allows for federating all edges of the cloud: Classic Infrastructure, Direct Link, and VPC.\n\n\n\n\n\n\n\n Address prefixes \n\nAddress prefixes are the summary information that is used by a VPC's implicit routing function to locate a destination virtual server instance, regardless of the availability zone in which the destination virtual server instance is located. The primary function of address prefixes is to optimize routing over the MPLS VPN, while pathological routing cases are avoided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-behind-the-curtain"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02547-1335-2984","score":14.3122959137,"text":"\nSelect Everything to see all the events, or a view.\n\n\n\nYou can view events through the view that you have selected.\n\n\n\n\n\n View a subset of the events by applying a search query \n\nYou can select the events that are displayed through a view by applying a search query. You can save that view for reuse later. [Learn more](https:\/\/cloud.ibm.com\/docs\/services\/activity-tracker?topic=activity-tracker-viewsviews_step2).\n\n\n\n\n\n View a subset of the events by applying a timeframe \n\nYou can select the events that are displayed through a view by applying a timeframe.\n\nYou can apply a timestamp by specifying an absolute time, a relative time, or a time range.\n\nComplete the following steps to jump to a specific time:\n\n\n\n1. [Go to the web UI](https:\/\/cloud.ibm.com\/docs\/services\/activity-tracker?topic=activity-tracker-launchlaunch).\n2. Click the Views icon ![Views icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/images\/views.png).\n3. Select Everything or a view.\n4. Enter a time query. Choose any of the following options:\n\n\n\n* Enter an abosute time to jump to a point in time in your events such as May 20 7:00pm.\n* Enter a relative time such as 2 days ago, today at 12am, or an hour ago.\n* Enter a time range such as yesterday 10am to yesterday 11am, last fri 4:30pm to 11\/12 1 AM, last wed 4:30pm to 23\/05 1 AM, or May 20 10am to May 22 10am. Make sure to include to to separate the initial timestamp from the end timestamp.\n\n\n\n5. Press ENTER.\n\nYou might get the error message: Your request is taking longer than expected, try refreshing your browser in a bit as we try to catch up. Retry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-view_events"},{"document_id":"ibmcld_16654-1654-3017","score":14.2967405319,"text":"\nIn the Catalogs configuration page, complete the following steps:\n\n\n\n1. Select the table format for managing your data. Apache Hive and Apache Iceberg catalogs are selected by default.\n2. Click Next.\n\n\n\n\n\n\n\n Step 3: Configure an engine \n\nYour watsonx.data needs a query engine to work with your data.\n\nIn the Engine configuration page, complete the following steps:\n\n\n\n1. Select the engine to run and process the data that you attached.\n2. Select the size of the engine based on the requirements of your workload.\n\n\n\nTable 2. Engine size\n\n Size Description \n\n Starter (5.6 RUs\/hour) Includes 1 coordinator node and 1 worker node. All nodes are storage-optimized. \n Small (11.2 RUs\/hour) Includes 1 coordinator node and 3 worker nodes. All nodes are storage-optimized. \n Medium (19.6 RUs\/hour) Includes 1 coordinator node and 6 worker nodes. All nodes are storage-optimized. \n Large (36.4 RUs\/hour) Includes 1 coordinator node and 12 worker nodes. All nodes are storage-optimized. \n\n\n\n3. Click Next.\n\n\n\n\n\n\n\n Step 4: Review the configuration details \n\nIn the Summary page, complete the following steps:\n\n\n\n1. Review the configurations before you finish setting up your watsonx.data.\n2. Click Finish and go.\n\n\n\nWhen the setup is complete, the watsonx.data home page appears.\n\n\n\n\n\n Next steps \n\nYou are all set to use the watsonx.data or you can configure it further.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-quick_start"},{"document_id":"ibmcld_02522-13463-15240","score":14.1215410233,"text":"\nFor example, to get the list of actions for a user, you can run the following query:\n\nSELECT _source.eventTime, _source.action, _source.o_target.name\nFROM cos:\/\/eu-gb\/sql-results\/jobid=3aa9e732-ba88-4ffe-b9fc-b8a265876467 STORED AS PARQUET\nWHERE _source.o_initiator.name = \"xxx@ibm.com\"\nORDER BY _source.eventTime\nINTO cos:\/\/eu-gb\/sql-results STORED AS CSV\n\nFor example, to get the event time, the action, the criticality of the action, and the outcome, you can run the following query:\n\nSELECT _source.eventTime AS EVENTTIME, _source.action AS ACTION, _source.severity AS SEVERITY, _source.outcome AS OUTCOME FROM PARQUET_FILE STORED AS PARQUET\nINTO RESULTS_BUCKET STORED AS CSV\n\n\n\n\n\n Step 3.7. Run a query to get a subset of the event fields ordered by the event time \n\nTo see information about each event, run the following query:\n\nSELECT FIELDS FROM PARQUET_FILE STORED AS PARQUET\nORDER BY _source.eventTime\nINTO RESULTS_BUCKET STORED AS CSV\n\nWhere\n\n\n\n* FIELDS is the list of fields that you want to get information on for the different records. For example, you can enter _source.eventTime AS EVENTTIME, _source.action AS ACTION, _source.severity AS SEVERITY, _source.outcome AS OUTCOME\n* PARQUET_FILE is the Result location URL that you get when you transform the archive file from JSON to PARQUET\n* RESULTS_BUCKET is the SQL URL of the custom COS bucket that you plan to use to upload the query results\n\n\n\nFor example, to get the event time, the action, the criticality of the action, and the outcome, you can run the following query:\n\nSELECT _source.eventTime AS EVENTTIME, _source.action AS ACTION, _source.severity AS SEVERITY, _source.outcome AS OUTCOME FROM PARQUET_FILE STORED AS PARQUET ORDER BY _source.eventTime\nINTO RESULTS_BUCKET STORED AS CSV\n\n\n\n\n\n Step 3.8.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-sqlquery"},{"document_id":"ibmcld_09989-0-1547","score":13.8918714523,"text":"\n\n\n\n\n\n\n  Query editor \n\nWith the query editor, you can run SQL queries on a specific host and database. You can also save any of the queries that you create.\n\n\n\n  Creating queries \n\n\n\n1.  Go to Query editor.\n2.  From Data objects, select the database and schema in which you want to run the query.\nIf you do not pick a schema, the default database schema is selected.\n3.  Type the SQL query that you want to run.\nIf your query is a select statement, a Set Limit option shows up to allow you to specify how many rows of data you would like to retrieve. The default is No limit.\n\nIn the Worksheet settings you can specify your Default maximum number of rows limit in result. If you decide, however, to add a limit clause in a select statement that is greater than your Default maximum number of rows limit in result, for example: select * from table1 limit 10;, the Results field shows the smaller value of these two parameters.\n\nIn the Worksheet settings you can also specify the Statement separator you want to use. A semicolon (\";\") is the default Statement separator and you must change it to an ampersand (\"&\") when your queries contain semicolons (\";\") to avoid errors.\n4.  When you input the information, you can do one of the following:\n\n\n\n*  Click Run to run the query.\nThe results of the query are displayed in the panel.\n*  Click the floppy disk icon that is in the SQLworksheet toolbar to save the query as a template.\nThe saved query is added to Saved queries and Queries > Recent Queries.\n*  Click Clear to clear the query.\n\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-query-editor"},{"document_id":"ibmcld_16662-0-1981","score":13.6771688461,"text":"\n\n\n\n\n\n\n  Running SQL queries \n\nSQL is a standardized language for defining and manipulating data in a relational database. You can use the Query workspace interface in IBM\u00ae watsonx.data to run SQL queries and scripts against your data.\n\nThe Query workspace has the following components:\n\n\n\n*  Data objects: To view the engines, catalogs, schemas, tables, and columns.\n*  Engine: To select an engine and view the associated catalogs.\n*  Saved queries: To view the saved queries.\n*  Worksheet: To write SQL queries.\n\n\n\nThe Query workspace page provides basic options to undo, redo, cut, copy, paste, save, clear, and delete.\n\nFormat selection option is enabled only when an SQL statement in a query worksheet is selected. The Format worksheet option formats all the content in the worksheet. Comment selection is used to explain sections of SQL statements.\n\nThe Delete option is enabled only after an SQL query is saved.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select SQL. The Query workspace page opens.\n3.  Select an engine from the Engine drop-down.\n4.  Select the catalog, schema, table, or column in which you want to run the query.\n5.  Click the overflow menu and select the required query.\n\n\n\n*  For a catalog and schema, you can run the Generate Path query.\n*  For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n*  For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\n6.  Click the Save icon to save the query. A Save query confirmation dialog appears.\n7.  Click Save.\n8.  Click the Run button to run the query.\n9.  Select Result set or Details tab to view the results.\n10. Click Saved queries to view the saved queries.\n11. Click [Explain](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-run_sql"},{"document_id":"ibmcld_13039-5322-7410","score":13.3617954254,"text":"\nThe following table show examples of queries for different actions:\n\n\n\nTable 4. Samples of queries by action type\n\n Action Sample query \n\n Provision a service action instance.create \n Remove an instance action instance.delete \n Add a user action user-management.user.create \n\n\n\n\n\n\n\n Query for events with a specific reason code \n\nYou can enter the following query to search for events with a specific reason code:\n\nreason.reasonCode:VALUE\n\nWhere VALUE represents the reason code value.\n\nFor example, to filter events with reason code 500, you can enter the following query:\n\nreason.reasonCode:500\n\n\n\n\n\n Query for events whose action fails \n\nWhen an action requested fails, the field outcome is set to failure. You can enter the following query to search for these type of events:\n\noutcome:failure\n\n\n\n\n\n Query by event criticallity \n\nEach event has a severity field that defines the level of threat an action may have on the Cloud.\n\nValid values are normal, warning, and critical.\n\n\n\n* Normal is set for routine actions in the Cloud. For example, starting an instance, or refreshing a token.\n* Warning is set for actions where a Cloud resource is updated or its metadata is modified. For example, updating the version of a worker node, renaming a certificate, or renaming a service instance.\n* Critical is set for actions that affect security in the Cloud. For example, changing credentials of a user, deleting data, unauthorized access to work with a Cloud resource.\n\n\n\nYou can enter the following query to search for these type of events:\n\nseverity:VALUE\n\nWhere VALUE can be set to normal, warning, or critical\n\nFor example, to query for critical events, you can run the following query:\n\nseverity:critical\n\n\n\n\n\n\n\n Step 3. Create a custom view \n\nAfter you apply the search query to the Everything view or to an existing custom view, complete the following steps to save the outcome as a custom view:\n\n\n\n1. In the web UI, click Unsaved View.\n2. Select Save as new view \/ alert. The Create new view page opens.\n3. Enter a name for the view in the Name field.\n4. Optionally, add a category.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/activity-tracker?topic=activity-tracker-views"},{"document_id":"ibmcld_13493-2289-4276","score":13.3431653976,"text":"\n* Use the INTO clause of a [query](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencechapterSQLQueryStatement) to specify the output [URI](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-runningunique), that is, the location to which the result is to be written and the wanted result format.\n\n\n\n2. The Target location field displays where the result is stored. An initial bucket in one of your Object Storage instances is automatically created for you when you open the UI. It is then chosen as your default location, if your query does not specify an INTO clause. To ensure the automatic setup of an initial bucket, do the following steps in advance:\n\n\n\n* You must create an Object Storage instance.\n* You must have at least 'Writer' access to the corresponding Object Storage bucket.\n\n\n\nIn the Details tab of the selected job, you can set any location that you specified in the INTO clause as your default location.\n3. Click Run.\n\nWhen the query completes, a preview of the query result is displayed in the query result tab of the UI. The preview function is only available for CSV and JSON result formats. You can run up to five queries simultaneously with a Standard plan instance of Data Engine.\n\n\n\n\n\n Sample queries \n\nWhat does a typical query look like? The following sample queries give you an idea to get you started:\n\n\n\n Example of a table exploration query \n\nThe following query selects all columns of a table and limits the result to 50 rows. Use it to explore a particular table.\n\nSELECT \nFROM cos:\/\/us-geo\/sql\/customers.csv STORED AS CSV\nORDER BY CustomerID\nLIMIT 50\n\n\n\n\n\n Example of an exact target path specification \n\nThe following query writes an SQL result into an exact result path. Normally, Data Engine always appends jobid=<jobid> to the provided target path to ensure a unique result location with each query execution. However, in the following sample query, this suffix is eliminated by adding JOBPREFIX NONE to the path in the INTO clause.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-running"},{"document_id":"ibmcld_12114-4110-6128","score":13.2379665375,"text":"\n4. Click Create host group.\n5. Enter a name for your host group and select the Schematics Workspaces that provisioned the target hosts that you want to add to your host group.\n6. Optional: Click Add query to add another condition to your query and limit the number of target hosts that are added to your host group. You can choose to identify your hosts by using the resource name or a tag. For more information, see [supported resource queries](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-inventories-setupsupported-queries).\n7. Repeat step 4-6 to add more host groups.\n8. From the table list, select the host groups that you want to include in your resource inventory.\n9. Click Create inventory.\n10. Follow the [steps](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-action-workingcreate-action) to create the Schematics Actions and use the resource inventory that you created.\n\n\n\n\n\n Supported resource queries \n\n\n\nResource query\n\n Supported query Description \n\n Workspace name Select all the IBM Cloud resources from a specific workspace. \n Workspace name AND resource name Select a specific resource from a specific workspace by using the resource name. To select multiple resources from the same workspace, you can add multiple queries of this type. \n Workspace name AND tag Select a specific resource from a specific workspace by using tags. Tags are added to the resource when you create the workspace and provision your resource. To select multiple resources with different tags from the same workspace, you can add multiple queries of this type. \n\n\n\n\n\n\n\n Limitations \n\nReview the following limitations of dynamic inventories in Schematics:\n\n\n\n* You can choose among the [supported queries](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-inventories-setupsupported-queries) to select the target virtual server instances to include in your resource inventory.\n* Schematics retrieves the IP address of a target Virtual Servers for VPCs and adds the IP address to the resource inventory.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-inventories-setup"},{"document_id":"ibmcld_13498-83087-84124","score":12.9722156525,"text":"\n-- all employees that work in a department that starts with letter C\nSELECT\nemp.col1 AS emp_id,\nemp.col2 AS emp_dept\nFROM VALUES\n(0, 'D01'),\n(2, 'C01'),\n(3, 'C02'),\n(4, 'D01'),\n(5, 'D02'),\n(6, 'C01'),\n(7, 'D01'),\n(8, 'C03'),\n(9, 'D01') AS emp\nWHERE emp.col2 LIKE 'C%'\n\nThe result of the example query is shown in the following table.\n\n\n\nTable 42. Query result for the example all\n\n EMP_ID EMP_DEPT \n\n 2 C01 \n 3 C02 \n 6 C01 \n 8 C03 \n\n\n\n-- all department names that do not start with letter C\nSELECT\nDISTINCT emp.col2 AS emp_dept\nFROM VALUES\n(0, 'D01'),\n(2, 'C01'),\n(3, 'C02'),\n(4, 'D01'),\n(5, 'D02'),\n(6, 'C01'),\n(7, 'D01'),\n(8, 'C03'),\n(9,'D01') AS emp\nWHERE emp.col2 NOT LIKE 'C%'\n\nThe result of the example query is shown in the following table.\n\n\n\nTable 43. Query result for example: all department names that do not start with letter C.\n\n EMP_DEPT \n\n D01 \n D02 \n\n\n\n\n\n\n\n RLIKE examples \n\n-- all rows that contain in col2 a value ending with 'bc'\nSELECT \nFROM VALUES\n(0, 'Abc'),\n(1, 'xyz abc'),\n(2, 'abcabcabc'),\n(3, 'abc xyzxyz abc'),","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_16666-10416-12326","score":12.7577962875,"text":"\n* Add the metadata catalogs to manage your table schemas.\n* Select the query engine to work with your data.\n\n\n\nComplete the following steps:\n\n\n\n1. In the Bucket configuration page, select Provision new IBM-managed bucket.\n2. Click Next. This displays the Catalogs configuration page.\n3. In the Catalogs configuration page, select a catalog.\n4. Click Next. This displays the Engine configuration page.\n5. In the Engine configuration page, select the Presto engine and smallest starter (1 coordinator node 1 worker node memory optimized).\n6. Click Next. This displays the Summary page.\n7. In the Summary page, review the configurations before you finish setting up your data infrastructure.\n\nWhen the setup is complete, the watsonx.data home page is displayed. You are all set to use the watsonx.data or you can configure it further.\n8. Click Finish and go. This displays the Infrastructure manager page.\n\n\n\nAlthough you can add more engines, catalogs, buckets, and databases in the Infrastructure manager page if you want to, this would change the consumption rate of your promo code. When you add items in the Infrastructure manager, you can see the resource unit consumption per hour.\n\nThe promotion credits consumption begins immediately after you configure and the support services are created for your metadata. Ensure that you pause the Presto engine when it is not used. This helps in optimizing the usage credit.\n\n\n\n\n\n Step 6: Ingesting data \n\nThe data files are ingested into watsonx.data using CLI. For the steps to perform ingestion, see the [Ingesting data through the command-line interface (CLI)](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-ingest_data_cli)\n\n\n\n\n\n Step 7: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_hp_intro"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2640681226,"ndcg_cut_10":0.2640681226}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00580-39512-41555","score":13.8693723679,"text":"\nThe Query is a standard JavaScript object, which is passed to the db.find function which it POSTs to the _find endpoint on your behalf.\n\nNow, time for a practical exercise. Devise your own IBM Cloudant Query that finds the titles of books that are written in the 20th Century. The IBM Cloudant Query documentation is at the on-screen URL if you need it.\n\nPause the presentation here if you don't want to know the answer...\n\nSee one solution:\n\nI use the $and operator to combine two clauses on the date attribute. One clause to locate documents whose date >= 1900, the other to find documents whose date is < the year 2000. Both clauses have to be true to select a document. As we need only the title of the matching books, we can supply a fields attribute instead of being returned the entire document.\n\nTo summarize, IBM Cloudant Query is a query language that is inspired by MongoDB where the syntax is expressed in JSON form.\n\nQueries select subsets of documents from the database by using clauses that operate on data inside the document - not just the document's _id.\n\nQueries are sent to the database's _find endpoint, either programmatically, by using curl, or by using the Dashboard.\n\nThe query's selector decides which cut of data is required,\n\nThat's the end of this part. The next part is called Indexing.\n\n\n\n\n\n\n\n Indexing video \n\nLearn how indexing can speed up your query process.\n\n\n\n* Indexing video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 11 - Indexing.\n\nThe queries that we executed in the previous part were not optimal: to get the answer, IBM Cloudant had to spool through every document in the database in turn to see whether it met with the search criteria.\n\nTo make queries that are run in a performant and scalable way, we need Indexing.\n\nWith IBM Cloudant, you can specify any number of Indexes (or indices).\n\nAn index is a secondary data structure that is built from the document list.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_07108-7-1958","score":12.3447761536,"text":"\nExpanding the meaning of queries \n\nYou can improve the quality of search results by expanding the meaning of the queries that are submitted by customers.\n\nTo expand the scope of a query beyond exact matches, add a synonyms list to your collection. When synonyms are defined, the customer does not need to submit an exact phrase or keyword that your project is trained to understand. Even variations of the term are recognized and used to find the best results. For example, you can expand a query for ibm to include international business machines and big blue. Query expansion terms are typically synonyms, antonyms, or common misspellings for terms.\n\nSynonyms that you add to improve the search results function differently from synonyms that you add to a dictionary. Dictionary synonyms are recognized and tagged at the time that a document is ingested. The synonyms that you define are recognized and tagged as occurrences of the associated dictionary term, so that they can be retrieved later by search. For more information about adding synonyms that are recognized when documents are processed, see [Dictionaries](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain-dictionary).\n\nYou can define two types of expansions:\n\nBidirectional\n: Each entry in the expanded_terms list expands to include all expanded terms. For example, a query for ibm expands to ibm OR international business machines OR big blue.\n\nBidirectional example:\n\n{\n\"expansions\": [\n{\n\"expanded_terms\":\n\"ibm\",\n\"international business machines\",\n\"big blue\"\n]\n}\n]\n}\n\nUnidirectional\n: The input_terms in the query is replaced by the expanded_terms. For example, a query for banana is converted to plantain OR fruit and does not contain the original term, banana. If you want an input term to be included in the query, then repeat the input term in the expanded terms list.\n\nUnidirectional example:\n\n{\n\"expansions\": [\n{\n\"input_terms\":\n\"banana\"\n],\n\"expanded_terms\":","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-settings"},{"document_id":"ibmcld_16653-0-871","score":12.0592050552,"text":"\n\n\n\n\n\n\n  Query history \n\nA query history audits all the current and past queries across the existing engines in IBM\u00ae watsonx.data.\n\nThe query history page in watsonx.data provides the following details that are related to the queries that are run:\n\n\n\n*  Query ID\n*  Query\n*  State\n*  Engine\n*  User\n*  Created\n\n\n\nIn the Query history page, you can search, refresh, filter, and customize the queries. You can select a Query from the page, view or copy the details of query statement, logical execution plan, and distributed execution plan. You can open the queries directly in a workspace, and also get the explain details of a query from the overflow menu of each query listed.\n\nFor more information about exporting and importing query history, see [Exporting and importing the query history](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-eximp-q-hist).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-query_history"},{"document_id":"ibmcld_07086-7-2167","score":11.9811792374,"text":"\nQuery overview \n\nIBM Watson\u00ae Discovery offers powerful content search capabilities through search queries.\n\nTo retrieve data from Discovery after it is ingested, indexed, and enriched, submit a query.\n\nAs data is added to Discovery, a representation of each file is stored in the index as a JSON-formatted document. Enrichments that are applied to your collections identify meaningful information in the data and store it in new fields in these documents. To search your data, submit a query to return the most relevant documents and extract the information you're looking for.\n\n\n\n Query types \n\nDiscovery accepts one of the following supported query types:\n\nQuery\n: Finds documents with values of interest in specific fields in your documents. Queries of this type use Discovery Query Language syntax to define the search criteria.\n\nParameter name: query\n\nNatural Language Query (NLQ)\n: Finds answers to queries that are written in natural language. NLQ requests accept a text string value.\n\nParameter name: natural_language_query\n\nAlong with the query that you specify by using one of the supported query types, you can include one or both of the following parameters. The values for these parameters are also specified by using the Discovery Query Language (DQL) syntax:\n\n\n\n* filter\n* aggregation\n\n\n\nFor more information about the Discovery Query Language, see [DQL overview](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-dql-overview).\n\nQueries that are submitted from the product user interface are natural language queries. A few other supported parameters are specified and given default values based on the project type in use. For more information, see [Default query settings](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-defaults).\n\nDiscovery does not log query request data. You cannot opt in to request logging.\n\n\n\n\n\n Choosing the right query type \n\nThe following table summarizes the capabilities that are supported for each query type. Use it to help you determine which type of query to submit.\n\n\n\nQuery types comparison\nThis table has row and column headers. The row headers identify query types.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-concepts"},{"document_id":"ibmcld_00522-1329-3028","score":11.9563760757,"text":"\nA query facility that allows a user to find a book by a known publisher and year.\n2. A general-purpose search engine that allows a user to find books by a combination of one or more of the following descriptors: author, title, year, and publisher.\n3. A report that details the number of books that are published by year.\n\n\n\n\n\n\n\n\n\n Step 2. Querying books by publisher and year - IBM Cloudant Query \n\nIBM Cloudant Query is a query language that allows small slices of a total database to be located. The following query finds 10 books that are published by Penguin in the year 2000:\n\n{\n\"selector\": {\n\"$and\": [\n{ \"publisher\": \"Penguin\" },\n{ \"year\": { \"$gt\": 2000 } }\n]\n},\n\"limit\": 10\n}\n\nThe query contains a selector object, which uses operators and text fields to define the slice of data you need:\n\n\n\n* $and means both of the query clauses must be satisfied for a document to make it to the result set.\n* { \"publisher\": \"Penguin\" }- the publisher must be \"Penguin\".\n* { \"year\": { \"$gt\": 2000 } } - the year must be greater than 2000. $gt means \"greater than\".\n\n\n\nWe can try the query by choosing \"Query\" when you view our books database in the IBM Cloudant Dashboard. You can paste in the query JSON and click Run Query.\n\n\n\n Running a query \n\nTo try the query, do the following steps:\n\n\n\n1. Go to IBM Cloudant Dashboard.\n2. Open the service instance that you created in the prerequisite section.\n3. Open the database that you created.\n4. Go to the Query tab.\n5. Paste the query JSON from the previous section into the Cloudant Query window.\n6. Click Run Query. See the results in the following screen capture:\n\nZoom\n\n![Run the query, and the results show the _id, author, pages, publisher, and year.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-dig-deeper-dashboard"},{"document_id":"ibmcld_07098-7-2215","score":11.8001804352,"text":"\nQuery parameters \n\nYou can use these parameters when you write queries with the Discovery Query Language. For more information, see the Discovery [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery-dataquery). For an overview of query concepts, see the [Query overview](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-concepts).\n\nQueries that are written in the Discovery Query Language can include both search and structure parameters.\n\nThe default values for query parameters can differ by project type. For more information about default values, see [Default query settings](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-defaults).\n\n\n\n Search parameters \n\nUse search parameters to search your collection, identify a result set, and analyze the result set.\n\nThe results set is the group of documents that are identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is submitted, the results set is equal to all the documents in the collection.\n\nDocuments that you do not have permissions to access are not returned in query results.\n\n\n\n\n\n Answer finding \n\nIBM Cloud\n\nThe find_answers parameter is supported in managed deployments only.\n\nBy default, Discovery provides answers by returning the entire [passage](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameterspassages) that contains the answer to a natural language query. When the answer-finding feature is enabled, Discovery also provides a \"short answer\" within the passage, and a confidence score to show whether the \"short answer\" answers the question that is explicit or implicit in the user query. Applications that use the answer-finding feature can display the short answer alone or can display the short answer emphasized in the context of the full passage. For most applications, displaying the short answer emphasized within the full passage is preferable, because answers generally make more sense in context.\n\nThe answer finding feature behaves in the following ways:\n\nIn the passage examples that follow, the short answers are shown in bold font.\n\n\n\n* Finds answers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"},{"document_id":"ibmcld_16662-0-1981","score":11.663775444,"text":"\n\n\n\n\n\n\n  Running SQL queries \n\nSQL is a standardized language for defining and manipulating data in a relational database. You can use the Query workspace interface in IBM\u00ae watsonx.data to run SQL queries and scripts against your data.\n\nThe Query workspace has the following components:\n\n\n\n*  Data objects: To view the engines, catalogs, schemas, tables, and columns.\n*  Engine: To select an engine and view the associated catalogs.\n*  Saved queries: To view the saved queries.\n*  Worksheet: To write SQL queries.\n\n\n\nThe Query workspace page provides basic options to undo, redo, cut, copy, paste, save, clear, and delete.\n\nFormat selection option is enabled only when an SQL statement in a query worksheet is selected. The Format worksheet option formats all the content in the worksheet. Comment selection is used to explain sections of SQL statements.\n\nThe Delete option is enabled only after an SQL query is saved.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select SQL. The Query workspace page opens.\n3.  Select an engine from the Engine drop-down.\n4.  Select the catalog, schema, table, or column in which you want to run the query.\n5.  Click the overflow menu and select the required query.\n\n\n\n*  For a catalog and schema, you can run the Generate Path query.\n*  For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n*  For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\n6.  Click the Save icon to save the query. A Save query confirmation dialog appears.\n7.  Click Save.\n8.  Click the Run button to run the query.\n9.  Select Result set or Details tab to view the results.\n10. Click Saved queries to view the saved queries.\n11. Click [Explain](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-run_sql"},{"document_id":"ibmcld_07190-7-1868","score":11.550693512,"text":"\nQuery operators \n\nOperators are the separators between different parts of a query. For the complete list of available operators, see the [Query reference](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceoperators).\n\n\n\n . [JSON delimiter] \n\nThis delimiter separates the levels of hierarchy in the JSON schema\n\nFor example:\n\nenriched_text.concepts.text\n\n\n\n\n\n : [Includes] \n\nThis operator specifies a match for the query term.\n\nFor example:\n\nenriched_text.concepts.text:\"cloud computing\"\n\n\n\n\n\n :: [Exact match] \n\nThis operator specifies an exact match for the query term.\n\nFor example:\n\nenriched_text.concepts.text::\"Cloud computing\"\n\nExact matches are case-sensitive.\n\n\n\n\n\n :! [Does not include] \n\nThis operator specifies that the results do not contain a match for the query term\n\nFor example:\n\nenriched_text.concepts.text:!\"cloud computing\"\n\n\n\n\n\n ::! [Not an exact match] \n\nThis operator specifies that the results do not exactly match the query term\n\nFor example:\n\nenriched_text.concepts.text::!\"Cloud computing\"\n\nExact matches are case-sensitive.\n\n\n\n\n\n \\ [Escape character] \n\nEscape character for queries that require the ability to query terms by using string literals that contain control characters.\n\nFor example:\n\ntitle::\"Dorothy said: \"There's no place like home\"\"\n\n\n\n\n\n \"\" [Phrase query] \n\nAll contents of a phrase query are processed as escaped. So no special characters within a phrase query are parsed, except for double quotes (\") inside a phrase query, which must be escaped (\"). Use phrase queries with full-text, rank-based queries, and not with boolean filter operations. Do not use wildcards () in phrase queries.\n\nSingle quotes (') are not supported.\n\nFor example:\n\nenriched_text.entities.text:\"IBM watson\"\n\n\n\n\n\n (), [] [Nested grouping] \n\nLogical groupings can be formed to specify more specific information.\n\nFor example:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators"},{"document_id":"ibmcld_00644-7-2122","score":11.4899787903,"text":"\nUsing Views \n\nUse views to search for content within a database that matches specific criteria. The criteria are specified within the view definition.\n\nCriteria can also be supplied as arguments when you use the view.\n\n\n\n Querying a view \n\nTo query a view, submit a GET request with the following format:\n\nMethod\n: Issue a partition query by using the following command, GET $SERVICE_URL\/$DATABASE\/_partition\/$PARTITION_KEY\/_design\/$DDOC\/_view\/$VIEW_NAME. Or issue a global query by using the following command, GET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME.\n\nRequest\n: None\n\nResponse\n: JSON of the documents that are returned by the view.\n\nRoles permitted\n: _reader\n\nThe request runs either:\n\n\n\n* The specified $VIEW_NAME from the specified $DDOC design document within the $DATABASE database, which is constrained to results within the specified $PARTITION_KEY data partition.\n* The specified $VIEW_NAME from the specified $DDOC design document within the $DATABASE database.\n\n\n\nThe examples in this document vary between partition and global queries for illustrative purposes. Unless otherwise noted, modifying the path to embed or remove the partition name works for any view query type.\n\n\n\n Query and JSON Body Arguments \n\nGlobal queries can use all query and JSON body arguments. Partition queries can use only the subset that is indicated in the table.\n\n\n\nTable 1. Subset of query and JSON body arguments available for partitioned queries\n\n Argument Description Optional Type Default Supported values Partition query \n\n conflicts Specify whether to include a list of conflicted revisions in the _conflicts property of the returned document. Ignored if include_docs isn't set to true. Yes Boolean False Yes \n descending Return the documents in descending by key order. Yes Boolean False Yes \n end_key Stop returning records when the specified key is reached. Yes String or JSON array Yes \n end_key_docid Stop returning records when the specified document ID is reached. Yes String Yes \n group Specify whether to group reduced results by key. Valid only if a reduce function is defined in the view.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_07178-7-2162","score":11.4607744217,"text":"\nQuery concepts \n\nIBM Watson\u2122 Discovery offers powerful content search capabilities. Once your content is uploaded and enriched by Discovery, you can build queries, then integrate Discovery into your own projects, or create a custom application by using the Watson Explorer Application Builder.\n\nThe queries you write vary by collection because all collections contain unique content.\n\nWhen you create a query or filter, Discovery looks at each result and tries to match the paths you define. When matches occur, they are added to the results set. When creating a query, you can be as vague or as specific as you want. The more specific the query, the more targeted the results.\n\nYou can write natural language queries (such as \"IBM Watson partnerships\") using the Discovery tooling or the API.\n\n\n\n Default query behavior \n\n\n\n* Stemming is applied to queries by default, which means that results match the root form of words. In contrast, stemming does not allow for matching on any arbitrary substring of a term. For example, words such as \"connections,\" \"connective,\" and \"connected\" are reduced to \"connect.\" But words such as \"boatbuilding,\" \"boathouse,\" and \"boatload,\" are not reduced to \"boat.\"\n* Tokenization occurs using a set of standard separators per language including whitespace, hyphen, underscore, and punctuation marks for English. For more information, see [Creating custom tokenization dictionaries](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptstokenization).\n* All private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* Discovery returns query results that include special characters for the following languages: English, German, French, Dutch, Italian, and Portuguese. For example, if you query for aqui, you receive results for both aqui and aqu\u00ed.\n\n\n\n\n\n\n\n Options for querying \n\n\n\n* You have the option to turn on passage retrieval. Passages are short, relevant excerpts extracted from the full documents returned by your query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.8772153153,"ndcg_cut_10":0.8772153153}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07214-57536-59639","score":16.8160266876,"text":"\nImproved query and add functions at top level : id, score, and highlight at the top level (You can continue to add documents to your collection using document IDs with the add a document function. See the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/discoveryadd-a-document) for details. : _ prefixed field names at the top level (as a result, when querying for a document by ID, you can query for id instead of _id.) : and , in the field name : + and - prefixed field names : \"\" empty values for a field name : If your JSON documents include these characters in the field names, or id, score, and highlight at the top level, you need to remove them before adding the documents to your collection, or those fields are empty. You can create a custom configuration and normalize your JSON before adding documents to your collection to avoid this issue. See the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discoveryadd-configuration) for details. In addition, documents that include the punctuation characters ?, :, or in the file name cause errors during ingestion. Before ingesting them, rename any documents that include these characters.\n\nImproved 'natural_language_query' retrieval methods : The retrieval methods for natural_language_query are updated to improve the relevance of results by matching words with related semantics. This update only affects collections that did not undergo relevance training. If you are using natural_language_query and did not conduct relevance training, you might see improvement in the order of results returned.\n\nImproved query builder navigation : Changes to the query builder to make it easier to toggle between the Discovery Query Language and Natural Language query options, as well as among query, filter, and aggregation.\n\n\n\n\n\n 25 August 2017 \n\nImproved 'passages' array : The passages array now includes field, start_offset, and end _offset. field is the name of the field the passage was extracted from. start_offset is the starting character of the passage text within the field. end_offset is the ending character of the passage text within the field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07163-1627-3707","score":16.7337875366,"text":"\nSee [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.\n\nSee [Training data requirements](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-apireqs) for the minimum requirements for training, as well as the training limits.\n\nSee [Usage monitoring](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-usage) for details on tracking usage and using this data to help you understand and improve your applications.\n\nThe components needed to train a Discovery instance include the following:\n\n\n\n* Training data. This is the set of queries and examples the service uses to refine query results.\n* Query. A natural-language query that applies to the training-data set. Each query has one or more associated examples, as described in the following bullet point. Each query must be unique within the training-data set.\n* Example. This is a document indexed in a Discovery collection that acts as an exemplar, good or bad, for the associated query. When you add an example to a training-data query, you include a relevance label that indicates the relevance (or \"goodness\" versus \"badness\") of the document as it applies to the specified query.\n\nExamples are identified by the indexed document ID. As noted, every example must include a label that indicates the \"goodness\" or \"badness\" of the document as it pertains to the query.\n\nExamples can optionally specify a cross-reference query. The cross-reference query needs to return only the example document and must be independent of the unique Watson Discovery document ID. Cross-reference queries are not currently used automatically but can be used to repair training data in the event that new IDs are assigned to documents during an ingestion event.\n\n\n\n\n\n Training data requirements","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"},{"document_id":"ibmcld_07042-8099-9796","score":16.3873310089,"text":"\nFor more information about SDU, see [Using Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-configuring-fields).\n10. Click Manage fields.\n\nThe Manage fields page lists the indexed fields. From here, you can include or remove fields from the index. You can also split large documents into many smaller documents.\n\nZoom\n\n![Shows the fields in the index.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/gs-sample-field-index.png)\n\nFigure 10. Fields in the collection index\n\nFor more information about splitting documents, see [Splitting documents to make query results more succinct](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-split-documents).\n\n\n\n\n\n\n\n Step 4: Search the sample project \n\n\n\n1. Click the Improve and customize icon from the navigation panel.\n\nThe Improve and customize page is where you can try out queries, then add and test customizations to improve the query results for your project. A list of sample queries is displayed to help you get started with submitting test queries.\n2. Click the Run search button forIBM.\n\nQuery results are displayed.\n3. From one of the query results, click View passages in document.\n\nA preview of the document where the result was found is shown.\n4. Do one of the following things to explore the search result.\n\nIBM Cloud\n\n\n\n1. Click Open advanced view.\n\nUseful summary information is displayed, such as the number of occurrences of any enrichments that are detected in the document.\n2. Select the URL entity to highlight mentions of URLs within the text.\n\nZoom\n\n![Shows the advanced text view with URL entities highlighted.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-getting-started"},{"document_id":"ibmcld_07175-7-2035","score":16.3811149597,"text":"\nViewing metrics and improving query results with the Performance dashboard \n\nThe Performance dashboard in the Discovery tooling can be used to view query metrics, as well as improve query results, including query relevance.\n\nYou can access the Performance dashboard by clicking the View data metrics icon. The dashboard is not available in Premium or Dedicated environments.\n\nThere are two options to improve natural language query results:\n\n\n\n* [Fix queries with no results by adding more data](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboardaddmore)\n* [Bring relevant results to the top by training your data](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboardtraindata)\n\n\n\nYou can view the data metrics in the [query overview](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboardoverview).\n\n\n\n Fix queries with no results by adding more data \n\nIn this section of the dashboard, you can review queries that returned zero results and add more data so that the query returns results in the future. Click the View all and add data button to get started.\n\n\n\n\n\n Bring relevant results to the top by training your data \n\nIn this section, you can train your collections to improve the relevance of natural language query results. Click the View all and perform relevancy training button to get started. Then see [Adding queries and rating the relevancy of results](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingresults) for instructions.\n\nFor more about training requirements and options, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n Query overview \n\nThe Query overview section displays:\n\n\n\n* The total number of queries made by users\n* The percentage of queries with one or more results clicked\n* The percentage of queries with no results clicked\n* The percentage of queries with no results returned","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboard"},{"document_id":"ibmcld_07108-7-1958","score":16.3035774231,"text":"\nExpanding the meaning of queries \n\nYou can improve the quality of search results by expanding the meaning of the queries that are submitted by customers.\n\nTo expand the scope of a query beyond exact matches, add a synonyms list to your collection. When synonyms are defined, the customer does not need to submit an exact phrase or keyword that your project is trained to understand. Even variations of the term are recognized and used to find the best results. For example, you can expand a query for ibm to include international business machines and big blue. Query expansion terms are typically synonyms, antonyms, or common misspellings for terms.\n\nSynonyms that you add to improve the search results function differently from synonyms that you add to a dictionary. Dictionary synonyms are recognized and tagged at the time that a document is ingested. The synonyms that you define are recognized and tagged as occurrences of the associated dictionary term, so that they can be retrieved later by search. For more information about adding synonyms that are recognized when documents are processed, see [Dictionaries](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain-dictionary).\n\nYou can define two types of expansions:\n\nBidirectional\n: Each entry in the expanded_terms list expands to include all expanded terms. For example, a query for ibm expands to ibm OR international business machines OR big blue.\n\nBidirectional example:\n\n{\n\"expansions\": [\n{\n\"expanded_terms\":\n\"ibm\",\n\"international business machines\",\n\"big blue\"\n]\n}\n]\n}\n\nUnidirectional\n: The input_terms in the query is replaced by the expanded_terms. For example, a query for banana is converted to plantain OR fruit and does not contain the original term, banana. If you want an input term to be included in the query, then repeat the input term in the expanded terms list.\n\nUnidirectional example:\n\n{\n\"expansions\": [\n{\n\"input_terms\":\n\"banana\"\n],\n\"expanded_terms\":","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-settings"},{"document_id":"ibmcld_07163-7-1995","score":16.2534580231,"text":"\nImproving result relevance with the API \n\nYou can train Discovery to improve the relevance of query results for your particular organization or subject area. When you provide a Discovery instance with training data, the service uses machine-learning Watson techniques to find signals in your content and questions. The service then reorders query results to display the most relevant results at the top. As you add more training data, the service instance becomes more accurate and sophisticated in the ordering of results it returns.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nFor comprehensive information about the training APIs, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery).\n\nIf you would prefer to use the Discovery tooling to train Discovery, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nTrained collections return a confidence score in the result of a natural language query. See [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"},{"document_id":"ibmcld_07045-7-2118","score":15.9649810791,"text":"\nImproving your query results \n\nLearn about actions you can take to improve the quality of your query results.\n\nYou can use the tools that are built in to Discovery to make improvements.\n\n\n\n Results include more than exact matches \n\nUnlike some other search applications, adding quotation marks to a phrase that you submit does not return only exact matches. Queries that are submitted from the product user interface are natural language queries. When quoted text is submitted in a natural language query, the phrase is used to boost result scores. However, results are not limited to documents that contain the entire phrase.\n\nIf you want more control over how queries are handled, you must use the query API. For more information about the phrase operator of the query API, see [Query operators](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsphrase).\n\n\n\n\n\n A short query returns irrelevant results \n\nIt might be that your query contains too many stop words and not enough distinct terms to trigger a meaningful search. When you submit a query, the query text is analyzed and optimized before it is submitted to the project. One of the changes that occurs is the removal of any stop words from the text. A stop word is a word that is considered to be not useful in distinguishing the semantic meaning of the content. Examples of stop words include terms such as and, the, and about. Discovery defines a list of stop words that it ignores automatically both when the data is indexed and when it is searched. When you submit a query that contains mostly or only stop words, such as About us, it is equivalent to submitting an empty query.\n\nAlthough us is not included in the stop words list, it is lemmatized to we, which is listed as a stop word.\n\nYou can edit the stop words that are used by your collection. However, you can only augment the stop words list; you cannot remove stop words. And the stop words that you define are used only at query time. They do not affect the stop word list that is used by Discovery when data is added to a collection and the index is created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-improvements"},{"document_id":"ibmcld_13075-7-2200","score":15.7161169052,"text":"\nImproving result relevance with the tooling \n\nThe relevance of natural language query results can be improved in IBM Watson\u2122 Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. See [Improving the relevance of your query results with the API](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api) if you would prefer to use the APIs.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nTo train Watson, you must provide the following:\n\n\n\n* Example queries that are representative of the queries your users enter\n* Ratings that indicate which results for each query are relevant and not relevant\n\n\n\nAfter Watson has enough training input, the information that you provide about which results are good and bad for each query is used to learn about your collection. Watson does not just memorize, but it also learns from the specific information about individual queries and applies the patterns it detects to all new queries. It does so, using machine-learning Watson techniques that find signals in your content and questions. After training, Discovery then reorders the query results to display the most relevant results at the top. As you add more and more training data, Discovery becomes more accurate in the ordering of query results.\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"},{"document_id":"ibmcld_07176-1848-3996","score":15.6854686737,"text":"\nThere are many ways to run queries against Discovery and the different operations used can impact performance. These query characteristics can impact performance:\n\n\n\n1. Length - Longer queries most likely have poorer performance.\n2. Aggregations - Aggregations are a more complex query type, with nested aggregations having the highest impact on performance.\n3. Operators - Wldcarding and fuzzy matching can impact performance.\n4. Counts - Reducing the count of documents returned can improve performance; if you need to page through results, use the offset parameter.\n5. Return fields - Limiting the fields returned to only those needed for your application can help (For example, don\u2019t return the full text of the document if only the title and passage are needed.)\n\n\n\nSee [Query reference](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-reference) for details.\n\n\n\n\n\n Features used \n\nThere are a number of features that enhance query results. The following features can impact performance:\n\n\n\n1. Passage Retrieval - Passage retrieval searches within documents to find relevant snippets of text for your query. Use the passages.fields parameter to adjust which fields in the documents that passage retrieval searches. The parameter can help reduce the latency of passage retrieval when your content has many fields. For more information about passage retrieval, see [Passages](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameterspassages).\n2. Relevancy Training - Relevancy training computes features for each top-level text field (fields at the same level as document_id in the JSON) in the collection. If there are many top level fields, this can cause a performance impact for a natural_language_query when using training. Reducing the number of top level fields can improve performance. This can be done via normalization or by manually editing the JSON to put fields that are not helpful to finding relevant content in a nested structure. Changing the fields used for training also has an impact on the model so you\u2019ll need to consider both the impact to performance and accuracy of results if making this change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-qp"},{"document_id":"ibmcld_07115-7009-9068","score":15.6661205292,"text":"\n* The rating that you apply to the result that indicates whether the result is relevant or not relevant\n\n\n\nTo apply relevancy training to a project, complete the following steps:\n\n\n\n1. Go to the Improve and customize page. On the Improvement tools panel, select Improve relevance, then Relevancy training.\n2. Enter a natural language query in the Enter a question to train field.\n\nDo not include a question mark in your query. Use the same wording as your users. For example, IBM Watson in healthcare. Write queries that include some of the terms that are mentioned in the target answer. Term overlap improves the initial results when the natural language query is evaluated.\n3. Click Add+.\n4. Click Rate results.\n5. After the results are displayed, assess each result, and then select Relevant or Not relevant, whichever option applies given the quality of the result.\n\nWhen you select Relevant, you apply a score of 10 to the result. Not relevant applies a score of 0. You can use a different scoring scale if you use the API to rate results, but you can't mix scoring scales within the same project.\n\nIf the result shows the message, \u201cNo content preview available for this document\u201d, it means that the document that was returned does not contain a text field or that its text field is empty. If none of the documents in your collection have a text field, use the API to train the project instead of training it from the product user interface.\n6. When you are finished, click Back to queries.\n7. Continue adding queries and rating them.\n\nAs you rate results, your progress is shown. Check your progress to see when enough rating information is available to meet the training threshold needs. Your progress is broken into the following tasks:\n\n\n\n* Add more queries\n* Rate more results\n* Add more variety to your ratings\n\n\n\nYou must evaluate at least 50 unique queries, maybe more, depending on the complexity of your data. You cannot add more than 10,000 training queries.\n8. You can continue adding queries and rating results after you reach the threshold.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-train"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.2,"recall_5":0.4,"recall_10":0.8,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.3451913422,"ndcg_cut_10":0.5652378764}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07068-19814-21296","score":16.7072219849,"text":"\nGet details about a query [GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data\/{query_id}](https:\/\/cloud.ibm.com\/apidocs\/discoverygettrainingdata) [GET \/v2\/projects\/{project_id}\/training_data \/queries\/{query_id}](https:\/\/cloud.ibm.com\/apidocs\/discovery-datagettrainingquery) \n Delete a training data query [DELETE \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data\/{query_id}](https:\/\/cloud.ibm.com\/apidocs\/discoverydeletetrainingdata) [DELETE \/v2\/projects\/{project_id}\/training_data \/queries\/{query_id}](https:\/\/cloud.ibm.com\/apidocs\/discovery-datadeletetrainingquery) \n List examples for a training data query [GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data\/{query_id}\/examples](https:\/\/cloud.ibm.com\/apidocs\/discoverylisttrainingexamples) [GET \/v2\/projects\/{project_id}\/training_data \/queries\/{query_id}](https:\/\/cloud.ibm.com\/apidocs\/discovery-datagettrainingquery) <br>The examples are in the list that is returned with the query. \n Add example to training data query [POST \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data\/{query_id}\/examples](https:\/\/cloud.ibm.com\/apidocs\/discoverycreatetrainingexample) [POST \/v2\/projects\/{project_id}\/training_data \/queries\/{query_id}](https:\/\/cloud.ibm.com\/apidocs\/discovery-dataupdatetrainingquery) <br>Use the Create training query method in v2 and pass all examples when you create the query. Otherwise, use the update API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api"},{"document_id":"ibmcld_13818-11430-13253","score":16.6045780182,"text":"\nQuery parameters Details \n\n version <br>Required <br>string Requests the version of the API as of a date in the format YYYY-MM-DD. Any date up to the current date can be provided. Specify the current date to request the latest version. <br>Possible values: Value must match regular expression ^[0-9]{4}-[0-9]{2}-[0-9]{2}$ \n\n\n\n\n\nTable 3. Request body attributes for adding prefix filters\n\n Request body Details \n\n action <br>Required <br>string Whether to permit or deny prefix filter. <br>Possible values: [permit,deny] <br>Example: permit \n prefix <br>Required <br>string IP prefix and subnet mask <br>Example: 192.168.100.0\/24 \n before <br>string Identifier of prefix filter to handle the ordering and follow semantics:<br><br><br><br> * When a filter reference another filter in it's before field, then the filter making the reference is applied before the referenced filter. For example: if filter A references filter B in its before field, A is applied before B.<br> * When a new filter is added that has the same before as an existing filter, then the older filter has its before field updated to point to the new filter. Starting with the above example: if filter C is added and it references B in its before field, then A's before field should be modified to point to C, so the order of application would be A, C and finally B.<br> * A filter that has an empty before reference is applied last (though the date order mentioned still applies). So continuing the preceding examples, if filter B has an empty before field, then it is applied last, but if filter D is created with an empty before field, then B's before field is modified to point to D, so B is applied before D. <br> Example: 1a15dcab-7e40-45e1-b7c5-bc690eaa9782<br><br><br> \n ge <br>integer IP prefix greater than or equal to this number is processed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/transit-gateway?topic=transit-gateway-adding-prefix-filters"},{"document_id":"ibmcld_03800-5111-6803","score":16.0657348633,"text":"\nYou can programmatically view your usage by calling the [IBM Cloud Usage Reports API](https:\/\/cloud.ibm.com\/apidocs\/metering-reportingget-account-usage). You can base the query in your API call on an account, org, resource group, or resource instance.\n\nThe following examples show queries that you can use to view account level usage:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X GET -H \"Authorization: {iam_token}\" -H \"Accept: application\/json\" \"{base_url}\/v4\/accounts\/{account_id}\/usage\/{billingmonth}\"\n\nServiceCall<AccountUsage> getAccountUsage(GetAccountUsageOptions getAccountUsageOptions)\n\nget_account_usage(self,\naccount_id: str,\nbillingmonth: str,\n,\nnames: bool = None,\naccept_language: str = None,\nkwargs\n) -> DetailedResponse\n\n(usageReports UsageReportsV4) GetAccountUsage(getAccountUsageOptions GetAccountUsageOptions) (result AccountUsage, response core.DetailedResponse, err error)\n\ngetAccountUsage(params)\n\n\n\n\n\n Exporting your usage details to a .csv file \n\nYou can export a summary of your account's usage, or information about your services and instances, to a CSV file. By exporting your CSV file, you can easily find usage and cost information estimates for each resource for chargebacks to your customers or to understand more about your costs. Because the report includes usage data for the entire account, you need Administrator access on the Billing service to export usage details.\n\nThis is not an estimate of your final bill. Instance costs don\u2019t reflect your final bill because other charges or discounts might be applied to your account.\n\n\n\n1. In the console, go to Manage > Billing and usage, and select Usage.\n2. Click Export CSV and select one of the options:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage"},{"document_id":"ibmcld_00331-35683-37392","score":16.0485858917,"text":"\nReturns the real-time metrics for the current account, including the total data (bandwidth and hits) over the given period of time and the detailed data divided with the given time interval. For more details, [View the examples](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-code-examples-using-the-cdn-apiexample-code-for-getting-real-time-metrics).\n\n\n\n* Parameters:\n\n\n\n* vendorName - The name of the CDN provider. Currently, only akamai is supported.\n* startTime - The start time timestamp (UTC+0) for query. The start time must be later than 48 hours ago. For example, if it's 9:00 AM 08 March 2020 now, the start time should be later than 9:00 AM 06 March 2020 in the same time zone(The timestamp should be more than 1583485200).\n* endTime - The end time timestamp (UTC+0) for query must be later than the start time.\n* timeInterval - An optional parameter to provide the time interval in seconds. The time interval must be a multiple of 60 and should be less than the time range from start time to end time.\n\n\n\n* Return - A collection of objects of type SoftLayer_Container_Network_CdnMarketplace_Metrics.\n\n\n\n--------------------\n\n\n\n\n\n getMappingRealTimeMetrics \n\nReturns the real-time metrics for the given mapping, including the total data (bandwidth and hits) over the given period of time and the detailed data divided with the given time interval. For more details, [View the examples](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-code-examples-using-the-cdn-apiexample-code-for-getting-real-time-metrics).\n\n\n\n* Parameters:\n\n\n\n* mappingUniqueId - Unique ID of the mapping for which metrics are queried.\n* startTime - The start time timestamp (UTC+0) for query. The start time must be later than 48 hours ago.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-cdn-api-reference"},{"document_id":"ibmcld_07214-74576-76512","score":16.0234508514,"text":"\nNew support for 'sort' parameter in the query API : The query API (GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query) now supports the sort parameter, which enables you to specify a comma-separated list of fields in the document to sort on. See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information.\n\nImproved handling by 'timeslice' parameter : The timeslice parameter for query aggregations now correctly handles dates in UNIX epoch format. See [Query reference](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceaggregations) for information about aggregations and the timeslice parameter.\n\nUpdate to JavaSDK : The Discovery Java SDK has been updated. See the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/discovery?language=java) for details.\n\nFixed known issues with wildcard limitations in queries : Only one wildcard worked in any given query. For example, query-month:ctober worked, but query-month:ctobe generated a parsing error. This is resolved. : Wildcards did not work with queries that contained capital letters. For example, given the key\/field pair {\"borrower\": \"GOVERNMENT OF INDIA\"}, query-borrower:ndia returned results but query-borrower:NDIA did not. This is resolved. : Wildcards are not necessary within phrases in queries. For example, given the key\/field pair {\"borrower\": \"GOVERNMENT OF TIMOR\"}, query-borrower:\"GOVERNMENT OF TIMOR\" returns results, but query-borrower:\"GOVERNMENT OF TIOR\" does not. Using a wildcard is not applicable within phrases because all of the characters within the quotation marks (\") of a phrase are escaped.\n\n\n\n\n\n 24 March 2017 \n\nNew feature for My data insights : Added filtering to the \"My data insights\" screen in the Discovery tooling.\n\n\n\n\n\n 15 March 2017 \n\nKnown issues : All fields that are ingested from HTML, PDF, and Word documents are typed as string.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_06308-0-500","score":15.7600669861,"text":"\n\n\n\n\n\n\n  APIs and SDKs \n\nWatson Query provides REST APIs that you can use to interact with your instance.\n\nTo access data, view and create database objects, administer, and monitor your service, use the [Watson Query APIs](https:\/\/cloud.ibm.com\/apidocs\/data-virtualization-on-cloud).\n\nThe following Watson Query SDKs are supported by IBM:\n\n\n\n*  [Go SDK](https:\/\/github.com\/IBM\/data-virtualization-on-cloud-go-sdk\/)\n*  [Java SDK](https:\/\/github.com\/IBM\/data-virtualization-on-cloud-java-sdk\/)\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/data-virtualization?topic=data-virtualization-con_rest_api"},{"document_id":"ibmcld_12561-6595-8106","score":15.7322444916,"text":"\nYou can get usage reports from an enterprise and its accounts by calling the [Enterprise Usage Reports API](https:\/\/cloud.ibm.com\/apidocs\/enterprise-apis\/resource-usage-reports). You can base the query in your API call on an enterprise, an account group, or an account and specify whether to view the entity or its children.\n\nThe following examples show queries that you can use to get different usage reports. When you call the API, replace the ID variables and IAM token with the values from your enterprise.\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X GET 'https:\/\/enterprise.cloud.ibm.com\/v1\/resource-usage-reports?enterprise_id=abc12340d4bf4e36b0423d209b286f24&month=2019-07' -H 'Authorization: Bearer <IAM Token>'\n\nServiceCall<Reports> getResourceUsageReport(GetResourceUsageReportOptions getResourceUsageReportOptions)\n\nget_resource_usage_report(self,\n,\nenterprise_id: str = None,\naccount_group_id: str = None,\naccount_id: str = None,\nchildren: bool = None,\nmonth: str = None,\nbilling_unit_id: str = None,\nlimit: int = None,\noffset: str = None,\nkwargs\n) -> DetailedResponse\n\n(enterpriseUsageReports EnterpriseUsageReportsV1) GetResourceUsageReport(getResourceUsageReportOptions GetResourceUsageReportOptions) (result Reports, response core.DetailedResponse, err error)\n\ngetResourceUsageReport(params)\n\n\n\n\n\n Exporting your enterprise usage details to a .csv file \n\nYou can export a summary of your account's usage, child account usage, or information about your services and instances, to a CSV file.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-usage"},{"document_id":"ibmcld_07096-7067-8508","score":15.6737775803,"text":"\n\"query\":\"enriched_text.entities.text:IBM^3\"\n}\n\n\n\n\n\n * (Wildcard) \n\nMatches unknown characters in a search expression. Do not use capital letters with wildcards.\n\nFor example:\n\n{\n\"query\":\"enriched_text.entities.text:ib\"\n}\n\n\n\n\n\n n (String variation) \n\nThe number of character differences that are allowed when matching a string. The maximum variation number that can be used is 2.\n\nFor example, the following query returns documents that contain car in the title field, as well as cap,cat,can, sat, and so on:\n\n{\n\"query\":\"title:cat1\"\n}\n\nThe normalized version of the word is used for matching. Therefore, if the input contains \"cats\", the search looks for \"cat\", which is the normalized form of the plural cats.\n\nWhen a phrase is submitted, each term in the phrase is allowed the specified number of variations. For example, the following input matches cat dog and far log in addition to car hog.\n\nFor example:\n\n{\n\"query\":\"title:\"car hog\"1\"\n}\n\n\n\n\n\n :* (Exists) \n\nUsed to return all results where the specified field exists.\n\nFor example:\n\n{\n\"query\":\"title:\"\n}\n\n\n\n\n\n :!* (Does not exist) \n\nUsed to return all results that do not include the specified field.\n\nFor example:\n\n{\n\"query\":\"title:!\"\n}\n\nFor more information, see the Discovery [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery-dataquery).\n\nFor an overview of query concepts, see the [Query overview](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-concepts).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operators"},{"document_id":"ibmcld_07242-7-2087","score":15.617934227,"text":"\nUsage monitoring \n\nYou can monitor and track usage of your Discovery instance and use this data to help you understand and improve your applications. The [Events API](https:\/\/cloud.ibm.com\/apidocs\/discoverycreate-event) can be used to create log entries that are associated with specific natural language queries and actions. For example, you can record which documents in a results set were \"clicked\" by a user, and when that click occurred.\n\nLogs and events are monitored only for natural language queries on private data collections. No logs are gathered on IBM Watson\u2122 Discovery News.\n\nDiscovery can log the following information:\n\n\n\n* Queries - Natural language queries run against collections in your environment\n* Impressions (or Results) - The results returned for a particular query, usually documents or passages\n* Events - Interactions a user performs on a result or set of results in Discovery (for example, a click on a document result)\n\n\n\nQueries and Impressions are logged automatically; Events logging can be integrated into your application via the API.\n\n\n\n Viewing the logs \n\nYou can search the query and event log to find query sessions that match the specified criteria. Searching the logs endpoint uses the standard Discovery query syntax for the parameters that are supported. The endpoint provides basic query functionality for viewing and searching through the recorded data.\n\nThe \/api\/v1\/logs endpoint supports the following Discovery query parameters.\n\n\n\n* query\n* filter\n* sort\n* count\n* offset\n* version\n\n\n\nFor additional details on the function and syntax for the parameters see [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters).\n\nExample of searching logs for a natural language query that contains the term \u201ctrain\u201d:\n\n{url}\/v1\/logs?version=2019-04-30&query=train\n\nReplace {url} with your URL.\n\nThe response of a logs query includes results that appear similar to Discovery document results. Each result is either a query or event, specified in the document type field.\n\nExample query log:\n\n{\n\"customer_id\": \"\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-usage"},{"document_id":"ibmcld_07068-9316-11113","score":15.5880079269,"text":"\nYou can get status information for a specific document by using the [Get document details](https:\/\/cloud.ibm.com\/apidocs\/discovery-datagetdocument) method. <br>The objects document_counts, disk_usage, training_status, and crawl_status are not present in the response body in v2. Training status is returned in the Get project method response. The other information is not available in v2. For example, you cannot get the document count for a collection and cannot get the crawl status for a collection that connects to an external data source in v2. In v2, you can get information about the enrichments that are applied to the collection. \n Update a collection v2 uses POST instead of PUT. In v2, you can update the enrichments that are applied to the documents in the collection by specifying an optional enrichments object. <br>The v2 response doesn't include the status and configuration_id fields. \n\n\n\n\n\n\n\n\n\n Query modifications \n\nThe method that was available in v1 for configuring tokenization programmatically is not supported in the v2 API.\n\n\n\nQuery modifications API support details\n\n v1 API v2 API \n\n [Tokenization dictionary API](https:\/\/cloud.ibm.com\/apidocs\/discoverycreatetokenizationdictionary) Not available. \n [Expansions v1 API](https:\/\/cloud.ibm.com\/apidocs\/discoverylistexpansions) [Expansions v2 API](https:\/\/cloud.ibm.com\/apidocs\/discovery-datalistexpansions) \n [Stopwords v1 API](https:\/\/cloud.ibm.com\/apidocs\/discoverygetstopwordliststatus) [Stopwords v2 API](https:\/\/cloud.ibm.com\/apidocs\/discovery-datagetstopwordlist) \n\n\n\n\n\n\n\n Documents \n\n\n\nDocuments API support details\n\n Action v1 API v2 API \n\n List documents Not available from the v1 API [GET \/v2\/projects\/{project_id}\/collections\/{collection_id}\/documents](https:\/\/cloud.ibm.com\/apidocs\/discovery-datalistdocuments)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1390561795}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16551-0-1579","score":19.7458133698,"text":"\n\n\n\n\n\n\n  How can I address storage space limits? \n\nDepending on your subscription plan, you might reach the storage limit that is specified for your plan and be prevented from completing tasks.\n\n  What\u2019s happening \n\nYou might see a message about exceeding the allowed storage space when you attempt to perform one of these tasks:\n\n\n\n*  Upload documents or dictionaries\n*  Deploy a model or version a model\n*  Run a pre-annotator on documents\n\n\n\n  Why it\u2019s happening \n\nThe storage limit is met or exceeded if the action proceeds.\n\n  How to fix it \n\nThe largest consumers of storage space are machine learning and rule-based models. To free up space, you can take the following actions:\n\n\n\n*  Delete snapshot versions of any models that you do not expect to need to revert to.\n*  Delete any models that you do not need.\n*  If your models are too important to delete, consider upgrading your plan to one that provides a larger allotment of storage space.\n\n\n\nAfter you remove models or model versions, wait an hour before you retry the action that resulted in the error message. It can take up to an hour for the storage space that you freed up to be available for use.\n\nTo manage your monthly bill, if the Admin role is assigned to you and you have a Premium or Standard account, you can set a storage limit on the Service Details page in Knowledge Studio. To see the Service Details page and set the storage limit, from the top navigation bar in Knowledge Studio, click the Settings icon, click the View\/modify service details link, and then click the Set storage limit link.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_ts_storage"},{"document_id":"ibmcld_00241-13788-15540","score":17.9439105988,"text":"\n-h, --help Show this message and exit.\n\nIf you're using the replication feature, be sure that the schedule you're deleting isn't the schedule that is used by replication. For more information about deleting a replication schedule, see [Replicating Data](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-replication).\n\n\n\n\n\n Deleting a snapshot in the UI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. Deletion is done through Storage > Block Storage for Classic.\n\n\n\n1. Click your storage volume and click Snapshot to see the list of existing snapshots.\n2. Click Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/14cf2f2f32b430cf4ed67ad14b3cecc010f91c45\/icons\/action-menu-icon.svg) next to a particular snapshot and click Delete. Click the confirmation box that warns about possible data loss, then click Delete. This deletion doesn't affect any future or past snapshots on the same schedule as snapshots don't depend on each other.\n\n\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations (oldest first).\n\n\n\n\n\n Deleting a snapshot from the SLCLI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. You can delete a snapshot from the SLCLI by using the following command.\n\n slcli block snapshot-delete\nUsage: slcli block snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingSnapshots"},{"document_id":"ibmcld_15078-2736-4706","score":17.9402885437,"text":"\nYou can configure up to 300 Block Storage for VPC volumes per account in a region. You can request to increase this quota by [opening support case](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-storage-limit) and specifying in which zone you need more volumes.\n\nYou can attach only one boot volume to a virtual server instance at a time, but you can attach up to 12 Block Storage for VPC data volumes to a single instance. For other limitations, see [Volume attachment limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-attaching-block-storagevol-attach-limits).\n\n\n\n Boot volumes \n\nWhen you create an instance from a stock image, a 100 GB, 3,000 IOPS general-purpose boot volume is created and attached to the instance by default. When you create an instance from a custom image, you can specify a boot volume capacity of 10 GB to 250 GB, depending what the image requires. This capacity can be any size between the minimum size that is supported for the selected image and the maximum supported image size. If the custom image is smaller than 10 GB, the boot volume capacity is rounded up to 10 GB. After the boot volume is created, you can expand the boot volume size to the maximum supported size, which is 250 GB.\n\nYou cannot create an image from a boot volume that is encrypted with customer-managed keys and is not 100 GB. Such an operation is not supported.\n\nBy default, boot volumes are encrypted by IBM-managed encryption. Optionally, you can use your own root keys (CRKs) by choosing customer-managed encryption during instance creation (see [Customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption)).\n\nBy default, boot volumes are deleted when you delete an instance. You can toggle this setting on or off in the instance details. A boot volume can be unattached only by deleting the instance that it is attached to. A boot volume cannot be detached from an instance while the instance exists.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about"},{"document_id":"ibmcld_01241-13660-15370","score":17.889377594,"text":"\n-h, --help Show this message and exit.\n\nIf you're using the replication feature, be sure that the schedule that you're deleting isn't the schedule that is used by replication. For more information about deleting a replication schedule, see [here](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-replication).\n\n\n\n\n\n Deleting a snapshot in the UI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. Deletion is done through Storage > File Storage for Classic.\n\n\n\n1. Click your storage volume and click Snapshot to see the list of existing snapshots.\n2. Click Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/04e9937a86546143babfc65ea21fdd4ea2d12d13\/icons\/action-menu-icon.svg) next to a particular snapshot and click Delete to delete the snapshot. This deletion doesn't affect any future or past snapshots on the same schedule as snapshots don't depend on each other.\n\n\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Deleting a snapshot from the SLCLI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. You can delete a snapshot from the SLCLI by using the following command.\n\n slcli file snapshot-delete --help\nUsage: slcli file snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managingSnapshots"},{"document_id":"ibmcld_05386-7736-9988","score":17.7608165741,"text":"\nThe maximum number of projects includes projects that are active and any projects that are not permanently deleted. When you delete a project, the project is soft deleted, and can be restored within 7 days before it is permanently deleted. Use the console or the CLI to display soft-deleted projects. For more information, see [deleting a project](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-manage-projectdelete-project).\n\nThe following table lists the quotas for projects.\n\nBe aware that the limits apply independently from each other within a project. If a limit is reached, such as the limit of 512 GB of memory, this quota limit might impact the ability to run a workload, even if another limit is not yet reached, such as 250 instances of apps or jobs.\n\n\n\nProject quotas\n\n Category Description \n\n Apps You are limited to 40 apps per project. \n App revisions You are limited to a total of 120 revisions for all apps per project. \n Builds You are limited to 100 build configurations per project. \n Build runs You are limited to 100 build runs per project before you need to remove or clean up old ones. \n Configmaps You are limited to 100 configmaps per project. \n CPU The total combination for all the app instances, running job instances, and running build instances cannot exceed 128 vCPU. \n Domain mappings (custom) You are limited to 80 custom domain mappings per project. \n Ephemeral storage The total combination for all the app instances, running job instances, and running build instances cannot exceed 512 G of ephemeral storage. \n Instances (active) The number of app instances, running job instances, and running build instances cannot exceed 250. \n Instances (total) The number of active instances and the number of completed job and build instances cannot exceed 2500. \n Jobs You are limited to 100 jobs per project. \n Job runs You are limited to 100 job runs per project before you need to remove or clean up old ones. \n Memory The total combination for all the app instances, running job instances, and running build instances cannot exceed 512 G of memory. \n Secrets You are limited to 100 secrets per project. \n Subscriptions (IBM Cloud Object Storage) You are limited to 100 (Object Storage) subscriptions per project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-limits"},{"document_id":"ibmcld_07578-769389-771160","score":17.4354991913,"text":"\nFor example, if object storage origin s3-example.object-storage.com with bucket name xyz-bucket-name is added in path \/example-cos\/, when a user opens the CDN URL cdn.example.com\/example-cos\/, the CDN edge server retrieves the content from s3-example.object-storage.com\/xyz-bucket-name\/.\n\n\n\n* What's the difference between the origin on the Settings page and the origins on the Origins page?\n\n What's the difference between the origin on the Settings page and the origins on the Origins page? \n\nThe Settings page shows the origin path created during CDN provisioning. You cannot edit or delete it. However, on the Origins page, you can configure different types of origins (COS or origin server). You can also edit or delete origins on this page.\n* Why can't I change the protocol and port for an origin?\n\n Why can't I change the protocol and port for an origin? \n\nThe displayed protocol and port options match what you selected when you ordered the CDN. For example, if you selected an HTTP port when you ordered a CDN, only the HTTP port option is shown as part of Add Origin.\n* How many origins can I add to a CDN?\n\n How many origins can I add to a CDN? \n\nSee [Known limitations](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-limits-and-maximum-valuesis-there-a-limit-on-the-number-of-origin-and-ttl-entries) for the number of origins per CDN.\n* Will deleting a CDN also delete my account?\n\n Will deleting a CDN also delete my account? \n\nNo. Selecting Delete deletes only the CDN; it does not delete your account.\n* Why is the DV SAN certificate CDN still there after I deleted it?\n\n Why is the DV SAN certificate CDN still there after I deleted it? \n\nIf your CDN is configured with HTTPS with DV SAN certificate, it can take up to 5 hours to complete the deletion process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01245-4-1307","score":16.9202709198,"text":"\n* CLI\n* API\n\n\n\n\n\n\n\n Managing storage limits \n\nBy default, you can provision a combined total of 700 Block Storage for Classic and File Storage for Classic volumes globally. By following this process, you can increase the number of volumes you can provision.\n\nFor more information about increasing your storage volume capacity beyond 12 TB, see [expanding File Storage for Classic capacity](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-expandCapacityincreasecapacityover12TB).\n\nIf you're unsure how many volumes you have, you can confirm the numbers by using multiple methods.\n\n\n\n Confirming your current limit and provisioning count from the CLI \n\n\n\n SLCLI \n\nYou can list the number of your volumes by using the [volume-limits](https:\/\/softlayer-python.readthedocs.io\/en\/latest\/cli\/file\/file-volume-limits) command in slcli (version 5.8.5 or higher).\n\n slcli file volume-limits\n\nThe output looks similar to the following example.\n\n[{'datacenterName': 'global', 'maximumAvailableCount': 700, 'provisioned Count':117}]\n:............:.......................:..................:\n: Datacenter : maximumAvailableCount : ProvisionedCount :\n:............:.......................:..................:\n: global : 700 : 117 :\n:............:.......................:..................:\n\n\n\n\n\n IBM Cloud CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits"},{"document_id":"ibmcld_00249-4-1321","score":16.8770484924,"text":"\n* CLI\n* API\n\n\n\n\n\n\n\n Managing storage limits \n\nBy default, you can provision a combined total of 700 Block Storage for Classic and File Storage for Classic volumes globally. By following this process, you can increase the number of volumes that you can provision.\n\nFor more information about increasing your storage volume capacity beyond 12 TB, see [expanding Block Storage for Classic capacity](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-expandingcapacityincreasecapacityover12TB).\n\n\n\n Confirming your current limit and provisioning count from the CLI \n\nIf you're unsure how many volumes you have, you can confirm the numbers by using multiple methods.\n\n\n\n SLCLI \n\nYou can list the number of your volumes by using the [volume-limits](https:\/\/softlayer-python.readthedocs.io\/en\/latest\/cli\/block\/block-volume-limits) command in slcli (version 5.8.5 or higher).\n\n slcli block volume-limits\n\nThe output looks similar to the following example.\n\n[{'datacenterName': 'global', 'maximumAvailableCount': 700, 'provisioned Count':117}]\n:............:.......................:..................:\n: Datacenter : maximumAvailableCount : ProvisionedCount :\n:............:.......................:..................:\n: global : 700 : 117 :\n:............:.......................:..................:\n\n\n\n\n\n IBM Cloud CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingstoragelimits"},{"document_id":"ibmcld_00241-4-1958","score":15.9843864441,"text":"\n* UI\n* CLI\n* Terraform\n\n\n\n\n\n\n\n Managing Snapshots \n\nSnapshots are a feature of IBM Cloud\u00ae Block Storage for Classic. A snapshot represents a volume's contents at a particular point in time. With snapshots, you can protect your data with no performance impact and minimal consumption of space. Learn more about how to manage snapshots by reading the following instructions.\n\n\n\n Adding a Snapshot schedule in the UI \n\nYou decide how often and when you want to create a point in time reference of your storage volume with Snapshot schedules. You can have a maximum of 50 snapshots per storage volume. Schedules are managed through the Storage > Block Storage for Classic tab of the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/classic-gen1).\n\nBefore you can set up your initial schedule, you must first purchase snapshot space if you didn't purchase it during the initial provisioning of the storage volume. For more information, see [Ordering Snapshots](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-orderingsnapshots).\n\nSnapshots schedules can be set up for hourly, daily, and weekly intervals, each with a distinct retention cycle. The maximum limit of snapshots is 50 per storage volume, which can be a mix of hourly, daily, and weekly schedules, and manual snapshots.\n\n\n\n1. Click your storage volume, click Actions, and click Edit Snapshot Schedule.\n2. In the Snapshot Schedule window, you can select from three different snapshot frequencies. Use any combination of the three to create a comprehensive snapshot schedule.\n\n\n\n* Hourly\n\n\n\n* Specify the minute each hour that a snapshot is to be taken. The default is the current minute.\n* Specify the number of hourly snapshots to be retained before the oldest is discarded.\n\n\n\n* Daily\n\n\n\n* Specify the hour and minute that a snapshot is to be taken. The default is the current hour and minute.\n* Select the number of hourly snapshots to be retained before the oldest is discarded.\n\n\n\n* Weekly","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingSnapshots"},{"document_id":"ibmcld_15588-2895-4731","score":15.9279718399,"text":"\n* z\/OS - Experimental Deleting a subnet through the user interface might not work as expected when you delete an existing VPC. You can use the command ibmcloud is subnet-delete as the workaround.\n\n\n\n\n\n\n\n Compute restrictions \n\n\n\n* Every x86-based profile has a network performance value of 2 Gbps per vCPU, with a cap of 80 Gbps.\n* Each x86-based network interface has a network performance cap of 16 Gbps.\n* Start and Stop actions are not registered under virtual server instance activity in the UI.\n* Activity Tracker logs (request logs and resource lifecycle event logs) are not available.\n* Updating the profile of a created instance is not supported.\n* The placement group of the instance can't be changed after an instance is provisioned with a placement group. You must delete the instance to remove it from the placement group.\n* API support for creating new instances from an existing boot volume is temporarily suspended. For more information, see the [API change log](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-api-change-log).\n\n\n\n\n\n\n\n Storage restrictions \n\nBlock storage volume names must be unique across the entire VPC infrastructure. A volume that is created on VPC compute resources can't have the same name as a volume created on the classic infrastructure. For more information about volume naming, see [Guidelines for naming volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-block-storagevolume-name-conventions).\n\n\n\n\n\n LinuxONE (s390x processor architecture) virtual server instance restrictions \n\nThe following feature is not supported:\n\n\n\n* Dedicated hosts\n* VPC Instance Metadata service.\n\n\n\n\n\n\n\n z\/OS virtual server instance restrictions \n\n\n\n* For limitations of z\/OS virtual server instances, see [IBM Wazi as a Service documentation](https:\/\/www.ibm.com\/docs\/en\/wazi-aas\/1.0.0?topic=known-limitations).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-limitations"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09984-0-1283","score":19.1179504395,"text":"\n\n\n\n\n\n\n  Overview \n\nData lakes are an essential tool for storing structured and unstructured data on the cloud. With IBM\u00ae Netezza\u00ae Performance Server for IBM Cloud Pak\u00ae for Data as a Service, you can use external tables to access parquet files that are stored outside of your database in data lakes (on AWS S3). Also, you can analyze this data by using the robust and massively parallel Netezza Performance Server execution engine.\n\nExternal data sources use connection strings to specify how you can access an external system. Each connection string describes where your data is placed and how to authenticate to your data source. Each external data source has a definition (schema), but the actual data exists external to the Netezza Performance Server database.\n\nYou cannot backup (nzbackup) and restore (nzrestore) external data source objects.\n\nUse cases for external data source include:\n\n\n\n*  [Running queries against parquet data that is stored in a data lake](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-querying_singularity).\n*  [Ingesting data into Netezza Performance Server](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-ingest_singularity).\n*  [Querying both local and remote data](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-merging_singularity).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-overview_singularity"},{"document_id":"ibmcld_16728-6533-8457","score":16.6441268921,"text":"\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Build a database-driven Slackbot](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson)Build a database-driven Slackbot Solution tutorial\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Build, deploy, test and monitor a predictive machine learning model](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model)Build, deploy, test and monitor a predictive machine learning model Solution tutorial\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"},{"document_id":"ibmcld_13162-12751-14416","score":15.3158082962,"text":"\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)\n* Build a web app with a dashboard for line of business users utilizing [IBM Cognos Dashboard Embedded](https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial).\n\n\n\n\n\n\n\n Step 8: Remove resources \n\nRun the following commands to remove services, applications and keys you created and used.\n\nibmcloud resource service-instance-delete data-lake-sql\n\nibmcloud resource service-instance-delete data-lake-studio\n\nibmcloud iam api-key-delete data-lake-cos-key\n\nibmcloud resource service-instance-delete data-lake-cos\n\nIf the deletion of data-lake-cos is not successful delete it from the storage section of the [Resource List](https:\/\/cloud.ibm.com\/resources).\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-resource-reclamation).\n\n\n\n\n\n Related content \n\n\n\n* [ibmcloudsql](https:\/\/github.com\/IBM-Cloud\/sql-query-clients\/tree\/master\/Python)\n* [Jupyter Notebooks](https:\/\/jupyter.org\/)\n* [Folium](https:\/\/python-visualization.github.io\/folium\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_13162-7-1878","score":15.0208482742,"text":"\nBuild a data lake using object storage \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n\n\n Objectives \n\n\n\n* Use Object Storage to store raw data files\n* Query data directly from Object Storage using Data Engine (previously SQL Query)\n* Refine and analyze data in IBM Watson\u00ae Studio\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/Smart-Data-Lake-Architecture.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. Raw data is stored on Object Storage.\n2. Data is reduced, enhanced or refined with Data Engine.\n3. Data analysis occurs in Watson Studio.\n4. Non-technical users access data through application(s).\n5. Refined data is pulled from Object Storage.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI.\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools you can use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_16729-11586-13439","score":14.8392877579,"text":"\n* 15 minutes\n* 2023-01-31\n\n\n\n[Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\nBlockchain[Setting up multiregion High Availability (HA) deployments for the ordering service](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-hadr-mr-os)Setting up multiregion High Availability (HA) deployments for the ordering service\n\nIn this tutorial, you learn how to set up a Raft ordering service with five ordering nodes that span multiple regions for maximum high availability.\n\nIBM Blockchain Platform\n\n\n\n* 2023-02-17\n\n\n\n[Using certificates from an external Certificate Authority](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-tutorial-extca)Using certificates from an external Certificate Authority\n\nIn this tutorial, you learn how to use certificates that were generated by an external Certificate Authority (CA) with your IBM\u00ae Blockchain Platform network. After you gather the required certificates for a peer or ordering node, you build a Membership Service Provider (MSP) definition that is used by your blockchain components.\n\nIBM Blockchain Platform\n\n\n\n* 30 minutes\n* 2023-02-17","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_16657-0-905","score":14.1485176086,"text":"\n\n\n\n\n\n\n  Release notes for watsonx.data \n\nUse these release notes to learn about the latest updates to IBM\u00ae watsonx.data that are grouped by date.\n\n\n\n  7 July 2023 \n\nwatsonx.data is a new open architecture that combines the elements of the data warehouse and data lake models. The best-in-class features and optimizations available on the watsonx.data make it an optimal choice for next generation data analytics and automation. In the first release (watsonx.data 1.0.0), the following features are supported:\n\n\n\n*  Creating, scaling, pausing, resuming, and deleting the Presto query engine\n*  Associating and dissociating a catalog with an engine\n*  Exploring catalog objects\n*  Adding and deleting a database-catalog pair\n*  Updating database credentials\n*  Adding and deleting bucket-catalog pair\n*  Exploring bucket objects\n*  Loading data\n*  Exploring data\n*  Querying data\n*  Query history\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-release"},{"document_id":"ibmcld_13162-11690-13171","score":14.0359563828,"text":"\nHeatMap(locations, radius=15).add_to(m)\nm\n\nZoom\n\n![Notebook](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/notebook-mapbox.png)\n\nNotebook\n3. Click File > Save to save your Notebook to Object Storage.\n\n\n\n\n\n\n\n Step 6: Share your dataset with the organization \n\nNot every user of the data lake is a data scientist. You can allow non-technical users to gain insight from the data lake. Tools with analytic capabilities or for visualization can import data stored in CSV files. Application developers can make use of [IBM Cognos Dashboard Embedded](https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial) to let users build and use feature-rich dashboards. Such a dashboard for the traffic data is shown below.\n\nZoom\n\n![Dashboard Chart](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/dashboard-chart.png)\n\nDashboard Chart\n\n\n\n\n\n Step 7: Expand the tutorial \n\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_16728-5097-7108","score":13.6716947556,"text":"\n[solution icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/magic-wand.svg) [Best practices for organizing users, teams, applications](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-users-teams-applications)Best practices for organizing users, teams, applications Solution tutorial\n\nThis tutorial gives an overview of the concepts available in IBM Cloud for identity and access management and how they can be implemented to support the multiple development stages of an application.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Bring Your Own IP Address](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-byoip)Bring Your Own IP Address Solution tutorial\n\nThis tutorial presents a brief overview of BYOIP implementation patterns that can be used with IBM Cloud and a decision tree for identifying the appropriate pattern when realizing the secure enclosure as described in the Isolate workloads with a secure private network tutorial. Setup may require additional input from your onsite network team, IBM Cloud technical support or IBM Services.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage Solution tutorial\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"},{"document_id":"ibmcld_14819-1476-3309","score":13.1745376587,"text":"\nFor data center location, click the Edit icon ![Edit icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/icons\/edit-tagging.svg) and select the geography, data center, and pod where the instance is to be hosted.\n2. Select the CPU model:\n\n\n\n* For Cascade Lake servers, select the CPU model and the RAM size.\n* For SAP-certified Cascade Lake servers, choose one of the preset configurations.\n\n\n\n3. Specify the number of bare metal servers.\n\n\n\n6. If you selected the VMware vSAN component, complete the vSAN\u2122 storage configuration.\n\n\n\n* If you want more storage, select the High performance with Intel Optane checkbox.\n* Specify the disk types for the capacity and cache disks, and the number of disks.\n* By default, the Enable vSAN deduplication and compression checkbox is selected. If you do not want to enable vSAN deduplication and compression, clear the checkbox.\n\n\n\n7. Complete the network interface settings:\n\n\n\n1. Enter the hostname prefix and domain name.\n2. Select the network setting of either Public and private network or Private network only.\n3. Select the uplink speed. The 25 Gb option is available only for specific pods and data center locations.\n4. Select the network interface that you want to use.\n\n\n\n* If you want to order new public and private VLANs, click Order new VLANs.\n* If you want to reuse the existing public and private VLANs when they are available, click Select existing VLANs and specify the VLANs and optionally the subnets.\n\n\n\n5. If you are ordering public VLANs, specify whether to apply the FortiGate Physical Appliance 300 Series HA Pair to secure your cloud environment.\n\n\n\n8. In the Summary pane, verify the cluster configuration and the estimated price.\n\n\n\n* To save the configuration as a template without placing an order, click Save configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_orderinginstances-procedure"},{"document_id":"ibmcld_09976-7-1778","score":13.0678100586,"text":"\nMerging and querying data \n\nYou might keep only the most recent data locally in a database and use data lakes as your long term storage. With Netezza Performance Server, you can seamlessly query both local and remote data without having to load the remote data into a database first.\n\n\n\n Before you begin \n\nIn the examples, the publicly available [New York taxi trip record data](https:\/\/www1.nyc.gov\/site\/tlc\/about\/tlc-trip-record-data.page) for yellow taxis in January 2021 and 2022 is used. To follow this example, make sure that the data is in an accessible S3 bucket.\n\n\n\n\n\n 1. Create an external data source. \n\nExternal datasources allow an administrator to grant access to S3 without providing the keys directly to a user.\n\na) Set ENABLE_EXTERNAL_DATASOURCE.\n\nset ENABLE_EXTERNAL_DATASOURCE = 1;\n\nb) Create an external data source.\n\ncreate EXTERNAL DATASOURCE 'DATA SOURCE' on 'REMOTE SOURCE'\nusing (\nACCESSKEYID 'ACCESS KEY ID' SECRETACCESSKEY 'SECRET ACCESS KEY' BUCKET 'BUCKET' REGION 'REGION'\n);\n\nExample:\n\ncreate EXTERNAL DATASOURCE EXAMPLEDATALAKE\u00a0on AWSS3\u00a0\nusing (\nACCESSKEYID 'XXXX' SECRETACCESSKEY 'XXXX' BUCKET 'exampledatalakebucket' REGION 'US-EAST-1'\n);\n\nFor more information, see [CREATE EXTERNAL DATASOURCE command](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=tables-create-external-datasource-command).\n\n\n\n\n\n 2. Identify the data from Netezza Performance Server to merge and compare. \n\nIn this example, data that was loaded into Netezza Performance Server (YELLOW_TAXI_JANUARY_2022) is compared with data from a data like (YELLOW_TAXI_JANUARY_2021).\n\nTo follow this example, ensure that YELLOW_TAXI_JANUARY_2022 is in your Netezza Performance Server database.\n\na) Create an external table for the data that you want to load (YELLOW_TAXI_JANUARY_2022).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-merging_singularity"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16613-0-1165","score":19.8881778717,"text":"\n\n\n\n\n\n\n  Creating table \n\nYou can generate, configure, and run DDL from the Data manager page by using the web console.\n\n\n\n1.  Log in to IBM\u00ae watsonx.data console.\n2.  From the navigation menu, select Data manager.\n3.  Select the engine from the Engine menu. Catalogs that are associated with the selected engine are listed.\n4.  Click Create and select Create table.\n5.  In the Create table form, drag a file to the box or click to upload.\n\n.CSV, .Parquet, .json, .txt are the supported data file formats. For .json file, you must enclose the content in [].\n6.  Click the data type and choose the required data types for each column. Click Next.\n7.  In the Target form, select the Engine, Catalog, and Schema in which the table is created.\n8.  Enter a name for the table in the Table name field and click Next.\n9.  Verify the details in the Summary page and scroll down to view the DDL preview.\n10. Click Create.\n11. Verify that the table creation status in the Result set is successful, indicated as true.\n12. Go to the Data manager page and select the schema under which you created the table and click the refresh icon. The newly created table is listed.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-create_table"},{"document_id":"ibmcld_09950-7-1844","score":19.6177997589,"text":"\nTables \n\nIn the table from the Tables tab, the value that is displayed in the row count column is an approximate. The exact row count is available after you run the GENERATE STATISTICS ON <table_name> command.\n\n\n\n Creating tables \n\n\n\n1. Go to Databases.\n2. Select the database in which you want to create a table.\n3. Select the schema in which you want to create a table.\n4. Ensure that you are in the DB Objects > Tables tab.\n5. Click Create table.\n6. Type a name for the table.\nIf the name contains special characters, enclose it in double quotation marks. The dot character (\".\") is not supported.\nYou can select a name that has up to 128 characters. The name must begin with a letter or an underscore and can't contain embedded spaces. The name must be unique.\n7. Optional: Specify the retention time interval (in days) for the table.\nYou can select between 1 day and up to 99 days, or zero to alter a temporal table to nontemporal.\n8. Add columns to the table:\n\n\n\n1. In the Columns section, under Name, type a name for the column. The name must start with a letter.\n2. Select your column type.\nThe data type restricts the type of data that can be stored in a column. For example, preventing entry of alphanumeric characters into a numeric field.\nData types also help sort data correctly and play a role in optimizing storage. For all these reasons, it is important to pick the appropriate data type.\n3. Specify whether Not null is true or false.\nA column that allows NULL values also allows rows to be inserted with no value in that column. A column that does not allow NULL values does not accept rows with no value.\n4. Specify the default value to be used if no value is specified when a row is inserted.\n5. In the Distribute on and Organize on sections, specify the distribution key for the table by selecting up to four columns.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-create-tables"},{"document_id":"ibmcld_16612-0-523","score":18.8047199249,"text":"\n\n\n\n\n\n\n  Creating schema \n\nYou can create schema from the Data manager page by using the web console.\n\n\n\n1.  Log in to IBM\u00ae watsonx.data console.\n2.  Select Data manager from the navigation menu.\n3.  Select the engine from the Engine menu. The catalogs that are associated with the selected engine are displayed.\n4.  Click the Create drop-down and select Create schema.\n\n\n\n1.  In the Create schema form, select the catalog and enter schema name.\n2.  Click Create. The schema is created under the selected catalog.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-create_schema"},{"document_id":"ibmcld_09947-0-947","score":18.7038002014,"text":"\n\n\n\n\n\n\n  Schemas \n\n\n\n  Creating schemas \n\n\n\n1.  Go to Databases.\n2.  Select the database in which you want to create a schema.\n3.  Click Create schema.\n4.  Type a name for the schema.\nIf the name contains special characters, enclose it in double quotation marks. The dot character (\".\") is not supported.\n5.  Specify the retention time interval (in days) for the schema.\n6.  Click Create.\n\n\n\n\n\n\n\n  Updating retention time interval (time travel) for schemas \n\n\n\n1.  Go to Databases.\n2.  Select the database in which the schema that you want to alter is.\n3.  From the overflow menu, click Update interval.\n4.  Type a retention time interval.\nYou can select between 1 day and up to 99 days, or zero to alter a temporal schema to nontemporal.\nFor more information on retention time interval and time travel, see [Netezza Performance Server time travel](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-enablingdisabling_tt).\n5.  Click Save.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-create-schemas"},{"document_id":"ibmcld_16638-0-764","score":18.3488788605,"text":"\n\n\n\n\n\n\n  Creating table from a file \n\nFiles can also be ingested or imported to IBM\u00ae watsonx.data through the overflow menu of schema in the Data explorer page to create tables.\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select Data manager.\n3.  Select the engine from the Engine drop-down. Catalogs that are associated with the selected engine are listed.\n4.  Select a schema under a catalog where you want to import a file to create table.\n5.  Click the overflow menu of the selected schema and select Create table from a file. The Create table from a file page opens.\n6.  Follow the steps in the [Creating tables](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-create_table) topic to complete importing the file.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-import_data"},{"document_id":"ibmcld_16627-0-1141","score":18.0863113403,"text":"\n\n\n\n\n\n\n  About Data manager \n\nThe Data manager page in IBM\u00ae watsonx.data is the entry point to browse the schemas and tables by engine. You can select an engine to view the associated catalogs, schemas, and tables.\n\nFrom the Data manager page, you can create schemas and tables by using the Create option that is provided in the left window. You can also select a catalog or schema, click the overflow menu, and use the corresponding Create option to create a schema or table. Create table from file option in the overflow menu of schema is also used to ingest a data file into watsonx.data. Similarly, schemas and tables can be dropped from the catalogs.\n\nWait for a few minutes to view the changes after a schema or table is dropped.\n\nAdding, renaming, or dropping a column are the other tasks that can be performed in the Data manager page.\n\nYou can browse the Table schema and upto 25 rows of Data sample for some tables. You can view the Time travel snapshots and use the Rollback feature to rollback to a given snapshot for Iceberg tables.\n\nPresto cannot roll back to the snapshots that are not ancestors of the current snapshot.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-exp_objects"},{"document_id":"ibmcld_13512-5424-5881","score":17.4094085693,"text":"\nThe <table name> part specifies the table that is created in your database. It has the format <schemaname>.<tablename>. If you omit the <schemaname> part, the table is created in the schema of database user that was created for the IBMid of the SQL user. The table name is case-preserving, so use uppercase to match database defaults.\n\nThe following URI is an example of a Db2 table URI:\n\ndb2:\/\/db2w-vqplkwx.us-south.db2w.cloud.ibm.com\/MYSCHEMA.QUERY_RESULT","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-writing-databases"},{"document_id":"ibmcld_16471-187736-189050","score":16.9220733643,"text":"\nif (returnSchema.size () != arg1Schema.size () + arg2Schema.size ()) { throw new TableUDFException (\n\"Schema sizes don't match (%d + %d != %d)\", arg1Schema.size (), arg2Schema.size (), returnSchema.size ()); }\n\n\/\/ Then check types\nfor (int i = 0; i < arg1Schema.size (); i++) {\nif (false == (arg1Schema.getFieldTypeByIx (i).equals (returnSchema.getFieldTypeByIx (i)))) { throw new TableUDFException (\n\"Field type %d of output doesn't match corresponding field of first input arg (%s != %s)\", i,\nreturnSchema.getFieldTypeByIx (i), arg1Schema.getFieldTypeByIx (i)); }\n}\n\nfor (int i = 0; i < arg2Schema.size (); i++) {\nif (false == (arg2Schema.getFieldTypeByIx (i).equals (returnSchema.getFieldTypeByIx (i + arg1Schema.size ())))) { throw new TableUDFException (\n\"Field type %d of output doesn't match corresponding field of first input arg (%s != %s)\", i\n+ arg1Schema.size (), returnSchema.getFieldTypeByIx (i + arg1Schema.size ()), arg2Schema.getFieldTypeByIx (i)); }\n}\n}\n\n}\nShow more\n\n\n\n\n\n\n\n Declaring user-defined functions \n\nYou can make the user-defined scalar functions and machine learning models from PMML files available to AQL by using the create function statement.\n\n\n\n Syntax \n\nThe general syntax of the create function statement is as follows:\n\ncreate function <function-name>(<input-schema-definition>)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_16471-188589-190073","score":16.8874511719,"text":"\n+ arg1Schema.size (), returnSchema.getFieldTypeByIx (i + arg1Schema.size ()), arg2Schema.getFieldTypeByIx (i)); }\n}\n}\n\n}\nShow more\n\n\n\n\n\n\n\n Declaring user-defined functions \n\nYou can make the user-defined scalar functions and machine learning models from PMML files available to AQL by using the create function statement.\n\n\n\n Syntax \n\nThe general syntax of the create function statement is as follows:\n\ncreate function <function-name>(<input-schema-definition>)\nreturn <return-type> [like <column-name>] | table ( <output-schema-definition)\nexternal_name <ext-name>\nlanguage [java | pmml]\n[deterministic | not deterministic]\n[return null on null input | called on null input];\n\n<input-schema-definition>\n<column-name> <data-type> | table (<output-schema-definition>) as locator [,<column-name> <data-type> | table (<output-schema-definition>) as locator ]\n\n<output-schema-definition>\n<column-name> <data-type> [,<column-name> <data-type>]\n\n\n\n\n\n Description \n\n\n\n* <function-name>\n\nThe <function-name> declares the AQL name of the UDF. The UDF is referred to in the AQL code with this name\n* <input-schema-definition>\n\nSpecifies the input parameters of the UDF. An input parameter has a name, which is specified as <column-name>, and can be either a scalar type or a table locator. When the language is PMML, the function must take a single table that is called params as the argument.\n* <column-name>\n\nSpecifies the name of a column in the input or the output of the UDF.\n* <data-type>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_09955-7-1812","score":16.748090744,"text":"\nDatabases \n\nYou can access database information by using the web console.\n\n\n\n Information about databases \n\n\n\nTable 1. The table lists database-related values and their definitions.\n\n Value Description \n\n Name Specifies the name of the database. \n Default schema Specifies the deafult schema. \n Owner Specifies the owner of the database. \n User tables Specifies the number of tables that are created in the database. \n Character set Specifies the character set for the database. \n Created on Specifies when the database was created. \n\n\n\n\n\n\n\n Creating databases \n\n\n\n1. Go to Databases.\n2. Click Create database.\n3. Type a name for the database.\nIf the name contains special characters, enclose it in double quotation marks. The dot character (\".\") is not supported.\n4. Optional: Specify the retention time interval (in days) for the database.\nYou can select between 1 day and up to 99 days.\nFor more information on retention time interval and time travel, see [Netezza Performance Server time travel](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-enablingdisabling_tt).\n5. Click Create.\n\n\n\n\n\n\n\n Assigning owners to databases \n\n\n\n1. Go to Databases.\n2. Select the database for which you want to assing an owner.\n3. From the overflow menu, click Assign owner.\n4. Select an owner for the database.\n5. Click Assign.\n\n\n\n\n\n\n\n Renaming databases \n\n\n\n1. Go to Databases.\n2. Select the database that you want to rename.\n3. From the overflow menu, click Rename.\n4. Type a new name for the database.\nIf the name contains special characters, enclose it in double quotation marks. The dot character (\".\") is not supported.\n5. Click Rename.\n\n\n\n\n\n\n\n Updating retention time interval (time travel) for databases \n\n\n\n1. Go to Databases.\n2. Select the database for which you want to update the retention time interval.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-databases"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.9060254355,"ndcg_cut_10":0.9060254355}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00539-7-1755","score":25.1489830017,"text":"\nUsing IBM Cloudant Query FAQ \n\n[IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query) is an API for querying slices of data based on the values of a database's document attributes. It is a flexible API that must be used carefully to ensure that database performance can be maintained as the data size grows over time.\n\n\n\n How do I use IBM Cloudant Query? \n\nIBM Cloudant Query is accessed through the [POST \/{db}\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) API endpoint where the JSON specification of the query is passed in the HTTP POST body. For example, this query finds up to 10 documents where the firstname is \"Charles\" and the surname is \"Dickens\":\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"limit\": 10\n}\n\nFor more information, see [Selector Syntax](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-queryselector-syntax).\n\n\n\n\n\n How do I create an index to support an IBM Cloudant Query? \n\nWithout a suitable secondary index, IBM Cloudant Query scans each document in the database in turn until it has enough matches to satisfy the query. The larger the data set and the more documents it has to scan to find matching documents, the slower the response time. For faster performance, an IBM Cloudant Query _find must be backed by a suitable secondary index. A secondary index is a pre-calculated data structure that allows IBM Cloudant to quickly jump to the slice of data it needs without scanning irrelevant documents. For the surname fields, we call the [POST \/{db}\/_index](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostindex) endpoint to pass the JSON index definition as the HTTP POST body:\n\n{\n\"index\": {\n\"fields\": [\"firstname\", \"surname\"]\n},\n\"ddoc\": \"jsonindexes\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_00580-41116-43256","score":24.7245101929,"text":"\nThe queries that we executed in the previous part were not optimal: to get the answer, IBM Cloudant had to spool through every document in the database in turn to see whether it met with the search criteria.\n\nTo make queries that are run in a performant and scalable way, we need Indexing.\n\nWith IBM Cloudant, you can specify any number of Indexes (or indices).\n\nAn index is a secondary data structure that is built from the document list. It contains data that is sorted by the fields you specify, for example, books that are sorted by date and title. If you perform a query that asks for data that matches a document's date and title, the indexed data structure can be used to speed up the query process. Instead of scanning through every document in turn, IBM Cloudant can jump to the relevant part of the index (say, the section on 20th century books) and retrieve the data much more quickly.\n\nIBM Cloudant Query indexes include two types of indexes: type=json and type=text. These indexes are backed by two underlying indexing technologies that we meet in subsequent parts of this course.\n\nAn index is defined when you POST some JSON to a database's _index endpoint.\n\nThe index object contains a fields array, which specifies which document attributes to index. Usually, the fields that need indexing are equivalent to the attributes used in the selector of a query you're going to use to retrieve the data. That is, if you need to query by the date field, we need to index the date field.\n\nAlthough the name of an index is optional, it's good practice and we follow this convention. It's good to ask IBM Cloudant a question and specify the name of the index you intend it to use. This practice saves IBM Cloudant from having to choose which index to use from the available ones, and it makes it easy for you to remember which index is which.\n\nLet's create an index on our books database from the dashboard. Select the database, then choose the Design Documents tab and Query Indexes from the menu.\n\nAny existing indexes are listed on the side: A special index must exist that represents the primary index, based on the document's _id.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00580-39512-41555","score":24.6337757111,"text":"\nThe Query is a standard JavaScript object, which is passed to the db.find function which it POSTs to the _find endpoint on your behalf.\n\nNow, time for a practical exercise. Devise your own IBM Cloudant Query that finds the titles of books that are written in the 20th Century. The IBM Cloudant Query documentation is at the on-screen URL if you need it.\n\nPause the presentation here if you don't want to know the answer...\n\nSee one solution:\n\nI use the $and operator to combine two clauses on the date attribute. One clause to locate documents whose date >= 1900, the other to find documents whose date is < the year 2000. Both clauses have to be true to select a document. As we need only the title of the matching books, we can supply a fields attribute instead of being returned the entire document.\n\nTo summarize, IBM Cloudant Query is a query language that is inspired by MongoDB where the syntax is expressed in JSON form.\n\nQueries select subsets of documents from the database by using clauses that operate on data inside the document - not just the document's _id.\n\nQueries are sent to the database's _find endpoint, either programmatically, by using curl, or by using the Dashboard.\n\nThe query's selector decides which cut of data is required,\n\nThat's the end of this part. The next part is called Indexing.\n\n\n\n\n\n\n\n Indexing video \n\nLearn how indexing can speed up your query process.\n\n\n\n* Indexing video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 11 - Indexing.\n\nThe queries that we executed in the previous part were not optimal: to get the answer, IBM Cloudant had to spool through every document in the database in turn to see whether it met with the search criteria.\n\nTo make queries that are run in a performant and scalable way, we need Indexing.\n\nWith IBM Cloudant, you can specify any number of Indexes (or indices).\n\nAn index is a secondary data structure that is built from the document list.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00579-2977-4822","score":24.3270454407,"text":"\n* IBM Cloudant guide to using [views](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsusing-views)\n* Performance implications of using [include_docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsmulti-document-fetching)\n\n\n\n\n\n\n\n Never rely on the default behavior of IBM Cloudant Query\u2019s no-indexing \n\nIt\u2019s tempting to rely on IBM Cloudant Query's ability to query without creating explicit indexes. This practice is costly in terms of performance, as every lookup is a full scan of the database rather than an indexed lookup. If your data is small, this full-scan lookup doesn\u2019t matter, but as the data set grows, performance becomes a problem for you, and for the cluster as a whole. It is likely that we will limit this facility soon. The IBM Cloudant Dashboard provides a method for creating indexes in an easy way.\n\nCreating indexes and crafting IBM Cloudant Queries that take advantage of them requires some flair. To identify which index is being used by a particular query, send a POST to the _explain endpoint for the database, with the query as data.\n\nFor more information, see [IBM Cloudant Query docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query).\n\n\n\n\n\n In IBM Cloudant Search (or IBM Cloudant Query indexes of type text), limit the number of fields \n\nIBM Cloudant Search and IBM Cloudant Query indexes of type text (both of which are Apache Lucene under the hood) provide you with a way to index any number of fields into the index. Some examples exist where this type of indexing is abused either deliberately, or mostly by mistake. Plan your indexing to comprise only the fields required by your actual queries. Indexes take up space and can be costly to rebuild if the number of indexed fields are large.\n\nWe also have the issue of which fields that you store in an IBM Cloudant Search.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00580-37889-39953","score":24.0514945984,"text":"\nIf you need to access objects within documents, you can use standard dot notation for example, address.zipcode to access a postal code string inside an address object.\n\nWe can also add the following parameters:\n\nFields\n: Specifies the document attributes that we want returned (the default is the entire document).\n\nSort\n: Defines how the data is to be sorted. Sort is an array, allowing the sort to be calculated on multiple attributes.\n\nLimit\n: The number of documents to return.\n\nIf you are from a relational database background, this query is the equivalent SQL query to that last IBM Cloudant query example.\n\nThe WHERE clause is the equivalent of SELECTOR in IBM Cloudant Query. ORDER and LIMIT are exactly equivalent, and the IBM Cloudant Query FIELDS list is equivalent to the comma-separated list of attributes after the SELECT keyword.\n\nThe JSON syntax might take a bit of getting used to, but MongoDB users might find it familiar.\n\nIBM Cloudant queries can be executed in the IBM Cloudant Dashboard. Select the database that you are working with, for example, books then choose the Query tab.\n\nEnter your IBM Cloudant Query JSON in the box that is provided, and click Run Query when you're ready. The result set appears on the page.\n\nThe Explain button is used to provide an explanation on how the database interprets the supplied query. This explanation becomes more important when we get to Indexing in the next part.\n\nQueries can be triggered from curl too. The Query JSON, in this case, is stored in a file and we POST to the _find endpoint by using the -d@ command-line syntax.\n\nThe Node.js code is similar. The Query is a standard JavaScript object, which is passed to the db.find function which it POSTs to the _find endpoint on your behalf.\n\nNow, time for a practical exercise. Devise your own IBM Cloudant Query that finds the titles of books that are written in the 20th Century. The IBM Cloudant Query documentation is at the on-screen URL if you need it.\n\nPause the presentation here if you don't want to know the answer...\n\nSee one solution:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00623-7-1781","score":23.91979599,"text":"\nWorking with IBM Cloudant Query \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query is a declarative JSON querying syntax for IBM Cloudant databases. You can use a json or text type of index with IBM Cloudant.\n\nIn the following cases, you can specify how the index is created by making it of type json:\n\n\n\n* You know exactly what data you want to look for.\n* You want to keep storage and processing requirements to a minimum.\n\n\n\nBut for maximum flexibility when you search for data, you typically create an index of type text. Indexes of type text have a simple mechanism for automatically indexing all the fields in the documents.\n\nWhile more flexible, text indexes might take longer to create and require more storage resources than json indexes.\n\n\n\n Creating an index \n\nYou can create an index with one of the following types:\n\n\n\n* \"type\": \"json\"\n* \"type\": \"text\"\n\n\n\n\n\n Creating a type=json index \n\nTo create a JSON index in the database $DATABASE, make a POST request to \/$DATABASE\/_index with a JSON object that describes the index in the request body. The type field of the JSON object must be set to json. A JSON index can be partitioned or global; this option is set by using the partitioned field.\n\nSee the following example that uses HTTP to request an index of type JSON:\n\nPOST \/$DATABASE\/_index HTTP\/1.1\nContent-Type: application\/json\n\nSee the following example of a JSON object that creates a partitioned index that is called foo-partitioned-index for the field called foo:\n\n{\n\"index\": {\n\"fields\": [\"foo\"]\n},\n\"name\" : \"foo-partitioned-index\",\n\"type\" : \"json\",\n\"partitioned\": true\n}\n\nSee the following example of a JSON object that creates a global index that is called bar-global-index for the field called bar:\n\n{\n\"index\": {\n\"fields\": [\"bar\"]\n},\n\"name\" : \"bar-global-index\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query"},{"document_id":"ibmcld_00639-7-2032","score":23.6773796082,"text":"\nSelector syntax \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query language is expressed as a JSON object that describes documents of interest. Within this structure, you can apply conditional logic by using specially named fields.\n\nThe IBM Cloudant Query language has some similarities with MongoDB query documents, but these similarities arise from a commonality of purpose and don't necessarily extend to equivalence of function or result.\n\n\n\n Selector basics \n\nElementary selector syntax requires you to specify one or more fields, and the corresponding values needed for those fields. The following example selector matches all documents that have a director field that contains the value Lars von Trier.\n\nSee the following example of a simple selector:\n\n{\n\"selector\": {\n\"director\": \"Lars von Trier\"\n}\n}\n\nIf you created a full text index by specifying \"type\":\"text\" when the index was created, you can use the $text operator to select matching documents. In the following example, the full text index is inspected to find any document that contains the word Bond.\n\nSee the following example of a simple selector for a full_text index:\n\n{\n\"selector\": {\n\"$text\": \"Bond\"\n}\n}\n\nYou can create more complex selector expressions by combining operators. However, for IBM Cloudant Query indexes of type json, you can't use \"combination\" or \"array logical\" operators such as $regex as the basis of a query. Only the equality operators such as $eq, $gt, $gte, $lt, and $lte - but not$ne - can be used as the basis of a more complex query. For more information about creating complex selector expressions, see [Creating selector expressions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-selector-syntaxcreating-selector-expressions).\n\n\n\n\n\n Selector with two fields \n\nIn the following example, the selector matches any document with a name field that contains Paul, and that also has a location field with the value \"Boston\".\n\nSee the following example of a more complex selector:\n\n{\n\"selector\": {\n\"name\": \"Paul\",\n\"location\": \"Boston\"\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-selector-syntax"},{"document_id":"ibmcld_00580-60601-62822","score":23.6347923279,"text":"\nWhen you create a secondary index, you choose whether its purpose is for per-partition or global scope.\n\nThat's the end of this part. The next part is called IBM Cloudant Search.\n\n\n\n\n\n\n\n IBM Cloudant Search video \n\nLearn how to use IBM Cloudant Search, as well as Lucene query language and faceting.\n\n\n\n* IBM Cloudant Search video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 16 - IBM Cloudant Search.\n\nWe have another method of querying and indexing in IBM Cloudant called IBM Cloudant Search that we briefly explore in this part.\n\nIBM Cloudant Search is built on another open source project, Apache Lucene, which powers the search capabilities of many products that include Elasticsearch.\n\nIt is primarily designed for free text search, where blocks of text are pre-processed before they are indexed: removing case, punctuation, common noise words, and trimming common language-specfic word endings, for example, farmer becomes farm, and farms becomes farm.\n\nThis text-processing is performed by a choice of analyzers at query time, searching. Before this time, it also allows some aggregation functionality that uses a technique that is called faceting.\n\nAn IBM Cloudant Search index is created by supplying JavaScript function. It is not unlike MapReduce, except this time, the emit function is replaced by an index function, which expects the name of the field, the data itself, and some options.\n\nIn this example, the document's name and title are indexed with default options. The category is nominated for faceting (the aggregation functionality) and the ISBN is stored in the index but not indexed for search itself. Sometimes it is more efficient to store some items in the index rather than doing include_docs=true at query time.\n\nLucene has its own query language that creates queries that match combinations of clauses with logic, fuzzy matching, ranges, and term boosting.\n\nSee the following examples:\n\n\n\n* Find documents whose title matches gastby and whose author starts with fitz. Notice the asterisk wildcard.\n* Find documents whose author is in the range austen to dickens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00472-7-1792","score":23.3994827271,"text":"\nUsing IBM Cloudant Search \n\nSearch indexes provide a way to query a database by using [Lucene Query Parser Syntax](https:\/\/lucene.apache.org\/core\/4_3_0\/queryparser\/org\/apache\/lucene\/queryparser\/classic\/package-summary.htmlOverview). A search index uses one or more fields from your documents.\n\nYou can use a search index to run queries, find documents based on the content they include, or work with groups, facets, or geographical searches.\n\nTo create a search index, you add a JavaScript function to a design document in the database. An index builds after it processes one search request or after the server detects a document update. The index function takes the following parameters:\n\n\n\n1. Field name - The name of the field you want to use when you query the index. If you set this parameter to default, then this field is queried if no field is specified in the query syntax.\n2. Data that you want to index, for example, doc.address.country.\n3. (Optional) The third parameter includes the following fields: boost, facet, index, and store. These fields are described in more detail later.\n\n\n\nBy default, a search index response returns 25 rows. The number of rows that is returned can be changed by using the limit parameter. However, a result set from a search is limited to 200 rows. Each response includes a bookmark field. You can include the value of the bookmark field in later queries to look through the responses.\n\nYou can query the API by using one of the following methods: URI, IBM Cloudant Dashboard, curl, or a browser plug-in, such as Postman or RESTClient.\n\nSee the following example design document that defines a search index:\n\n{\n\"_id\": \"_design\/search_example\",\n\"indexes\": {\n\"animals\": {\n\"index\": \"function(doc){ ... }\"\n}\n}\n}\n\n\n\n Search index partitioning type","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search"},{"document_id":"ibmcld_00580-42802-44973","score":23.2687149048,"text":"\nThis practice saves IBM Cloudant from having to choose which index to use from the available ones, and it makes it easy for you to remember which index is which.\n\nLet's create an index on our books database from the dashboard. Select the database, then choose the Design Documents tab and Query Indexes from the menu.\n\nAny existing indexes are listed on the side: A special index must exist that represents the primary index, based on the document's _id.\n\nComplete the index definition with the JSON:\n\nClick Create Index when you're done.\n\nClicking the button sends a POST request to the _index endpoint (other API calls are available to update and delete existing indexes).\n\nIndexes are built asynchronously by IBM Cloudant in the background. For large databases, it can take IBM Cloudant some time to construct the index for the first time. The index cannot use the database until that initial build is ready.\n\nWe can repeat our query for books in the 20th century. This time we specify the index name with the use_index field. The answer returns - this time powered by our index. You might not notice a speed improvement for a small database, but the benefit is definitely felt as your data size and query volume grows. Indexing helps your queries remain performant as your application scales.\n\nWhen you tell IBM Cloudant to create a secondary index, it starts a background task that looks at all the documents in turn and creates a new data structure on disk: the index. The index is a balanced tree which pairs the keys (the attribute or attributes that you need indexed) with the document _id they came from.\n\nThe index can be used to efficiently lookup known keys and ranges of keys without having to rescan the entire database.\n\nAnother trick that you can employ at index time is the partial filter. You can optionally supply a partial filter in your index definition. This IBM Cloudant Query selector is executed at index time to decide which documents' data makes it to the index and which are ignored.\n\nIn this example, a selector is employed that allows only dates that fall on a weekend to make it to the index. Smaller indexes are faster and more efficient.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.39038005}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16258-1324-3123","score":18.1314315796,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-2570-3569","score":15.6062746048,"text":"\n[Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps. A panel opens showing the full back and forth between your customer and the assistant, including step interactions. The panel also provides a summary of how many requests there were, how many were recognized, whether search was initiated, and the duration of the conversation.\n\n![Conversation detail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-side.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-7-1952","score":15.4125890732,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_03028-7-1945","score":14.765089035,"text":"\nImprove your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nThe Analytics page was introduced with version 1.5.0.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nMessage logs are retained for 90 days.\n\n\n\n\n\n Filtering messages \n\nYou can filter messages by Search user statements, Intents, Entities, and Last n days.\n\nSearch user statements - Type a word in the search bar. This searches the users' inputs, but not your assistant's replies.\n\nIntents - Select the drop-down menu and type an intent in the input field, or choose from the populated list. You can select more than one intent, which filters the results using any of the selected intents, including Irrelevant.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs"},{"document_id":"ibmcld_06953-2615-5096","score":14.2602834702,"text":"\nWhen Emphasize the answer is used (\"find_answers\": true), Discovery rescores and reorders the documents to ensure that documents with the highest-quality answers are returned first.\n\n\n\n\n\n Choosing a project type \n\nIf the Conversational Search project type isn't providing the best answers and you want to understand why, switch to using a Document Retrieval project type.\n\nMost often, the Conversational Search project type is the right choice. You get great results from the start, and when you enable extra features like Emphasize the answer, the answers are clear and concise. However, for advanced use cases, or if you want to be able to troubleshoot issues, a Document Retrieval project type might be a better fit.\n\nTo help you choose the right Discovery project type, review the project type differences that are described in the following table.\n\n\n\nProject type details\n\n Function Conversational Search Document Retrieval \n\n Enrichment support Only the Part of Speech enrichment is applied. The Part of Speech and Entities enrichments are applied. The Entities enrichment is helpful for identifying important information and introduces more ways to filter query results. \n Testing queries from the Improve and customize page in Discovery You see only one of the responses that are returned from the chatbot. You cannot see all of the available responses and cannot analyze individual query results. You can filter query results by enrichment-based facets. You can review details about fields that are indexed in the source documents that are returned for a query. Access to more information makes it easier to troubleshoot unexpected results. \n Search triggers Returns answers from the text field automatically. If answers are stored in another field, you must change the configuration. You can apply a Smart Document Understanding (SDU) model or enrichments to your collections and retrieve useful information from fields other than text when search is triggered from the assistant. \n\n\n\nFor both project types, the best way to test is to trigger search from the Watson Assistant preview. When you configure search support for an assistant, you can fine-tune the experience in ways that aren't available in Discovery.\n\nAnd settings that are available from the Search results tool for a Document Retrieval project type are replaced by configuration settings that you specify in Watson Assistant. For example, the query response title and body are defined in Watson Assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-chat-choose-project"},{"document_id":"ibmcld_03330-3253-5192","score":14.1250362396,"text":"\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https:\/\/medium.com\/ibm-watson\/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https:\/\/www.ibm.com\/blogs\/watson\/2020\/03\/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits\/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_03330-1656-3789","score":13.8118314743,"text":"\nMake your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/arch-detail.png)\n\n\n\n* Customers interact with the assistant through one or more of these channels:\n\n\n\n* An existing social media messaging platform, such as Slack, Facebook Messenger, or WhatsApp\n* A phone call or text message\n* A web chat that you embed in your company website and that can transfer complex requests to a customer support representative.\n* A custom application that you develop, such as a mobile app or a robot with a voice interface\n\n\n\n* The assistant receives a message from a customer and sends it down the appropriate resolution path.\n\nIf you want to preprocess incoming messages, this is where you would use webhooks to inject logic that calls an external service that can process the messages before the assistant routes them. Likewise, you can process responses from the assistant before they are returned to the customer.\n* The assistant chooses the appropriate resolution from among these options:\n\n\n\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_16370-1488-3149","score":13.7154788971,"text":"\nDepending on the design of your application, there are various ways to do this, but one simple mechanism is to check the value of a URL query parameter (in this example, page):\n\nconst page = new URLSearchParams(window.location.search).get('page');\n2. Create a handler for the [pre:send](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventspresend) event, which is fired before a message is sent to the assistant. This handler starts by checking the [is_welcome_request](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventsmessageextensions) property to determine whether the message being sent is the empty message that starts the conversation by triggering the Greet customer action.\n\nIf it is, the handler then checks the currently displayed page, and it replaces the outgoing empty message with a message that will trigger an action that is specific to the page. (This example only shows setting the message to Credit Cards, but additional if conditions could customize the message for other pages.)\n\nfunction preSendHandler(event) {\nif (event.data.history && event.data.history.is_welcome_request) {\nif (page === 'cards') {\nevent.data.input.text = 'Credit Cards';\n}\n}\n}\n3. In your onLoad event handler, use the [once()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsonce) instance method to subscribe to the pre:send event, registering the preSendHandler() function as the callback. (We can use once() instead of on() because this handler needs to be called only for the first message in the session.)\n\ninstance.once({ type: 'pre:send', handler: preSendHandler});","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-custom-action-for-page"},{"document_id":"ibmcld_03273-3976-5874","score":13.5592489243,"text":"\nTo add a context variable, specify the variable name, and press Enter.\n2. To define a default value for the context variable, find the context variable you added in the list, and then specify a value for it.\n\n\n\nSee [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-context) for more information.\n8. Continue to interact with the dialog to see how the conversation flows through it.\n\n\n\n* To find and resubmit a test utterance, you can press the Up key to cycle through your recent inputs.\n* To remove prior test utterances from the chat pane and start over, click the Clear link. Not only are the test utterances and responses removed, but this action also clears the values of any context variables that were set as a result of your interactions with the dialog.\n\n\n\n\n\n\n\n What to do next \n\nMake changes to the dialog to address issues you see when testing:\n\n\n\n* If you determine that the wrong intents or entities are being recognized, you might need to modify your intent or entity definitions.\n* If the correct intents and entities are being recognized, but the wrong nodes are being triggered in your dialog, make sure your conditions are written properly.\n\n\n\nIf you are ready to put the conversation to work helping your users, integrate your assistant with a messaging platform or custom application. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add).\n\n\n\n\n\n\n\n Searching your dialog \n\nYou can search the dialog to find one or more dialog nodes that mention a given word or phrase.\n\n\n\n1. Select the Search icon: ![Search icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/search_icon.png)\n2. Enter a search term or phrase.\n\nThe first time you search, an index is created. You might be asked to wait while the text in your dialog nodes is indexed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_16364-201078-203239","score":13.3573093414,"text":"\nSee [Fuzzy matching](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-fuzzy-matching) for details.\n\n\n\n\n\n 13 June 2017 \n\nUser conversations\n: The Improve panel now includes a User conversations page, which provides a list of user interactions with your chatbot that can be filtered by keyword, intent, entity, or number of days. You can open individual conversations to correct intents, or to add entity values or synonyms.\n\nRegex change\n: The regular expressions that are supported by SpEL functions like find, matches, extract, replaceFirst, replaceAll and split have changed. A group of regular expression constructs are no longer allowed, including look-ahead, look-behind, possessive repetition and backreference constructs. This change was necessary to avoid a security exposure in the original regular expression library.\n\n\n\n\n\n 12 June 2017 \n\nUpdates\n: This release includes the following updates:\n\n\n\n* The maximum number of workspaces that you can create with the Lite plan (formerly named the Free plan) changed from 3 to 5.\n* You can now assign any name to a dialog node; it does not need to be unique. And you can subsequently change the node name without impacting how the node is referenced internally. The name you specify is treated as an alias and the system uses its own internal identifier to reference the node.\n* You can no longer change the language of a workspace after you create it by editing the workspace details. If you need to change the language, you can export the workspace as a JSON file, update the language property, and then import the JSON file as a new workspace.\n\n\n\n\n\n\n\n 6 June 2017 \n\nLearn\n: A new Learn about IBM Watson\u00ae Assistant page is available that provides getting started information and links to service documentation and other useful resources. To open the page, click the icon in the page header.\n\nBulk export and delete\n: You can now simultaneously export a number of intents or entities to a CSV file, so you can then import and reuse them for another Watson Assistant application. You can also simultaneously select a number of entities or intents for deletion in bulk.\n\nUpdates to Korean","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03042-2711-4616","score":21.2172393799,"text":"\n{: note}\n\n1. conversation_id (v1 only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\nShow more\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For web chat, you can set the value of the user_id property. For more information, see [Adding user identity information](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid).\n\n\n\n\n\n Handling anonymous users \n\nIf your custom application or assistant interacts with users who are anonymous, you can generate a randomized universally unique ID to represent each anonymous user. For more information about UUIDs, see [RFC 4122](https:\/\/tools.ietf.org\/html\/rfc4122.html).\n\n\n\n* For web chat, if you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user.\n\n\n\n\n\n\n\n\n\n Service API versioning","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-services-information"},{"document_id":"ibmcld_03107-5127-7134","score":21.1889533997,"text":"\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For Facebook integrations, the user_id property is set to the sender ID that Facebook provides in its payload.\n* For Slack integrations, the user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n* For web chat, you can set the value of the user_id property.\n\n\n\nBilling is managed per monthly active user per service instance. If a single user interacts with assistants that are hosted by different service instances that belong to the same plan, each interaction is treated as a separate use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_03037-1358-3485","score":18.9574069977,"text":"\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing. A skill is effectively a wrapper for a V1 workspace.\n\n\n\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each \/message API call.\n\n\n\n\n\n Enabling user metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_03107-3801-5605","score":18.4000339508,"text":"\nThe user_id property is specified at the root of the request body, as in this example:\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"I want to cancel my order\"\n},\n\"user_id\": \"my_user_id\"\n}\n\nIn some older SDK versions, the user_id property is not supported as a top-level method parameter. As an alternative, you can specify user_id within the nested context.global.system object.\n\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2messagestateless)\n* [v2 stateful \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_16258-1324-3123","score":17.9599246979,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16252-3899-5971","score":17.6068782806,"text":"\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2messagestateless)\n* [v2 stateful \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"},{"document_id":"ibmcld_16259-1485-3642","score":17.4235496521,"text":"\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery\/takeout, Small\/Medium\/Large, Cheese\/Pepperoni\/Mushrooms\/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview"},{"document_id":"ibmcld_03109-5081-6683","score":16.2335929871,"text":"\nThe Intercom user_id property is the id of the author message object in the Conversation Model that is defined by Intercom.\n\n\n\n* To get the ID, open the channel from a web browser. Open the web developer tools to view the console. Look for author.\n\n\n\nThe full customer ID looks like this: customer_id=intercom_5c499e5535ddf5c7fa2d72b3.\n* For Slack, the customer_id is the user_id prepended with slack_. The Slack user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n\n\n\n* To get the team ID, open the channel from a web browser. Open the web developer tools to view the console. Look for [BOOT] Initial team ID.\n* You can copy the member ID from the user's Slack profile.\n* To get the IDs programmatically, use the Slack API. For more information, see [Overview](https:\/\/api.slack.com\/apis). The full customer ID looks like this: customer_id=slack_T09LVDR7YW4F8K9JNF.\n\n\n\n* For the web chat integration, the service takes the user_id that is passed in and adds it as the customer_id parameter value to the X-Watson-Metadata header with each request.\n\n\n\n\n\n Before you begin \n\nTo be able to delete message data associated with a specific user, you must first associate all messages with a unique customer ID for each user. To specify the customer ID for any messages sent using the \/message API, include the X-Watson-Metadata: customer_id property in your header. For example:\n\ncurl -X POST -u \"apikey:3Df... ...Y7Pc9\"\n--header\n'Content-Type: application\/json'\n'X-Watson-Metadata: customer_id=abc'\n--data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-securing"},{"document_id":"ibmcld_03036-7103-8947","score":15.7260160446,"text":"\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter. See [Enabling user metrics](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resourceslogs-resources-user-id) for more information.\n\n\n\n\n\n\n\n Top Intents and Top Entities \n\nYou can also view the intents and entities that were recognized most often during the specified time period.\n\n\n\n* Top intents - Intents are shown in a simple list. In addition to seeing the number of times an intent was recognized, you can select an intent to open the User conversations page with the date range filtered to match the data you are viewing, and the intent filtered to match the selected intent.\n* Top entities are also shown in a list. For each entity you can select from the Values column to see a list of the most common values that were identified for this entity during the time period. You can also select an entity to open the User conversations page with the date range filtered to match the data you are viewing, and the entity filtered to match the selected entity.\n\n\n\nSee [Improve your skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs) for tips on how to edit intents and entities based on discoveries you make by reviewing the intents and entities that your assistant recognizes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03273-2494-4395","score":15.7247667313,"text":"\n[Location](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/location.png) icon next to it.\n\nIf you are not already on the Dialog page, open it.\n\nThe source node is given focus and the route that your assistant traversed through the tree to get to it is highlighted. It remains highlighted until you perform another action, such as entering a new test input.\n7. To check or set the value of a context variable, click the Manage context link.\n\nAny context variables that you defined in the dialog are displayed.\n\nIn addition, the following context variables are listed:\n\n\n\n* $timezone: The Try it out pane gets user locale information from the web browser and uses it to set the $timezone context variable. This context variable makes it easier to deal with time references in test dialog exchanges.\n* $metadata: This context variable contains a user ID name and value pair. Because no user_id is specified by default in the Try it out pane, the conversation_id is used as the user_id value. At run time, the ID value is typically passed to the assistant from whatever integration you are using. If you design a custom application, you set this value yourself.\n\n\n\nYou can add a variable and set its value to see how the dialog responds in the next test dialog turn. This capability is helpful if, for example, the dialog is set up to show different responses based on a context variable value that is provided by the user.\n\n\n\n1. To add a context variable, specify the variable name, and press Enter.\n2. To define a default value for the context variable, find the context variable you added in the list, and then specify a value for it.\n\n\n\nSee [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-context) for more information.\n8. Continue to interact with the dialog to see how the conversation flows through it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2640681226,"ndcg_cut_10":0.2640681226}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03966-5017-7130","score":21.386631012,"text":"\nAssociating the identity of the CA admin \n\nBefore you can create identities, you need to associate the identity of the CA admin. Open your CA on the Nodes tab. If you are using the CA for the first time, you can click the Associate identity button to generate the CA admin identity and import it into your console wallet. On the Associate identity side panel, provide the Enroll ID and Enroll secret of the CA admin that you provided when you created the CA.\n\nYou can view the enroll ID of the associated admin on the left side of the CA panel, below the CA name, Node location, and Fabric version. You can use this identity to create other identities by using the Register button. The CA admin also allows you to get the list of registered identities, and then use these identities to generate certificates by using the Enroll button.\n\nTo use a different identity as the CA admin, click the identity that is associated with the CA admin. This opens the Associate identity side panel. You can use the Enroll an identity tab to provide the enrollID and secret of another CA admin. You can specify an identity that exists in the wallet by using the Select an existing identity tab.\n\nYou can only use admin identities to register new users. You can create new admins with restrictions on the type of users they are allowed to create. As a result, you can let another user operate your CA by providing them an admin that is not able to create admins or deploy nodes. This allows other members or departments of your organization to access your CA without compromising your network. For more information, see [Creating new CA admins](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identitiesibp-console-identities-ca-admin).\n\n\n\n\n\n Registering identities \n\nThe first step in creating an identity is known as registration. During registration, an enroll ID and secret are created which can be used by a node or an org administrator to enroll this identity by generating a signing certificate and private key.\n\nYou need to enter the following information when you register a new identity with your CA.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_02210-1649-3259","score":20.740524292,"text":"\nRequired access for managing service ID API keys \n\nAll users can create service IDs in an account, and they are the administrator for those IDs and can create the associated API key and access policies. However, account owners and users assigned the Administrator role on the IAM Identity service can manage the API keys for all service IDs in an account. Users can also be given access to a single service ID only, if the ID is specified when the administrator assigns the access.\n\nIf you are a user with the required access, you can view, update, and delete API keys for any service ID in the account. Go to the API keys page, and select the All service ID API keys option in the View menu to find an API key that you want to view details for, update, or delete.\n\n\n\n\n\n Creating an API key for a service ID \n\nCreate an API key to associate with a service ID in the console:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Service IDs.\n2. If you don't have a service ID created, create the service ID.\n3. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/action-menu-icon.svg) > Manage service ID.\n4. Click API keys.\n5. Click Create.\n6. Add a name and description to easily identify the API key.\n7. Click Create.\n8. Save your API key by copying or downloading it to secure location.\n\n\n\nFor security reasons, the API key is only available to be copied or downloaded at the time of creation. If the API key is lost, you must create a new API key.\n\n\n\n\n\n Creating an API key for a service ID by using the CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceidapikeys&interface=ui"},{"document_id":"ibmcld_11474-5244-7072","score":20.5352230072,"text":"\nOpen the App ID instance page from the [resource list](https:\/\/cloud.ibm.com\/resources) Services and software section.\n2. Go to Manage Authentication \u2192 Cloud Directory \u2192 Users, and click Create User. Enter the user details.\n\n\n\n\n\n\n\n Step 6: Create or modify users' project assignments \n\nIf the IDP administrator will assign users to projects, you can define project values in the user's attributes.\n\n\n\n1. Open the App ID instance page from the [resource list](https:\/\/cloud.ibm.com\/resources) Services and software section.\n2. Go to Manage Authentication \u2192 Cloud Directory \u2192 Users, and click a user to open it.\n3. Scroll down to Custom Attributes, and click Edit.\n4. Enter a key value pair that can will checked by the dynamic rules of the access groups, then click Save. You can add several values in the same string (for example, {\"project\":\"ml finance\"}); the contains qualifier of the dynamic rule detects a match of a substring. For our example, add:\n\n{\"project\":\"ml\"}\n\nThe value project corresponds to the convention defined in the planning section. ml is the project that the user belongs to.\n\nThis check is done on every login, so changes in the ID provider user attributes will be effective when a user next logs in.\n\n\n\n\n\n\n\n User flow \n\n\n\n1. A user is sent the ID provider URL for the IBM Cloud account.\n\nThe administrator can always go to [Manage \u2192 Access (IAM) \u2192 Identity providers](https:\/\/cloud.ibm.com\/iam\/identity-providers) to look up the ID provider URL.\n2. To work with Qiskit Runtime serive instances, users must create an API key by going to ([Manage \u2192 Access (IAM) \u2192 API keys](https:\/\/cloud.ibm.com\/iam\/apikeys)).\n3. For further information, users can review [Getting started, Step 2](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-get-startedinstall-packages).\n\n\n\n\n\n\n\n Example scenario","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-appid-org"},{"document_id":"ibmcld_09382-5993-6824","score":20.472234726,"text":"\nAdd a user or service ID to the access group \n\nContinue to set up your group by adding users or service IDs.\n\n\n\n Add a user to the access group \n\nComplete the following steps to add a user:\n\n\n\n1. From the menu bar, click Manage > Access (IAM), and select Access Groups.\n2. Select the name of the group that you want to assign access to.\n3. Click Add users on the Users tab.\n4. Select the users that you want to add from the list, and click Add to group.\n\n\n\n\n\n\n\n Add a service ID to the access group \n\nComplete the following steps to add a service ID:\n\n\n\n1. From the menu bar, click Manage > Access (IAM), and select Access Groups.\n2. Select the name of the group that you want to assign access to.\n3. Click the Service IDs tab, and click Add service ID.\n4. Select the IDs that you want to add from the list, and click Add to group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-iam_manage_events"},{"document_id":"ibmcld_11472-2693-4203","score":20.2846431732,"text":"\nStep 3: Integrate the App ID instance as the ID provider for the administrator's account \n\n\n\n1. Go to [Manage \u2192 Access (IAM) \u2192 Identity Providers](https:\/\/cloud.ibm.com\/iam\/identity-providers). For Type, choose IBM Cloud App ID, then click Create.\n2. Specify a name and select the App ID instance from the drop-down list.\n3. Select the checkbox to enable the ID provider.\n\nZoom\n\n![Create identity provider](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5f399fa794584e8a662591b494b9a99aa927c74c\/quantum-computing\/images\/org-guide-idp-reference.png)\n\nFigure 3. Create identity provider page\n4. The default IdP URL is shown. Share this URL with users when they need to log in.\n\n\n\n\n\n\n\n Step 4: Add Users \n\nWhen you use App ID as ID provider with the Cloud directory, you can create users in the IBM Cloud user interface.\n\n\n\n1. Open the App ID instance page from the [resource list](https:\/\/cloud.ibm.com\/resources) Services and software section.\n2. Go to Manage Authentication \u2192 Cloud Directory \u2192 Users, and click Create User. Enter the user details.\n\n\n\n\n\n\n\n Step 5: Create or modify users' project assignments \n\n\n\n1. Go to [Manage \u2192 Access (IAM) \u2192 Users](https:\/\/cloud.ibm.com\/iam\/users) and click the user.\n\nZoom\n\n![Change User Access](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5f399fa794584e8a662591b494b9a99aa927c74c\/quantum-computing\/images\/org-guide-manage-user.png)\n\nFigure 11. Change User Access\n\nIf you don't see the user that you want to manage, verify that they logged in to IBM Cloud at least once.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-appid-cloud-org"},{"document_id":"ibmcld_08423-6549-8265","score":20.2614879608,"text":"\n3. To create an API key for the service ID, follow these steps:\n\n\n\n1. Click the API keys tab on the SO user service ID page.\n2. Click Create.\n3. Add a name and description to easily identify the API key, for example, SO user API key.\n4. Click Create.\n5. Save your API key by copying or downloading it to secure location.\n\n\n\nThe API key is to be used as the PIN for the SO user logins, and cannot be retrieved. Make sure to make a copy of it in this step.\n\n\n\n\n\n\n\n 2. Create service IDs and API keys for the normal user \n\nTo create a service ID for the normal user and the corresponding API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Service IDs.\n2. To create the service ID for the normal user, follow these steps:\n\n\n\n1. Click Create.\n2. Create a name Normal user and description for the normal user service ID.\n3. Click Create.\n\n\n\n3. To create an API key for the service ID, follow these steps:\n\n\n\n1. Click the API keys tab on the Normal user service ID page.\n2. Click Create.\n3. Add a name and description to easily identify the API key, for example, Normal user API key.\n4. Click Create.\n5. Save your API key by copying or downloading it to secure location.\n\n\n\nThe API key is to be used as the PIN for the normal user logins, and cannot be retrieved. Make sure to make a copy of it in this step.\n\n\n\n\n\n\n\n 3. Create service IDs and API keys for the anonymous user \n\nTo create a service ID for the anonymous user and the corresponding API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Service IDs.\n2. To create the service ID for the anonymous user, follow these steps:\n\n\n\n1. Click Create.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-best-practice-pkcs11-access"},{"document_id":"ibmcld_02174-4-2100","score":20.1805934906,"text":"\n* UI\n* Terraform\n\n\n\n\n\n\n\n Restricting users from creating service IDs \n\nBy default, all members of an account can create service IDs. However, access can be restricted so that only members with the correct access can create service IDs by using the Service ID creation setting. For more information about Service IDs, see [Creating and working with service IDs](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceids).\n\n\n\n Enabling the restriction to create service IDs in the console \n\nTo enable the setting to restrict users from creating service IDs, you must have the following assigned access:\n\n\n\n* An IAM policy with the Administrator, Operator, or Editor role on the [IAM Identity Service](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-servicesidentity-service-account-management).\n\n\n\nIf you enable the Service ID creation setting, users in your account require specific access to create service IDs, including the account owner. To restrict who can create service IDs, use the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Settings.\n2. In the Account section, enable the Service ID creation setting.\n3. Click Yes to confirm.\n\n\n\nNow that the setting is enabled to restrict users from creating service IDs, you can assign the required access to enable specific users to continue creating service IDs. Remember, the account owner is also required to be assigned this explicit access.\n\n\n\n\n\n Enabling the restriction to create service IDs by using Terraform \n\nIf you enable the Service ID creation setting, users in your account require specific access to create service IDs, including the account owner.\n\nTo enable the setting to restrict users from creating service IDs, you must have the following assigned access:\n\n\n\n* An IAM policy with the Administrator, Operator, or Editor role on the [IAM Identity Service](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-servicesidentity-service-account-management).\n\n\n\nBefore you can set limits for login sessions by using Terraform, make sure that you have completed the following:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-restrict-service-id-create"},{"document_id":"ibmcld_02104-7488-9365","score":20.1455173492,"text":"\nFor more information about trusted profiles, see [Creating trusted profiles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-trusted-profile).\n\n\n\nIf you have onboarding set to Static and the user selects a trusted profile when they log in the first time, the user is still added to the account.\n5. Then, select the following settings (Optional):\n\n\n\n* Enable for account login?: Enable your IdP references to be used for users to log in to your account. This option is set by default when you first create an IdP reference.\n* Set as the default?: Users can use the default IdP reference URL that you created when you enabled this feature to log in to your account. You can have only one default IdP reference. For all other IdP references that you create, users must use the realm IDs to log in.\n\n\n\n6. Click Create.\n\n\n\nYour IdP reference is now available on the Identity providers list and the realm ID is generated automatically as the value that represents your IAM IdP in IBM Cloud.\n\n\n\n\n\n Logging in with external identity provider credentials \n\nAfter your App ID instance is connected to your IdP, and your App ID instance is integrated with IAM, your users can start logging in to your account. If the IdP reference is set as the default, then you can share the Default IdP URL for your account.\n\nHowever, since you can have only one set as the default, but you can have up to five set up in your account, you might need to get the URL for another IdP reference:\n\n\n\n1. From the Identity provider pages, click the Actions icon ![List of actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/action-menu-icon.svg) for the row of the IdP reference you need a URL for.\n2. Select View IdP URL.\n3. Copy the IdP URL link to give to users to log in.\n\n\n\n\n\n\n\n Using App ID instances to build dynamic rules in access groups","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-idp-integration"},{"document_id":"ibmcld_03966-9450-11507","score":19.8575439453,"text":"\nBe sure that you have [set the identity](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identitiesibp-console-identities-ca-identity) to a CA admin that has the ability to register new users before you attempt this task. In general, this is your admin user. If the button is gray, you have either not set an identity, or that the identity cannot create new identities.\n\nClicking Register user opens a series of side panels:\n\n\n\n1. On the first side panel, enter the Enroll ID and Enroll Secret of the new identity. Save these values, as they are not stored by the console.\n2. Select the identity Type. The drop-down list contains the list of types that the CA supports. If you are registering an identity that will serve as an admin of a node, select type admin. If you are registering a peer identity select peer and likewise for an ordering node identity select orderer. When you need to register an identity for a client application select the type client.\n3. You can associate an affiliation with the user. Check the Use root affiliation checkbox for the user if you want them to have the root affiliation and be able to see all other users registered with this CA. When you deselect Use root affiliation, you can select a specific affiliation from the list to associate with this user. The platform includes the default affiliation ibp.\n4. Enter the Maximum Enrollments allowed for this identity. If not specified, the value defaults to unlimited enrollments.\n5. On the last side panel, add the Attributes of the identity you are creating.\n\n\n\nAfter you click Register, the new identity will be added to the list of Authenticated users that have been created by your CA. The identities are listed by their Enroll ID, along with their Type and Affiliation. Clicking on an identity in the table opens a side panel that displays the number of Maximum Enrollments and Attributes that were created during registration.\n\nDeleting a user\nIf you need to delete a registered user, click the action menu next to any user and select Delete user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_08423-7919-9687","score":19.8546867371,"text":"\n3. Create service IDs and API keys for the anonymous user \n\nTo create a service ID for the anonymous user and the corresponding API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM), and select Service IDs.\n2. To create the service ID for the anonymous user, follow these steps:\n\n\n\n1. Click Create.\n2. Create a name Anonymous user and description for the anonymous user service ID.\n3. Click Create.\n\n\n\n3. To create an API key for the service ID, follow these steps:\n\n\n\n1. Click the API keys tab on the Anonymous user service ID page.\n2. Click Create.\n3. Add a name and description to easily identify the API key, for example, Anonymous user API key.\n4. Click Create.\n5. Save your API key by copying or downloading it to secure location.\n\n\n\nThe API key is to be used as the PIN for the anonymous user logins, and cannot be retrieved. Make sure to make a copy of it in this step.\n\n\n\nFor more information about creating services IDs, see [Creating and working with service IDs](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceids). For detailed instructions on creating service ID API keys, see [Managing service ID API keys](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceidapikeys).\n\n\n\n\n\n\n\n Step 3: Assign IAM roles to the service IDs \n\nYou can grant access to service IDs within a Hyper Protect Crypto Services service instance by using the IBM Cloud console.\n\n\n\n 1. Assign the custom roles to the SO user service ID \n\nTo assign the custom roles that are defined in [Step 1](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-best-practice-pkcs11-accessstep1-create-custom-roles) to the SO user service ID, follow these steps:\n\nTo assign access to the keystores for the SO user, follow these steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-best-practice-pkcs11-access"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.3065735964}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02746-7-1681","score":17.2050685883,"text":"\nDefining password policies \n\nPassword policies, such as strength requirements, help you to enforce more secure applications. By defining advanced policies, you can define the rules that a user must conform to when they set their password or attempt to sign in to your app. For example, you can set the number of times that a user can try to sign in before they are locked out of their account.\n\n\n\n Policy: password strength \n\nA strong password makes it difficult, or even improbable for someone to guess the password in either a manual or automated way. To set requirements for the strength of a user's password, you can use the following steps.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. In the Define password strength box, click Edit. A screen opens.\n3. Enter a valid regex string in the Password strength box.\n\nExamples:\n\n\n\n* Must be at least 8 characters. (^.{8,}$)\n* Must have one number, one lowercase letter, and one capital letter. (^(?:(?=.d)(?=.[a-z])(?=.[A-Z]).)$)\n* Must have only English letters and numbers. (^[A-Za-z0-9]$)\n* Must have at least one unique character. (^(w)w?(?!1)w+$)\n\n\n\n4. Click Save.\n\n\n\nPassword strength can be set in the Cloud Directory settings page in the App ID dashboard, or by using [the management APIs](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Management%20API%20-%20Config\/mgmt.set_cloud_directory_password_regex).\n\n\n\n Setting a custom error message \n\nIf you set your own password regex policy and a user chooses a password that does not meet your requirements, the default message is The password doesn't meet the strength requirements.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_07765-0-1628","score":16.7962532043,"text":"\n\n\n\n\n\n\n  IA-5 (4) - Automated Support for Password Strength Determination \n\n\n\n  Control requirements \n\nIA-5 (4) - 0\n:   The organization employs automated tools to determine if password authenticators are sufficiently strong to satisfy [Assignment: organization-defined requirements].\n\n\n\n\n\n  IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n*  Check whether App ID advanced password policies are enabled\n*  IBMid employs automated tools to determine if password authenticators satisfy IBMid password requirements\n*  Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n*  Check whether App ID password strength regex is configured\n*  Check whether IBMid password policy policy contains spaces or any of the following characters: ;:(\"?)<>\n*  Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters\n*  Check whether IBMid password policy requires at least one uppercase letter\n*  Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nThis control enhancement focuses on the creation of strong passwords and the characteristics of such passwords (e.g., complexity) prior to use, the enforcement of which is carried out by organizational information systems in IA-5 (1).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5.4"},{"document_id":"ibmcld_02746-1213-3197","score":15.2558250427,"text":"\nPassword strength can be set in the Cloud Directory settings page in the App ID dashboard, or by using [the management APIs](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Management%20API%20-%20Config\/mgmt.set_cloud_directory_password_regex).\n\n\n\n Setting a custom error message \n\nIf you set your own password regex policy and a user chooses a password that does not meet your requirements, the default message is The password doesn't meet the strength requirements. You can also choose to set your own message by using the [\/management\/v4\/{tenantId}\/config\/cloud_directory\/password_regex endpoint](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Management%20API%20-%20Config\/mgmt.set_cloud_directory_password_regex).\n\n\n\n\n\n\n\n Advanced password policies \n\nYou can enhance the security of your application by enforcing password constraints.\n\nYou can create an advanced password policy that consists of any combination of the following five features:\n\n\n\n* Lockout after repeated wrong credentials\n* Avoid password reuse\n* Password expiration\n* Minimum period between password changes\n* Ensure that the password does not include user name\n\n\n\nWhen you enable this feature, extra billing for advanced security capabilities is activated. For more information, see [how does App ID calculate pricing](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-pricing).\n\n\n\n Policy: Avoid Password Reuse \n\nYou might want to prevent your users from choosing a recently used password when they attempt to create a new one. If they try to set their password to one that was recently used, an error is shown in the default Login Widget GUI and the user is prompted to enter another option. This setting allows for you to choose the number of passwords that a user must have before they're able to repeat a previously used password.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. Toggle Advanced password policy to Enabled.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_13992-1563-3789","score":15.0416088104,"text":"\nSSH provides better security solution than password authentication. See [Getting started with SSH keys](https:\/\/cloud.ibm.com\/docs\/ssh-keys?topic=ssh-keys-getting-started-tutorialgetting-started-tutorial).\n\n\n\n\n\n Record IP addresses and credentials \n\nKeep a log of IP addresses and credentials for the server in a safe location so that you can access them quickly without having to log in to the IBM Cloud console.\n\n\n\n* Individual device IP addresses can be viewed from the Device List.\n* Individual device root passwords can be viewed in the device\u2019s Snapshot View. Click the arrow next to the device name to expand the view.\n* Multiple device IP addresses can be viewed by using the Download CSV action within the Device List. Select Download CSV from the Settings cog to download a full list of devices and details in spreadsheet format.\n\n\n\n\n\n\n\n Update software credentials \n\nAll software that was loaded onto your device during the provisioning process was assigned temporary credentials. These credentials are viewed and managed on the Passwords tab of each device in the IBM Cloud console. Use these temporary credentials to access your software for the first time. As a best practice, change the password to your software after you access it for the first time. Use a strong password that consists of a combination of letters, numbers, and symbols.\n\nOptionally, password updates can be stored on the Passwords tab for each device; however, understand that when you store passwords within the IBM Cloud console, any person with access to the account and appropriate permissions can view passwords that are stored on the Passwords screen.\n\nFor more information about viewing and managing your software credentials, see [Managing classic infrastructure access](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=account-mngclassicinfra).\n\n\n\n\n\n Access your server on the private network \n\nThe private network is the precursor to interacting with your devices through remote desktop (RDP) using SSH and KVM over IP. The VPN Access tool allows for private network connection to either the closest SSL VPN endpoint or to the endpoint of your choice. VPN access is also required to interact with several services that are offered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-configuring-virtual-servers"},{"document_id":"ibmcld_02746-7454-8167","score":14.8918743134,"text":"\n\"user_id\" : \"356e065e-49da-45f6-afa3-091a7b464f51\"\n}\n\n\n\n\n\n\n\n Policy: Ensure that the password does not include user name \n\nFor stronger passwords, you might want to prevent users from creating a password that contains their username or the first part of their email address.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. Toggle Advanced password policy to Enabled.\n3. Toggle Password should not contain user ID to Enabled.\n4. Click Save.\n\n\n\nThis constraint is not case-sensitive. Users are not able to alter the case of some or all the characters to use the personal information. To configure this option, toggle the switch to on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_02775-4830-5961","score":13.9207468033,"text":"\nFor a complete list of the options and setup information, see [Advanced password management](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strengthcd-advanced-password). \n\n\n\nThese features are available only to those instances that are on the graduated tier pricing plan and that were created after 15 March 2018.\n\n\n\n\n\n When am I charged? \n\nYour first 1000 authentication events and 1000 authorized users per service instance are free of charge. You are charged monthly for any additional authentication events and authorized users, as well as any advanced security features that are enabled for each service instance.\n\n\n\n\n\n How do I stop getting charged for App ID? \n\nIf you no longer want to be charged for authentication events and authorized users, you need to ensure that no user can authenticate by using App ID. You must remove the App ID configuration from your app code or confirm that your users are not able to use the configuration to log in to your app. To stop getting charged for advance security features, you must disable them on the Manage Authentication > Authentication Settings page of the service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-pricing"},{"document_id":"ibmcld_07761-2352-4487","score":13.1069488525,"text":"\nIA-5 (c) <br><br> * Check whether App ID advanced password policies are enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID prevent username in password policy is enabled<br> * Check whether App ID password strength regex is configured<br> * Check whether OpenShift cluster has image pull secrets enabled<br> * IBM Cloud IAM ensures that authenticators, such as API keys, have sufficient strength for their intended use<br> * Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters<br> * Check whether App ID avoid password reuse policy is enabled<br> * IBMid ensures that passwords have sufficient strength for their intended use<br><br><br> \n IA-5 (f) <br><br> * Check whether App ID minimum period between password changes policy is set to greater than 0<br> * IBM Cloud IAM establishes minimum and maximum lifetime restrictions and reuse conditions for authenticators, such as API keys<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * IBMid establishes minimum and maximum lifetime restrictions and reuse conditions for authenticators<br> * Check whether App ID avoid password reuse policy is enabled<br><br><br> \n IA-5 (g) <br><br> * Check whether Secrets Manager user credentials are rotated at least every # days<br> * Check whether Secrets Manager arbitrary secrets are rotated at least every # days<br> * Check whether Hyper Protect Crypto Services encryption keys that are generated by the service are rotated automatically at least every # months<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nIndividual authenticators include, for example, passwords, tokens, biometrics, PKI certificates, and key cards. Initial authenticator content is the actual content (e.g., the initial password) as opposed to requirements about authenticator content (e.g., minimum password length).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5"},{"document_id":"ibmcld_02602-9630-11410","score":13.0380554199,"text":"\nProperty name:\n\n\n\n16. If required, add another property name. If you do not require any more properties press Enter to finish adding the model.\n\n\n\nBy default, a LoopBack; project comes configured with an in-memory data source, suitable for development and testing. However, at some point you'll want to connect your models to a real data source such as database server. Complete the following steps to add a data source:\n\n\n\n1. Enter the following command:\n\n\n\napic create --type datasource\n\nThe tool prompts you for the name of the data source.\n\n? Enter the data-source name:\n\n\n\n2. Enter a name for the data source. You can use any alphanumeric character, dashes, and underscores in a data source name. The tool prompts you to select the connector to use for the data source:\n\n\n\n? Select the connector for myds: (Use arrow keys)\n> In-memory db (supported by StrongLoop)\nEmail (supported by StrongLoop)\nMySQL (supported by StrongLoop)\nPostgreSQL (supported by StrongLoop)\nOracle (supported by StrongLoop)\nMicrosoft SQL (supported by StrongLoop)\nMongoDB (supported by StrongLoop)\n(Move up and down to reveal more choices)\n\n\n\n3. Use the arrow keys to select the connector that you want to use, then press Enter. The tool then adds the data source to the project.\n4. Enter your host, port, user, password, and database credentials. The tool prompts you to install the LoopBack connector.\n\n\n\nInstall loopback-connector-<connector>?\n\n\n\n5. Type Yes. The tool installs the connector.\n\n\n\nNote: If you selected the Oracle connector, you must set an environment variable in IBM Cloud for the Oracle app to start. To do this, complete the following steps:\n\n\n\n1. In the IBM Cloud UI, select Compute.\n2. In CF Applications, select the application that you want to work with.\n3. Click Runtime.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-creating_apis"},{"document_id":"ibmcld_07761-1647-3208","score":12.9077119827,"text":"\n* [Handling and securing secrets](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-secrets)\n\n\n\n\n\n\n\n IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\nRules for IA-5 in IBM Cloud for Financial Services v1.2.0 profile\n\n Requirement ID Rules \n\n IA-5 (b) <br><br> * IBM Cloud IAM establishes initial authenticator content for authenticators that are defined by the organization (for example, API keys)<br><br><br> \n IA-5 (c) <br><br> * Check whether App ID advanced password policies are enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID prevent username in password policy is enabled<br> * Check whether App ID password strength regex is configured<br> * Check whether OpenShift cluster has image pull secrets enabled<br> * IBM Cloud IAM ensures that authenticators, such as API keys, have sufficient strength for their intended use<br> * Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters<br> * Check whether App ID avoid password reuse policy is enabled<br> * IBMid ensures that passwords have sufficient strength for their intended use<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5"},{"document_id":"ibmcld_07787-0-1608","score":12.3271760941,"text":"\n\n\n\n\n\n\n  MA-4 - Nonlocal Maintenance \n\n\n\n  Control requirements \n\nThe organization:\n\nMA-4 (a)\n:   Approves and monitors nonlocal maintenance and diagnostic activities;\n\nMA-4 (b)\n:   Allows the use of nonlocal maintenance and diagnostic tools only as consistent with organizational policy and documented in the security plan for the information system;\n\nMA-4 (c)\n:   Employs strong authenticators in the establishment of nonlocal maintenance and diagnostic sessions;\n\nMA-4 (d)\n:   Maintains records for nonlocal maintenance and diagnostic activities; and\n\nMA-4 (e)\n:   Terminates session and network connections when nonlocal maintenance is completed.\n\n\n\n\n\n  NIST supplemental guidance \n\nNonlocal maintenance and diagnostic activities are those activities conducted by individuals communicating through a network, either an external network (e.g., the Internet) or an internal network. Local maintenance and diagnostic activities are those activities carried out by individuals physically present at the information system or information system component and not communicating across a network connection. Authentication techniques used in the establishment of nonlocal maintenance and diagnostic sessions reflect the network access requirements in IA-2. Typically, strong authentication requires authenticators that are resistant to replay attacks and employ multifactor authentication. Strong authenticators include, for example, PKI where certificates are stored on a token protected by a password, passphrase, or biometric. Enforcing requirements in MA-4 is accomplished in part by other controls.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ma-4"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03354-4-1897","score":19.1016616821,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Improve your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nThe length of time for which messages are retained depends on your Watson Assistant service plan:\n\nService plan | Chat message retention\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"},{"document_id":"ibmcld_03363-4413-6535","score":18.7165546417,"text":"\nFor more information, see [Ending the conversation gracefully](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-startdialog-start-anything-else).\n\nThe containment and coverage metrics are available to Plus or Enterprise plan users.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period. This number counts exchanges in which the welcome message is displayed to a user, even if the user doesn't respond.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter to be specified with the messages. This value is typically specified by all integrations because it is used for billing purposes. For more information, see [User-based plans explained](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).\n\n\n\n\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03363-6198-7991","score":17.4007053375,"text":"\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter. In each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.\n\nThe time shown for each conversation is localized to reflect the time zone of your browser. However, API log calls are always shown in UTC time. As a result, if you choose a single day view, for example, the time shown in the visualization might differ from the timestamp specified in the log for the same conversation.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-time2.png)\n* Intents and Entities filters - Use either of these drop-down filters to show data for a specific intent or entity in your skill.\n\nThe intent and entities filters are populated by the intents and entities in the skill, and not what is in the data source. If you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_05088-35529-37138","score":16.6636009216,"text":"\nThe new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\ndef add_protection_configuration_to_bucket(bucket_name):\ntry:\nnew_protection_config = {\n\"Status\": \"Retention\",\n\"MinimumRetention\": {\"Days\": 10},\n\"DefaultRetention\": {\"Days\": 100},\n\"MaximumRetention\": {\"Days\": 1000}\n}\n\ncos.put_bucket_protection_configuration(Bucket=bucket_name, ProtectionConfiguration=new_protection_config)\n\nprint(\"Protection added to bucket {0}n\".format(bucket_name))\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to set bucket protection config: {0}\".format(e))\nShow more\n\n\n\n\n\n Check protection on a bucket \n\ndef get_protection_configuration_on_bucket(bucket_name):\ntry:\nresponse = cos.get_bucket_protection_configuration(Bucket=bucket_name)\nprotection_config = response.get(\"ProtectionConfiguration\")\n\nprint(\"Bucket protection config for {0}n\".format(bucket_name))\nprint(protection_config)\nprint(\"n\")\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to get bucket protection config: {0}\".format(e))\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_09950-6051-7138","score":16.5372657776,"text":"\nUpdating retention time interval (time travel) for tables \n\n\n\n1. Go to Databases.\n2. Select the database and schema in which the table that you want to update is.\n3. Select the table.\n4. From the overflow menu, click Update interval.\n5. Type a retention time interval.\nYou can select between 1 day and up to 99 days, or zero to alter a temporal database to nontemporal. For more information on retention time interval and time travel, see [Netezza Performance Server time travel](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-enablingdisabling_tt).\n6. Click Save.\n\n\n\n\n\n\n\n Dropping tables \n\n\n\n1. Go to Databases.\n2. Select the database and schema in which the table that you want to update is.\n3. Select the table.\n4. From the overflow menu, click Drop.\n5. Confirm your choice by clicking Drop.\n\n\n\n\n\n\n\n Viewing space usage (time travel) \n\n\n\n1. Go to Databases.\n2. Select the database and schema in which the temporal table that you want to analyze is located.\n3. Select the table.\n4. Go to the Time travel tab.\n5. Analyze the data.\nYou can view the information in a list or as a chart.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-create-tables"},{"document_id":"ibmcld_05070-25374-27355","score":16.2807540894,"text":"\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period stored in the object metadata is either increased by the given additional time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nfunction extendRetentionPeriodOnObject(bucketName, objectName, additionalSeconds) {\nconsole.log(Extend the retention period on ${objectName} in bucket ${bucketName} by ${additionalSeconds} seconds.);\nreturn cos.extendObjectRetention({\nBucket: bucketName,\nKey: objectName,\nAdditionalRetentionPeriod: additionalSeconds\n}).promise()\n.then((data) => {\nconsole.log(New retention period on ${objectName} is ${data.RetentionPeriod});\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_04939-62476-64507","score":16.2593307495,"text":"\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period stored in the object metadata is either increased by the given additional time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\npublic static void extendRetentionPeriodOnObject(String bucketName, String objectName, Long additionalSeconds) {\nSystem.out.printf(\"Extend the retention period on %s in bucket %s by %s seconds.n\", objectName, bucketName, additionalSeconds);\n\nExtendObjectRetentionRequest req = new ExtendObjectRetentionRequest(\nbucketName,\nobjectName)\n.withAdditionalRetentionPeriod(additionalSeconds);\n\ncos.extendObjectRetention(req);\n\nSystem.out.printf(\"New retention period on %s is %sn\", objectName, additionalSeconds);\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-java"},{"document_id":"ibmcld_05044-62456-64487","score":16.2593307495,"text":"\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)\n\n\n\nThe current retention period stored in the object metadata is either increased by the given additional time or replaced with the new value, depending on the parameter that is set in the extendRetention request. In all cases, the extend retention parameter is checked against the current retention period and the extended parameter is only accepted if the updated retention period is greater than the current retention period.\n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\npublic static void extendRetentionPeriodOnObject(String bucketName, String objectName, Long additionalSeconds) {\nSystem.out.printf(\"Extend the retention period on %s in bucket %s by %s seconds.n\", objectName, bucketName, additionalSeconds);\n\nExtendObjectRetentionRequest req = new ExtendObjectRetentionRequest(\nbucketName,\nobjectName)\n.withAdditionalRetentionPeriod(additionalSeconds);\n\ncos.extendObjectRetention(req);\n\nSystem.out.printf(\"New retention period on %s is %sn\", objectName, additionalSeconds);\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-java"},{"document_id":"ibmcld_05075-1845-4162","score":16.0476989746,"text":"\nThe object version can be be deleted after this date is passed (assuming there are no legal holds on the object version).\n\nThe retention period for new objects can be inherited from the default value set on the bucket, or it can be explicitly defined when writing the object by specifying a Retain Until Date.\n\nWhen you use bucket default settings, you don\u2019t specify a Retain Until Date. Instead, you specify a duration, in either days or years, for which every object version placed in the bucket should be protected. When you place an object in the bucket, a Retain Until Date is calculated for the object version by adding the specified duration to the time of the object write.\n\nIf your request to place an object version in a bucket contains an explicit retention mode and Retain Until Date, those settings override any bucket default settings for that object version.\n\nLike all other Object Lock settings, the Retain Until Date applies to individual object versions. Different versions of a single object can have different retention modes and periods.\n\nImagine an object that is 60 days into a 90-day retention period, and you overwrite that object with the same name and a two year retention period. The operation will succeed and a new version of the object with a two year retention period is created. Meanwhile, after 30 more days the original version is eligible for deletion.\n\n\n\n\n\n Extending a retention period \n\nTo extend the retention period of an object, simply send a request to set a new, longer, retention period. The old value will be overwritten with the new, assuming the requestor has the cloud-object-storage.object.put_object_lock_retention and cloud-object-storage.object.put_object_lock_retention_version actions.\n\n\n\n\n\n Legal Hold \n\nA legal hold is like a retention period in that it prevents an object version from being overwritten or deleted. However, legal holds are more flexible and don't have a defined temporal component. Instead they simply remain in effect until removed. Legal holds can be freely placed and removed by any user who has the cloud-object-storage.object.put_object_lock_legal_hold and cloud-object-storage.object.put_object_lock_legal_hold_version actions.\n\nLegal holds have the additional benefit of acting as method for applying indefinite retention on an object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview"},{"document_id":"ibmcld_09956-7-2100","score":16.0378990173,"text":"\nManaging the default retention time interval for the system and viewing retention time intervals \n\nBefore you set retention time interval for all tables in a schema or database, consider the cost of storage for temporal tables, which could be significant. See [Managing time travel space usage](https:\/\/cloud.ibm.com\/docs\/docs\/netezza?topic=netezza-managing_tt).\n\n\n\n Setting the retention time interval for the system \n\nTo set the default DATA_VERSION_RETENTION_TIME to a specific value for the system, run the SET SYSTEM DEFAULT command.\n\nBefore you set DATA_VERSION_RETENTION_TIME for all tables in a schema or database, consider the cost of storage for temporal tables, which could be significant. See [Managing time travel space usage](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-managing_tt).\n\nSET SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME TO <NUMBER OF DAYS>\n\nExample:\n\nSET SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME TO 30\n\nThe value of the property at the system level determines the default value inherited by a subsequent CREATE DATABASE statement that does not explicitly specify this property.\n\nTo set DATA_VERSION_RETENTION_TIME for a specific object, you can run the ALTER or CREATE command.\n\n\n\n\n\n Viewing the retention time interval with the command-line \n\n\n\n Viewing the default retention time interval for the system with the command-line \n\nTo view DATA_VERSION_RETENTION_TIME for the system, run the SHOW SYSTEM DEFAULT command.\n\nSHOW SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME\n\nIf you did not set the retention time previously, the default is 0.\n\n\n\n\n\n Viewing the retention time interval for tables, schemas, and databases with the command-line \n\nTo view DATA_VERSION_RETENTION_TIME for a specific object, run one of these commands. The commands display DATA_VERSION_RETENTION_TIME only if it is a nonzero value.\n\nd <table_name>\n\nSHOW SCHEMA <schema_name>\n\nl+ <all databases, with detail>\n\nRetention time interval and retention lower bound for an object are available in the dataverretntime and dataverretnlowerbound columns of the following system views:\n\n\n\n* _v_table","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-dataretentioninterval_tt"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.4,"recall_5":0.8,"recall_10":0.8,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.6608397947,"ndcg_cut_10":0.6608397947}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16417-3559-5683","score":18.0465278625,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-3559-5682","score":18.0410766602,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_11132-7-2063","score":11.6120910645,"text":"\nIBM Cloud service level objectives \n\nService level objectives (SLOs) describe the design points that the IBM Cloud\u00ae services are engineered to meet in the following areas:\n\n\n\n* Availability\n* Operations management\n* Performance\n\n\n\nThe SLO is not a warranty and IBM will not issue credits for failure to meet an objective. Refer to the [Service Level Agreements (SLAs)](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slas) for commitments and credits that are issued for failure to meet any committed SLAs.\n\nThe following tables describe the service level objectives (SLOs) for the IBM Cloud services in a high availability configuration. As you aggregate or deploy services into a single zone, your SLO might vary. For more information about how IBM Cloud is striving to ensure the highest availability of services, see [How IBM Cloud ensures high availability and disaster recovery](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtime).\n\n\n\n Service level objectives for IBM Cloud platform services and other vital services \n\nThese services include our control plane and self-service interfaces, IAM service, key management service, virtual machine compute instances, block and object storage services, virtual networks service, web or Layer 7 load-balancing service, and relational DBaaS.\n\n\n\n Platform services \n\nThe following table describes the service level objectives (SLOs) for the vital IBM Cloud platform services in a high availability configuration.\n\n\n\nTable 1. Service level objectives (SLOs) for the IBM Cloud platform services\n\n Platform service Availability target High availability guidance \n\n IBM Cloud console 99.999% [High availability for the platform](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimeplatform-ha) \n IBM Cloud CLI 99.999% [Understanding high availability and disaster recovery for the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ha-dr) \n IBM Cloud network 99.9999% [High availability for the network](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimeha-network)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slo"},{"document_id":"ibmcld_13074-10516-12214","score":11.5168581009,"text":"\n{\n\"text\": \"Georgia\",\n\"sentiment\": {\n\"score\": 0\n},\n\"relevance\": 0.306485\n}\n]\n}\n}\nShow more\n\nIn the preceding example, you could query the keyword text by accessing enriched_text.keywords.text\n\nsentiment is calculated for keywords even if the sentiment enrichment is not selected. To learn more about sentiment scoring, see [Sentiment analysis](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicesentiment-analysis).\n\nThe relevance score ranges from 0.0 to 1.0. The higher the score, the more relevant the keyword.\n\n\n\n\n\n Category classification \n\nCategorizes input text, HTML, or web-based content into a hierarchical taxonomy up to five levels deep. Deeper levels allow you to classify content into more accurate and useful subsegments.\n\nExample portion of a document enriched with Category Classification:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"categories\": [\n{\n\"score\": 0.361614,\n\"label\": \"\/business and industrial\"\n},\n{\n\"score\": 0.329377,\n\"label\": \"\/business and industrial\/company\/merger and acquisition\"\n},\n{\n\"score\": 0.154254,\n\"label\": \"\/business and industrial\/business operations\/business plans\"\n}\n]\nShow more\n\nIn the preceding example, you could query the category label by accessing enriched_text.categories.label\n\nThe label is the detected category. The hierarchy levels are separated by forward slashes. The score for that category ranges from 0.0 to 1.0. The higher the score, the greater the confidence in that category.\n\n\n\n\n\n Concept tagging \n\nIdentifies concepts with which the input text is associated, based on other concepts and entities that are present in that text.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_16417-5155-7505","score":11.0368881226,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":11.0368881226,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_02808-0-1689","score":10.7329368591,"text":"\n\n\n\n\n\n\n  High availability and disaster recovery \n\nAll IBM Cloud\u00ae general availability (GA) services have a Service Level Agreement of 99.99% availability. The services that provide the IBM Cloud getting started experience are GA services that are offered in these regions: Dallas, London, Frankfurt, Sydney, Tokyo, and Washington, DC. Each region has multiple different data centers for redundancy. The data for each location is kept in the data centers near that location. If all the data centers in a location fail, the services for that location become unavailable.\n\nThe services are available only on the public cloud, but the tools that are used with IBM Cloud\u00ae Continuous Delivery, which the services use, can run in dedicated or public cloud environments and in on-premises environments.\n\nYou can add resources manually before you create your app. If the resource stores data, you must ensure that the resource meets all business continuity, disaster recovery, and regulatory compliance standards and policies for your organization. For more information, see [resource-specific documentation](https:\/\/cloud.ibm.com\/docs?tab=all-docs).\n\nSee [ensure zero downtime](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtime) to learn more about the high availability and disaster recovery standards in IBM Cloud. For more information about high availability and disaster recovery for Continuous Delivery, see [Continuous Delivery high availability and disaster recovery](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-ha-dr). You can also find information about [Service Level Agreements](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slas).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-ha-dr"},{"document_id":"ibmcld_16464-13891-15856","score":10.6435241699,"text":"\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_13074-11746-13648","score":10.5829944611,"text":"\nIn the preceding example, you could query the category label by accessing enriched_text.categories.label\n\nThe label is the detected category. The hierarchy levels are separated by forward slashes. The score for that category ranges from 0.0 to 1.0. The higher the score, the greater the confidence in that category.\n\n\n\n\n\n Concept tagging \n\nIdentifies concepts with which the input text is associated, based on other concepts and entities that are present in that text. Concept tagging understands how concepts relate, and can identify concepts that are not directly referenced in the text. For example, if an article mentions CERN and the Higgs boson, the Concepts API functions identifies Large Hadron Collider as a concept even if that term is not mentioned explicitly in the page. Concept tagging enables higher level analysis of input content than just basic keyword identification.\n\nExample portion of a document enriched with Concept Tagging:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"concepts\": [\n{\n\"text\": \"Acme Corporation\",\n\"relevance\": 0.91136,\n\"dbpedia_resource\": \"http:\/\/dbpedia.org\/resource\/Acme_Corporation\"\n},\n{\n\"text\": \"Factory\",\n\"relevance\": 0.886784,\n\"dbpedia_resource\": \"http:\/\/dbpedia.org\/resource\/Factory\"\n}\n]\nShow more\n\nIn the preceding example, you can query the concept text type by accessing enriched_text.concepts.text\n\nThe relevance score ranges from 0.0 to 1.0. The higher the score, the more relevant the concept. Links to the resource(s) are provided, if applicable.\n\n\n\n\n\n Semantic Role extraction \n\nIdentifies subject, action, and object relations within sentences in the input content. Relation information can be used to automatically identify buying signals, key events, and other important actions.\n\nExample portion of a document enriched with Semantic Role Extraction:\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_01313-1377-3091","score":10.5591306686,"text":"\nDetails of specific third-party service integrations can be found in the [External Service Integrations](https:\/\/cloud.ibm.com\/docs\/services\/IoT?topic=IoT-ref-indexref-index) topic.\n\n\n\n How the Watson IoT Platform works with IBM Cloud \n\nInstances of the Watson IoT Platform can be created in the IBM Cloud dashboard. The Watson IoT Platform can be integrated with other IBM Cloud services and accessed by using the IBM Cloud dashboard, however, Watson IoT Platform does not run on IBM Cloud hardware, which allows for continual data collection by your Watson IoT Platform service.\n\n\n\n\n\n Watson IoT Platform service level agreement \n\nThe Watson IoT Platform has provisions for a specified level of service. For details of the service level agreement, see [Watson IoT Platform service level agreement ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimeSLAs).\n\n\n\n\n\n IBM Cloud service level agreement \n\nIBM Cloud publishes terms of use, which differ depending on whether the [IBM Cloud Services Agreement ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](http:\/\/www-05.ibm.com\/support\/operations\/files\/pdf\/csa_us.pdf?cm_mc_uid=65870113399114371461368&cm_mc_sid_50200000=1469524513) or the [IBM International Passport Advantage Agreement ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.ibm.com\/software\/passportadvantage\/pa_agreements.html) apply to the user.\n\n\n\n\n\n Watson IoT Platform Pricing \n\n\n\n IoT Pricing Calculator \n\nFor more information on the available Watson IoT Platform plans and pricing models:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/IoT?topic=IoT-iot-cloud-index"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16417-3559-5683","score":21.3045654297,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-3559-5682","score":21.2840480804,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16464-12399-14287","score":19.0151348114,"text":"\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16417-5155-7505","score":18.4368934631,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":18.4368934631,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16410-8324-10312","score":18.1452541351,"text":"\nInter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set.\n\nYou cannot change the annotation set name after the set is created.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.\n* Open a task to add annotation sets to it. Ensure that the annotation sets that you add include documents that overlap with documents in the original annotation sets.\n\n\n\nFrom the Settings tab of the main navigation, you can specify the following information:\n\n\n\n* Specify preferences for using colors and keyboard shortcuts in the ground truth editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16481-1764-4158","score":18.0020771027,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16417-1764-4158","score":18.0020771027,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16464-10867-12930","score":17.4245986938,"text":"\n[This screen capture shows two mentions connected by the relation type, \"founderOf\".](images\/wks_tut_annotaterelation.png \"This screen capture shows two mentions connected by the relation type, \"founderOf\".\")\n\n\n\n8. From the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\n> Note: In a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16563-10714-12816","score":17.1136856079,"text":"\nFrom the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.4118338404}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03827-9857-10948","score":14.8251981735,"text":"\nn3392fd peerc-statedb-pvc Bound pvc-e945df85-5a32-4d37-991d-b2be334bc09b 100Gi RWO ibmc-file-bronze 48d\nn3392fd peerorg1ca-pvc Bound pvc-152be78e-202d-43a4-bcf7-81a6a9013c2d 20Gi RWO ibmc-file-bronze 49d\nShow more\n\nTo get the details on a particular volume, issue:\n\nkubectl describe pv <VOLUME>\n\nIf you are using the CLI to manage snapshots, you'll need the volumeId value. If you are using the cluster UI, you'll need the Username value. For an example volume named pvc-494ba122-3501-4413-b719-cbb4b3a8f91b, you would issue this command:\n\nkubectl describe pv pvc-494ba122-3501-4413-b719-cbb4b3a8f91b\n\nWhich produces a list of details similar to this example:\n\nName: pvc-494ba122-3501-4413-b719-cbb4b3a8f91b\nLabels: CapacityGb=100\nDatacenter=dal10\nIops=2\nStorageType=ENDURANCE\nUsername=IBM02SEV2046428_106\nbillingType=hourly\nfailure-domain.beta.kubernetes.io\/region=us-south\nfailure-domain.beta.kubernetes.io\/zone=dal10\npath=IBM02SEV2046428_106data01\nserver=fsf-dal1002h-fz.adn.networklayer.com\nvolumeId=155617812\nAnnotations: ibmFileProvisionerIdentity: 44cc1a5f-b755-11ea-bfae-3692beefed97","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-backup-restore"},{"document_id":"ibmcld_03827-10732-12034","score":14.3932180405,"text":"\nfailure-domain.beta.kubernetes.io\/zone=dal10\npath=IBM02SEV2046428_106data01\nserver=fsf-dal1002h-fz.adn.networklayer.com\nvolumeId=155617812\nAnnotations: ibmFileProvisionerIdentity: 44cc1a5f-b755-11ea-bfae-3692beefed97\npv.kubernetes.io\/provisioned-by: ibm.io\/ibmc-file\nFinalizers: [kubernetes.io\/pv-protection]\nStorageClass: ibmc-file-bronze\nStatus: Bound\nClaim: n3392fd\/peera-statedb-pvc\nReclaim Policy: Delete\nAccess Modes: RWO\nVolumeMode: Filesystem\nCapacity: 100Gi\nNode Affinity: <none>\nMessage:\nSource:\nType: NFS (an NFS mount that lasts the lifetime of a pod)\nServer: fsf-dal1002h-fz.adn.networklayer.com\nPath: \/IBM02SEV2046428_106\/data01\nReadOnly: false\nEvents: <none>\nShow more\n\nYou can then order snapshots for that volume, which can be done by using either the CLI or the cluster UI. For information on how to take the snapshot, see [Ordering Snapshots](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-ordering-snapshots).\n\nIn this case, \"ordering\" refers to the \"order to take snapshots\" and not \"ordering nodes\".\n\nFor our example, we use the CLI and order a single snapshot by using 5 GB of space by issuing:\n\nibmcloud sl file snapshot-order 155617812 -s 5\n\nYou might need more or less than 5 GB of space, depending on the size of the pod and the resources that have been used on it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-backup-restore"},{"document_id":"ibmcld_15092-4396-6100","score":14.3693037033,"text":"\nAll volumes are assigned instance bandwidth proportional to their maximum bandwidth, where the sum of all volume bandwidth equals the overall \"volumes\" bandwidth.\n\nIn our [example](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-bandwidthvolume-adjust-bandwidth), the remaining bandwidth that is allocated on the instance for data volumes is 1,607 Mbps (2000 Mbps less 393 Mbps for the boot volume). After the data volume is attached to the instance, the volume optimally requires 640 Mbps. If this volume is the only attached volume, it gets the full bandwidth allocation. If you had two more volumes of greater capacity, the bandwidth allocation is less.\n\nUnattached volume bandwidth might not be the same as the actual bandwidth that you see after the volume is attached to an instance. The difference is due to the amount of bandwidth that is dedicated to the boot volume and all other attached data volumes.\n\n\n\n\n\n\n\n Estimating volume bandwidth \n\nThink about the type of data volume that your workloads require and select the right volume profile. Data intensive workloads might require the higher bandwidth performance of a 10 IOPS\/GB profile. For more information about the relationship of volume profiles to compute profiles, see [How virtual server profiles relate to storage profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles&interface=uivsi-profiles-relate-to-storage). For more information about how block size affects performance, see [Block storage capacity and performance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-capacity-performance&interface=uihow-block-size-affects-performance).\n\n\n\n\n\n Next steps \n\nAllocate total volume bandwidth by using the API or CLI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-bandwidth"},{"document_id":"ibmcld_15111-1536-3423","score":14.2232780457,"text":"\nThe volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n\n\n Are there limits on the number of volumes I can create? \n\nYou can create up to 300 total Block Storage for VPC volumes (data and boot) per account in a region. To increase this [quota](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-quotasblock-storage-quotas), open a [support case](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-help) and specify the zone where you need more volumes.\n\n\n\n\n\n After a data volume is created with a specific capacity, can the capacity later be increased? \n\nYou can increase the capacity of data volumes that are attached to a virtual server instance. You can indicate capacity in GB increments up to 16,000 GB capacity, depending on your volume profile. For more information, see [Increasing Block Storage for VPC volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes).\n\n\n\n\n\n Can I increase capacity of a boot volume? \n\nBoot volume capacity can be increased during instance provisioning or later, by directly modifying the boot volume.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-faq"},{"document_id":"ibmcld_10056-53892-55561","score":13.3390617371,"text":"\n: Enter the <statefulset_name> of your PVC name.\n\nspec.replicas\n: Enter the number of replicas that you want to create for your stateful set. The number of replicas must equal the number of PVCs that you created earlier.\n\nIf your PVCs are in different zones, don't include a region or zone label in your stateful set.\n3. Verify that the PVCs are used in your stateful set replica pods by listing the pods in your cluster. Identify the pods that belong to your stateful set.\n\noc get pods\n4. Verify that your existing PVC is mounted to your stateful set replica. Review the ClaimName in the Volumes section of your CLI output.\n\noc describe pod <pod_name>\n\nExample output\n\nName: nginx-0\nNamespace: default\nNode: 10.xxx.xx.xxx\/10.xxx.xx.xxx\nStart Time: Fri, 05 Oct 2022 13:24:59 -0400\n...\nVolumes:\nmyvol:\nType: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)\nClaimName: myvol-nginx-0\n...\n\n\n\n\n\n\n\n\n\n Changing the size and IOPS of your existing storage device \n\nIf you want to increase storage capacity or performance, you can modify your existing volume.\n\nFor questions about billing and to find the steps for how to use the IBM Cloud console to modify your storage, see [Expanding Block Storage capacity](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-expandingcapacityexpandingcapacity) and [Adjusting IOPS](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-adjustingIOPS). Updates that you make from the console are not reflected in the persistent volume (PV). To add this information to the PV, run oc patch pv <pv_name> and manually update the size and IOPS in the Labels and Annotation section of your PV.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-block_storage"},{"document_id":"ibmcld_16410-6875-8784","score":13.3265323639,"text":"\nTo add an annotation set in one task to a different task, you must first delete the task where the annotation set is active.\n* If you delete a human annotator's user account, it affects their annotations too. Any annotations in documents that were assigned to that user but were not promoted to ground truth are deleted.\n* If the type system or ground truth editor settings change after you create a human annotation task, you must decide whether to propagate the changes to the task. Type system changes can affect annotations; human annotators might need to review and update their documents.\n* If the dictionaries change, the changes are not reflected in the current annotation task. To apply resource changes to ground truth, you must create a new annotation task.\n* You can have up to 256 annotation tasks per workspace.\n\n\n\n\n\n\n\n\n\n Procedure \n\nTo create an annotation task:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. Select the Machine Learning Model > Annotations page, then click the Annotation Tasks tab.\n3. Click Add Task.\n4. Specify a descriptive task name and select the date that the task must be completed.\n5. If no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_03038-6010-7982","score":13.1771402359,"text":"\n* stop: Stops the service by scaling down the replicas in an order that limits possible dependency issues. This option also stores an annotation within the deployment or statefulset. If you subsequently try to use the script to start the service and the annotation doesn't exist in one of the deployments or statefulsets, the script fails.\n* start: You can only use this command to start the service if the wactl script was used to stop the service.\n* restart: Use this method to scale down the replicas, but to keep at least one replica for each pod running at all times to prevent a disruption in service.\n* clean: Removes the annotation that was created by the stop option from all objects including datastores.\n\n\n\n* release: The release name is hardcoded as watson-assistant.\n* cli: Specify the command line interface you are using.\n\nSpecify oc for OpenShift and kubectl for Kubernetes.\n* include-ds: Optional. Indicates that you want to perform the action on the data sources. When you specify this parameter with the restart action, all of the data sources are restarted except Redis.\n\n\n\n\n\n\n\n To manually scale the cluster all the way down and back \n\nTo scale down the cluster all the way, you must scale down the deployed services in the following order:\n\n\n\n* ui deployment\n* store deployment\n* gateway deployment\n* All other deployments\n* All statefulsets\n\n\n\n\n\n1. If you have local storage, complete the following steps:\n\n\n\n* Connect over SSH to each worker node, and then run the following command from a given worker to synchronize data to the same directory on each other worker.\n\nThe destination folders should be empty. If they're not, empty them.\n\nrsync -av \/mnt\/local-storage\/storage\/watson\/assistant\/{yourPV} {other worker}:\/mnt\/local-storage\/storage\/watson\/assistant\n* Double-check the postgres-keeper persistent volume permissions on each worker node.\n\nYou might need to scale postgres-keeper deployments first to see which persistent volumes they claim.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-manage"},{"document_id":"ibmcld_16493-3353-5349","score":13.143204689,"text":"\nIn human annotation, a collection of documents that are extracted from the corpus that allow the workload to be shared by multiple human annotators. In machine-based annotation, a collection of documents that can be used as blind data, training data, or test data.\n* annotation process manager\n\nA role that is responsible for managing the full annotation lifecycle activities within a workspace. The project manager that is added to a workspace typically performs the activities of an annotation process manager.\n* annotator\n\nSee [human annotator](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_H) and [machine learning annotator](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_M).\n* attribute\n\nA characteristic or trait of an entity that describes the entity; for example, the telephone number of an employee is one of the employee attributes.\n\n\n\n\n\n\n\n B \n\n\n\n* blind data\n\nA set of documents annotated with the ground truth, such as question and answer pairs, semantic annotation, and passage judgment. Blind data is never released or seen by developers and is used to test the system periodically to evaluate performance on unseen data. Testing on blind data prevents accuracy from being tainted by over-fitting to known question sets or annotations. Reported results should only come from tests that are run on blind data. See also [testing data](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_T) and [training data](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_T).\n\n\n\n\n\n\n\n C \n\n\n\n* concordance\n\nProvides a way to ensure that the same mention is annotated with the same entity type throughout a document and across annotation sets. Concordance helps ensure consistency across multiple occurrences of a mention without requiring the human annotator to manually label each occurrence.\n* confusion matrix","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-glossary"},{"document_id":"ibmcld_01232-1469-3545","score":13.0080184937,"text":"\nYou can find a full list of upgraded data centers and available features [here](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-selectDC).\n\n\n\n\n\n How can I find the correct mount point for my File Storage for Classic? \n\nAll encrypted File Storage for Classic volumes that are provisioned in the enhanced data centers have a different mount point than nonencrypted volumes. To ensure that you're using the correct mount point, view the mount point information in the Volume Details page in the UI. You can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n\n\n\n\n\n How many volumes can I provision? \n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n\n\n\n\n\n How many instances can share the use of a provisioned File Storage for Classic volume? \n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n\n\n\n\n\n How many File Storage for Classic volumes can be attached to a single host? \n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n\n\n\n\n\n How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size? \n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-file-storage-faqs"},{"document_id":"ibmcld_06259-18351-19507","score":12.9869613647,"text":"\nrunAsNonRoot: false\nrunAsUser: 0\nprivileged: false\nresources:\nlimits:\ncpu: 50m\nmemory: 50Mi\nrequests:\ncpu: 5m\nmemory: 10Mi\nvolumeMounts:\n- mountPath: \/csi\nname: plugin-dir\nserviceAccountName: ibm-vpc-block-node-sa\ntolerations:\n- operator: Exists\nvolumes:\n- hostPath:\npath: \/var\/lib\/kubelet\/plugins_registry\/\ntype: Directory\nname: registration-dir\n- hostPath:\npath: \/var\/lib\/kubelet\ntype: Directory\nname: kubelet-data-dir\n- hostPath:\npath: \/var\/lib\/kubelet\/plugins\/vpc.block.csi.ibm.io\/\ntype: DirectoryOrCreate\nname: plugin-dir\n- hostPath:\npath: \/dev\ntype: Directory\nname: device-dir\n- hostPath:\npath: \/etc\/udev\ntype: Directory\nname: etcudevpath\n- hostPath:\npath: \/run\/udev\ntype: Directory\nname: runudevpath\n- hostPath:\npath: \/lib\/udev\ntype: Directory\nname: libudevpath\n- hostPath:\npath: \/sys\ntype: Directory\nname: syspath\n- name: customer-auth\nsecret:\nsecretName: storage-secret-store\n- configMap:\nname: cluster-info\nname: cluster-info\n- apiVersion: apps\/v1\nkind: StatefulSet\nmetadata:\nannotations:\nversion: 2.0.3_354\nlabels:\naddonmanager.kubernetes.io\/mode: Reconcile\napp: ibm-vpc-block-csi-driver\nname: ibm-vpc-block-csi-controller\nnamespace: kube-system","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-block-storage-driver-unmanaged"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16507-9193-11335","score":19.9744338989,"text":"\nClick Run.\n\nIf you are doing a validation check of the pre-annotator, then open the annotated documents and review the annotations that were added. Make sure a sufficient number of accurate annotations were created. If the annotations are accurate, then you can run the annotator again on more and larger document sets. If the annotations are not accurate, then consider mapping different Natural Language Understanding entity types to your types. If the types do not naturally overlap, then the Natural Language Understanding pre-annotator is not the best pre-annotator for you to use.\n\nPre-annotation is applied to individual documents without regard for the various document sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n Results \n\nGround truth that is produced by documents that were pre-annotated by the Natural Language Understanding service cannot be used directly outside of Knowledge Studio. You can download the ground truth (in non-readable form) to move it from one Knowledge Studio workspace to another. And you can continue to develop the ground truth and use it to build a machine learning model or rule-based model that can be deployed for use in services outside of Knowledge Studio.\n\nDocuments that were pre-annotated with Natural Language Understanding are obscured into a non-readable format when they are downloaded. But, all annotations in those documents are obscured, including annotations that were added to the documents by human annotators.\n\nRelated information:\n\n[Natural Language Understanding](https:\/\/www.ibm.com\/watson\/services\/natural-language-understanding\/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16563-3072-4738","score":18.2811946869,"text":"\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.\n\nFor more information about pre-annotation with dictionaries, see [Pre-annotating documents with a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Assets > Dictionaries.\n\nThe Test dictionary dictionary opens. The [Adding a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless4) lesson of the Getting started with Knowledge Studio tutorial shows you how to create this dictionary.\n2. From the Entity type list, select the ORGANIZATION entity type to map it to the Test dictionary dictionary.\n\nThe [Creating a type system](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless3) lesson of the Getting started with Knowledge Studio tutorial shows how to create the type system that contains the ORGANIZATION entity type.\n3. On the Machine Learning Model > Pre-annotation page, click Run Pre-annotators.\n4. Select Dictionary, then click Next.\n5. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introtut_lessml1).\n6. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16444-1600-3658","score":18.2730922699,"text":"\nHuman annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16507-7-2044","score":18.1798496246,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-7-2064","score":17.9632816315,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16463-4148-5042","score":17.6971874237,"text":"\nAfter the pre-annotation is complete, create a human annotation task that includes the annotation set you created.\n\nFor more information about creating an annotation task, see [Annotation setup](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents).\n7. To view the annotations that were applied by the machine learning model to the new documents, open the annotation task.\n\nBecause the new documents were pre-annotated with the machine learning model, human annotation requires less time. For more information about adding annotations by human annotators, see [Annotating documents](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide).\n\n\n\n\n\n\n\n Results \n\nBy using your machine learning model to pre-annotate new document sets, you can expedite human annotation tasks for those documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutboot_intro"},{"document_id":"ibmcld_16507-1455-3632","score":17.6530952454,"text":"\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-7346-9136","score":16.9555549622,"text":"\nHuman annotations are preserved even if this is selected.\n10. Select the check box for each document set that you want to pre-annotate and click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets or annotation sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\nRelated information:\n\n[Creating dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-dictionaries)\n\n[Getting Started > Adding a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintrowks_tutless4)\n\n\n\n\n\n\n\n Pre-annotating documents with the machine learning model \n\nYou can use an existing machine learning model to pre-annotate documents that you add to your corpus.\n\n\n\n About this task \n\nAfter 10 to 30 documents are annotated, a machine learning model can be trained on the data. Don't use such a minimally trained model in a production. However, you can use the model to pre-annotate documents to help speed up the human annotation of subsequent documents. For example, if you add documents to the corpus after you train a machine learning model, you can use the model to pre-annotate the new document sets. Never run a pre-annotator on the same documents that have been annotated by a person. Pre-annotators remove human annotation.\n\n\n\n\n\n Procedure \n\nTo use an existing machine learning model to pre-annotate documents:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Go to the Machine Learning Model > Pre-annotation page.\n3. Click Run Pre-annotators.\n4. Select Machine Learning Model, and then click Next.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16552-4166-4924","score":16.4210720062,"text":"\nFor more information about creating an annotation task, see [Annotation setup](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents).\n6. To view the annotations that were applied by the machine learning model to the new documents, open the annotation task.\n\nBecause the new documents were pre-annotated with the machine learning model, human annotation requires less time. For more information about adding annotations by human annotators, see [Annotating documents](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-user-guide).\n\n\n\n\n\n\n\n Results \n\nBy using your machine learning model to pre-annotate new document sets, you can expedite human annotation tasks for those documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutboot_intro"},{"document_id":"ibmcld_10916-57815-59652","score":16.3322925568,"text":"\npre-annotation \n\nThe process of annotating a set of documents prior to human annotation. Documents can be pre-annotated by using a rule-based model, a machine-learning model, IBM Watson Natural Language Understanding, or a dictionary. Pre-annotation can help human annotators more quickly prepare a set of ground truth documents.\n\n\n\n\n\n precision \n\nA measurement that specifies the proportion of results that are relevant. Precision, which is a positive predictive value, is determined by the number of correct positive results divided by the number of all positive results. Accuracy is best measured by using both precision and recall. See also [recall](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2154357), [accuracy](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx3125742).\n\n\n\n\n\n private cloud \n\nA cloud computing environment in which access is limited to members of an enterprise and partner networks. See also [public cloud](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx4585370).\n\n\n\n\n\n private image repository \n\nThe combination of an organization's IBM Cloud registry and its namespace. The private image repository is used when referencing an image in a command. See also [image](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2024928), [namespace](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2031005).\n\n\n\n\n\n private key \n\nAn algorithmic pattern used to encrypt messages that only the corresponding public key can decrypt. The private key is also used to decrypt messages that were encrypted by the corresponding public key. The private key is kept on the user system and is protected by a password.\n\n\n\n\n\n private resource \n\nAn entry that is visible only to account owners and their included accounts. When resources are created, they are private by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossary"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.67973105,"ndcg_cut_10":0.67973105}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06981-1673-3761","score":17.2090129852,"text":"\nLater, you can limit the search to return content from only the tips field.\n\nOr maybe you have extra large documents that contain subsections. You can teach the SDU model to recognize these subsections, and then split the large document into multiple, smaller, and easier-to-manage documents that begin with one of these subsections.\n* The best way to prepare a collection for use in Conversational Search projects is to identify discrete question-and-answer pairs. You can use the SDU tool to find and annotate them. If you configure the project to contain answers in an answer field, you must update the search configuration in Watson Assistant to get the body of the response from the custom answer field.\n* A pretrained SDU model is applied to Document Retrieval for Contracts projects automatically. The pretrained SDU model knows how to recognize terms and concepts that are significant to contracts. As a result, you cannot apply a user-trained SDU model to this project type, but you also don't need to.\n* The SDU tool is rarely used with Content Mining projects.\n\n\n\nYou can use the SDU tool to annotate the following file types only:\n\n\n\n* Image files (PNG, TIFF, JPG)\n* Microsoft PowerPoint\n* Microsoft Word\n* PDF\n\n\n\nFor a complete list of file types that Discovery supports, see [Supported file types](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collectionssupportedfiletypes).\n\nThe Smart Document Understanding tool uses optical character recognition (OCR) to extract text from images in the files that it analyzes. Images must meet the minimum quality requirements that are supported by OCR. For more information, see [Optical character recognition](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collectionsocr).\n\nThe tool cannot read documents with the following characteristics; remove them from your collection before you begin:\n\n\n\n* Documents that appear to have text that overlays other text are considered double overlaid and cannot be annotated.\n* Documents that contain multiple columns of text on a single page cannot be annotated.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-configuring-fields"},{"document_id":"ibmcld_16444-3168-4952","score":17.0958900452,"text":"\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.\n\n\n\n* [Dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannot)\n* [Machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannotsire)\n* [Rules-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannotrule)\n\n\n\n\n\n Configuring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson. If a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16507-3099-4772","score":16.7532367706,"text":"\nIt can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections:\n\n\n\n* [Natural Language Understanding](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotnlu)\n* [Dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot)\n* [Machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotsire)\n* [Rules-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotrule)\n\n\n\n\n\n Configuring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-1600-3658","score":16.4069843292,"text":"\nHuman annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16507-1455-3632","score":16.1643066406,"text":"\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16507-4382-6307","score":15.3045959473,"text":"\nConfiguring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson. If a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2. Click the Move up and Move down arrow** buttons to move pre-annotation methods earlier or later in the order.\n3. Click Save.\n4. Double check the Order column on the Pre-annotation page to make sure that it matches the order that you want.\n\n\n\n\n\n\n\n Run pre-annotators \n\n\n\n1. After your pre-annotation methods are prepared and you have configured the order of your pre-annotators, click Run Pre-annotators.\n2. Select the pre-annotators that you want to use, and then click Next.\n3. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with Natural Language Understanding \n\nYou can use the Natural Language Understanding service to pre-annotate documents that you add to your corpus.\n\n\n\n Before you begin \n\nDetermine whether the Natural Language Understanding pre-annotator is likely to add value for your use case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16507-9193-11335","score":15.2199249268,"text":"\nClick Run.\n\nIf you are doing a validation check of the pre-annotator, then open the annotated documents and review the annotations that were added. Make sure a sufficient number of accurate annotations were created. If the annotations are accurate, then you can run the annotator again on more and larger document sets. If the annotations are not accurate, then consider mapping different Natural Language Understanding entity types to your types. If the types do not naturally overlap, then the Natural Language Understanding pre-annotator is not the best pre-annotator for you to use.\n\nPre-annotation is applied to individual documents without regard for the various document sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n Results \n\nGround truth that is produced by documents that were pre-annotated by the Natural Language Understanding service cannot be used directly outside of Knowledge Studio. You can download the ground truth (in non-readable form) to move it from one Knowledge Studio workspace to another. And you can continue to develop the ground truth and use it to build a machine learning model or rule-based model that can be deployed for use in services outside of Knowledge Studio.\n\nDocuments that were pre-annotated with Natural Language Understanding are obscured into a non-readable format when they are downloaded. But, all annotations in those documents are obscured, including annotations that were added to the documents by human annotators.\n\nRelated information:\n\n[Natural Language Understanding](https:\/\/www.ibm.com\/watson\/services\/natural-language-understanding\/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16468-3297-5708","score":14.8414506912,"text":"\n* Involving domain subject matter experts to create the following resources, or to identify existing resources that can be re-used or modified for your domain:\n\n\n\n* Annotation guidelines and examples to help human annotators learn how words and passages in your domain content are to be annotated.\n* Type systems that define the domain-specific types (objects) and features (data classifications) that can be discovered in your domain content through text analysis. The type system controls the types of annotations that a human annotator can add to documents.\n* Dictionaries of terms that are to be treated as equivalent terms in your domain content.\n\n\n\n* Creating a corpus of documents that are representative of your domain content.\n* Pre-annotating documents based on the dictionaries that you add to a Knowledge Studio workspace. After you create a machine learning model, you can use the model to pre-annotate new documents that you add to the corpus. Pre-annotation is a process of machine-annotating a document to the extent possible before a machine learning model is available to do so. Pre-annotation can reduce human-annotation labor by replacing some human annotation creation with mere verification of the correctness of machine annotation.\n* Dividing documents among human annotators, who then use the IBM Watson\u00ae Knowledge Studio ground truth editor tool to manually add annotations to small sets of documents.\n* Comparing the human annotation results and resolving conflicts. Adjudication in this phase is needed to ensure accurate and consistently annotated documents are promoted to ground truth, where they can be used to train and test a machine learning model.\n\n\n\n\n\n\n\n Model development \n\nThis stage refers to the use of Knowledge Studio tools to create a model. After establishing ground truth, the human annotation results can be used to train an algorithm for automatically adding annotations to large collections of documents, such as collections that include millions of documents.\n\n\n\n\n\n Model evaluation \n\nThis stage refers to the use of Knowledge Studio tools to refine the model and improve performance. The results generated by the model are evaluated against a test set of ground truth documents. Accuracy analysis identifies the causes of annotation errors. Headroom analysis helps you assess which errors require focus and where model refinements can yield the greatest impact.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_16507-7-2044","score":14.1726579666,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-7346-9136","score":14.1462888718,"text":"\nHuman annotations are preserved even if this is selected.\n10. Select the check box for each document set that you want to pre-annotate and click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets or annotation sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\nRelated information:\n\n[Creating dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-dictionaries)\n\n[Getting Started > Adding a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintrowks_tutless4)\n\n\n\n\n\n\n\n Pre-annotating documents with the machine learning model \n\nYou can use an existing machine learning model to pre-annotate documents that you add to your corpus.\n\n\n\n About this task \n\nAfter 10 to 30 documents are annotated, a machine learning model can be trained on the data. Don't use such a minimally trained model in a production. However, you can use the model to pre-annotate documents to help speed up the human annotation of subsequent documents. For example, if you add documents to the corpus after you train a machine learning model, you can use the model to pre-annotate the new document sets. Never run a pre-annotator on the same documents that have been annotated by a person. Pre-annotators remove human annotation.\n\n\n\n\n\n Procedure \n\nTo use an existing machine learning model to pre-annotate documents:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Go to the Machine Learning Model > Pre-annotation page.\n3. Click Run Pre-annotators.\n4. Select Machine Learning Model, and then click Next.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.2463023887,"ndcg_cut_10":0.3638184935}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08582-6197-7807","score":10.6096591949,"text":"\ncorrelation_ID The unique identifier that is used to track and correlate transactions. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you create a key alias. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https:\/\/www.nist.gov\/publications\/guide-protecting-confidentiality-personally-identifiable-information-pii).\n\nA successful POST api\/v2\/keys\/<key_ID>\/aliases\/<key_alias> response returns the alias for your key, along with other metadata. The alias is a unique name that is assigned to your key and can be used for to retrieve more information about the associated key.\n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.key+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"keyId\": \"02fd6835-6001-4482-a892-13bd2085f75d\",\n\"alias\": \"test-alias\",\n\"creationDate\": \"2020-03-12T03:37:32Z\",\n\"createdBy\": \"...\"\n}\n]\n}\n\nFor a detailed description of the response parameters, see the Hyper Protect Crypto Services [REST API reference doc](https:\/\/cloud.ibm.com\/apidocs\/hs-crypto).\n\n\n\n\n\n\n\n\n\n Deleting key aliases \n\nTo remove a key alias for a key, you can use either the console or the key management service API.\n\n\n\n Deleting key aliases with the console \n\nDelete a key alias with the console by completing the following steps:\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-key-alias"},{"document_id":"ibmcld_09099-9914-10963","score":10.4593820572,"text":"\ncorrelation_ID Optional.The unique identifier that is used to track and correlate transactions. \n new_key_ring_ID Required. The unique identifier for the target key ring that you would like to move the key to. \n\n\n\nA successful PATCH api\/v2\/keys\/keyID_or_alias request returns the key's metadata, including the id of the key ring that the key is a part of.\n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.key+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"type\": \"application\/vnd.ibm.kms.key+json\",\n\"id\": \"02fd6835-6001-4482-a892-13bd2085f75d\",\n\"name\": \"test-root-key\",\n\"aliases\":\n\"alias-1\",\n\"alias-2\"\n],\n\"description\": \"A test root key\",\n\"state\": 1,\n\"extractable\": false,\n\"keyRingID\": \"new-key-ring\",\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/f047b55a3362ac06afad8a3f2f5586ea:12e8c9c2-a162-472d-b7d6-8b9a86b815a6:key:02fd6835-6001-4482-a892-13bd2085f75d\",\n\"imported\": false,\n\"creationDate\": \"2020-03-12T03:37:32Z\",\n\"createdBy\": \"...\",\n\"algorithmType\": \"Deprecated\",\n\"algorithmMetadata\": {\n\"bitLength\": \"256\",\n\"mode\": \"Deprecated\"\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys"},{"document_id":"ibmcld_09165-3941-4947","score":10.4073848724,"text":"\ncorrelation_ID Optional.The unique identifier that is used to track and correlate transactions. \n\n\n\nA successful GET api\/v2\/keys\/<key_ID_or_alias>\/metadata response returns details about your key. The following JSON object shows an example returned value for a standard key.\n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.key+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"type\": \"application\/vnd.ibm.kms.key+json\",\n\"id\": \"02fd6835-6001-4482-a892-13bd2085f75d\",\n\"name\": \"test-standard-key\",\n\"aliases\":\n\"alias-1\",\n\"alias-2\"\n],\n\"state\": 1,\n\"expirationDate\": \"2020-03-15T03:50:12Z\",\n\"extractable\": true,\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/f047b55a3362ac06afad8a3f2f5586ea:12e8c9c2-a162-472d-b7d6-8b9a86b815a6:key:02fd6835-6001-4482-a892-13bd2085f75d\",\n\"imported\": false,\n\"creationDate\": \"2020-03-12T03:50:12Z\",\n\"createdBy\": \"...\",\n\"algorithmType\": \"Deprecated\",\n\"algorithmMetadata\": {\n\"bitLength\": \"256\",\n\"mode\": \"Deprecated\"\n},\n\"algorithmBitSize\": 256,\n\"algorithmMode\": \"Deprecated\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-key-metadata"},{"document_id":"ibmcld_00324-12617-14618","score":9.572347641,"text":"\nMetrics with graphical views \n\nMetrics for an individual CDN are provided on the Overview tab of the customer portal for that CDN mapping. Two types of metrics are calculated from the CDN's usage: those that show the metrics over a time period as a graph, and those that are shown as aggregate values.\n\nFor metrics that display the change over a period of time as a graph, you can see three line graphs and a pie chart. The three line graphs are: Bandwidth, Hits by Mapping, and Hits by Type. They display the activity daily over the course of your specified timeframe. The graphs for Bandwidth and Hits by Mapping are single-line graphs, whereas the breakdown of Hits by Type shows a line for each of the hit types provided. The pie chart displays a regional breakdown of the bandwidth for a CDN mapping on a percentage basis.\n\nMetrics that are shown for aggregate values include Bandwidth Usage in GB, Total Hits to the CDN Edge server, and the Hit Ratio. Hit Ratio indicates that the percentage of times content is delivered by the Edge server, not through its origin. Hit ratio currently is shown as a function of all your CDN mappings, not just the one being viewed.\n\nBy default, both the aggregate numbers and the graphs default to show metrics for the last 30 days, but you can change this through the [IBM Cloud console](https:\/\/cloud.ibm.com\/). Both categories can display metrics for 7-, 15-, 30-, 60-, or 90-day periods.\n\n\n\n\n\n Object storage origin support \n\nIBM Cloud CDN can be configured to serve content from an object storage endpoint by providing the endpoint, the bucket name, protocol, and port. Optionally, you can specify a list of file extensions to allow caching for files only with those extensions. All objects in the bucket must be set with anonymous read or public read access.\n\nFor more information, see [Accelerate delivery of static files using a CDN](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-static-files-cdn).\n\n\n\n\n\n Path-based CDN mappings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-about-content-delivery-networks-cdn-"},{"document_id":"ibmcld_08765-3651-5450","score":9.4548473358,"text":"\ncorrelation_ID Optional. The unique identifier that is used to track and correlate transactions. \n encrypted_data_key The ciphertext value that was returned during a wrap operation. \n\n\n\nThe original key material is returned in the response entity-body. The response body also contains the ID of the key version that was used to unwrap the supplied ciphertext. The following JSON object shows a sample returned value.\n\n{\n\"plaintext\": \"Rm91ciBzY29yZSBhbmQgc2V2ZW4geWVhcnMgYWdv\",\n\"keyVersion\": {\n\"id\": \"02fd6835-6001-4482-a892-13bd2085f75d\"\n}\n}\n\nIf Hyper Protect Crypto Services detects that you rotated the root key that is used to unwrap and access your data, the service also returns a newly wrapped data encryption key (ciphertext) in the unwrap response body. The latest key version (rewrappedKeyVersion) that is associated with the new ciphertext is also returned. Store and use the new ciphertext value for future envelope encryption operations so that your data is protected by the latest root key.\n\n\n\n\n\n\n\n Decoding your key material \n\nWhen you unwrap a data encryption key, the key material is returned in base64 encoding. You need to decode the key before you encrypt it.\n\n\n\n Using OpenSSL to decode key material \n\n\n\n1. Download and install [OpenSSL](https:\/\/github.com\/openssl\/opensslfor-production-use).\n2. Base64 encode your key material string by running the following command:\n\n$ openssl base64 -d -in <infile> -out <outfile>\n\nReplace the variables in the example request according to the following table.\n\n\n\nTable 2. Describes the variables needed to decode your key material\n\n Variable Description \n\n infile The name of the file where your base64 encoded key material string resides. \n outfile The name of the file where your decoded key material is outputted after the command is run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-unwrap-keys"},{"document_id":"ibmcld_12561-9263-11199","score":9.3634576797,"text":"\nYou can also use the Usage Reports API to get [account summary usage](https:\/\/github.ibm.com\/BSS\/metering-report-downloader\/wiki\/Regular-Usage-Reportsaccount-summary-report) and [resource instance usage](https:\/\/github.ibm.com\/BSS\/metering-report-downloader\/wiki\/Regular-Usage-Reportsaccount-instance-report).\n\nThe following examples show queries that you can use to download your enterprise account .csv report. When you call the API, replace the ID variables and IAM token with the values from your enterprise.\n\ncurl -X GET -H 'Authorization: Bearer <IAM Token>' '{base_url}\/v1\/resource-usage-reports?month=2023-03&format=csv&recurse=true&enterprise_id={enterprise_id}'\n\n\n\n Understanding .csv table headings and JSON report fields for enterprise account summary \n\nThe following table shows the correlation between the heading titles in your .csv report and JSON report fields.\n\nEntity Metadata\n\nEntity Hierarchy\n\nBilling Units\n\nCredit Pools\n\nOverages\n\nEnterprise Usage Summary\n\nEnterprise Resource Usage\n\n\n\nTable 1. Enterprise usage report CSV contents for entity metadata\n\n .csv Header Description \n\n Entity ID ID of the requested entity (enterprise_id\/account_group_id\/account_id) \n Entity Type Type of the requested entity (enterprise\/account_group\/account) \n Billing Month The month in which usages were incurred. Represented in yyyy-mm format \n Currency Rate Currency Exchange Rate with USD as the base \n Created Time Timestamp at which the CSV report was generated \n\n\n\nWhen recurse=true, the usage in the Enterprise Resource Usage section is aggregated by each metric of a service plan and it's broken down by child accounts. Each row represents the total usage of a service plan metric in some child account. When recurse=false, the usage is aggregated by each metric of a service plan and each row represents the total usage of a service plan metric of all the sub-accounts or child-accounts in the requested entity hierarchy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-usage"},{"document_id":"ibmcld_09194-4924-6647","score":9.3089046478,"text":"\ncorrelation_ID Optional.The unique identifier that is used to track and correlate transactions. \n additional_data Optional.The additional authentication data (AAD) that is used to further secure the key. Each string can hold up to 255 characters. If you supply AAD when you make a wrap call to the service, you must specify he same AAD during the unwrap call. \n encrypted_data_key Required. The ciphertext value that was returned during a wrap operation. \n\n\n\nThe original key material is returned in the response entity-body. The response body also contains the ID of the key version that was used to unwrap the supplied ciphertext.\n\nThe plaintext that is returned is base64 encoded. For more information on how to decode your key material, see [Decoding your key material](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-unwrap-keyshow-to-decode-key-material). The following JSON object shows an example returned value.\n\n{\n\"plaintext\": \"Rm91ciBzY29yZSBhbmQgc2V2ZW4geWVhcnMgYWdv\",\n\"keyVersion\": {\n\"id\": \"02fd6835-6001-4482-a892-13bd2085f75d\"\n}\n}\n\nIf Key Protect detects that you rotated the root key that is used to unwrap and access your data, the service also returns a newly wrapped data encryption key (ciphertext) in the unwrap response body. The latest key version (rewrappedKeyVersion) that is associated with the new ciphertext is also returned. Store and use the new ciphertext value for future envelope encryption operations so that your data is protected by the latest root key.\n\n\n\n\n\n Decoding your key material \n\nWhen you unwrap a data encryption key, the key material is returned in base64 encoding. You will need to decode the key before encrypting it.\n\n\n\n Using OpenSSL to decode key material \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-unwrap-keys"},{"document_id":"ibmcld_08988-57435-58563","score":9.2992525101,"text":"\ncorrelation_id='c2edbdad-7e62-4690-8fcc-10515ade9913',\nmsg='Conflict: Action could not be performed on key. Please see \"reasons\" for more details.',\nreasons='[KEY_ACTION_INVALID_STATE_ERR: Key is not in a valid state -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\n\n\n\n\n\n Example 3 \n\nCreate a root key with an alias, use that alias to identify the key to be disabled, verify the key state (suspended), then enable the root key and verify the new key state (active).\n\n create a root key\n$ ibmcloud kp key create root-key-with-alias -a example-alias-1 --output json\n\n{\n\"id\": \"264fadc3-7667-4b25-916e-5825fe70de0b\",\n\"name\": \"root-key-with-alias\",\n\"type\": \"application\/vnd.ibm.kms.key+json\",\n\"extractable\": false,\n\"state\": 1,\n\"aliases\": [\n\"example-alias\"\n],\n\"deleted\": false,\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/ea998d3389c3473aa0987652b46fb146:390086ac-76fa-4094-8cf3-c0829bd69526:key:264fadc3-7667-4b25-916e-5825fe70de0b\"\n}\n\n show key details using the alias as identifier - a state of \"1\" is \"active\"\n$ ibmcloud kp key show example-alias-1 --output json\n\n{\n\"id\": \"264fadc3-7667-4b25-916e-5825fe70de0b\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_13499-15933-17480","score":9.2125492096,"text":"\n: Convert num from from_base to to_base.\n: Example of an SQL function usage fragment\n\n> SELECT conv('100', 2, 10)\n: Result value\n\n4\n: Example of an SQL function usage fragment\n\n> SELECT conv(-10, 16, -10)\n: Result value\n\n-16\n\n\n\n\n\n corr \n\ncorr(expr1, expr2)\n: Returns Pearson coefficient of correlation between a set of number pairs.\n\n\n\n\n\n cos \n\ncos(expr)\n: Returns the cosine of expr.\n: Example of an SQL function usage fragment\n\n> SELECT cos(0)\n: Result value\n\n1.0\n\n\n\n\n\n cosh \n\ncosh(expr)\n: Returns the hyperbolic cosine of expr.\n: Example of an SQL function usage fragment\n\n> SELECT cosh(0)\n: Result value\n\n1.0\n\n\n\n\n\n cot \n\ncot(expr)\n: Returns the cotangent of expr.\n: Example of an SQL function usage fragment\n\n> SELECT cot(1)\n: Result value\n\n0.6420926159343306\n\n\n\n\n\n count \n\ncount(*)\n: Returns the total number of retrieved rows, including rows that contain null.\n\ncount(expr)\n: Returns the number of rows for which the supplied expression is nonnull.\n\ncount(DISTINCT expr[, expr...])\n: Returns the number of rows for which the supplied expressions are unique and nonnull.\n\n\n\n\n\n count_min_sketch \n\ncount_min_sketch(col, eps, confidence, seed)\n: Returns a count-min sketch of a column with the indicated esp, confidence, and seed. The result is an array of bytes, which can be de-serialized to a CountMinSketch before usage. Count-min sketch is a probabilistic data structure that is used for cardinality estimation by using sublinear space.\n\n\n\n\n\n covar_pop \n\ncovar_pop(expr1, expr2)\n: Returns the population covariance of a set of number pairs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sqlfunctions"},{"document_id":"ibmcld_03364-2333-4446","score":9.0148735046,"text":"\nCreate a Watson Studio account, [create a project](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/getting-started\/projects.html), and add a Cloud Object Storage account to it.\n2. From the Watson Studio community, choose a notebook.\n\nEarly in the development process, use the Dialog skill analysis for Watson Assistant notebook to help you get started. It offers the following types of insights:\n\n\n\n* Examines the terms that are correlated with each intent in your training data to find anomalies that might identify problems that you can investigate further.\n* Uses a blind test set that you provide to calculate performance on statistical metrics like Accuracy, Precision, Recall & F1.\n* Offers advanced features that you can use to find the causes of common issues such as why some sentences are often misidentified.\n\n\n\nTo learn more about how this notebook can help you improve your dialog, read this [Medium.com blog post](https:\/\/medium.com\/ibm-watson\/announcing-dialog-skill-analysis-for-watson-assistant-83cdfb968178).\n3. After you deploy a version of the assistant, and have some conversation log data collected, run the Measure Watson Assistant Performance notebook.\n4. Follow the step-by-step instructions provided with the notebooks to analyze a subset of the dialog exchanges from the logs.\n\nRun the following notebook first:\n\n\n\n* Measure: Gathers metrics that focus on coverage (how often the assistant is confident enough to respond to users) and effectiveness (when the assistant does respond, whether the responses are satisfying user needs).\n\n\n\nThe insights are visualized in ways that make it easier to understand areas for improvement in your assistant.\n5. Export a sample set of the logs from ineffective conversations, and then analyze and annotate them.\n\nFor example, indicate whether a response is correct. If correct, mark whether it is helpful. If a response is incorrect, then identify the root cause, the wrong intent or entity was detected, for example, or the wrong dialog node was triggered. After identifying the root cause, indicate what the correct choice would have been.\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resources"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08446-4-1771","score":21.2466621399,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting managed keys \n\nYou can delete your managed keys in Unified Key Orchestrator with the IBM Cloud\u00ae console, or programmatically with the Unified Key Orchestrator API.\n\nWhen you delete a managed key, the key is to be detached from all target keystores, and all key materials and the metadata are destroyed permanently.\n\n\n\n Deleting managed keys with the IBM Cloud console \n\nTo delete a key in Active state, you need to first deactivate the key, and then destroy the key and remove it from the vault.\n\nTo delete a key in Pre-active or Deactivated state, you only need to destroy the key, and then remove it from the vault.\n\nFor more information about key states and transitions, see [Monitoring the lifecycle of encryption keys in Unified Key Orchestrator](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-uko-key-states).\n\nFollow these steps to complete the process:\n\n\n\n1. [Log in to the Hyper Protect Crypto Services instance](https:\/\/cloud.ibm.com\/login).\n2. Click Managed keys from the navigation to view all the available keys.\n3. If the managed key that you want to delete is in Active state, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/action-menu-icon.svg) and choose Deactivated to deactivate the key first.\n\nWhen you change the Active key to Deactivated state, the key is detached from all the target keystores, and not accessible to all associated resources and their data. Make sure that you open the confirmation tile to check all the associated resources before you continue. However, you can still reactivate the key so that it is accessible to the resources again.\n4. To destroy a Pre-active or Deactivated key, click the Actions icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-managed-keys"},{"document_id":"ibmcld_13028-13559-15025","score":21.1379566193,"text":"\n.catch(err => {\nconsole.warn(err);\n});\n\n\n\n\n\n\n\n Deleting an API key \n\nIf you are using a key rotation strategy, you might want to delete an older key and replace it with a new key.\n\nTo delete an API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM) > API keys.\n2. Identify the row of the API key that you want to delete, and select Delete from the Actions![List of actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/814aeaf04800bb4f74ea1c057d4abb166a5f357a\/icons\/action-menu-icon.svg) menu.\n3. Confirm the deletion by clicking Delete.\n\n\n\nTo delete an API key that is not your own, but you have access to manage, go to the API keys page. Then, select the All user IBM Cloud API keys option from the View menu to find the API key.\n\n\n\n\n\n Deleting an API key by using the CLI \n\nTo delete an API key by using the CLI:\n\nEnter ibmcloud iam api-key-delete NAME in your command prompt, specifying the name of the key to delete.\n\n\n\n\n\n Deleting an API key by using the API \n\nTo delete an API key by using the API, call the [IAM Identity Service API](https:\/\/cloud.ibm.com\/apidocs\/iam-identity-token-apidelete-api-key) as shown in the following example:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X DELETE 'https:\/\/iam.cloud.ibm.com\/v1\/apikeys\/APIKEY_UNIQUE_ID' -H 'Authorization: Bearer TOKEN' -H 'Content-Type: application\/json'\n\nDeleteApiKeyOptions deleteApiKeyOptions = new DeleteApiKeyOptions.Builder()\n.id(apikeyId)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/account?topic=account-userapikey"},{"document_id":"ibmcld_02210-14394-15623","score":21.0399971008,"text":"\n});\n\n\n\n\n\n\n\n Deleting an API key for a service ID using the API \n\nTo delete an API key by for a service ID using the API, call the [IAM Identity Service API](https:\/\/cloud.ibm.com\/apidocs\/iam-identity-token-apidelete-api-key) as shown in the following example:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X DELETE 'https:\/\/iam.cloud.ibm.com\/v1\/apikeys\/APIKEY_UNIQUE_ID' -H 'Authorization: Bearer TOKEN' -H 'Content-Type: application\/json'\n\nDeleteApiKeyOptions deleteApiKeyOptions = new DeleteApiKeyOptions.Builder()\n.id(apikeyId)\n.build();\n\nservice.deleteApiKey(deleteApiKeyOptions).execute();\n\ndelete_api_key(self,\nid: str,\nkwargs\n) -> DetailedResponse\n\nresponse = iam_identity_service.delete_api_key(id=apikey_id)\n\nprint(response)\n\ndeleteAPIKeyOptions := iamIdentityService.NewDeleteAPIKeyOptions(apikeyID)\n\nresponse, err := iamIdentityService.DeleteAPIKey(deleteAPIKeyOptions)\nif err != nil {\npanic(err)\n}\n\nconst params = {\nid: apikeyId,\n};\n\niamIdentityService.deleteApiKey(params)\n.then(res => {\nconsole.log(JSON.stringify(res.result, null, 2));\n})\n.catch(err => {\nconsole.warn(err);\n});\n\n\n\n\n\n Before you begin \n\nBefore you can manage service ID API keys by using Terraform, make sure that you have completed the following:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceidapikeys&interface=ui"},{"document_id":"ibmcld_02314-13559-15025","score":20.996175766,"text":"\n.catch(err => {\nconsole.warn(err);\n});\n\n\n\n\n\n\n\n Deleting an API key \n\nIf you are using a key rotation strategy, you might want to delete an older key and replace it with a new key.\n\nTo delete an API key, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Access (IAM) > API keys.\n2. Identify the row of the API key that you want to delete, and select Delete from the Actions![List of actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/action-menu-icon.svg) menu.\n3. Confirm the deletion by clicking Delete.\n\n\n\nTo delete an API key that is not your own, but you have access to manage, go to the API keys page. Then, select the All user IBM Cloud API keys option from the View menu to find the API key.\n\n\n\n\n\n Deleting an API key by using the CLI \n\nTo delete an API key by using the CLI:\n\nEnter ibmcloud iam api-key-delete NAME in your command prompt, specifying the name of the key to delete.\n\n\n\n\n\n Deleting an API key by using the API \n\nTo delete an API key by using the API, call the [IAM Identity Service API](https:\/\/cloud.ibm.com\/apidocs\/iam-identity-token-apidelete-api-key) as shown in the following example:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X DELETE 'https:\/\/iam.cloud.ibm.com\/v1\/apikeys\/APIKEY_UNIQUE_ID' -H 'Authorization: Bearer TOKEN' -H 'Content-Type: application\/json'\n\nDeleteApiKeyOptions deleteApiKeyOptions = new DeleteApiKeyOptions.Builder()\n.id(apikeyId)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-userapikey&interface=ui"},{"document_id":"ibmcld_08435-3634-5079","score":20.9203834534,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08446-1337-2966","score":20.8783035278,"text":"\nWhen you change the Active key to Deactivated state, the key is detached from all the target keystores, and not accessible to all associated resources and their data. Make sure that you open the confirmation tile to check all the associated resources before you continue. However, you can still reactivate the key so that it is accessible to the resources again.\n4. To destroy a Pre-active or Deactivated key, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/action-menu-icon.svg) and choose Destroyed.\n\nWhen you destroy a managed key, the key cannot be restored in Unified Key Orchestrator. However, you can still restore your keys in external keystores depending on the settings of the cloud providers. For more information, see [Azure Key Vault soft-delete overview](https:\/\/docs.microsoft.com\/en-us\/azure\/key-vault\/general\/soft-delete-overview), [Deleting AWS KMS keys](https:\/\/docs.aws.amazon.com\/kms\/latest\/developerguide\/deleting-keys.html), or [Deleting and purging keys in Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keys).\n5. Click Destroy key to confirm.\n6. To remove the key and the metadata from the vault, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/action-menu-icon.svg) and choose Remove from vault.\n\nWhen you remove the managed key from the vault that the key is assigned to, the remaining key metadata is removed permanently.\n\n\n\nThe managed key has been deleted and detached from all target keystores.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-managed-keys"},{"document_id":"ibmcld_09070-7-2084","score":20.823797226,"text":"\nAbout deleting and purging keys \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to delete an encryption key and its key material if you are a manager for your Key Protect instance.\n\nBefore you can delete an instance, you must delete every key in that instance. However, if you close your account, any existing instances and keys are automatically hard deleted. Check out [Account cancelation and data deletion](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-complianceaccount-cancelation) for more information.\n\nIn the event that a key is no longer needed or should be removed, Key Protect allows you to delete and ultimately purge keys, an action that shreds the key material and makes any of the data encrypted with it inaccessible.\n\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\nThe following table lists the time frames in which you can view, restore, and purge a key after it has been deleted.\n\n\n\nTable 1. Lists how users can interact with keys during certain time intervals after a key has been deleted","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keys"},{"document_id":"ibmcld_16727-1212381-1214315","score":20.5725631714,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1209748-1211682","score":20.5725631714,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_08987-26871-28352","score":20.570066452,"text":"\nCreating key: 'my-root-key', in instance: '390086ac-76fa-4094-8cf3-c0829bd69526'...\nOK\nKey ID Key Alias\n24203f96-b134-440e-981a-a24f2d432256 my-alias\n\n\n\n\n\n\n\n Required parameters \n\n\n\n* KEY_ID\n\nThe ID of the key that you want to modify. To retrieve a list of your available keys, run the [kp keys](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-pluginkp-keys) command.\n* KEY_ALIAS\n\nThe alias, or alternate identifier, of the key that you want to modify. The identifier must be: alphanumeric, and no spaces or special characters other than '-' or '_', and can not be a version 4 UUID.\n* -i, --instance-ID\n\nThe IBM Cloud instance ID that identifies your Key Protect instance.\n\nYou can set an environment variable instead of specifying -i with the following command: $ export KP_INSTANCE_ID=<INSTANCE_ID>.\n\n\n\n\n\n\n\n Optional parameters \n\n\n\n* -o, --output\n\nSet the CLI output format. By default, all commands print in table format. To change the output format to JSON, use --output json.\n\n\n\n\n\n\n\n\n\n kp key cancel-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-pluginkp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.3379680345}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-3634-5079","score":23.8368015289,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_16059-18192-20019","score":22.8868656158,"text":"\n[Authorize deletion for a key with the API (dual authorization)](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysset-key-deletion-api) [Authorize deletion for a key with the API (dual authorization)](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) \n Restore key [Restoring a deleted key with the API](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-restore-keysrestore-api) [Restoring a deleted key with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-keysrestore-api) \n\n\n\n\n\n\n\n Removing service authorization to a root key \n\nYou can make your data inaccessible but retain it on the cloud by removing IAM authorization to use that root key.\n\nWhen you [authorize use](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceauthserviceauth) of your root key, you grant permission for IBM to use the key to encrypt your resource. Authorization is done at the key management service level through IAM, when you authorize service between your service (for example, Cloud Block Storage) and the key management service.\n\nYou can remove any authorization between services in your account when you have the Administrator role on the target service (in this case, the key management service). If you remove an access policy that was created by the source service for its dependent services, the source service is unable to complete the workflow or access the target service.\n\nBecause the root keys are under your control, you don't need to contact IBM to remove authorization.\n\nDo not remove IAM authorization between Cloud Block Storage and the KMS instance, and then delete a block storage volume, snapshot, or image resource. Such action causes the root key in the KMS instance to remain registered with the deleted resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing&interface=ui"},{"document_id":"ibmcld_09061-1334-3188","score":22.8831176758,"text":"\nWhen the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted. When you delete a key, it is \"soft deleted\", meaning that the key and its associated data will be restorable up to 30 days after deletion. You are able to still retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically [purged](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-key-purge), or hard deleted, and its associated data will be permanently removed from the Key Protect service.\n\n\n\n\n\n\n\n Authorize deletion for a key in the console \n\n[After you enable dual authorization for an instance or key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by using the Key Protect IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09055-69659-70937","score":22.401260376,"text":"\nUser 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-twokp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_09061-4-1966","score":22.3282375336,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09055-23127-24436","score":22.2814750671,"text":"\nUser 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:policy:2427dbde-6cff-41eb-8b5a-ff26b038cafc\",\n\"lastUpdateDate\": \"2020-06-22T21:29:10Z\",\n\"updatedBy\": \"user id ...<redacted>...\",\n\"dualAuthDelete\": {\n\"enabled\": true\n}\n}\n]\n\n cancel a previously scheduled key delete\n$ ibmcloud kp key cancel-delete $KEY_ID\n\nCancelling key for deletion...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_08435-1255-3053","score":21.9779911041,"text":"\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09038-20413-22510","score":21.6615829468,"text":"\nA registration with \"preventKeyDeletion\": true indicates that the associated resource has a retention policy. To enable deletion, contact an account owner to remove the retention policy on each resource that is associated with this key.\n\nA delete key event could also receive a reason.reasonCode of 409 due to a dual auth deletion policy on the key. Make a GET request to \/api\/v2\/keys\/{id}\/policies to see if there is a dual authorization policy associated with your key. If there is a policy set, contact the other authorized user to schedule the key for deletion.\n\n\n\n\n\n Unable to authenticate while make a request \n\nIf the event has a reason.reasonCode of 401, you do not have the correct authorization to perform Key Protect actions in the specified Key Protect instance. Verify with an administrator that you are assigned the correct platform and service access roles in the applicable service instance. For more information about roles, see [Roles and permissions](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-access).\n\nCheck that you are using a valid token that is associated with an account authorized to perform the service action.\n\n\n\n\n\n Unable to view or list keys in a Key Protect instance \n\nIf you make a call to GET api\/v2\/keys to list the keys that are available in your Key Protect instance and responseData.totalResources is 0, you may need to query for keys in the deleted state using the state parameter or adjust the offset and limit parameters in your request.\n\n\n\n\n\n Lifecycle action on a key with registrations did not complete \n\nThe responseData.reasonForFailure and responseData.resourceCRN fields contain information on why the action wasn't able to be completed.\n\nIf the event has a reason.reasonCode of 409, the action could not be completed due to the adopting service's key state conflicting with the key state that Key Protect has.\n\nIf the event has a reason.reasonCode of 408, the action could not be completed because Key Protect was not notified that all appropriate actions were taken within 4 hours of the action request.\n\n\n\n\n\n\n\n Event Severity","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events"},{"document_id":"ibmcld_16045-17715-19288","score":21.5304813385,"text":"\nDelete key [Deleting keys with the API (single authorization)](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-key-api) [Deleting keys with the API (single authorization)](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api) \n [Authorize deletion for a key with the API (dual authorization)](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysset-key-deletion-api) [Authorize deletion for a key with the API (dual authorization)](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) \n Restore key [Restoring a deleted key with the API](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-restore-keysrestore-api) [Restoring a deleted key with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-keysrestore-api) \n\n\n\n\n\n\n\n Removing service authorization to a root key \n\nYou can make your data inaccessible but retain it on the cloud by removing IAM authorization to use that root key.\n\nWhen you [authorize use](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceauthserviceauth) of your root key, you grant permission for IBM to use the key to encrypt your resource. Authorization is done at the key management service level through IAM, when you authorize service between your service (for example, Cloud Block Storage) and the key management service.\n\nYou can remove any authorization between services in your account when you have the Administrator role on the target service (in this case, the key management service).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing"},{"document_id":"ibmcld_09088-10880-12721","score":21.1807556152,"text":"\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n\n\n\n\n\n What is a dual authorization policy? \n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n\n\n\n\n\n What happens after I enable a dual authorization policy? \n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-dual-auth-key-policy).\n\n\n\n\n\n Can I disable a dual authorization settings for my Key Protect instance? \n\nYes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"}],"retriever_scores":{"recall_1":0.2,"recall_3":0.4,"recall_5":0.4,"recall_10":0.6,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.5087403079,"ndcg_cut_10":0.6217937097}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-8253-9823","score":17.3139228821,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-4752-6201","score":16.9101219177,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-7530-9143","score":13.104347229,"text":"\nIf no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-up-api).\n2. Retrieve the ID of the key that you would like to delete.\n\nYou can retrieve the ID for a specified key by making a GET \/v2\/keys request, or by viewing your keys in the Key Protect dashboard.\n3. Run the following curl command to delete the key and its contents.\n\n$ curl -X DELETE \"https:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\" -H \"prefer: <return_preference>\"\n\nReplace the variables in the example request according to the following table.\n\n\n\n\n\nTable 2. Describes the variables that are needed to delete a key.\n\n Variable Description \n\n region Required. The region abbreviation, such as us-south or eu-gb, that represents the geographic area where your Key Protect instance resides. <br> <br>For more information, see [Regional service endpoints](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-regionsservice-endpoints). \n key_ID_or_alias Required. The unique identifier or alias for the key that you would like to delete. \n IAM_token Required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_02775-1723-3822","score":12.8427095413,"text":"\nFor example, if a user signs in with Facebook and later signs in by using Google, they are considered two separate authorized users. The total number of your authorized users includes future users that you preregistered to your app because you already know who they are going to be. You are charged for each future user at the time of registration. For example, you work at a company and recently hired a team lead. When you preregister them to your application, they become an authorized user and count toward your total. As an authorized user, they can sign in for the first time without needing to interact with you. [Learn more](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregister).\n\n\n\n\n\n What are authentication events? \n\nAn authentication event happens when you issue a new regular or anonymous access token. Tokens can be issued in response to a sign-in request that is initiated by the user, or by an app on behalf of the user. By default, your users' access tokens are valid for 1 hour and anonymous tokens are valid for 30 days. After the tokens expire, your users must create a new token to access protected resources. You can manage the expiration time of your App ID tokens on the Manage Authentication > Authentication Settings page of the service dashboard.\n\n\n\n\n\n What are advanced security features? \n\nYou can strengthen the security of your application with advanced security features such as Multi-Factor authentication (MFA), runtime activity tracking, and password policy management. An advanced authentication event happens when you issue tokens for advanced security features.\n\nBy default, advanced features are disabled. You incur an extra charge when you enable them. For example, if you obtain 10,000 access tokens, then you turn on password policy management and obtain 10,000 more. You would pay for 20,000 authentication events and 10,000 advanced security events. If you disable all the advanced features, your account reverts to the original-cost policy.\n\n\n\nTable 1. Description of the benefits that are gained with advanced authentication events\n\n Feature Benefit","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-pricing"},{"document_id":"ibmcld_02746-4399-6393","score":12.7816772461,"text":"\n4. Specify The time a user will be locked out after trying to sign in with wrong credentials. The time is specified in minutes. You can use any whole value in range 1 - 1440 (24 hours).\n5. Toggle The number of times a user can try to sign in before getting locked out row to Enabled.\n6. Click Save.\n\n\n\nYou can unlock a user before the lockout period is over. To see whether they are locked out, check whether the active field is set to false. You can also check to see whether their status on the Users tab of the service dashboard is set to disabled. To unlock a user, you must use [the API](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Cloud_Directory_Users\/updateCloudDirectoryUser) to set the active field to true.\n\n\n\n\n\n Policy: Minimum period between password changes \n\nYou might want to prevent your users from quickly switching passwords by setting a minimum time that a user must wait between password changes.\n\nThis feature is especially useful when used with the Avoid password reuse policy. Without this limitation, a user might simply change their password multiple times in quick succession to circumvent the limitation of reusing recent passwords.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. Toggle Advanced password policy to Enabled.\n3. Specify The minimum time between password changes. The time is specified in hours. You can use any whole value in range 1 - 720 (30 days).\n4. Toggle The minimum time between password changes to Enabled.\n5. Click Save.\n\n\n\n\n\n\n\n Policy: Password expiration \n\nFor security reasons, you might want to enforce a password rotation policy. By setting an expiration for your users password, they are forced to update their password to retain access to your application. This lessens the chance that a user's credentials can cause long term damage to your application. When their password expires, your users are forced to reset it on their next sign-in attempt.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_04120-1663-2947","score":12.660235405,"text":"\nSelect from the actions listed, and specify the timeout period. In this case, the timeout refers to the ban period that the action takes place. A 60 second timeout means the action is applied for 60 seconds.\n\n\n\nTable 1. Actions for rate limiting\n\n Action Description \n\n Block Issues a 429 error when the threshold is exceeded \n Challenge User must pass a Google reCaptcha Challenge before proceeding. If successful, we accept the request. Otherwise, the request gets blocked. \n JS Challenge User must pass a Javascript Challenge before proceeding. If successful, we accept the request. Otherwise, the request gets blocked. \n Simulate You can use this option to test your rule before applying any of the other options in your live environment. \n\n\n\nIn the Advanced response section, specify the response type when a rule's threshold is exceeded.\n\n\n\n\n\n Bypassing URLs \n\nBypass lets you create the equivalent of a allowlist or exception for a set of URLs. No actions trigger for those URLs, even if the Rate Limiting rule is matched.\n\n\n\n\n\n\n\n Protecting login \n\nProtect login creates a standard rule that protects login pages against brute-force attacks. Clients attempting to log in more than 5 times in 5 minutes are blocked for 15 minutes.\n\nEnter a name for the rule, and the login URL.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-rate-limiting"},{"document_id":"ibmcld_02294-6247-7862","score":12.4943008423,"text":"\n[Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/i-avatar-icon.svg)> Profile > Login settings. The user must set up the security questions and answers before an account owner or administrator can enable this setting on the User details page. Users with access to manage their own login settings by having the User-managed login setting that is turned on from their User details page can turn on and off this MFA setting.\n\nExternal authentication\n: Symantec is the only external, third-party authentication option that can be ordered for a monthly cost. An account owner or administrator must order this option for a user and enable it to be used from the User details page for the user. For Symantec, the administrator must work with the user to get that user's credential ID to complete the order. Users with access to manage their own login settings by having the User-managed login setting that is turned on from their User details page can turn on and off this MFA setting.\n\nPassword expiration\n: The password expiration is set to never by default. When you sign up for an account, you're never required to change your password. When you set a password expiration period, you're notified of your password expiration by email 14 days before, 7 days before, and the day the password is set to expire. This option is available only to users that log in with a SoftLayer ID. To update your password expiration, you must be an account owner or have the User-managed login setting that is turned on by your account administrator on your IAM User details page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-types"},{"document_id":"ibmcld_08435-3634-5079","score":12.4164466858,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_10007-1574-3749","score":12.4089679718,"text":"\nPassword expiration Specifies when a user password expires. \n Created on Specifies when the user was created. \n Authentication type Specifies the authentication type. \n\n\n\n\n\n\n\n User actions \n\nIn the users list view, there is an overflow menu that lists the actions that can be taken on the user.\n\n\n\nTable 1. The table lists user actions and their definitions.\n\n Value Description \n\n Assign owner Set the owner of the user account. \n Change password Change the password for the system user. \n Account expiration Set a date that the system user account will be valid until. \n Password expiration Set a number of days until the password for the user account expires. \n Rename Change the username of the user account. \n Admin privileges View and grant admin privileges. \n Object privileges View and grant object privileges. \n Remove Delete the user account from the system. \n\n\n\n\n\n\n\n Granting admin privileges to users \n\nUser privileges dictate what actions can be taken by a particular user account. When new users are created, they have no privileges, so in most cases privileges need to be added.\n\n\n\n1. Go to Users and groups > Users.\n2. Select the user for which you want to grant admin privileges and select Admin privileges from the overflow menu.\nIn this view, you can see different admin privileges, which are already granted or that can be granted to the selected user.\nGranting these privileges allows the user to do the actions that the privileges correspond to. Granting privileges on global database and global schema unlocks all the privileges to the user equivalent to an admin.\n3. Click Edit.\n4. Update, grant, or revoke object privileges by putting ticks in corresponding boxes.\n5. Click Save.\n\n\n\n\n\n\n\n Granting object privileges to users \n\nUser privileges dictate what actions can be taken by a particular user account. When new users are created, they have no privileges, so in most cases privileges need to be added.\n\n\n\n1. Go to Users and groups > Users.\n2. Select the user for which you want to grant object privileges and select Object privileges from the overflow menu.\n3. Select a database.\nYou can choose between the Global database and a specific database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-users-groups"},{"document_id":"ibmcld_02763-1774-3651","score":12.3493499756,"text":"\nSign in attempts per account Yes 200 per second All sign-in attempts for the instance are blocked for 1 minute. \n Sign up attempts per account Yes 200 per second All sign-up attempts for the instance are blocked for 1 minute. \n Email sending request No 10 emails in 5 minutes per user Email requests for the user are blocked for 30 minutes. \n SMS sending request No 10 SMS in 5 minutes per user SMS requests for the user are blocked for 30 minutes. \n MFA code characters No 6 numeric characters The code automatically has 6 characters that must be input by the user. \n MFA code expiration No 15 minutes If a user does not validate their code within 15 minutes, they can request that another code is sent as long as the authentication session is not expired. Within the authentication session, the code can be sent multiple times. Once the authentication session expires, the user must repeat the login process from the beginning. \n\n\n\nFor more information, see the [rate limit management API](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Management%20API%20-%20Config\/mgmt.updateRateLimitConfig).\n\n\n\n\n\n Ingress annotation \n\nBe sure to review the following limitations before you configure your annotation.\n\n\n\n* Refresh tokens are not currently supported.\n* IBM Cloud\u00ae Kubernetes Service supports one Ingress per namespace. If you already have one, you can update the existing Ingress configuration or use a different namespace.\n* The annotation does not work behind a proxy.\n\n\n\n\n\n\n\n Extensions \n\n\n\n* The response from your pre-mfa extension point must not exceed 10 KB. If it does, the request is canceled and the user is required to complete MFA.\n* If it takes App ID longer than 5 seconds to establish a connection to your pre-mfa extension point, or if the request takes longer than 7 seconds to complete, the request is canceled and the user is required to complete MFA.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-known-issues-limits"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.5,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.6366824387,"ndcg_cut_10":0.7598336331}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08211-2628-3483","score":31.9352855682,"text":"\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period. If a server is restored, the timeframe for which the server was within the resource reclamations is billed to your account.\n\nAfter the server is deleted, only metadata, which isn't considered to be personal data is kept for 6 months. Make sure you back up important data for future use because you can't recover data after the virtual server has been deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_08211-1158-3123","score":25.9443569183,"text":"\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_08217-1687-3909","score":21.0367984772,"text":"\nWhen you click the 'Inactive' server in Name field, an error message is displayed to indicate that provisioning has failed.\n\n What\u2019s happening \n\nYou try to create more than five virtual servers within a short period in one data center without any existing virtual server instances.\n\n Why it\u2019s happening \n\nThe number of virtual servers per data center is limited to five. Creating more than five virtual servers almost all at the same time in one data center leads to the status 'Inactive' (provisioning failed) for the sixth and all subsequent instances.\n\n How to fix it \n\nYou can either provision more than five virtual servers in different data centers. Or you can provision more than five instances by using different IBM Cloud accounts.\n\n\n\n\n\n Generating a new virtual server fails because of exhausted resources \n\nYou can only create a limited number of virtual server instances in each data center.\n\n What\u2019s happening \n\nWhen you provision a new virtual server, you get an error message because the resources (for example, memory) are exhausted.\n\n Why it\u2019s happening \n\nThe resources for the selected data center are exhausted.\n\n How to fix it \n\nRetry the action and select a different data center.\n\n\n\n\n\n Can't connect to free virtual server anymore \n\nI can't connect to a server (for example, via SSH), which is in the free plan although it's visible in the IBM Cloud resource list.\n\n What\u2019s happening \n\nYou can't connect to a server in the free plan anymore. The server is still visible in the resource list, but the dashboard shows an error message. The message indicates that the server has expired. When a server expires, the server and all data that is stored on the server are deleted.\n\n Why it\u2019s happening \n\nAll virtual servers in free plans are deleted after 30 days.\n\n How to fix it \n\nVirtual servers in paid plans aren't deleted. You can remove the server from the resource list by deleting it from the resource list.\n\n\n\n\n\n Can't create new virtual servers because of exhausted resources or plan limitations \n\nYou can't create new virtual servers because of exhausted resources or plan limitations, although you've less than the described limits.\n\n What\u2019s happening \n\nYou try to create a new server but fail.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-troubleshooting"},{"document_id":"ibmcld_15998-1422-3109","score":20.2247047424,"text":"\nCommon problems \n\nHere are a few difficulties you might encounter.\n\n\n\n Not authorized (401 or 403 error) \n\nYour account might not be authorized for VPC. Make sure that you are using an account that has been onboarded.\n\n\n\n\n\n IAM token expired \n\nThe service is no longer returning any JSON, instead of just giving an HTTP \"401 Unauthorized\" to all requests. This error occurs after about an hour if your IAM token has expired. Refresh your IAM token by rerunning iam_token=$(ibmcloud iam oauth-tokens | awk '\/IAM\/{ print $4; }').\n\n\n\n\n\n Cannot create resources \n\nIf you cannot create a VPC or other resources, make sure that the owner of the account has granted you the correct [permissions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resourcesmanaging-user-permissions-for-vpc-resources).\n\n\n\n\n\n No response from API \n\nIf the API is no longer returning any JSON, it is likely your IAM token has expired and needs to be refreshed. Log in to IBM Cloud again or refresh your token by running iam_token=$(ibmcloud iam oauth-tokens | awk '\/IAM\/{ print $4; }').\n\n\n\n\n\n\n\n Cannot delete resources \n\nCertain operations--creating and deleting virtual server instances, and creating and deleting subnets, for example--are completed asynchronously through the API. Because of this fact, it is recommended to poll the resources you're deleting, to check for deletion before proceeding.\n\nIt can take several minutes for resources to be deleted from the system, due to these asynchronous operations. To facilitate deletion, the best practice is to do things in this order:\n\n\n\n1. Delete your instances\n2. Delete your public gateways\n3. Delete your subnets\n4. Delete your VPCs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-troubleshooting-vpc"},{"document_id":"ibmcld_08217-3469-5347","score":20.0583763123,"text":"\nHow to fix it \n\nVirtual servers in paid plans aren't deleted. You can remove the server from the resource list by deleting it from the resource list.\n\n\n\n\n\n Can't create new virtual servers because of exhausted resources or plan limitations \n\nYou can't create new virtual servers because of exhausted resources or plan limitations, although you've less than the described limits.\n\n What\u2019s happening \n\nYou try to create a new server but fail. Instead a message is displayed, which informs you that the maximum number of servers is reached in the selected data center for this account, or that you've reached the maximum number of free plans for this account. When you look in the resource list, you see that you haven't reached the limit.\n\n Why it\u2019s happening \n\nThe resource list is not a complete list of your servers. If you \u201cdelete\u201d a server from the resource list, it's made inaccessible and marked for deletion, but it's still available for you within the [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) for a limited amount of time, as described in [Deleting a virtual server](https:\/\/cloud.ibm.com\/docs\/services\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs).\n\n How to fix it \n\nDepending on your requirements, you must either delete the resource from the resource reclamations, or select a different data center (maximum number of servers is reached), or select the appropriate paid plan that meets your requirements if you reach the maximum number of free plans. For more information, see [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations).\n\n\n\n\n\n VoiceOver on MacOS does not announce all information on the dashboard in Firefox \n\nVoiceOver on MacOS does not announce information presented on the dashboard in Firefox.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-troubleshooting"},{"document_id":"ibmcld_08211-7-1559","score":19.4818954468,"text":"\nDeleting a virtual server \n\nYou can use the Hyper Protect Virtual Servers UI or the CLI to delete virtual servers. Deleted servers that belong to paid plans can also be restored before the reclamation period expires.\n\n\n\n Deleting a virtual server in the UI \n\n\n\n1. Go to the [Resource list](https:\/\/cloud.ibm.com\/resources) (see [Retrieving virtual server information](https:\/\/cloud.ibm.com\/docs\/services\/hp-virtual-servers?topic=hp-virtual-servers-retrieve-info-vs)) to delete a virtual server.\n2. Select the instance from the Services list and apply the Delete from its action list.\n\n\n\nZoom\n\n![Deleting a virtual server instance](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/29e0ddc9fd7149f916889ba6a4d131cc3528c9bc\/hp-virtual-servers\/image\/hpvs_delete_instance.gif)\n\nFigure 1. Deleting a virtual server instance\n\n\n\n\n\n Deleting a virtual server from the CLI \n\nTo delete Hyper Protect Virtual Servers from the [CLI](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-plugin):\n\n\n\n1. Make sure you know the Cloud resource name (CRN) of the server you want to delete. To find the CRN, run:\n\nibmcloud hpvs instances\n2. To delete the server, run the following command:\n\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_09087-65885-67524","score":18.8955459595,"text":"\nUsing the CLI, create an import token, allow it to expire, then attempt to retrieve it.\n\n create an import token that expires in 5 minutes (300 seconds) and allows 2 retrievals\n$ ibmcloud kp import-token create -e 300 -m 2\n\nCreated Expires Max Retrievals Remaining Retrievals\n2020-08-18 19:39:06 +0000 UTC 2020-08-18 19:44:06 +0000 UTC 2 2\n\n sleep 300 seconds, which allows the import token to expire\n$ sleep 300\n\n show the import token\n$ ibmcloud kp import-token show\n\nFAILED\nkp.Error:\ncorrelation_id='fb677c6e-9bfa-422e-a14b-0e221bbad32b',\nmsg='Conflict:\nImport Token could not be retrieved.\nPlease see reasons for more details.',\nreasons='[IMPORT_TOKEN_EXPIRED_ERR:\nThe import token has expired. -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\nShow more\n\n\n\n\n\n\n\n\n\n 24 - The key cannot be deleted because it's... \n\n\n\n Message \n\nThe key cannot be deleted because it's protecting a cloud resource that has a retention policy: Before you delete this key, contact an account owner to remove the retention policy on each resource that is associated with the key\n\nReason code: PREV_KEY_DEL_ERR\n\n\n\n\n\n HTTP status code \n\n409 - Conflict\n\nThe HTTP 409 Conflict response status code indicates a request conflict with current state of the server.\n\nConflicts are most likely to occur in response to a PUT request. For example, you may get a 409 response when uploading a file which is older than the one already on the server resulting in a version control conflict.\n\n\n\n\n\n Context \n\nThis error occurs when a key, used for \"Registrations\", is deleted.\n\nIn most cases, a key with registrations can be deleted using the --force option.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_00324-15719-17878","score":18.3176689148,"text":"\nThat content is then cached for the TTL duration specified for the content. If a user request is received after the TTL has expired, the Edge server reaches out to the origin host to fetch the content. If the origin server cannot be reached for some reason (for instance, the origin host is down, or there is a network issue), the Edge server serves the expired (stale) content to the request. This feature is supported by Akamai and cannot be turned off.\n\n\n\n\n\n Support for multiple origins with distinct paths \n\nIn certain cases, you might want to deliver certain content from a different origin server. For example, you might want certain photos or videos that are served from different origin servers. IBM Cloud CDN provides the option to set up multiple origin servers with multiple paths. This allows flexibility with regards to how and where the data is stored.\n\nThe path that is specified for the origin server must be unique regarding the CDN. The origin server itself does not need to be unique.\n\n\n\n\n\n Time to Live (TTL) \n\nTime to Live indicates the amount of time (in seconds) the Edge server retains the cached content for that particular file or directory path. When a CDN is first created, a global TTL is created for path \/* with a default time of 3600 seconds. The minimum value for TTL is 0 seconds, and the maximum value is 2147483647 seconds. For each entry, the TTL path must be unique for the CDN. If multiple paths match a given content, the most recently configured path match applies to that content. For example, consider two TTLs, \/example\/file created first with a time to live value of 3000 seconds and \/example\/* is created later, with a value of 4000 seconds. Although \/example\/file is more specific, \/example\/ was created most recently, so the TTL for \/example\/file is 4000 seconds. After creation, TTL entries can be edited for path, time, or both. TTL entries can also be deleted.\n\n\n\n\n\n Token authentication \n\nToken authentication is the process of generating tokens, associating them with an authenticated user session, and validating the request by using these tokens to prevent unauthorized sharing of links to your content.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-about-content-delivery-networks-cdn-"},{"document_id":"ibmcld_02586-13815-15875","score":17.6976070404,"text":"\n* A request would use an existing resource (for example, to generate a new resource) which has client-mutable state preventing such use.\n* A request would delete a resource that another resource depends on.\n\n\n\nThe following scenarios MUST NOT result in a 409 Conflict:\n\n\n\n* A request has an internal conflict. This SHOULD result in a 400 Bad Request.\n* A request depends on a resource that does not exist. This SHOULD result in a 400 Bad Request.\n* A request would update or create a resource with a binding to an existing resource that the user is unauthorized to bind to. This SHOULD result in a 403 Forbidden unless the user is [not permitted to know about](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-status-codesinformation-exposure-with-401-and-403) the existing resource.\n* A request would conflict with state that is invisible to clients. This MUST NOT happen by design, but unexpected runtime scenarios MAY result in a 500 Internal Server Error.\n* A request would conflict with state that is immutable for clients. This SHOULD result in a 400 Bad Request.\n* A safe[10] request cannot be made because of the current state of the system. This SHOULD NOT happen by design. Consider modeling the missing functionality as an \"empty\" resource with a 200 OK response or an absent resource with a 404 Not Found response.\n\n\n\nThe following scenarios SHOULD NOT result in a 409 Conflict:\n\n\n\n* A request cannot be processed because of transient resource state and the client is advised to wait for that state to change and retry the request. This SHOULD NOT happen by design, but if it does, it MAY result in a 409 Conflict.\n* A request would update or create a resource with a binding to an existing resource which has irrecoverably failed or expired. This SHOULD result in a 400 Bad Request.\n* A request would use an existing resource (for example, to generate a new resource) which has irrecoverably failed or expired. This SHOULD result in a 400 Bad Request.\n\n\n\n\n\n\n\n\n\n Server errors: 5xx \n\n\n\nServer error status codes\n\n Code Meaning Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-status-codes"},{"document_id":"ibmcld_08399-10340-11838","score":17.0736083984,"text":"\nhpvs instance-delete \n\nThis command deletes a Hyper Protect Virtual Servers.\n\nibmcloud hpvs instance-delete (NAME | CRN)\n\n\n\n Command options \n\nNAME\n: The name of your new instance. An error message is displayed if you specify a NAME that is not unique, for example,\n\nVS name 'ABC' is ambiguous: more than one VS exist for the provided name: [crn1 crn2].\n\nSpecify the CRN if your instance name is not unique.\n\nCRN\n: The server's Cloud resource name (CRN). Specify the CRN if NAME is not unique. You can run the ibmcloud hpvs instances command to get the CRN.\n\n--force\n: Forces the deletion of the Hyper Protect Virtual Servers instance without prompting for confirmation.\n\n\n\n\n\n Example output \n\nAre you sure you want to delete the service instance? [y\/N]> y\n\nDeleting service instance crn:v1:staging:public:hpvs:dal13:a\/1075962b93044362a562c8deebbfba2e:231fbbf4-1415-4162-86f0-9d50c260106d:: ...\n\nOK\nService instance 'crn:v1:staging:public:hpvs:dal13:a\/1075962b93044362a562c8deebbfba2e:231fbbf4-1415-4162-86f0-9d50c260106d::' was deleted.\nYou can restore a resource within 7 days after you delete it.\nYou can run the 'ibmcloud resource reclamations' command to check the resources that you can restore.\nTo irrecoverable delete the instance run the 'ibmcloud resource reclamation-delete RECLAMATION_ID' command.\n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it stops and is marked for deletion. It is deleted after a reclamation period of seven days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpvs-cli-plugin?topic=hpvs-cli-plugin-hpvs_cli_plugin"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08695-7-1852","score":21.8956851959,"text":"\nWhy can't I delete keys? \n\nWhen you use the Hyper Protect Crypto Services user interface, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Hyper Protect Crypto Services service.\n\nYou're assigned a Manager access policy for the service instance. You try to delete a key, but the action fails with either of the following error messages:\n\n\n\n* Error message 1:\n\n> The service was not able to delete key \"<key_name>\". The key cannot be deleted because it is protecting one or more cloud resources that have a retention policy.\n* Error message 2:\n\n> The service was not able to delete key \"<key_name>\". Because the key is enabled with the dual authorization policy and you set the key for deletion, a second approver needs to continue with the key deletion operation.\n\n\n\n Why it\u2019s happening \n\nThe following reasons might cause the errors:\n\n\n\n* If error message 1 is displayed, this key is actively protecting one or more cloud resources, such as a Cloud Object Storage bucket.\n* If error message 2 is displayed, this key is enabled with the dual authorization policy that requires a deletion authorization from two users. You set the key for deletion and you need to contact the second approver to complete the deletion.\n\n\n\n How to fix it \n\nThe following instructions can help you solve the problems:\n\n\n\n* To resolve the error that is reported in error message 1, [review the resources](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"},{"document_id":"ibmcld_08414-28698-30846","score":20.5101909637,"text":"\nIf the delete key event has a reason.reasonCodeof 409, the key cannot be deleted because it is possibly protecting one or more cloud resources that have a retention policy. Make a GET request to \/keys\/{id}\/registrations to learn which resources this key is associated with. A registration with \"preventKeyDeletion\": true indicates that the associated resource has a retention policy. To enable deletion, contact an account owner to remove the retention policy on each resource that is associated with this key.\n\nA delete key event might also receive a reason.reasonCode of 409 due to a dual auth deletion policy on the key. Make a GET request to \/api\/v2\/keys\/{id}\/policies to see whether a dual authorization policy is associated with your key. If there is a policy set, contact the other authorized user to delete the key.\n\n\n\n\n\n Unable to authenticate while making a request \n\nIf the event has a reason.reasonCode of 401, you might not have the correct authorization to perform Hyper Protect Crypto Services actions in the specified service instance. Verify with an administrator that you are assigned the correct platform and service access roles in the applicable service instance. For more information about roles, see [Roles and permissions](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-access).\n\nCheck that you are using a valid token that is associated with an account that is authorized to perform the service action.\n\n\n\n\n\n Unable to view or list keys in a service instance \n\nYou can call GET api\/v2\/keys to list the keys that are available in your service instance. If responseData.totalResources is 0, query for keys in the deleted state by using the state parameter or adjust the offset and limit parameters in your request.\n\n\n\n\n\n Lifecycle action on a key with registrations did not complete \n\nThe responseData.reasonForFailure and responseData.resourceCRN fields contain information about why the action wasn't able to be completed.\n\nIf the event has a reason.reasonCode of 409, the action cannot be completed due to the adopting service's key state conflicting with the key state that Hyper Protect Crypto Services has.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events"},{"document_id":"ibmcld_09038-20413-22510","score":20.2830085754,"text":"\nA registration with \"preventKeyDeletion\": true indicates that the associated resource has a retention policy. To enable deletion, contact an account owner to remove the retention policy on each resource that is associated with this key.\n\nA delete key event could also receive a reason.reasonCode of 409 due to a dual auth deletion policy on the key. Make a GET request to \/api\/v2\/keys\/{id}\/policies to see if there is a dual authorization policy associated with your key. If there is a policy set, contact the other authorized user to schedule the key for deletion.\n\n\n\n\n\n Unable to authenticate while make a request \n\nIf the event has a reason.reasonCode of 401, you do not have the correct authorization to perform Key Protect actions in the specified Key Protect instance. Verify with an administrator that you are assigned the correct platform and service access roles in the applicable service instance. For more information about roles, see [Roles and permissions](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-access).\n\nCheck that you are using a valid token that is associated with an account authorized to perform the service action.\n\n\n\n\n\n Unable to view or list keys in a Key Protect instance \n\nIf you make a call to GET api\/v2\/keys to list the keys that are available in your Key Protect instance and responseData.totalResources is 0, you may need to query for keys in the deleted state using the state parameter or adjust the offset and limit parameters in your request.\n\n\n\n\n\n Lifecycle action on a key with registrations did not complete \n\nThe responseData.reasonForFailure and responseData.resourceCRN fields contain information on why the action wasn't able to be completed.\n\nIf the event has a reason.reasonCode of 409, the action could not be completed due to the adopting service's key state conflicting with the key state that Key Protect has.\n\nIf the event has a reason.reasonCode of 408, the action could not be completed because Key Protect was not notified that all appropriate actions were taken within 4 hours of the action request.\n\n\n\n\n\n\n\n Event Severity","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events"},{"document_id":"ibmcld_08680-0-1120","score":19.8110542297,"text":"\n\n\n\n\n\n\n  Why can't I delete internal keystores? \n\nYou are not able to delete the internal KMS keystore through either UI or API.\n\n  What\u2019s happening \n\nYou have destroyed all keys in the KMS keystore. However, when you try to delete the keystore, you still receive an error similar to one of the following:\n\n> The service was not able to delete keystore <keystore_name> because it still contains some keys. Conflict: Key ring could not be deleted: Please see reasons for more details.\n\n  Why it\u2019s happening \n\nThe KMS key metadata is to be automatically removed in 90 days. Before that, the key metadata still remains in the keystore and you cannot delete the keystore.\n\n  How to fix it \n\nDelete the internal KMS keystore after the key metadata gets removed automatically. Or, you can [manually remove all key metadata using the KMS API](https:\/\/cloud.ibm.com\/apidocs\/hs-cryptopurgekey) in 4 hours after you destroy the key. Make sure that you have the KMS Key Purge role assigned. For more information about roles, see [Managing user access](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-uko-manage-access).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-delete-keystore"},{"document_id":"ibmcld_08681-0-887","score":19.7767429352,"text":"\n\n\n\n\n\n\n  Why can't I delete vaults? \n\nYou are not able to delete vaults by using either UI or API.\n\n  What\u2019s happening \n\nYou try to delete a vault, but it fails with the following message:\n\n> The service was not able to delete vault <vault_name> because it still contains some keys or keystores.\n\n  Why it\u2019s happening \n\nIf you want to delete a vault, you need to delete all managed keys, and delete or disconnect from all target keystores that are managed in the vault first. The Delete function is available for empty vaults only.\n\n  How to fix it \n\nVerify with your administrator that you're assigned [the correct role](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessroles) in the applicable resource group or service instance. And then, delete all managed keys, and delete or disconnect from all target keystores that are managed in the vault, and try again.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-delete-vault"},{"document_id":"ibmcld_09087-19156-20902","score":19.4657096863,"text":"\n6 - Key could not be deleted... \n\n\n\n HTTP status code \n\n409 - Conflict\n\nThe HTTP 409 Conflict client error response code indicates that an error in the client request can be resolved per the specified reason code returned.\n\n\n\n\n\n Context \n\nThe message returns a reason in the message that provides the specific context.\n\n\n\n\n\n Message \n\nReason code: AUTHORIZATIONS_NOT_MET\n\nThe key cannot be deleted because it failed the dual authorization request. Before you delete this key, make sure dual authorization procedures are followed. See the topic, [Deleting keys using dual authorization](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys).\n\nReason code: PROTECTED_RESOURCE_ERR\n\nThe key cannot be deleted because the key has one or more associated resources. See the topic, [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\nReason code: PREV_KEY_DEL_ERR\n\nThe key cannot be deleted because it's protecting a cloud resource that has a retention policy. Before you delete this key, contact an account owner to remove the retention policy on each resource that is associated with the key. See the topic, [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Example Response 1 \n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Key could not be deleted. Please 'reasons' for more details.\",\n\"reasons\":\n{\n\"code\": \"AUTHORIZATIONS_NOT_MET\",\n\"message\": \"The key cannot be deleted because it failed the dual authorization request.\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_09087-21484-22833","score":19.3597011566,"text":"\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Key could not be deleted. Please 'reasons' for more details.\",\n\"reasons\":\n{\n\"code\": \"PREV_KEY_DEL_ERR\",\n\"message\": \"The key cannot be deleted because it's protecting a cloud resource that has a retention policy.\",\n\"status\": 409,\n\"moreInfo\":\"https:\/\/cloud.ibm.com\/apidocs\/key-protect\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n\n\n 7 - Key has already been deleted... \n\n\n\n Message \n\nKey has already been deleted: Please delete references to this key\n\nReason code: KEY_DELETED_ERR\n\n\n\n\n\n HTTP status code \n\n410 - Gone\n\nThe HTTP 410 Gone client error response code indicates that access to the target resource is no longer available at the origin server and that this condition is likely to be permanent.\n\nIf you don't know whether this condition is temporary or permanent, a 404 status code should be used instead.\n\nA 410 response is cacheable by default.\n\n\n\n\n\n Context \n\nThe delete key request fails because the key was previously deleted. You cannot delete a key more than once.\n\n\n\n Example \n\n delete an existing key\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID\n\nDeleting key: '0c17...<redacted>...5c34', from instance: 'a192...<redacted>...7411'...\nOK\nDeleted Key\n0c17...<redeacted>...5c34\n\n this request fails because the key was previously deleted","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_05010-22156-23485","score":18.9648475647,"text":"\nFor details on establishing a hard quota that prevents usage beyond a set bucket size, see [Using Bucket Quota](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-quota).\n\n\n\n\n\n Why am I unable to delete a Object Storage instance? \n\nIt isn't possible to delete an instance if the API key or Service ID being used is locked. You'll need to navigate in the console to Manage > Access (IAM) and unlock the API Key or Service ID. The error provided may seem ambiguous but is intended to increase security:\n\n> An error occurred during an attempt to complete the operation. Try fixing the issue or try the operation again later. Description: 400\n\nThis is intentionally vague to prevent any useful information from being conveyed to a possible attacker. For more information on locking API keys or Service IDs, [see the IAM documentation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceids&interface=uilock_serviceid).\n\n\n\n\n\n How do I download the Root CA certificate for Object Storage? \n\nObject Storage root CA certificates can be downloaded from [https:\/\/www.digicert.com\/kb\/digicert-root-certificates.htm](https:\/\/www.digicert.com\/kb\/digicert-root-certificates.htm). Please download PEM or DER\/CRT format from \"DigiCert TLS RSA SHA256 2020 CA1\" that is located under \"Other intermediate certificates.\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq"},{"document_id":"ibmcld_16045-10806-12293","score":18.855890274,"text":"\nIf you can't delete the key, see [troubleshooting key management service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).\n\nBlock Storage for VPC volumes, snapshots, and custom images with a deleted root key appear in the list of resources with an unusable status. File Storage for VPC shares show a suspended status. The API reason code is encryption_key_deleted.\n\nDeletion of the root key results in the following conditions.\n\n\n\n* All instances with an unusable boot volume do not restart.\n* You can't attach unusable data volumes to an instance.\n* You can't restore a volume from a snapshot.\n* You can't access a file share.\n* You can't provision instances from unusable images.\n* Billing continues for unusable resources until you delete them.\n\n\n\nBefore you force delete a root key, it's best to review all resources that are associated with that root key. Consider [temporarily disabling the key](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managingbyok-disable-root-keys) instead of deleting it to suspend the use of that root key. Root keys can be restored within 30 days, but only if they are imported root keys, not KMS generated.\n\nFor more information about deleting root keys, see the following topics.\n\n\n\n* [Key Protect - Deleting keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys)\n* [Hyper Protect Crypto Services - Deleting keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-managing"},{"document_id":"ibmcld_09192-4150-5583","score":18.6641273499,"text":"\nIf the Key Protect instance contains more than 200 keys, you need to use the [offset and limit parameters](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keysretrieve-subset-keys-api) to list another subset of keys.\n\nFor example, if you want to list keys 201 - 210 that are available in a service instance, you use ..\/keys?offset=200&limit=10 to skip the first 200 keys.\n\n\n\n\n\n Unable to delete keys \n\nWhen you use the Key Protect user interface or REST API, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Key Protect service.\n\nYou're assigned a Manager access policy for the Key Protect instance. You try to delete a key, but the action fails with the following error message.\n\nConflict: Key could not be deleted. Status: 409, Correlation ID: 160cc463-71d1-4b30-a5f2-d3f7e9f2b75e\n\nYou also try to delete the key by using the Key Protect API, but you receive the following error message.\n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Conflict: Key could not be deleted. Please see reasons for more details.\",\n\"reasons\":\n{\n\"code\": \"PROTECTED_RESOURCE_ERR\",\n\"message\": \"Key is protecting one or more cloud resources\",\n\"status\": 409,\n\"moreInfo\": \"https:\/\/cloud.ibm.com\/apidocs\/key-protect\",\n\"target\": {\n\"type\": \"query_param\",\n\"name\": \"force\"\n}\n}\n]\n}\n]\n}\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshooting"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.39038005}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01019-1608-2449","score":23.3585987091,"text":"\nIf you need to delete the key during the soft-deletion period, you have to force delete the key. After the soft-deletion period, the key can be deleted without the force. You can check the association between the key and your deployment to determine when you can delete the key.\n\n\n\n\n\n Deleting data in your database \n\nThe Db2 database stores data in pages on block storage. When DELETE or TRUNCATE operations are performed, that data is no longer accessible unless you are using TEMPORAL tables. The physical pages that contain the data are not immediately erased and might still exist on the disk, but will be overwritten as needed. There is no ability to recover this data. The database provides the REORG and REDUCE MAX capability to reclaim this space for other activities or it will be reused when the database needs to store more data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-del_db"},{"document_id":"ibmcld_09064-9212-10938","score":21.8867607117,"text":"\nForce deletion on a key won't succeed if the key is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy), which is a Write Once Read Many (WORM) policy set on the your IBM Cloud resource. You can verify whether a key is associated with a non-erasable resource by checking the 'preventKeyDeletion\" field in the [registration details](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) for the key. Then, you must contact an account owner to remove the retention policy on each registered IBM Cloud resource that is associated with the key before you can delete the key.\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-up-api).\n2. Retrieve the ID of the key that you want to force delete.\n\nYou can retrieve the ID for a specified key by making a GET \/v2\/keys\/ request, or by viewing your keys in the Key Protect dashboard.\n3. Run the following curl command to force delete the key and its contents.\n\n$ curl -X DELETE \"https:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>?force=true\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\" -H \"prefer: <return_preference>\"\n\nReplace the variables in the example request according to the following table.\n\n\n\n\n\nTable 2. Describes the variables that are needed to delete keys with the Key Protect API.\n\n Variable Description \n\n region Required. The region abbreviation, such as us-south or eu-gb, that represents the geographic area where your Key Protect instance resides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys"},{"document_id":"ibmcld_09088-9397-11338","score":21.6485118866,"text":"\nIf it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\n\n\n\n\n What happens if I try to delete a key that's actively encrypting data? \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_16727-1212381-1214315","score":21.6174907684,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1209748-1211682","score":21.6174907684,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_09087-30097-31549","score":21.5784244537,"text":"\nYou must use the force option to delete a root key that is registered with another cloud resource.\n\nRegistrations are associations between root keys and other cloud resources, such as Cloud Object Storage (COS) buckets or Cloud Databases deployments.\n\nFor more information about Registrations, see [viewing associations between root keys and encrypted IBM Cloud resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources).\n\n[See this explanation](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-delete) of deleting keys that are registered with another cloud resource (look at the force option).\n\n this CLI request fails because the registration was not deleted\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID\n\nDeleting key: 52a9d772-8982-4620-bfb4-b070dd812a0c, from instance: b0d84b32-09d0-4314-8049-da78e3b9ab6f...\nFAILED\nkp.Error:\ncorrelation_id='c27b7948-4a1f-4cbd-8770-cb3616888e27',\nmsg='Conflict:\nKey could not be deleted.\nPlease see \"reasons\" for more details.',\nreasons='[PROTECTED_RESOURCE_ERR:\nKey is protecting one or more cloud resources -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshootingunable-to-delete-keys]'\n\n this CLI request succeeds when using the --force option\n the registration between Key Protect and the cloud resource exists\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID --force --output json\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_01019-7-2103","score":21.4348907471,"text":"\nDeleting a database \n\nWhen a service instance is deleted, the database that it provides is also removed. This will delete any online data and logs as well as database backups. The data will not be recoverable after this action.\n\n\n\n How is the data deleted \n\nAll data is encrypted at rest to ensure data is protected at all times using encryption keys stored in a key management service called Key Protect. When access to those keys is removed, the data is crypto-shredded and cannot be recovered. When the service instance is deleted, the block storage that is used for the database is wiped to ensure that all of the data is erased. Any data objects in cloud object storage are also deleted and not recoverable.\n\n\n\n\n\n When is the data deleted \n\n\n\n\n\n Using your own encryption keys to delete data \n\nYou can use your own encryption keys to delete data. This is called crypto-shredding. After the key is deleted, your data is unrecoverable and unreadable by anyone.\n\nKey Protect allows you to initiate a force delete of a key that is in use by various IBM Cloud\u00ae services, including your Db2 on Cloud service instances. Deleting a key that is in use on your deployment locks the disks containing your data when the key is requested again. You can have this occur right away by contacting IBM Support or by deleting your service instance. Key deletion is sent to the Log Analysis Activity Tracker as kms.secrets.delete.\n\nIf you delete a deployment that is protected with your Key Protect key, the deployment remains registered against the key for the duration of the soft-deletion period (up to 9 days). If you need to delete the key during the soft-deletion period, you have to force delete the key. After the soft-deletion period, the key can be deleted without the force. You can check the association between the key and your deployment to determine when you can delete the key.\n\n\n\n\n\n Deleting data in your database \n\nThe Db2 database stores data in pages on block storage. When DELETE or TRUNCATE operations are performed, that data is no longer accessible unless you are using TEMPORAL tables.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-del_db"},{"document_id":"ibmcld_01034-3831-4923","score":21.2629642487,"text":"\nAfter the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-hpcs"},{"document_id":"ibmcld_06564-2541-3625","score":21.0598831177,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-deprovisioning"},{"document_id":"ibmcld_06381-2433-3517","score":21.0598831177,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.6052602441}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06499-2416-3629","score":17.2735137939,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"},{"document_id":"ibmcld_06443-2410-3623","score":17.2735137939,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-deprovisioning"},{"document_id":"ibmcld_06341-2428-3641","score":17.2735137939,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"},{"document_id":"ibmcld_06627-2422-3635","score":17.2735137939,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"},{"document_id":"ibmcld_06696-2412-3625","score":17.2735137939,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-deprovisioning"},{"document_id":"ibmcld_06564-2541-3625","score":15.846698761,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-deprovisioning"},{"document_id":"ibmcld_06381-2433-3517","score":15.846698761,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"},{"document_id":"ibmcld_09551-2545-3629","score":15.846698761,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"},{"document_id":"ibmcld_01034-3831-4923","score":14.875,"text":"\nAfter the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-hpcs"},{"document_id":"ibmcld_09562-3760-5490","score":14.0571594238,"text":"\nWhen you rotate a key, the process initiates a syncing KMS state task, and your deployment is reencrypted with the new key. The task is displayed on the Tasks page on your deployment's Overview and the associated Key Protect and Cloud Databases events are sent to Activity Tracker.\n\nFor more information, see [Rotating manually or automatically](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-rotationcompare-key-rotation-options).\n\n\n\n\n\n Deleting the Deployment \n\nIf you delete a deployment that is protected with a Key Protect key, the deployment remains registered against the key during the soft-deletion period (up to 9 days). To delete the key in the soft-deletion period, [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) the key. After the soft-deletion period, the key can be deleted without the force. To determine when you can delete the key, check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources).\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nKey Protect allows you to [initiate a force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-key-protect"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.5147714449,"ndcg_cut_10":0.7467049735}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06627-2422-3635","score":18.8996200562,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"},{"document_id":"ibmcld_06696-2412-3625","score":18.8996200562,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-deprovisioning"},{"document_id":"ibmcld_06443-2410-3623","score":18.8996200562,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-deprovisioning"},{"document_id":"ibmcld_06499-2416-3629","score":18.8996200562,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"},{"document_id":"ibmcld_06341-2428-3641","score":18.8996200562,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"},{"document_id":"ibmcld_09551-2545-3629","score":18.756570816,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"},{"document_id":"ibmcld_06564-2541-3625","score":18.756570816,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-deprovisioning"},{"document_id":"ibmcld_06381-2433-3517","score":18.756570816,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"},{"document_id":"ibmcld_08622-7-1971","score":17.2652416229,"text":"\nRestoring your data from another region \n\nIf a regional disaster that affects all available zones occurs, you're notified through the [IBM Cloud status](https:\/\/cloud.ibm.com\/status?selected=status) web page and an email. In this case, depending on your [pricing plan](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-provision), whether you enable failover crypto units, and your requirements for recovery time, you can restore your data with different options.\n\n\n\n Restoring your data by using failover crypto units \n\nIf you are using the standard plan, and create your instance in Dallas (us-south) or Washington DC (us-east) and you enable failover crypto units, your data is restored automatically to reduce the downtime and data loss. In this case, you switch to use the failover crypto units in another region to manage your keys and perform cryptographic operations. The failover crypto units contain a backup of all the encryption keys and other resources in the operational crypto units.\n\nAt the same time, IBM repairs your service instance in the original region. If new operational crypto units are required to complete the repair, you will be notified by IBM and you need to load the master key to the new operational crypto units by [using recovery crypto units or master key parts](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-initialize-instance-mode). After your original service instance is recovered, IBM automatically redirects traffic back to the original region.\n\nTo use failover crypto units to restore data in a regional disaster, make sure that you initialize and configure all the failover crypto units the same as the operational crypto units before the disaster happens. For more information about initialization approaches, see [Introducing service instance initialization approaches](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-initialize-instance-mode).\n\n\n\n\n\n Restoring your data by opening an IBM support ticket","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data"},{"document_id":"ibmcld_09562-4925-6841","score":17.0084457397,"text":"\nKey Protect allows you to [initiate a force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events) as kms.secrets.delete.\n\n\n\n\n\n Bring your own key for backups \n\nIf you use Key Protect, when you provision a database you can also designate a key to encrypt the Cloud Object Storage disk that holds your deployment's backups.\n\nBYOK for backups is available only in US regions us-south and us-east, and eu-de.\n\nOnly keys in the us-south and eu-de are durable to region failures. To ensure that your backups are available even if a region failure occurs, you must use a key from us-south or eu-de, regardless of your deployment's location.\n\n\n\n Granting the delegation authorization \n\nTo enable your deployment to use the Key Protect key, you need to [Enable authorization to be delegated](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceauth) when granting the service authorizations. If the delegation authorization is not present before provisioning your deployment with a key, the provision fails.\n\n\n\n\n\n Using the Key at Provision in the CLI \n\nAfter the appropriate authorization and delegation is granted, you supply the [key name or CRN](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keys) when you provision a deployment.\n\nIn the CLI, use the backup_encryption_key_crn parameter in the parameters JSON object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-key-protect"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-4752-6201","score":23.1578369141,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-8253-9823","score":22.3934955597,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-3634-5079","score":20.802532196,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09125-1519-3352","score":19.4285354614,"text":"\nActive 1 Keys move immediately into the Active state on the activation date. This transition marks the beginning of a key's cryptoperiod. Keys with no activation date become active immediately and remain active until they expire or are destroyed. \n Suspended 2 A key moves into the Suspended state when it is [disabled for encrypt and decrypt operations](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keys). In this state, the key is unable to cryptographically protect data and can only be moved to the Active or Destroyed states. \n Deactivated 3 A key moves into the Deactivated state within one hour past its expiration date, if one is assigned. In this state, the only actions that can be performed on the key are unwrap, rewrap, rotate, and delete. \n Destroyed 5 Keys are moved into the Destroyed state after being deleted. Keys in this state can be recovered for 30 days but become eligible to be purged after 90 days. They can also be purged four hours after being moved into the Destroyed state, if necessary. After being moved into a Destroyed state, metadata that is associated with a key, such as its name and a record of when it last transitioned, is kept in the Key Protect database until the key is purged. For more information, check out [About deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keys). \n\n\n\n\n\n\n\n Key states and service actions \n\nKey states affect whether an action that is performed on a key succeeds or fails. For example, if a key is in the Active state, you can't restore the key, because the key wasn't previously deleted.\n\nThe following table describes how key states affect service actions. The column headers represent the key states, and the row headers represent the actions that you can perform on a key. The check mark icon (!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states"},{"document_id":"ibmcld_09061-7530-9143","score":19.1568565369,"text":"\nIf no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-up-api).\n2. Retrieve the ID of the key that you would like to delete.\n\nYou can retrieve the ID for a specified key by making a GET \/v2\/keys request, or by viewing your keys in the Key Protect dashboard.\n3. Run the following curl command to delete the key and its contents.\n\n$ curl -X DELETE \"https:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\" -H \"prefer: <return_preference>\"\n\nReplace the variables in the example request according to the following table.\n\n\n\n\n\nTable 2. Describes the variables that are needed to delete a key.\n\n Variable Description \n\n region Required. The region abbreviation, such as us-south or eu-gb, that represents the geographic area where your Key Protect instance resides. <br> <br>For more information, see [Regional service endpoints](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-regionsservice-endpoints). \n key_ID_or_alias Required. The unique identifier or alias for the key that you would like to delete. \n IAM_token Required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-6176-7874","score":18.9332675934,"text":"\n<br> <br>For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br>For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) by using the Key Protect GUI or API.\n\nIf you need to prevent the deletion of a key that's already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<keyID_or_alias>\/actions\/unsetKeyForDeletion.\n\n\n\n Delete the key \n\nAfter you set a key for deletion, another user with a Manager access policy can safely delete the key by using the Key Protect GUI or API.\n\nKey Protect sets a seven-day authorization period that starts after you provide the first authorization to delete the key. During this seven-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) and all key operations are allowed on the key. If no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09088-9397-11338","score":18.8269004822,"text":"\nIf it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\n\n\n\n\n What happens if I try to delete a key that's actively encrypting data? \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-faqs"},{"document_id":"ibmcld_16727-1212381-1214315","score":18.8182277679,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1209748-1211682","score":18.8182277679,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_09159-4-1910","score":18.3332042694,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Restoring keys \n\nWhen a key is deleted, it is moved to a \"destroyed\" state. However, information about the key (such as its metadata) can still be viewed and you have 30 days to restore the key to an active state. For this reason, a key deletion is considered a \"soft delete\" in that the key still exists but can no longer be used to access the data it has encrypted. This topic describes the process to restore a key and the limitations of the key restoration process.\n\nAs part of a testing and development process, it is normal to create and delete keys often. These keys are not gone forever; rather they are \"soft deleted\" and moved to a destroyed state. This does not mean they have been destroyed in the sense that they are gone forever. Instead, it simply means they cannot be used as part of any key actions such as using the key to encrypt or decrypt data. The key data can only be looked at, and, if the key was deleted in error, it might be possible to restore the key to an active state.\n\nThis intermediate period, in which a key has been deleted but can still be restored, lasts for 30 days. Between 30 days and 90 days, the key data can still be accessed, but the key can no longer be restored. After 90 days, the key becomes eligible to be automatically purged, which can occur at any time after 90 days. Purged keys, unlike destroyed keys, are gone forever.\n\n\n\nTable 1. Ties key states to the time from a key's deletion to what actions are possible with the key.\n\n Time from key deletion Name of key state Can view\/access key data? Can restore? \n\n One-30 days Destroyed Yes Yes \n 30-90 days Destroyed Yes No \n After 90 days Purged* No No \n\n\n\nNote: because purged keys are completely inaccessible and \"destroyed\" in the common usage of the word, there is technically no \"purged\" key state. Purged keys are simply gone and therefore don't have a \"state\" one way or another.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-restore-keys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10495-9135-10569","score":22.8598537445,"text":"\n(https:\/\/cognitiveclass.ai\/courses\/docker-essentials)\n\n\n\n\n\n What is Red Hat OpenShift? \n\nRed Hat OpenShift is a Kubernetes container platform that provides a trusted environment to run enterprise workloads. It extends the Kubernetes platform with built-in software to enhance app lifecycle development, operations, and security. With Red Hat OpenShift, you can consistently deploy your workloads across hybrid cloud providers and environments. For more information about the differences between the community Kubernetes and Red Hat OpenShift cluster offerings, see the [comparison table](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\n\n\n\n\n What compute host infrastructure does the service offer? \n\nYou can create clusters on Classic or IBM Cloud\u00ae Virtual Private Cloud infrastructure. You can also bring your own hosts by using Satellite.\n\nFor more information, see [Supported infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers).\n\n\n\n\n\n Related resources \n\nReview how you can learn about Kubernetes concepts and the terminology.\n\n\n\n* Familiarize yourself with the product by completing the [Creating clusters tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Learn how Kubernetes and Red Hat OpenShift on IBM Cloud work together by completing this [course](https:\/\/cognitiveclass.ai\/courses\/kubernetes-course).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview"},{"document_id":"ibmcld_10214-1438-3413","score":22.417924881,"text":"\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n\n\n\n\n\n What container platforms are available for my cluster? \n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform. If you want to use multiple container platforms, create a separate cluster for each.\n\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https:\/\/kubernetes.io\/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10154-7-1896","score":22.3340473175,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_08006-1379-2960","score":21.8339862823,"text":"\nEven though it is shown in the diagram as an option, it is not required to put Red Hat OpenShift on IBM Cloud in your management VPC.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud concepts \n\nRed Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift on IBM Cloud cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\nRed Hat OpenShift on IBM Cloud extends the Kubernetes platform with built-in software to enhance app lifecycle development, operations, and security. The master nodes are entirely IBM's responsibility, while there is shared responsibility for the worker nodes.\n\nFor IBM Cloud for Financial Services, you should provision Red Hat OpenShift on IBM Cloud in a VPC only and not in classic infrastructure.\n\nFor more information, see [Understanding Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview).\n\n\n\n\n\n Next steps \n\n\n\n* [Setup environment for deployment and configuration](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-deployment-setup-environment).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-openshift"},{"document_id":"ibmcld_10495-7-2029","score":21.7326965332,"text":"\nUnderstanding Red Hat OpenShift on IBM Cloud \n\nLearn more about [Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift), its capabilities, and the options that are available to you to customize the cluster to your needs.\n\nReview frequently asked questions and key technologies that Red Hat OpenShift on IBM Cloud uses.\n\n\n\n What is Red Hat OpenShift on IBM Cloud and how does it work? \n\nRed Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\n\n\n\n\n What is Kubernetes? \n\nKubernetes is an open source platform for managing containerized workloads and services across multiple hosts, and offers management tools for deploying, automating, monitoring, and scaling containerized apps with minimal to no manual intervention.\n\nZoom\n\n![Kubernetes certification badge](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/openshift\/images\/certified-kubernetes-color.svg)\n\nFigure 1. This badge indicates Kubernetes certification for IBM Cloud Container Service.\n\nThe open source project, Kubernetes, combines running a containerized infrastructure with production workloads, open source contributions, and Docker container management tools. The Kubernetes infrastructure provides an isolated and secure app platform for managing containers that is portable, extensible, and self-healing in case of a failover. For more information, see [What is Kubernetes?](https:\/\/www.ibm.com\/topics\/kubernetes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview"},{"document_id":"ibmcld_16727-396949-399109","score":21.6590175629,"text":"\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-396975-399135","score":21.6590175629,"text":"\nWith Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Does the service come with a managed Red Hat OpenShift master and worker nodes?\n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of Red Hat OpenShift on IBM Cloud.\n\nPeriodically, Red Hat OpenShift releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Red Hat OpenShift API server version or other components in your Red Hat OpenShift master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and Red Hat OpenShift on IBM Cloud components apply the latest security updates and patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_04644-7-1968","score":21.6100635529,"text":"\nRed Hat OpenShift on IBM Cloud \n\nIBM\u00ae Cloud Foundry is deprecated and no longer supported as of 1 June 2023. For more information, see the [deprecation details](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-deprecationdep_details).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae is a managed offering to create your own OpenShift cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. The managed OpenShift offering combines the built-in industry leading OpenShift capabilities including RHEL-based infrastructure, enterprise hardened Kubernetes, validated integrations, integrated container registry, developer workflow tools, and easy access to services through service brokers with the operational cluster lifecycle excellence from IBM Cloud SRE.\n\nAs a managed offering, IBM deploys the compute, networks, and storage based on the customer's requirements through the UI, CLI, API, or automation through IBM Cloud Schematics. Additionally, IBM provides the tooling for updates including OS patches, vulnerability remediation, and updates to any component in the stack with the customer determining when they should upgrade. Red Hat OpenShift on IBM Cloud supports HA masters, multi-zone clusters, compute isolation choices including bare metal worker nodes, customer managed keys using IBM Key Protect or industry leading HyperProtect Crypto Services using FIPS 140-2 Level 4 encryption, and secure access to IBM Cloud services to enhance your application's capabilities including Watson, IoT, and Analytics.\n\n\n\n Resources \n\nThe following resources are available to help you learn more about the OpenShift on IBM Cloud:\n\n\n\n* [IBM information page](https:\/\/www.ibm.com\/cloud\/openshift)\n* [Overview](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview)\n* [IBM Cloud service creation](https:\/\/cloud.ibm.com\/kubernetes\/overview?platformType=openshift)\n* [Documentation](https:\/\/cloud.ibm.com\/docs\/openshift)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-deprecation_openshift"},{"document_id":"ibmcld_14497-1215-3210","score":21.4863204956,"text":"\n[VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.\n\nThe operating system of the nodes is Red Hat\u00ae Enterprise Linux\u00ae CoreOS, which is the container host version of Red Hat Enterprise Linux (RHEL) and features an RHEL kernel with SELinux enabled by default. RHEL CoreOS includes kubelet, which is the Kubernetes node agent, and the CRI-O container runtime, which is optimized for Kubernetes. In Red Hat OpenShift 4.7, you must use RHEL CoreOS for all control plane machines, but you can use Red Hat Enterprise Linux (RHEL) as the operating system for compute, or worker machines. If you choose to use RHEL workers, you must perform more system maintenance than if you use RHEL CoreOS for all of the cluster machines.\n\nThe reference architecture and this build process use RHEL CoreOS. The nodes must have direct Internet access to complete the following tasks.\n\n\n\n* Access the Red Hat OpenShift Infrastructure Providers page to download the installation program.\n* Access quay.io to obtain the packages that are required to install the cluster.\n* Obtain the packages that are required to perform cluster updates.\n* Access Red Hat\u2019s software as a service page to perform subscription management.\n\n\n\nIn the reference architecture, the following components are installed and configured in the build process:\n\n\n\n* Bastion node - This RHEL VM acts as a \"jump-server\" on the overlay network to enable the build process. It is accessed by using SSH through the private network. It also hosts a webserver to help the build process of the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_10214-3003-4898","score":21.2506275177,"text":"\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https:\/\/kubernetes.io\/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system. With the [IBM Cloud Kubernetes Service version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionscs_versions), you get access to community Kubernetes API features that are considered beta or higher by the community. Kubernetes alpha features, which are subject to change, are generally not enabled by default. With Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios. To get started, try out the [Red Hat OpenShift on IBM Cloud tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\n\n\n\n\n Does the service come with a managed Red Hat OpenShift master and worker nodes? \n\nEvery cluster in Red Hat OpenShift on IBM Cloud is controlled by a dedicated Red Hat OpenShift master that is managed by IBM in an IBM-owned IBM Cloud infrastructure account. The Red Hat OpenShift master, including all the master components, compute, networking, and storage resources, is continuously monitored by IBM Site Reliability Engineers (SREs).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.9197207891,"ndcg_cut_5":0.9197207891,"ndcg_cut_10":0.9197207891}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10154-7-1896","score":24.3303852081,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10170-12206-14575","score":23.1228275299,"text":"\nDevelopers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.\n\nRed Hat OpenShift on IBM Cloud provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services as needed. Using industry-standard containers technology apps can be quickly developed and shared across multiple Development, Test, and Production environments. This setup provides the immediate benefit of scalability. Using Kubernetes rich set of deployment and runtime objects, the HR team can monitor and manage upgrades to apps reliably. They can also replicate and scale the apps, by using defined rules and the automated Kubernetes orchestrator.\n\n\n\n Step 1: Containers, microservices, and the Garage Method \n\n\n\n* Apps are built in a set of cooperative microservices that run in Red Hat OpenShift on IBM Cloud. The architecture represents the functional areas of the app with the most quality problems.\n* Deploy apps to container in Red Hat OpenShift on IBM Cloud, continuously scanned with IBM Vulnerability Advisor.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Adopt the essential agile and iterative development practices within the IBM Garage Method to enable frequent releases of new functions, patches, and fixes without downtime.\n\n\n\n\n\n\n\n Step 2: Connections to existing benefits back-end \n\n\n\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure tunnel to on-premises systems that host the benefits systems.\n* Combination of on-premises data and Red Hat OpenShift on IBM Cloud lets them access sensitive data while they adhere to regulations.\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_10531-7-2246","score":22.3095569611,"text":"\nRed Hat OpenShift on IBM Cloud partners \n\nTo provide you with all the capabilities that you need to run production workloads in the cloud, Red Hat OpenShift on IBM Cloud partners with other third-party service providers to enhance your cluster with logging, monitoring, and storage tools.\n\nReview the list of partners and the benefits of each solution that they provide. To find other proprietary IBM Cloud and third-party open source services that you can use in your cluster, see [Understanding IBM Cloud and 3rd party integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations).\n\n\n\n Portworx \n\n[Portworx](https:\/\/portworx.com\/products\/portworx-enterprise\/\/) is a highly available software-defined storage solution that you can use to manage local persistent storage for your containerized databases and other stateful apps, or to share data between pods across multiple zones.\n\nAn software defined storage (SDS), such as Portworx, solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n Benefits \n\nReview the following table to find a list of key benefits that you can get by using Portworx.\n\n\n\nBenefits of using Portworx\n\n Benefit Description \n\n Cloud native storage and data management for stateful apps Portworx aggregates available local storage that is attached to your worker nodes and that can vary in size or type, and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using Kubernetes persistent volume claims (PVC), you can add local persistent storage to your apps to store your data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners"},{"document_id":"ibmcld_10214-1438-3413","score":21.5484142303,"text":"\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n\n\n\n\n\n What container platforms are available for my cluster? \n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform. If you want to use multiple container platforms, create a separate cluster for each.\n\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https:\/\/kubernetes.io\/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10170-10609-12793","score":21.459028244,"text":"\nThus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* Red Hat OpenShift on IBM Cloud\n* IBM Cloud\u00ae Continuous Delivery\n* IBM Logging and Monitoring\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae\n* IBM Cloud App ID\n\n\n\nAccelerated development is a key win for the HR Exec. The team gets started by containerizing their apps and putting them in the cloud. With the use of modern containers, Developers can experiment easily with Node.js SDK and push changes to Development and Test systems, which are scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. No longer were updates to the HR site languishing in slow, error-prone build processes. They can deliver incremental updates to their site, daily or even more frequently. Moreover, logging and monitoring for the HR site is rapidly integrated, especially for how the site pulls personalized data from back-end benefit systems. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems. Developers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_10165-7426-9964","score":20.9904499054,"text":"\nA Development Exec has Developers that use on-premises application tools that slow down prototyping while they wait for hardware procurement.\n\nRed Hat OpenShift on IBM Cloud provides spin-up of compute by using open-source standard technology. After the company moved to Red Hat OpenShift on IBM Cloud, Developers have access to DevOps friendly tools, such as portable and easily shared containers.\n\nThen, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains. Their application development tools get a new face when they add on AI cloud services to apps with a click.\n\n\n\n Context \n\nStreamlining developer productivity and deploying AI tools to partners 4 times faster**\n\n\n\n* Disruption is rampant in the payment industry that also has dramatic growth both in the consumer and business-to-business segments. But updates to payment tools were slow.\n* Cognitive features are needed to target fraudulent transactions in new and faster ways.\n* With the growing numbers of partners and their transactions, the tool traffic increases, but their infrastructure budget needs to decrease, by maximizing efficiency of the resources.\n* Their technical debt is growing, not shrinking from an inability to release quality software to keep up with market demands.\n* Capital expense budgets are under tight control, and IT feels they don't have the budget or staff to create the testing and staging landscapes with their in-house systems.\n* Security is increasingly a primary concern, and this concern only adds to the delivery burden that all cause even more delays.\n\n\n\n\n\n\n\n Solution \n\nThe Development Exec is faced with many challenges in the dynamic payment industry. Regulations, consumer behaviors, fraud, competitors, and market infrastructures are all rapidly evolving. Fast-paced development is essential to being part of the future payment world.\n\nTheir business model is to provide payment tools to business partners, so they can help these financial institutions and other organizations deliver security-rich digital payment experiences.\n\nThey need a solution that helps the Developers and their business partners:\n\n\n\n* FRONT-END TO PAYMENT TOOLS: fee systems, payment tracking including cross-border, regulatory compliance, biometrics, remittance, and more\n* REGULATION-SPECIFIC FEATURES: each country has unique regulations so that the overall toolset might look similar but show country-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate roll-out of features and bug fixes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_finance"},{"document_id":"ibmcld_10166-7-2382","score":20.7420787811,"text":"\nGovernment use cases for IBM Cloud \n\nThese use cases highlight how workloads on Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae benefit from the public cloud. These workloads are isolated in global regions for data sovereignty, use Watson machine learning instead of net-new code, and connect to on-premises databases.\n\n\n\n Regional government improves collaboration and velocity with community Developers who combine public-private data \n\nAn Open-Government Data Program Executive needs to share public data with the community and private sector, but the data is locked in an on-premises monolithic system.\n\nWith Red Hat OpenShift on IBM Cloud, the Exec delivers the value of combined public-private data. Likewise, the service provides the public cloud platform to refactor and expose microservices from monolithic on-premises apps. Also, the public cloud allows government and the public partnerships to use external cloud services and collaboration-friendly open-source tools.\n\n\n\n Context \n\n\n\n* An \u201copen government\u201d model is the future, but this regional government agency can't make the leap with their on-premises systems.\n* They want to support innovation and foster co-development between private sector, citizens, and public agencies.\n* Disparate groups of Developers from the government and private organizations don\u2019t have a unified open-source platform where they can share APIs and data easily.\n* Government data is locked in on-premises systems with no easy public access.\n\n\n\n\n\n\n\n Solution \n\nAn open-government transformation must be built on a foundation that provides performance, resilience, business continuity, and security. As innovation and co-development move ahead, agencies and citizens depend on software, services, and infrastructure companies to \u201cprotect and serve.\u201d\n\nTo bust bureaucracy and transform government\u2019s relationship with its constituency, they turned to open standards to build a platform for co-creation.\n\n\n\n* OPEN DATA \u2013 data storage where citizens, government agencies, and businesses access, share, and enhance data freely\n* OPEN APIs \u2013 a development platform where APIs are contributed by and reused with all community partners\n* OPEN INNOVATION \u2013 a set of cloud services that allow developers to use plug-in innovation instead of manually coding it\n\n\n\nTo start, the government uses IBM Cloud Object Storage to store its public data in the cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_gov"},{"document_id":"ibmcld_10166-12374-14395","score":20.717540741,"text":"\n* Deploy the manifest and shipment apps to container that run in Red Hat OpenShift on IBM Cloud.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Use IBM Secure Gateway to maintain secure connections to existing on-premises databases.\n\n\n\n\n\n\n\n Step 2: Ensure global availability \n\n\n\n* After Developers deploy the apps in their Dev and Test clusters, they use the IBM Cloud\u00ae Continuous Delivery toolchains and Helm to deploy country-specific apps into clusters across the globe.\n* Workloads and data can then meet regional regulations.\n* Built-in HA tools in Red Hat OpenShift on IBM Cloud balance the workload within each geographic region, including self-healing and load balancing.\n\n\n\n\n\n\n\n Step 3: Data sharing \n\n\n\n* IBM Cloudant is a modern NoSQL database suitable a range of data-driven use cases from key-value to complex document-oriented data storage and query.\n* To minimize queries to the regional databases, IBM Cloudant is used to cache the user's session data across apps.\n* This configuration improves the front-end app usability and performance across apps on Kubernetes Service.\n* While worker apps in Red Hat OpenShift on IBM Cloud analyze on-premises data and store results in IBM Cloudant, IBM Cloud\u00ae Functions reacts to changes and automatically sanitizes data on the incoming feeds of data.\n* Similarly, notifications of shipments in one region can be triggered through data uploads so that all down-stream consumers can access new data.\n\n\n\n\n\n\n\n\n\n Results \n\n\n\n* Microservices greatly reduce time to delivery for patches, bug fixes, and new features. Initial development is fast, and updates are frequently 10 times per week.\n* Shipping customers and government officials have access to manifest data and can share customs data, while they comply with local regulations.\n* The shipping company benefits from improved logistics management in the supply chain: reduced costs and faster clearance times.\n* 99% are digital declarations, and 90% of imports processed without human intervention.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_gov"},{"document_id":"ibmcld_10214-7-1980","score":20.6945228577,"text":"\nFAQs \n\nReview frequently asked questions (FAQs) for using Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\n\n\n How does Red Hat OpenShift on IBM Cloud work? \n\nWith Red Hat OpenShift on IBM Cloud, you can create your own Red Hat OpenShift cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n\n\n\n\n\n Why should I use Red Hat OpenShift on IBM Cloud? \n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10169-8515-10516","score":20.5340633392,"text":"\n* Red Hat OpenShift on IBM Cloud provides scalable compute, so that the inventory and cross-sales API workloads can grow during high-volume periods of the year, such as the fall holidays.\n\n\n\n\n\n\n\n\n\n Traditional grocer increases customer traffic and sales with digital insights \n\nA Chief Marketing Officer (CMO) needs to increase customer traffic by 20% in stores by making the stores a differentiating asset. Large retail competitors and online retailers are stealing sales. At the same time, the CMO needs to reduce inventory without markdowns because holding inventory too long locks up millions in capital.\n\nRed Hat OpenShift on IBM Cloud provides easy spin-up of more compute, where Developers quickly add Cloud Analytics services for sales behavior insights and digital market adaptability.\n\nKey technologies:\n\n\n\n* [Horizontal scaling to accelerate development](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deployhighly_available_apps)\n* [Clusters that fit varied CPU, RAM, storage needs](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes)\n* [Insights to market trends with Watson Discovery](https:\/\/www.ibm.com\/products\/watson-discovery)\n* [DevOps native tools, including open toolchains in IBM Cloud\u00ae Continuous Delivery](https:\/\/www.ibm.com\/cloud\/architecture\/toolchains\/)\n* [Inventory management with IBM\u00ae Event Streams for IBM Cloud\u00ae](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-aboutabout)\n\n\n\n\n\n Context \n\nTraditional grocer increases customer traffic and sales with digital insights.\n\n\n\n* Competitive pressures from online retailers and large retail stores disrupted traditional grocery retail models. Sales are declining, evidenced by low foot traffic in physical stores.\n* Their loyalty program needs a boost in the arm with a modern take on the printed coupons at check out. So Developers must constantly evolve the related apps, but traditional tools slow their ability to deploy updates and features frequently.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_retail"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14497-7-1724","score":22.0332927704,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_10154-15474-17414","score":21.6194076538,"text":"\nRed Hat OpenShift on IBM Cloud clusters come with all the same configurable project and build components as OCP clusters. You can also choose to integrate your cluster with IBM Cloud services like [Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cicd). \n Cluster health You can also set up logging, monitoring, and metering tools by installing and configuring various operators. These solutions are cluster-specific and not highly available unless you back them up. Your clusters feature one-click integrations with IBM Log Analysis and IBM Cloud Monitoring for enterprise-grade, persistent monitoring and logging solutions across clusters. You can also install the logging and monitoring operators as with standard OCP, but you might have to adjust the configuration settings. For more information, see [Logging and monitoring cluster health](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health). \n Migrating clusters You can use the cluster migrator operator to migrate clusters from one major version to another. Migration requires separate clusters; you can't update a cluster from one major version to another. Various open source tools might be used, but are not officially supported. As with standard OpenShift Container Platform, you can't update a cluster from one major version to another. If you use a third-party open source tool such as the [cluster migrator operator](https:\/\/github.com\/migtools\/mig-operator), the tool is not supported by IBM and might have limitations such as the migration UI being unavailable. \n Container-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10407-1492-3206","score":21.5615272522,"text":"\nContainer-native virtualization The Red Hat OpenShift [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) to run VM workloads alongside container workloads is not supported by IBM. If you choose to install the add-on yourself, you must use bare metal machines, not virtual machines. You are responsible for resolving any issues and impact to your workloads from using container-native virtualization. \n Calico network plug-in Changing the Calico plug-in, components, or default Calico settings is not supported. For example, don't deploy a new Calico plug-in version, or modify the daemon sets or deployments for the Calico components, default IPPool resources, or Calico nodes. Instead, you can follow the documentation to [create a Calico NetworkPolicy or GlobalNetworkPolicy](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-network_policies), to [change the Calico MTU](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelcalico-mtu), or to [disable the port map plug-in for the Calico CNI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelcalico-portmap). \n Cluster quota You can't exceed 100 clusters per region and per [infrastructure provider](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers). If you need more of the resource, [contact IBM Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar). In the support case, include the new quota limit for the region and infrastructure provider that you want. \n IAM access groups You can't scope IBM Cloud IAM service access roles to an IAM access group because the roles are not synced to the RBAC roles within the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitations"},{"document_id":"ibmcld_14682-7-2113","score":21.45936203,"text":"\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"},{"document_id":"ibmcld_11282-0-1290","score":20.8103122711,"text":"\n\n\n\n\n\n\n  Cloud native development and application modernization by using Red Hat OpenShift on Power Systems Virtual Server \n\nCloud-native applications are the applications that are born in the cloud, which means that the applications use microservice-based architecture, containers, and a corresponding container orchestration platform. Red Hat\u00ae OpenShift\u00ae is enterprise Kubernetes platform enabling IT organizations to develop applications faster, deploy them reliably, and manage them efficiently.\n\nIn addition to developing new cloud-native applications, IT organizations are modernizing older, monolithic core business applications to support the faster delivery of new function to the business.\n\nFor information on application modernization on Power Systems, see [Field Guide to Application Modernization on IBM Power Systems](https:\/\/www.ibm.com\/downloads\/cas\/D9POQ3YR).\n\nFor information on deploying Red Hat OpenShift on Power Systems Virtual Server and tutorials to explore the platform, see [Deploying Red Hat OpenShift Container Platform 4.x on IBM Power Systems Virtual Servers](https:\/\/developer.ibm.com\/series\/deploy-ocp-cloud-paks-power-virtual-server\/?mhsrc=ibmsearch_a&mhq=%20Deploying%20Red%20Hat%20OpenShift%20Container%20Platform%20on%20Power%20Virtual%20Servers).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-app-modernization-using-RedHat-openshift"},{"document_id":"ibmcld_14492-7-1792","score":20.7300720215,"text":"\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_10531-7-2246","score":20.6005687714,"text":"\nRed Hat OpenShift on IBM Cloud partners \n\nTo provide you with all the capabilities that you need to run production workloads in the cloud, Red Hat OpenShift on IBM Cloud partners with other third-party service providers to enhance your cluster with logging, monitoring, and storage tools.\n\nReview the list of partners and the benefits of each solution that they provide. To find other proprietary IBM Cloud and third-party open source services that you can use in your cluster, see [Understanding IBM Cloud and 3rd party integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations).\n\n\n\n Portworx \n\n[Portworx](https:\/\/portworx.com\/products\/portworx-enterprise\/\/) is a highly available software-defined storage solution that you can use to manage local persistent storage for your containerized databases and other stateful apps, or to share data between pods across multiple zones.\n\nAn software defined storage (SDS), such as Portworx, solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n Benefits \n\nReview the following table to find a list of key benefits that you can get by using Portworx.\n\n\n\nBenefits of using Portworx\n\n Benefit Description \n\n Cloud native storage and data management for stateful apps Portworx aggregates available local storage that is attached to your worker nodes and that can vary in size or type, and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using Kubernetes persistent volume claims (PVC), you can add local persistent storage to your apps to store your data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners"},{"document_id":"ibmcld_10495-9135-10569","score":20.5056018829,"text":"\n(https:\/\/cognitiveclass.ai\/courses\/docker-essentials)\n\n\n\n\n\n What is Red Hat OpenShift? \n\nRed Hat OpenShift is a Kubernetes container platform that provides a trusted environment to run enterprise workloads. It extends the Kubernetes platform with built-in software to enhance app lifecycle development, operations, and security. With Red Hat OpenShift, you can consistently deploy your workloads across hybrid cloud providers and environments. For more information about the differences between the community Kubernetes and Red Hat OpenShift cluster offerings, see the [comparison table](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\n\n\n\n\n What compute host infrastructure does the service offer? \n\nYou can create clusters on Classic or IBM Cloud\u00ae Virtual Private Cloud infrastructure. You can also bring your own hosts by using Satellite.\n\nFor more information, see [Supported infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers).\n\n\n\n\n\n Related resources \n\nReview how you can learn about Kubernetes concepts and the terminology.\n\n\n\n* Familiarize yourself with the product by completing the [Creating clusters tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Learn how Kubernetes and Red Hat OpenShift on IBM Cloud work together by completing this [course](https:\/\/cognitiveclass.ai\/courses\/kubernetes-course).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview"},{"document_id":"ibmcld_10154-17039-18368","score":20.4401130676,"text":"\nContainer-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https:\/\/www.redhat.com\/en\/topics\/microservices\/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https:\/\/docs.openshift.com\/container-platform\/4.11\/service_mesh\/v1x\/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https:\/\/gist.githubusercontent.com\/kitch\/39c504a2ed9e381c2aadea436d5b52e4\/raw\/d8efa69f41d41425b16bb363a881a98d40d3708c\/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_11950-7-2002","score":20.3258953094,"text":"\nSetting up virtualization on a Satellite location \n\nYou can set up your Bare Metal Servers to use Red Hat OpenShift virtualization in your Satellite location. By using virtualization, you can provision Windows or other virtual machines on your Bare Metal Servers in a managed Red Hat OpenShift space.\n\nSupported host operating systems\n: Red Hat CoreOS (RHCOS)\n\n\n\n Prerequisites \n\n\n\n* Create a RHCOS-enabled location. To check whether your location is RHCOS-enabled, see [Is my location enabled for Red Hat CoreOS?](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locationsverify-coreos-location). If your location is not enabled, [create a new one with RHCOS](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locations).\n* Attach hosts to your location and set up your [location control plane](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-control-plane).\n* Find and record your bare metal host name.\n* Find your bare metal server network information. Record the CIDR and gateway information for the public and private interfaces for your system.\n* If you want to use IBM Cloud Object Storage to store your ignition file, create or identify a bucket.\n* Create or identify a cluster within the Satellite location that runs a supported operating system; for example, this tutorial uses a Red Hat OpenShift cluster that is running 4.11.\n* If you want to use OpenShift Data Foundation as your storage solution, add 2 storage disks to each of your Bare Metal Servers when you provision them.\n\n\n\n\n\n\n\n Bare Metal Server requirements for Satellite \n\nTo set up virtualization, your Bare Metal Server must meet the following requirements.\n\n\n\n* Must support virtualization technology.\n\n\n\n* For Intel CPUs, support for virtualization is referred to as Intel VT or VT-x.\n* For AMD CPUs, support for virtualization is referred to as AMD Virtualization or AMD-V.\n\n\n\n* Must have a minimum of minimum of 8 cores and 32 GB RAM, plus any additional cores that you need for your vCPU overhead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-location"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11149-7-2279","score":21.6486644745,"text":"\nWhat is the IBM Cloud platform? \n\nThe IBM Cloud\u00ae platform combines platform as a service (PaaS) with infrastructure as a service (IaaS) to provide an integrated experience. The platform scales and supports both small development teams and organizations, and large enterprise businesses. Globally deployed across data centers around the world, the solution you build on IBM Cloud\u00ae spins up fast and performs reliably in a tested and supported environment you can trust!\n\nIBM Cloud provides solutions that enable higher levels of compliance, security, and management, with proven architecture patterns and methods for rapid delivery for running mission-critical workloads. Available in data centers worldwide, with multizone regions in North and South America, Europe, Asia, and Australia, you are enabled to deploy locally with global scalability.\n\nIBM Cloud offers the most open and secure public cloud for business with a next-generation hybrid cloud platform, advanced data and AI capabilities, and deep enterprise expertise across 20 industries. Solutions are available depending on your needs for working in the public cloud, on-premises, or a combination:\n\n\n\n* With public cloud, the resources are made available to you over the public internet. It is a multi-tenant environment, and resources like hardware and infrastructure are managed by IBM\u00ae.\n* A [hybrid cloud solution](https:\/\/www.ibm.com\/cloud\/hybrid) is a combination of public and private, giving you the flexibility to move workloads between the two based on your business and technological needs. IBM uses Red Hat OpenShift on IBM Cloud, the market-leading hybrid cloud container platform for hybrid solutions that enables you to build once and deploy anywhere. With IBM Cloud Satellite, you can create a hybrid environment that brings the scalability and on-demand flexibility of public cloud services to the applications and data that runs in your secure private cloud.\n* Support for [multicloud](https:\/\/www.ibm.com\/cloud\/learn\/multicloud) and hybrid multicloud solutions is also available, which makes it easy for you to work with different vendors. [IBM Cloud Paks](https:\/\/www.ibm.com\/cloud\/paks) are software products for hybrid clouds that enable you to develop apps once and deploy them anywhere.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatis-platform"},{"document_id":"ibmcld_11149-6741-9103","score":21.3986339569,"text":"\nDiscover all that IBM Cloud has to offer. From services, software, and\n\ndeployable architecturesranging from containers, compute, security, data, AI, and more, find what you need to transform your business.\n\nThe available services include options for compute, storage, networking, end-to-end developer solutions for app development, testing and deployment, security management services, traditional and open source databases, and cloud-native services. The lifecycle and operations of services are the responsibility of IBM.\n\nYou can also find a number of software products, including [Cloud Paks](https:\/\/www.youtube.com\/watch?v=DzFhhSR8SSs), Terraform-based templates, Helm charts, and Operators. The preconfigured software solutions help you build faster. And, with a simplified installation process, you can get started quickly. You manage the deployment and configuration of the software on your own compute resources.\n\nIf you're looking for more robust solutions for your enterprise business goals, IBM Cloud offers deployable architectures that use cloud automation for deploying common architectural patterns that combine one or more cloud resources that are designed for easy deployment, scalability, and modularity.\n\nAnd, if you're looking for help in your journey to cloud, check out our professional services. Browse your options for scheduling a consultation with technical experts depending on your needs, such as cloud migration, creating business solutions with IBM Garage, or developing a container security solution that works for you.\n\nThe catalog supports command-line interfaces (CLIs) and a RESTful API for you to use to retrieve information about existing products.\n\n\n\n Searching the catalog for services \n\nAll products that are available in IBM Cloud are displayed by default in the catalog. You can filter the catalog by type to view a specific type of product, for example, only services, software, or deployable architectures. Enter keywords or set additional filters to further scope your view of the catalog. For example, if you want to deploy an analytics instance to Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you can select the Analytics category, and filter the results by selecting Red Hat OpenShift as the deployment target.\n\nSee the following table for the list of filters that you can use to search the catalog.\n\nCategory\n\nCompliance","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatis-platform"},{"document_id":"ibmcld_14566-7-2015","score":20.0041618347,"text":"\nOverview of VMware Solutions \n\nThe IBM Cloud\u00ae for VMware Solutions offerings help you extend your existing VMware\u00ae virtualized datacenter into the IBM Cloud, or to house cloud native applications.\n\nThe solution supports use cases, such as capacity expansion into the cloud (and contraction when not needed), migration to the cloud, disaster recovery to the cloud, and backup into the cloud. With the solution, you can create a dedicated cloud environment for development, testing, training, lab, or production.\n\nReview this information for the design of the IBM Cloud for VMware Solutions vCenter Server, whose target workloads require high levels of availability and scalability.\n\nThis design serves as a baseline architecture that provides the foundation for other internal or vendor-specific components to be added for specific use cases.\n\nZoom\n\n![Overview of VMware on IBM Cloud](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/vcsv4radiagrams-ra-variationsonatheme.svg)\n\nFigure 1. Overview of VMware on IBM Cloud\n\n\n\n Key benefits of VMware Solutions \n\nVMware vCenter Server\u00ae provides the fundamental building blocks, which include VMware vSphere\u00ae, vCenter Server, VMware NSX\u00ae, and shared storage options, such as vSAN\u2122. These components are needed to flexibly design a VMware software-defined data center solution that best fits your workloads.\n\nBy applying advanced automation and single-tenant bare metal infrastructure, you can quickly deploy the entire VMware environment to the IBM Cloud in hours. Then, you can access and manage the IBM-hosted environment through the native VMware clients, command-line interface (CLI), existing scripts, or other familiar vSphere API-compatible tools.\n\nPost deployment, you can add to (and remove from) VMware ESXi\u2122 servers for an instance, add and remove clusters, join additional vCenter Server instances to an existing instance, and add products and services by using the VMware Solutions console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-solution_overview"},{"document_id":"ibmcld_02400-28985-30276","score":19.8943462372,"text":"\nWith IBM Cloud for VMware Solutions, you can quickly and seamlessly integrate or migrate your on-premises VMware workloads to the IBM Cloud by using the scalable, secure, and high-performance IBM Cloud infrastructure and the industry-leading VMware hybrid virtualization technology. You can easily deploy your VMware virtual environments and manage the infrastructure resources on IBM Cloud. At the same time, you can still use your familiar native VMware product console to manage the VMware workloads. [Learn more](https:\/\/www.ibm.com\/cloud\/vmware).\n\nThe following table lists VMware solution services that send auditing events:\n\n\n\nTable 15. List of VMware solution services\n\n Service CRN service name Activity Tracker hosted event search offering Events \n\n [IBM Cloud for VMware Solutions](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_vcenterserveroverview) vmware-solutions ![Checkmark](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/\/images\/checkmark-icon.svg) [Global events](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-at-eventsat-events) \n [IBM Cloud\u00ae for VMware\u00ae Solutions Shared](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_overview) vmware-solutions !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-cloud_services"},{"document_id":"ibmcld_11602-16066-18031","score":19.8483314514,"text":"\n* IBM Cloud for VMware Solutions Dedicated, fully automated VMware SDDC setup and configuration\n\n\n\n* includes optional BYOL and access to advanced VMware capabilities, such as VMware HCX for seamless bidirectional network extension and connection to existing VMware clusters on-premises\n\n\n\n\n\nFor more information about IBM Cloud for VMware on Classic Infrastructure, see [IBM Cloud for VMware](https:\/\/www.ibm.com\/cloud\/vmware). Additional information is available on:\n\n\n\n* [IBM Cloud Intel Bare Metal and VMware vSphere (ESXi OS)](https:\/\/cloud.ibm.com\/docs\/vmware?topic=vmware-about-vmware) for the manual VMware setup and configuration\n* [IBM Cloud for VMware Solutions Dedicated](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-inst_comp_chart) for fully automated VMware SDDC setup and configuration\n\n\n\n\n\n\n\n Compliance \n\nIBM treats your data with the same safeguards as our own, the security is built to IBM\u2019s rigorous standards and certified for compliance.\n\nIBM Cloud is designed for organizations who are building a cloud environment, which is security-rich, open, hybrid Cloud (i.e., on-premises data center workloads) and multi-cloud. Deployments to IBM Cloud include many secure and regulated workloads, by using our extensive IBM Cloud compliance programs with clear delineation of roles and responsibilities.\n\n[IBM Cloud compliance programs](https:\/\/www.ibm.com\/cloud\/compliance) provide compliance and trust certifications, which reaffirm IBM's commitment to protection of customer data and applications. These compliance programs are for regulations, standards, and frameworks across Global, Government, Industry, and Regional.\n\nMore supplementary information to the IBM Cloud compliance programs is available on [IBM Cloud service offering descriptions and terms](https:\/\/www-03.ibm.com\/software\/sla\/sladb.nsf\/sla\/bm?OpenDocument) which contain links to individual Data Processing and Protection data sheets for IBM Cloud offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-iaas-offerings"},{"document_id":"ibmcld_14682-7-2113","score":19.7315063477,"text":"\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"},{"document_id":"ibmcld_13114-7-2018","score":19.6713047028,"text":"\nGetting started with solution tutorials \n\nSolution tutorials provide step-by-step instructions on how to use IBM Cloud to implement common patterns based on best practices and proven technologies.\n\nBefore going through the tutorials collection, this guide will help you set up your development environment to successfully follow the instructions of the guides found in this collection.\n\n\n\n Objectives \n\nInstall must-have tools to be productive with IBM Cloud:\n\n\n\n* IBM Cloud CLI - the command line interface to interact with IBM Cloud API.\n* Docker - to deliver and run software in packages called containers.\n* kubectl - a command line interface for running commands against Kubernetes clusters.\n* oc - manages OpenShift applications, and provides tools to interact with each component of your system.\n* Helm 3 - helps you manage Kubernetes applications \u2014 Helm Charts help you define, install, and upgrade even the most complex Kubernetes application.\n* Terraform - automates your resource provisioning.\n* jq - a lightweight and flexible command-line JSON processor.\n* Git - a free and open source distributed version control system.\n\n\n\nTo avoid the installation of these tools, you can also use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console.\n\n\n\n\n\n Microsoft Windows \n\nThe following sections assume you are running Microsoft Windows 10 64-bit under a user with Administrator privileges. Once you're done with the specific sections, proceed to the configuration [common to all operating systems](https:\/\/cloud.ibm.com\/docs\/solution-tutorialsgetting-started-common).\n\n\n\n IBM Cloud CLI \n\n\n\n1. Download and install the IBM Cloud CLI from [https:\/\/github.com\/IBM-Cloud\/ibm-cloud-cli-release\/releases\/latest](https:\/\/github.com\/IBM-Cloud\/ibm-cloud-cli-release\/releases\/latest).\n2. Verify the installation with:\n\nibmcloud version\n\nYou may need to restart your machine after the installation.\n\n\n\n\n\n\n\n Docker \n\n\n\n1. Docker Desktop on Windows is one option to run container images on Windows.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials"},{"document_id":"ibmcld_11143-7-2028","score":19.4894523621,"text":"\nNavigating the IBM Cloud console \n\nThe [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com) is the user interface that you use to manage all your IBM Cloud resources. You can create a free account, log in, access documentation, access the catalog, view pricing information, get support, or check the status of IBM Cloud components. After you log in, the menu bar contains a Navigation Menu icon ![Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/adcecdbe4e86955f88aac7f3c1e7ec3ff44992ef\/icons\/icon_hamburger.svg) and more links.\n\n\n\n Watch a tour \n\n\n\n* Video transcript\n\nWelcome to IBM Cloud, your open, secure, and enterprise-ready cloud platform with over 350 unique products for you to start building the solutions that you need today! Just log in, and you're ready to start building in the cloud.\n\nFrom the global navigation, you can explore how to get started with key technologies in IBM Cloud. Choose from technologies including serverless computing with Functions [Click Menu icon > Functions], container-based deployments on Kubernetes [Click Kubernetes to expand the options] or Red Hat OpenShift [Click OpenShift to expand the options], and VPC infrastructure [Click VPC Infrastructure to expand the options]. Developers can start with API management tools, app development starter kits, DevOps toolchains, and more to expedite and automate your app development.\n\nYou can get started creating resources through any of these guided journeys [Click Kubernetes > Clusters].\n\nOr, if you want to explore everything that IBM Cloud has to offer, go to the catalog to browse over 350 unique products [Click Catalog menu item]. Choose from our broad portfolio of managed services [Click Services], explore software products to take advantage of simplified installation [Click Software], or consult with IBM Cloud experts [Click Consulting]. If you're just here to try it out, filter the catalog by products that offer Lite plans, which are free to use [Click Services, and select the Lite pricing plan option].","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-ui"},{"document_id":"ibmcld_14576-7-2053","score":19.3774032593,"text":"\nAttached storage infrastructure design \n\nIBM Cloud\u00ae for VMware Solutions provides VMware\u00ae technology that is deployed in an automated way within IBM Cloud data centers across the globe. Within the WMware Solutions portfolio, the VMware vCenter Server\u00ae offering consists of up to 10 clusters. Each cluster contains up to 59 vSphere hosts, a single Platform Services Controller (PSC), and a vCenter Server Appliance capable of managing up to 400 hosts and 4,000 virtual machines.\n\nThe architecture that is presented here complements the vCenter Server solution by adding attached storage as a shared storage device for the environment. The attached storage device is located within the same IBM Cloud data center as the vCenter Server deployment. The storage device consists of a single Network File System (NFS) share or multiple NFS exports from the IBM Cloud.\n\nThe following graphic provides the overall architecture of the attached storage on vCenter Server deployment.\n\nZoom\n\n![Attached storage architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/vcsv4radiagrams-ra-nfs-shares.svg)\n\nFigure 1. High-level architecture of attached storage on IBM Cloud\n\n\n\n Physical infrastructure design \n\nThe physical infrastructure consists of three main components: physical compute, physical storage, and physical network. The physical infrastructure includes the IBM Cloud services network and the physical storage that is used by the infrastructure.\n\n\n\n\n\n Physical network design \n\nPhysical networking is handled by IBM Cloud. The following section describes the physical network that is provided by the IBM Cloud as it relates to attached storage.\n\n\n\n IBM Cloud network overview \n\nThe physical network of IBM Cloud is separated into three distinct networks: Public, Private, and Management. For more information about the public, private, and management networks, see [Overview of VMware Solutions](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-solution_overview).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-storage-infra-design"},{"document_id":"ibmcld_05009-7-2283","score":19.2360267639,"text":"\nUsing IBM Cloud Object Storage File Access \n\nIBM Cloud Object Storage File Access is a software-defined solution providing an SMB and NFS protocol interface for applications to store and retrieve infrequently used files on IBM Cloud Object Storage. This solution is an excellent choice for archiving, retention, and active archiving use cases as it also provides a built-in capability to discover and migrate files form existing file systems to IBM Cloud Object Storage.\n\nIT administrators can use Cloud Object Storage File Access to discover and migrate cold and infrequently used files from multiple enterprise NAS, Windows, or Linux file servers to Cloud Object Storage. This enables administrators to free up storage space on their filer systems or completely eliminate file infrastructure that is used solely for infrequently used file data, such as backup and active archiving workloads and file repositories.\n\nMultiple enterprise applications can access one or more unified file systems on Cloud Object Storage through SMB and NFS protocol interfaces provided by Cloud Object Storage File Access without any rewrite. It is a highly secure and available solution that is easy to install, use, and manage. It can be integrated with Active Directory to provide authentication and access control to file data stored on Cloud Object Storage.\n\nIBM Cloud Object Storage File Access runs as a pair of active-passive gateway virtual appliances (VMware, Hyper-V, or KVM). Configuration and maintenance operations are performed using a browser pointing to a portal that also runs in another pair of active-active virtual appliances (VMware, Hyper-V, or KVM).\n\n\n\n Requirements \n\n\n\n Hardware requirements \n\nRecommended minimum server hardware configuration for the VMware ESXi, Microsoft Hyper-V, or Red Hat\u00ae Enterprise Linux hypervisor that will run the IBM Cloud Object Storage File Access Gateway VM:\n\n\n\n* CPU x64 (4+ cores)\n* RAM 8 GB\n* Cache disk Up to 8 TB, SSD or NVMe preferred (2 TB minimum)\n* Network 10 Gigabit\n* Network switch (At least 2 for redundancy)\n\n\n\nRecommended minimum server hardware configuration for the VMware ESXi or Red Hat Enterprise Linux hypervisor that will run the IBM Cloud Object Storage File Access Portal VM:\n\n\n\n* CPU x64 (12+ cores)\n* RAM 40+ GB","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-fa-gateway"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.234639363,"ndcg_cut_10":0.234639363}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10154-7-1896","score":23.6156673431,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10170-12206-14575","score":22.3699893951,"text":"\nDevelopers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.\n\nRed Hat OpenShift on IBM Cloud provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services as needed. Using industry-standard containers technology apps can be quickly developed and shared across multiple Development, Test, and Production environments. This setup provides the immediate benefit of scalability. Using Kubernetes rich set of deployment and runtime objects, the HR team can monitor and manage upgrades to apps reliably. They can also replicate and scale the apps, by using defined rules and the automated Kubernetes orchestrator.\n\n\n\n Step 1: Containers, microservices, and the Garage Method \n\n\n\n* Apps are built in a set of cooperative microservices that run in Red Hat OpenShift on IBM Cloud. The architecture represents the functional areas of the app with the most quality problems.\n* Deploy apps to container in Red Hat OpenShift on IBM Cloud, continuously scanned with IBM Vulnerability Advisor.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Adopt the essential agile and iterative development practices within the IBM Garage Method to enable frequent releases of new functions, patches, and fixes without downtime.\n\n\n\n\n\n\n\n Step 2: Connections to existing benefits back-end \n\n\n\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure tunnel to on-premises systems that host the benefits systems.\n* Combination of on-premises data and Red Hat OpenShift on IBM Cloud lets them access sensitive data while they adhere to regulations.\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_10531-7-2246","score":21.6757354736,"text":"\nRed Hat OpenShift on IBM Cloud partners \n\nTo provide you with all the capabilities that you need to run production workloads in the cloud, Red Hat OpenShift on IBM Cloud partners with other third-party service providers to enhance your cluster with logging, monitoring, and storage tools.\n\nReview the list of partners and the benefits of each solution that they provide. To find other proprietary IBM Cloud and third-party open source services that you can use in your cluster, see [Understanding IBM Cloud and 3rd party integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations).\n\n\n\n Portworx \n\n[Portworx](https:\/\/portworx.com\/products\/portworx-enterprise\/\/) is a highly available software-defined storage solution that you can use to manage local persistent storage for your containerized databases and other stateful apps, or to share data between pods across multiple zones.\n\nAn software defined storage (SDS), such as Portworx, solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n Benefits \n\nReview the following table to find a list of key benefits that you can get by using Portworx.\n\n\n\nBenefits of using Portworx\n\n Benefit Description \n\n Cloud native storage and data management for stateful apps Portworx aggregates available local storage that is attached to your worker nodes and that can vary in size or type, and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using Kubernetes persistent volume claims (PVC), you can add local persistent storage to your apps to store your data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners"},{"document_id":"ibmcld_10214-1438-3413","score":21.3594322205,"text":"\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n\n\n\n\n\n What container platforms are available for my cluster? \n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform. If you want to use multiple container platforms, create a separate cluster for each.\n\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https:\/\/kubernetes.io\/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10169-8515-10516","score":20.5946617126,"text":"\n* Red Hat OpenShift on IBM Cloud provides scalable compute, so that the inventory and cross-sales API workloads can grow during high-volume periods of the year, such as the fall holidays.\n\n\n\n\n\n\n\n\n\n Traditional grocer increases customer traffic and sales with digital insights \n\nA Chief Marketing Officer (CMO) needs to increase customer traffic by 20% in stores by making the stores a differentiating asset. Large retail competitors and online retailers are stealing sales. At the same time, the CMO needs to reduce inventory without markdowns because holding inventory too long locks up millions in capital.\n\nRed Hat OpenShift on IBM Cloud provides easy spin-up of more compute, where Developers quickly add Cloud Analytics services for sales behavior insights and digital market adaptability.\n\nKey technologies:\n\n\n\n* [Horizontal scaling to accelerate development](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deployhighly_available_apps)\n* [Clusters that fit varied CPU, RAM, storage needs](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes)\n* [Insights to market trends with Watson Discovery](https:\/\/www.ibm.com\/products\/watson-discovery)\n* [DevOps native tools, including open toolchains in IBM Cloud\u00ae Continuous Delivery](https:\/\/www.ibm.com\/cloud\/architecture\/toolchains\/)\n* [Inventory management with IBM\u00ae Event Streams for IBM Cloud\u00ae](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-aboutabout)\n\n\n\n\n\n Context \n\nTraditional grocer increases customer traffic and sales with digital insights.\n\n\n\n* Competitive pressures from online retailers and large retail stores disrupted traditional grocery retail models. Sales are declining, evidenced by low foot traffic in physical stores.\n* Their loyalty program needs a boost in the arm with a modern take on the printed coupons at check out. So Developers must constantly evolve the related apps, but traditional tools slow their ability to deploy updates and features frequently.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_retail"},{"document_id":"ibmcld_10170-10609-12793","score":20.5923442841,"text":"\nThus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* Red Hat OpenShift on IBM Cloud\n* IBM Cloud\u00ae Continuous Delivery\n* IBM Logging and Monitoring\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae\n* IBM Cloud App ID\n\n\n\nAccelerated development is a key win for the HR Exec. The team gets started by containerizing their apps and putting them in the cloud. With the use of modern containers, Developers can experiment easily with Node.js SDK and push changes to Development and Test systems, which are scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. No longer were updates to the HR site languishing in slow, error-prone build processes. They can deliver incremental updates to their site, daily or even more frequently. Moreover, logging and monitoring for the HR site is rapidly integrated, especially for how the site pulls personalized data from back-end benefit systems. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems. Developers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_10165-7426-9964","score":20.377286911,"text":"\nA Development Exec has Developers that use on-premises application tools that slow down prototyping while they wait for hardware procurement.\n\nRed Hat OpenShift on IBM Cloud provides spin-up of compute by using open-source standard technology. After the company moved to Red Hat OpenShift on IBM Cloud, Developers have access to DevOps friendly tools, such as portable and easily shared containers.\n\nThen, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains. Their application development tools get a new face when they add on AI cloud services to apps with a click.\n\n\n\n Context \n\nStreamlining developer productivity and deploying AI tools to partners 4 times faster**\n\n\n\n* Disruption is rampant in the payment industry that also has dramatic growth both in the consumer and business-to-business segments. But updates to payment tools were slow.\n* Cognitive features are needed to target fraudulent transactions in new and faster ways.\n* With the growing numbers of partners and their transactions, the tool traffic increases, but their infrastructure budget needs to decrease, by maximizing efficiency of the resources.\n* Their technical debt is growing, not shrinking from an inability to release quality software to keep up with market demands.\n* Capital expense budgets are under tight control, and IT feels they don't have the budget or staff to create the testing and staging landscapes with their in-house systems.\n* Security is increasingly a primary concern, and this concern only adds to the delivery burden that all cause even more delays.\n\n\n\n\n\n\n\n Solution \n\nThe Development Exec is faced with many challenges in the dynamic payment industry. Regulations, consumer behaviors, fraud, competitors, and market infrastructures are all rapidly evolving. Fast-paced development is essential to being part of the future payment world.\n\nTheir business model is to provide payment tools to business partners, so they can help these financial institutions and other organizations deliver security-rich digital payment experiences.\n\nThey need a solution that helps the Developers and their business partners:\n\n\n\n* FRONT-END TO PAYMENT TOOLS: fee systems, payment tracking including cross-border, regulatory compliance, biometrics, remittance, and more\n* REGULATION-SPECIFIC FEATURES: each country has unique regulations so that the overall toolset might look similar but show country-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate roll-out of features and bug fixes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_finance"},{"document_id":"ibmcld_10165-7-2413","score":20.3163223267,"text":"\nFinancial services use cases for IBM Cloud \n\nThese use cases highlight how workloads on Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae can take advantage of high availability, high-performance compute, easy spin-up of clusters for faster development, and AI from IBM Watson\u00ae.\n\n\n\n Mortgage company trims costs and accelerates regulatory compliance \n\nA Risk Management VP for a residential mortgage company processes 70 million records a day, but the on-premises system was slow and also inaccurate. IT expenses soared because hardware quickly went out of date and wasn't utilized fully. While they waited for hardware provisioning, their regulatory compliance slowed.\n\n\n\n Context \n\nTo improve risk analysis, the company looked to Red Hat OpenShift on IBM Cloud and IBM Cloud Analytic services to reduce costs, increase worldwide availability, and ultimately accelerate regulatory compliance. With Red Hat OpenShift on IBM Cloud in multiple regions, their analysis apps can be containerized and deployed across the globe, improving availability and addressing local regulations. Those deployments are accelerated with familiar open source tools, already part of Red Hat OpenShift on IBM Cloud.\n\nThey started by containerizing the analysis apps and putting them in the cloud. In a flash, their hardware headaches went away. They were able to easily design Kubernetes clusters to fit their high-performance CPU, RAM, storage, and security needs. And when their analysis apps change, they can add or shrink compute without huge hardware investments. With the Red Hat OpenShift on IBM Cloud horizontal scaling, their apps scale with the growing number of records, resulting in faster regulatory reports. Red Hat OpenShift on IBM Cloud provides elastic compute resources around the world that are secure and capable.\n\nNow those apps receive high-volume data from a data warehouse on IBM Cloudant. Cloud-based storage in IBM Cloudant ensures higher availability than when it was locked in an on-premises system. Since availability is essential, the apps are deployed across global data centers: for DR and for latency too.\n\nThey also accelerated their risk analysis and compliance. Their predictive and risk analytics functions, such as Monte Carlo calculations, are now constantly updated through iterative agile deployments. Container orchestration is handled by a managed Kubernetes so that operations costs are reduced too.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_finance"},{"document_id":"ibmcld_10214-7-1980","score":20.1127204895,"text":"\nFAQs \n\nReview frequently asked questions (FAQs) for using Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\n\n\n How does Red Hat OpenShift on IBM Cloud work? \n\nWith Red Hat OpenShift on IBM Cloud, you can create your own Red Hat OpenShift cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n\n\n\n\n\n Why should I use Red Hat OpenShift on IBM Cloud? \n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10166-7-2382","score":20.064956665,"text":"\nGovernment use cases for IBM Cloud \n\nThese use cases highlight how workloads on Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae benefit from the public cloud. These workloads are isolated in global regions for data sovereignty, use Watson machine learning instead of net-new code, and connect to on-premises databases.\n\n\n\n Regional government improves collaboration and velocity with community Developers who combine public-private data \n\nAn Open-Government Data Program Executive needs to share public data with the community and private sector, but the data is locked in an on-premises monolithic system.\n\nWith Red Hat OpenShift on IBM Cloud, the Exec delivers the value of combined public-private data. Likewise, the service provides the public cloud platform to refactor and expose microservices from monolithic on-premises apps. Also, the public cloud allows government and the public partnerships to use external cloud services and collaboration-friendly open-source tools.\n\n\n\n Context \n\n\n\n* An \u201copen government\u201d model is the future, but this regional government agency can't make the leap with their on-premises systems.\n* They want to support innovation and foster co-development between private sector, citizens, and public agencies.\n* Disparate groups of Developers from the government and private organizations don\u2019t have a unified open-source platform where they can share APIs and data easily.\n* Government data is locked in on-premises systems with no easy public access.\n\n\n\n\n\n\n\n Solution \n\nAn open-government transformation must be built on a foundation that provides performance, resilience, business continuity, and security. As innovation and co-development move ahead, agencies and citizens depend on software, services, and infrastructure companies to \u201cprotect and serve.\u201d\n\nTo bust bureaucracy and transform government\u2019s relationship with its constituency, they turned to open standards to build a platform for co-creation.\n\n\n\n* OPEN DATA \u2013 data storage where citizens, government agencies, and businesses access, share, and enhance data freely\n* OPEN APIs \u2013 a development platform where APIs are contributed by and reused with all community partners\n* OPEN INNOVATION \u2013 a set of cloud services that allow developers to use plug-in innovation instead of manually coding it\n\n\n\nTo start, the government uses IBM Cloud Object Storage to store its public data in the cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_gov"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6713860725,"ndcg_cut_10":0.6713860725}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05173-7408-9438","score":25.5262184143,"text":"\n2. Enter or select the Red Hat OpenShift on IBM Cloud project where you want to deploy IBM Cloud Pak for Data.\n\n\n\n\n\n\n\n Step 3. Configure your workspace \n\nSpecify how you will track and manage your installation:\n\n\n\n1. Enter or select a name for the installation.\n2. Consider changing the default resource group.\n3. Specify any tags that you want to use for the installation. Specify multiple tags as a comma-separated list.\n\n\n\n\n\n\n\n Step 4. Complete the preinstallation task \n\nA Red Hat OpenShift on IBM Cloud cluster administrator must complete this step. Specifically, the administrator must have an [access](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-users) policy in IBM Cloud Identity and Access Management that has an Operator role or higher.\n\n\n\n* If you are not an administrator, use the Share link to share the script with your cluster administrator.\n* If you are a cluster administrator, click Run script to run the preinstallation set up on your cluster.\n\n\n\nThe preinstallation script makes the following changes to your Red Hat OpenShift on IBM Cloud cluster:\n\n\n\n* Increases the size of the Docker registry to 200 GB. This change increases the cost of your Red Hat OpenShift on IBM Cloud cluster.\n* Creates the security context constraints that are required for IBM Cloud Pak\u00ae for Data.\n* Grants access to the security context constraints to the service accounts that are required for IBM Cloud Pak\u00ae for Data.\n\n\n\nConfirm that the script completes successfully before you proceed.\n\nIf the cluster administrator is not allowed to modify the storage, or the infrastructure account is not the same as the current account, a storage administrator can manually execute the script that is provided in [Complete the preinstallation section](https:\/\/cloud.ibm.com\/catalog\/content\/ibm-cp-datacore-6825cc5d-dbf8-4ba2-ad98-690e6f221701-global).\n\n\n\n\n\n Step 5. Set the deployment values \n\nChoose a storage class:\n\n\n\n* EnduranceFileStorage - This option uses the storage class ibmc-file-gold-gid to install Cloud Pak for Data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-data"},{"document_id":"ibmcld_05174-7319-9347","score":25.4923534393,"text":"\nSpecify where you want to install IBM Cloud Pak for Data:\n\n\n\n1. Select the Red Hat OpenShift on IBM Cloud cluster where you want to deploy IBM Cloud Pak for Data.\n2. Enter or select the Red Hat OpenShift on IBM Cloud project where you want to deploy IBM Cloud Pak for Data.\n\n\n\n\n\n\n\n Step 3. Configure your workspace \n\nSpecify how you will track and manage your installation:\n\n\n\n1. Enter or select a name for the installation.\n2. Consider changing the default resource group.\n3. Specify any tags that you want to use for the installation. Specify multiple tags as a comma-separated list.\n\n\n\n\n\n\n\n Step 4. Complete the preinstallation task \n\nA Red Hat OpenShift on IBM Cloud cluster administrator must complete this step. Specifically, the administrator must have an [access](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-users) policy in IBM Cloud Identity and Access Management that has an Operator role or higher.\n\n\n\n* If you are not an administrator, use the Share link to share the script with your cluster administrator.\n* If you are a cluster administrator, click Run script to run the preinstallation set up on your cluster.\n\n\n\nThe preinstallation script makes the following changes to your Red Hat OpenShift on IBM Cloud cluster:\n\n\n\n* Increases the size of the Docker registry to 200 GB. This change increases the cost of your Red Hat OpenShift on IBM Cloud cluster.\n* Creates the security context constraints that are required for IBM Cloud Pak\u00ae for Data.\n* Grants access to the security context constraints to the service accounts that are required for IBM Cloud Pak\u00ae for Data.\n\n\n\nConfirm that the script completes successfully before you proceed.\n\nIf the cluster administrator is not allowed to modify the storage, or the infrastructure account is not the same as the current account, a storage administrator can manually execute the script that is provided in [Complete the preinstallation section](https:\/\/cloud.ibm.com\/catalog\/content\/ibm-cp-datacore-6825cc5d-dbf8-4ba2-ad98-690e6f221701-global).\n\n\n\n\n\n Step 5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-data?topic=cloud-pak-data-getting-started"},{"document_id":"ibmcld_06392-9291-11081","score":24.7405166626,"text":"\nEach folder has its own simple Dockerfile file that is used by the script to create a container image, which is then uploaded to the IBM Container Registry.\n2. It creates a bunch of kubernetes secrets with all the credentials that are going to be needed to access the different IBM services (IBM Cloudant, Redis and Event Streams).\n3. It deploys the application code (and the secretes) to the Red Hat OpenShift on IBM Cloud cluster using the instructions contained in the deployment.yml script.\n\n\n\n\n\n\n\n The deployment.yml script \n\nThis script tells Openshift what to deploy to the machines in the Openshift cluster. In our case this is:\n\n\n\n1. Data producers (trucktrackerproducer).\n2. Data consumers (trucktrackerredisconsumer and trucktrackercloudantconsumer)\n3. Web application (trucktrackerweb)\n\n\n\nIn all cases, they pull an image from the container registry and get fed some environment variables with the credentials they require to access external services.\n\n\n\n\n\n The Truck Tracker system \n\nThe Truck Tracker system is a set of simple Node.js scripts that use four main packages:\n\n\n\n1. [@ibm-cloud\/cloudant](https:\/\/github.com\/IBM\/cloudant-node-sdk) to connect to IBM Cloudant and read\/write data.\n2. [Redis](https:\/\/www.npmjs.com\/package\/redis) to connect to the Redis instance and read\/write data.\n3. [kafkajs](https:\/\/www.npmjs.com\/package\/kafkajs) to connect to the Event Streams instance.\n4. [Express](https:\/\/expressjs.com\/) to enable a simple web server that allows interaction with the data.\n\n\n\nThere are five main files:\n\n\n\n1. server.js: This runs the web server and communicates with Redis. It is getting regular calls from the front end to the \/data route. It connects to Redis, downloads an object with the ID and position of every truck and returns that to the front end.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-truck-tracker-ibmcloud"},{"document_id":"ibmcld_13144-1354-3173","score":24.1514434814,"text":"\n3. Users access the frontend application.\n4. The IBM Cloudant database instance is provisioned through an IBM Cloud Operator Service.\n5. The backend application is connected to the database with an IBM Cloud Operator Binding.\n6. Log Analysis is provisioned and agent deployed.\n7. Monitoring is provisioned and agent deployed.\n8. An Administrator monitors the app with Log Analysis and Monitoring.\n\n\n\nThere are [scripts](https:\/\/github.com\/IBM-Cloud\/patient-health-frontend\/tree\/master\/scripts) that will perform some of the steps below. It is described in the [README.md](https:\/\/github.com\/IBM-Cloud\/patient-health-frontend). If you run into trouble and want to start over just execute the destroy.sh script and sequentially go through the scripts that correspond to the steps to recover.\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI,\n\n\n\n* IBM Cloud Kubernetes Service plugin (kubernetes-service),\n\n\n\n* oc to interact with OpenShift.\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools, you can use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console. Use oc version to ensure the version of the Red Hat OpenShift on IBM Cloud CLI matches your cluster version (4.12.x). If they do not match, install the matching version by following [these instructions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorialsgetting-started-cloud-shell).\n\n\n\n\n\n Step 1: Create a Red Hat OpenShift on IBM Cloud cluster \n\nWith Red Hat OpenShift on IBM Cloud, you have a fast and secure way to containerize and deploy enterprise workloads in clusters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-openshift-microservices"},{"document_id":"ibmcld_14684-7-1830","score":24.0124568939,"text":"\nIBM Cloud networking and infrastructure \n\n\n\n Physical structure \n\nThe physical infrastructure required to deploy a Red Hat\u00ae OpenShift\u00ae production instance onto a VMware\u00ae vCenter Server\u00ae cluster requires the following minimum specification.\n\n\n\nTable 1. vCenter Server specification for Red Hat OpenShift\n\n Item NFS deployment vSAN deployment \n\n Number of servers 3 4 \n CPU 28 Cores 2.2 GHz 28 Cores 2.2 GHz \n Memory (GB) 384 384 \n Storage 2,000 GB 2 IOPS\/GB Management <br>2,000 GB 4 IOPS\/GB Workload <br>4,000 GB 4 IOPS\/GB Min 960-GB SSD x2 \n\n\n\nIn addition to the Red Hat OpenShift hardware requirements, you must create persistent volumes in the Red Hat OpenShift environment to store images from the container register or customer workloads.\n\n\n\n\n\n Virtual structure \n\nZoom\n\n![Physical structure](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-networking41.svg)\n\nFigure 1. Physical structure\n\nWithin the vCenter Server instance, the Red Hat OpenShift instance is deployed with a dedicated NSX\u00ae Edge Services Gateway (ESG) and Distributed Logical Router (DLR). The Red Hat OpenShift installation is loaded into the VXLAN subnet that is defined in the previous components.\n\nThe ESG is configured with a source NAT rule (SNAT) to allow outbound traffic, which enables internet connectivity to download the Red Hat OpenShift prerequisites and to connect to GitHub and Red Hat\u00ae. Alternatively, you can use a web-proxy for internet connectivity. The ESG is also configured to provide access to DNS and NTP services within the IBM Cloud\u00ae environment.\n\nThe ESG is also configured to use the load balancer capability, thus reducing the need for HAProxy nodes. The load balancers are configured for the apps wildcard DNS URL and the API \/ API-INT DNS Records.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-sddc-infra"},{"document_id":"ibmcld_09790-7-1923","score":23.9242134094,"text":"\nMonitoring a Red Hat OpenShift cluster \n\nUse this tutorial to learn how to configure a Red Hat\u00ae OpenShift\u00ae cluster to forward metrics to the IBM Cloud\u00ae Monitoring service. You can monitor clusters in IBM Cloud, on-prem, and in other clouds.\n\nTo configure a cluster to forward metrics, you must install a monitoring agent onto each worker node in your Red Hat OpenShift cluster by using a [DaemonSet](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/daemonset\/). The monitoring agent uses an access key (token) to authenticate with the IBM Cloud Monitoring instance. The monitoring agent acts as a data collector. It automatically collects metrics such as worker node CPU and worker node memory usage, HTTP traffic into and out of your containers, and data about several infrastructure components. In addition, the agent can collect custom application metrics by using either a Prometheus-compatible scraper or a StatsD facade.\n\nZoom\n\n![Components overview on the IBM Cloud](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/infrastructure\/images\/openshift.png)\n\nComponents overview\n\nFor example, to configure your Red Hat OpenShift cluster to forward metrics to your IBM Cloud Monitoring instance, you can deploy the agent by using Helm or a script:\n\n\n\n* [Helm](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-agent-deploy-openshift-helm)\n* [Script](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-agent_openshift)\n\n\n\nThe Monitoring agent automatically collects the following types of system metrics per host:\n\n\n\n* System hosts metrics provide information about CPU, memory, and storage usage metrics, that you can use to analyze the performance and resource utilization of all your processes.\n* File and File System metrics provide information about files and file system that you can use to analyze file interactions that occur in your system.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-openshift_cluster"},{"document_id":"ibmcld_10568-22837-24687","score":23.9122867584,"text":"\nWith Red Hat OpenShift on IBM Cloud, you have [a mix of flavors](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes) that you can deploy: from bare metal for intensive workloads to virtual machines for rapid scaling. Use labels or namespaces to organize deployments to your machines. When you create a deployment, limit it so that your app's pod deploys only on machines with the best mix of resources. For example, you might want to limit a database application to a bare metal machine with a significant amount of local disk storage like the md1c.28x512.4x4tb.\n\n\n\n\n\n Set up multiple namespaces when you have multiple teams and projects that share the cluster \n\nNamespaces are kind of like a cluster within the cluster. They are a way to divide up cluster resources by using [resource quotas](https:\/\/kubernetes.io\/docs\/concepts\/policy\/resource-quotas\/) and [default limits](https:\/\/kubernetes.io\/docs\/tasks\/administer-cluster\/manage-resources\/memory-default-namespace\/). When you make new namespaces, be sure to set up proper [RBAC policies](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-usersrbac) to control access. For more information, see [Share a cluster with namespaces](https:\/\/kubernetes.io\/docs\/tasks\/administer-cluster\/namespaces\/) in the Kubernetes documentation.\n\nIf you have a small cluster, a couple dozen users, and resources that are similar (such as different versions of the same software), you probably don't need multiple namespaces. You can use labels instead.\n\n\n\n\n\n Set resource quotas so that users in your cluster must use resource requests and limits \n\nTo ensure that every team has the necessary resources to deploy services and run apps in the cluster, you must set up [resource quotas](https:\/\/kubernetes.io\/docs\/concepts\/policy\/resource-quotas\/) for every namespace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategy"},{"document_id":"ibmcld_08006-1379-2960","score":23.7711639404,"text":"\nEven though it is shown in the diagram as an option, it is not required to put Red Hat OpenShift on IBM Cloud in your management VPC.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud concepts \n\nRed Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift on IBM Cloud cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\nRed Hat OpenShift on IBM Cloud extends the Kubernetes platform with built-in software to enhance app lifecycle development, operations, and security. The master nodes are entirely IBM's responsibility, while there is shared responsibility for the worker nodes.\n\nFor IBM Cloud for Financial Services, you should provision Red Hat OpenShift on IBM Cloud in a VPC only and not in classic infrastructure.\n\nFor more information, see [Understanding Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview).\n\n\n\n\n\n Next steps \n\n\n\n* [Setup environment for deployment and configuration](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-deployment-setup-environment).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-openshift"},{"document_id":"ibmcld_06392-8136-9785","score":23.7069568634,"text":"\nGo into the root of the project and type the following:\n\n.\/build.sh\n\n\n\n\n\n Step 5: Watch your trucks truckin' \n\nThe end of the script will output a URL \u2014 something like https:\/\/ some.thing.eu-gb.appdomain.cloud.\n\nIf you visit the URL that has been generated, you should be able to see a map of the US and, after a few seconds, several markers on the map that represent your trucks:\n\nZoom\n\n![The Truck Tracker Wide View](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5561b38c6df9e8168523d143eaf64ab6acd7b600\/cloud-databases\/images\/trucktrackerwide.png)\n\nFigure 3. All-Truck View\n\nIf you zoom in on one of these markers you will see it moving along the road. As the fleet manager, you now know where all your trucks are.\n\nZoom\n\n![The Truck Tracker Zoom View](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5561b38c6df9e8168523d143eaf64ab6acd7b600\/cloud-databases\/images\/trucktrackerzoom.png)\n\nFigure 4. Single-Truck View\n\n\n\n\n\n\n\n What you just did \n\n\n\n The build.sh script \n\nThe build.sh script does a number of things:\n\n\n\n1. It builds a docker image for each of the services you need. The producer, consumers and web application are all in different folders. Each folder has its own simple Dockerfile file that is used by the script to create a container image, which is then uploaded to the IBM Container Registry.\n2. It creates a bunch of kubernetes secrets with all the credentials that are going to be needed to access the different IBM services (IBM Cloudant, Redis and Event Streams).\n3. It deploys the application code (and the secretes) to the Red Hat OpenShift on IBM Cloud cluster using the instructions contained in the deployment.yml script.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-truck-tracker-ibmcloud"},{"document_id":"ibmcld_11763-7-1950","score":23.6996688843,"text":"\nHost system requirements \n\nReview the following requirements that relate to the computing and system setup of host machines for IBM Cloud Satellite\u00ae.\n\nYou can add hosts from other cloud providers to your location. For more information, see [Cloud infrastructure providers](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-infrastructure-plan).\n\n\n\n* If you plan on deploying Red Hat OpenShift clusters, make sure the operating system that you want to use for your hosts is supported for your location type and cluster version. For more information, see [Red Hat OpenShift version information](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* Make sure that you use [official Red Hat certified hardware](https:\/\/catalog.redhat.com\/hardware).\n* If you cannot meet these host requirements, [contact IBM Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) and include the following information: the host system configuration that you want, why you want the system configuration, and how many hosts you intend to create.\n\n\n\nYou can verify your host setup with the satellite-host-check script. For more information, see [Checking your host setup](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-network-check).\n\n\n\n Computing characteristics \n\n\n\n* Hosts must run the latest Red Hat Enterprise Linux 7 or 8, or the latest Red Hat CoreOS on x86 architecture with the kernel that is distributed with those versions. Other operating systems, such as Windows; other mainframe systems, such as IBM Z or IBM Power; and other kernel versions are not supported.\n\n\n\n* For RHEL 7, the latest is 7.9.\n* For the latest RHEL 8 version information, see [Red Hat Enterprise Linux Release Dates](https:\/\/access.redhat.com\/articles\/3078RHEL8).\n* For the latest Red Hat CoreOS version information, see [Red Hat CoreOS mirrors](https:\/\/mirror.openshift.com\/pub\/openshift-v4\/x86_64\/dependencies\/rhcos\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-reqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07705-0-1395","score":11.2460746765,"text":"\n\n\n\n\n\n\n  CM-11 - User-installed Software \n\n\n\n  Control requirements \n\nThe organization:\n\nCM-11 (a)\n:   Establishes [Assignment: organization-defined policies] governing the installation of software by users;\n\nCM-11 (b)\n:   Enforces software installation policies through [Assignment: organization-defined methods]; and\n\nCM-11 (c)\n:   Monitors policy compliance at [IBM Assignment: continuously].\n\n\n\n\n\n  NIST supplemental guidance \n\nIf provided the necessary privileges, users have the ability to install software in organizational information systems. To maintain control over the types of software installed, organizations identify permitted and prohibited actions regarding software installation. Permitted software installations may include, for example, updates and security patches to existing software and downloading applications from organization-approved \u201capp stores\u201d Prohibited software installations may include, for example, software with unknown or suspect pedigrees or software that organizations consider potentially malicious. The policies organizations select governing user-installed software may be organization-developed or provided by some external entity. Policy enforcement methods include procedural methods (e.g., periodic examination of user accounts), automated methods (e.g., configuration settings implemented on organizational information systems), or both.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-cm-11"},{"document_id":"ibmcld_09656-4468-6281","score":10.6392307281,"text":"\nINDICATEPROGRESS=\"False\"\n\n; Specifies that Setup should install into WOW64. This command line argument is not supported on an IA64 or a 32-bit system.\n\nX86=\"False\"\n\n; Specify a default or named instance. MSSQLSERVER is the default instance for non-Express editions and SQLExpress for Express editions. This parameter is required when installing the SQL Server Database Engine (SQL), or Analysis Services (AS).\n\nINSTANCENAME=\"MSSQLSERVER\"\n\n; Specify the root installation directory for shared components. This directory remains unchanged after shared components are already installed.\n\nINSTALLSHAREDDIR=\"C:Program FilesMicrosoft SQL Server\"\n\n; Specify the root installation directory for the WOW64 shared components. This directory remains unchanged after WOW64 shared components are already installed.\n\nINSTALLSHAREDWOWDIR=\"C:Program Files (x86)Microsoft SQL Server\"\n\n; Specify the Instance ID for the SQL Server features you have specified. SQL Server directory structure, registry structure, and service names will incorporate the instance ID of the SQL Server instance.\n\nINSTANCEID=\"MSSQLSERVER\"\n\n; Account for SQL Server CEIP service: DomainUser or system account.\n\nSQLTELSVCACCT=\"NT ServiceSQLTELEMETRY\"\n\n; Startup type for the SQL Server CEIP service.\n\nSQLTELSVCSTARTUPTYPE=\"Automatic\"\n\n; Specify the installation directory.\n\nINSTANCEDIR=\"C:Program FilesMicrosoft SQL Server\"\n\n; Agent account name\n\nAGTSVCACCOUNT=\"sqlserversqlsvc\"\n\n; Auto-start service after installation.\n\nAGTSVCSTARTUPTYPE=\"Automatic\"\n\n; CM brick TCP communication port\n\nCOMMFABRICPORT=\"0\"\n\n; How matrix will use private networks\n\nCOMMFABRICNETWORKLEVEL=\"0\"\n\n; How inter brick communication will be protected\n\nCOMMFABRICENCRYPTION=\"0\"\n\n; TCP port used by the CM brick\n\nMATRIXCMBRICKCOMMPORT=\"0\"\n\n; Startup type for the SQL Server service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/microsoft?topic=microsoft-mssql-configfile"},{"document_id":"ibmcld_11624-23322-25007","score":10.3435583115,"text":"\n\/dev\/mapper\/datavg-sapmntlv\n165G 60M 157G 1% \/sapmnt\n\nIf you install an SAP NetWeaver-based SAP application on IBM Db2, you must create subdirectories under \/backup owned by the database admin user (db2SID) for full backups and archived log files. To automatically archive the log files, set LOGMETH1 in your Db2 on Cloud database. Refer to the [Db2 on Cloud documentation)](http:\/\/www.ibm.com\/support\/knowledgecenter\/SSEPGG_10.5.0\/com.ibm.db2.luw.admin.ha.doc\/doc\/c0051344.html) for details.\n\n\n\n\n\n\n\n Step 4: Installing your SAP landscape \n\n\n\n Prerequisite: Installing RPM packages \n\nAn SAP installation requires certain prerequisites for the packages that are installed on the OS and the OS daemons that are running. Refer to the latest [installation guides)](https:\/\/support.sap.com\/en\/my-support\/software-downloads.html). Click Access downloads under Installations & Upgrades (requires an [SAP S-user ID](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-necessary-credentials). Also, refer to the latest [support notes)](https:\/\/support.sap.com\/en\/my-support\/knowledge-base.html) (requires an SAP S-user ID) from SAP for an up-to-date list of these prerequisites.\n\nTwo more packages need to be installed:\n\n\n\n* compat-sap-c++: Generally achieves compatibility of the C++ runtime with the compilers that are used by SAP. Because Red Hat Enterprise Linux for SAP Business Application 7.X was selected as the OS for both the 32 GB application server and the 192 GB database server, you use compat-sap-c++-7.\n* uuidd: Maintains OS support for the creation of UUIDs.\n\n\n\n\n\n\n\n Checking if uuidd is installed \n\n\n\n1. Check whether uuid daemon (uuidd) is installed. If it is not, install and start it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-quickstudy-bm-netweaver-rhel"},{"document_id":"ibmcld_11579-13787-15608","score":10.1585359573,"text":"\nIf you see no errors, you can proceed with the installation.\n\n\n\n\n\n Is there a central SAP Note for installing NetWeaver on Oracle? \n\n[SAP Note 2172935 - Installation - SAP Systems based on SAP NetWeaver: Oracle Database](https:\/\/launchpad.support.sap.com\/\/notes\/2172935) provides hardware and storage requirements for Oracle and details the required file systems and mount points.\n\n\n\n\n\n Is there a central SAP Note for using MaxDB for NetWeaver installations? \n\n[SAP Note 2365014 - Installation of SAP Systems Based on SAP NetWeaver: SAP MaxDB](https:\/\/launchpad.support.sap.com\/\/notes\/2365014) outlines the installation and provides other useful information for MaxDB users.\n\n\n\n\n\n\n\n SAP HANA generic questions \n\n\n\n What hardware database virtualization\/sharing\/isolation options are supported in the IBM Cloud infrastructure? \n\nIBM Cloud SAP-certified infrastructure offerings are certified for SAP and do not include database virtualization\/sharing\/isolation options such as Multitenant Database Containers (MDC) testing. The customer is responsible for following SAP guidance to:\n\n\n\n* Correctly set up the SAP HANA features and functions\n* Ensure that the infrastructure remains compliant with the SAP certification\n\n\n\n\n\n\n\n Is scale-out supported for SAP HANA? \n\nYes. For OLTP (i.e. SAP S\/4HANA) see [SAP S\/4HANA - Scale-up\/Scale-out](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-s4hanas4hana-hana-scaling), and for OLAP (i.e. BW\/4HANA) see [SAP BW\/4HANA - Scale-up\/Scale-out](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-bw4hanabw4hana-hana-scaling). Alternatively view the latest top specific available in the summary table on [FAQ of Profile List with Benchmarks and Specifications](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-faq-profile-specsfaq-profile-specs-maximums).\n\n\n\n\n\n How do I back up my SAP HANA-certified servers?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-faq-ibm-cloud-for-sap"},{"document_id":"ibmcld_05187-1383-2410","score":10.1068124771,"text":"\nService Install from the Cloud Pak for Data installation page Install by using the CLI \n\n [Analytics Engine Powered by Apache Spark](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/spark.html) \u2713 \u2713 \n [Cognos Analytics](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/ca.html) \u2713 \n [Cognos Dashboards](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/cde.html) \u2713 \u2713 \n [Data Refinery](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/dr.html) See Watson Knowledge Catalog or Watson Studio See Watson Knowledge Catalog or Watson Studio \n [DataStage](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/ds.html) \u2713 \n [Db2 Big SQL](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/bigsql.html) \u2713 \n [Db2 Data Gate](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/dg.html) \u2713 \u2713 \n [Db2 Data Management Console](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/dmc.html) \u2713 \u2713 \n [Db2 Warehouse](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/db2wh.html) \u2713 \u2713 \n [Db2 ](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/db2oltp.html) \u2713","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-data?topic=cloud-pak-data-install-services"},{"document_id":"ibmcld_05187-7-1663","score":10.0911636353,"text":"\nInstalling services \n\nIf you deploy IBM Cloud Pak for Data on IBM Cloud, you can install a subset of the services that are available in the Cloud Pak for Data services catalog.\n\nYou can install services by using two different methods. The supported methods depend on the services that you want to install:\n\n\n\n* Some services can be installed from the [Cloud Pak for Data installation page](https:\/\/cloud.ibm.com\/catalog\/content\/ibm-cp-datacore-6825cc5d-dbf8-4ba2-ad98-690e6f221701-global) in the IBM Cloud catalog.\n* Some services can be installed by creating a catalog source and an operator subscription for each service. For general information and prerequisites, see [Installing IBM Cloud Pak for Data](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/install\/install.html). To use this method, you must:\n\n\n\n* Use the Red Hat OpenShift command-line interface (oc CLI) to connect to the cluster. For more information, see [Connecting to the cluster from the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_clusteraccess_oc_cli).\n* Create an operator subscription for each service that you plan to install. For more information, see [Creating OLM objects for an express installation](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/install\/install-platform-express-olm.html).\n\n\n\n\n\nUse the links in the following table to learn how to install each of these services.\n\n\n\n Service Install from the Cloud Pak for Data installation page Install by using the CLI \n\n [Analytics Engine Powered by Apache Spark](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/spark.html) \u2713 \u2713 \n [Cognos Analytics](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-welcome\/ca.html) \u2713","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-data?topic=cloud-pak-data-install-services"},{"document_id":"ibmcld_06110-24862-26182","score":10.0183887482,"text":"\nReview the pod details to verify that the plug-in installation succeeded.\n\n\n\n1. Verify the installation succeeded by listing the driver pods.\n\nkubectl get pod --all-namespaces -o wide | grep object\n\nExample output\n\nibmcloud-object-storage-driver-9n8g8 1\/1 Running 0 2m\nibmcloud-object-storage-plugin-7c774d484b-pcnnx 1\/1 Running 0 2m\n\nThe installation is successful when you see one ibmcloud-object-storage-plugin pod and one or more ibmcloud-object-storage-driver pods. The number of ibmcloud-object-storage-driver pods equals the number of worker nodes in your cluster. All pods must be in a Running state for the plug-in to function properly. If the pods fail, run kubectl describe pod -n ibm-object-s3fs <pod_name> to find the root cause for the failure.\n2. Verify that the storage classes are created successfully.\n\nkubectl get storageclass | grep s3\n\nExample output\n\nibmc-s3fs-cold-cross-region ibm.io\/ibmc-s3fs 8m\nibmc-s3fs-cold-regional ibm.io\/ibmc-s3fs 8m\nibmc-s3fs-flex-cross-region ibm.io\/ibmc-s3fs 8m\nibmc-s3fs-flex-perf-cross-region ibm.io\/ibmc-s3fs 8m\nibmc-s3fs-flex-perf-regional ibm.io\/ibmc-s3fs 8m\nibmc-s3fs-flex-regional ibm.io\/ibmc-s3fs 8m\nibmc-s3fs-standard-cross-region ibm.io\/ibmc-s3fs 8m\nibmc-s3fs-standard-perf-cross-region ibm.io\/ibmc-s3fs 8m\nibmc-s3fs-standard-perf-regional ibm.io\/ibmc-s3fs 8m","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_cos_install"},{"document_id":"ibmcld_11590-2721-3826","score":9.9719018936,"text":"\n* Install SAP HANA on RHEL:\n\n\n\n* [SAP Note 2772999 - Red Hat Enterprise Linux 8.x: Installation and Configuration](https:\/\/me.sap.com\/notes\/2772999)\n* [SAP Note 2777782 - SAP HANA DB: Recommended OS Settings for RHEL 8](https:\/\/me.sap.com\/notes\/2777782)\n\n\n\n* SAP HANA Server Installation:\n\n\n\n* [SAP HANA Server Installation and Update Guide](https:\/\/help.sap.com\/docs\/SAP_HANA_PLATFORM\/2c1988d620e04368aa4103bf26f17727\/7eb0167eb35e4e2885415205b8383584.html?locale=en-US)\n\n\n\n* SAP HANA System Replication:\n\n\n\n* [SAP HANA System Replication Guide](https:\/\/help.sap.com\/docs\/SAP_HANA_PLATFORM\/4e9b18c116aa42fc84c7dbfd02111aba\/afac7100bc6d47729ae8eae32da5fdec.html?locale=en-US)\n\n\n\n* Configure SAP HANA System Replication:\n\n\n\n* [Automating SAP HANA Scale-Up System Replication by using the RHEL HA Add-On - 2. SAP HANA System Replication](https:\/\/access.redhat.com\/articles\/3004101sap-hana-system-replication)\n\n\n\n\n\n* A valid RHEL for SAP Applications or RHEL for SAP Solutions subscription is required to enable the repositories that you need to install SAP HANA and the resource agents for HA configurations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-ha-rhel-hana-sr"},{"document_id":"ibmcld_04301-2407-3165","score":9.9607133865,"text":"\nSAClient_600.tgz gateway installation.log\nconfig install_client.sh safenet\n6. Navigate to the \/var\/safenet\/config\/ directoy and execute the safenet_config script:\n\nroot@IBMADC690867-s6dr cd \/var\/safenet\/config\/\nroot@IBMADC690867-s6dr pwd\n\/var\/safenet\/config\n\nroot@IBMADC690867-s6dr sh safenet_config\n7. Verify that \/etc\/Chrystoki.conf and the symbolic link \/usr\/lib\/libCrystoki_64 were created:\n\nroot@IBMADC690867-s6dr ls -l \/etc\/Chrystoki.conf\n-rw-r--r-- 1 root wheel 1185 Jul 26 16:17 \/etc\/Chrystoki.conf\nroot@IBMADC690867-s6dr ls -l \/usr\/lib\/libCryptoki2_64.so\nlrwxr-xr-x 1 root wheel 54 Jul 26 16:17 \/usr\/lib\/libCryptoki2_64.so ->\n\/var\/safenet\/safenet\/lunaclient\/lib\/libCryptoki2_64.so\n\n\n\nThe IBM Hardware Security Module has been installed successfully.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/citrix-netscaler-vpx?topic=citrix-netscaler-vpx-install-the-ibm-hardware-security-module-hsm-client-software"},{"document_id":"ibmcld_11435-4260-6030","score":9.9182043076,"text":"\nCopy the ISO image to an existing AIX VM's file system by using the [scp](https:\/\/www.ibm.com\/support\/knowledgecenter\/ST5Q4U_1.5.2\/com.ibm.storwize.v7000.unified.152.doc\/usgr_usng_scp.html) command.\n\nThe scp command does not work unless you are on a public network.\n\nscp [Options]From_Host:]Source_File [User@]To_Host:]\n2. Run the [loopmount](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/ssw_aix_72\/l_commands\/loopmount.html) command to make the ISO image available as a file system by using the loopback device.\n\nloopmount {-i imagefile | -l device}[-o mount options -m mountpoint]\n3. Use the [installp](https:\/\/www.ibm.com\/support\/knowledgecenter\/ssw_aix_72\/i_commands\/installp.html) command to install the image in a compatible installation package. The following command and flags are most commonly used during installations, installp -agXd path software_to_install.\n4. Upon the completion of the installation, the system generates an installation summary. Verify that the Result column shows success for all of the loaded files. You can also verify the installation's success by typing, lslpp -aL, at a command line.\n\n\n\n\n\n\n\n Installing optional software products from the AIX stock image \n\nThe AIX stock images have a local repository that contains all available packages for the current level of the operating system. Any software that is not automatically installed is considered as optional and is included with the operating system in a separate file system starting with the 7100-05-05 or newer images \/usr\/sys\/inst.images. By creating a separate file system, the local repository prevents the expansion of \/usr file system. In addition, the separate file system can be safely removed if you want to reclaim the additional space used by the local repository.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-using-ess-iso"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10488-5523-7411","score":13.0499925613,"text":"\nCluster networking <br><br> * Set up cluster management components, such as public or private cloud service endpoints, VLANs, and load balancers.<br> * Fulfill requests for more infrastructure, such as attaching worker nodes to existing VLANs or subnets upon resizing a worker pool.<br> * Create clusters with subnet IP addresses reserved to use to expose apps externally.<br> * Set up a Konnectivity connection between the master and worker nodes when the cluster is created.<br> * Provide the ability to set up a VPN connection with on-premises resources such as through the strongSwan IPSec VPN service or the IBM Cloud VPC VPN.<br> * Provide the ability to isolate network traffic with edge nodes.<br><br><br> <br><br> * Use the provided API, CLI, or console tools to adjust [cluster networking configuration](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_network_cluster) to meet the needs of your workload, such as configuring service endpoints, adding VLANs to provide IP addresses for more worker nodes, setting up a VPN connection, or edge node worker pools.<br><br><br> \n App networking <br><br> * Set up a public application load balancer (ALB) that is multizone, if applicable. Provide the ability to set up private ALBs and public or private network load balancers (NLBs).<br> * Support native Kubernetes public and private load balancers and Ingress routes for exposing services externally.<br> * Install Calico as the container networking interface, and set up default Calico network policies to control basic cluster traffic.<br><br><br> <br><br> * Set up any additional app networking capabilities that are needed, such as private ALBs, public or private NLBs, or additional Calico network policies.<br><br><br> \n Observability <br><br> * Provide Log Analysis and Monitoring as managed add-ons to enable observability of your cluster and container environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iks"},{"document_id":"ibmcld_06057-5551-7441","score":12.9961557388,"text":"\nCluster networking <br><br> * Set up cluster management components, such as public or private cloud service endpoints, VLANs, and load balancers.<br> * Fulfill requests for more infrastructure, such as attaching worker nodes to existing VLANs or subnets upon resizing a worker pool.<br> * Create clusters with subnet IP addresses reserved to use to expose apps externally.<br> * Set up a Konnectivity connection between the master and worker nodes when the cluster is created.<br> * Provide the ability to set up a VPN connection with on-premises resources such as through the strongSwan IPSec VPN service or the IBM Cloud VPC VPN.<br> * Provide the ability to isolate network traffic with edge nodes.<br><br><br> <br><br> * Use the provided API, CLI, or console tools to adjust [cluster networking configuration](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_network_cluster) to meet the needs of your workload, such as configuring service endpoints, adding VLANs to provide IP addresses for more worker nodes, setting up a VPN connection, or edge node worker pools.<br><br><br> \n App networking <br><br> * Set up a public application load balancer (ALB) that is multizone, if applicable. Provide the ability to set up private ALBs and public or private network load balancers (NLBs).<br> * Support native Kubernetes public and private load balancers and Ingress routes for exposing services externally.<br> * Install Calico as the container networking interface, and set up default Calico network policies to control basic cluster traffic.<br><br><br> <br><br> * Set up any additional app networking capabilities that are needed, such as private ALBs, public or private NLBs, or additional Calico network policies.<br><br><br> \n Observability <br><br> * Provide Log Analysis and Monitoring as managed add-ons to enable observability of your cluster and container environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks"},{"document_id":"ibmcld_10505-5527-7417","score":12.9961557388,"text":"\nCluster networking <br><br> * Set up cluster management components, such as public or private cloud service endpoints, VLANs, and load balancers.<br> * Fulfill requests for more infrastructure, such as attaching worker nodes to existing VLANs or subnets upon resizing a worker pool.<br> * Create clusters with subnet IP addresses reserved to use to expose apps externally.<br> * Set up a Konnectivity connection between the master and worker nodes when the cluster is created.<br> * Provide the ability to set up a VPN connection with on-premises resources such as through the strongSwan IPSec VPN service or the IBM Cloud VPC VPN.<br> * Provide the ability to isolate network traffic with edge nodes.<br><br><br> <br><br> * Use the provided API, CLI, or console tools to adjust [cluster networking configuration](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_network_cluster) to meet the needs of your workload, such as configuring service endpoints, adding VLANs to provide IP addresses for more worker nodes, setting up a VPN connection, or edge node worker pools.<br><br><br> \n App networking <br><br> * Set up a public application load balancer (ALB) that is multizone, if applicable. Provide the ability to set up private ALBs and public or private network load balancers (NLBs).<br> * Support native Kubernetes public and private load balancers and Ingress routes for exposing services externally.<br> * Install Calico as the container networking interface, and set up default Calico network policies to control basic cluster traffic.<br><br><br> <br><br> * Set up any additional app networking capabilities that are needed, such as private ALBs, public or private NLBs, or additional Calico network policies.<br><br><br> \n Observability <br><br> * Provide Log Analysis and Monitoring as managed add-ons to enable observability of your cluster and container environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-satellite-responsibilities"},{"document_id":"ibmcld_11889-0-903","score":12.9438495636,"text":"\n\n\n\n\n\n\n  Setting up cluster groups \n\nThe cluster group specifies all clusters that you want to include in the deployment of your Kubernetes resources. The clusters can run in your Satellite location or in IBM Cloud.\n\nIf you want to use the console to create Satellite configurations, you can create cluster groups as part of the configuration creation process. If you want to use the CLI to create Satellite configurations, you must create a cluster group first. Follow these steps to create a cluster group with the CLI:\n\n\n\n1.  List the clusters that are registered with the Satellite Config component and note their ID.\n\nibmcloud sat cluster ls\n2.  Add the cluster to your cluster group.\n\nibmcloud sat group attach --cluster <cluster_ID> --group <cluster_group_name>\n3.  Verify that your cluster is successfully added to your cluster group.\n\nibmcloud sat group get --group <cluster_group_name>\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig-groups"},{"document_id":"ibmcld_10167-12276-14706","score":12.8662815094,"text":"\nA cron job periodically triggers a Cloud Function to push anonymized data documents from the regional centers to the global processing cluster's IBM Cloudant instance.\n: The compute cluster runs the PyTorch ML framework, and machine learning apps are written in Python to analyze the aggregated data. In addition to ML apps, researchers in the collective group also develop their own apps that can be published and run on the global cluster.\n: The nonprofit also provides apps that run on non-bare metal nodes of the global cluster. The apps view and extract the aggregated data and the ML app output. These apps are accessible by a public endpoint, which is secured by the API Gateway to the world. Then, researchers and data analysts from everywhere can download data sets and do their own analysis.\n\nDevelopers started by deploying their research-sharing SaaS apps in containers with Red Hat OpenShift on IBM Cloud. They created clusters for a Development environment that allow worldwide Developers to collaboratively deploy app improvements quickly.\n\nSecurity first: The Development Exec chose bare metal to host the research clusters. With bare metal for Red Hat OpenShift on IBM Cloud, the sensitive research workloads now have familiar isolation but within the flexibility of public cloud. Because this nonprofit also has a partnership with pharmaceutical companies, app security is crucial. Competition is fierce, and corporate espionage is possible. From that secure core, Vulnerability Advisor provides scanning.\n\n\n\n* Image vulnerability scanning\n* Policy scanning based on ISO 27k\n\n\n\nSecured research apps lead to increased clinical trial participation.\n\nTo achieve global availability, the Dev, Test, and Production systems are deployed across the globe in several data centers. For HA, they use a combination of clusters in multiple geographic regions as well as multizone clusters. They can easily deploy the research app to Frankfurt clusters to comply with the local European regulation. They also deploy the app within the United States clusters to ensure availability and recovery locally. They also spread the research workload across multizone clusters in Frankfurt to ensure that the European app is available and also balances the workload efficiently. Because researchers are uploading sensitive data with the research-sharing app, the app\u2019s clusters are hosted in regions where stricter regulations apply.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_health"},{"document_id":"ibmcld_05628-4-2149","score":12.858300209,"text":"\n* UI\n* CLI\n* Terraform\n\n\n\n\n\n\n\n Creating classic clusters \n\nClassic infrastructure\n\nUse the IBM Cloud CLI or the IBM Cloud console to create a fully customizable standard cluster with your choice of hardware isolation and access to features like multiple worker nodes for a highly available environment.\n\nRed Hat OpenShift on IBM Cloud clusters are created with a public only or both a public and private service endpoint. Public service endpoints can't be disabled, and therefore, you can't convert a public Red Hat OpenShift cluster to a private one. If you want your cluster to remain private, see [Planning your cluster network setup](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-pgw).\n\n\n\n Creating a classic cluster in the console \n\nCreate your single zone or multizone classic Kubernetes cluster by using the IBM Cloud console. Follow the console instructions to make the following cluster configurations. To begin creating your cluster, navigate to the [Kubernetes clusters console](https:\/\/cloud.ibm.com\/kubernetes\/clusters) and click Create cluster.\n\nLocation details\n: When you create a cluster, its resources remain in the location that you deploy the cluster to.\n: \n\n* Resource group: A cluster can be created in only one resource group, and after the cluster is created, you can't change its resource group. To create clusters in a resource group other than the default, you must have at least the [Viewer role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms) for the resource group.\n\n\n\n: \n\n* Geography: Select an area to create the cluster in, such as North America. The geography helps filter the Availability and Metro values that you can select in the console.\n\n\n\n: \n\n* Availability: A cluster can be created with a Single zone or Multizone configuration. A multizone cluster provides high availability, with the Kubernetes master deployed in a multizone-capable zone and three replicas of the master spread across different zones.\n\n\n\n* For multizone clusters, choose a Metro location. For the best performance, select the metro location that is physically closest to you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classic&interface=ui"},{"document_id":"ibmcld_06128-5590-7522","score":12.8221244812,"text":"\nEach persona uses different technical skills to successfully run and deploy apps to a cluster.\n\nWhat are a cluster admin's main tasks and technical knowledge?\n: As a cluster admin, you are responsible to set up, operate, secure, and manage the IBM Cloud infrastructure of your cluster. Typical tasks include:\n\n\n\n* Size the cluster to provide enough capacity for your workloads.\n* Design a cluster to meet the high availability, disaster recovery, and compliance standards of your company.\n* Secure the cluster by setting up user permissions and limiting actions within the cluster to protect your compute resources, your network, and data.\n* Plan and manage network communication between infrastructure components to ensure network security, segmentation, and compliance.\n* Plan persistent storage options to meet data residency and data protection requirements.\n\n\n\nThe cluster admin persona must have a broad knowledge that includes compute, network, storage, security, and compliance. In a typical company, this knowledge is spread across multiple specialists, such as System Engineers, System Administrators, Network Engineers, Network Architects, IT Managers, or Security and Compliance Specialists. Consider assigning the cluster admin role to multiple people in your company so that you have the required knowledge to successfully operate your cluster.\n\nWhat are an app developer's main tasks and technical skills?\n: As a developer, you design, create, secure, deploy, test, run, and monitor cloud-native, containerized apps in an Kubernetes cluster. To create and run these apps, you must be familiar with the concept of microservices, the [12-factor app](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy12factor) guidelines, [Docker and containerization principles](https:\/\/www.docker.com\/), and available [Kubernetes deployment options](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategy"},{"document_id":"ibmcld_09655-7-1917","score":12.7822227478,"text":"\nCreate a cluster \n\nThis section steps through the build tasks needed to create the Windows Server Failover Cluster (WSFC) and the availability group.\n\nThis guide assumes that you:\n\n\n\n* Have at least two servers running Windows 2019 and SQL Server 2019 to cluster.\n* Have a bastion host with external Internet access.\n* Have deployed active directory.\n\n\n\n\n\n Install the Failover Clustering feature \n\n\n\n1. RDP to the first SQL server using a user from the SQL Admins group account and open a PowerShell session.\n2. Add the SQL Admins group to the local Remote Management Users group so users in this group, can execute remote commands.\n3. Allow inbound TCP port 5022 into the server as this port is used for availability group traffic. Install the Failover Clustering feature and then restart the server:\n\n$domainnb = \"<NB_Domain>\"\n$group = $domainnb + \"SQLAdmins\"\nAdd-LocalGroupMember -Group \"Remote Management Users\" -Member $group\nNew-NetFirewallRule -DisplayName 'SQL-AG-Inbound' -Profile Domain -Direction Inbound -Action Allow -Protocol TCP -LocalPort 5022\nInstall-WindowsFeature \u2013Name Failover-Clustering \u2013IncludeManagementTools\nRestart-Computer -Force\n4. Repeat for the second SQL server.\n\n\n\n\n\n\n\n Create a WSFC and enable SQL Always On \n\n\n\n1. RDP to the first SQL server using a user from the SQL Admins group account and open a PowerShell session.\n2. Run a cluster validation test. Ignore any \"one pair of network interfaces\" warnings, as this is normal for this deployment.\n3. If there are no errors them create a WSFC cluster with a name of wsfc01 which includes the two SQL servers <hostname1> and <hostname2>. The -ManagementPointNetworkType Distributed option uses the node IP address of the virtual server which means that secondary IP addressing on the interface is not required. This option creates a Distributed Network Name (DNN), which routes traffic to the appropriate clustered resource.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/microsoft?topic=microsoft-mssql-cluster"},{"document_id":"ibmcld_14612-23048-24716","score":12.6949615479,"text":"\n[Edit icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/icons\/edit-tagging.svg) and select the geography, data center, and pod to host the cluster.\n2. Specify the cluster name.\n3. Select the CPU model, RAM size, and the number of bare metal servers.\n\n\n\n7. For network interface settings, enter the hostname prefix, and then select the uplink speed and network type.\n8. On the Summary pane, verify the cluster configuration before you add the cluster.\n\n\n\n1. Review the settings for the cluster.\n2. Review the estimated price of the cluster. Click Pricing details to generate a PDF summary. To save or print your order summary, click the Print or the Download icon ![Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/icons\/download.svg) on the upper right of the PDF window.\n3. Click the link or links of the terms that apply to your order, and confirm that you agree with these terms before you add the cluster.\n4. Click Create.\n\n\n\n\n\n\n\n\n\n Results after you add clusters to vCenter Server instances \n\n\n\n1. The deployment of the cluster starts automatically and the status of the cluster is changed to Initializing. You can check the status of the deployment by viewing the deployment history on the instance details page.\n2. When the cluster is ready to use, its status changes to Available. The newly added cluster is enabled with vSphere High Availability (HA) and vSphere Distributed Resource Scheduler (DRS).\n\n\n\nYou cannot change the cluster name. Changing the cluster name might cause the add or delete ESXi servers operations in the cluster to fail.\n\n\n\n\n\n Related links","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingclusters"},{"document_id":"ibmcld_10646-34141-35678","score":12.6907405853,"text":"\nThe labels for the predefined cluster roles are as follows.<br><br><br><br> * IAM Manager service access role, scoped to a namespace: rbac.authorization.k8s.io\/aggregate-to-admin: \"true\"<br> * IAM Writer service access role: rbac.authorization.k8s.io\/aggregate-to-edit: \"true\"<br> * IAM Reader service access role: rbac.authorization.k8s.io\/aggregate-to-view: \"true\"<br><br><br> \n rules.apiGroups Specify the Kubernetes [API groups](https:\/\/kubernetes.io\/docs\/reference\/using-api\/api-groups) that you want users to be able to interact with, such as \"apps\", \"batch\", or \"extensions\". For access to the core API group at REST path api\/v1, leave the group blank: [\"\"]. \n rules.resources Specify the Kubernetes [resource types](https:\/\/kubernetes.io\/docs\/reference\/kubectl\/cheatsheet\/) to which you want to grant access, such as \"daemonsets\", \"deployments\", \"events\", or \"ingresses\". \n rules.verbs Specify the types of [actions](https:\/\/kubectl.docs.kubernetes.io\/) that you want users to be able to do, such as \"get\", \"list\", \"describe\", \"create\", or \"delete\". \n\n\n\n2. Create the cluster role in your cluster. Any users that have a role binding to the admin cluster role now have the additional permissions from the view-pod-metrics cluster role.\n\noc apply -f <cluster_role_file.yaml>\n3. Follow up with users that have the admin cluster role. Ask them to [refresh their cluster configuration](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster) and test the action, such as oc top pods.\n\n\n\n\n\n\n\n\n\n Checking user permissions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-users"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":23.2212314606,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04131-13412-14896","score":22.2297000885,"text":"\nTo delete an alert policy by using the CLI, run the following command:\n\nibmcloud cis alert-policy delete POLICY_ID [-i, --instance INSTANCE] [-f, --force]\n\nWhere:\n\n\n\n* POLICY_ID is the id of alert policy.\n* -f, --force attempts to delete alert policy without prompting for confirmation.\n* -i, --instance value is the instance name or ID.\n\n\n\n\n\n\n\n\n\n Creating an alert policy by using the API \n\nTo create an email alert, take the following steps:\n\n\n\n1. Log in to your IBM Cloud account.\n2. Get a token.\n3. Using that token, run one of the following commands:\n\n\n\n* DDoS attack layer 7\n* Pool toggle alert\n* Security (WAF) alert\n* Advanced security (WAF) alert\n\n\n\n\n\n\n\n Alert commands \n\n\n\n DDoS attack layer 7 command \n\ncurl -X POST https:\/\/api.cis.cloud.ibm.com\/v1\/:crn\/alerting\/policies -H 'content-type: application\/json' -H 'x-auth-user-token: Bearer xxxxxx' -d '{\"name\":\"Example Policy\",\"enabled\":true,\"alert_type\":\"dos_attack_l7\",\"mechanisms\":{\"email\":[{\"id\":\"cistestemail@ibm.com\"}],\"webhooks\":[]}}'\n\nWhere:\n\n\n\n* -d is the array of attributes that are required to create the alert.\n\n\n\n* name is the name of the alert.\n* enabled is the state of the alert (one of true, false).\n* alert_type is the type of the alert (one of dos_attack_l7, load_balancing_pool_enablement_alert, clickhouse_alert_fw_anomaly, clickhouse_alert_fw_ent_anomaly, dedicated_ssl_certificate_event_type, universal_ssl_event_type, or load_balancing_health_alert).\n* mechanisms are at least one of email, webhooks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies"},{"document_id":"ibmcld_04132-3821-5296","score":22.1468658447,"text":"\nDeleting a webhook using the CLI \n\nTo delete a webhook using the CLI, run the following command.\n\nibmcloud cis alert-webhook-delete WEBHOOK_ID [-i, --instance INSTANCE] [-f, --force]\n\nWhere:\n\n\n\n* WEBHOOK_ID is the ID of webhook.\n* i, --instance value is the instance name or ID. If not set, the context instance specified by 'cis instance-set INSTANCE' is used.\n* -f, --force attempts to delete webhook without prompting for confirmation.\n\n\n\n\n\n\n\n\n\n Configuring webhooks using the API \n\nTo call these methods, you must be assigned one or more IAM access roles.\n\n\n\n* internet-svcs.zones.read\n* internet-svcs.zones.update\n\n\n\nYou can check your access by going to Users > name > Access policies.\n\n\n\n Creating a webhook using the API \n\nCreating a webhook alert is a two step process. First, create the webhook, then use the ID in the response that you receive to create the alert.\n\nTo create a webhook by using the API, follow these steps:\n\n\n\n1. Set up your API environment with the correct variables.\n2. Store your the following variable to be used in the API command:\n\n\n\n* crn: the full url-encoded CRN of the service instance.\n* name: the name of the webhook.\n* url: the URL of the webhook.\n* secret: the optional secret or API key needed to use the webhook.\n\n\n\n3. When all variables are initiated, create the webhook:\n\n\n\ncurl -X POST https:\/\/api.cis.cloud.ibm.com\/v1\/:crn\/alerting\/destinations\/webhooks\n-H 'content-type: application\/json'\n-H 'x-auth-user-token: Bearer xxxxxx'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks"},{"document_id":"ibmcld_07578-755905-757955","score":22.0389041901,"text":"\nYou can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n* Can I downgrade from Standard to the Free Trial?\n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n* My Free Trial has expired. What are my options?\n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance. If the instance is not deleted or upgraded after 45 days (from the initiation of the instance) the configuration domain, global load balancers, pools, and health checks are deleted automatically.\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?\n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-domain-moved-status).\n* I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues?\n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_04132-6123-7500","score":21.840637207,"text":"\nStore your the following variable to be used in the API command:\n\n\n\n* crn: the full url-encoded CRN of the service instance.\n* webhook_id: alert webhook identifier.\n\n\n\n3. When all variables are initiated, get the webhook details:\n\n\n\ncurl -X GET https:\/\/api.cis.cloud.ibm.com\/v1\/:crn\/alerting\/destinations\/webhooks\/:webhook_id\n-H 'content-type: application\/json'\n-H 'accept: application\/json'\n-H 'x-auth-user-token: Bearer xxxxxx'\n\n\n\n\n\n Updating a webhook using the API \n\nTo update a webhook by using the API, follow these steps:\n\n\n\n1. Set up your API environment with the correct variables.\n2. Store your the following variable to be used in the API command:\n\n\n\n* crn: the full url-encoded CRN of the service instance.\n* webhook_id: alert webhook identifier.\n* name: the name of the webhook.\n* url: the URL of the webhook.\n* secret: the optional secret or API key needed to use the webhook.\n\n\n\n3. When all variables are initiated, update the webhook:\n\n\n\ncurl -X PUT https:\/\/api.cis.cloud.ibm.com\/v1\/:crn\/alerting\/destinations\/webhooks\/:webhook_id\n-H 'content-type: application\/json'\n-H 'x-auth-user-token: Bearer xxxxxx'\n-d '{\"name\":\"Example Webhook\",\"url\":\"https:\/\/hooks.slack.com\/services\/Ds3fdBFbV\/456464Gdd\"}'\n\n\n\n\n\n Deleting a webhook using the API \n\nTo delete a webhook by using the API, follow these steps:\n\n\n\n1. Set up your API environment with the correct variables.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks"},{"document_id":"ibmcld_13139-17831-19468","score":21.8117542267,"text":"\nIn addition, you can now control what content gets cached by CIS and how long it stays cached. Go to Performance > Caching to define the global caching level and the browser expiration. You can customize the global security and caching rules with Page Rules. Page Rules enable fine-grained configuration using specific domain paths. As example with Page Rules, you could decide to cache all contents under \/assets for 3 days:\n\nZoom\n\n![Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis"},{"document_id":"ibmcld_04186-18298-19703","score":21.7013988495,"text":"\n[Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers)\n* [Building containers from images](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-images)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cis"},{"document_id":"ibmcld_04334-129430-130643","score":21.6017837524,"text":"\nIf not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.<-- <\/section \"id=\"section-command-options-logpush-job-delete\" \"> --><-- <section \"id=\"section-command-example-logpush-job-delete\" \"> --> Examples Delete http_requests log push job for domain 31984fea73a15b45779fa0df4ef62f9b. ibmcloud cis logpush-job-delete 31984fea73a15b45779fa0df4ef62f9b --dataset http_requests -i cis-demo --force\n<-- <\/section \"id=\"section-command-example-logpush-job-delete\" \"> --><-- <\/section \"id=\"section-logpush-job-delete\" \"> --><-- <section \"id=\"section-get-log-push-available-fields\" \"> --> ibmcloud cis logpush-available-fields Get all available fields for a data set (Enterprise plan only). ibmcloud cis logpush-available-fields DNS_DOMAIN_ID --dataset DATASET] -i, --instance INSTANCE] ! ! ! ! ! ! ! !\n<-- <section \"id=\"section-command-options-logpush-available-fields\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.--dataset value: The category of logs you want to receive. This value cannot be changed after the job is created. Valid values: http_requests, range_events, firewall_events. The default value is http_requests.-i , --instance value: Instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04145-1739-3868","score":21.5890045166,"text":"\nThe functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n\n\n\n\n\n How do I delete my CIS instance? \n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-domain-moved-status).\n\n\n\n\n\n I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues? \n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access\n\n\n\nYou need platform access roles to create and manage service instances, while service access roles perform service-specific operations on service instances. In the console, these settings can be updated by selecting Manage > Security > Identity and Access.\n\n\n\n\n\n Why is my domain in Pending state? How do I activate it? \n\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider. We periodically scan the public DNS system to check whether the name servers have been configured as instructed. As soon as we are able to verify the name server change (which can take up to 24 hours), we activate your domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq"},{"document_id":"ibmcld_01391-18343-19753","score":21.4218578339,"text":"\n[Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers)\n* [Building containers from images](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-images)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1845756968}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":24.671957016,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04195-6086-8151","score":24.4499835968,"text":"\nBecause CIS doesn't support email traffic by default, you must set the PTR record to the location of your email server. Contact your email provider for assistance.\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, you can click the Edit record option from the menu, which opens a dialog box that you can use to update the record.\n\nAfter you are finished making your changes, select Update record to save them, or Cancel to abort the changes.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, you can select the Delete record option from the menu, which opens a dialog box to confirm the delete process.\n\nYou can select the Delete button to confirm your delete action. Select Cancel if you don't want to delete.\n\n\n\n\n\n Importing and exporting DNS records \n\nDNS records can be imported into and exported from CIS. All files are imported and exported as .txt files in BIND format. Learn more about [BIND format](https:\/\/en.wikipedia.org\/wiki\/Zone_file). Click the overflow menu and select to import or export records.\n\nImport records - By default, a total of 3500 DNS records are allowed (imported and created on CIS). You can import multiple files, one at a time, as long as the total number of records is under the max limit. After importing, you are shown a summary with the number of records successfully added and the number that failed, along with the reason why each record failed.\n\nExport records - Use Export records to create a backup of your zone file, or export it to use with another DNS provider. When this menu option is clicked, the records are downloaded to the location specified by your browser settings (typically the Downloads folder). To select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cis"},{"document_id":"ibmcld_04334-32129-33511","score":21.0153121948,"text":"\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.\n\nibmcloud cis dns-records DNS_DOMAIN_ID [--type TYPE] [--name NAME] [--content CONTENT] [--page PAGE] [--per-page PER_PAGE] [--order ORDER] [--direction DIRECTION] [--match MATCH] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--type\n: Type of DNS records to display.\n\n--name\n: Value of name field to filter by.\n\n--content\n: Value of content field to filter by.\n\n--page\n: Page number of paginated results.\n\n--per_page\n: Maximum number of DNS records per page.\n\n--order\n: Field by which to order list of DNS records. Valid values are type, name, content, ttl, proxied\n\n--direction\n: Direction in which to order results [ascending or descending order]. Valid values are asc, desc\n\n--match\n: Whether to match all or at least one search parameter. Valid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04171-7-2143","score":20.728017807,"text":"\nKnown limitations \n\nThe following information describes some limitations when working with IBM Cloud\u00ae Internet Services (CIS), as well as some suggested courses of action to improve your experience.\n\n\n\n* It is recommended that you use Chrome.\n* The free trial plan is limited to one instance per account. After you create a resource instance and add a domain to it, you are not allowed to add new resource instances for CIS. This restriction is enforced even if you delete a trial domain and then attempt to add a domain again to the same resource instance. You'll encounter an error if you attempt to do so.\n* For this service, we support subdomain delegation only using NS records from another provider. CNAME delegation is not supported.\n* A, AAAA, and CNAME wildcard records (\"*\") cannot be proxied.\n* When you delete a dedicated certificate, it might reappear in the list for a short time before the deletion is complete.\n* To modify your custom dedicated certificate\u2019s hostnames after ordering, you must order a new certificate and then delete the old one.\n* IP rules created with two letter country codes can only be made with the Challenge action. If you want to block visitors from a country, upgrade to the Enterprise plan or place rules on your server to fully block.\n\n\n\n\n\n Global load balancer \n\n\n\n* Cloud Internet Services allows you to use the character _ in load balancer hostnames. However, Kubernetes clusters cannot use _.\n* The Standard plan permits a maximum of 5 load balancers, pools, and health checks. Each pool can have a total of 6 origins, but only 6 unique origins are permitted throughout each CIS instance.\n* Health check events for deleted pools and origins cannot be filtered, but they still appear in the table.\n* If you filter Health check events by Pool Health, Degraded pools are included because they technically are healthy, but might contain 1 or more critical origins.\n* When adding the request header name for a health check, use Host, capitalized. Using a lower-case host for a health check fails.\n\n\n\n\n\n\n\n DNS \n\n\n\n* Exporting DNS records includes Cloudflare CNAME records that should be hidden.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-known-limitations"},{"document_id":"ibmcld_04334-31256-32402","score":20.6860351562,"text":"\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet a dns record details in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record-delete \n\nDelete a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-delete DNS_DOMAIN_ID DNS_RECORD_ID [-i, --instance INSTANCE]\n\n\n\n Command options \n\n`DNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE will be used.\n\n\n\n\n\n Examples \n\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04145-1739-3868","score":20.3663635254,"text":"\nThe functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n\n\n\n\n\n How do I delete my CIS instance? \n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-domain-moved-status).\n\n\n\n\n\n I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues? \n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access\n\n\n\nYou need platform access roles to create and manage service instances, while service access roles perform service-specific operations on service instances. In the console, these settings can be updated by selecting Manage > Security > Identity and Access.\n\n\n\n\n\n Why is my domain in Pending state? How do I activate it? \n\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider. We periodically scan the public DNS system to check whether the name servers have been configured as instructed. As soon as we are able to verify the name server change (which can take up to 24 hours), we activate your domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq"},{"document_id":"ibmcld_04334-33215-34565","score":20.1082630157,"text":"\nValid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-import \n\nImport your BIND config.\n\nibmcloud cis dns-records-import DNS_DOMAIN_ID --file FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: BIND config to import. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nImport BIND config in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-import 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-export \n\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_07411-11870-13124","score":20.09034729,"text":"\n}\n\n\n\n\n\n\n\n Deleting a resource record \n\n\n\n Request \n\ncurl -X DELETE $DNSSVCS_ENDPOINT\/v1\/instances\/$INSTANCE_ID\/dnszones\/$DNSZONE_ID\/resource_records\/$RECORD_ID -H \"Authorization: $TOKEN\"\n\n\n\n\n\n Response \n\nHTTP 204 is returned, no content in response.\n\n\n\n\n\n\n\n Importing bulk resource records from a DNS zone file \n\n\n\n Request \n\ncurl -X POST $DNSSVCS_ENDPOINT\/v1\/instances\/$INSTANCE_ID\/dnszones\/$DNSZONE_ID\/import_resource_records --form \"file=@.\/bind.cfg\" -H \"Authorization: $TOKEN\"\n\n\n\n\n\n Response \n\n{\n\"total_records_parsed\": 17,\n\"records_added\": 17,\n\"records_failed\": 0,\n\"records_added_by_type\": {\n\"A\": 10,\n\"AAAA\": 2,\n\"CNAME\": 4,\n\"SRV\": 0,\n\"TXT\": 0,\n\"MX\": 0,\n\"PTR\": 1\n},\n\"records_failed_by_type\": {\n\"A\": 0,\n\"AAAA\": 0,\n\"CNAME\": 0,\n\"SRV\": 0,\n\"TXT\": 0,\n\"MX\": 0,\n\"PTR\": 0\n},\n\"message\": null,\n\"errors\": null\n}\n\n\n\n\n\n\n\n Exporting bulk resource records to a DNS zone file \n\n\n\n Request \n\ncurl -X GET $DNSSVCS_ENDPOINT\/v1\/instances\/$INSTANCE_ID\/dnszones\/$DNSZONE_ID\/export_resource_records -o dns_records.cfg -H \"Authorization: $TOKEN\"\n\n\n\n\n\n Response \n\nHTTP 200 is returned with zone file content in byte format\n\n\n\n\n\n\n\n\n\n Using the CLI \n\nFirst use the ibmcloud dns instance-target command to set the target operating DNS Services instance.\n\n$ ibmcloud dns instances","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-managing-dns-records"},{"document_id":"ibmcld_05351-9684-10230","score":19.8824996948,"text":"\nDelete your DNS records from CIS. For more information, see [Deleting DNS records](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cisdeleting-dns-records).\n3. Delete each project that you created. When you delete a project, all the components contained in that project are also deleted. For more information, see [Delete a project](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-manage-projectdelete-project).\n\n\n\nNote that your custom domain is not deleted, but is no longer associated with the application that you created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-deploy-multiple-regions"},{"document_id":"ibmcld_04334-34286-35758","score":19.6266117096,"text":"\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nExport BIND config for domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-export 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n Domain \n\nManipulate domains by using the following domain commands.\n\n\n\n ibmcloud cis domain-add \n\nAdd a domain.\n\nibmcloud cis domain-add DNS_DOMAIN_NAME [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\ntype value\n: Specify the domain type setup. Valid values: full, partial (default full).\n\n\n\n* full: A full zone implies that DNS is hosted.\n* partial: A partial zone implies that CNAME setup domain.\n\n\n\njump-start\n: Automatically attempt to fetch existing DNS records.\n\nDNS_DOMAIN_NAME\n: The FQDN of DNS domain. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nAdd a new domain test.com in instance cis-demo.\n\nibmcloud cis domain-add \"test.com\" -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis domain-resume \n\nResume the given domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":27.1009235382,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04195-6086-8151","score":25.3376617432,"text":"\nBecause CIS doesn't support email traffic by default, you must set the PTR record to the location of your email server. Contact your email provider for assistance.\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, you can click the Edit record option from the menu, which opens a dialog box that you can use to update the record.\n\nAfter you are finished making your changes, select Update record to save them, or Cancel to abort the changes.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, you can select the Delete record option from the menu, which opens a dialog box to confirm the delete process.\n\nYou can select the Delete button to confirm your delete action. Select Cancel if you don't want to delete.\n\n\n\n\n\n Importing and exporting DNS records \n\nDNS records can be imported into and exported from CIS. All files are imported and exported as .txt files in BIND format. Learn more about [BIND format](https:\/\/en.wikipedia.org\/wiki\/Zone_file). Click the overflow menu and select to import or export records.\n\nImport records - By default, a total of 3500 DNS records are allowed (imported and created on CIS). You can import multiple files, one at a time, as long as the total number of records is under the max limit. After importing, you are shown a summary with the number of records successfully added and the number that failed, along with the reason why each record failed.\n\nExport records - Use Export records to create a backup of your zone file, or export it to use with another DNS provider. When this menu option is clicked, the records are downloaded to the location specified by your browser settings (typically the Downloads folder). To select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cis"},{"document_id":"ibmcld_05353-20027-21778","score":24.3813533783,"text":"\nIf you use the CIS TLS mode of End-to-End-flexible, you can switch to use the CIS TLS End-to-End CA signed mode, and obtain a CA signed certificate that is created outside of Cloud Internet Services (CIS).\n\n\n\n1. Create the TLS\/SSL certificate outside of CIS. See [How can I obtain a certificate for my custom domain?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingsprepare-custom-domain-cert)\n2. [Create the custom domain mapping](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingscustom-domain) in Code Engine with the certificate chain and the private key.\n3. [Obtain the CNAME record for the custom domain mapping](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingscompleting-custom-domain-cname).\n4. In CIS, update the DNS records to point to your Code Engine project. In CIS, go to the DNS records page (Reliability>DNS) and Add the CNAME record.\n5. Change the CIS mode. Go to the TLS security page (Security>TLS). Select End-to-end CA signed as the TLS mode.\n\n\n\nIf you need to register multiple domains and subdomains, such as example.com and www.example.com, you must repeat the previous steps 2 and 3 for each subdomain. You can consider creating a single certificate that covers more than one domain. However, you can use that single certificate only one time in a region. If you plan to use your custom domains in more than one project in a single region, keep them separate.\n\n\n\n\n\n\n\n Testing your custom domain \n\nAfter the CNAME record updates are published, you can test the application with the custom domain mapping.\n\nWith a browser, call the application by targeting the custom domain by using curl.\n\ncurl -v -X GET https:\/\/www.example.com\n\nExample output\n\nHello World from:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings"},{"document_id":"ibmcld_04186-9163-11063","score":23.9445209503,"text":"\n* [Configure the Ingress for the DNS subdomain](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cismulti-region-k8s-cis-ingress)\n\n\n\n\n\n\n\n Step 3: Configure multi-location load-balancing \n\nYour application is now running in two clusters but it is missing one component for the users to access either clusters transparently from a single entry point.\n\nIn this section, you will configure IBM Cloud Internet Services (CIS) to distribute the load between the two clusters. CIS is a one stop-shop service providing Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your Cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the Ingress Subdomain of the Kubernetes clusters,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the clusters.\n\n\n\n\n\n Register a custom domain with IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. After you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cis"},{"document_id":"ibmcld_01391-9188-11098","score":23.8674736023,"text":"\n* [Configure the Ingress for the DNS subdomain](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cismulti-region-k8s-cis-ingress)\n\n\n\n\n\n\n\n Step 3: Configure multi-location load-balancing \n\nYour application is now running in two clusters but it is missing one component for the users to access either clusters transparently from a single entry point.\n\nIn this section, you will configure IBM Cloud Internet Services (CIS) to distribute the load between the two clusters. CIS is a one stop-shop service providing Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your Cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the Ingress Subdomain of the Kubernetes clusters,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the clusters.\n\n\n\n\n\n Register a custom domain with IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. After you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"},{"document_id":"ibmcld_04171-7-2143","score":23.5552177429,"text":"\nKnown limitations \n\nThe following information describes some limitations when working with IBM Cloud\u00ae Internet Services (CIS), as well as some suggested courses of action to improve your experience.\n\n\n\n* It is recommended that you use Chrome.\n* The free trial plan is limited to one instance per account. After you create a resource instance and add a domain to it, you are not allowed to add new resource instances for CIS. This restriction is enforced even if you delete a trial domain and then attempt to add a domain again to the same resource instance. You'll encounter an error if you attempt to do so.\n* For this service, we support subdomain delegation only using NS records from another provider. CNAME delegation is not supported.\n* A, AAAA, and CNAME wildcard records (\"*\") cannot be proxied.\n* When you delete a dedicated certificate, it might reappear in the list for a short time before the deletion is complete.\n* To modify your custom dedicated certificate\u2019s hostnames after ordering, you must order a new certificate and then delete the old one.\n* IP rules created with two letter country codes can only be made with the Challenge action. If you want to block visitors from a country, upgrade to the Enterprise plan or place rules on your server to fully block.\n\n\n\n\n\n Global load balancer \n\n\n\n* Cloud Internet Services allows you to use the character _ in load balancer hostnames. However, Kubernetes clusters cannot use _.\n* The Standard plan permits a maximum of 5 load balancers, pools, and health checks. Each pool can have a total of 6 origins, but only 6 unique origins are permitted throughout each CIS instance.\n* Health check events for deleted pools and origins cannot be filtered, but they still appear in the table.\n* If you filter Health check events by Pool Health, Degraded pools are included because they technically are healthy, but might contain 1 or more critical origins.\n* When adding the request header name for a health check, use Host, capitalized. Using a lower-case host for a health check fails.\n\n\n\n\n\n\n\n DNS \n\n\n\n* Exporting DNS records includes Cloudflare CNAME records that should be hidden.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-known-limitations"},{"document_id":"ibmcld_04145-3314-5349","score":23.4467830658,"text":"\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider. We periodically scan the public DNS system to check whether the name servers have been configured as instructed. As soon as we are able to verify the name server change (which can take up to 24 hours), we activate your domain. You can submit a request to recheck name servers by clicking on Recheck name servers in the overview page.\n\n\n\n\n\n Who is the registrar for my domain? \n\nConsult [https:\/\/whois.icann.org\/](https:\/\/whois.icann.org\/) for this information.\n\nYou must have the administrator privilege to edit your domain's configuration at the registrar in order to update or add the name servers provided for your domain when you add it to CIS. If you don't know who the registrar is for the domain you're trying to add to CIS, it is unlikely you have the permission to update your domain's configuration at the registrar. Work with the owner of the domain in your organization to make the necessary changes.\n\n\n\n\n\n I want to keep my current DNS provider for my domain (example.com). Can I delegate a subdomain (subdomain.example.com) from my current DNS provider to CIS? \n\nYes. The process is similar to adding a domain, but instead of the registrar, you work with the DNS provider for the higher level domain. When you add a subdomain to CIS, you are given two name servers to configure, as usual. You configure a Name Server (NS) record for each of the two name servers as DNS records within your domain being managed by the other DNS provider. When we are able to verify that the required NS records have been added, we activate your subdomain. If you do not manage the higher level domain within your organization, you must work with the owner of the higher level domain to get the NS records added.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq"},{"document_id":"ibmcld_04166-1564-3481","score":22.8120708466,"text":"\nA non-CIS domain cannot CNAME to a CIS domain unless the non-CIS domain is added to a CIS account.\n\nAttempting to directly access DNS records used for CIS CNAME setups also causes error 1001.\n\nDisable Always Online if using Custom Hostnames (SSL for SaaS).\n\n\n\n\n\n\n\n Error 1002: DNS points to Prohibited IP \n\nCommon causes for 1002 errors when a DNS points to a prohibited IP address are:\n\n\n\n* A DNS record in your CIS DNS points to one of CIS's IP addresses.\n* An incorrect target is specified for a CNAME record in your CIS DNS.\n* Your domain is not on CIS but has a CNAME that refers to a CIS domain.\n\n\n\n\n\n Resolution \n\nUpdate your CIS A or CNAME record to point to your origin IP address instead of a CIS IP address:\n\n\n\n1. Contact your hosting provider to confirm your origin IP address or CNAME record target.\n2. Log in to your CIS account.\n3. Select the domain that generates error 1002.\n4. Select the DNS app.\n5. Click Value for the A record to update.\n6. Update the A record.\n\n\n\nTo ensure your origin web server doesn\u2019t proxy its own requests through CIS, configure your origin webserver to resolve your CIS domain to:\n\n\n\n* The internal NAT-ed IP address, or\n* The public IP address of the origin web server.\n\n\n\n\n\n\n\n\n\n Error 1002: Restricted \n\nThe most common cause of 1002: Restricted errors is when the CIS domain resolves to a local or disallowed IP address or an IP address not associated with the domain.\n\n\n\n Resolution \n\nIf you own the website:\n\n\n\n1. Confirm your origin web server IP addresses with your hosting provider\n2. Log in to your CIS account\n3. Update the A records in the CIS DNS to the IP address confirmed by your hosting provider\n\n\n\n\n\n\n\n\n\n Error 1003 Access Denied: Direct IP Access Not Allowed \n\nThe most common cause of 1003 errors is when a client or browser directly accesses a CIS IP address.\n\n\n\n Resolution \n\nBrowse to the website domain name in your URL instead of the CIS IP address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-html-1xxx-errors"},{"document_id":"ibmcld_07578-978380-979969","score":22.6338977814,"text":"\nYou must re-import the certificate with a different CRN, and then update the VPN server with the new certificate CRN.\n* Can I use a customized hostname for the VPN server?\n\nYes, you can. You must create a CNAME DNS record and point it to the VPN server hostname in your DNS provider. After that, edit the client profile by replacing direct remote 445df6c234345.us-south.vpn-server.appdomain.cloud with remote your-customized-hostname.com.\n\n445df6c234345.us-south.vpn-server.appdomain.cloud is an example VPN server hostname.\n\nIf you are using [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started) as your DNS provider, refer to [CNAME Type record](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-ciscname-type-record) for information about how to add a CNAME DNS record.\n* What information should I provide in an IBM Support case if I need help?\n\nSupply the following content in your [IBM Support case](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case):\n\n\n\n1. Your VPN server ID.\n2. Your VPN client and operating system version.\n3. The logs from your VPN client.\n4. The time range when you encountered the problem.\n5. If user-ID-based authentication is used, supply the username.\n6. If certificate-based authentication is used, supply the common name of your client certificate.\n\nTo view the common name of your client certificate, use the OpenSSL command openssl x509 -noout -text -in your_client_certificate_file in the subject section.\n\n\n\n* How do I assign the VPN client role using IAM access management tags in the API?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-978256-979845","score":22.6338977814,"text":"\nYou must re-import the certificate with a different CRN, and then update the VPN server with the new certificate CRN.\n* Can I use a customized hostname for the VPN server?\n\nYes, you can. You must create a CNAME DNS record and point it to the VPN server hostname in your DNS provider. After that, edit the client profile by replacing direct remote 445df6c234345.us-south.vpn-server.appdomain.cloud with remote your-customized-hostname.com.\n\n445df6c234345.us-south.vpn-server.appdomain.cloud is an example VPN server hostname.\n\nIf you are using [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started) as your DNS provider, refer to [CNAME Type record](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-ciscname-type-record) for information about how to add a CNAME DNS record.\n* What information should I provide in an IBM Support case if I need help?\n\nSupply the following content in your [IBM Support case](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case):\n\n\n\n1. Your VPN server ID.\n2. Your VPN client and operating system version.\n3. The logs from your VPN client.\n4. The time range when you encountered the problem.\n5. If user-ID-based authentication is used, supply the username.\n6. If certificate-based authentication is used, supply the common name of your client certificate.\n\nTo view the common name of your client certificate, use the OpenSSL command openssl x509 -noout -text -in your_client_certificate_file in the subject section.\n\n\n\n* How do I assign the VPN client role using IAM access management tags in the API?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04122-7-1660","score":12.6870660782,"text":"\nSetting Transport Layer Security (TLS) options \n\nThe Transport Layer Security (TLS) options let you control whether visitors can browse your website over a secure connection, and when they do, how IBM Cloud\u00ae Internet Services connects to your origin server.\n\nUse the latest version of the TLS protocol (TLS 1.3) for improved security and performance by switching from Off to On.\n\n\n\n TLS encryption modes \n\nSet the TLS mode by selecting one of the following options from the Mode list.\n\nThese options are listed in the order from the least secure (Off) to the most secure (End-to-End CA signed).\n\n\n\n* [Off](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-off) (not recommended)\n* [Client-to-Edge](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-client-to-edge) (edge to origin not encrypted, self-signed certificates are not supported)\n* [End-to-End flexible](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-flexible) (edge to origin certificates can be self-signed)\n* [End-to-End CA signed](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-ca-signed) (default and recommended)\n* [HTTPS only origin pull](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-origin-only-pull) (Enterprise only)\n\n\n\n\n\n Off \n\nNo secure connection between your visitor and CIS, and no secure connection between CIS and your web server. Visitors can only view your website over HTTP, and any visitor attempting to connect using HTTPS receives an HTTP 301 Redirect to the plain HTTP version of your website.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-options"},{"document_id":"ibmcld_04335-232495-234138","score":12.3842306137,"text":"\nA Transport Layer Security (TLS) secret contains a signed TLS certificate, including all its intermediate certificates, and its corresponding private key from a certificate authority (CA). Use TLS secrets when you work with custom domain mappings.\n\nTo see CLI help for creating a TLS secret, run ibmcloud ce secret create --format tls.\n\nThe following example creates an TLS secret that is named mysecret-tls. The certificate chain that corresponds to the custom domain is contained in the file certificate.txt and the matching private key file is contained in the file privatekey.txt. Both of these files are located in the root directory of the local workstation.\n\nibmcloud ce secret create --name mysecret-tls --format tls --cert-chain-file certificate.txt --private-key-file privatekey.txt\n\n\n\n\n\n Example output for a TLS secret \n\nCreating TLS secret mysecret-tls...\nOK\n\n\n\n\n\n\n\n ibmcloud ce secret delete \n\nDelete a secret.\n\nibmcloud ce secret delete --name SECRET_NAME [--force] [--ignore-not-found] [--quiet]\n\n\n\n Command Options \n\n--name, -n\n: The name of the secret. This value is required.\n\n--force, -f\n: Force deletion without confirmation. This value is optional. The default value is false.\n\n--ignore-not-found, --inf\n: If not found, do not fail. This value is optional. The default value is false.\n\n--quiet, -q\n: Specify this option to reduce the output of the command. This value is optional. The default value is false.\n\n\n\n\n\n Example \n\nibmcloud ce secret delete --name mysecret-genericfromfile -f\n\n\n\n\n\n Example output \n\nDeleting secret mysecret-genericfromfile...\nOK\n\n\n\n\n\n\n\n ibmcloud ce secret get \n\nDisplay the details of a secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cli"},{"document_id":"ibmcld_05278-264010-265653","score":12.3842306137,"text":"\nA Transport Layer Security (TLS) secret contains a signed TLS certificate, including all its intermediate certificates, and its corresponding private key from a certificate authority (CA). Use TLS secrets when you work with custom domain mappings.\n\nTo see CLI help for creating a TLS secret, run ibmcloud ce secret create --format tls.\n\nThe following example creates an TLS secret that is named mysecret-tls. The certificate chain that corresponds to the custom domain is contained in the file certificate.txt and the matching private key file is contained in the file privatekey.txt. Both of these files are located in the root directory of the local workstation.\n\nibmcloud ce secret create --name mysecret-tls --format tls --cert-chain-file certificate.txt --private-key-file privatekey.txt\n\n\n\n\n\n Example output for a TLS secret \n\nCreating TLS secret mysecret-tls...\nOK\n\n\n\n\n\n\n\n ibmcloud ce secret delete \n\nDelete a secret.\n\nibmcloud ce secret delete --name SECRET_NAME [--force] [--ignore-not-found] [--quiet]\n\n\n\n Command Options \n\n--name, -n\n: The name of the secret. This value is required.\n\n--force, -f\n: Force deletion without confirmation. This value is optional. The default value is false.\n\n--ignore-not-found, --inf\n: If not found, do not fail. This value is optional. The default value is false.\n\n--quiet, -q\n: Specify this option to reduce the output of the command. This value is optional. The default value is false.\n\n\n\n\n\n Example \n\nibmcloud ce secret delete --name mysecret-genericfromfile -f\n\n\n\n\n\n Example output \n\nDeleting secret mysecret-genericfromfile...\nOK\n\n\n\n\n\n\n\n ibmcloud ce secret get \n\nDisplay the details of a secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cli"},{"document_id":"ibmcld_05436-3283-5187","score":10.842669487,"text":"\n<br>This secret is also used as a Git repository access secret in the CLI and Code repo access in the console. \n Transport Layer Security (TLS) A secret that contains a signed TLS certificate, including all its intermediate certificates, and its corresponding private key from a certificate authority (CA). <br>Use TLS secrets when you work with [custom domain mappings](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings) in Code Engine. \n\n\n\n\n\n\n\n\n\n Creating secrets \n\nUse secrets to provide sensitive information to your apps or jobs. Secrets are defined in key-value pairs and the data that is stored in secrets is encoded.\n\n\n\n Creating a secret from the console \n\nLearn how to create secrets from the Code Engine console.\n\n\n\n Creating a generic secret from the console \n\nLearn how to create generic secrets from the Code Engine console that can be consumed by jobs or apps as environment variables.\n\nBefore you begin, [create a project](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-manage-project).\n\n\n\n1. After your project is in Active status, click the name of your project on the [Code Engine Projects page](https:\/\/cloud.ibm.com\/codeengine\/projects).\n2. From the Components page, click Secrets and configmaps.\n3. From the Secrets and configmaps page, click Create to create your secret.\n4. From the Create config page, complete the following steps:\n\n\n\n1. Select the Secret option.\n2. Provide a name; for example, mysecret.\n3. Click Add key-value pair. Specify one or more key-value pairs for this secret. For example, specify one key as secret1 with the value of mysecret1 and specify another key as secret2 with the value of target-secret. The name that you choose for your key does not need to be the same as the name of your environment variable. Notice that the value for the key is hidden, but it can be viewed if needed.\n\n\n\n5. Click Create to create the secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret"},{"document_id":"ibmcld_05342-3283-5187","score":10.842669487,"text":"\n<br>This secret is also used as a Git repository access secret in the CLI and Code repo access in the console. \n Transport Layer Security (TLS) A secret that contains a signed TLS certificate, including all its intermediate certificates, and its corresponding private key from a certificate authority (CA). <br>Use TLS secrets when you work with [custom domain mappings](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings) in Code Engine. \n\n\n\n\n\n\n\n\n\n Creating secrets \n\nUse secrets to provide sensitive information to your apps or jobs. Secrets are defined in key-value pairs and the data that is stored in secrets is encoded.\n\n\n\n Creating a secret from the console \n\nLearn how to create secrets from the Code Engine console.\n\n\n\n Creating a generic secret from the console \n\nLearn how to create generic secrets from the Code Engine console that can be consumed by jobs or apps as environment variables.\n\nBefore you begin, [create a project](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-manage-project).\n\n\n\n1. After your project is in Active status, click the name of your project on the [Code Engine Projects page](https:\/\/cloud.ibm.com\/codeengine\/projects).\n2. From the Components page, click Secrets and configmaps.\n3. From the Secrets and configmaps page, click Create to create your secret.\n4. From the Create config page, complete the following steps:\n\n\n\n1. Select the Secret option.\n2. Provide a name; for example, mysecret.\n3. Click Add key-value pair. Specify one or more key-value pairs for this secret. For example, specify one key as secret1 with the value of mysecret1 and specify another key as secret2 with the value of target-secret. The name that you choose for your key does not need to be the same as the name of your environment variable. Notice that the value for the key is hidden, but it can be viewed if needed.\n\n\n\n5. Click Create to create the secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-configmap-secret"},{"document_id":"ibmcld_14311-2669-4435","score":10.8124494553,"text":"\nIf you use the existing workload edge cluster, you must create the edge bridge profile by using that cluster and change the existing-distributed port group to allow Promiscuous mode and Forged transmits. This setup shares the capacity of the private uplinks from the edge nodes for both private routed and bridged traffic. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-edge-private.\n\nZoom\n\n![Layer 2 bridge setup with workload edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-workload-edge.svg)\n\nFigure 2. Layer 2 bridge setup with workload edge cluster\n\nAlternatively, you can deploy a new edge cluster for bridging. In this case, you must create new edge nodes and create a new edge cluster by using these nodes. When you configure the edge bridge profile, you can then use this edge cluster for bridging only. This alternative scales better, and provides a better dedicated bridging performance. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-bridge.\n\nZoom\n\n![Layer 2 bridge setup with a new bridge edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_14311-3835-5367","score":10.3916282654,"text":"\n[Layer 2 bridge setup with a new bridge edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.\n* If you have a larger deployment, deploying a dedicated edge cluster or several edge clusters offers better performance and generally scales better.\n* If you use new edge nodes for bridging, they do not have to be in the same network or POD as the workload edge. Edge nodes are transport nodes and they communicate with the other NSX-T transport nodes (edges or hosts) through Geneve tunnels over layer 3 routed connections by using the IBM Cloud classic network as a transport network.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [VMware vSphere overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview)\n* [Getting started with IBM Cloud Gateway Appliance](https:\/\/cloud.ibm.com\/docs\/gateway-appliance?topic=gateway-appliance-getting-started)\n* [Installing NSX-T edge transport nodes](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.2\/installation\/GUID-5EF2998C-4867-4DA6-B1C6-8A6F8EBCC411.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_15141-7808-9997","score":10.3360700607,"text":"\nTransport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP. Sending a message by using UDP takes much less time than using TCP. It performs little error checking and does not add any advantages to IP services except to provide process-to-process communication instead of host-to-host communication.\n* Transmission Control Protocol (TCP)\n\nTransmission Control Protocol (TCP) is a reliable but complex transport-layer protocol. TCP adds connection-oriented features and reliability to IP services.\n\nTCP is a stream delivery service that guarantees delivery of data streams sent from one host to another without duplication or lost data. Since packet transfer is not reliable, a technique known as positive acknowledgment with retransmission is used to guarantee reliability of packet transfers. This fundamental technique requires the receiver to respond with an acknowledgment message as it receives the data.\n\nThe sender keeps a record of each packet it sends, and waits for acknowledgment before sending the next packet. The sender also keeps a timer from when the packet was sent, and retransmits a packet if the timer expires. This timer is needed in case a packet becomes lost or corrupted.\n\n\n\n\n\n\n\n Full versus split-tunnel mode \n\nWhen a VPN connection is set up, an encrypted tunnel is created over the internet to the VPN server. The VPN connection appears as a virtual network interface to the computer in addition to the existing LAN interface. You can now use both interfaces simultaneously by sending the private traffic destined to the VPC inside the VPN tunnel and the public traffic (internet traffic) over the other interface (outside the VPN tunnel). When the traffic is split between the VPN interface and other interfaces, split tunneling is said to be in use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-vpn-planning"},{"document_id":"ibmcld_04184-7-1931","score":10.1404705048,"text":"\nUsing mutual TLS \n\nMutual Transport Layer Security (mTLS) authentication ensures that traffic is both secure and trusted in both directions between a client and server. It is only available for customers at the Enterprise or Security plan level.\n\nWhen mTLS is configured, access is granted only to requests with a corresponding client certificate. When a request reaches the application, CIS responds with a request for the client certificate. If the client fails to present the certificate, the request is not allowed to proceed. Otherwise, the key exchange proceeds.\n\nZoom\n\n![Diagram of mTLS handshake](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/images\/mtls-handshake.png)\n\nFigure 1. Diagram of an mTLS handshake\n\n\n\n Configuring mutual TLS \n\nMutual TLS is not enabled by default. It is an additional service that requires prior authorization and enablement.\n\nTo obtain authorization, you must submit an IBM Support case.\n\nAfter mTLS is turned on for your account, take the following steps to enable it.\n\n\n\n1. Navigate to the Security page in the CIS UI.\n2. Select the Mutual TLS tab.\n3. Click Enable to enable the feature.\n\n\n\nAfter mTLS is enabled, it cannot be disabled.\n\nTo set up mTLS authentication in the IBM Cloud Internet Services UI for a particular endpoint:\n\n\n\n1. In the Root certificates table, click Add to define a new root certificate.\n2. Paste the certificate content into the content field, provide a name for the Root CA, and add one or more fully qualified domain names (FQDN) of the endpoints that you want to use this certificate. These FQDNs are the hostnames that are used for the resources being protected by the application policy. You must associate the Root CA with the FQDN that the application being protected uses.\n3. Click Save.\n\nIf your zone is using an intermediate certificate in addition to the root certificate, upload the entire chain.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mtls-features"},{"document_id":"ibmcld_14311-7-1811","score":10.1312675476,"text":"\nArchitecture pattern for using layer 2 (L2) bridging with NSX-T \n\nWith layer 2 bridging, you can have a L2 connection to a VLAN-backed port group or a device that is outside of your NSX-T data center deployment. An L2 bridge is also useful in a migration scenario, in which you need to split a subnet across physical and virtual workloads. Or when you run a database cluster on IBM Cloud bare metal servers.\n\nYou can use layer 2 bridging in IBM Cloud by following the principles that are presented in this pattern. You can adapt the pattern based on your needs by following VMware\u00ae best practices and IBM Cloud Classic network capabilities.\n\n\n\n Layer 2 bridging with NSX-T \n\nThe following diagram presents an overview for an architecture pattern for using layer 2 bridging with NSX-T edges in IBM Cloud classic infrastructure.\n\nZoom\n\n![Layer 2 bridging with NSX-T](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge.svg)\n\nFigure 1. Layer 2 bridging with NSX-T\n\nThe following list is a summary of the architecture pattern deployment:\n\n\n\n1. An L2 bridge requires an Edge cluster and an Edge Bridge profile to be deployed. An Edge Bridge profile specifies which Edge cluster to use for bridging and which Edge transport node acts as the primary and backup bridge.\n2. You need to have a new VLAN for the bridged devices. After the VLAN is provisioned, you can request to trunk the hosts. VLAN must be trunked to all hosts in your cluster through IBM Cloud Classic portal (Classic Infrastructure > Network > Gateway appliances). Then, add the ESX hosts to a wanted NSX-T VLAN transport zone, for example tz-bridge.\n3. On the edge cluster uplink distributed port group, enable Promiscuous mode and Forged transmits for bridging.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.7977228895}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02776-3988-5695","score":14.5141439438,"text":"\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.\n\nThese Service Providers have access to Personal Data only to perform these tasks on Developer\u2019s behalf and are obligated not to disclose or use it for any other purpose.\n\n\n\n\n\n Children's Privacy \n\nThe Permitted Use of the Service does not address anyone under the age of 18 (\"Children\").\n\nDeveloper does not knowingly collect Personal Data from anyone under the age of 18. If Developer becomes aware of the collection or processing of Personal Data from Children without verification of parental consent, Developer will take steps to remove that information from the default settings of App ID.\n\n\n\n\n\n Changes To This Privacy Policy \n\nThis Privacy Policy may be updated from time to time and any changes will be reflected by posting the new Privacy Policy on this page. Before the change becomes effective and updated, notification is made via prominent notice on our Service.\n\nThis Privacy Policy should be reviewed periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\n\n\n\n\n\n Contact Us \n\nFor any questions about this Privacy Policy, please contact the Developer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-privacy-policy"},{"document_id":"ibmcld_09109-6121-7923","score":14.2218179703,"text":"\n<br> <br>Important: To protect your privacy, do not store your personal data as metadata for your key. <br> <br>Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies. registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. \n key_description Optional.An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_material Required.The base64-encoded key material, such as a symmetric key, that you want to manage in the service. For more information, check out [Base64 encoding your key material](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-standard-keyshow-to-encode-standard-key-material). <br> <br>Ensure that the key material meets the following requirements: <br>A standard key can be up to 7,500 bytes in size. The key must be base64-encoded. \n key_type A boolean value that determines whether the key material can leave the service. <br> <br>When you set the extractable attribute to true, the service designates the key as a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-standard-keys"},{"document_id":"ibmcld_08515-6389-8309","score":14.156416893,"text":"\nTo protect your privacy, do not store your personal data as metadata for your key. \n key_description An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_material The base64 encoded key material, such as an existing key-wrapping key, that you want to store and manage in the service. For more information, see [Base64 encoding your key material](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-import-root-keysencode-key-material-root-key). Ensure that the key material meets the following requirements:<br><br><br><br> * The key must be 16, 24, or 32 bytes long, corresponding to 128, 192, or 256 bits.<br> * The key must be base64-encoded.<br><br><br> \n key_type A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to false, the service designates the key as a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https:\/\/www.nist.gov\/publications\/guide-protecting-confidentiality-personally-identifiable-information-pii).\n\nA successful POST api\/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Hyper Protect Crypto Services key management service API.\n3. Optional: Verify that the key was added by running the following call to browse the keys in your Hyper Protect Crypto Services service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-import-root-keys"},{"document_id":"ibmcld_09059-2794-4456","score":13.8913698196,"text":"\nTo protect your privacy, ensure that the key name does not contain personally identifiable information (PII), such as your name or location. Note that key names do not need to be unique. \n Key alias Optional. [Key aliases](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-key-alias) are ways to describe a key that allow them to be identified and grouped beyond the limits of a display name. Keys can have up to five aliases. \n Key ring Optional. [Key rings](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys) are groupings of keys that allow those groupings to be managed independently as needed. Every key must be a part of a key ring. If no key ring is selected, keys are placed in the default key ring. Note that to place the key you're creating in a key ring, you must have the Manager role over that key ring. For more information about roles, check out [Managing user access](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-access). \n Rotation policy Optional. If you hold the [Manager role](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-access), you can set a rotation policy for the key at key-creation time. If an [instance policy](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-policies-instance) exists to create rotation policies on keys by default, you can also overwrite that policy at key-creation time to a different interval. Note that if your instance has a rotation policy enabled and you Disable the rotation policy at key creation time, the policy is still written to your key in a Disabled state. If you want to enable this policy later, you can do so.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-root-keys"},{"document_id":"ibmcld_14910-7-1976","score":13.6056470871,"text":"\nConfidential computing with LinuxONE \n\nConfidential computing is enabled on LinuxONE (s390x processor architecture) by using the [IBM Secure Execution for Linux](https:\/\/www.ibm.com\/docs\/en\/linux-on-systems?topic=virtualization-introducing-secure-execution-linux) technology. This technology is part of the hardware of IBM z15 (z15) and IBM LinuxONE III generation systems. With IBM Secure Execution for Linux, you can securely deploy workloads in the cloud. It ensures the integrity and confidentiality of boot images, and server authenticity. Applications are isolated from the operating system, thus providing more privacy and security for the workload.\n\nBy using IBM Secure Execution for Linux, you can create encrypted Linux images that can run on a public, private, or hybrid cloud with their in-use memory protected. The workload or data is protected from external and insider threats.\n\nA new operating system that leverages the IBM Secure Execution for Linux technology is now available as IBM Hyper Protect. The associated image that's used to create the instance is called the [IBM Hyper Protect Container Runtime (HPCR) image](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vsabout-imageshyper-protect-runtime). A virtual server instance that's provisioned by using this image is called as an IBM Cloud Hyper Protect Virtual Servers for VPC (Virtual Private Cloud) instance.\n\nFor a technical deep dive into the IBM Hyper Protect Platform, see the white paper [The Second Generation of IBM Hyper Protect Platform](https:\/\/www.ibm.com\/downloads\/cas\/GPVMWPM3).\n\nCheck out the [tutorial](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-financial-transaction-confidential-computing-on-hyper-protect-virtual-server-for-vpc) and the [video](https:\/\/mediacenter.ibm.com\/media\/Confidential+Computing+for+a+financial+transaction+using+Hyper+Protect+Virtual+Server+for+VPC\/1_vv3j2oo6) on Confidential Computing for a financial transaction using Hyper Protect Virtual Server for VPC.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-se"},{"document_id":"ibmcld_09060-6596-8123","score":13.5426931381,"text":"\nTo protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_type Optional.A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to true, the service creates a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.\n\nA successful POST api\/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Key Protect API.\n\nOptional: Verify that the key was created by running the following call to get the keys in your Key Protect service instance.\n\n$ curl -X GET \"https:\/\/<regon>.kms.cloud.ibm.com\/api\/v2\/keys\" -H \"accept: application\/vnd.ibm.collection+json\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\"\n\n\n\n\n\n What's next \n\n\n\n* To find out more about programmatically managing your keys, [check out the Key Protect API reference doc](https:\/\/cloud.ibm.com\/apidocs\/key-protect).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-standard-keys"},{"document_id":"ibmcld_04519-20259-21874","score":13.355047226,"text":"\nTo protect your privacy, do not use personal data, such as your name or location, as a description for your secret group.\n\nThe maximum length is 1024 characters. The minimum length is 0 characters. The value must match regular expression \/(.?)\/.\n\n--labels ([]string)\n: Labels that you can use to search secrets in your instance. Only 30 labels can be created.\n\nLabel can be between 2-30 characters, including spaces.\n\nTo protect your privacy, do not use personal data, such as your name or location, as a label for your secret.\n\nThe list items must match regular expression \/(.?)\/. The maximum length is 30 items. The minimum length is 0 items.\n\n--custom-metadata (generic map)\n: The secret metadata that a user can customize.\n\n--expiration-date (strfmt.DateTime)\n: The date when the secret material expires. The date format follows the RFC 3339 format.\n\n--ttl (string)\n: The time-to-live (TTL) or lease duration to assign to credentials that are generated.\n\nFor iam_credentials secrets, the TTL defines for how long each generated API key remains valid. The value can be either an integer that specifies the number of seconds, or the string representation of a duration, such as 120m or 24h.\n\nThe minimum duration is 1 minute. The maximum is 90 days.\n\nThe maximum length is 10 characters. The minimum length is 2 characters. The value must match regular expression \/^[0-9]+[s,m,h,d]{0,1}$\/.\n\n--rotation ([RotationPolicy](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-secrets-manager-clicli-rotation-policy-example-schema))\n: This field indicates whether Secrets Manager rotates your secrets automatically.\n\n\n\n\n\n Example","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-secrets-manager-cli"},{"document_id":"ibmcld_08432-6308-8159","score":13.3289871216,"text":"\nA unique, human-readable name for easy identification of your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional. One or more unique, human-readable aliases assigned to your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key.<br><br>Each alias must be alphanumeric, case-sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Hyper Protect Crypto Services reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be 2 - 90 characters (inclusive). \n key_description Optional: An extended description of your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS Optional: The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service.<br><br>When you set the extractable attribute to false, the service creates a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https:\/\/nvlpubs.nist.gov\/nistpubs\/Legacy\/SP\/nistspecialpublication800-122.pdf).\n\nIf you set the expirationDate in your request, the key is moved to the deactivated state within 1 hour past the key's expiration date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-create-root-keys"},{"document_id":"ibmcld_13616-13587-15670","score":13.1766691208,"text":"\n[https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html)\n\n\n\n\n\n Data Privacy and Subject Rights \n\n\n\n* IBM Privacy Statement\n\n\n\nIBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\n\n\n* Right to Lodge a Complaint\n\n\n\nIn the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\n\n\n* IBM TRIRIGA Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\n\n\n* IBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the TRIRIGA Application Suite applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n* IBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n\n\n DDoS Protection \n\n\n\n* IBM Cloud provides DDoS (Distributed Denial of Service) protection for its environment, designed to protect the entire network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tas-ms?topic=tas-ms-security"},{"document_id":"ibmcld_08433-6344-8271","score":13.0844163895,"text":"\nOne or more unique, human-readable aliases assigned to your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key.<br><br>Each alias must be alphanumeric, case-sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Hyper Protect Crypto Services reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be 2 - 90 characters (inclusive). \n key_description Optional: An extended description of your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS Optional: The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service.<br><br>When you set the extractable attribute to true, the service creates a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https:\/\/nvlpubs.nist.gov\/nistpubs\/Legacy\/SP\/nistspecialpublication800-122.pdf).\n\nA successful POST \/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Hyper Protect Crypto Services key management service API.\n3. Optional: Verify that the key was created by running the following call to get the keys in your Hyper Protect Crypto Services service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-create-standard-keys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07637-3693-4843","score":12.2061700821,"text":"\nThe term security labeling refers to the association of security attributes with subjects and objects represented by internal data structures within organizational information systems, to enable information system-based enforcement of information security policies. Security labels include, for example, access authorizations, data life cycle protection (i.e., encryption and data expiration), nationality, affiliation as contractor, and classification of information in accordance with legal and compliance requirements. The term security marking refers to the association of security attributes with objects in a human-readable form, to enable organizational process-based enforcement of information security policies. The AC-16 base control represents the requirement for user-based attribute association (marking). The enhancements to AC-16 represent additional requirements including information system-based attribute association (labeling). Types of attributes include, for example, classification level for objects and clearance (access authorization) level for subjects. An example of a value for both of these attribute types is Top Secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ac-16"},{"document_id":"ibmcld_07859-4616-6150","score":10.9881877899,"text":"\nThe security engineering principles in SA-8 cannot be properly applied if individuals that design, code, and test information systems and system components (including information technology products) do not understand security. Therefore, organizations include qualified personnel, for example, chief information security officers, security architects, security engineers, and information system security officers in system development life cycle activities to ensure that security requirements are incorporated into organizational information systems. It is equally important that developers include individuals on the development team that possess the requisite security expertise and skills to ensure that needed security capabilities are effectively integrated into the information system. Security awareness and training programs can help ensure that individuals having key security roles and responsibilities have the appropriate experience, skills, and expertise to conduct assigned system development life cycle activities. The effective integration of security requirements into enterprise architecture also helps to ensure that important security considerations are addressed early in the system development life cycle and that those considerations are directly related to the organizational mission\/business processes. This process also facilitates the integration of the information security architecture into the enterprise architecture, consistent with organizational risk management and information security strategies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-sa-3"},{"document_id":"ibmcld_12768-0-777","score":10.757566452,"text":"\n\n\n\n\n\n\n  Existing network configurations and security groups \n\nA security group augments any existing network configuration. Therefore, a security group cannot span across networks that cannot communicate with one another.\n\nIf virtual server instances cannot communicate with one another, adding them to a security group does not change that behavior. Gateways must allow the traffic that is defined by the selected security groups.\n\nIf your account is enabled for custom private addressing (CPA) as well as security groups, be aware that security groups are scoped to the account level, not the network level. Security groups are defined by IP addresses, not private networks.\n\nSecurity groups are available in all data centers with virtual server instance provisioning.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-groups?topic=security-groups-existing-network-configurations-and-security-groups"},{"document_id":"ibmcld_07860-2886-4871","score":10.4074821472,"text":"\nSecurity strength requirements associated with such capabilities, functions, and mechanisms include degree of correctness, completeness, resistance to direct attack, and resistance to tampering or bypass. Security assurance requirements include: (i) development processes, procedures, practices, and methodologies; and (ii) evidence from development and assessment activities providing grounds for confidence that the required security functionality has been implemented and the required security strength has been achieved. Security documentation requirements address all phases of the system development life cycle. Security functionality, assurance, and documentation requirements are expressed in terms of security controls and control enhancements that have been selected through the tailoring process. The security control tailoring process includes, for example, the specification of parameter values through the use of assignment and selection statements and the specification of platform dependencies and implementation information. Security documentation provides user and administrator guidance regarding the implementation and operation of security controls. The level of detail required in security documentation is based on the security category or classification level of the information system and the degree to which organizations depend on the stated security capability, functions, or mechanisms to meet overall risk response expectations (as defined in the organizational risk management strategy). Security requirements can also include organizationally mandated configuration settings specifying allowed functions, ports, protocols, and services. Acceptance criteria for information systems, information system components, and information system services are defined in the same manner as such criteria for any organizational acquisition or procurement. The Federal Acquisition Regulation (FAR) Section 7.103 contains information security requirements from FISMA.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-sa-4"},{"document_id":"ibmcld_07821-1734-3870","score":10.3252496719,"text":"\nIn addition, the security architecture can include other important security-related information, for example, user roles and access privileges assigned to each role, unique security requirements, the types of information processed, stored, and transmitted by the information system, restoration priorities of information and information system services, and any other specific protection needs. In today\u2019s modern architecture, it is becoming less common for organizations to control all information resources. There are going to be key dependencies on external information services and service providers. Describing such dependencies in the information security architecture is important to developing a comprehensive mission\/business protection strategy. Establishing, developing, documenting, and maintaining under configuration control, a baseline configuration for organizational information systems is critical to implementing and maintaining an effective information security architecture. The development of the information security architecture is coordinated with the Senior Agency Official for Privacy (SAOP)\/Chief Privacy Officer (CPO) to ensure that security controls needed to support privacy requirements are identified and effectively implemented. PL-8 is primarily directed at organizations (i.e., internally focused) to help ensure that organizations develop an information security architecture for the information system, and that the security architecture is integrated with or tightly coupled to the enterprise architecture through the organization-wide information security architecture. In contrast, SA-17 is primarily directed at external information technology product\/system developers and integrators (although SA-17 could be used internally within organizations for in-house system development). SA-17, which is complementary to PL-8, is selected when organizations outsource the development of information systems or information system components to external entities, and there is a need to demonstrate\/show consistency with the organization\u2019s enterprise architecture and information security architecture.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-pl-8"},{"document_id":"ibmcld_16171-1267-2113","score":10.3093156815,"text":"\nDetection is the process of monitoring the events occurring in your network and analyzing them for signs of possible threats to your security policies. Prevention refers to the process stopping the detected incidents. \n [On-box logging and reporting CSB statistics in J-web](https:\/\/public.dhe.ibm.com\/cloud\/bluemix\/network\/vsrx\/on-box-logging-reporting-11320.pdf) This guide describes how to enable on-box security event reporting using the set security log report CLI command. \n [Juniper searchable IPS signature database](https:\/\/threatlabs.juniper.net\/signatures\/search\/\/list\/ips?page_number=1&page_size=20) Juniper's searchable database of IPS and application signatures to help protect your environment. These signature pages describe the vulnerabilities covered, their CVE numbers, CVSS scores, and Juniper's recommendation for deployment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vsrx?topic=vsrx-supplemental-ibm-cloud-juniper-vsrx-documentation"},{"document_id":"ibmcld_12758-7-2232","score":9.9142370224,"text":"\nAbout IBM security groups \n\nAn IBM Cloud\u00ae security group is a set of IP filter rules that define how to handle incoming (ingress) and outgoing (egress) traffic to both the public and private interfaces of a virtual server instance. The rules that you add to a security group are known as security group rules.\n\n\n\n* You can assign security groups to the public and\/or private network interfaces of a single virtual server or multiple virtual server instances.\n* You can assign security groups that are provided by IBM or that you create.\n* When a security group is applied to the network component of a virtual server instance, all traffic to and from that network component is denied, unless explicitly permitted by a security group rule.\n* The inbound traffic to a virtual server instance is referred to as ingress traffic.\n* The outbound traffic from a virtual server instance is referred to as egress traffic.\n\n\n\nSecurity groups are implemented on the hypervisor hosting the virtual server.\n\n\n\n Security groups provided by IBM \n\nYou can assign any of the following security groups that are provided by IBM to the network interfaces of your virtual server instances:\n\n\n\n* allow_ssh - This security group defines the IP rules that allow ingress TCP traffic on the SSH port only (22\/TCP).\n* allow_http - This security group defines the IP rules that allow ingress traffic on HTTP port only (80\/TCP).\n* allow_https - This security group defines the IP rules that allow ingress TCP traffic on HTTPS port only (443\/TCP).\n* allow_outbound - This security group defines the IP rules that allow all egress traffic from the server.\n* allow_all - This security group defines the IP rules that allow all ingress traffic on all ports.\n\n\n\n\n\n\n\n Security groups and audit logs \n\nAll security group interactions are logged to an account's audit log. The entries track specific security group changes as well as which user requested the change. Logs are written for the following interactions:\n\n\n\n* A security group is added to or removed from a virtual server's network interface.\n* A security group's rules are changed by add rule, edit rule, or remove rule.\n\n\n\nFor each of those interactions, one log is written for each affected object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-groups?topic=security-groups-about-ibm-security-groups"},{"document_id":"ibmcld_07637-1599-4413","score":9.8096666336,"text":"\nNIST supplemental guidance \n\nInformation is represented internally within information systems using abstractions known as data structures. Internal data structures can represent different types of entities, both active and passive. Active entities, also known as subjects, are typically associated with individuals, devices, or processes acting on behalf of individuals. Passive entities, also known as objects, are typically associated with data structures such as records, buffers, tables, files, inter-process pipes, and communications ports. Security attributes, a form of metadata, are abstractions representing the basic properties or characteristics of active and passive entities with respect to safeguarding information. These attributes may be associated with active entities (i.e., subjects) that have the potential to send or receive information, to cause information to flow among objects, or to change the information system state. These attributes may also be associated with passive entities (i.e., objects) that contain or receive information. The association of security attributes to subjects and objects is referred to as binding and is typically inclusive of setting the attribute value and the attribute type. Security attributes when bound to data\/information, enables the enforcement of information security policies for access control and information flow control, either through organizational processes or information system functions or mechanisms. The content or assigned values of security attributes can directly affect the ability of individuals to access organizational information. Organizations can define the types of attributes needed for selected information systems to support missions\/business functions. There is potentially a wide range of values that can be assigned to any given security attribute. Release markings could include, for example, US only, NATO, or NOFORN (not releasable to foreign nationals). By specifying permitted attribute ranges and values, organizations can ensure that the security attribute values are meaningful and relevant. The term security labeling refers to the association of security attributes with subjects and objects represented by internal data structures within organizational information systems, to enable information system-based enforcement of information security policies. Security labels include, for example, access authorizations, data life cycle protection (i.e., encryption and data expiration), nationality, affiliation as contractor, and classification of information in accordance with legal and compliance requirements. The term security marking refers to the association of security attributes with objects in a human-readable form, to enable organizational process-based enforcement of information security policies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ac-16"},{"document_id":"ibmcld_12655-7-2271","score":9.7514677048,"text":"\nAbout IBM Cloud Data Security Broker \n\nData Security Broker is a software that makes data breaches irrelevant by ensuring data remains encrypted, not only when it is stored but also when it is being processed by databases and applications. Data Security Broker provides easy and feasible way to provide enhanced data protection for sensitive data in public or private cloud environments. The software includes dynamic management of customer-owned keys and the ability to protect databases at a column-level granularity.\n\n\n\n How it works \n\nData Security Broker delivers an enterprise-level transparent data security platform that secures databases through a \"no code\" model at the field or file level. The software supports tokenization, format-preserving encryption (FPE), and role-based access control.\n\nThe encyrption is made simpler, faster, and seamless.\n\nZoom\n\n![High level architecture of Data Security Broker Manager](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/57ab3ec034294d8a6de510b97bec3035d4654761\/security-broker\/images\/deploy_architecture.png)\n\nHigh level architecture of Data Security Broker Manager\n\nThe Data Security Broker supports data encryption by migrating the data from an existing SQL\/NoSQL database into a secure database with the ability to encrypt fields at a column granularity, thereby enabling selective privacy.\n\nThis is accomplished by inserting the Data Security Broker Shield driver layer proxy between the application and the database. The Shield is used to intercept SQL or its NoSQL equivalent generated by the application to access data records in the database by encrypting on writes and decrypting on reads.\n\nThe encryption process manages keys that are generated by a commercially available key management service such as IBM\u00ae Key Protect and Hyper Protect Crypto Services.\n\nApplication performance is minimally impacted allowing for enterprise workflows to continue to operate in a secure environment. The Data Security Broker Manager is the cloud-based management console providing scalability, fault tolerance, and manageability of the software.\n\n\n\n\n\n Encryption Technology Configuration Overview: \n\nData Security Broker supports data protection services that can be configured in four main modes.\n\n\n\n Data Encryption:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_about"},{"document_id":"ibmcld_12538-5772-6664","score":9.6942062378,"text":"\nSecurity and Compliance Center allows you to define the controls you need to meet by using pre-defined or custom profiles, attach the profiles to a group of resources, or scope, and [perform regularly scheduled evaluations](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-scan-resources). As evaluations are completed, the results are displayed in a dashboard so you can get an overarching view of your current compliance posture against the controls that are important for your use case and download compliance reports. Your security and compliance managers can also choose to set up notifications to get alerted when an issue is found so that it can be remediated quickly. In addition, Security and Compliance Center can collect evidence from your DevSecOps pipeline runs on your application code so that it can show a complete view of your compliance on IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-continuous-compliance"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01028-7-1325","score":19.4439945221,"text":"\nFirewall Allowlist \n\nIf you use allowlists to control connections in your environment, you can use the following IP lists to allowlist Db2 on Cloud deployments. You should allowlist all of the subnet ranges for the entire region that your deployments live in.\n\nAs new clusters in a region are created, there will be additional IP ranges that will be added. If an existing Db2oC customer adds a new instance, it may be necessary to add these new IP ranges into the firewall rules.\n\n\n\n Dallas List \n\n\n\n Subnet Location \n\n 52.116.179.72\/29 Dal 10 \n 169.47.221.160\/29 Dal 10 \n 169.48.136.32\/29 Dal 10 \n 169.61.233.8\/29 Dal 10 \n 52.117.144.16\/29 Dal 10 \n 169.46.44.40\/29 Dal 10 \n 169.46.55.64\/29 Dal 10 \n 169.47.195.32\/29 Dal 10 \n 52.116.221.96\/29 Dal 12 \n 169.59.195.128\/29 Dal 12 \n 169.61.143.48\/29 Dal 12 \n 169.61.156.232\/29 Dal 12 \n 52.117.238.40\/29 Dal 13 \n 52.117.249.176\/29 Dal 13 \n 169.61.51.96\/29 Dal 13 \n 169.62.167.128\/29 Dal 13 \n 52.116.3.56\/29 Dal 13 \n 169.48.70.200\/29 Dal 13 \n 169.60.146.120\/29 Dal 13 \n 169.60.154.184\/29 Dal 13 \n 169.60.164.88\/29 Dal 13 \n\n\n\n\n\n\n\n Frankfurt List \n\n\n\n Subnet Location \n\n 159.122.98.248\/29 Fra 02 \n 159.122.121.232\/29 Fra 02 \n 169.50.5.8\/29 Fra 02 \n 161.156.8.168\/29 Fra 04 \n 161.156.91.56\/29 Fra 04 \n 161.156.103.32\/29 Fra 04 \n 149.81.98.128\/29 Fra 05 \n 149.81.142.0\/29 Fra 05","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-firewall-allowlist"},{"document_id":"ibmcld_04170-1738-2974","score":19.2096672058,"text":"\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed. Your CSP should allow scripts that are served from your origin domain (script-src self).\n* If your CSP uses a nonce for script tags, CIS adds these nonces to the scripts it injects by parsing your CSP response header.\n* If your CSP does not use nonce for script tags and JavaScript Detection is enabled, you might see a console error such as\n\nRefused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self'\". Either the 'unsafe-inline' keyword, a hash ('sha256-b123b8a70+4jEj+d6gWI9U6IilUJIrlnRJbRR\/uQl2Jc='), or a nonce ('nonce-...') is required to enable inline execution.\n* It is not recommended to use unsafe-inline. Instead, it is recommend that you use CSP nonces in script tags which are parsed and supported in the CDN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_16727-312686-314637","score":18.7098560333,"text":"\nIf you're using firewalls, you must configure rules for all communications from the IBM\u00ae CloudDriver virtual server instance (VSI) and the SDDC Manager virtual machines (VMs). These rules must allow all protocols to communicate on the IP addresses 10.0.0.0\/8 and 161.26.0.0\/16. Examples of such firewalls are NSX Distributed Firewalls (DFW) or vSRX gateway cluster firewalls.\n\nSome components might attempt to connect to the public network, although they are deployed to your private network. In some cases, such as Zerto Virtual Replication or FortiGate-VM, this connection is required for licensing or to report usage. These components are configured to connect either by using the instance NAT or a proxy you provide. You might need to allow these connections in your firewall. In other cases, these connection attempts are only for diagnostic and usage data, and the connections fail since no public connectivity is available or configured.\n* Using NSX with your virtual machines\n\nDuring vCenter Server instance deployment, VMware NSX\u00ae is ordered, installed, licensed, and configured in your instance. Also, NSX Manager, VMware NSX Controllers\u2122, and NSX Transport Zone are set up, and each VMware ESXi\u2122 server is configured with the NSX components.\n\nAn VMware NSX Edge\u2122 Services Gateway is also deployed to be used by your workload VM or VMs. For more information, see [Configuring your network to use the customer-managed NSX ESG with your VMs](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_esg_config).\n* Considerations when you change passwords for NSX-T components\n\n Considerations when you change passwords for NSX-T components \n\n\n\n* Do not change the NSX Manager admin password for NSX-T.\n* You can change the NSX Manager root password. This password is not displayed in the VMware Solutions console. However, the password is the same as the one for the root user for NSX Controllers, which is displayed in the console.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-312712-314663","score":18.7098560333,"text":"\nIf you're using firewalls, you must configure rules for all communications from the IBM\u00ae CloudDriver virtual server instance (VSI) and the SDDC Manager virtual machines (VMs). These rules must allow all protocols to communicate on the IP addresses 10.0.0.0\/8 and 161.26.0.0\/16. Examples of such firewalls are NSX Distributed Firewalls (DFW) or vSRX gateway cluster firewalls.\n\nSome components might attempt to connect to the public network, although they are deployed to your private network. In some cases, such as Zerto Virtual Replication or FortiGate-VM, this connection is required for licensing or to report usage. These components are configured to connect either by using the instance NAT or a proxy you provide. You might need to allow these connections in your firewall. In other cases, these connection attempts are only for diagnostic and usage data, and the connections fail since no public connectivity is available or configured.\n* Using NSX with your virtual machines\n\nDuring vCenter Server instance deployment, VMware NSX\u00ae is ordered, installed, licensed, and configured in your instance. Also, NSX Manager, VMware NSX Controllers\u2122, and NSX Transport Zone are set up, and each VMware ESXi\u2122 server is configured with the NSX components.\n\nAn VMware NSX Edge\u2122 Services Gateway is also deployed to be used by your workload VM or VMs. For more information, see [Configuring your network to use the customer-managed NSX ESG with your VMs](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_esg_config).\n* Considerations when you change passwords for NSX-T components\n\n Considerations when you change passwords for NSX-T components \n\n\n\n* Do not change the NSX Manager admin password for NSX-T.\n* You can change the NSX Manager root password. This password is not displayed in the VMware Solutions console. However, the password is the same as the one for the root user for NSX Controllers, which is displayed in the console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_04119-1639-3490","score":18.4339408875,"text":"\nIn general, firewall rules are designed for properties exposed in OSI Layer 7 (HTTP), such as request headers and body content characteristics.\n\n\n\n\n\n Adding an application using the console \n\nFollow these steps to add an application using the UI.\n\nIn the console, UDP applications must be enabled through a Support case. After the functionality is enabled, you can create a UDP application through the CLI or API.\n\n\n\n1. Navigate to Security > Range.\n2. Click Create.\n3. Select a type of application from the list menu. You can choose TCP, UDP, HTTP, HTTPS, RDP, SSH, or Minecraft.\n4. Enter the application name. Your application becomes associated with a DNS name on your CIS domain.\n5. Enter the edge port. CIS listens for incoming connections to these addresses on this port. Connections to these addresses are proxied to your origin. You can enter a port range (for example: 8080-8090), but the origin must have the same quantity of ports specified in a consecutive range.\n6. Select the edge IP connectivity.\n7. In the Origin section, enter the origin IP and port of your TCP application. You can also select an existing load balancer and its port.\n8. Enable IP firewall (optional). When enabled, firewall rules with a \"block\" or \"allowlist\" action are enforced for this application.\n9. Enable edge TLS termination (optional). When enabled, select the type of TLS termination you want to use from the list menu.\n10. Select a [PROXY Protocol](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-enable-proxy-protocol) if you have a proxy in-line that supports PROXY Protocol (optional). This feature is useful if you are running a service that requires knowledge of the true client IP. In most cases, this setting remains off.\n11. Click Create.\n\n\n\nProvisioning a Range application incurs additional costs, based on the amount of bandwidth used per application.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-range"},{"document_id":"ibmcld_13915-4792-6873","score":18.1968631744,"text":"\nFor example, allowing backend subnets inbound on dp0bond0 would be less work than allowing backend subnets outbound toward each VLAN virtual interface.\n\n\n\n Per-interface firewall rules \n\nOne method for configuring the firewall on a VRA is to apply firewall rule sets to each interface. In this case an interface can be a dataplane interface (dp0s0) or a virtual interface (dp0bond0.303). Each interface has three possible firewall assignments:\n\nin - The firewall is checked against packets entering through the interface. These packets can be traversing or be destined for the VRA.\n\nout - The firewall is checked against packets leaving through the interface. These packets can be traversing or originating on the VRA.\n\nlocal - The firewall is checked against packets which are destined directly for the VRA.\n\nAn interface can have multiple rule sets applied in each direction. They are applied in the order of configuration. Note that it is not possible to firewall traffic originating from the VRA device using per-interface firewalls.\n\nAs an example, to assign the ALLOW_LEGACY rule set to the in option for the bp0s1 interface, you would use the configuration command:\n\nset interfaces dataplane dp0s1 firewall in ALLOW_LEGACY\n\n\n\n\n\n\n\n Control Plane Policing (CPP) \n\nControl plane policing (CPP) provides protection against attacks on the IBM Cloud\u00ae Virtual Router Appliance by allowing you to configure firewall policies that are assigned to desired interfaces and applying these policies to packets entering the VRA.\n\nCPP is implemented when the local keyword is used in firewall policies that are assigned to any type of VRA interface, such as data plane interfaces or loopback. Unlike the firewall rules applied for packets traversing through the VRA, the default action of firewall rules for traffic entering or leaving the control plane is Allow. Users must add explicit drop rules if the default behavior is not desired.\n\nThe VRA provides a basic CPP rule set as template. You can merge it into your configuration by running:\n\nvyatta@vrouter merge \/opt\/vyatta\/etc\/cpp.conf","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"},{"document_id":"ibmcld_13915-3198-5235","score":17.6710891724,"text":"\nset security firewall name ALLOW_LEGACY rule 1 action drop\nset security firewall name ALLOW_LEGACY rule 1 source address network-group1\nset security firewall name ALLOW_LEGACY rule 2 action drop\nset security firewall name ALLOW_LEGACY rule 2 destination port 23\nset security firewall name ALLOW_LEGACY rule 2 log\nset security firewall name ALLOW_LEGACY rule 2 protocol tcp\nset security firewall name ALLOW_LEGACY rule 2 source address network-group2\n\nIn the ruleset, ALLOW_LEGACY, there are two rules defined. The first rule drops any traffic sourced from an address group named network-group1. The second rule discards and logs any traffic destined for the telnet port (tcp\/23) from the address group named network-group2. The default-action indicates that anything else is accepted.\n\n\n\n\n\n Allowing data center access \n\nIBM\u00a9 offers several IP subnets to provide services and support to systems running within the data center. For example, DNS resolver services are running on 10.0.80.11 and 10.0.80.12. Other subnets are used during provisioning and support. You can find the IP ranges used in the data centers in [this topic](https:\/\/cloud.ibm.com\/docs\/hardware-firewall-dedicated?topic=hardware-firewall-dedicated-ibm-cloud-ip-ranges).\n\nYou can allow data center access by placing the proper SERVICE-ALLOW rules at the beginning of the firewall rule sets with an action of accept. Where the rule set must be applied depends on the routing and firewall design being implemented.\n\nIt is recommended that you place the firewall rules in the location which causes the least duplication of work. For example, allowing backend subnets inbound on dp0bond0 would be less work than allowing backend subnets outbound toward each VLAN virtual interface.\n\n\n\n Per-interface firewall rules \n\nOne method for configuring the firewall on a VRA is to apply firewall rule sets to each interface. In this case an interface can be a dataplane interface (dp0s0) or a virtual interface (dp0bond0.303). Each interface has three possible firewall assignments:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"},{"document_id":"ibmcld_13915-6476-8449","score":17.6643848419,"text":"\nUnlike the firewall rules applied for packets traversing through the VRA, the default action of firewall rules for traffic entering or leaving the control plane is Allow. Users must add explicit drop rules if the default behavior is not desired.\n\nThe VRA provides a basic CPP rule set as template. You can merge it into your configuration by running:\n\nvyatta@vrouter merge \/opt\/vyatta\/etc\/cpp.conf\n\nAfter this rule set is merged, a new firewall rule set named CPP is added and applied to the loopback interface. It is recommend that you modify this rule set to suit your environment.\n\nPlease note that CPP rules cannot be stateful, and will only apply on ingress traffic.\n\n\n\n\n\n Zone firewalling \n\nAnother firewall concept within the IBM Cloud\u00ae Virtual Router Appliance is zone based firewalls. In zone-based firewall operation an interface is assigned to a zone (only one zone per interface) and firewall rule sets are assigned to the boundaries between zones with the idea that all interfaces within a zone have the same security level and are allowed to route freely. Traffic is only scrutinized when it is passing from one zone to another. Zones drop any traffic coming into them which is not explicitly allowed.\n\nAn interface can either belong to a zone or have a per-interface firewall configuration; an interface cannot do both.\n\nImagine the following office scenario with three departments, each department with its own VLAN:\n\n\n\n* Department A - VLANs 10 and 20 (interface dp0bond1.10 and dp0bond1.20)\n* Department B - VLANs 30 and 40 (interface dp0bond1.30 and dp0bond1.40)\n* Department C - VLAN 50 (interface dp0bond1.50)\n\n\n\nA zone can be created for each department and the interfaces for that department can be added to the zone. The following example illustrates this:\n\nset security zone-policy zone DEPARTMENTA interface dp0bond1.10\nset security zone-policy zone DEPARTMENTA interface dp0bond1.20\nset security zone-policy zone DEPARTMENTB interface dp0bond1.30","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"},{"document_id":"ibmcld_15540-1696-3731","score":17.460193634,"text":"\nThis step adds another level of security.\n\nAnother alternative is to use allow rules to define access to particular users or groups. Allow rules require you to decide what software needs access to instance metadata. By defining rules, you can prevent software from accidentally accessing the metadata service if you later change the software or configuration on the instance.\n\nYou can also define group usage of the allow rules. Add and remove users from a permitted group without changing the firewall rule.\n\nThe following example prevents access to the instance metadata service by all processes, except for processes that are running in the user account trustworthy-user:\n\nsudo iptables --append OUTPUT --proto tcp --destination 169.254.169.254 --match owner ! --uid-owner trustworthy-user --jump REJECT\n\n\n\n\n\n Limit trusted profiles for compute resource identities \n\nLimit trusted profiles that you create for compute resource identities. Optionally, don't assign a compute resource identity to an instance.\n\nWhen you [remove trusted profiles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-trusted-profile-remove), compute resources and federated users are unlinked from the profile, and can no longer apply the trusted profile identity.\n\nYou can also update existing trusted profiles by redefining the trust relationship, assigning access policies, and updating session limits. For more information, see [Updating trusted profiles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-trusted-profile-update).\n\n\n\n\n\n Additional network security measures \n\nConsider the following options for controlling network traffic to your virtual server instances:\n\n\n\n* Restrict access to your instances by using [security groups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-configuring-the-security-group).\n* Set up [access control lists](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-acls)(ACL) to control all incoming and outgoing traffic in IBM Cloud\u00ae Virtual Private Cloud. An ACL is a built-in, virtual firewall, similar to a security group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-imd-security-best-practices"},{"document_id":"ibmcld_14498-5055-6221","score":17.4148750305,"text":"\nConfigure the default firewall rule on the DLR to \"allow\"\n$dlr = Get-NsxLogicalRouter OpenShift-DLR\n$dlr.features.firewall.defaultpolicy.action = \"Accept\"\n$dlr | Set-NsxLogicalRouter -Confirm:$false\n\n Configure DHCP relay on DLR\n$dlrID = (Get-NsxLogicalRouter -Name \"OpenShift-DLR\").Id\n$internalLifVnicId = (Get-NsxLogicalRouter OpenShift-DLR | Get-NsxLogicalRouterInterface \"ToLS\").index\n$uri = \"\/api\/4.0\/edges\/$($dlrID)\/dhcp\/config\/relay\"\n$xmlPayload = \"\n<relay>\n<relayServer>\n<ipAddress>192.168.100.1<\/ipAddress>\n<\/relayServer>\n<relayAgents>\n<relayAgent>\n<vnicIndex>$($internalLifVnicId)<\/vnicIndex>\n<giAddress>192.168.133.1<\/giAddress>\n<\/relayAgent>\n<\/relayAgents>\n<\/relay>\"\n\n$null = invoke-nsxwebrequest -method \"put\" -uri $uri -body $xmlPayload -connection $nsxConnection\n\n Disconnect\nDisconnect-NsxServer\nShow more\n\n\n\n\n\n Related links \n\n\n\n* [Red Hat OpenShift Bastion node setup](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-bastion-intro)\n* [Red Hat OpenShift 4.7 user provider infrastructure installation](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-install-intro)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-nsxdlr-intro"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-2884-4620","score":14.3845176697,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7-1802","score":13.6862592697,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02689-1748-4183","score":13.5363483429,"text":"\nWithin your application, the isEnabled() method of the App Configuration SDK is used to activate conditional blocks of code to turn features on and off based on the state of a feature flag. Use feature flags to dark launch features into production and then switch them on only for selected users or roll them out to your users selectively and independently from deployments. Each feature flag must belong to a collection.\n\n\n\n\n\n Properties \n\nProperties are configuration parameters that don't change often, but that still need centralized management. Consolidate properties for all your app and environment components into one central cloud dashboard, with App Configuration, thus avoiding the hassle of managing multiple parameter files. Within your application, the getCurrentValue() method of the App Configuration SDK is used to access the current value of a property. Each property must belong to a collection.\n\n\n\n\n\n Segments \n\nUsing App Configuration, a single feature flag, or property, can have many values, with each value applied to a specific group of entities (users, devices, infrastructure components). Each group is called a segment. Members of a segment share one or more common attributes as defined by a set of segment rules. Segments are optional.\n\n\n\n\n\n Attribute \n\nAn attribute is a parameter that is used to define a segment. Attributes are used to create segment rules on the App Configuration dashboard, but names of the attributes and values of each attribute are defined in your code. At run time, the App Configuration SDK fetches the segment rules into your application instance and determine whether it is a part of the segment.\n\n\n\n\n\n Targeting definition \n\nFeature flags and properties are targeted to segments based on a set of rules that are called the targeting definition. With targeting, you can override the default value for a flag or property, for any segment you define.\n\n\n\n\n\n App Configuration SDK \n\nThe App Configuration SDK handles the automatic delivery of the appropriate flag state or property value into your application. It connects to the endpoints provided by the App Configuration API, fetches collections, and evaluates segment and targeting rules. Server-side SDKs connect to the App Configuration service through a web socket for real-time updates. Client-side SDKs pull values from the App Configuration service upon a lifecycle change such being opened or brought to the foreground.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-overview"},{"document_id":"ibmcld_12330-7-2140","score":12.6650104523,"text":"\nContent \n\n\n\n Languages \/ platforms \n\nEvery IBM Service that offers public APIs SHOULD offer SDKs for the languages \/ platforms most commonly used by developers that use the service.\n\n\n\n* Java, Node, Python, and Go are \"first-tier\" languages that should have SDK support.\n* iOS and Android SDKs are important for services that may be used from mobile devices.\n* Other languages that may warrant SDK support in particular domains are C#, Ruby, Scala.\n\n\n\n\n\n\n\n Basic interface \n\nThe SDK SHOULD provide a basic interface that maps directly onto the operations of the underlying API. Each method of an SDK SHOULD correspond to exactly one operation of the underlying API, and this relationship should be clear from design of the API.\n\nOperations whose functionality is fully supported by a related operation SHOULD be omitted. This can occur, for example, when an operation is exposed with both a GET and an POST method, where the GET offers a subset of the features of the POST but with a simpler interface.\n\n\n\n\n\n Methods \n\nMethods MUST employ a flexible parameter-passing design that allows optional parameters to be added to a method without causing incompatibility with applications using the prior version of the method.\n\nIn some languages this can be accomplished using standard language features like default parameter values, but in other languages (e.g. Java) the method parameters must be encapsulated into an \"options\" object.\n\n\n\n\n\n Streaming \n\nFor a language\/runtime that supports stream value types:\n\n\n\n* The SDK SHOULD allow any potentially large input value to a method to be supplied as a stream.\n* The SDK SHOULD allow the result of a method to be returned as a stream if that value may be large.\n\n\n\n\n\n\n\n Asynchronous method calls \n\nThe SDK MUST support asynchronous invocation of any method that performs a network operation. The SDK SHOULD support synchronous or pseudo-synchronous (e.g. async\/await) invocation of methods that perform network operation in languages where this method style is idiomatic.\n\n\n\n\n\n Instrumentation \n\nThe SDK SHOULD be instrumented so that relevant usage data can be collected by the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-content"},{"document_id":"ibmcld_10817-6582-8092","score":12.3522853851,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_13429-166159-168045","score":12.1597032547,"text":"\nNew UK English and Arabic models\n: The service supports more languages with its transcription models: en-UK_BroadbandModel and en-UK_NarrowbandModel for UK English, and ar-AR_BroadbandModel for Modern Standard Arabic. For more information, see [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models).\n\nNew session_closed field for session-based methods\n: In the JSON responses that it returns for errors with session-based methods, the service now also includes a new session_closed field. The field is set to true if the session is closed as a result of the error. For more information about possible return codes for any method, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nHTTP platform timeout no longer applies\n: HTTP recognition requests are no longer subject to a 10-minute platform timeout. The service now keeps the connection alive by sending a space character in the response JSON object every 20 seconds as long as recognition is ongoing. For more information, see [Timeouts](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtimeouts).\n\nRate limiting with curl command no longer needed\n: When you use the curl command to transcribe audio with the service, you no longer need to use the --limit-rate option to transfer data at a rate no faster than 40,000 bytes per second.\n\nChanges to HTTP error codes\n: The service no longer returns HTTP status code 490 for the session-based HTTP methods GET \/v1\/sessions\/{session_id}\/observe_result and POST \/v1\/sessions\/{session_id}\/recognize. The service now responds with HTTP status code 400 instead.\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile SDKs are available for the speech services. The SDKs enable mobile applications to interact with both the Speech to Text and Text to Speech services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_02674-7-1766","score":12.1323633194,"text":"\nApp Configuration server SDK for Go \n\nApp Configuration service provides SDK to integrate with your Golang web and mobile applications, microservices, and distributed environments.\n\n\n\n Prerequisites \n\nFollowing is the prerequisite for using App Configuration service SDK for Go:\n\n\n\n* Go version 1.16 or later\n\n\n\n\n\n\n\n Integrating server SDK for Go \n\nThe v1.x.x versions of the App Configuration Go SDK have been retracted.\n\nApp Configuration service provides SDK to integrate with your Golang web and mobile applications, microservices, and distributed environments. You can evaluate the values of your property and feature flag by integrating the App Configuration SDK.\n\n\n\n1. Install the SDK by using the following code from the git repository.\n\ngo get -u github.com\/IBM\/appconfiguration-go-sdk@latest\n2. In your Golang microservice or application, include the SDK module with:\n\nimport (\nAppConfiguration \"github.com\/IBM\/appconfiguration-go-sdk\/lib\"\n)\n\nRun go mod tidy to download and install the new dependency and update your Go application's go.mod file.\n3. Initialize the SDK to connect with your App Configuration service instance.\n\ncollectionId := \"airlines-webapp\"\nenvironmentId := \"dev\"\n\nappConfiguration = AppConfiguration.GetInstance()\nappConfiguration.Init(\"region\", \"guid\", \"apikey\")\nappConfiguration.SetContext(\"collectionId\", \"environmentId\")\n\nWhere,\n\n\n\n* region: Region name where the service instance is created. Use AppConfiguration.REGION_US_SOUTH for Dallas, AppConfiguration.REGION_US_EAST for Washington DC, AppConfiguration.REGION_EU_GB for London, and AppConfiguration.REGION_AU_SYD for Sydney.\n* guid: Instance ID of the App Configuration service. Get it from the service credentials section of the App Configuration service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-golang"},{"document_id":"ibmcld_02698-7-1759","score":11.9423389435,"text":"\nIntegrating SDKs \n\nThe App Configuration client SDK is available for Android, JavaScript, and React, the server SDKs for Node, Python, Go, and Java, and the admin SDK for Go, to integrate with your web and mobile applications, microservices, and distributed environments.\n\n\n\n Client-side and Server-side SDKs \n\nUnderstand the differences between the various SDKs so that you can decide between SDK types for your use case.\n\n\n\n Types of SDKs \n\nSDKs supported by App Configuration include:\n\n\n\n* Server-side SDK\n* Client-side SDK\n* Admin SDK\n\n\n\nSDKs that help evaluate feature flag and property values are broadly classified as Server-side or Client-side - based on the deployment environment. These SDKs can be integrated into your application to assess the feature or property values by considering segment targeting rules, if any.\n\nEvaluation SDKs fetch the latest configuration data from the App Configuration service and ensure that any change in the service configuration is made available to your application in real time.\n\nAdmin SDKs can be used to create and manage configurations for Environments, Collections, Feature flags, Properties, and Segments. As an option to IBM Cloud Dashboard or IBM Cloud CLI, Admin SDKs can be used to programmatically manage your service configuration from within your application.\n\nThe currently available Go language Admin SDK integrates with your Go application.\n\nDifferences between client-side and server-side SDKs:\n\n\n\nTable 1. List of App Configuration server, client, and admin SDKs\n\n SDK type Details Links to SDKs and integration docs \n\n Server side These SDKs are designed for multi-user systems and are intended to be used in a trusted environment, such as inside a corporate network or on a web server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-sdks"},{"document_id":"ibmcld_10805-1522-3235","score":11.8576564789,"text":"\nTo control inbound traffic, you might want to grant access to other users such as assigning Reader role to invoke actions. \n API key An API Key for the service ID that can be used to generate IAM tokens. You can use the tokens to authenticate the namespace with other IBM Cloud services. The API key is provided to actions as the environment variable __OW_IAM_NAMESPACE_API_KEY. \n\n\n\nYou can view a list of your service IDs by running the following command.\n\nibmcloud iam service-ids\n\nYou can view the API keys that are associated with a service ID by running the following command.\n\nibmcloud iam service-api-keys <ServiceID-12345678-1234-abcd-1234-123456789abc>\n\nDo not delete service IDs or API keys.\n\n\n\n\n\n Are there any limitations for namespaces? \n\nThe [mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk) is not supported for IAM-managed namespaces.\n\nThe names of all entities, including actions, triggers, rules, packages, and namespaces, are a sequence of characters that follow the following format:\n\n\n\n* The first character must be an alphanumeric character, or an underscore.\n* The subsequent characters can be alphanumeric, spaces, or any of the following values: _, @, ., -.\n* The last character can't be a space.\n\n\n\n\n\n\n\n What do I do if I have a Cloud Foundry-based namespace? \n\nYour Cloud Foundry-based namespaces still work. However, to take advantage of new features, you must create an IAM-enabled namespace.\n\n\n\n\n\n How do I see a list of my Cloud Functions namespaces? \n\nYou can see a list of your Cloud Functions namespaces by running the [namespace list](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_namespace_list) command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespaces"},{"document_id":"ibmcld_10820-21590-23317","score":11.7865819931,"text":"\n* For batch requests, each object change is handled individually and the trigger is fired for each successful change event.\n* All characters are permitted in an object key except for ASCII control character NUL.\n* Naming limitations for Cloud Functions triggers can be found on the [System details and limits](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-limitslimits_fullnames) page.\n\n\n\n\n\n\n\n\n\n\n\n Configuring the IBM Cloud Object Storage package \n\nAfter you have [created an IBM Cloud Object Storage service instance](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-gs-devgs-dev-provision) and [created at least one bucket](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storagegs-create-buckets), you can install the IBM Cloud Object Storage package into your namespace to work with your buckets and objects.\n\nThe installable IBM Cloud Object Storage package deploys a set of pre-built actions that you can use to work with your IBM Cloud Object Storage buckets and objects. These actions are executed in either Node.js or Python. You can select a runtime when you install the package. If you want to use a different runtime, you can use the [COS SDK](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-sdk-gs). You can also [build your own actions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-actions) or [web actions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-actions_web) to respond to the trigger.\n\nFor a list of the actions in the cloud-object-storage package, see [Available entities](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_actions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorage"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":20.9575519562,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-1342-3184","score":20.3666629791,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-4213-5899","score":20.1343402863,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-7-1743","score":17.8041553497,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_07551-14062-16080","score":15.5721101761,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10852-43319-44485","score":15.0850124359,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_04518-1426-3052","score":14.4313545227,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_12332-1034-2510","score":14.171957016,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_06805-51238-53254","score":13.8726577759,"text":"\nIf both of them are provided, --git-token-path and --git-api-url take precedence.\n\nReturn values:\n\n\n\n* The command lists incident issue URLs found or created according to the result file and subject.\n* If no issues are found, or all found issues have either Exempt or Grace period set, the command exits with zero status.\n* If any of the issues that are found have no Exempt or Grace Period set, the command exits with a nonzero status.\n\n\n\nRunning the command:\n\n$ cocoa incident process --type va --subject us.icr.io\/service-image --drilldown-url us.icr.io\/service-image@sha256:digest path\/to\/scan-result.json\n\n\n\n\n\n cocoa incident process-legacy \n\nThis command creates incident issues in the provided repository for scenarios when a scan file isn't available. Typically, such scenarios would be non-vulnerability related failures like unit-test failure, branch protection failure, acceptance test failure, and image signing failure. These failures would be non-vulnerabilities, yet they would be a deviation from the compliance posture. If issues exist already for incident-subject-tool combinations, the command does not create new ones. By default, high severity rating is set to issues created.\n\nIf --set-due-date is set, the command either creates issues, or updates existing issues with due dates. The due dates are calculated from the grace period of the issue, based on the severity.\n\nIf --close-resolved-issues flag is set, the command searches for open issues with the same tool, subject and the incident ID as the current run. If there are any issues found, while the --current-status was passed as success, the command closes those issues.\n\nIf --read-only is set, the command does not create new issues or amend existing ones. Results are processed, and existing issues are collected for results. The output contains the issue URL list that are supposed to be tracked in issues if the read-only mode is not activated.\n\nUsage:\n\ncocoa incident process-legacy <options>\n\nOptions:\n\n--type (Required) Tool type","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cli"},{"document_id":"ibmcld_05088-32788-34517","score":13.061255455,"text":"\nSolution: The first step to resolving this issue would be to reinstall the Aspera libraries. There might have been a failure during the installation. As a result this might have affected the DLL files. If that does not resolve the issues, then you will be required to update your version of Python. If you are unable to do this, then you can use installation [Intel\u00ae Distribution for Python*](https:\/\/software.intel.com\/en-us\/distribution-for-python). This should allow you to install the Aspera SDK on Python 3.6.x without any issues.\n\n\n\n\n\n\n\n Updating metadata \n\nThere are two ways to update the metadata on an existing object:\n\n\n\n* A PUT request with the new metadata and the original object contents\n* Running a COPY request with the new metadata specifying the original object as the copy source\n\n\n\n\n\n Using PUT to update metadata \n\nNote: The PUT request overwrites the existing contents of the object so it must first be downloaded and re-uploaded with the new metadata.\n\ndef update_metadata_put(bucket_name, item_name, key, value):\ntry:\n retrieve the existing item to reload the contents\nresponse = cos_cli.get_object(Bucket=bucket_name, Key=item_name)\nexisting_body = response.get(\"Body\").read()\n\n set the new metadata\nnew_metadata = {\nkey: value\n}\n\ncos_cli.put_object(Bucket=bucket_name, Key=item_name, Body=existing_body, Metadata=new_metadata)\n\nprint(\"Metadata update (PUT) for {0} Complete!n\".format(item_name))\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nlog_error(\"Unable to update metadata: {0}\".format(e))\nShow more\n\n\n\n\n\n Using COPY to update metadata \n\ndef update_metadata_copy(bucket_name, item_name, key, value):\ntry:\n set the new metadata\nnew_metadata = {\nkey: value","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.9674679835,"ndcg_cut_10":0.9674679835}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":20.8771266937,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-1342-3184","score":20.2943611145,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-4213-5899","score":20.1568202972,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-7-1743","score":17.7717475891,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_07551-14062-16080","score":16.411239624,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10852-43319-44485","score":14.5260305405,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_04518-1426-3052","score":14.4989585876,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_12332-1034-2510","score":13.5568723679,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10817-2884-4620","score":12.6337652206,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_13900-52291-53957","score":11.2272558212,"text":"\nVRVDR-51828 Major SIAD ACL: BCM SDK error when deleting ACL configuration \n VRVDR-51639 Critical Response for \"request hardware-diag version\" takes much longer with 1912b \n VRVDR-51619 Critical SIAD ACL: Ensure that rulesets which would exceed the TCAM are rejected \n VRVDR-51616 Critical Storm Control triggered snmpd warning messages in journal \n VRVDR-51543 Critical IPsec peers stuck in 'init' state after upgrade from 1801q to 1912d \n VRVDR-51539 Critical Repeated FAL BCM \"L3 Interface\" for VSI 0 Syslog \n VRVDR-51521 Critical NAT64 opd yang file missing required type field in 1908 and 1912 \n VRVDR-51518 Critical Dataplane performance fails for forward pkts when scatter mode driver is used \n VRVDR-51483 Major Removing guest configuration fails with scripting error \n VRVDR-51385 Critical Dataplane Crash in next_hop_list_find_path_using_ifp \n VRVDR-51348 Major libsnmp-dev built from DANOS\/net-snmp is not API compatible with libsnmp-dev from upstream \n VRVDR-51345 Critical S9500-30XS: 100G Interface LED lit even when disabled \n VRVDR-51311 Blocker DAS Switch with 1912b seeing low rate of drops vs 1903m \n VRVDR-51295 Critical Changing speed on interface resets configured MTU to default \n VRVDR-51247 Major S9500 - missing hw_rev.cfg file \n VRVDR-51238 Major After broadcast storm, TACACS doesn't recover \n VRVDR-51185 Blocker Link doesn't come up after swapping 1000BASE-T SFP for 1000BASE-X SFP \n VRVDR-51183 Major 'FAL neighbor del' log is generated by dataplane for each ARP received for an unknown address \n VRVDR-51179 Critical live-cd installs should not install all unique state \n VRVDR-51148 Critical S9500 interface flaps when MTU is modified","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-ciena-vyatta-5600-vrouter-software-patches"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.9674679835,"ndcg_cut_10":0.9674679835}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":19.6388301849,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-1426-3052","score":16.8051891327,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_02772-4213-5899","score":16.8017711639,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-7-1743","score":16.4361801147,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-7-1802","score":15.6536188126,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_06805-40466-41942","score":13.6989908218,"text":"\n$ cocoa inventory add --environment=environment --artifact=foo-helm-chart\/foo\/chart.yaml --repository-url=http:\/\/validURL.com --commit-sha=786800e8e48938664fe2397ca14ab8dabd48f34656ef5cfda4143b4519cb714f --build-number=33 --pipeline-run-id=123123valid --version=v4 --name=chart\n\n\n\n\n\n cocoa inventory get \n\nGets an entry from the inventory repository. The target can be a specific version or an environment. Either use --version or --environment, and use only one of them. If the --property option is missing, the whole content of the inventory entry is printed.\n\nRequired Environment Variables, if you are using GitHub:\n\nGHE_TOKEN= Github Enterprise API Token (Optional if you are using --git-token-path)\n\nOptions for Git:\n\n--git-token-path (Optional) Github Token's path\n--git-api-url (Optional) Github API url\n\nIf you are using github, use --git-token-path field to set your GitHub Token and --git-api-url field to set the # GitHub Enterprise API URL instead of GHE_TOKEN and GH_URL environment variables. If both GHE_TOKENGH_URL and --git-token-path--git-api-url pairs are provided, then --git-token-path and --git-api-url take precedence.\n\nBy default, the CLI on each invocation ensures that you work with an up-to-date version of a Git locker. This behavior can be disabled by setting COCOA_USE_CACHE to any value except 0, false, no, or n. In this case, the CLI uses its internal cache to look up evidence (much faster), but results might be stale.\n\nRunning the command:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cli"},{"document_id":"ibmcld_06805-30750-32555","score":13.5618124008,"text":"\ncocoa evidence upload --backend=git --artifact <url> <hash> --artifact <url> <hash> --issue <issue-url> --issue <issue-url> --git-provider='github'\n\nartifact consists of a URL that points to the artifact file and a hash, provide these items in the same way as in the previous example.\n\n\n\n\n\n cocoa evidence summarize \n\nQueries evidence from the Evidence Locker and generates an Evidence Summary from their contents. Backends can be different evidence locker types, such as Object Storage or GitHub. Currently, git and cos are supported as backend. Different lockers require different parameters to be provided.\n\nRequired Environment Variables for Git:\n\nEVIDENCE_REPO_ORG= Use this environment varibale to provide the owner organisation of the evidence repository (Required if you are using 'git' backend)\nEVIDENCE_REPO_NAME= Use this environment varibale to provide the name of the evidence repository (Required if you are using 'git' backend)\nPIPELINE_RUN_ID= Can be used instead of '--pipeline-run-id' option\nTOOLCHAIN_CRN= Can be used instead of '--toolchain-crn' option\n\nRequired Environment Variables, if you are using GitHub:\n\nGHE_TOKEN= Github Enterprise API Token (Optional if you are using --git-token-path)\n\nOptions for Git:\n\n--backend (Required) Specifies the type of locker from where the evidences are queried\n--repo Evidence Repositories name (can be substituted by EVIDENCE_REPO_NAME environment variable)\n--org Evidence Repositories owner organisation (can be substituted by EVIDENCE_REPO_ORG environment variable)\n--pipeline-run-id (Required)\n--toolchain-crn (Required)\n--prefix-list (Required) a list of paths separated by comma where evidences can be found in the repository\n--output (Optional) file name to write the evidence summary into\n--git-token-path (Optional) Github Token's path","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cli"},{"document_id":"ibmcld_12332-1034-2510","score":13.4022369385,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_05525-71248-72155","score":12.7356557846,"text":"\nInstead, you can use [Kubernetes admission webhooks](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/extensible-admission-controllers\/).<br><br><br> \n Kubernetes DNS autoscaler 1.3.0 1.4.0 See the [Kubernetes DNS autoscaler release notes](https:\/\/github.com\/kubernetes-sigs\/cluster-proportional-autoscaler\/releases\/tag\/1.4.0). \n Kubernetes feature gates configuration N\/A N\/A <br><br> * Added RuntimeClass=false to disable selection of the container runtime configuration.<br> * Removed ExperimentalCriticalPodAnnotation=true because the scheduler.alpha.kubernetes.io\/critical-pod pod annotation is no longer supported. Instead, you can use [Kubernetes pod priority](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod_prioritypod_priority).<br><br><br> \n Trusted compute agent e132aa4 e7182c7 Updated image for [CVE-2019-11068](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2019-11068).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-114_changelog"},{"document_id":"ibmcld_06805-47399-49182","score":12.5290298462,"text":"\nGHE_REPO= Can be used instead of --repo (either the option or the variable is required)\nPIPELINE_RUN_URL= Can be used instead of --pipeline-run-url (either the option or the variable is required)\nAPP_REPO_URL= Can be used instead of --app-repo-url (either the option or the variable is required)\n\nRequired Environment Variables, if you are using GitHub:\n\nGHE_TOKEN= Github Enterprise API Token (Optional if you are using --git-token-path)\n\nIf you are using github, use --git-token-path field to set your GitHub Token and --git-api-url field to set the # GitHub Enterprise API URL instead of GHE_TOKEN and GH_URL environment variables. If both of them are provided, --git-token-path and --git-api-url take precedence.\n\nRunning the command:\n\ncocoa incident add --task=<failing-task-name> --commit-hash=<abc123>\n\n\n\n\n\n cocoa incident process \n\nThis command processes provided scan results and creates incident issues in the provided repository per vulnerability (not per task run like cocoa incident add does). If issues exist already for subject-incident pairs, it does not create new ones.\n\nIf --set-grace-period is set, it creates issues with Grace Period set, or update existing issues, to have Grace Period.\n\nGrace Period is set to 15 days if enabled. If Exempt or Grace Period is set on an incident issue, the check lists the issue, but does not mark it as an error.\n\nExceptions are either configured in CR VA, or you can submit the Incident or CVE for an exemption approval. If approved, you can edit the Incident issue (setting Excempt: true), and link to the approved request.\n\nCurrently supported scan result files:\n\n\n\n* Container Registry VA scan (option --type va)\n* CRA Vulnerability scan (option --type cra)\n* Xray (option --type xray)\n* OWASP ZAP (option --type owasp-zap)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cli"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.9469024295,"ndcg_cut_10":0.9469024295}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":25.3073616028,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-15747-17355","score":22.979927063,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10817-7-1802","score":22.764629364,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-14062-16080","score":22.6205158234,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_04518-7-1743","score":21.917345047,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_04518-1426-3052","score":21.7540493011,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-44214-45420","score":21.026309967,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10852-43319-44485","score":18.4070930481,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-2884-4620","score":18.0975093842,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12332-1034-2510","score":17.5407409668,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.703918089,"ndcg_cut_10":0.871078544}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03036-7-2061","score":15.5903787613,"text":"\nMetrics overview \n\nThe Overview page provides a summary of the interactions between users and your assistant. You can view the amount of traffic for a given time period, as well as the intents and entities that were recognized most often in user conversations.\n\nThe Analytics page was introduced with version 1.5.0. The Analytics feature is supported only on clusters that are installed on Red Hat OpenShift 4.5 or later.\n\nUse the metrics to answer questions like:\n\n\n\n* What was the average number of conversations per week during the last month?\n* How often did customers need to go elsewhwere for support?\n* Which intents appeared most often last week?\n* Which entity values were recognized the most times during February?\n* Which days had the largest or smallest numbers of conversations in the last month?\n\n\n\nTo see metrics information, select Overview in the navigation bar.\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter. In each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_00324-12617-14618","score":12.9869384766,"text":"\nMetrics with graphical views \n\nMetrics for an individual CDN are provided on the Overview tab of the customer portal for that CDN mapping. Two types of metrics are calculated from the CDN's usage: those that show the metrics over a time period as a graph, and those that are shown as aggregate values.\n\nFor metrics that display the change over a period of time as a graph, you can see three line graphs and a pie chart. The three line graphs are: Bandwidth, Hits by Mapping, and Hits by Type. They display the activity daily over the course of your specified timeframe. The graphs for Bandwidth and Hits by Mapping are single-line graphs, whereas the breakdown of Hits by Type shows a line for each of the hit types provided. The pie chart displays a regional breakdown of the bandwidth for a CDN mapping on a percentage basis.\n\nMetrics that are shown for aggregate values include Bandwidth Usage in GB, Total Hits to the CDN Edge server, and the Hit Ratio. Hit Ratio indicates that the percentage of times content is delivered by the Edge server, not through its origin. Hit ratio currently is shown as a function of all your CDN mappings, not just the one being viewed.\n\nBy default, both the aggregate numbers and the graphs default to show metrics for the last 30 days, but you can change this through the [IBM Cloud console](https:\/\/cloud.ibm.com\/). Both categories can display metrics for 7-, 15-, 30-, 60-, or 90-day periods.\n\n\n\n\n\n Object storage origin support \n\nIBM Cloud CDN can be configured to serve content from an object storage endpoint by providing the endpoint, the bucket name, protocol, and port. Optionally, you can specify a list of file extensions to allow caching for files only with those extensions. All objects in the bucket must be set with anonymous read or public read access.\n\nFor more information, see [Accelerate delivery of static files using a CDN](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-static-files-cdn).\n\n\n\n\n\n Path-based CDN mappings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-about-content-delivery-networks-cdn-"},{"document_id":"ibmcld_04612-2600-4714","score":11.2680311203,"text":"\nThe CPU utilization can be affected by the total workload of the hosting hardware and other factors.\n* Responsetime is the average amount of time that the app takes to respond to a request. Responsetime is specified in ms (milliseconds).\n* Throughput is the total number of the requests that are processed in a time period. Throughput is specified in rps (requests per second).\n* Custom_metric is your own custom metric. The Custom_metric name can be any alphanumeric value. Autoscaling is triggered when the corresponding metric is emitted to the App Autoscaler. For more information, see the [custom metric usage guide](https:\/\/github.com\/cloudfoundry\/app-autoscaler\/tree\/develop\/docsauto-scale-your-application-with-custom-metrics).\n\n\n\nIn addition to specifying the metric type, specify an operator, threshold, breach duration, adjustment, and cooldown period values.\n\nWhen the threshold is continuously breached during the breach duration period, and beyond the cooldown period, the App AutoScaler triggers the defined autoscaling action. The number or percentage of app instances is adjusted.\n\n\n\n* The operator can be >=, >, <=, or <.\n* The threshold must be a numeric value.\n* The breach duration is defined in seconds. The default value is 120 seconds.\n* The adjustment value specifies how the number of app instances change in each scaling action. You can specify an absolute number or a percentage of instances to add or remove.\n* The cooldown period specifies the time to wait before the taking the next autoscaling action. A cooldown period ensures that your app does not launch new instances or stop existing instances before your app is stable. The cooldown period is specified in seconds. The default cooldown period is 300 seconds.\n\n\n\n4. (Optional) Define Schedules to scale your app during a set time period.\n\nYou can define specific time periods when you know that your app requires different numbers of instances to handle peak loads. The schedule policy overwrites the default instance limits and sets the number of instances to the Initial Minimum Instance Count value for the scheduled period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-autoscale_cloud_foundry_apps"},{"document_id":"ibmcld_03036-1611-3443","score":11.2523860931,"text":"\nIn each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.\n\nThe time shown for each conversation is localized to reflect the time zone of your browser. However, API log calls are always shown in UTC time. As a result, if you choose a single day view, for example, the time shown in the visualization might differ from the timestamp specified in the log for the same conversation.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-time2.png)\n* Intents and Entities filters - Use either of these drop-down filters to show data for a specific intent or entity in your skill.\n\nThe intent and entities filters are populated by the intents and entities in the skill, and not what is in the data source. If you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_04162-7-1319","score":11.1651802063,"text":"\nQuerying Edge Functions metrics with GraphQL \n\nThis example uses the GraphQL Analytics API to query for Edge Functions Metrics over a specified time period. You can query up to one week of data for dates up to three months ago.\n\nThe following API call requests an Edge Functions script's metrics over a one day period, and outputs the requested fields. Adjust the datetimeStart, datetimeEnd, accountTag, and scriptName variables as needed.\n\n\n\n The API call \n\nPAYLOAD='{ \"query\":\n\"query GetEdgeFunctionsAnalytics($accountTag: string, $datetimeStart: string, $datetimeEnd: string, $scriptName: string) {\nviewer {\naccounts(filter: {accountTag: $accountTag}) {\nworkersInvocationsAdaptive(limit: 100, filter: {\nscriptName: $scriptName,\ndatetime_geq: $datetimeStart,\ndatetime_leq: $datetimeEnd\n}) {\nsum {\nsubrequests\nrequests\nerrors\n}\nquantiles {\ncpuTimeP50\ncpuTimeP99\n}\ndimensions{\ndatetimeHour\nscriptName\nstatus\n}\n}\n}\n}\n}\",\n\"variables\": {\n\"accountTag\": \"90f518ca7113dc0a91513972ba243ba5\",\n\"datetimeStart\": \"2020-05-04T00:00:00.000Z\",\n\"datetimeEnd\": \"2020-05-04T00:00:00.000Z\",\n\"scriptName\": \"edge-function-subrequest-test-client\"\n}\n}'\n\ncurl -X POST -H \"Content-Type: application\/json\" -H \"Authorization: IBM IAM TOKEN\" --data \"$(echo $PAYLOAD)\" https:\/\/api.cis.cloud.ibm.com\/v1\/<crn>\/zones\/<zoneid>\/graphql\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-edge-func"},{"document_id":"ibmcld_03036-5624-7724","score":11.1516857147,"text":"\n[Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were covered (meaning intents in your dialog understood user requests and were able to address them), and not covered (meaning the input did not match an intent in the dialog and was processed by the Anything else node instead).\n* The trend graph shows the percentage of daily conversations that were covered. This graph helps you to see if your dialog is getting better or worse at covering conversations over time.\n\n\n\n![Shows the two coverage metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/coverage-metric.png)\n\nThe coverage metric requires that your dialog contain an Anything else node.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_13129-7227-9128","score":10.8339338303,"text":"\nOnce the experiment completes running,\n\n\n\n1. Click on Pipeline comparison to view how the top pipelines compare.\n2. Sort the leaderboard by a different metric by clicking on the various column headers.\n3. Click a pipeline to view more detail about the metrics and performance.\n\nSorting by different metrics may not change the leaderboard rankings as the dataset used in this tutorial is very simple and used only for your understanding of the concepts. With other datasets, the rank may vary.\n4. Next to the model with Rank 1 when sorted by Accuracy, click on Save as > Model.\n5. Check the details of the model and click Create.\n6. From the received notification, click View in project.\n\n\n\nThe accuracy of the model will be improved in the later part of the tutorial.\n\n\n\n\n\n Step 4: Deploy and test your model \n\nIn this section, you will deploy the saved model and test the deployed model,\n\n\n\n1. Under the created model, click on Promote to deployment space.\n2. Under Target Space, select Create a new deployment space. You use deployment spaces to deploy models and manage your deployments.\n\n\n\n1. Set the Name to iris_deployment_space.\n2. Select the Object Storage service you use in previous steps and the machine-learning-tutorial service from the respective dropdowns.\n3. Click Create.\n\n\n\n3. Click on Promote.\n4. From the received notification, navigate to the deployment space.\n5. Under the deployment space, click on the name of the model you just created.\n6. Click the New deployment button.\n7. Select Online as the Deployment type, provide iris_deployment as the name and then click Create.\n8. Under Deployments tab, once the status changes to Deployed, Click on the Name of the new web service to check the details.\n\n\n\n\n\n Test the deployed model \n\n\n\n1. Under Test tab of your deployment, click on JSON input icon next to Enter input data and provide the JSONbelow as input.\n\n{\n\"input_data\": [{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model"},{"document_id":"ibmcld_13115-18852-20356","score":10.8182067871,"text":"\nIn the New Panel:\n\n\n\n1. Set the Metric to sysdig_container_net_http_request_time.\n2. Set Group by to container_id.\n\n\n\n3. Edit the Dashboard scope, set the filter to container_image, is and icr.io\/solution-tutorials\/tutorial-application-log-analysis:latest.\n4. Save the dashboard.\n\n\n\nZoom\n\n![New Dashboard](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution12\/new_dashboard.png)\n\nFigure 3. New dashboard\n\nTo add another panel:\n\n\n\n1. Use the Add Panel button in the dashboard.\n2. Change the panel type from Timechart to Number\n3. Set the Metric to sysdig_container_net_request_count.\n4. Set the Time Aggregation to Rate.\n5. Set the Group by to Sum.\n6. Enable Compare To and set the value to 1 Hour ago.\n7. Save the dashboard.\n\n\n\n\n\n\n\n\n\n Step 7: Remove resources \n\n\n\n* If you created them as part of this tutorial, remove the logging and monitoring instances from [Observability](https:\/\/cloud.ibm.com\/observe) page.\n* Delete the cluster including worker node, app and containers. This action cannot be undone.\n\nibmcloud ks cluster rm --cluster $MYCLUSTER -f --force-delete-storage\n\n\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-resource-reclamation).\n\n\n\n\n\n Expand the tutorial","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-application-log-analysis"},{"document_id":"ibmcld_15746-8362-10414","score":10.7934131622,"text":"\nNavigate to the [metrics monitoring portal](https:\/\/cloud.ibm.com\/observe\/monitoring).\n2. Click Open Dashboard next to the service name of the monitoring instance you want to work with. The dashboard displays.\n3. On the left sidebar, select Dashboards. Then, click the green + sign in the panel.\n4. Select Blank dashboard, then select the type of visual representation you want.\n\nIBM Cloud Monitoring offers eight different visualizations for your dashboard. Read the description for each visualization, then choose the one that best meets your requirements.\n\nLine (\"View trends over time\") is the easiest and most basic option. It is also the most frequently selected option. The examples in this topic show a Line-based visualization.\n5. Configure your custom dashboard.\n\n\n\n* In the Metrics field, enter ibm_is to display the two load balancer metrics: ibm_is_load_balancer_active_connections and ibm_is_load_balancer_connection_rate.\n\nYou can monitor listener port traffic by enabling the ibm_is_load_balancer_listener_port metric.\n* You can choose a scope to display in your dashboard by clicking Override Dashboard Scope. For example, you can display the metrics for a particular load balancer.\n* You can also set a segment to compare metrics across the scope you have defined. For example, you can look at Active connections for a particular load balancer segmented by listener port.\n\n\n\n6. Click Save for your new custom dashboard to be accessible.\n\nBy default, the dashboard begins with the name \"blank dashboard\". You can change the name by selecting Dashboards from the sidebar, then clicking the Pencil icon next to the name.\n\n\n\nTo return to the default dashboard at any time, select Dashboards > Default Dashboards > IBM > Load Balancer Monitoring Metrics.\n\n\n\n\n\n Working with IBM Cloud Monitoring using the APIs \n\nYou can also work with the monitoring instance by using the metric query APIs. You might want to do this if you need raw data points or want to consume your metrics from a command-line interface rather than using the dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-nlb_monitoring-metrics"},{"document_id":"ibmcld_15712-16034-17981","score":10.643445015,"text":"\nNavigate to the [metrics monitoring portal](https:\/\/cloud.ibm.com\/observe\/monitoring).\n2. Click View IBM Cloud Monitoring next to the service name of the monitoring instance you want to work with. The dashboard displays.\n3. On the left sidebar, select Dashboards. Then, click the green + sign in the panel.\n4. Select Blank dashboard, then select the type of visual representation you want.\n\nIBM Cloud Monitoring offers eight different visualizations for your dashboard. Read the description for each visualization, then choose the one that best meets your requirements.\n\nLine (\"View trends over time\") is the easiest and most basic option. It is also the most frequently selected option. The examples in this topic show a Line-based visualization.\n5. Configure your custom dashboard.\n\n\n\n* In the Metrics field, enter ibm_is to display the three load balancer metrics: ibm_is_load_balancer_active_connections, ibm_is_load_balancer_connection_rate, and ibm_is_load_balancer_throughput.\n\n\n\nYou can monitor listener port traffic by enabling the ibm_is_load_balancer_listener_port metric.\n\n\n\n* You can choose a scope to display in your dashboard by clicking Override Dashboard Scope. For example, you can display the metrics for a particular load balancer.\n* You can also set a segment to compare metrics across the scope that you defined. For example, you can look at throughput for a particular load balancer segmented by listener port.\n\n\n\n6. Click Save for your new custom dashboard to be accessible.\n\nBy default, the dashboard begins with the name \"blank dashboard\". You can change the name by selecting Dashboards from the sidebar, then clicking the Pencil icon next to the name.\n\n\n\nTo return to the default dashboard at any time, select Dashboards > Default Dashboards > IBM > Load Balancer Monitoring Metrics.\n\n\n\n\n\n Working with IBM Cloud Monitoring using the APIs \n\nYou can also work with the monitoring instance by using the metric query APIs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-monitoring-metrics-alb"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6713860725,"ndcg_cut_10":0.6713860725}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07908-0-899","score":17.4750556946,"text":"\n\n\n\n\n\n\n  SI-4 (5) - System-generated Alerts \n\n\n\n  Control requirements \n\nSI-4 (5) - 0\n:   The information system alerts [Assignment: organization-defined personnel or roles] when the following indications of compromise or potential compromise occur: [Assignment: organization-defined compromise indicators].\n\n\n\n\n\n  NIST supplemental guidance \n\nAlerts may be generated from a variety of sources, including, for example, audit records or inputs from malicious code protection mechanisms, intrusion detection or prevention mechanisms, or boundary protection devices such as firewalls, gateways, and routers. Alerts can be transmitted, for example, telephonically, by electronic mail messages, or by text messaging. Organizational personnel on the notification list can include, for example, system administrators, mission\/business owners, system owners, or information system security officers.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-si-4.5"},{"document_id":"ibmcld_09703-1640-3664","score":17.1720867157,"text":"\n* Alerts are executed in 1 minute or less from receipt, with the option to configure the trigger wait time by hour or day.\n* For PromQL alerts only, you can optionally configure a 0 minute wait time.\n\n\n\nYou can enable predefined alerts, modify alerts, and create custom alerts in the web UI and by using the IBM Cloud Monitoring API.\n\nYou manage alerts in the Alerts view of the web UI. You can configure the table columns that are displayed in the Alerts view. Valid column options are Name, Scope, Alert When, Segment By, Notifications, Enabled, Modified, Captures, Channels, Created, Description, Email recipients, For at least, OpsGenie, PagerDuty, Severity, Slack, WebHook, Type, and VictorOps.\n\n\n\n Types of alerts \n\nThe IBM Cloud Monitoring service includes pre-defined alerts that you can enable. In addition, you can configure custom alerts from panels in a dashboard, by using the REST API, or in the Alerts section of the web UI.\n\nIn the IBM Cloud Monitoring service, you can define any of the following types of alerts:\n\n\n\n* Downtime: Use this type of alert to monitor sources and alert when they are down, for example, a bare metal.\n* Metric: Use this type of alert to monitor time-series metrics and alert when they reach the thresholds defined.\n* PromQL: Use this type of metric to monitor metrics by using a PromQL query.\n* Event: Use this type of alert to monitor occurrences of specific events and alert when they reach the thresholds defined. For example, you can use this alert to monitor when a number of unauthorize access requests are reported.\n* Anomaly Detection: Use this type of alert to monitor hosts based on historical behaviors and alert when they deviate from the expected pattern.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n* Group Outlier: Use this type of alert to monitor hosts and be notified when 1 acts differently from the rest.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n\n\n\n\n\n\n\n Notification channels","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alerts"},{"document_id":"ibmcld_09701-10445-12445","score":17.0723209381,"text":"\nThe name is used to identify the alert in the Alerts section of the monitoring UI, and it is included in notification emails.\n\n\n\n\n\n modifiedOn (integer) \n\nDefines when an alert was last modified in milliseconds.\n\nThis parameter defines the Unix-timestamp when the alert was last modified.\n\n\n\n\n\n notificationChannelIds (array) \n\nLists the notification channels that are configured to notify when an alert is triggered.\n\nValid options are EMAIL, PAGER_DUTY, WEBHOOK, VICTOROPS, and SLACK.\n\n\"notificationChannelIds\": [\n\"EMAIL\",\n\"WEBHOOK\"\n]\n\n\n\n\n\n notificationCount (integer) \n\nDefines the number of notifications that are sent for the alert during the past 2 weeks.\n\n\n\n\n\n reNotify (boolean) \n\nDefines whether you want to get follow up notifications until the alert condition is acknowledged and resolved.\n\nBy default, follow up notifications are not enabled and the field is set to false.\n\n\n\n\n\n reNotifyMinutes (integer) \n\nDefines how often do you want to receive notifications on an alert that is not resolved.\n\nYou specify the number of minutes before a reminder is sent.\n\n\n\n\n\n severity (integer) \n\nDefines the syslog-encoded alert severity.\n\nThe following table lists the values that you can set:\n\n\n\nTable 2. Severity values\n\n Severity Info \n\n 0 emergency \n 1 alert \n 2 critical \n 3 error \n 4 warning \n 5 notice \n 6 informational \n 7 debug \n\n\n\n\n\n\n\n severityLabel (string) \n\nDefines the criticality of an alert. Valid values are HIGH, MEDIUM, LOW, and INFO. A lesser value indicates a higher severity.\n\nThe following table shows the severity status that must be set depending on the severity parameter value:\n\n\n\nTable 3. Severity level values\n\n Severity Severity status \n\n 0 HIGH \n 1 HIGH \n 2 MEDIUM \n 3 MEDIUM \n 4 LOW \n 5 LOW \n 6 INFO \n 7 INFO \n\n\n\n\n\n\n\n segmentBy (array of strings) \n\nDefines additional segmentation criteria.\n\nFor example, you can segment a CPU alert by ['host.mac', 'proc.name'] so the alert can report on any process in any machine for which you get data in the monitoring instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_09276-7-2089","score":16.8154029846,"text":"\nWorking with alerts \n\nYou can configure alerts to notify about the state of your infrastructure, applications, and IBM Cloud services.\n\nA rule specifies the scope of the data that you want to monitor and be notified if certain conditions occur. Per alert rule, consider the following information:\n\n\n\n* You can define 1 or more notification channels.\n* You can configure different alert types for each notification channel that you configure for an alert.\n* You can configure different triggering conditions for each notification channel that you configure for an alert.\n\n\n\nA rule is also the basis of a view. You can see the data that is included by any rule by using it as a view. The two are interchangeable.\n\n\n\n Types of alerts \n\nYou can configure any of the following types of alerts for each notification channel that you configure for an alert:\n\n\n\n Presence alert \n\nYou can configure a presence alert to notify when the number of logs that show in a view is more than what you expect.\n\nFor example, you might have a view that shows logs that report payments that are rejected by your service. You can configure a presence alert that triggers an alert when 1 or more logs show in the view.\n\n\n\n\n\n Absence alert \n\nConfigure an absence alert to notify when the number of logs that show in a view is less than what you expect, or none.\n\nAn absence alert is triggered when the view that has an absence alert attached to it is active. A view is active when the view receives logs within the last 24 hours.\n\nFor example, you might have a view that does not get any logs for 2 days. Therefore, this view is not active. You have an absence alert attached to this view that is configured to send a notification after 30 minutes. Because the view is not active, the absence alert is muted and you do not get notifications. To make the view active and get notifications for the absence condition, logs need to start flowing into the view.\n\n\n\n\n\n\n\n Alert conditions \n\nYou can configure any of the following triggering conditions for each notification channel that you configure for an alert:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-alerts"},{"document_id":"ibmcld_09701-12088-14157","score":16.4369010925,"text":"\nSeverity Severity status \n\n 0 HIGH \n 1 HIGH \n 2 MEDIUM \n 3 MEDIUM \n 4 LOW \n 5 LOW \n 6 INFO \n 7 INFO \n\n\n\n\n\n\n\n segmentBy (array of strings) \n\nDefines additional segmentation criteria.\n\nFor example, you can segment a CPU alert by ['host.mac', 'proc.name'] so the alert can report on any process in any machine for which you get data in the monitoring instance.\n\n\n\n\n\n segmentCondition (string) \n\nDefines when the alert is triggered for each monitored entity that is specified in the segmentBy parameter. This parameter is required for MANUAL alerts only.\n\nValid values are the following:\n\n\n\n* ANY: The alert is triggered when at least one of the monitored entities satisfies the condition.\n* ALL: The alert is triggered when all of the monitored entities satisfy the condition.\n\n\n\n\n\n\n\n teamId (string) \n\nDefines the GUID of the team that owns the alert.\n\n\n\n\n\n type (string) \n\nDefines the type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\nSet to MANUAL for alerts that you want to control when a notification is sent. You must define the threshold that determines when the alert is triggered.\n\nSet to BASELINE for alerts that you want to notify when unexpected metric values are detected. New metric data is compared with metric values that are collected over time.\n\nSet to HOST_COMPARISON for alerts that you want to notify when 1 host in a group reports metrics values that are different from the other hosts in the group.\n\n\n\n\n\n timespan (integer) \n\nMinimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered.\n\nThe minimum value is 60000000 microseconds, that is, 1 minute.\n\nThe value of this parameter must be a multiple of 60000000 microseconds.\n\n\n\n\n\n version (integer) \n\nVersion of an alert.\n\nThe version changes every time you update an alert.\n\nThe version is used for optimistic locking.\n\n\n\n\n\n\n\n Query parameters \n\n\n\n alertId (integer) \n\nID of an alert.\n\n\n\n\n\n from (long) \n\nDefines the start timestamp, in microseconds, that is used when you request information about alerts that are defined.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_09703-3207-5376","score":16.2760276794,"text":"\n* Anomaly Detection: Use this type of alert to monitor hosts based on historical behaviors and alert when they deviate from the expected pattern.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n* Group Outlier: Use this type of alert to monitor hosts and be notified when 1 acts differently from the rest.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n\n\n\n\n\n\n\n Notification channels \n\nA notification channel defines where you want to receive information when an alert is triggered.\n\nWhen you configure an alert, you can specify 1 or more notification channels.\n\nBy default, when an alert is triggered, you get a notification in the Events section.\n\nYou can configure any of the following notification channels:\n\n\n\n* Email\n* IBM Cloud Functions\n* IBM Event Notifications\n* Microsoft Teams\n* OpsGenie\n* PagerDuty\n* Slack\n* Teams Email\n* VictorOps\n* WebHook\n\n\n\n\n\n\n\n Events \n\nAn event is a notification that informs about something that occurs in any of the nodes that forward data to your Monitoring instance. Use events to review, track, and resolve issues.\n\nThe following list outlines different types of events:\n\n\n\n* Alert events are events that are triggered by user-configured alerts.\n* Infrastructure-based events are events that are collected from Docker and Kubernetes nodes. By default, the monitoring agent automatically discovers and collects data from a select group of events. You can edit the agent configuration file to enable more events.\n* Custom events that you configure through any of the following integrations: Slackbot, pre-built Python scripts, custom user-created Python scripts, or cURL requests.\n\n\n\nBy default, an event has a state:\n\n\n\n* Active: This state indicates that the circumstances that triggered the event remain in place, for example, a node continues to be down.\n* OK: This state indicates that the situation is back to normal, for example, a node is up and running.\n\n\n\nYou manage events in the Events section of the web UI.\n\n\n\n* You can view alert events through the Alert Events tab.\n* You can view infrastructure-based events through the Custom events tab.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alerts"},{"document_id":"ibmcld_09702-3991-5614","score":16.0685806274,"text":"\nFor example, you could define this entry if you want to receive a notification only if the name of the process meets the condition.\n* [notify]: You can define the type of notifications that you want the alert to generate. Set this entry to the notification IDs of the channels that you have defined.\n* [enabled]: You can configure the status of the alert when it is created. By default, alerts are enabled and the entry is set to true. Set to false if you do not want it enabled when you create it.\n* [annotations]: You can add custom properties that you can associate with the alert.\n* [alert_obj]: You can attach an alert object instead of specifying the individual parameters.\n\n\n\n\n\n\n\n Updating an alert (PUT) \n\nTo update an existing alert, you need the ID of that alert.\n\nThe following code shows the structure of a Python script that you can use to update an alert:\n\n Reference the Python client\nfrom sdcclient import IbmAuthHelper, SdMonitorClient\n\n Add the monitoring instance information that is required for authentication\nURL = <MONITORING-ENDPOINT>\nAPIKEY = <IAM_APIKEY>\nGUID = <GUID>\nibm_headers = IbmAuthHelper.get_headers(URL, APIKEY, GUID)\n\n Instantiate the Python client\nsdclient = SdMonitorClient(sdc_url=URL, custom_headers=ibm_headers)\n\nres = sdclient.get_alerts()\nif not res[0]:\nprint(\"Failed to fetch existing alerts\")\n\nalert_found = False\n\nfor alert in res['alerts']:\nif alert['name'] == alert_name:\nalert_found = True\nif 'notificationChannelIds' in alert:\nalert['notificationChannelIds'] = alert['notificationChannelIds']\nupdate_txt = '(changed by update_alert)'\nif alert['description'] != update_txt:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_python"},{"document_id":"ibmcld_09782-1362-3189","score":15.8042268753,"text":"\n: Information about the alert.\n\n--type <TYPE>\n: Type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\n--timespan <TIMESPAN>\n: Minimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered. The default value is 60,000,000 microseconds.\n\n--condition <CONDITION>\n: Threshold of the alert. This parameter is required for manual alerts, and does not apply to other alert types.\n\n--severity <SEVERITY> | -s <SEVERITY>\n: Level of severity. Valid values range from 0 to 7. 0 means emergency and 7 means debug. By default, severity is set to 4.\n\n--severity-label <LOW | MEDIUM | HIGH>\n: Criticality of an alert. Valid values are HIGH, MEDIUM, LOW. A lower severity value indicates a higher severity.\n\n--disable\n: State of the alert. By default, an alert is enabled when it is created. You must set this parameter to disable the alert when it is created.\n\n--segment <SEGMENT>\n: Additional segmentation criteria. For example, you can segment an alert by ['host.mac', 'proc.name'].\n\n--segment-condition <SEGMENT_CONDITION>\n: Defines when the alert is triggered for each monitored entity that is specified in the --segment parameter. This parameter is required for manual alerts, and does not apply to other alert types. Valid values are ANY and ALL. ANY indicates that the alert is triggered when at least one of the monitored entities satisfies the condition. ALL indicates that the alert is triggered when all of the monitored entities satisfy the condition.\n\n--user-filter <USER_FILTER>\n: Boolean expression that you can set to reduce the scope of the alert. Use this parameter to configure segments, such as filters like kubernetes.namespace.name='production' or container.image='nginx'.\n\n--notify <NOTIFY>\n: Type of notification that you want this alert to generate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-monitor-cli"},{"document_id":"ibmcld_09414-2945-4767","score":15.7638692856,"text":"\nFor example, you might want to be notified if the number of actions that fail are greater than a threshold that you specify.\n\nThrough the IBM Log Analysis web UI, you can apply search queries to define the logs that are displayed through a custom view. Then, you can attach an alert to that view to be notified when a condition occurs. A bell icon is displayed with the view to indicate that this view has an alert attached to it.\n\nConsider the following information when you configure alerts:\n\n\n\n* You can [attach one alert](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-alerts) per custom view.\n* There are 2 types of alerts: presence alert and absence alert.\n* You can configure conditions that are based on the number of event lines that meet the search query in the view, on a time frequency, or both.\n* The time frequency that is specified as part of the condition defines the reset time of an alert after it is triggered.\n* You can define multiple notification channels for an alert. For information about the supported channels, see [Alert notification channels](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-alerts).\n* You can [define presets](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-preset_ui). A preset is an alert template that users can attach to any number of views. Service administrators define presets. Notice that when you delete a preset, any alerts that are defined by using this preset are automatically deleted.\n* You can enable or disable the feature on alerts that allow a user to mute an alert for a period of time. This feature only applies to email notification channels.\n* You can [detach an alert](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-remove_alert_ui) from a view.\n* The timestamp that you see in a notification is set to UTC.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-monitor_logs"},{"document_id":"ibmcld_14504-1731-3967","score":15.739900589,"text":"\n* Smarts SAM Notification \u2013 sends alert notifications to EMC Smarts Server Assurance Manager.\n* Network Share \u2013 sends reports to a shared location, supports SMB version 2.0.\n\n\n\nNotifications are alert notifications that meet the filter criteria in the notification rules before they are sent northbound to external systems. Notification rules are configured for the required outbound alerts so that they can be filtered before they are sent to the selected external system. The notifications list is used to manage these rules.\n\n\n\n Integration use case \n\nThis example use case is based on an existing generic service management layer that is used by an enterprise. The client provisioned a vCenter Server instance with the Operations Management option, and they want to integrate this platform into their service management platform. They use an event aggregation system to integrate the alerts generated from the domain-specific monitoring tools:\n\n\n\n* A tool set to monitor the OS, middleware and applications across their UNIX\u00ae, Linux\u00ae, and Windows\u00ae workloads, but this tool does not monitor the infrastructure components like VMware\u00ae, networking devices, or storage.\n* An SNMP manager to receive SNMP traps from their network infrastructure. This tool also collects SNMP metrics to enable performance and capacity alerts.\n* A backup management tool to manage their backups.\n* Storage management tools to manage their storage arrays.\n* An availability tool that uses ping to test the devices reachability.\n\n\n\nTheir service management layer also consists of:\n\n\n\n* A server capacity and performance tool to collect metrics to provide reports.\n* A patching and compliance server to update OS, middleware, and applications and measure compliance on these platforms.\n* A ticketing tool used to manage tickets for, incidents, problems, and changes. This tool is also the enterprise\u2019s Configuration Management Database (CMDB). The tool is able to send emails to the operations teams and SMS messages.\n* An enterprise logging system that captures logs from all systems and managed by the security team.\n\n\n\nNow that they have VMware Aria Operations they can integrate this tool by using northbound notification that uses the SNMP Trap plug in.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsmgmt-integration"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03036-4322-6185","score":12.3530712128,"text":"\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-4-2165","score":11.991976738,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03363-1671-3630","score":10.3563432693,"text":"\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03036-2789-4951","score":9.6692762375,"text":"\nIf you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_09630-0-1462","score":8.4736328125,"text":"\n\n\n\n\n\n\n  Understanding routing precedence \n\nYou can configure exactly where IBM Cloud\u00ae Metrics Routing routes platform metrics in your account. Route rule inclusion filters provides elevated control over how your metrics are routed. You can also configure default targets by using IBM Cloud\u00ae Metrics Routing settings. How the configuration is processed determines the final destination where metrics are sent; each data point is processed individually.\n\n\n\n1.  If a route rule's inclusion filters match the data point, the data point is sent to the configured targets. Route rules are processed sequentially, the first match is used. If there are multiple routes, all route rules will be processed to find a match.\n\nIf a matched route rule uses the drop action, the data point will be dropped and no destinations will receive it.\n2.  If the data point does not match any route rules, the [default targets setting](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-target-default) is used to route the data point to the default targets.\n3.  If the data point does not match any route rules, and no default target is defined, the metric is routed to the IBM Cloud Monitoring instance defined in the region as the receiver of platform metrics. [A IBM Cloud Monitoring instance enabled to receive platform metrics must exist in the region to receive the metrics.](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-platform_metrics_enabling)\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-routes_precedence"},{"document_id":"ibmcld_09607-7-1880","score":8.313791275,"text":"\nUnderstanding high availability for IBM Cloud Metrics Routing \n\nIBM Cloud\u00ae Metrics Routing is a highly available, multi-tenant, platform service. In this topic, you can learn more about IBM Cloud Metrics Routing's availability strategy.\n\nHigh availability(HA) is a core discipline in an IT infrastructure to keep your apps up and running, even after a partial or full site failure. The main purpose of high availability is to eliminate potential points of failures in an IT infrastructure.\n\n\n\n Responsibilities \n\nFor more information about your responsibilities when using IBM Cloud Metrics Routing, see [Shared responsibilities for IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-shared-responsibilities).\n\n\n\n\n\n Availability zones \n\nIBM Cloud Metrics Routing is available in multiple regions. For more information on the regions where IBM Cloud Metrics Routing is available, see [Regions](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions).\n\n\n\n* Each region has three different data centers for redundancy configured in active\/active mode.\n* If all the data centers in a location fail, IBM Cloud Metrics Routing becomes unavailable in that location.\n* In each supported region, traffic is load balanced across infrastructure in multiple availability zones, with no single point of failure.\n\n\n\nFor more information about service availability, see [Service Level Agreements (SLAs)](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slas).\n\nThe following table lists the high-availability (HA) status for the regions (locations) where the IBM Cloud Activity Tracker service is available:\n\n\n\nTable 1. List of locations where the service is available.\n\n Geography Region EU-Supported HA Status \n\n North America Dallas (us-south) N\/A MZR \n North America Washington DC (us-east) N\/A MZR \n Europe Frankfurt (eu-de) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-ha"},{"document_id":"ibmcld_13406-6795-8870","score":8.1900177002,"text":"\nThe metrics indicate the progress and complexity of the engine's processing:\n\n\n\n* seen_by_engine is audio that the service has read and passed to the engine at least once.\n* received - seen_by_engine is audio that has been buffered at the service but has not yet been seen or processed by the engine.\n* The relationship between the times is received >= seen_by_engine >= transcription >= speaker_labels.\n\n\n\nThe following relationships can also be helpful in understanding the results:\n\n\n\n* The values of the received and seen_by_engine fields are greater than the values of the transcription and speaker_labels fields during speech recognition processing. The service must receive the audio before it can begin to process results.\n* The values of the received and seen_by_engine fields are identical when the service has finished processing the audio. The final values of the fields can be greater than the values of the transcription and speaker_labels fields by a fractional number of seconds.\n* The value of the speaker_labels field typically trails the value of the transcription field during speech recognition processing. The values of the transcription and speaker_labels fields are identical when the service has finished processing the audio.\n\n\n\n\n\n\n\n Processing metrics example: WebSocket interface \n\nThe following example shows the start message that is passed for a request to the WebSocket interface. The request enables processing metrics and sets the processing metrics interval to 0.25 seconds. It also sets the interim_results and speaker_labels parameters to true. The audio contains the simple message \"hello world long pause stop.\"\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/flac',\nprocessing_metrics: true,\nprocessing_metrics_interval: 0.25,\ninterim_results: true,\nspeaker_labels: true\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n\nThe following example output shows the first few processing metrics results that the service returns for the request.\n\n{\n\"processing_metrics\": {\n\"processed_audio\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metrics"},{"document_id":"ibmcld_13406-1732-4088","score":7.9140133858,"text":"\nThey can also help you distinguish the absence of results due to\n\n\n\n* Lack of audio.\n* Lack of speech in submitted audio.\n* Engine stalls at the server and network stalls between the client and the server. To differentiate between engine and network stalls, results are periodic rather than event-based.\n\n\n\nThe metrics can also help you estimate response jitter by examining the periodic arrival times. Metrics are generated at a constant interval, so any difference in arrival times is caused by jitter.\n\n\n\n Requesting processing metrics \n\nTo request processing metrics, use the following optional parameters:\n\n\n\n* processing_metrics is a boolean that indicates whether the service is to return processing metrics. Specify true to request the metrics. By default, the service returns no metrics.\n* processing_metrics_interval is a float that specifies the interval in seconds of real wall-clock time at which the service is to return metrics. By default, the service returns metrics once per second. The service ignores this parameter unless the processing_metrics parameter is set to true.\n\nThe parameter accepts a minimum value of 0.1 seconds. The level of precision is not restricted, so you can specify values such as 0.25 and 0.125. The service does not impose a maximum value.\n\n\n\nHow you provide the parameters and how the service returns processing metrics differ by interface:\n\n\n\n* With the WebSocket interface, you specify the parameters with the JSON start message for a speech recognition request. The service calculates and returns metrics in real-time at the requested interval.\n* With the asynchronous HTTP interface, you specify query parameters with a speech recognition request. The service calculates the metrics at the requested interval, but it returns all metrics for the audio with the final transcription results.\n\n\n\nThe service also returns processing metrics for transcription events. If you request interim results with the WebSocket interface, you can receive metrics with greater frequency than the requested interval.\n\nTo receive processing metrics only for transcription events instead of at periodic intervals, set the processing interval to a large number. If the interval is larger than the duration of the audio, the service returns processing metrics only for transcription events.\n\n\n\n\n\n Understanding processing metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metrics"},{"document_id":"ibmcld_13129-16717-17970","score":7.8349823952,"text":"\nTo understand the quality metrics, refer to [Quality metric overview](https:\/\/cloud.ibm.com\/docs\/ai-openscale?topic=ai-openscale-anlz_metrics)\n\n\n\n\n\n\n\n\n\n Step 7: Remove resources \n\n\n\n1. Navigate to [IBM Cloud\u00ae Resource List](https:\/\/cloud.ibm.com\/resources\/).\n2. Under Name, enter tutorial in the search box.\n3. Delete the services which you created for this tutorial.\n\n\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-resource-reclamation).\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Pak for Data Overview](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/getting-started\/welcome-main.html?context=analytics)\n* [Automatic model creation](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/analyze-data\/autoai-overview.html?context=analytics)\n* [Machine learning & AI](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/analyze-data\/wml-ai.html?context=analytics)\n* [Watson OpenScale documentation](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/model\/getting-started.html?context=analytics)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model"},{"document_id":"ibmcld_09634-7-2168","score":7.7980661392,"text":"\nUnderstanding your responsibilities when using IBM Cloud Metrics Routing \n\nLearn about the management responsibilities and terms and conditions that you have when you use IBM Cloud\u00ae Metrics Routing. For a high-level view of the service types in IBM Cloud and the breakdown of responsibilities between the customer and IBM for each type, see [Shared responsibilities for IBM Cloud offerings](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-shared-responsibilities).\n\nReview the following sections for the specific responsibilities for you and for IBM when you use IBM Cloud Metrics Routing. For the overall terms of use, see [IBM Cloud Terms and Notices](https:\/\/cloud.ibm.com\/docs\/overview\/terms-of-use?topic=overview-terms).\n\n\n\n Incident and operations management \n\n\n\nTable 1. Responsibilities for incident and operations\n\n Task IBM Responsibilities Your Responsibilities \n\n Incident and operations management Maintain service instances and infrastructure workloads. Maintain incident and operations management of your data. \n Monitor incidents Provide notifications for planned maintenance, security bulletins, or unplanned outages. Set preferences to [receive emails about platform notifications](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-uiemail-prefsl). <br>Monitor the [IBM Cloud announcements page](https:\/\/cloud.ibm.com\/status?selected=announcement) for general announcements. \n Maintain IBM Cloud high availability SLA for IBM Cloud Metrics Routing Provide IBM Cloud Metrics Routing functionality across availability zones in a Multi-Zone Region (MZR). <br>Provide replication, fail-over features, and infrastructure maintenance and updates. Keep your IBM Cloud Metrics Routing configuration in a version control system so that you can reconfigure a region if needed. <br>Comply with [Operational responsibilities when using IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-shared-responsibilities). \n Monitor metrics for IBM Cloud Metrics Routing [Participating Cloud services](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr) publish relevant data to their subscribing clients.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-shared-responsibilities"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2640681226,"ndcg_cut_10":0.2640681226}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16250-8881-11263","score":14.9943828583,"text":"\n* The embed script that contains your integration ID, region, service instance ID, and subscription ID (if applicable) needs be changed or updated to use the IDs for the new integration and region.\n* If you are using Salesforce or ZenDesk integrations for connecting to human agents, update the configuration within those systems to make sure they can communicate with the correct integration. Follow the instructions on the Live agent tab in the web chat configuration for setting up those systems. This is only needed for obtaining the conversation history for the agent.\n* If you have web chat security enabled and you are using encrypted payloads, the IBM-provided public key used for the encryption may be different depending on region. If so, you need to update the system that generates the JSON Web Token (JWT) to use the correct key.\n\n\n\nYou can set up an active\/active configuration of web chat by using different integration IDs in your embed scripts, and by ensuring the web chat integration is \"sticky\" by user. Otherwise, if the user fails over to a different integration, the conversation history might be lost.\n\n\n\n\n\n\n\n API \n\n\n\n Monitoring \n\nCapture and monitor response codes of \/message calls. Response codes of live \/message traffic should be captured and aggregated.\n\nIdeally, save the response code statistics in an external persistence store. This shared store can aggregate response code results from all deployed instances of a your application and provide the greatest fidelity in determining if a failover should be triggered.\n\nAlternatively, response codes can be aggregated and evaluated in memory for a given instance of your application. As only a fraction of traffic is contributing to the failover decision, this could lead to different behavior with respect to how often the failover decision is acted upon.\n\nWith either aggregation approach, exceeding a defined threshold could trigger a failover. Common approaches for determining a failover include:\n\n\n\n* Percentage-based: greater than X% of requests return a non-200 response code\n* Consecutive-based: X calls in a row return a non-200 response code\n* Limit-based: X calls return a non-200 response in a given timeframe\n\n\n\nTo avoid an unnecessary failover between regions, make sure a robust retry mechanism is present when calling the \/message endpoint.\n\n\n\n\n\n Failover for v1 and v2 stateless API","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_16250-12497-14080","score":13.2015752792,"text":"\nAt that point, the system can respond by updating the relevant failover metadata to route traffic to the service instance in the other region. Once a failover happens, you can decide to continue using the new region as the active instance, or if you want to resume using the initial region once it has stabilized.\n\nFor an active\/active topology, some form of a load balancing can be used, where two or more service instances in unique regions always receive a percentage of traffic. Additional logic would need to be established to determine when to pull a region out of rotation. This monitoring logic could use a [circuit break pattern](https:\/\/martinfowler.com\/bliki\/CircuitBreaker.html) similar to the active\/passive configuration or rely on a separate dedicated monitoring framework that determines region health. Also similar to active\/passive, determining when to insert a region back in rotation would need to be considered as well.\n\n\n\n\n\n Failover for v2 stateful API \n\nFailover for the v2 stateful API is similar to stateless, with these details to consider:\n\n\n\n* The state of a given conversation is persisted by Watson Assistant in a database that is tied to a particular region. As such, a failover for the stateful v2 \/message may more disruptive.\n* For an active\/passive topology, you should assume that all in-progress conversations are ended.\n* For an active\/active topology, given the region-locked persistence constraints of the v2 stateful \/message architecture, all turns (\/message API calls) of a given conversation (session) should occur within the same region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_16250-7169-9454","score":13.0556221008,"text":"\nUsing only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training. When automation is enabled it is best to start with a strategy for detecting and failing over to the passive backup region when a complete regional outage is detected. After this is in place, a strategy can be implemented to deal with partial outages, which should cover the vast majority of failure conditions that can occur with a phone integration deployment.\n\n\n\n\n\n\n\n Web chat \n\n\n\n Monitoring \n\nWeb chat provides an onError listening feature that allows the host page to detect specific types of outage errors, in particular INITIAL_CONFIG, OPEN_CONFIG, and MESSAGE_COMMUNICATION errors.\n\nYou can find the documentation for this feature here:\n\n[https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration#onerror-detail](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationonerror-detail)\n\n\n\n\n\n Failover \n\nHandling a failover for web chat is simple assuming you have set up an additional web chat integration in another region. When the failover needs to be manually triggered, make the following changes:\n\n\n\n* The embed script that contains your integration ID, region, service instance ID, and subscription ID (if applicable) needs be changed or updated to use the IDs for the new integration and region.\n* If you are using Salesforce or ZenDesk integrations for connecting to human agents, update the configuration within those systems to make sure they can communicate with the correct integration. Follow the instructions on the Live agent tab in the web chat configuration for setting up those systems. This is only needed for obtaining the conversation history for the agent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_03363-1671-3630","score":12.1087875366,"text":"\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03042-2711-4616","score":12.0741786957,"text":"\n{: note}\n\n1. conversation_id (v1 only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\nShow more\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For web chat, you can set the value of the user_id property. For more information, see [Adding user identity information](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid).\n\n\n\n\n\n Handling anonymous users \n\nIf your custom application or assistant interacts with users who are anonymous, you can generate a randomized universally unique ID to represent each anonymous user. For more information about UUIDs, see [RFC 4122](https:\/\/tools.ietf.org\/html\/rfc4122.html).\n\n\n\n* For web chat, if you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user.\n\n\n\n\n\n\n\n\n\n Service API versioning","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-services-information"},{"document_id":"ibmcld_03036-4322-6185","score":11.9232625961,"text":"\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03028-7-1945","score":11.6704235077,"text":"\nImprove your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nThe Analytics page was introduced with version 1.5.0.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nMessage logs are retained for 90 days.\n\n\n\n\n\n Filtering messages \n\nYou can filter messages by Search user statements, Intents, Entities, and Last n days.\n\nSearch user statements - Type a word in the search bar. This searches the users' inputs, but not your assistant's replies.\n\nIntents - Select the drop-down menu and type an intent in the input field, or choose from the populated list. You can select more than one intent, which filters the results using any of the selected intents, including Irrelevant.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs"},{"document_id":"ibmcld_03107-5127-7134","score":11.5844020844,"text":"\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For Facebook integrations, the user_id property is set to the sender ID that Facebook provides in its payload.\n* For Slack integrations, the user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n* For web chat, you can set the value of the user_id property.\n\n\n\nBilling is managed per monthly active user per service instance. If a single user interacts with assistants that are hosted by different service instances that belong to the same plan, each interaction is treated as a separate use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_03037-1358-3485","score":11.5457344055,"text":"\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing. A skill is effectively a wrapper for a V1 workspace.\n\n\n\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each \/message API call.\n\n\n\n\n\n Enabling user metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_16259-1485-3642","score":11.5450325012,"text":"\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery\/takeout, Small\/Medium\/Large, Cheese\/Pepperoni\/Mushrooms\/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.5,"ndcg_cut_5":0.5,"ndcg_cut_10":0.5}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03363-4-2165","score":25.0498962402,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03037-1358-3485","score":23.8504161835,"text":"\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing. A skill is effectively a wrapper for a V1 workspace.\n\n\n\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each \/message API call.\n\n\n\n\n\n Enabling user metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_16252-3899-5971","score":23.495672226,"text":"\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2messagestateless)\n* [v2 stateful \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"},{"document_id":"ibmcld_03028-7-1945","score":22.9303817749,"text":"\nImprove your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nThe Analytics page was introduced with version 1.5.0.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nMessage logs are retained for 90 days.\n\n\n\n\n\n Filtering messages \n\nYou can filter messages by Search user statements, Intents, Entities, and Last n days.\n\nSearch user statements - Type a word in the search bar. This searches the users' inputs, but not your assistant's replies.\n\nIntents - Select the drop-down menu and type an intent in the input field, or choose from the populated list. You can select more than one intent, which filters the results using any of the selected intents, including Irrelevant.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs"},{"document_id":"ibmcld_03354-4-1897","score":22.2822761536,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Improve your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nThe length of time for which messages are retained depends on your Watson Assistant service plan:\n\nService plan | Chat message retention\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"},{"document_id":"ibmcld_03107-5127-7134","score":22.2621612549,"text":"\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For Facebook integrations, the user_id property is set to the sender ID that Facebook provides in its payload.\n* For Slack integrations, the user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n* For web chat, you can set the value of the user_id property.\n\n\n\nBilling is managed per monthly active user per service instance. If a single user interacts with assistants that are hosted by different service instances that belong to the same plan, each interaction is treated as a separate use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_16324-1477-3681","score":22.0318717957,"text":"\nIf you have an existing interactive voice response (IVR) system with a branching structure (\u201cpress 1 for billing, press 2 for payments\u201d), you might choose the [phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone) as your initial channel. You can integrate Watson Assistant with your existing system to automate the IVR experience so customers can talk with your assistant over the phone.\n\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform. For more information about ways to deploy an assistant, see [Adding integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-integration-add).\n\n\n\n\n\n 2. Pick your assistant's domain of expertise \n\nDecide which general domain of expertise you want your assistant to cover (for example, billing support or scheduling appointments). To make an informed decision, review any support call logs that you have access to or ask your customer service representatives. After you choose a domain, be sure that it aligns with a channel that you can control and change. For example, don\u2019t choose to automate billing support questions if you're unable to add the web chat client to the billing web pages.\n\nAfter you select a domain, you can decide which specific questions or tasks the assistant will help customers with. Start small. Pick one or a handful of customer issues that will deliver the highest value to start. It might be valuable for your assistant to answer a simple question that is asked all the time. Or maybe there's a task, such as scheduling appointments, that you can offload to the assistant to tackle incoming customer requests.\n\nChoose a narrow set of user goals first. If you start small and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. After your assistant is live, the built-in metrics of active user conversations help you understand what your customers are asking about, how well your assistant is able to meet their needs, and what to focus on next.\n\n\n\n\n\n 3. Choose the tone and language of your assistant","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-plan-assistant"},{"document_id":"ibmcld_03312-1841-4150","score":21.9427833557,"text":"\nWatson Assistant analytics provide overview statistics on the number of interactions with users and containment rates. Analytics doesn't cumulate statistics across regions. With an active\/passive topology, this approach to analytics should be sufficient. However, using an active\/active topology likely requires using [webhooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-log) to gather interaction data, and build custom data warehouses and reports to understand total usage.\n\n\n\n\n\n Recommendations \n\nThe intent and user example recommendation features use production data to make the recommendations. The available recommendations may vary by instance due to differences in the data across regions.\n\n\n\n\n\n Autolearning \n\nThe autolearning feature uses production data to train an improved intent recognizer. The autolearning results may vary by instance due to differences in the data across regions.\n\n\n\n\n\n Session history for web chat and the v2 api \n\nSession history allows your web chats to maintain conversation history and context when users refresh a page or change to a different page on the same website. This feature doesn't work across instances, so in-progress conversations need to be restarted.\n\n\n\n\n\n Billing \n\nIBM calculates your bill based on the IBM Cloud Account. Watson Assistant calculates monthly average user (MAU) metrics by aggregating within a given service instance as follows:\n\n\n\n* The same MAU used in 2 different assistant resources in the same service instance counts as 1 MAU\n* The same MAU used in 2 different assistant resources in different service instances counts as 2 MAUs\n\n\n\nNote that for an active\/active topology, under the worst case scenario, the MAU count could end up being doubled for a given billing period.\n\n\n\n\n\n\n\n Phone integration \n\nA Watson Assistant phone integration in one region is unaware of a phone integration in a different region. You need to ensure that your assistants are identically configured in both regions. You also need to rely on the upstream SIP trunking provider to detect and manage failing over between regions.\n\n\n\n Monitoring \n\nSIP trunking providers can be configured to actively health-check the Watson Assistant session border controllers (SBCs) by sending periodic SIP OPTIONS messages to each zone within a region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-failover"},{"document_id":"ibmcld_03117-7179-9311","score":21.8751583099,"text":"\n- The conversation context is now organized into two objects:\n\n- The global context contains system-level context data shared by all skills used by the assistant.\n\n- The skill context contains any user-defined context variables used by your dialog skill.\n\nHowever, keep in mind that state data, including conversation context, is now maintained by the assistant, so your application might not need to access the context at all (see [Let the assistant maintain state](api-migration-state)).\n\nRefer to the v2 [API Reference ](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message){: external} for complete documentation of the v2 response format.\n\n Let the assistant maintain state {: api-migration-state}\n\nFor most applications, you can now remove any code included for the purpose of maintaining state. It is no longer necessary to save the context and send it back to Watson Assistant with each turn of the conversation. The context is automatically maintained by Watson Assistant and can be accessed by your dialog as before.\n\nNote that with the v2 API, the context is by default not included in responses to the client application. However, your code can still access context variables if necessary:\n\n- You can still send a context object as part of the message input. Any context variables you include are stored as part of the context maintained by Watson Assistant. (If the context variable you send already exists in the context, the new value overwrites the previously stored value.)\n\nMake sure the context object you send conforms to the v2 format. All user-defined context variables sent by your application should be part of the skill context; typically, the only global context variable you might need to set is system.user_id, which is used by Plus and Premium plans for billing purposes.\n\n- You can still retrieve context variables from either the global or skill context. To have the context object included with message responses, use the return_context property in the message input options. For more information, see [Accessing context data](\/docs\/assistant?topic=assistant-api-client-get-context).\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-migration"},{"document_id":"ibmcld_03112-4-2069","score":21.8644218445,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Accessing context data in dialog](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Accessing context data \n\nThe context is an object containing variables that persist throughout a conversation and can be shared by the dialog and the client application. Both the dialog and the client application can read and write context variables.\n\nYou can choose whether you want the context to be maintained by your application or by the Watson Assistant service:\n\n\n\n* If you use the stateful v2 message API, the context is automatically maintained by the assistant on a per-session basis. Your application must explicitly create a session at the beginning of each conversation; the context is stored by the service as part of the session and is not returned in message responses unless you request it. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message).\n* If you use the stateless v2 message API (or the legacy v1 message API) your application is responsible for storing the context after each conversation turn and sending it back to the service with the next message. For a complex application, or an application that needs to store personally identifiable information, you might choose to store the context in a database.\n\nA session ID is automatically generated at the beginning of the conversation, but no session data is stored by the service. With the stateless message API, the context is always included with each message response. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2messagestateless).\n\n\n\nImportant: One use of the context is to specify a unique user ID for each end user who interacts with the assistant. For user-based plans, this ID is used for billing purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-client-get-context"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03028-1501-3230","score":23.4535732269,"text":"\nYou can filter messages by Search user statements, Intents, Entities, and Last n days.\n\nSearch user statements - Type a word in the search bar. This searches the users' inputs, but not your assistant's replies.\n\nIntents - Select the drop-down menu and type an intent in the input field, or choose from the populated list. You can select more than one intent, which filters the results using any of the selected intents, including Irrelevant.\n\n![Intents drop-down menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/intents_filter.png)\n\nEntities - Select the drop-down menu and type an entity name in the input field, or choose from the populated list. You can select more than one entity, which filters the results by any of the selected entities. If you filter by intent and entity, your results will include the messages that have both values. You can also filter for results with No entities found.\n\n![Entities drop-down menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/entities_filter.png)\n\nMessages might take some time to update. Allow at least 30 minutes after a user's interaction with your assistant before attempting to filter for that content.\n\n\n\n\n\n Viewing individual messages \n\nFor any user input entry, click Open conversation to see the user input and the response made to it by the assistant within the context of the full conversation.\n\nThe time that is shown for each conversation is localized to reflect the time zone of your browser. This time might differ from the timestamp shown if you review the same conversation log via an API call; API log calls are always shown in UTC.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs"},{"document_id":"ibmcld_02991-7699-8461","score":21.687040329,"text":"\n| [response.output.intents:intent::order,response.output.entities:entity::beverage] |\n\n\n\n\n\n Filtering v1 logs \n\nIf your application is still using the v1 API, you can query and filter logs using the v1 \/logs method. The filtering syntax is the same, but the structure of v1 logs and message requests is different. For more information, see [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1listlogs).\n\nWith the v1 \/logs API, you can filter on the following fields:\n\n\n\n* request.context.metadata.deployment\n* request.context.system.assistant_id\n* request.input.text\n* response.entities\n* response.input.text\n* response.intents\n* response.top_intent\n* meta.message.entities_count\n* workspace_id\n\n\n\nFiltering on other fields is not currently supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference"},{"document_id":"ibmcld_04489-234834-236561","score":20.7040138245,"text":"\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster that you want to update a logging filter for.\n\n--id FILTER_ID\n: The ID of the log filter to update.\n\n--type LOG_TYPE\n: The type of logs that you want to apply the filter to. Currently all, container, and host are supported.\n\n-lc, --logging-config CONFIG\n: Optional: The logging configuration ID. If not provided, the filter is applied to all the cluster logging configurations that are passed to the filter. You can view log configurations that match the filter by using the --show-matching-configs option with the command. To specify multiple IDs, use multiple options, such as -lc id1 -lc id2.\n\n-n, --namespace KUBERNETES_NAMESPACE\n: Optional: The Kubernetes namespace from which you want to filter logs.\n\n--container CONTAINER_NAME\n: Optional: The name of the container from which you want to filter out logs. This option applies only when you are using log type container.\n\n--level LOGGING_LEVEL\n: Optional: Filters out logs that are at the specified level and less. Acceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_05891-234382-236109","score":20.7040138245,"text":"\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster that you want to update a logging filter for.\n\n--id FILTER_ID\n: The ID of the log filter to update.\n\n--type LOG_TYPE\n: The type of logs that you want to apply the filter to. Currently all, container, and host are supported.\n\n-lc, --logging-config CONFIG\n: Optional: The logging configuration ID. If not provided, the filter is applied to all the cluster logging configurations that are passed to the filter. You can view log configurations that match the filter by using the --show-matching-configs option with the command. To specify multiple IDs, use multiple options, such as -lc id1 -lc id2.\n\n-n, --namespace KUBERNETES_NAMESPACE\n: Optional: The Kubernetes namespace from which you want to filter logs.\n\n--container CONTAINER_NAME\n: Optional: The name of the container from which you want to filter out logs. This option applies only when you are using log type container.\n\n--level LOGGING_LEVEL\n: Optional: Filters out logs that are at the specified level and less. Acceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. Example output {\"log\": \"hello\", \"level\": \"info\"}\n\n--message MESSAGE\n: Optional: Filters out any logs that contain a specified message anywhere in the log. Example: The messages \"Hello\", \"!\", and \"Hello, World!\", would apply to the log \"Hello, World!\".\n\n--regex-message MESSAGE\n: Optional: Filters out any logs that contain a specified message that is written as a regular expression anywhere in the log.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_05832-21399-23084","score":20.5823822021,"text":"\nIf not provided, the filter is applied to all the cluster logging configurations that are passed to the filter. You can view log configurations that match the filter by using the --show-matching-configs option. \n <kubernetes_namespace> Optional: The Kubernetes namespace that you want to forward logs from. This option applies only when you are using log type container. \n <container_name> Optional: The name of the container from which you want to filter logs. \n <logging_level> Optional: Filters out logs that are at the specified level and less. Acceptable values in their canonical order are fatal, error, warn\/warning, info, debug, and trace. As an example, if you filtered logs at the info level, debug, and trace are also filtered. Note: You can use this option only when log messages are in JSON format and contain a level field. To display your messages in JSON, append the --output json option to the command. \n <message> Optional: Filters out logs that contain a specified message that is written as a regular expression. \n <filter_ID> Optional: The ID of the log filter. \n --show-matching-configs Optional: Show the logging configurations that each filter applies to. \n --all Optional: Delete all your log forwarding filters. \n\n\n\n\n\n1. Create a logging filter.\n\nibmcloud ks logging filter create --cluster <cluster_name_or_ID> --type <log_type> --logging-configs <configs> --namespace <kubernetes_namespace> --container <container_name> --level <logging_level> --regex-message <message>\n2. View the log filter that you created.\n\nibmcloud ks logging filter get --cluster <cluster_name_or_ID> --id <filter_ID> --show-matching-configs\n3. Update the log filter that you created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health"},{"document_id":"ibmcld_16310-7627-8554","score":20.2487220764,"text":"\nAn intent name in the response exactly matches order, and an entity name in the response exactly matches beverage. [response.output.intents:intent::order,response.output.entities:entity::beverage] \n\n\n\n\n\n\n\n Filtering v1 logs \n\nIf your application is still using the v1 API, you can query and filter logs using the v1 \/logs method. The filtering syntax is the same, but the structure of v1 logs and message requests is different. For more information, see [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1listlogs).\n\nWith the v1 \/logs API, you can filter on the following fields:\n\n\n\n* language\n* meta.message.entities_count\n* request.context.metadata.deployment\n* request.context.system.assistant_id\n* request.input.text\n* response.context.conversation_id\n* response.entities\n* response.input.text\n* response.intents\n* response.top_intent\n* workspace_id\n\n\n\nFiltering on other fields is not currently supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-filter-reference"},{"document_id":"ibmcld_02991-4944-6614","score":19.9253444672,"text":"\nresponse.output.entities:value::soda\n\nSimilarly, you can filter on intents or entities sent as part of the request, as in this example:\n\nrequest.input.intents:intent::hello\n\n\n\n\n\n Filtering by other fields \n\nTo filter on another field in the log data, specify the location as a path identifying the levels of nested objects in the JSON response from the \/logs API. Use dots (.) to specify successive levels of nesting in the JSON data. For example, the location request.input.text idenfities the user input text field as shown in the following JSON fragment:\n\n\"request\": {\n\"input\": {\n\"text\": \"Good morning\"\n}\n}\n\nFiltering is not available for all fields. You can filter on the following fields:\n\n\n\n* assistant_id\n* customer_id\n* language\n* request.context.global.system.user_id\n* request.input.text\n* request_timestamp\n* response.context.global.system.user_id\n* response.output.entities\n* response.output.intents\n* response_timestamp\n* skill_id\n* snapshot\n\n\n\nFiltering on other fields is not currently supported.\n\n\n\n\n\n\n\n Examples \n\nThe following examples illustrate various types of queries using this syntax.\n\n\n\n Description Query \n\n The date of the response is in the month of July 2020. response_timestamp>=2020-07-01,response_timestamp<2020-08-01 \n The timestamp of the response is earlier than 2019-11-01T04:00:00.000Z. response_timestamp<2019-11-01T04:00:00.000Z \n The message is labeled with the customer ID my_id. customer_id::my_id \n The message was sent to a specific assistant. assistant_id::dcd5c5ad-f3a1-4345-89c5-708b0b5ff4f7 \n The user input text contains the word \"order\" or a grammatical variant (for example, orders or ordering. request.input.text:order","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference"},{"document_id":"ibmcld_16310-4856-6524","score":19.6097888947,"text":"\nFor example, this query matches any logged event where the response includes a detected entity with the value soda:\n\nresponse.output.entities:value::soda\n\nSimilarly, you can filter on intents or entities sent as part of the request, as in this example:\n\nrequest.input.intents:intent::hello\n\n\n\n\n\n Filtering by other fields \n\nTo filter on another field in the log data, specify the location as a path identifying the levels of nested objects in the JSON response from the \/logs API. Use dots (.) to specify successive levels of nesting in the JSON data. For example, the location request.input.text idenfities the user input text field as shown in the following JSON fragment:\n\n\"request\": {\n\"input\": {\n\"text\": \"Good morning\"\n}\n}\n\nFiltering is not available for all fields. You can filter on the following fields:\n\n\n\n* assistant_id\n* customer_id\n* language\n* request.context.global.system.user_id\n* request.input.text\n* request_timestamp\n* response.context.global.system.user_id\n* response.output.entities\n* response.output.intents\n* response_timestamp\n* session_id\n* skill_id\n* snapshot\n\n\n\nFiltering on other fields is not currently supported.\n\n\n\n\n\n\n\n Examples \n\nThe following examples illustrate various types of queries using this syntax.\n\n\n\n Description Query \n\n The date of the response is in the month of July 2020. response_timestamp>=2020-07-01,response_timestamp<2020-08-01 \n The timestamp of the response is earlier than 2019-11-01T04:00:00.000Z. response_timestamp<2019-11-01T04:00:00.000Z \n The message is labeled with the customer ID my_id. customer_id::my_id \n The message was sent to a specific assistant. assistant_id::dcd5c5ad-f3a1-4345-89c5-708b0b5ff4f7","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-filter-reference"},{"document_id":"ibmcld_03354-1698-3275","score":19.5954456329,"text":"\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days\nTrial | Last 30 days\nLite | Last 7 days\n\n\n\n\n\n Filtering messages \n\nYou can filter messages by Search user statements, Intents, Entities, and Last n days.\n\nSearch user statements - Type a word in the search bar. This searches the users' inputs, but not your assistant's replies.\n\nIntents - Select the drop-down menu and type an intent in the input field, or choose from the populated list. You can select more than one intent, which filters the results using any of the selected intents, including Irrelevant.\n\n![Intents drop-down menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/intents_filter.png)\n\nEntities - Select the drop-down menu and type an entity name in the input field, or choose from the populated list. You can select more than one entity, which filters the results by any of the selected entities. If you filter by intent and entity, your results will include the messages that have both values. You can also filter for results with No entities found.\n\n![Entities drop-down menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/entities_filter.png)\n\n\n\n\n\n Viewing individual messages \n\nFor any user input entry, click Open conversation to see the user input and the response made to it by the assistant within the context of the full conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"},{"document_id":"ibmcld_07560-1741-2768","score":19.5140686035,"text":"\nA notification sent to the Event Notifications service must conform to the [CNCF](https:\/\/www.cncf.io\/)[CloudEvents](https:\/\/cloudevents.io\/) format.\n\n\n\n\n\n More about filters \n\nA filter is a conditional statement, which connects a source to a topic. Filters are written to route notifications of interest to a particular topic. All notifications that pass through the filters into a topic are then routed to the topic subscribers. Filtering is absent between topic and destination.\n\nTo simplify filtering, a source might include event categories in their notifications. Event categories are standard filter keys with the following hierarchy: Event Category -> Event Type -> Severity. Event categories simplify filtering because they appear as dropdown selection boxes when you are creating topics and filters in the Event Notifications UI. For more advance filtering, use [JSONPath](https:\/\/jsonpath.com\/) in the Custom Filter field. For more on JSONPath, see [JSONPath Online Evaluator](https:\/\/restfulapi.net\/json-jsonpath\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-relation"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.6105456989}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16364-101992-104197","score":20.0975666046,"text":"\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03369-108318-110450","score":19.9696426392,"text":"\nYou can use this method to extract a specific occurrence of a regular expression pattern that recurs in user input. For more details, see the [dialog methods](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methodsdialog-methods-strings-getMatch) topic.\n\n\n\n\n\n 9 August 2019 \n\nIntroductory product tour\n: For some first-time users, a new introductory product tour is shown that the user can choose to follow to perform the initial steps of creating an assistant.\n\n\n\n\n\n 6 August 2019 \n\n\n\n* Webhook callouts and Dialog page improvements are available in Dallas.\n\n\n\n\n\n\n\n 1 August 2019 \n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. The new Webhook support simplifies the callout implementation process. (No more action JSON objects required.) For more information, see [Making a programmatic call from a dialog node](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-webhooks).\n\nImproved dialog page responsiveness\n: In all service instances, the user interface of the Dialog page was updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\n\n\n\n\n 31 July 2019 \n\nSearch skill and autocorrection are generally available\n: The search skill and spelling autocorrection features, which were previously available as beta features, are now generally available.\n\n\n\n* Search skills can be created by users of Plus or Premium plans only.\n* You can enable autocorrection for English-language dialog skills only. It is enabled automatically for new English-language dialog skills.\n\n\n\n\n\n\n\n 26 July 2019 \n\nMissing skills issue is resolved\n: In some cases, workspaces that were created through the API only were not being displayed when you opened the Watson Assistant user interface. This issue has been addressed. All workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03043-7-2031","score":19.7551517487,"text":"\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_03369-109994-112063","score":19.3652801514,"text":"\nIt is enabled automatically for new English-language dialog skills.\n\n\n\n\n\n\n\n 26 July 2019 \n\nMissing skills issue is resolved\n: In some cases, workspaces that were created through the API only were not being displayed when you opened the Watson Assistant user interface. This issue has been addressed. All workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do. For more information about disambiguation, see [Disambiguation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation).\n\nDialog search issue\n: In some skills, the search function is not working in the Dialog page. A new user interface library, which increases the page responsiveness, is being rolled out to existing service instances in phases. This search issue affects only dialog skills for which the new library is not yet enabled.\n\nMissing skills issue\n: In some cases, workspaces that were created through the API only are not being displayed when you open the Watson Assistant user interface. Normally, these workspaces are displayed as dialog skills. If you do not see your skills from the UI, don't worry; they are not gone. Contact support to report the issue, so the team can enable the workspaces to be displayed properly.\n\n\n\n\n\n 15 July 2019 \n\nNumeric system entities upgrade available in Dallas\n: The new system entities are now also available as a beta feature for instances that are hosted in Dallas. See [New system entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities)\n\n\n\n\n\n 12 June 2019 \n\nNumeric system entities upgrade\n: New system entities are available as a beta feature that you can enable in dialog skills that are written in English or German.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03049-2703-4536","score":19.3503246307,"text":"\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Troubleshooting skill import issues \n\nIf you receive warnings when you try to upload a skill, take a moment to try to fix the issues.\n\n\n\n1. Make a note of the warning message that are displayed when you try to upload the JSON file.\n2. Edit the skill to address the issues.\n\n\n\n* If you have access to a public service instance, open the skill from there and make edits. Export the edited skill by downloading it.\n* Otherwise, open the JSON file in a text editor and make edits.\n\n\n\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03313-4560-6553","score":19.3486385345,"text":"\nA dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offer step-by-step flows for a conversations and are made so that anybody can build them. A search skill is configured to search the appropriate external data sources for answers to customer questions. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add). \n Skill version Versions are snapshots of a skill that you can create at key points during the development lifecycle. You can deploy one version to production, while you continue to make and test improvements that you make to another version of the skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-versions). \n Slots A special set of fields that you can add to a dialog node that enable the assistant to collect necessary pieces of information from the customer. For example, the assistant can require a customer to provide valid date and location details before it gets weather forecast information on the customer's behalf. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots). \n Step A step that you add to an action represents a single interaction or exchange of information with a customer, a turn in the conversation. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actions-overviewactions-overview-steps). \n System entity Prebuilt entities that recognize references to common things like dates and numbers. You can add these to your skill and start using them immediately. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"},{"document_id":"ibmcld_03369-66296-68553","score":19.3268470764,"text":"\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-163116-165172","score":19.2035598755,"text":"\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time. No more passing context with each API call; the session state is managed for you as part of the assistant layer.\n\n\n\nWhat is presented in the tooling as a dialog skill is effectively a wrapper for a V1 workspace. There are currently no API methods for authoring skills and assistants with the V2 API. However, you can continue to use the V1 API for authoring workspaces.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03369-64600-66787","score":18.8102531433,"text":"\n: Want a quick way to see how your dialog is doing at responding to customer queries? Enable the new coverage metric to find out. The coverage metric measures the rate at which your dialog is confident that it can address a customer's request per message. For conversations that are not covered, you can review the logs to learn more about what the customer wanted. For the metric to work, you must design your dialog to include an Anything else node that is processed when no other dialog node intents are matched. For more information, see [Graphs and statistics](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overviewlogs-overview-graphs).\n\nTry out the enhanced intent detection model\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time.\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-103662-105841","score":18.6436424255,"text":"\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nThe actions skill is available as a beta feature. For more information, see [Adding an actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add).\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance. For more information, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\nText messaging integration was renamed\n: The Twilio messaging integration was renamed to SMS with Twilio.\n\n\n\n\n\n 9 October 2020 \n\nSearch skill update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6508205186,"ndcg_cut_10":0.7920874914}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02839-1790-3940","score":17.6653423309,"text":"\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03120-3469-5331","score":17.524438858,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_02839-7-2335","score":17.314863205,"text":"\nAdding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_02839-3583-5403","score":17.2094116211,"text":"\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03353-5263-7331","score":17.0091228485,"text":"\nItalian (it) GA Deprecated \n Japanese (ja) GA Deprecated \n Korean (ko) GA Deprecated \n Portuguese (Brazilian) (pt-br) GA Deprecated \n Spanish (es) GA Deprecated \n Universal (xx) GA NA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the tool interface itself (descriptions, labels, etc.) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee has mandated that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing a skill language \n\nOnce a skill has been created, its language cannot be modified. If it is necessary to change the supported language of a skill, you can do so by editing the skill's underlying JSON.\n\nTo change the skill language, take the following steps:\n\n\n\n1. Download the skill that you want to edit.\n2. Open the downloaded skill JSON file in a text editor.\n3. Search for the property named language.\n\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_16364-101992-104197","score":16.2007236481,"text":"\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03353-4-2000","score":15.7243347168,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Supported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a Beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add) [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add) \n\n English (en) GA GA GA \n Arabic (ar) GA GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_03418-1763-3833","score":15.602183342,"text":"\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Global audience support \n\nThe underlying skills understand customer messages that are written in any of the languages that are supported by the service. For more information, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support). The responses from your assistant are defined by you in the underlying skill and can be written in any language you want.\n\nEven if your skill includes responses in a language other than English, some of the phrases that are displayed in the web chat widget are added by the web chat itself and do not come from the underlying skill. These hardcoded phrases are specified in English unless you choose to apply a different language.\n\nThere are language files that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1. To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basics"},{"document_id":"ibmcld_03027-7-1946","score":15.5233831406,"text":"\nSupported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add) \n\n English (en) GA GA \n Arabic (ar) GA GA \n Chinese (Simplified) (zh-cn) GA GA \n Chinese (Traditional) (zh-tw) GA GA \n Czech (cs) GA GA \n Dutch (nl) GA GA \n French (fr) GA GA \n German (de) GA GA \n Italian (it) GA GA \n Japanese (ja) GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_03120-4813-6717","score":15.3934345245,"text":"\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions. For a dialog skill, add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Phone integration: If you want to deploy an assistant that uses the universal language model with the phone integration, you must connect to custom Speech service language models that can understand the language you're using. For more information about supported language models, see the [Speech to Text](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-modelsmodelsList) and [Text to Speech](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices) documentation.\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03119-7-1688","score":15.9503326416,"text":"\nCreating an assistant \n\nCreate an assistant with the skills it needs to address the business goals of your customers.\n\nTo learn more about what an assistant is first, see [Assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants).\n\nFollow these steps to create an assistant:\n\n\n\n1. Click the Assistants icon ![Assistants menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/nav-ass-icon.png).\n2. Click Create assistant.\n3. Add details about the new assistant:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n\n\n\n4. Click Create assistant.\n5. Add a skill to the assistant.\n\nNote: You can choose to add an existing skill or create a new one.\n\nSee [Adding a skill to an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add).\n\n\n\n\n\n Assistant limits \n\nThe number of assistants you can create depends on your Watson Assistant [plan type](https:\/\/www.ibm.com\/products\/watson-assistant\/pricing\/). There is also a limit of 100 assistants per service instance.\n\nAfter 30 days of inactivity, an unused assistant in a Lite plan service instance might be deleted to free up space. See [Changing the inactivity timeout setting](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-settings) for more information on the subject.\n\nYou can connect one skill of each type to your assistant. The number of skills you can build differs depending on the plan you have. See [Skill limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-limits) for more details.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add"},{"document_id":"ibmcld_16364-158662-160553","score":15.6090869904,"text":"\nDialog node limit changes\n: The dialog node limit was temporarily changed from 100,000 to 500 for new Standard plan instances. This limit change was later reversed. If you created a Standard plan instance during the time frame in which the limit was in effect, your dialogs might be impacted. The limit was in effect for skills created between 10 December and 12 December 2018. The lower limits will be removed from all impacted instances in January. If you need to have the lower limit lifted before then, open a support ticket.\n\n\n\n\n\n 1 December 2018 \n\nDetermine the number of dialog nodes\n: To determine the number of dialog nodes in a dialog skill, do one of the following things:\n\n\n\n* From the tool, if it is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n* Send a GET request to the \/dialog_nodes API endpoint, and include the include_count=true parameter. For example:\n\ncurl -u \"apikey:{apikey}\" \"https:\/\/{service-hostname}\/assistant\/api\/v1\/workspaces\/{workspace_id}\/dialog_nodes?version=2018-09-20&include_count=true\"\n\nwhere {service-hostname} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.\n\nSee [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors) for information about how to edit skills that you want to continue using.\n\n\n\n\n\n\n\n 27 November 2018 \n\nA new service plan, the Plus plan, is available\n: The new plan offers premium-level features at a lower price point. Unlike previous plans, the Plus plan is a user-based billing plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03043-7-2031","score":15.426194191,"text":"\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_03139-3702-4938","score":15.3149280548,"text":"\n* Description: An optional description no more than 200 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the skill, it appears as a tile on the Skills page.\n\n\n\n\n\n Re-creating your assistant \n\nYou can now re-create your assistant. You can then link your uploaded skills to the assistant, and configure integrations for it.\n\nSee [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add) and [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-adddeploy-integration-add-task) for more details.\n\n\n\n\n\n Update your client applications \n\nWhen you import a dialog skill that you exported, a new skill is created. The new skill has a new workspace ID. If you have existing client applications that use the v1 API to access this skill, then you must update any workspace ID references to use the new worskpace ID instead.\n\nWhen you re-create your assistant, it is given a new assistant ID. If you have existing client applications that use the v2 API to access the assistant, then you must update any assistant ID references to use the new assistant ID instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-backup"},{"document_id":"ibmcld_03073-7-1928","score":15.0510492325,"text":"\nCreating skill versions \n\nVersions help you manage the workflow of a dialog skill development project.\n\nCreate a skill version to capture a snapshot of the training data (intents and entities) and dialog in the skill at key points during the development process. Being able to save an in-progress skill at a specific point in time is especially useful as you start to fine tune your assistant. You often need to make a change and see the impact of the change in real time before you can determine whether or not the change improves or lessens the effectiveness of the assistant. Based on your findings from a test environment deployment, you can make an informed decision about whether to deploy a given change to an assistant that is deployed in a production environment.\n\nTo learn more about how versions can improve the workflow you use to build an assistant, [read this blog post](https:\/\/medium.com\/ibm-watson\/watson-assistant-versions-announcement-d60869b1f5f).\n\n\n\n Creating a version \n\nYou can edit only one version of the dialog skill at a time. The in-progress version is called the development version.\n\nWhen you save a version, any skill settings that you applied to the development version are saved also.\n\nTo create a dialog skill version, follow these steps:\n\n\n\n1. From the header of the skill, click Save new version, and then describe the current state of the skill.\n\nAdding a good description will help you to distinguish multiple versions from one another later.\n2. Click Save.\n\n\n\nA snapshot is taken of the current skill and saved as a new version. You remain in the development version of the skill. Any changes you make continue to be applied to the development version, not the version you saved. To access the version you saved, go to the Versions page.\n\n\n\n\n\n Deploying a skill version \n\n\n\n1. From the skill menu, click Versions.\n\nv1.3: Click the Skills tab, and then click Versions.\n2. Click the !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-versions"},{"document_id":"ibmcld_03369-121126-122848","score":14.1116876602,"text":"\n: You can now create Watson Assistant service instances that are hosted in the London data center without syndication. See [Data centers](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-services-informationservices-information-regions) for more details.\n\nDialog node limit changes\n: The dialog node limit was temporarily changed from 100,000 to 500 for new Standard plan instances. This limit change was later reversed. If you created a Standard plan instance during the time frame in which the limit was in effect, your dialogs might be impacted. The limit was in effect for skills created between 10 December and 12 December 2018. The lower limits will be removed from all impacted instances in January. If you need to have the lower limit lifted before then, open a support ticket.\n\n\n\n\n\n 1 December 2018 \n\nDetermine the number of dialog nodes\n: To determine the number of dialog nodes in a dialog skill, do one of the following things:\n\n\n\n* From the tool, if it is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n* Send a GET request to the \/dialog_nodes API endpoint, and include the include_count=true parameter. For example:\n\ncurl -u \"apikey:{apikey}\" \"https:\/\/{service-hostname}\/assistant\/api\/v1\/workspaces\/{workspace_id}\/dialog_nodes?version=2018-09-20&include_count=true\"\n\nwhere {service-hostname} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-146046-148039","score":14.0833044052,"text":"\n: For some first-time users, a new introductory product tour is shown that the user can choose to follow to perform the initial steps of creating an assistant.\n\n\n\n\n\n 1 August 2019 \n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. The new Webhook support simplifies the callout implementation process. (No more action JSON objects required.) For more information, see [Making a programmatic call from a dialog node](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-webhooks).\n\nImproved dialog page responsiveness\n: In all service instances, the user interface of the Dialog page was updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\n\n\n\n\n 31 July 2019 \n\nSearch skill and autocorrection are generally available\n: The search skill and spelling autocorrection features, which were previously available as beta features, are now generally available.\n\n\n\n* Search skills can be created by users of Plus or Premium plans only.\n* You can enable autocorrection for English-language dialog skills only. It is enabled automatically for new English-language dialog skills.\n\n\n\n\n\n\n\n 26 July 2019 \n\nMissing skills issue is resolved\n: In some cases, workspaces that were created through the API only were not being displayed when you opened the Watson Assistant user interface. This issue has been addressed. All workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_02838-7-1984","score":14.0178098679,"text":"\nCreating an assistant \n\nCreate an assistant with the skills it needs to address the business goals of your customers.\n\nFollow these steps to create an assistant:\n\n\n\n1. Click the Assistants icon ![Assistants menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png).\n\n1.3: Click the Assistants tab. If you don't see the Assistants tab, click the breadcrumb link in the page header.\n2. Click Create assistant.\n3. Add details about the new assistant:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n\n\n\n1.5: With the 1.5.0 release, if your assistant has a skill associated with it, the following integrations are created for you automatically unless you choose not to enable them:\n\n\n\n* Web chat: Creates a chat widget that you can embed in your company website to deploy your assistant in minutes.\n* Preview link: Creates an IBM-branded public web page that you and your team can use to test your assistant.\n\n\n\nYou cannot enable the integrations from the assistant creation page unless a skill (dialog or search) exists.\n4. Click Create assistant.\n5. Add a skill to the assistant by choosing one of the following skill types to add.\n\nNote: You can choose to add an existing skill or create a new one.\n\n\n\n* Add Dialog Skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific dialog skill version, add it from the skill's Versions page instead.\n* Add Search Skill: For a given user query, uses the IBM Watson\u00ae Discovery service to retrieve information from a data source that you identify and shares any relevant information that it finds as the response to the user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add"},{"document_id":"ibmcld_03139-2715-4132","score":14.003947258,"text":"\n[Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/nav-skills-icon.png).\n2. Click Create skill.\n3. Choose to create either an actions or dialog skill, then click Next.\n4. Select the JSON file you want to import.\n\nThe imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON file cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1createworkspace).\n5. Click Upload.\n\nIf you have trouble uploading a skill, see [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors).\n6. Specify the details for the skill:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the skill, it appears as a tile on the Skills page.\n\n\n\n\n\n Re-creating your assistant \n\nYou can now re-create your assistant. You can then link your uploaded skills to the assistant, and configure integrations for it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-backup"},{"document_id":"ibmcld_16364-147609-149563","score":13.8007364273,"text":"\nAll workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do. For more information about disambiguation, see [Disambiguation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation).\n\nDialog search issue\n: In some skills, the search function is not working in the Dialog page. A new user interface library, which increases the page responsiveness, is being rolled out to existing service instances in phases. This search issue affects only dialog skills for which the new library is not yet enabled.\n\nMissing skills issue\n: In some cases, workspaces that were created through the API only are not being displayed when you open the Watson Assistant user interface. Normally, these workspaces are displayed as dialog skills. If you do not see your skills from the UI, don't worry; they are not gone. Contact support to report the issue, so the team can enable the workspaces to be displayed properly.\n\n\n\n\n\n 15 July 2019 \n\nNumeric system entities upgrade available in Dallas\n: The new system entities are now also available as a beta feature for instances that are hosted in Dallas. See [New system entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 12 June 2019 \n\nNumeric system entities upgrade\n: New system entities are available as a beta feature that you can enable in dialog skills that are written in English or German. The revised system entities offer better date and time understanding. They can recognize date and number spans, national holiday references, and classify mentions with more precision.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09903-9624-10554","score":10.9005746841,"text":"\nHebrew [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2) [Version 2](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding\/?topic=natural-language-understanding-entity-types-version-2)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-type-systems"},{"document_id":"ibmcld_09913-7-1696","score":8.3221902847,"text":"\nLanguage support \n\nNatural Language Understanding supports a variety of languages depending on which features you analyze. Currently, English is the only language that is supported across all features. The rest of the languages have limited support. To jump to the list of features that are compatible with a language, click the language in the following list.\n\n\n\n* [Arabic](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportarabic)\n* [Chinese (Simplified)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportchinese-simplified)\n* [Czech](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportczech)\n* [Danish](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportdanish)\n* [Dutch](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportdutch)\n* [English](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportenglish)\n* [Finnish](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportfinnish)\n* [French](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportfrench)\n* [German](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportgerman)\n* [Hebrew](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supporthebrew)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_02747-19701-21292","score":8.2613658905,"text":"\nlg-UG Ganda Uganda \n ka-GE Georgian Georgia \n de-AT German Austria \n de-DE German Germany \n de-LU German Luxembourg \n de-CH German Switzerland \n el-GR Greek Greece \n gu-IN Gujarati India \n ha-NG Hausa Nigeria \n he-IL Hebrew Israel \n hi-IN Hindi India \n hu-HU Hungarian Hungary \n is-IS Icelandic Iceland \n ig-NG Igbo Nigeria \n id-ID Indonesian Indonesia \n it-IT Italian Italy \n it-CH Italian Switzerland \n ja-JP Japanese Japan \n kn-IN Kannada India \n kk-KZ Kazakh Kazakhstan \n km-KH Khmer Cambodia \n rw-RW Kinyarwanda Rwanda \n kok-IN Konkani India \n ko-KR Korean South Korea \n lo-LA Lithuanian Lithuania \n lv-LV Latvian Latvia \n lt-LT Khmer Cambodia \n mk-MK Macedonian Macedonia \n ms-Latn-MY Malay-Latin Malaysia \n ml-IN Malayalam India \n mt-MT Maltese Malta \n mr-IN Marathi India \n mn-Cyrl-MN Mongolian-Cyrillic Mongolia \n ne-IN Nepali India \n ne-NP Nepali Nepal \n nb-NO Norwegian Bokm\u00e5l Norway \n nn-NO Norwegian Nynorsk Norway \n or-IN Oriya (Odia) India \n om-ET Oromo Ethiopia \n pl-PL Polish Poland \n pt-AO Portuguese Angola \n pt-BR Portuguese Brazil \n pt-MO Portuguese Macao S.A.R. of the PRC \n pt-MZ Portuguese Mozambique \n pt-PT Portuguese Portugal \n pa-IN Punjabi India \n ro-RO Romanian Romania \n ru-RU Russian Russia \n sr-Cyrl-RS Serbian-Cyrillic Serbia \n sr-Latn-ME Serbian-Latin Montenegro \n sr-Latn-RS Serbian-Latin Serbia \n si-LK Sinhala Sri Lanka \n sk-SK Slovak Slovakia \n sl-SI Slovenian Slovenia \n es-AR Spanish Argentina \n es-BO Spanish Bolivia \n es-CL Spanish Chile \n es-CO Spanish Colombia \n es-CR Spanish Costa Rica \n es-DO Spanish Dominican Republic \n es-EC Spanish Ecuador","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-types"},{"document_id":"ibmcld_03389-11954-13341","score":8.1150865555,"text":"\nNew Year's Eve newyearseve \n\n\n\n\n\n\n\n Holidays (ar-ar) \n\n\n\nArabic holidays\n\n Holiday name String to use to check for a festival match \n\n new year newyear \n Valentine valentine \n easter sunday easter \n christmas eve christmaseve \n christmas christmas \n Eid al-Fitr eidalfitr \n Eid al-Adha eidaladha \n Ramadan ramadan \n Islamic New Year islamicnewyear \n Ashura ashura \n Mawlid an-Nabi mawlidannabi \n Day of Arafat dayofarafat \n Laylat al-Miraj laylatalmiraj \n\n\n\n\n\n\n\n Holidays (iw-il) \n\n\n\nHebrew holidays\n\n Holiday name String to use to check for a festival match \n\n Erev Purim erevpurim \n Yom HaAliyah yomhaaliyah \n Erev Pesach erevpesach \n Pesach I (First day of Passover) pesachi \n Pesach II (Passover) pesachii \n Pesach III (Passover) pesachiii \n Pesach IV (Passover) pesachiv \n Pesach V (Passover) pesachv \n Pesach VI (Passover) pesachvi \n Pesach VII (Last day of Passover) pesachvii \n Yom HaShoah\/Holocaust Memorial Day yomhashoah \n Yom HaZikaron (Memorial Day) yomhazikaron \n Yom HaAtzmaut (Independence Day) yomhaatzmaut \n Yom Yerushalayim (Jerusalem Day) yomyerushalayim \n Erev Shavuot erevshavuot \n Shavuot (Pentecost) shavuot \n Erev Tisha B'Av erevtishabav \n Tisha B'Av tishabav \n Erev Rosh Hashana erevroshhashana \n Rosh Hashana (New Year) roshhashana \n Rosh Hashana II (New Year day 2) roshhashanaii \n Erev Yom Kippur erevyomkippur \n Yom Kippur yomkippur \n Erev Sukkot erevsukkot","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-sys-date-festivals"},{"document_id":"ibmcld_07104-32103-34057","score":8.0068178177,"text":"\nFor more information, see [Monitoring usage](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-analyzeapiapi-usage).\n\n\n\n\n\n 30 August 2020 \n\nUpdate to API version\n: The current API version (v2) is now 2020-08-30. The following change was made with this version:\n\nChange to 'options' object\n: The List enrichments method no longer returns the options object per enrichment. Use the Get enrichment method to return the options object for a single enrichment.\n\n\n\n\n\n 2.1.3 release, 19 June 2020 \n\nNew release now available\n: IBM Watson\u00ae Discovery for IBM Cloud Pak\u00ae for Data version 2.1.3 is available.\n: Discovery for Cloud Pak for Data now works with IBM Cloud Pak\u00ae for Data 3.0.1.\n\nNew Finnish and Hebrew language support\n: Added basic support for Finnish and Hebrew. For more information, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n\nChange to Analyze endpoint\n: The Analyze endpoint, which supports stateless document ingestion workflows. For details, see the [Analyze API](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-analyzeapi). The Analyze API supports JSON documents only. Use of the Analyze API affects license usage.\n\nNew options for Content Miner\n: The content mining application includes two new options: Cyclic time scale on the Time series dashboard, and the Contextual view tab.\n\nNew shortcut for Content Mining projects\n: For Content Mining projects only, the Improve and customize page includes a shortcut: the Launch application button. Previously, you were required to open the Integrate and deploy page, select the Launch application tab, and click the Launch button.\n\nImproved segment limit\n: The segment limit when splitting documents has been increased to 1,000. For details, see [Split documents to make query results more succinct](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-split-documents).\n\nImproved Filenet connector","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes-data"},{"document_id":"ibmcld_03055-12075-13392","score":7.9665760994,"text":"\nValentine valentine \n easter sunday easter \n christmas eve christmaseve \n christmas christmas \n Eid al-Fitr eidalfitr \n Eid al-Adha eidaladha \n Ramadan ramadan \n Islamic New Year islamicnewyear \n Ashura ashura \n Mawlid an-Nabi mawlidannabi \n Day of Arafat dayofarafat \n Laylat al-Miraj laylatalmiraj \n\n\n\n\n\n\n\n Holidays (iw-il) \n\n\n\nHebrew holidays\n\n Holiday name String to use to check for a festival match \n\n Erev Purim erevpurim \n Yom HaAliyah yomhaaliyah \n Erev Pesach erevpesach \n Pesach I (First day of Passover) pesachi \n Pesach II (Passover) pesachii \n Pesach III (Passover) pesachiii \n Pesach IV (Passover) pesachiv \n Pesach V (Passover) pesachv \n Pesach VI (Passover) pesachvi \n Pesach VII (Last day of Passover) pesachvii \n Yom HaShoah\/Holocaust Memorial Day yomhashoah \n Yom HaZikaron (Memorial Day) yomhazikaron \n Yom HaAtzmaut (Independence Day) yomhaatzmaut \n Yom Yerushalayim (Jerusalem Day) yomyerushalayim \n Erev Shavuot erevshavuot \n Shavuot (Pentecost) shavuot \n Erev Tisha B'Av erevtishabav \n Tisha B'Av tishabav \n Erev Rosh Hashana erevroshhashana \n Rosh Hashana (New Year) roshhashana \n Rosh Hashana II (New Year day 2) roshhashanaii \n Erev Yom Kippur erevyomkippur \n Yom Kippur yomkippur \n Erev Sukkot erevsukkot \n Sukkot I sukkoti \n Sukkot II sukkotii \n Sukkot III sukkotiii \n Sukkot IV sukkotiv","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-sys-date-festivals"},{"document_id":"ibmcld_02839-3583-5403","score":7.801074028,"text":"\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_09229-17595-19748","score":7.5982036591,"text":"\nel-en Greek (el) English (en) general \n\n\n\n\n\n\n\n Gujarati \n\nThe following Gujarati translation model can be customized.\n\n\n\nTable 21. Gujarati translation model\n\n Model ID Source Target Domain \n\n gu-en Gujarati (gu) English (en) general \n\n\n\n\n\n\n\n Hebrew \n\nThe following Hebrew translation model can be customized.\n\n\n\nTable 22. Hebrew translation model\n\n Model ID Source Target Domain \n\n he-en Hebrew (he) English (en) general \n\n\n\n\n\n\n\n Hindi \n\nThe following Hindi translation model can be customized.\n\n\n\nTable 23. Hindi translation model\n\n Model ID Source Target Domain \n\n hi-en Hindi (hi) English (en) general \n\n\n\n\n\n\n\n Hungarian \n\nThe following Hungarian translation model can be customized.\n\n\n\nTable 24. Hungarian translation model\n\n Model ID Source Target Domain \n\n hu-en Hungarian (hu) English (en) general \n\n\n\n\n\n\n\n Indonesian \n\nThe following Indonesian translation model can be customized.\n\n\n\nTable 25. Indonesian translation model\n\n Model ID Source Target Domain \n\n id-en Indonesian (id) English (en) general \n\n\n\n\n\n\n\n Irish \n\nThe following Irish translation model can be customized.\n\n\n\nTable 26. Irish translation model\n\n Model ID Source Target Domain \n\n ga-en Irish (ga) English (en) general \n\n\n\n\n\n\n\n Italian \n\nThe following Italian translation models can be customized.\n\n\n\nTable 27. Italian translation models\n\n Model ID Source Target Domain \n\n it-de Italian (it) German (de) general \n it-en Italian (it) English (en) general \n\n\n\n\n\n\n\n Japanese \n\nThe following Japanese translation model can be customized.\n\n\n\nTable 28. Japanese translation model\n\n Model ID Source Target Domain \n\n ja-en Japanese (ja) English (en) general \n\n\n\n\n\n\n\n Kannada \n\nThe following Kannada translation model can be customized.\n\n\n\nTable 29. Kannada translation model\n\n Model ID Source Target Domain \n\n kn-en Kannada (kn) English (en) general \n\n\n\n\n\n\n\n Korean \n\nThe following Korean translation model can be customized.\n\n\n\nTable 30. Korean translation model\n\n Model ID Source Target Domain \n\n ko-en Korean (ko) English (en) general \n\n\n\n\n\n\n\n Latvian \n\nThe following Latvian translation model can be customized.\n\n\n\nTable 31. Latvian translation model\n\n Model ID Source Target Domain","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-models"},{"document_id":"ibmcld_03120-3469-5331","score":7.358915329,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_09226-18248-20249","score":7.1783714294,"text":"\n* English to and from Slovenian (en-sl and sl-en)\n\n\n\nNew identifiable languages\n: The following languages can now be identified by the service:\n\n\n\n* Catalan (ca)\n* Croatian (hr)\n* Irish (ga)\n* Malay (ms)\n* Maltese (mt)\n* Serbian (sr)\n* Slovenian (sl)\n* Thai (th)\n\n\n\n\n\n\n\n 14 June 2019 \n\nNew translation models\n: New translation models are now available for English and Greek:\n\n\n\n* English to Greek (en-el)\n* Greek to English (el-en)\n\n\n\n\n\n\n\n 13 June 2019 \n\nNew translation models\n: New translation models are now available for English and Hebrew:\n\n\n\n* English to Hebrew (en-he)\n* Hebrew to English (he-en)\n\n\n\n\n\n\n\n 21 March 2019 \n\nChanges to service credential information\n: From March 21 2019, you will see only service credential information associated with the role that has been assigned to your IBM Cloud account. For example, if you have assigned a reader role, any writer or higher levels of service credentials will not be visible.\n\nThis change does not affect API access for users or applications with existing service key credentials. Only the viewing of credentials within IBM Cloud is affected.\n\nFor more information about service keys and user roles, see [Authenticating to Watson services](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iam).\n\n\n\n\n\n 14 December 2018 \n\nNew London location\n: You can now create Language Translator service instances in the IBM Cloud London location.\n\n\n\n\n\n 16 November 2018 \n\nNew beta support for document translation\n: [Translating documents](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorial) is now available through new API endpoints. Submit a Microsoft Office document, PDF, or other document with a supported file format, and Language Translator will provide a translated copy that preserves the original formatting. [Supported file formats](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorialsupported-file-formats) include .doc, .ppt, .pdf, and more.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00539-2548-4016","score":16.1262302399,"text":"\n\"type\": \"json\"\n}\n\n\n\n\n\n Can I sort in reverse order? \n\nYes! IBM Cloudant Query supports sorting the result set in ascending or descending order, but not a combination of the two. For example, a query that sorts some fields in ascending order, and a query where descending is not allowed.\n\nThis query returns documents that match firstname and surname and sorts by surname\/firstname\/date descending:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\n{ \"firstname\": \"desc\" },\n{ \"surname\": \"desc\" },\n{ \"date\": \"desc\" }\n],\n\"limit\": 10\n}\n\nA suitable index must be present that contains the selector fields and the sort fields. Otherwise, IBM Cloudant refuses to execute the query. A suitable index definition for the previous query is shown next:\n\n{\n\"index\": {\n\"fields\": [\n\"firstname\",\n\"surname\",\n\"date\"\n]\n},\n\"ddoc\": \"jsonindexes\",\n\"name\": \"byNameAndDate\",\n\"type\": \"json\"\n}\n\nThe previous index is suitable for both ascending and descending sort order.\n\n\n\n\n\n How can I tell if an index is backing a query? \n\nThe [POST \/{db}\/_explain](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=javapostexplain) API endpoint when passed a JSON object that is usually sent to the [POST \/{db}\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) endpoint, explains how such a query is handled and which indexes, if any, might be used.\n\nIf the index object in the response indicates that \"all_docs\" is being used, a full database scan is required to service the query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_00644-15701-17094","score":15.6128149033,"text":"\nWhen you issue a view request that specifies the keys parameter, the results are returned in the same order as the supplied keys array.\n\nSee the example of using HTTP to request the records in reversed sort order:\n\nGET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME?descending=true HTTP\/1.1\nAccept: application\/json\n\nSee the example of requesting the records in reverse sort order.\n\nClient libraries use POST method instead of GET because they have a similar behavior.\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X GET \"$SERVICE_URL\/users\/_design\/allusers\/_view\/getVerifiedEmails?descending=true\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostViewOptions;\nimport com.ibm.cloud.cloudant.v1.model.ViewResult;\n\nCloudant service = Cloudant.newInstance();\n\nPostViewOptions viewOptions = new PostViewOptions.Builder()\n.db(\"users\")\n.ddoc(\"allusers\")\n.view(\"getVerifiedEmails\")\n.descending(true)\n.build();\n\nViewResult response =\nservice.postView(viewOptions).execute()\n.getResult();\n\nSystem.out.println(response);\n\nconst { CloudantV1 } = require('@ibm-cloud\/cloudant');\n\nconst service = CloudantV1.newInstance({});\n\nservice.postView({\ndb: 'users',\nddoc: 'allusers',\nview: 'getVerifiedEmails',\ndescending: true\n}).then(response => {\nconsole.log(response.result);\n});\n\nfrom ibmcloudant.cloudant_v1 import CloudantV1\n\nservice = CloudantV1.new_instance()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_00644-14024-16089","score":14.3548488617,"text":"\nWhile IBM Cloudant strives to keep indexes updated in the background, no guarantee exists about how out-of-date the view is when queried with update=false or update=lazy.\n\nThe stable option indicates whether you would prefer to get results from a single, consistent set of shards. The false value means that all available shard replicas are queried and IBM Cloudant uses the fastest response. By contrast, setting stable=true forces the database to use just one replica of the index.\n\nUsing stable=true can cause high latency as it consults only one of the copies of the index, even if the other copies would respond faster.\n\n\n\n\n\n Combining parameters \n\nIf you specify stable=false and update=false, you see greater inconsistency between results, even for the same query and without making database changes. We recommend against this combination unless you are sure that your system can tolerate this behavior.\n\n\n\n\n\n\n\n Sorting returned rows \n\nThe data that is returned by a view query is in the form of an array. Each element within the array is sorted by using standard [UTF-8](https:\/\/en.wikipedia.org\/wiki\/UTF-8) sorting. The sort is applied to the key defined in the view function.\n\nThe basic order of the output is shown in the following table:\n\n\n\nTable 2. Order of returned rows\n\n Value Order \n\n null First \n false \n true \n Numbers \n Text (lowercase) \n Text (uppercase) \n Arrays (according to the values of each element, by using the order given in this table) \n Objects (according to the values of keys, in key order by using the order given in this table) Last \n\n\n\nYou can reverse the order of the returned view information by setting the descending query value true.\n\nWhen you issue a view request that specifies the keys parameter, the results are returned in the same order as the supplied keys array.\n\nSee the example of using HTTP to request the records in reversed sort order:\n\nGET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME?descending=true HTTP\/1.1\nAccept: application\/json\n\nSee the example of requesting the records in reverse sort order.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_08058-1611-3488","score":13.6926441193,"text":"\nsort number <br>subject <br>severity <br>updatedAt Only one of the sort options can be used at one time. You can use the prefix to reverse the sorting order. \n status new <br>inProgress <br>waitingOnClient <br>resolutionProvided <br>resolved <br>closed Any number of options can be used. The available options can be entered as status:new,inProgress or as status:new status:inProgress. \n page target page to view If you have several results from your search that spans multiple pages, you can view your results from any result page. For example, to view page 5 out of 10, use page:5. \n pageSize 10 <br>25 <br>50 <br>100 The size of that page to be viewed. The page size refers to the number of results that you want to load. \n\n\n\nIf you enter a term without a parameter, the search results are shown for the support case number and the case subject.\n\n\n\n Query and URL examples \n\nYou can enter search queries in the search bar by stating a parameter and option separated by a colon (:) or you can use parameters in a URL to go directly to a specific case or group of cases on the Manage cases page.\n\nTo use parameters in the URL, add a question mark (?) to the end of the URL. Then, set your parameter equal to the option you select. You can also separate additional parameters with an ampersand (&).\n\nTo search for a case by keyword, you can enter the word in the search bar without a parameter. To search for a keyword with the URL, use search as a parameter and set it equal to your keyword, for example, search=server.\n\n\n\n Searching by case number \n\nEnter the following to search support cases by case number:\n\nQuery\n: number:CS1234567\n\nURL\n: https:\/\/cloud.ibm.com\/unifiedsupport\/cases?number=CS1234567\n\n\n\n\n\n Searching with multiple parameters \n\nYou might want to search for both new and in progress support cases, limit the results to 25 per page, and displayed by severity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-managing-support-cases"},{"document_id":"ibmcld_03935-31897-34103","score":13.5824947357,"text":"\nBut that peer cannot join a channel that is configured with application capability 2.x.\n* If a channel application capability level is upgraded to 2.x before the peer 1.4.x image is upgraded to 2.x, the peer stops functioning and needs to be upgraded to the 2.x image.\n* It is possible for a peer that is running a 2.x image to join a channel with application capability 1.4 and another channel with application capability 2.x at the same time. But smart contracts on the peer in .cds format use the [legacy smart contract deployment](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-smart-contracts-v14) process where they have to be instantiated on the channel with application capability 1.4. Smart contracts on the peer in tar.gz format follow the [Fabric 2.x smart contract lifecycle](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-smart-contracts-v2) process on the channel with application capability 2.x.\n\n\n\nLike the orderer and channel capabilities, the application capability level can be edited through a channel configuration update. The orderer capability can also be specified during the creation of a channel, but will require the approval of the ordering service.\n\nIf you are using the SDK to create or edit a channel, take caution to not submit a channel configuration with an invalid application capability. Because application capabilities are not validated by the ordering service, invalid application capabilities are not flagged. Because the peers cannot process capabilities that do not exist, the peers will crash when attempting to read the configuration block containing an invalid capability. Because the peers will be unable to progress beyond this configuration block, it will not be possible to reverse this configuration block and submit another one to \"fix\" the problem. A channel in this state is unrepairable.\n\n\n\n\n\n\n\n\n\n Tuning your ordering service \n\nPerformance of a blockchain platform can be affected by many variables such as transaction size, block size, network size, as well as limits of the hardware. The orderer node includes a set of tuning parameters that together can be used to control orderer throughput and performance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-govern"},{"document_id":"ibmcld_03891-23613-25771","score":13.4829874039,"text":"\nClusters that do not use a system channel can join and unjoin ordering nodes to an application channel. You can verify if a cluster does or does not use a system channel by clicking the cluster's tile and looking near the Orderer Type text.\n\nJoining an orderer to an application channel will make it either a follower or a consenter. It will be a consenter if the node is found in the the channel's config block in the consenters section. Otherwise the orderer will be a follower. Both types of orderers will receive transaction\/block data, but only a consenter can vote and play a role in the consensus algorithm. A node can be promoted from a follower to a consenter by first joining it to the channel, and then editing the channel's config to add it as a consenter. Similarly these steps can be reversed to demote an orderer and unjoin it completely if need be.\n\nJoining an orderer to the application channel can be started by clicking the cluster's tile. Next click either the plus sign on a channel tile or the Join channel blue button. Follow the prompts and select which orderer nodes to join. Then click Submit. Once an orderer has joined it will begin downloading blocks to catch up to the current level.\n\n\n\n\n\n\n\n Removing ordering service nodes \n\nIf a user wants to delete an ordering node, it must first remove the node from all channels where it is a consenter. This is because the console does not distinguish between a deleted node and an unavailable node, and will keep an ordering node as part of its consenter set until it is removed.\n\nAs a result, when you delete a node, a check is performed to see if it is a consenter on any channels. If it is, you will not be able to delete the node until it has been removed as a consenter from all channels. After removing the node as a consenter from all channels, you will be able to delete the node by clicking the trash can icon. Note that this action will have to be taken in the console where the node was created.\n\nAs part of this same process, make sure to reach out to the other console operators to let them know that the node has been deleted so they can remove the tile from their console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-add-remove-orderer"},{"document_id":"ibmcld_03935-33555-35918","score":13.1405324936,"text":"\nBecause the peers will be unable to progress beyond this configuration block, it will not be possible to reverse this configuration block and submit another one to \"fix\" the problem. A channel in this state is unrepairable.\n\n\n\n\n\n\n\n\n\n Tuning your ordering service \n\nPerformance of a blockchain platform can be affected by many variables such as transaction size, block size, network size, as well as limits of the hardware. The orderer node includes a set of tuning parameters that together can be used to control orderer throughput and performance. You can use these parameters to customize how your orderer processes transactions depending on whether you have many small frequent transactions, or fewer but large transactions that arrive less frequently. Essentially, you have the control to decide when the blocks are cut based on your transaction size, quantity, and arrival rate.\n\nThe following parameters are available in the console by clicking the orderer node in the Nodes tab and then clicking its Settings icon. Click the Advanced button to open the Advanced channel configuration for the orderer.\n\n\n\n Block cutting parameters \n\nThe following three parameters work together to control when a block is cut, based on a combination of setting the maximum number of transactions in a block as well as the block size itself.\n\n\n\n* Absolute max bytes Set this value to the largest block size in bytes that can be cut by the orderer. No transaction may be larger than the value of Absolute max bytes. Usually, this setting can safely be two to ten times larger than your Preferred max bytes. Note: The maximum size permitted is 99MB.\n* Max message count Set this value to the maximum number of transactions that can be included in a single block.\n* Preferred max bytes Set this value to the ideal block size in bytes, but it must be less than Absolute max bytes. A minimum transaction size, one that contains no endorsements, is around 1KB. If you add 1KB per required endorsement, a typical transaction size is approximately 3-4KB. Therefore, it is recommended to set the value of Preferred max bytes to be around Max message count * expected averaged tx size. At run time, whenever possible, blocks will not exceed this size. If a transaction arrives that causes the block to exceed this size, the block is cut and a new block is created for that transaction.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-govern"},{"document_id":"ibmcld_16727-768404-770345","score":13.1317491531,"text":"\nCIS's reverse proxy is also able to convert between compressed formats and uncompressed formats, meaning that it can pull content from a customer's origin server via gzip and serve it to clients uncompressed (or vice versa). This is done independently of caching.\n\nThe Accept-Encoding header is not respected and is removed.\n\n\n\nContent Delivery Network (CDN)\n\n\n\n* How does the CDN edge server retrieve content from the origin server?\n\n How does the CDN edge server retrieve content from the origin server? \n\n\n\n* For the Server type of origin, the CDN keeps the origin path in the URL. For example, if you add origin origin.example.com in path \/example\/, when a user opens the CDN URL cdn.example.com\/example\/, the CDN edge server retrieves the content from origin.example.com\/example\/.\n* For the Object Storage type of origin, the CDN makes a URL transformation. For example, if object storage origin s3-example.object-storage.com with bucket name xyz-bucket-name is added in path \/example-cos\/, when a user opens the CDN URL cdn.example.com\/example-cos\/, the CDN edge server retrieves the content from s3-example.object-storage.com\/xyz-bucket-name\/.\n\n\n\n* What's the difference between the origin on the Settings page and the origins on the Origins page?\n\n What's the difference between the origin on the Settings page and the origins on the Origins page? \n\nThe Settings page shows the origin path created during CDN provisioning. You cannot edit or delete it. However, on the Origins page, you can configure different types of origins (COS or origin server). You can also edit or delete origins on this page.\n* Why can't I change the protocol and port for an origin?\n\n Why can't I change the protocol and port for an origin? \n\nThe displayed protocol and port options match what you selected when you ordered the CDN. For example, if you selected an HTTP port when you ordered a CDN, only the HTTP port option is shown as part of Add Origin.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16456-6603-8681","score":12.6585912704,"text":"\nIn this mode, the human annotator connects mentions by associating a relation type, as defined in the type system. For example, the mention John Smith might be connected to the mention IBM by the relation type employedBy. The annotation of relation types is optional and can occur before or after you annotate mentions as coreferences.\n* Coreference mode\n\nIn this mode, the human annotator identifies mentions that mean the same thing, thus helping to ensure consistency in the annotations when words are not identical. For example, the mention of IBM in the first sentence, the mention of International Business Machines, and the mention of IBM in a later sentence refer to the same thing and would all be labeled by the same entity type, such as ORGANIZATION. The annotation of mentions as coreferences is optional and can occur before or after you annotate relation types.\n\n\n\n\n\n Tips for using the editor \n\n\n\n* Save your work as you go.\n* If you make a mistake, you can press Ctrl+Z to undo the previous action. To redo the action after undoing it, press Ctrl+Y. You can undo the previous 10 actions that you performed while editing the current document. The actions are lost as soon as you close the document. The actions must be undone in reverse order, and you must switch to the mode that you were in when you performed the action to undo it. You cannot undo and redo concordance tool actions.\n\n\n\n\n\n\n\n\n\n Annotating entity mentions \n\nTo annotate entity mentions, a human annotator selects a string of text in a document, and then applies a label that most appropriately describes what the string of text represents. The labels that can be applied are entity types defined in the workspace's type system.\n\n\n\n About this task \n\nBefore starting to annotate entity mentions in a document, it's a good practice to read the entire document. Doing so can help keep the entire context in mind while annotating, and can help provide insights into how entity mentions might relate to each other and which mentions might need to be coreferenced in future passes through the document.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide"},{"document_id":"ibmcld_16530-6603-8681","score":12.6585912704,"text":"\nIn this mode, the human annotator connects mentions by associating a relation type, as defined in the type system. For example, the mention John Smith might be connected to the mention IBM by the relation type employedBy. The annotation of relation types is optional and can occur before or after you annotate mentions as coreferences.\n* Coreference mode\n\nIn this mode, the human annotator identifies mentions that mean the same thing, thus helping to ensure consistency in the annotations when words are not identical. For example, the mention of IBM in the first sentence, the mention of International Business Machines, and the mention of IBM in a later sentence refer to the same thing and would all be labeled by the same entity type, such as ORGANIZATION. The annotation of mentions as coreferences is optional and can occur before or after you annotate relation types.\n\n\n\n\n\n Tips for using the editor \n\n\n\n* Save your work as you go.\n* If you make a mistake, you can press Ctrl+Z to undo the previous action. To redo the action after undoing it, press Ctrl+Y. You can undo the previous 10 actions that you performed while editing the current document. The actions are lost as soon as you close the document. The actions must be undone in reverse order, and you must switch to the mode that you were in when you performed the action to undo it. You cannot undo and redo concordance tool actions.\n\n\n\n\n\n\n\n\n\n Annotating entity mentions \n\nTo annotate entity mentions, a human annotator selects a string of text in a document, and then applies a label that most appropriately describes what the string of text represents. The labels that can be applied are entity types defined in the workspace's type system.\n\n\n\n About this task \n\nBefore starting to annotate entity mentions in a document, it's a good practice to read the entire document. Doing so can help keep the entire context in mind while annotating, and can help provide insights into how entity mentions might relate to each other and which mentions might need to be coreferenced in future passes through the document.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-user-guide"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16468-8522-10510","score":13.7528371811,"text":"\nIf no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set. You cannot change the annotation set name after the set is created.\n\nThe maximum size of the annotation set name is 256 characters.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_16308-1647-3532","score":12.7957763672,"text":"\nClick the first segment of the generated condition, and then scroll down and click Expression.\n3. Optional: Click the ![Expand icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/expression-editor-icon.png)Expand icon to open the expression editor window. (You can also type the expression directly in the field without opening the window, but the editor makes it easier to edit a longer or more complex expression.)\n4. Type the expression that you want to use.\n\n\n\n\n\n\n\n Using an expression to assign a value to a session variable \n\nYou can use an expression when assigning a value to a session variable if you want the variable's value to be calculated based on other variables.\n\nFor example, suppose you want to tell your customer the total cost of a purchase, including 6% sales tax and a flat $3.00 processing fee. To calculate the total cost, you could create a session variable and assign the value using an expression:\n\n(${price} * 1.06) + 3\n\nYou can then reference this variable in the Assistant says field.\n\nTo use an expression when assigning a value to a session variable, follow these steps:\n\n\n\n1. From within a step, click Set variable values.\n2. Click Set new value.\n3. From the drop-down list, select the session variable you want to store the value in.\n4. After to, select Expression.\n5. Type the expression you want to use.\n6. If you are using the expression editor, click Apply to save your changes and close the editor window.\n\n\n\nYou can also use an expression to assign an initial value to a session variable. In the Session variable window, go to the Initial value field and click Use expression.\n\nYou can also write an expression directly without first picking a variable:\n\n\n\n1. From within a step, click Set variable values.\n2. Click Set new value.\n3. From the drop-down list, select Expression.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-expressions"},{"document_id":"ibmcld_13189-11566-13271","score":12.7316074371,"text":"\nStatic Group sg-private-networks net-application and net-db \n\n\n\nTo create an IP Set:\n\n\n\n1. In the top menu navigation, click on Networking.\n2. Click on Edge Gateways and select your virtual data center's Edge Gateway.\n3. Under Security, click IP Sets.\n4. Click New to create a new IP Set.\n5. In the new IP Set window, enter a name and the IP range for this IP Set. In this example, ipset-dnat-to-jump is used as the name and public-ip-0 (the first actual public IP obtained in the previous task) is used.\n6. Click Add to add the IP Set then click Save to complete the window.\n\n\n\nRepeat the process for the other required IP Sets, or more if needed in your solution.\n\nTo create a Static Group:\n\n\n\n1. In the top menu navigation, click on Networking.\n2. Click on Edge Gateways and select your virtual data center's edge gateway.\n3. Under Security, click Static Groups.\n4. Click New to create a new Static Group. Enter the name and Click Save.\n5. Select the created Static Group and click Manage Members. Select the net-application and net-dbnetworks created in the previous step. Click Save.\n\n\n\nUpon completion of these tasks, the new IP Sets and Static Groups will be added.\n\n\n\n\n\n Step 4: Create NAT rules to allow virtual machines to access the Internet \n\nThe next step is to create NAT rules to allow your virtual machines to access the public Internet and you to access the virtual machines over the public Internet.\n\nYou will create the following NAT rules in this tutorial.\n\n\n\nNAT rules\n\n Name Type External IP Internal IP Application \n\n dnat-to-jump DNAT public-ip-0 192.168.100.10\/32 N\/A \n snat-to-inet-app SNAT public-ip-1 192.168.100.0\/24 N\/A \n snat-to-inet-db SNAT public-ip-1 192.168.101.0\/24 N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vmware-as-a-service-vdc"},{"document_id":"ibmcld_16481-7043-9158","score":12.7102661133,"text":"\nYou can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common. For another example, if you create annotation sets with overlapping documents, but add one annotation set per task instead of adding all of the annotation sets to a single task, no overlapping documents will be found and inter-annotator agreement cannot be calculated.\n\n\n\n\n\n Procedure \n\nTo assess annotation agreement between human annotators:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select the Machine Learning Model > Annotations page, then click the Annotation Tasks tab. Open the task that you want to evaluate.\n3. Click Calculate Inter-Annotator Agreement. The default view shows agreement scores for how consistently pairs of human annotators annotated mentions. The top row shows the overall consistency between each pair of annotators, and the table below shows how consistently a pair of annotators labeled specific mentions in the text.\n4. To explore how consistently pairs of human annotators annotated relations and coreferences, select Relation or Coreference from the first menu.\n5. To explore how consistently a pair of human annotators annotated entities, relations, or coreferences in specific overlapping documents, select Document in the second menu and then select the pair of annotators that you want to evaluate.\n6. After reviewing the scores, you can decide whether you want to approve or reject annotation sets that are in Submitted status. After an annotation set is submitted, a check box is displayed next to its name. Take one of these actions:\n\n\n\n* If the inter-annotator agreement scores are acceptable for an annotation set, select the check box and click Accept.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16417-7044-9159","score":12.7102661133,"text":"\nYou can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common. For another example, if you create annotation sets with overlapping documents, but add one annotation set per task instead of adding all of the annotation sets to a single task, no overlapping documents will be found and inter-annotator agreement cannot be calculated.\n\n\n\n\n\n Procedure \n\nTo assess annotation agreement between human annotators:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select the Machine Learning Model > Annotations page, then click the Annotation Tasks tab. Open the task that you want to evaluate.\n3. Click Calculate Inter-Annotator Agreement. The default view shows agreement scores for how consistently pairs of human annotators annotated mentions. The top row shows the overall consistency between each pair of annotators, and the table below shows how consistently a pair of annotators labeled specific mentions in the text.\n4. To explore how consistently pairs of human annotators annotated relations and coreferences, select Relation or Coreference from the first menu.\n5. To explore how consistently a pair of human annotators annotated entities, relations, or coreferences in specific overlapping documents, select Document in the second menu and then select the pair of annotators that you want to evaluate.\n6. After reviewing the scores, you can decide whether you want to approve or reject annotation sets that are in Submitted status. After an annotation set is submitted, a check box is displayed next to its name. Take one of these actions:\n\n\n\n* If the inter-annotator agreement scores are acceptable for an annotation set, select the check box and click Accept.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_09148-8939-9806","score":12.561000824,"text":"\nTo setup a metric, complete the follow steps.\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert at the top of the page.\n3. Select Metric as the alert type.\n4. Select the aggregation and the metric that you would like to be performed on.\n5. Select the scope if applicable.\n6. Set the metric and time requirements for the alert to trigger.\n7. Configure and set up the notification channel and notification interval.\n8. Click the CREATE button.\n\n\n\nThe figure as shown provides an example of how to configure an alert when your service instance receives multiple 401 and 403 errors within a 10 minute time span.\n\nZoom\n\n![An example of a 401 and 403 configuration.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc\/key-protect\/images\/monitor-401-alert.png)\n\nFigure 5. The configuration for a 401 alert in a Monitoring dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-operational-metrics"},{"document_id":"ibmcld_16410-8324-10312","score":12.5490903854,"text":"\nInter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set.\n\nYou cannot change the annotation set name after the set is created.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.\n* Open a task to add annotation sets to it. Ensure that the annotation sets that you add include documents that overlap with documents in the original annotation sets.\n\n\n\nFrom the Settings tab of the main navigation, you can specify the following information:\n\n\n\n* Specify preferences for using colors and keyboard shortcuts in the ground truth editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16410-6875-8784","score":12.1388673782,"text":"\nTo add an annotation set in one task to a different task, you must first delete the task where the annotation set is active.\n* If you delete a human annotator's user account, it affects their annotations too. Any annotations in documents that were assigned to that user but were not promoted to ground truth are deleted.\n* If the type system or ground truth editor settings change after you create a human annotation task, you must decide whether to propagate the changes to the task. Type system changes can affect annotations; human annotators might need to review and update their documents.\n* If the dictionaries change, the changes are not reflected in the current annotation task. To apply resource changes to ground truth, you must create a new annotation task.\n* You can have up to 256 annotation tasks per workspace.\n\n\n\n\n\n\n\n\n\n Procedure \n\nTo create an annotation task:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. Select the Machine Learning Model > Annotations page, then click the Annotation Tasks tab.\n3. Click Add Task.\n4. Specify a descriptive task name and select the date that the task must be completed.\n5. If no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_05263-22429-24294","score":12.0120706558,"text":"\nYou can change this behavior by updating your application and setting the minimum scale to 1 either in the console or from the CLI.\n\nThe default value for the maximum number of instances for your app is 0, which allows your app to scale as needed. For more information, see [Scaling boundaries](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-app-scaleapp-scale-boundaries).\n\n\n\n Changing the autoscaling range from the console \n\nTo change the range within which Code Engine autoscales the number of running instances for an app from the console, follow these steps.\n\n\n\n1. Navigate to your app.\n2. Select Configuration\n3. Click Edit and create new revision.\n4. Select Runtime.\n5. Set the number for minimum and maximum instances for your app.\n6. (Optional) Review and set the request concurrency and timing settings for autoscaling your app.\n7. Click Save and Create.\n\n\n\nWhen you update your application, your app creates a new revision and routes traffic to that instance.\n\n\n\n\n\n Changing the autoscaling range with the CLI \n\nTo change the range within which Code Engine autoscales the number of running instances for an app with the CLI, run the [application update](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-application-update) command with the --min-scale and --max-scale options set to the number of instances that you want for your app. You can optionally set request concurrency and timing settings for your app. These options include --concurrency, --concurrency-target, --request-timeout, and --scale-down-delay. For more information about setting these autoscaling values, see [Scaling boundaries](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-app-scaleapp-scale-boundaries), and [Autoscaling settings for concurrency and timing](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-app-scaleapp-scale-timeconcurrency).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-app-scale"},{"document_id":"ibmcld_09382-5993-6824","score":12.0048904419,"text":"\nAdd a user or service ID to the access group \n\nContinue to set up your group by adding users or service IDs.\n\n\n\n Add a user to the access group \n\nComplete the following steps to add a user:\n\n\n\n1. From the menu bar, click Manage > Access (IAM), and select Access Groups.\n2. Select the name of the group that you want to assign access to.\n3. Click Add users on the Users tab.\n4. Select the users that you want to add from the list, and click Add to group.\n\n\n\n\n\n\n\n Add a service ID to the access group \n\nComplete the following steps to add a service ID:\n\n\n\n1. From the menu bar, click Manage > Access (IAM), and select Access Groups.\n2. Select the name of the group that you want to assign access to.\n3. Click the Service IDs tab, and click Add service ID.\n4. Select the IDs that you want to add from the list, and click Add to group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-iam_manage_events"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15918-37367-38469","score":23.1663417816,"text":"\nThe Snapshot for VPC service is integrated with the IBM Cloud\u00ae Security and Compliance Center to help you manage security and compliance for your organization. For snapshots, you can set up a goal that checks whether snapshots are encrypted by using customer-managed keys. By using the Security and Compliance Center to validate the snapshot resource configurations in your account against a profile, you can identify potential issues as they arise.\n\nBecause snapshots are created from Block Storage for VPC volumes, Block Storage for VPC goals provide an extra level of security. For more information, see [Monitoring security and compliance posture with VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-security-compliancemonitor-vpc). For more information about creating security and compliance goals, see [Defining rules](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-rules-define&interface=ui) in the Security and Compliance Documentation.\n\n\n\n\n\n Next steps \n\nYou can [Restore a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-manage"},{"document_id":"ibmcld_15922-37393-38495","score":23.1663417816,"text":"\nThe Snapshot for VPC service is integrated with the IBM Cloud\u00ae Security and Compliance Center to help you manage security and compliance for your organization. For snapshots, you can set up a goal that checks whether snapshots are encrypted by using customer-managed keys. By using the Security and Compliance Center to validate the snapshot resource configurations in your account against a profile, you can identify potential issues as they arise.\n\nBecause snapshots are created from Block Storage for VPC volumes, Block Storage for VPC goals provide an extra level of security. For more information, see [Monitoring security and compliance posture with VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-security-compliancemonitor-vpc). For more information about creating security and compliance goals, see [Defining rules](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-rules-define&interface=ui) in the Security and Compliance Documentation.\n\n\n\n\n\n Next steps \n\nYou can [Restore a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-manage&interface=ui"},{"document_id":"ibmcld_15921-37405-38507","score":23.1663417816,"text":"\nThe Snapshot for VPC service is integrated with the IBM Cloud\u00ae Security and Compliance Center to help you manage security and compliance for your organization. For snapshots, you can set up a goal that checks whether snapshots are encrypted by using customer-managed keys. By using the Security and Compliance Center to validate the snapshot resource configurations in your account against a profile, you can identify potential issues as they arise.\n\nBecause snapshots are created from Block Storage for VPC volumes, Block Storage for VPC goals provide an extra level of security. For more information, see [Monitoring security and compliance posture with VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-security-compliancemonitor-vpc). For more information about creating security and compliance goals, see [Defining rules](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-rules-define&interface=ui) in the Security and Compliance Documentation.\n\n\n\n\n\n Next steps \n\nYou can [Restore a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-manage&interface=cli"},{"document_id":"ibmcld_15007-3814-5680","score":22.8209247589,"text":"\nBehind the scenes, the [Snapshot for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about) service is used to create a point-in-time copy of your data. When the first backup snapshot is taken, the entire contents of the volume are copied and retained in IBM Cloud\u00ae Object Storage. Subsequent backups of the same volume capture the changes that occurred since the previous backup. You can take up to [750 backups of a volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots_vpc_considerations).\n\nYou can [restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-aboutbackup-service-restore-concepts) data from a backup snapshot to a new, fully provisioned volume. If the backup is of a boot volume, you can use it to provision a new instance. However, when you provision an instance by restoring a boot volume from a bootable backup snapshot, you can expect degraded performance in the beginning. During the restoration process, the data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC, and thus the provisioned IOPS cannot be fully realized until that process finishes.\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. The [cross-regional copy](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-aboutbackup-service-crc) can be used in disaster recovery scenarios when you need to turn on your virtual server instance and data volumes in a different region. The remote copy can be created automatically as part of a backup plan, or manually later.\n\nWith the fast restore feature, you can cache snapshots in a specified zone of your choosing. This way, volumes can be restored from snapshots nearly immediately and the new volumes operate with full IOPS instantly. The fast restore feature can achieve a","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about"},{"document_id":"ibmcld_15007-5092-6710","score":22.4164829254,"text":"\nThe [cross-regional copy](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-aboutbackup-service-crc) can be used in disaster recovery scenarios when you need to turn on your virtual server instance and data volumes in a different region. The remote copy can be created automatically as part of a backup plan, or manually later.\n\nWith the fast restore feature, you can cache snapshots in a specified zone of your choosing. This way, volumes can be restored from snapshots nearly immediately and the new volumes operate with full IOPS instantly. The fast restore feature can achieve a\n\nrecovery time objective(RTO) quicker than restoring from a regular backup snapshot. When you opt for fast restore, your existing regional plan is adjusted, including billing. For more information about the cost of fast restore, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n Comparison of backups and snapshots \n\nBackups are in effect, backup snapshots. In the console, backups appear in the list of Block Storage for VPC snapshots. Backups are identified by how they were created, in this case, by backup policy. These terms are used interchangeably in the Documentation, depending on the context.\n\nThe snapshots service is used to create backups, similarities and differences exist between backups and snapshots. Table 1 compares backups to snapshots.\n\n\n\nTable 1. Comparison of backups and snapshots\n\n Feature Backup Snapshot \n\n Backs up Block Storage for VPC boot and data volumes. ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/icons\/checkmark-icon.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about"},{"document_id":"ibmcld_15810-54092-55873","score":22.3431606293,"text":"\nFor more information, see [IBM Wazi as a Service product page](https:\/\/www.ibm.com\/cloud\/wazi-as-a-service).\n\nFile storage for VPC\n: You can now access a customer root key (CRK) from one account, and then use that key to encrypt file shares you create in another account. When you create the file share, you specify the CRN of a root key from the account that contains the key. For more information, see [Cross-account encryption for multitenant file storage resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-byok-cross-acct-key-file).\n\n\n\n\n\n 24 June 2022 \n\nNew stock image for bare metal servers\n: Ubuntu (20.04 and 18.04) is now supported as an image when you provision a bare metal server.\n\n\n\n\n\n 21 June 2022 \n\nBackup for VPC (GA)\n: You can now create automated backup snapshots of your block storage volumes. If your original volume is compromised, you can restore it from a backup snapshot. You create a backup policy to control which source volumes are selected for backup by matching user tags in the volume with tags that are defined in the policy. Each policy contains up to four backup plans, which define how often backup snapshots are taken (daily, weekly, monthly, or more frequently by using a cron-spec) and retained (by date or by count). You can also view backup jobs, which show status of backup snapshots that are being created or deleted. For more information about this service, see [Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n\nThe backup policy jobs API remains in [beta](https:\/\/cloud.ibm.com\/apidocs\/vpc-beta24-may-2022).\n\n\n\n\n\n 10 June 2022 \n\nBlock Storage for VPC\n: You can use the volumes API to restore an unattached data volume from a snapshot. Restoring from a snapshot creates a new, fully provisioned volume.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-release-notes"},{"document_id":"ibmcld_15020-3827-5719","score":22.3174209595,"text":"\nBehind the scenes, the [Snapshot for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about) service is used to create a point-in-time copy of your data. When the first backup snapshot is taken, the entire contents of the volume are copied and retained in IBM Cloud\u00ae Object Storage. Subsequent backups of the same volume capture the changes that occurred since the previous backup. You can take up to [750 backups of a volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots_vpc_considerations).\n\nYou can [restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=uibackup-service-restore-concepts) data from a backup snapshot to a new, fully provisioned volume. If the backup is of a boot volume, you can use it to provision a new instance. However, when you provision an instance by restoring a boot volume from a bootable backup snapshot, you can expect degraded performance in the beginning. During the restoration process, the data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC, and thus the provisioned IOPS cannot be fully realized until that process finishes.\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. The [cross-regional copy](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=uibackup-service-crc) can be used in disaster recovery scenarios when you need to turn on your virtual server instance and data volumes in a different region. The remote copy can be created automatically as part of a backup plan, or manually later.\n\nWith the fast restore feature, you can cache snapshots in a specified zone of your choosing. This way, volumes can be restored from snapshots nearly immediately and the new volumes operate with full IOPS instantly. The fast restore feature can achieve a","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=ui"},{"document_id":"ibmcld_15020-5118-6749","score":22.2706336975,"text":"\nThe [cross-regional copy](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=uibackup-service-crc) can be used in disaster recovery scenarios when you need to turn on your virtual server instance and data volumes in a different region. The remote copy can be created automatically as part of a backup plan, or manually later.\n\nWith the fast restore feature, you can cache snapshots in a specified zone of your choosing. This way, volumes can be restored from snapshots nearly immediately and the new volumes operate with full IOPS instantly. The fast restore feature can achieve a\n\nrecovery time objective(RTO) quicker than restoring from a regular backup snapshot. When you opt for fast restore, your existing regional plan is adjusted, including billing. For more information about the cost of fast restore, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n Comparison of backups and snapshots \n\nBackups are in effect, backup snapshots. In the console, backups appear in the list of Block Storage for VPC snapshots. Backups are identified by how they were created, in this case, by backup policy. These terms are used interchangeably in the Documentation, depending on the context.\n\nThe snapshots service is used to create backups, similarities and differences exist between backups and snapshots. Table 1 compares backups to snapshots.\n\n\n\nTable 1. Comparison of backups and snapshots\n\n Feature Backup Snapshot \n\n Backs up Block Storage for VPC boot and data volumes. ![Checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/icons\/checkmark-icon.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=ui"},{"document_id":"ibmcld_15957-3967-5967","score":22.2069244385,"text":"\n99.999999999% (11 nines) durability means that if you store 10 million files, then you expect to lose one file every 10000 years.\n\nWhen people hear the word durability, most of them think of hardware failures of storage, compute, and network components that might cause data loss. In VPC storage, your data is protected against drive failures and numerous type of disk errors that otherwise might negatively impact data durability and data integrity. The data is stored redundantly across multiple physical disks in an Availability Zone to prevent data loss due to failure of any single component.\n\nOther than physical failure, a common source of data loss is accidental deletion or modifications of files by users. Block Storage for VPC, Snapshots for VPC, and File Storage for VPC are only accessible to authorized hosts within your virtual private network. You control who can access it. For more information, see [Managing security and compliance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-security-compliance).\n\nAnother measure to protect against accidental deletion and modification of files is a snapshot. If a user accidentally modifies or deletes crucial data from a volume, the data can be easily and quickly restored from a snapshot or a backup. For more information about this feature, see [About Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n\nThe 11 nines durability target applies to a single Availability Zone. To protect against natural or man-made disasters that might destroy an entire Availability Zone, consider storing your most important data in multiple locations. For more information, see [Understanding high availability and disaster recovery](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-ha-dr-vpc).\n\n\n\n\n\n High Availability \n\nVPC storage is built upon best-in-class, proven, enterprise-grade hardware and software to ensure high availability and uptime. The data is stored redundantly across multiple physical disks on HA paired nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-storageavailability"},{"document_id":"ibmcld_15034-6870-7844","score":22.1318969727,"text":"\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-vpc-faq"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09081-1687-4004","score":16.0215187073,"text":"\nData encryption keys (DEKs) are designed to encrypt your data and can be generated and managed by your service or an IBM Cloud service.\n\nEnvelope encryption offers several benefits for protecting your data:\n\n\n\n* Protection under a combination of multiple algorithms Envelope encryption uses the best benefits from symmetric and public key algorithms to keep your keys secure.\n\n\n\n1. Symmetric key algorithms work faster, are more scalable, and more secure than public key algorithms. Public key algorithms use complicated mathematics that increase computational overhead, especially when dealing with large volumes of data. Public key algorithms are also more susceptible to brute force attacks due to having a private key algorithm component that is easily recognizable by hackers. Symmetric key algorithms requires less computed power and are resistant to brute force attacks due to having a less recognizable structure.\n2. Public key algorithms allow for easier access control when granting access to keys at an individual level compared to symmetric key algorithms. Symmetric key algorithms have a key exchange problem, which is that access to a secret key can only be exchanged through a secure transfer. By using public key algorithms, encrypted DEKs (wDEKs) can be shared and unencrypted only by those with access to the encrypting root key, mitigating the key exchange problem of symmetric algorithms.\n\n\n\n* Easier key management You can encrypt multiple DEKs under a singular root key, which minimizes the amount of keys that you might need to manage in a key management service. You can also choose to save time on key maintenance by only rotating your root keys, instead of rotating and re-encrypting all of your DEKs. Note that in cases such as personnel turnover, process malfunctions, or the detection of a security issue, it is recommended to rotate all DEKs and root keys associated with the incident.\n* Data Key Protection Since your DEKs are wrapped by a root key, you do not have to worry about how to store the encrypted data key. Due to this, you can store the wDEK with alongside the associated encrypted data.\n\n\n\nKey Protect uses the Advanced Encryption Standard algorithm in Galois\/Counter Mode (AES GCM) to wrap and unwrap DEKs. CRKs that are not imported are created with 256-bit key material.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption"},{"document_id":"ibmcld_12678-7-2410","score":15.8401794434,"text":"\nKnown issues (Limitations) \n\nUse this topic to find the details of the limitations that are applicable to the Data Security Broker software.\n\n\n\n Application-level Encryption: \n\nData Security Broker encryption gives database applications a no-code way to implement application-level encryption. Application-level encryption can be implemented by including a database proxy that intercepts and encrypts sensitive data in accordance with the pre-established data protection policy.\n\nData Security Broker encryption has some restrictions, like any other approaches to the application-level encryption implementation. The various aspects of the application level encryption limitations are explained below:\n\nPerformance hit Data encryption consumes more time and resources than data decryption. This overhead is normally negligible. If the proxy (Shield) has an appropriately sized CPU and Memory, there should not be any noticeable performance penalties. Most users experience a 10--20% reduction in the overall application performance. This can be mitigated by horizontal scaling. In the event of failure, Shield can be horizontally scaled by adding more of them behind a load balancer.\n\nKey management You must have a place to store your secret key or key file. You can use IBM Key Protect. IBM Key Protect provides full encryption visibility and control, allowing you to see and manage data encryption and the entire key lifecycle from a single location. Alternatively, you can secure the information with a password, but this reduces security, depending on the level of your password's strength.\n\nAccessibility If your key file is lost, your data is also lost. So, make a backup of your data and your key.\n\nDatabase operations carried out on encrypted versions of the data The information is kept in encrypted form in the database and the database engine and, consequently, the database administrator is never permitted to see the information in form of the plaintext.\n\nMany of today's server and network technologies allow for easier configuration and implementation to minimize the impact on utilization. Implementing encryption of data in transit from endpoint to endpoint both remotely and internally is mandatory in today's cyber risk environment.\n\nThe following are considered equality check operators and are supported:\n\n\n\n* =\n* <>\n* IS NULL\n* IS NOT NULL\n* IN\n* NOT\n* JOIN (all types)\n* GROUP BY","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_limitations"},{"document_id":"ibmcld_08739-8238-10173","score":15.5876188278,"text":"\n* With TDE, you can encrypt sensitive data on database storage media, such as table spaces and files, and on backup media. Transparent Data Encryption ensures that sensitive data is encrypted, meets compliance, and provides functionality that streamlines encryption operations. The database system automatically and transparently encrypts and decrypts data when it is used by authorized users and applications. Database users do not need to be aware of TDE and database applications do not need to be adapted specifically for TDE.\n\nTDE uses a two-tiered key hierarchy that is composed of a TDE master encryption key and a TDE data encryption key. The TDE data encryption key is used to encrypt and decrypt data, while the TDE master encryption key is used to encrypt and decrypt the TDE data encryption key.\n\nZoom\n\n![Transparent Database Encryption by using the standard PKCS #11 API](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/hs-crypto\/\/images\/pkcs-database.svg)\n\nFigure 5. Transparent Database Encryption by using the standard PKCS #11 API\n* IBM Db2 default encryption protects key database files and database backup images from inappropriate access while they are stored on external storage media. The database system automatically encrypts and decrypts data when it is used by authorized users and applications. Typically, database users do not need to be aware of default encryption and database client applications do not need to be adapted specifically.\n\nDb2 default encryption uses a two-tiered key hierarchy: Data is encrypted with a data encryption key (DEK). The DEK is encrypted with a master key and is stored in encrypted form with the database or the backup image. A unique DEK is generated by Db2 for each encrypted database and for each encrypted backup. A master key is used to encrypt a DEK. Each encrypted database is associated with one master key at one time.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-uko-use-cases"},{"document_id":"ibmcld_01145-7-1486","score":15.4346065521,"text":"\nData security and privacy \n\nIBM\u00ae uses the following methods to help ensure the security and privacy of your data.\n\n\n\n Cryptographic protocols \n\n\n\n* Connections are restricted to the following strong cipher suites:\n\n\n\nFor TLS v1.2:\n\n* TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\n* TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\n* TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\n\nFor TLS v1.3:\n\n* TLS_AES_128_GCM_SHA256\n* TLS_AES_256_GCM_SHA384\n* TLS_CHACHA20_POLY1305_SHA256\n\n\n\n* To be a fully supported configuration, all clients must support the following:\n\n\n\n* TLS v1.2 or v1.3\n* Elliptic curve cryptography\n* TLS server name indication (SNI)\n\n\n\n* Additionally, you must use TLS v1.2 or v1.3 in the following cases:\n\n\n\n* To make connections to the Kafka native and REST interfaces.\n* The browser that you use to access the Event Streams dashboard must support TLS v1.2 or v1.3.\n\n\n\n\n\n\n\n\n\n Encryption of message payloads, topic names, and consumer groups \n\nMessage data is encrypted for transmission between Event Streams and clients as a result of TLS. Event Streams stores message data at rest and message logs on encrypted disks.\n\nTopic names and consumer groups are encrypted for transmission between Event Streams and clients as a result of TLS. However, Event Streams does not encrypt these values at rest. Therefore, do not use confidential information in your topic names.\n\nOn the Satellite plan, all encryption is determined by the options that you specify on your chosen storage provider.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-data_security"},{"document_id":"ibmcld_12655-1658-4229","score":15.4109544754,"text":"\nThe encryption process manages keys that are generated by a commercially available key management service such as IBM\u00ae Key Protect and Hyper Protect Crypto Services.\n\nApplication performance is minimally impacted allowing for enterprise workflows to continue to operate in a secure environment. The Data Security Broker Manager is the cloud-based management console providing scalability, fault tolerance, and manageability of the software.\n\n\n\n\n\n Encryption Technology Configuration Overview: \n\nData Security Broker supports data protection services that can be configured in four main modes.\n\n\n\n Data Encryption: \n\nData Security Broker functions as an application-level encryption (ALE) software in this mode for encrypting data on a field-level basis. This is performed using Data Security Broker Manager to enumerate the data schema and enable an encryption key mapping.\n\n\n\n\n\n Data Tokenization: \n\nData Security Broker supports length preserving and data type preserving tokenization method to anonymize data at the field level databases or in semi-structured data files.\n\n\n\n\n\n Record Level Encryption: \n\nData Security Broker can be configured for record level encryption to support multiple keys within a single column that are mapped to respective data owners or entities. This encryption mode can be used effectively in multi-tenant or shared data environments where segmenting of the data can be challenging. In this mode, data shredding can be enabled by deleting public keys and private keys for a respective entity.\n\n\n\n\n\n Data Masking: \n\nData Security Broker can enable simplified data masking to prevent decryption of data and sensitive file information based on configuration or deleted keys. This mode can minimize data exposure in public cloud environment and provides a better control of data exfiltration to external parties.\n\n\n\n\n\n\n\n Deployment Plans in IBM Cloud Data Data Security Broker: \n\nWhen you assign and customize default Data Protection Policies with Data Security Broker Manager, there are three options that you can choose to implement your data encryption policy:\n\n\n\n Save Policy: \n\nSave Policy option is selected by default. This option saves your selected data, but does not execute encryption or data protection on your database. Your policy remains saved with the application until a new policy is saved to overwrite it. You can use the saved policy to deploy or migrate it later.\n\n\n\n\n\n Deploy Policy: \n\nDeploy Policy option saves your policy and deploys your configured Data Security Broker Shield as a proxy for the configured database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_about"},{"document_id":"ibmcld_03869-10240-12288","score":15.1447267532,"text":"\nEncryption uses a two-way function to transform data into a form that hides its original value, but can be converted back to the original state. As an example, when data is sent over a network that is secured using TLS, the data is encrypted using a TLS certificate. It is then sent over the network as crypto text, and then decrypted by the recipient. The encrypted text contains all the original data, and can be decrypted using a private key. However, hashing is a one-way function that uses data to create a unique string of numbers and letters. The hashed data cannot be converted back to the original form using the hash. To verify the data that created the hash, a recipient needs to create a new hash of the original data using the same hash function, and verify that the hash values match. A third party cannot use the hash without a copy of the original data.\n\nIt is important to be aware with this option that while Orgs A and B cannot see the actual ledger data because it is hashed, they are still able to see that Orgs C and D are transacting and can see the volume of transactions that are occurring between them.\n\nAlso, consider that data inside a private data collection can be purged from the peers that store it. While data is stored on a channel forever, collections allow members to specify how many blocks are committed to a channel before the [private data is purged](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/private_data_tutorial.htmlpd-purge). Once data is removed from the private data collection, the hash on the channel can no longer be used to verify the transaction that created it. In the example network in Figure 3, Org C and Org D can use a block to live policy to ensure that any data that does not need to persist forever is removed from the network entirely within a specified time period.\n\n\n\n\n\n Option two: Private data collections on a separate channel \n\nOrg C and Org D can also use private data collections in the context of a separate channel to provide additional isolation for their data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-console-icp-about-data-residency"},{"document_id":"ibmcld_08713-7-1935","score":14.7887239456,"text":"\nUsing Hyper Protect Crypto Services PKCS 11 for Oracle Transparent Database Encryption \n\nTransparent Data Encryption (TDE) is a well-established technology to encrypt sensitive data in databases. TDE is supported by various popular database systems, both in the cloud and on premises, like Oracle\u00ae database. With TDE, a database system encrypts data on database storage media, such as table spaces and files, and on backup media. The database system automatically and transparently encrypts and decrypts data when it is used by authorized users and applications. Database users do not need to be aware of TDE and database applications do not need to be adapted specifically for TDE.\n\nTypically, TDE uses a two-tiered key hierarchy, which is composed of a TDE master encryption key and a TDE data encryption key. The TDE data encryption key is used to encrypt and decrypt data, while the TDE master encryption key is used to encrypt and decrypt the TDE data encryption key.\n\nTherefore, one important question when you plan for TDE is: Where do you keep the TDE master encryption key, and how do you secure it?\n\n\n\n Objectives \n\nThis tutorial shows how you can keep complete and exclusive control of your TDE master encryption keys by storing them in IBM Cloud\u00ae Hyper Protect Crypto Services. For this purpose, you need to use the PKCS #11 integration feature of Hyper Protect Crypto Services.\n\nWith this tutorial, you are going to implement the setup that is depicted in the following illustration.\n\nZoom\n\n![Transparent Database Encryption by using the standard PKCS #11 API](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/hs-crypto\/images\/pkcs-database.svg)\n\nFigure 1. Transparent Database Encryption by using the standard PKCS #11 API\n\nIn this setup, the Oracle Database is to call operations to manage the TDE master encryption keys on the Hyper Protect Crypto Services PKCS #11 library.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-tde-pkcs11"},{"document_id":"ibmcld_08008-7-1954","score":14.4952020645,"text":"\nData encryption at rest \n\nProtecting data against unauthorized disclosure, modification or destruction throughout the data lifecycle is of paramount importance in the IBM Cloud for Financial Services. Cryptographic controls must be in place in all regions and availability zones to protect the confidentiality and integrity of data. Data at rest is to always be encrypted using your keys.\n\n\n\n Data encryption at rest in IBM Cloud \n\nWithin IBM Cloud, you must use [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-overview) to manage encryption keys. Hyper Protect Crypto Services is a dedicated key management service and hardware security module (HSM). Hyper Protect Crypto Services is the only service in the cloud industry that is built on FIPS 140-2 Level 4-certified hardware.\n\nWith Hyper Protect Crypto Services you can take ownership of the cloud HSM to fully manage your encryption keys and to perform cryptographic operations by using [Keep Your Own Key (KYOK)](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-understand-conceptskyok-concept). This means you have full control and authority over encryption keys. No one except you (not even IBM) has access to your encryption keys.\n\nYou must ensure that:\n\n\n\n* Keys are created for a single purpose, and dedicated encryption keys are unique per consumer.\n* Keys have a lifecycle that is defined and are rotated periodically based on IBM Cloud Framework for Financial Services controls.\n* Recovery functions, if used, can be accessed only by authorized personnel.\n\n\n\n\n\n Setting up Hyper Protect Crypto Services \n\n\n\n* Provision and configure an instance of Hyper Protect Crypto Services. See [Getting started with Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-get-started) for specific instructions.\n\n\n\nFor the highest level of security, you should use smart cards when initializing Hyper Protect Crypto Services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-encryption-at-rest"},{"document_id":"ibmcld_08462-7-2096","score":14.4432935715,"text":"\nProtecting your data with envelope encryption - Standard Plan \n\nEnvelope encryption is the practice of encrypting data with a\n\ndata encryption key (DEK)and then wrapping the DEK with aroot keythat you can fully manage. The root keys in Hyper Protect Crypto Services service instance are also wrapped and protected by the hardware security module (HSM)master key.\n\nWith envelope encryption, Hyper Protect Crypto Services protects your at-rest data with advanced encryption and offers the following benefits:\n\n\n\nTable 1. Describes the benefits of customer-managed encryption\n\n Benefit Description \n\n Customer-managed encryption keys With the service, you can provision root keys to protect the security of your encrypted data in the cloud. Root keys serve as key-wrapping keys, which help you manage and safeguard the data encryption keys (DEKs) provisioned in IBM Cloud data services. You decide whether to [import your existing root keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-import-root-keys), or have Hyper Protect Crypto Services [generate root keys on your behalf](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-create-root-keys). \n Confidentiality and integrity protection Hyper Protect Crypto Services uses the Advanced Encryption Standard (AES) algorithm in Cipher Blocker Chaining (CBC) mode to create and protect keys. When you create keys in the service, Hyper Protect Crypto Services generates them in the Hyper Protect Crypto Services instance and the master key encrypts the keys to ensure only you have the access. \n Cryptographic shredding of data If your organization detects a security issue, or your application no longer needs a set of data, you can choose to shred the data permanently from the cloud. When you delete a root key that protects other DEKs, you ensure that the keys' associated data can no longer be accessed or decrypted. \n Delegated user access control By assigning Cloud Identity and Access Management (IAM) roles, Hyper Protect Crypto Services supports a centralized access control system to enable granular access for your keys.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-envelope-encryption"},{"document_id":"ibmcld_14893-18490-20377","score":14.3754558563,"text":"\nThe information provided in this section is used to mount the attached data volume (provided by the user) and is later encrypted using the \"seeds\" provided in the workload and env sections. You can provide any path of your choice for the \"mount\" field. The path provided by the user is used internally to mount the data volume. The mount path provided in the contract must match the path provided under the volumes section of the docker-compose.yaml file, so that all the data associated with the container workload is stored in this data volume.\n\nThe volumes subsection has support for auto encryption of the data volume with user-provided seeds. If a data volume is attached to the Hyper Protect Virtual Servers instance, it is encrypted automatically with the seeds that are provided through the \"seed\" field in the volumes subsections of the contract. Thus two seeds must be provided, one through the workload section (by the workload persona) and the other through the env section (by the deployer persona). These two seeds are internally converted to UTF8 sequences and then concatenated. Later, the hash (SHA256) of the concatenated sequence is computed as a hexdigest, which is used as the LUKS passphrase to encrypt the data volume. You can use the following command to validate the hexdigest:\n\necho -n \"seed1seed2\" | sha256sum\n\nHere you can learn how the \"seed\" can be provided in the workload section of the contract. For more information about how the \"seed\" input can be provided through the env section, see [The env section](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-contract_sehpcr_contract_env). It is mandatory to provide both the seeds for encryption. Encryption fails if only one of the seeds is provided instance shuts down.\n\nYou can add a higher level of encryption protection and control to your data at rest by integrating with Hyper Protect Crypto Services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-contract_se"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.39038005}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14774-27023-28718","score":21.0487480164,"text":"\nIf a local restore is needed, the VMware datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the protected region HPCS instance through the KMIP for VMware service.\n5. Veeam network encryption is used for file and backup copy jobs to the recovery region.\n6. VM backup files are encrypted on disk in the recovery region Veeam Repository with Veeam encryption.\n7. If a restore is needed in the recovery region, the Veeam datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the recovery region HPCS instance through the KMIP for VMware service.\n\n\n\nFor more information about Veeam encryption, see [Encryption standards](https:\/\/helpcenter.veeam.com\/docs\/backup\/vsphere\/encryption_standards.html?ver=100).\n\nIn the IBM Cloud for VMware\u00ae Regulated Workloads dual region design for SaaS Consumer key management, then the same encryption keys are required in the recovery region as used in the protected region. Currently, HPCS does not support the same encryption keys in two regions. If a failure of the first HPCS instance occurs, keys can be restored to another HPCS instance in another region.\n\nFor more information, see:\n\n\n\n* [HPCS cross-region disaster recovery](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-drcross-region-disaster-recovery)\n* [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data)\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Caveonix integration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-caveonix)\n* [Veeam on IBM Cloud overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeamvm_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-dualregion-design"},{"document_id":"ibmcld_14774-18795-21198","score":20.6818351746,"text":"\nWhile this design has only one backup server instance, it is recommended to deploy Enterprise Manager when encryption is used for backup or backup copy jobs. It is advised to install the Enterprise Manager server on the recovery site so it is available for disaster recovery.\n* Proxy server - This proxy is used for management components that are located in the recovery region.\n* Repository - A location used to store backup files for the management components in the recovery region and also the target for backup copy jobs from the protected region.\n* SFTP\/SMB server - These servers are not Veeam services but native Windows services that are used for file-level backups of some of the management components. A Veeam file copy job copies files to the protected region for extra protection.\n\n\n\nReview the following Veeam design decisions:\n\n\n\n* For optimal performance and availability, placing the Veeam components on separate virtual and physical servers is considered best practice. However, this practice increases complexity in smaller environments. Therefore, the all-in-one deployment scenario for use case 1 is selected.\n* As the total number of protected VMs is low, the embedded database option for the database for use case 1 is selected.\n* The bare metal servers with direct attached storage option are used as it provides a backup infrastructure that is separated from the virtualized infrastructure compute and storage.\n* In a two-site environment, it is best practice to install the Veeam Backup server component in the DR site. In a disaster situation, Veeam Backup server is available to start the recovery.\n* Deploy Enterprise Manager to use password loss protection. Enterprise Manager administrators can unlock backup files by using a challenge-response mechanism.\n* It is recommended that the proxy is as close as possible to the source data with a high-bandwidth connection. The traffic from the source to the proxy is not yet optimized, meaning that 100% of the backup data is transferred over this link. A good connection is required between proxy and repository as optimized data (normally 50% of the source data size) is transferred across this link. Therefore, place proxies in both the protected and recovery regions.\n* Proxies can be hosted on Windows Server or Linux OS with almost no performance differences. For the all-in-one deployment scenario, a Windows OS is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-dualregion-design"},{"document_id":"ibmcld_14774-17155-19347","score":20.6443710327,"text":"\nFor more information, see [Repository storage](https:\/\/bp.veeam.com\/vbr\/VBP\/2_Design_Structures\/D_Veeam_Components\/D_backup_repositories\/repositories%20storage.html).\n\nThe protected region bare metal Windows server hosts the following components:\n\n\n\n* Proxy - A proxy is a \u201cdata mover\u201d component that is used to retrieve VM data from the source datastore, process it and deliver to the target. As a rule, have the proxy as close as possible to the source data. This proxy is used for management components that are located in the protected region.\n* Repository - A location used to store backup files for the management components in the protected region and also the target for backup copy jobs from the recovery region.\n* SFTP\/SMB server - These servers are not Veeam services but native Windows services that are used for file-level backups of some of the management components. A Veeam file copy job copies files to the recovery region for extra protection.\n\n\n\nThe recovery region bare metal Windows server hosts the following components:\n\n\n\n* Backup server - In a two-site environment where replication is used, best practice is to install the Veeam Backup server component in the DR site. In a disaster situation, the backup server is available to start the recovery.\n* Veeam Backup & Replication Database - Veeam Backup & Replication stores information about backup infrastructure, jobs settings, job history, sessions, and other configuration data in a Microsoft SQL Server database.\n* Enterprise Manager - Enterprise Manager provides centralized management and reporting for one or multiple backup servers through a web interface. While this design has only one backup server instance, it is recommended to deploy Enterprise Manager when encryption is used for backup or backup copy jobs. It is advised to install the Enterprise Manager server on the recovery site so it is available for disaster recovery.\n* Proxy server - This proxy is used for management components that are located in the recovery region.\n* Repository - A location used to store backup files for the management components in the recovery region and also the target for backup copy jobs from the protected region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-dualregion-design"},{"document_id":"ibmcld_14533-1761-4064","score":20.6171760559,"text":"\nThe encryption key is not stored and is unavailable to IBM. After the VMware Cloud Director Data Center is deleted, all backups are deleted, and cannot be recovered.\n\n\n\n\n\n High availability and disaster recovery \n\nThe VMware Shared management service is initially only offered in the IBM Cloud NA South and Europe regions. Recovering from potential disasters that affect an entire location requires planning and preparation.\n\n\n\n* You are responsible for understanding your configuration, customization, and usage of the service.\n* You are responsible for enabling your VMs or virtual applications (vApps) to participate in the provided backup service.\n* You are responsible for being ready to restore all instances of your VMs or vApps used in the service in the restored location or new location.\n\n\n\n\n\n High availability \n\nVMware Shared supports high availability of the VMware Cloud Director service itself. The service achieves high availability automatically and transparently by using the Multizone region (MZR) feature that is provided by IBM Cloud.\n\nHowever, you cannot configure workloads that are running VMs and vApps in a high availability manner across multiple IBM Cloud data center sites. VMware Shared currently allows workloads to operate in only one IBM Cloud data center site.\n\nUse VMware Shared with vCenter Server to achieve high availability. You can deploy vCenter Server in multiple IBM Cloud data center regions.\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery can become an issue if an IBM Cloud location experiences a significant failure that includes the potential loss of data. Because MZRs are not available across locations, you must wait for IBM to bring a location back online if it becomes unavailable. If underlying data services are compromised by the failure, you must also wait for IBM to restore those data services.\n\nIf a catastrophic failure occurs, IBM might not be able to recover data from database backups. In this case, you need to restore your data to return your service instance to its most recent state. You can restore the data to the same or to a different location, including a vCenter Server instance.\n\nYour disaster recovery plan includes knowing, preserving, and being prepared to restore all data that is maintained on IBM Cloud.\n\n\n\n\n\n\n\n Related links","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_data"},{"document_id":"ibmcld_08622-7-1971","score":19.9402446747,"text":"\nRestoring your data from another region \n\nIf a regional disaster that affects all available zones occurs, you're notified through the [IBM Cloud status](https:\/\/cloud.ibm.com\/status?selected=status) web page and an email. In this case, depending on your [pricing plan](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-provision), whether you enable failover crypto units, and your requirements for recovery time, you can restore your data with different options.\n\n\n\n Restoring your data by using failover crypto units \n\nIf you are using the standard plan, and create your instance in Dallas (us-south) or Washington DC (us-east) and you enable failover crypto units, your data is restored automatically to reduce the downtime and data loss. In this case, you switch to use the failover crypto units in another region to manage your keys and perform cryptographic operations. The failover crypto units contain a backup of all the encryption keys and other resources in the operational crypto units.\n\nAt the same time, IBM repairs your service instance in the original region. If new operational crypto units are required to complete the repair, you will be notified by IBM and you need to load the master key to the new operational crypto units by [using recovery crypto units or master key parts](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-initialize-instance-mode). After your original service instance is recovered, IBM automatically redirects traffic back to the original region.\n\nTo use failover crypto units to restore data in a regional disaster, make sure that you initialize and configure all the failover crypto units the same as the operational crypto units before the disaster happens. For more information about initialization approaches, see [Introducing service instance initialization approaches](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-initialize-instance-mode).\n\n\n\n\n\n Restoring your data by opening an IBM support ticket","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data"},{"document_id":"ibmcld_14738-7598-10031","score":19.5127563477,"text":"\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Encryption Provide secure SSL connections to administration portals and replication endpoints. Workload can be deployed by using AES 256-bit encrypted data stores with unique key per customer instance. Backups are encrypted uniquely per customer. Choose encrypted data stores when you are deploying workloads into the environment where appropriate. Use encrypted networking for workload to workload and workload to IBM Cloud Service connections. Use the IBM Cloud private network where appropriate. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Backup of management configuration data Conduct backups of the management component configurations. These backups include single-tenant vCenter Server, VMware NSX-T, VMware Cloud Director\u2122, and service configurations. Offsite immutable backup copies are enabled in an independent backup account and they run daily. \n Backup of workloads Enable backup services for customer workload. Choose and implement a backup provider for critical workloads. For more information, see [Understanding business continuity and disaster recovery](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-bc-dr). \n Recovery of configuration Conduct recovery in the original data center after the infrastructure is available. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, provide customer restore services after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vmaas-understand-responsib"},{"document_id":"ibmcld_09434-5744-7613","score":19.4384860992,"text":"\n[IBM Cloud\u00ae Object Storage provides several options to encrypt your data.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Meet security and compliance objectives Maintain controls that are commensurate to various industry compliance standards such as SOC2, PCI, HIPAA and Privacy Shield. Set up and maintain security and regulation compliance for your apps and data. This includes: <br>[Defining the account management strategy](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoptionadoption_account) <br>[Configuring the accounts settings for compliance](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoptionadoption_acc_settings) <br>Define IAM Strategy <br>[Define the notification strategy](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoptionadoption_alerts) \n\n\n\n\n\n\n\n Disaster recovery \n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM Responsibilities Your Responsibilities \n\n Restore the service[] Automatically recover and restart service components after any disaster event. N\/A \n Backup the IBM Log Analysis key resources that are provided by the service Daily backup of the IBM Log Analysis infrastructure and components. N\/A \n Backup logging agents N\/A Backup each logging agent YAML file that is deployed in your organization. \n Recovery of logging agents N\/A [Reinstall](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-logdna_agentlogdna_agent_configure) the logging agent in the event of any disaster event that impacts the agent runtime. \n Backup the metadata of a logging instance Backup metadata that is used by the service. [Backup the metadata such as views, dashboards, screens, parsing templates, and alerts for each logging instance.](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-reuse_resource_definitionsexport_config_res)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-shared-responsibilities"},{"document_id":"ibmcld_09515-7-2313","score":19.1915245056,"text":"\nBackups and Disaster Recovery \n\n\n\n Application Backups \n\nData used by applications within the Maximo Application Suite portfolio are backed up according to the following:\n\nAll backups are encrypted. Communication between applications, backup scripts the storage layer and DB services are perfromed via secure transport and accessed only via private endpoints that are offered by the service. Production backups are performed once a day. Backups are stored in a separate AWS data center location.\n\n\n\n\n\n System Configuration Backups \n\nMaximo Application Suite utilizes different components to deliver the applications to clients. Each of these services are backed up using the appropriate backup tool for that component. In general, all component backups:\n\n\n\n* are encrypted\n* are taken daily\n* are stored in a separate data center\n* are saved for 30 days\n\n\n\n\n\n\n\n Database Backup Retention \n\nDatabase backups will be retained for the standard duration of 14 days for Production environments and 7 days for Non-Production environments. In scenarios where the customer would like to retain a backup for longer than the standard duration outlined, the IBM SRE team will perform a database backup and save it to the COS bucket. It will then be the responsibility of the customer to download and maintain these backups. If a restore using one of these downloaded backups is required, the customer will need to upload the backup back to the COS bucket and open a case specifying which backup to use and for which environment they would like the restore.\n\n\n\n\n\n Restore \n\nRestore requests must be submitted via case (ticket) through the IBM Support Community Portal. The expected turn around time will depend on the severity and the size of the restore required. Generally expect 1 - 3 days for a restore to happen. Database restore can only be done to one of the previous daily backups (cannot restore to point in time).\n\n\n\n\n\n Disaster Recovery \n\nIn the event of a DR issue with the Maximo Application Suite SaaS offering for a specific customer, IBM's focus will be in the following order:\n\n\n\n1. Recover the existing infrastructure in place\n2. Recover within the same AWS data center to a new infrastructure\n3. Recover to a secondary AWS data center\n\n\n\nIn the event a disaster is declared, the base parameters are:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-backups-and-disaster-recovery"},{"document_id":"ibmcld_08511-7-2392","score":19.1563148499,"text":"\nHigh availability and disaster recovery \n\nIBM Cloud\u00ae Hyper Protect Crypto Services is a highly available, regional service with automatic features that help keep your applications secure and operational.\n\nLearn more about availability and disaster recovery strategies of Hyper Protect Crypto Services.\n\n\n\n Locations, tenancy, and availability \n\nYou can create Hyper Protect Crypto Services resources in one of the supported [IBM Cloud regions](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-regions), which represent the geographic area where your Hyper Protect Crypto Services requests are handled and processed. Each IBM Cloud region contains [multiple availability zones](https:\/\/www.ibm.com\/cloud\/data-centers\/) to meet local access, low latency, and security requirements for the region.\n\nAs you plan your encryption at rest strategy with IBM Cloud, keep in mind that provisioning Hyper Protect Crypto Services in a region that is nearest to you is more likely to result in faster, more reliable connections when you interact with the Hyper Protect Crypto Services APIs. Choose a specific region if the users, apps, or services that depend on a Hyper Protect Crypto Services resource are geographically concentrated. Users and services who are far away from the region might experience higher latency.\n\nYour encryption keys are confined to the region that you created them in. Hyper Protect Crypto Services does not copy or export encryption keys to other regions.\n\n\n\n\n\n In-region data redundancy and failover \n\nMultiple\n\ncrypto unitsin a service instance are automatically synchronized and load balanced across multiple availability zones. If one available zone that contains your provisioned service instance cannot be accessed, Hyper Protect Crypto Services has automatic in-region data failover in place. The service follows IBM Cloud requirements for planning and recovering from disaster events. For more information, see [Disaster recovery](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimedisaster-recovery).\n\n\n\n\n\n Cross-region disaster recovery \n\nIBM also performs cross-region backup for your key resources. Your data is automatically backed up in another supported region daily. Depending on where you create your instance and your requirements for recovery time, you can restore your data in case of a regional disaster with the following options:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-dr"},{"document_id":"ibmcld_09494-7-2307","score":19.0996589661,"text":"\nBackups and Disaster Recovery \n\n\n\n Application Backups \n\nData used by applications within the Maximo Application Suite portfolio are backed up according to the following:\n\nAll backups are encrypted. Communication between applications, backup scripts the storage layer and DB services are perfromed via secure transport and accessed only via private endpoints that are offered by the service. Production backups are performed once a day. Backups are stored in a separate IBM Cloud data center location.\n\n\n\n\n\n System Configuration Backups \n\nMaximo Application Suite utilizes different components to deliver the applications to clients. Each of these services are backed up using the appropriate backup tool for that component. In general, all component backups:\n\n\n\n* are encrypted\n* are taken daily\n* are stored in a separate data center\n* are saved for 30 days\n\n\n\n\n\n\n\n Database Backup Retention \n\nDatabase backups will be retained for the standard duration of 14 days for Production environments and 7 days for Non-Production environments. In scenarios where the customer would like to retain a backup for longer than the standard duration outlined, the IBM SRE team will perform a database backup and save it to the COS bucket. It will then be the responsibility of the customer to download and maintain these backups. If a restore using one of these downloaded backups is required, the customer will need to upload the backup back to the COS bucket and open a case specifying which backup to use and for which environment they would like the restore.\n\n\n\n\n\n Restore \n\nRestore requests must be submitted via case (ticket) through the IBM Support Community Portal. The expected turn around time will depend on the severity and the size of the restore required. Generally for non-production systems, expect 1 - 3 days for a restore to happen. Database restore can only be done to one of the previous daily backups (cannot restore to point in time).\n\n\n\n\n\n Disaster Recovery \n\nIn the event of a DR issue with the Maximo Application Suite Dedicated Service offering for a specific customer, IBM's focus will be in the following order:\n\n\n\n1. Recover the existing infrastructure in place\n2. Recover within the same IBM Cloud data center to a new infrastructure\n3. Recover to a secondary IBM Cloud data center","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-backups-and-disaster-recovery"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14905-7-2029","score":15.4103136063,"text":"\nAbout networking \n\nIBM Cloud\u00ae Virtual Private Cloud (VPC) is a virtual network that is linked to your customer account. It gives you cloud security, with the ability to scale dynamically, by providing fine-grained control over your virtual infrastructure and your network traffic segmentation.\n\n\n\n Overview \n\nEach VPC is deployed to a single region. Within that region, the VPC can span multiple zones.\n\nSubnets in your VPC can connect to the public internet through an optional public gateway. You can assign floating IP addresses to any virtual server instance to enable it to be reachable from the internet, independent of whether its subnet is attached to a public gateway.\n\nSubnets within the VPC offer private connectivity; they can talk to each other over a private link through the implicit router. Setting up routes is not necessary. Figure 1 shows how you can subdivide a virtual private cloud with subnets and each subnet can reach the public internet.\n\nZoom\n\n![Figure showing how a VPC can be subdivided with subnets](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/vpc\/images\/vpc-experience-simple.svg)\n\nFigure 1. IBM VPC connectivity and security\n\n\n\n\n\n Terminology \n\nTo work with your VPC, review the basic concepts of region and zone as they apply to your deployment.\n\n\n\n Regions \n\nA region is an abstraction that is related to the geographic area in which a VPC is deployed. Each region contains multiple zones, which represent independent fault domains. A VPC can span multiple zones within its assigned region.\n\n\n\n\n\n Zones \n\nA zone is an abstraction that refers to the physical data center that hosts the compute, network, and storage resources, plus the related cooling and power, which provides services and applications. Zones are isolated from each other to create no shared single point of failure, improved fault tolerance, and reduced latency. Each zone is assigned a default address prefix, which specifies the address range in which subnets can be created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-networking-for-vpc"},{"document_id":"ibmcld_16728-8917-10957","score":15.38859272,"text":"\nA VPC can be a building block that encapsulates a corporate division (marketing, development, accounting, ...) or a collection of microservices owned by a DevSecOps team. VPCs can be connected to an on-premises enterprise and each other. This may create the need to route traffic through centralized firewall-gateway appliances. This tutorial will walk through the implementation of a hub and spoke architecture depicted in this high-level view:\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Centralize communication through a VPC Transit Hub and Spoke architecture - Part two](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-transit2)Centralize communication through a VPC Transit Hub and Spoke architecture - Part two Solution tutorial\n\nA layered architecture will introduce resources and demonstrate connectivity. Each layer will add additional connectivity and resources. The layers are implemented in Terraform. It will be possible to change parameters, like number of zones, by changing a Terraform variable. A layered approach allows the tutorial to introduce small problems and demonstrate a solution in the context of a complete architecture.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Configure NAT for Internet access from a private network](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-nat-config-private)Configure NAT for Internet access from a private network Solution tutorial\n\nThis tutorial presents the setup of Network Address Translation (NAT) masquerade on a Virtual Router Appliance (VRA) to connect to a secured subnet on the IBM Cloud private network. It builds on the Isolating workloads with a secure private network tutorial, adding a Source NAT (SNAT) configuration, where the source address is obfuscated and firewall rules are used to secure out-bound traffic. More complex NAT configurations can be found in the supplemental VRA documentation.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"},{"document_id":"ibmcld_14916-7-2291","score":15.2164392471,"text":"\nOverview \n\nUse IBM Cloud\u00ae Virtual Private Cloud to create your own space in IBM Cloud\u00ae. A virtual private cloud (VPC) is a secure, isolated virtual network that combines the security of a private cloud with the availability and scalability of IBM's public cloud.\n\n\n\n Logical isolation \n\nVPC gives your applications logical isolation from other networks, while providing scalability and security. To make this logical isolation possible, the VPC is divided into subnets that use a range of private IP addresses. You can create subnets in suggested prefix ranges, or bring your own public IP address range (BYOIP) to your IBM Cloud account. By default, all resources within the same VPC can communicate with each other over the private network, regardless of their subnet.\n\n\n\n\n\n Quick instance provisioning with high network performance \n\nYou can quickly provision scalable compute resources in your VPC by creating virtual server instances with the core and RAM configuration that's best for your workload. You can select from the supported stock images or custom images that were imported from IBM Cloud Object Storage. All images are cloud-init enabled. You can connect to your instance without using a password by adding SSH keys.\n\nYou can create instances with up to 80 Gbps network bandwidth per instance. Each instance can be multi-homed, that is, you can create multiple network interfaces per instance.\n\n\n\n\n\n Multi-architecture images \n\nYou can choose to create virtual server instances with different operating systems on x86_64 or s390x processor architecture. For more information, see [Images](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-images).\n\n\n\n\n\n Storage capabilities \n\nWhen you create an instance, a 100 GB block storage volume is automatically attached as a primary boot volume. To add secondary data volumes to your instance, create block storage volumes.\n\n\n\n\n\n External connectivity \n\nSeveral options are available for enabling your instances to communicate with the public internet:\n\n\n\n* To enable all instances in a subnet to send outgoing traffic, attach a public gateway to the subnet.\n* To enable communication to and from a particular instance, independent of whether the subnet is attached to a public gateway, associate the instance with a floating IP.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc"},{"document_id":"ibmcld_16729-187656-189537","score":15.0762214661,"text":"\nA Virtual Private Cloud (VPC) provides network isolation and security in the IBM Cloud. A VPC can be a building block that encapsulates a corporate division (marketing, development, accounting, ...) or a collection of microservices owned by a DevSecOps team. VPCs can be connected to an on-premises enterprise and each other. This may create the need to route traffic through centralized firewall-gateway appliances. This tutorial will walk through the implementation of a hub and spoke architecture depicted in this high-level view:\n\nVirtual Private Cloud (VPC) Transit Gateway\n\n+1\n\nDirect Link on Classic\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Centralize communication through a VPC Transit Hub and Spoke architecture - Part two](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-transit2)Centralize communication through a VPC Transit Hub and Spoke architecture - Part two\n\nA layered architecture will introduce resources and demonstrate connectivity. Each layer will add additional connectivity and resources. The layers are implemented in Terraform. It will be possible to change parameters, like number of zones, by changing a Terraform variable. A layered approach allows the tutorial to introduce small problems and demonstrate a solution in the context of a complete architecture.\n\nVirtual Private Cloud (VPC) Transit Gateway\n\n+4\n\nDirect Link on Classic,DNS Services,IBM Cloud Databases,Databases For Redis\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Connecting Locations with IBM Cloud using Direct Link](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-direct-link-tutorial)Connecting Locations with IBM Cloud using Direct Link\n\nUse a secure IBM Cloud\u00ae Direct Link connection for Satellite Link communications between your services running in an IBM Cloud Satellite\u00ae Location and IBM Cloud\u00ae.\n\nSatellite Kubernetes service\n\n+1\n\nDirect Link\n\n\n\n* 2 hours\n* 2023-07-05","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_15130-4-2136","score":14.6350069046,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Protecting Virtual Private Cloud (VPC) Infrastructure Services with context-based restrictions \n\nContext-based restrictions give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud\u00ae resources based on the context of access requests. Access to VPC Infrastructure Services can be controlled with context-based restrictions and identity and access management (IAM) policies.\n\nThese restrictions work with traditional IAM policies, which are based on identity, to provide an extra layer of protection. Unlike IAM policies, context-based restrictions don't assign access. Context-based restrictions check that an access request comes from an allowed context that you configure. Since both IAM access and context-based restrictions enforce access, context-based restrictions offer protection even in the face of compromised or mismanaged credentials. For more information, see [What are context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis).\n\nA user must have the Administrator role on the VPC Infrastructure Services to create, update, or delete rules that target VPC Infrastructure Services. A user must have either the Editor or Administrator role on the context-based restrictions service to create, update, or delete network zones. A user with the Viewer role on the context-based restrictions service can add network zones to a rule only.\n\nThe context-based restriction service generates audit logs every time a context-based policy is enforced. For more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).\n\nTo get started protecting your VPC Infrastructure Services with context-based restrictions, see the tutorial for [Leveraging context-based restrictions to secure your resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-tutorial).\n\n\n\n How VPC Infrastructure Services integrates with context-based restrictions \n\nVPC Infrastructure Services is a composite service made up of a number of child services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr&interface=cli"},{"document_id":"ibmcld_15129-4-2136","score":14.6350069046,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Protecting Virtual Private Cloud (VPC) Infrastructure Services with context-based restrictions \n\nContext-based restrictions give account owners and administrators the ability to define and enforce access restrictions for IBM Cloud\u00ae resources based on the context of access requests. Access to VPC Infrastructure Services can be controlled with context-based restrictions and identity and access management (IAM) policies.\n\nThese restrictions work with traditional IAM policies, which are based on identity, to provide an extra layer of protection. Unlike IAM policies, context-based restrictions don't assign access. Context-based restrictions check that an access request comes from an allowed context that you configure. Since both IAM access and context-based restrictions enforce access, context-based restrictions offer protection even in the face of compromised or mismanaged credentials. For more information, see [What are context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis).\n\nA user must have the Administrator role on the VPC Infrastructure Services to create, update, or delete rules that target VPC Infrastructure Services. A user must have either the Editor or Administrator role on the context-based restrictions service to create, update, or delete network zones. A user with the Viewer role on the context-based restrictions service can add network zones to a rule only.\n\nThe context-based restriction service generates audit logs every time a context-based policy is enforced. For more information, see [Monitoring context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-cbr-monitor).\n\nTo get started protecting your VPC Infrastructure Services with context-based restrictions, see the tutorial for [Leveraging context-based restrictions to secure your resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-tutorial).\n\n\n\n How VPC Infrastructure Services integrates with context-based restrictions \n\nVPC Infrastructure Services is a composite service made up of a number of child services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-cbr"},{"document_id":"ibmcld_15957-3967-5967","score":14.1682929993,"text":"\n99.999999999% (11 nines) durability means that if you store 10 million files, then you expect to lose one file every 10000 years.\n\nWhen people hear the word durability, most of them think of hardware failures of storage, compute, and network components that might cause data loss. In VPC storage, your data is protected against drive failures and numerous type of disk errors that otherwise might negatively impact data durability and data integrity. The data is stored redundantly across multiple physical disks in an Availability Zone to prevent data loss due to failure of any single component.\n\nOther than physical failure, a common source of data loss is accidental deletion or modifications of files by users. Block Storage for VPC, Snapshots for VPC, and File Storage for VPC are only accessible to authorized hosts within your virtual private network. You control who can access it. For more information, see [Managing security and compliance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-security-compliance).\n\nAnother measure to protect against accidental deletion and modification of files is a snapshot. If a user accidentally modifies or deletes crucial data from a volume, the data can be easily and quickly restored from a snapshot or a backup. For more information about this feature, see [About Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n\nThe 11 nines durability target applies to a single Availability Zone. To protect against natural or man-made disasters that might destroy an entire Availability Zone, consider storing your most important data in multiple locations. For more information, see [Understanding high availability and disaster recovery](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-ha-dr-vpc).\n\n\n\n\n\n High Availability \n\nVPC storage is built upon best-in-class, proven, enterprise-grade hardware and software to ensure high availability and uptime. The data is stored redundantly across multiple physical disks on HA paired nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-storageavailability"},{"document_id":"ibmcld_11650-7-2200","score":14.1477403641,"text":"\nBackground for automating SAP HANA stand-alone virtual server instance on IBM Cloud\u00ae VPC \n\n\n\n IBM Cloud\u00ae Virtual Private Cloud (VPC) introduction \n\nIBM Cloud\u00ae VPC offers the possibility to quickly provision virtual server instances for VPC with high network performance. VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. A VPC is a public cloud offering that an enterprise uses to establish its own private cloud-like computing environment on shared [public cloud](https:\/\/www.ibm.com\/cloud\/public) infrastructure. A VPC gives an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud tenants, creating a private, secure place on the public cloud.\n\nImagine that a cloud provider\u2019s infrastructure is a residential apartment building with multiple families living inside. Being a public cloud tenant is akin to sharing an apartment with a few roommates. In contrast, having a VPC is like having your own private condominium. No one else has the key, and no one can enter the space without your permission.\n\nA VPC\u2019s logical isolation is implemented by using virtual network functions and security features that give an enterprise customer granular control over which IP addresses or applications can access particular resources. It is analogous to the \u201cfriends-only\u201d or \u201cpublic\/private\u201d controls on social media accounts used to restrict who can or can\u2019t see your otherwise public posts.\n\nWith IBM Cloud VPC, you can use the UI, CLI, and API to quickly provision virtual server instances for VPC with high network performance. VPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC overviews and VPC tutorials. [Getting started with Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started)\n\n\n\n\n\n SAP HANA in IBM Cloud \n\nThe IBM public cloud is an open, security-rich, and enterprise-ready public cloud for business.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-sap-hana-vpc-background"},{"document_id":"ibmcld_07986-7-1973","score":14.0134296417,"text":"\nVPC reference architecture for IBM Cloud for Financial Services \n\n[IBM Cloud\u00ae Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpcabout-vpc) is a public cloud offering that lets an enterprise establish its own private cloud-like computing environment on shared public cloud infrastructure. A VPC gives an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud tenants, creating a private, secure place on the public cloud. The VPC reference architecture for the IBM Cloud for Financial Services is designed to provide a framework for building a VPC-based offering according to the [best practices and requirements](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practices) of the IBM Cloud Framework for Financial Services. We detail this architecture and provide guidance for deploying, configuring, and managing it.\n\n\n\n Architecture diagram \n\nZoom\n\n![High-level VPC reference architecture for IBM Cloud for Financial Services](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9ac5c38b41e0aa1cb4ccc6cc7f547751ec805221\/framework-financial-services\/vpc\/images\/vpc-high-level\/vpc-high-level-v2.svg)\n\nFigure 1. High-level VPC reference architecture for IBM Cloud for Financial Services\n\nCentral to the architecture are two VPCs, which provide for separation of concerns between provider management functionality and consumer workloads.\n\nManagement VPC\n: Provides compute, storage, and network services to enable the application application provider's administrators to monitor, operate, and maintain the environment.\n\nWorkload VPC\n: Provides compute, storage, and network services to support hosted applications and operations that deliver services to the consumer.\n\nOther key features to note:\n\n\n\n* Supports a single tenant.\n* Resides in one or more [multizone regions](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locations).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-about"},{"document_id":"ibmcld_01790-5035-7392","score":13.8203439713,"text":"\nYou can also skip APIs to restrict all operations on the service that you select.\n\n\n\n\n\n\n\n Contexts \n\nContexts define where your resource can be accessed. A context is made up of the allowed endpoint types and network zones that you configure.\n\n\n\n* If a context includes network zones, then access is granted only when the request is created from within one of those zones.\n* If a context includes service endpoint types, then access is granted only when the request is received over a connection that matches one of those types.\n* If a context includes multiple restrictions, for example, both zones and endpoint types, then all restrictions must be satisfied for access to be granted.\n\n\n\n\n\n Network zone \n\nA network zone represents an allowlist of IP addresses where an access request is created. It defines a set of one or more network locations that are specified by the following attributes:\n\n\n\n* IP addresses, which include individual addresses, ranges, or subnets.\n* VPCs\n* Service references, which allow access from other IBM Cloud\u00ae services.\n\n\n\n\n\n IP addresses \n\nCustomers can specify the IP addresses they know that they want to be able to send traffic from. Anything outside of the specified IP addresses is denied.\n\n\n\n\n\n VPCs \n\nIf you have apps that are deployed in a VPC that need access to a context-based restricted resource, you can include the VPC IP addresses in your network zone. To do so, select the target VPC in your network zone and add that network zone to your rule. This way, you don\u2019t have to find the IP addresses that the VPC uses. Resources that are contacted see that the request is coming from a set of allowed IP addresses.\n\n\n\n\n\n Service references \n\nA service reference represents the network locations of a service or service instance. Including a service reference in a network zone adds the IP addresses associated with the service to your allowlist without requiring you to know the service's underlying IP addresses. Service references are helpful since the network locations of cloud services are unknown to the context-based restriction administrator and can change over time.\n\nThe following is a list of services that you can add to a network zone as a service reference:\n\n\n\nTable 1. Services that are compatible with service references.\n\n Service Service type \n\n All Account Management services Account Management","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatis"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.4367467095,"ndcg_cut_10":0.4367467095}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12834-6741-7997","score":18.7301807404,"text":"\n: The delivery of a computing platform, including applications, optimized middleware, development tools, and Java and Web 2.0 runtime environments, in a cloud-based environment.\n\nCategories of third-party services that fit within the service types include:\n\n\n\n* Container services that help build containerized applications\n* Storage services for persistent cloud storage and data encryption\n* AI and machine learning services (by integrating with IBM Watson)\n* Analytics services for analyzing data to deploy in cognitive applications\n* Blockchain services for data exchange\n* Database services for high availability, enhanced security, and scalable performance\n* Developer and migration tool services\n* Logging and monitoring services for detecting and troubleshooting issues\n* Integration services for faster integration\n* Internet of Things services for working with application data\n* Security services for enterprise-grade cloud security\n* Mobile services for building and starting mobile applications\n\n\n\nThe process includes registering your service with IBM Cloud, defining your product and its pricing plans, and linking a broker. For more information, see [Getting set up to sell services](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-started).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-selling-clouds"},{"document_id":"ibmcld_04734-4788-6538","score":18.4232616425,"text":"\n[External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/8aa0853d34cf2349f1d2db8e5c61e6422a580169\/icons\/launch-glyph.svg)](https:\/\/www.ibm.com\/blogs\/cloud-computing\/2016\/08\/10\/practical-guide-paas\/).\n\nWith the SaaS model, your provider maintains the systems through the actual application. The application is cloud-aware, and users can use different end points, depending on the software provider, to use the software. The cloud provider is responsible for all infrastructure and application management, which includes software updates, hardware repairs, and network settings. This model is often used in pay-as-you-go software licensing models. For more information, see [SaaS applications for business and IT](https:\/\/www.ibm.com\/cloud\/saas)![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/8aa0853d34cf2349f1d2db8e5c61e6422a580169\/icons\/launch-glyph.svg).\n\n\n\n\n\n Cloud types \n\nThere are three different types of clouds available: public, private, and hybrid. A public cloud includes a shared set of resources that are provisioned to allow access to a company's resources. It is hosted in a multi-tenant environment on a virtual server, and it can be accessed from anywhere.\n\nA private cloud includes resources that are provisioned to allow access to a company's resources. It is hosted on dedicated hardware, such as a bare metal server, and either onsite at the company's office (or across offices) or by a cloud provider. A private cloud can be accessed from anywhere.\n\nA hybrid cloud includes resources that combine the aspects of both public and private clouds. It is hosted both onsite at a company's office (or across offices) and by a cloud provider. A hybrid cloud can be accessed from anywhere.\n\n\n\n\n\n Next steps","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-getting-started-tutorial"},{"document_id":"ibmcld_11665-7-2043","score":16.3113975525,"text":"\nIBM Cloud\u00ae Virtual Private Cloud (VPC) Infrastructure environment introduction \n\nAn Infrastructure-as-a-Service (IaaS) environment consists of many components - primarily compute, storage, and network from a specified region (such as the US) and a designated site location (also referred to as a zone), which is a data center site.\n\n\n\n Deployment and management \n\nIBM Cloud VPC Infrastructure offerings, such as virtual or bare metal servers, are deployed through the [IBM Cloud VPC Infrastructure console](https:\/\/cloud.ibm.com\/vpc-ext\/overview).\n\nAlternatively, deployments can be made and managed by using:\n\n\n\n* IBM Cloud CLI\n* IBM Cloud VPC Infrastructure API calls that use an IBM Cloud API key\n* [Terraform Provider for IBM Cloud](https:\/\/cloud.ibm.com\/docs\/terraform?topic=terraform-getting-started) by using an IBM Cloud API key\n\n\n\nFor more information, see [Managing VPC Infrastructure (IAM)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-iam-getting-started).\n\n\n\n\n\n Locations - availability zones \n\nWith availability zones across North and South America, Europe, Asia, and Australia, you can provision cloud resources where (and when) you need them. Many regions are available globally, with multiple availability zones in each region. Each availability zone is connected to the IBM Cloud global private network, making data transfers faster and more efficient anywhere in the world.\n\nFor more information about IBM Cloud availability zones, data centers, and Points of Presence (PoPs), see the [global regions, availability zones, and data centers map](https:\/\/www.ibm.com\/cloud\/data-centers\/datacentermap).\n\n\n\n\n\n Compute Resources \n\nTwo types of compute resource can be deployed in IBM Cloud VPC Infrastructure environment:\n\n\n\n* Intel Virtual Server Instances (VSIs)\n* Intel Bare Metal Servers\n\n\n\nThese compute resources are offered in different profiles that define CPU and RAM combinations.\n\nFor more information, see [Infrastructure certified for SAP](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-iaas-offerings).\n\n\n\n\n\n Networking","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-vpc-env-introduction"},{"document_id":"ibmcld_11149-1736-3999","score":15.926618576,"text":"\nWith IBM Cloud Satellite, you can create a hybrid environment that brings the scalability and on-demand flexibility of public cloud services to the applications and data that runs in your secure private cloud.\n* Support for [multicloud](https:\/\/www.ibm.com\/cloud\/learn\/multicloud) and hybrid multicloud solutions is also available, which makes it easy for you to work with different vendors. [IBM Cloud Paks](https:\/\/www.ibm.com\/cloud\/paks) are software products for hybrid clouds that enable you to develop apps once and deploy them anywhere.\n* [Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started) is available as a public cloud service that lets you establish your own private cloud-like computing environment on shared public cloud infrastructure. With VPC, enterprises can define and control a virtual network that is logically isolated from all other public cloud tenants, creating a private, secure place on the public cloud.\n\n\n\nWith our open source technologies, such as Kubernetes, Red Hat OpenShift, and a full range of compute options, including virtual machines, containers, bare metal, and serverless, you have the control and flexibility that's required to support workloads in your hybrid environment. You can deploy cloud-native apps while also ensuring workload portability.\n\nWhether you need to migrate apps to the cloud, modernize your existing apps by using cloud services, ensure data resiliency against regional failure, or use new paradigms and deployment topologies to innovate and build your cloud-native apps, the platform's open architecture is built to accommodate your use case.\n\n\n\n What's built into the platform? \n\nAs the following diagram illustrates, the IBM Cloud platform is composed of multiple components that work together to provide a consistent and dependable cloud experience.\n\n\n\n* A robust console that serves as the front end for creating, viewing, managing your cloud resources\n* An identity and access management component that securely authenticates users for both platform services and controls access to resources consistently across IBM Cloud\n* A catalog that consists of hundreds of supported products\n* A search and tagging mechanism for filtering and identifying your resources","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatis-platform"},{"document_id":"ibmcld_04709-7-2265","score":15.6325826645,"text":"\nComparing IBM Cloud Classic and VPC infrastructure environments \n\nCompare the key differences between IBM Cloud\u00ae infrastructure environments to decide which one is best for your workloads and applications. Check out this [video](https:\/\/mediacenter.ibm.com\/media\/IBM%20Bare%20Metal%20Servers%20-%20Classic%20vs.%20VPC%20Infrastructure%20Explainer%20Video\/1_hn1d69nn) to learn more about the differences between the Classic and VPC infrastructures.\n\nIf you aren't familiar with the environment types, review the following descriptions.\n\n\n\n* Classic infrastructure is our existing IaaS platform. This environment is best for lift and shift workloads so you can move applications quickly and keep the same architecture.\n* VPC infrastructure is our new IaaS platform, based on software-defined networking and ideal for cloud-native applications.\n\n\n\nClassic infrastructure and VPC infrastructure are cost neutral, so you can focus on what environment best meets your needs.\n\n\n\n Compute differentiators \n\nSee the following table for the compute differences between classic and VPC.\n\n\n\nTable 1. Compute comparison\nThis table has row and column headers. The row headers identify possible features. The column headers identify the differentiators between classic infrastructure and VPC infrastructure. To understand the differences between environments, go to the row and find the details for the feature that you're interested in.\n\n Category Classic Infrastructure VPC Infrastructure \n\n Services Full catalog of services, such as Bare Metal Servers, Virtual Servers instances, VMware, SAP Virtual Servers and Bare Metal Servers \n Performance and availability Better availability achievable through zone architecture \n Pricing Hourly and monthly billing, plus suspend billing features Hourly, suspend billing, and sustained usage discount \n Virtual server families Public, dedicated, transient, reserved Public, dedicated \n Profiles All profiles, including the GPU profiles Balanced, compute, memory profiles with higher RAM and vCPU options \n Supported images Full set of pre-stock images, plus custom images Limited set of pre-stock images, plus the ability to import a custom image \n Platform integration IAM and resource group integration for a unified experience","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-compare-infrastructure"},{"document_id":"ibmcld_08295-115771-117604","score":15.4846076965,"text":"\nYou can define environment variables for IBM Cloud catalog offerings that are provisioned by using a bash script files. \n variable_name Optional Enter the name for the input variable that you declared in your Terraform configuration files. \n variable_type Optional Terraform v0.12 supports string, list, map, bool, number and complex data types such as list(type), map(type), object({attribute name=type,..}), set(type), tuple([type]). \n variable_value Optional Enter the value as a string for the primitive types such as bool, number, string, and HCL format for the complex variables, as you provide in a .tfvars file. You need to enter escaped string of HCL format for the value, as shown in the example. For more information about how to declare variables in a Terraform configuration file and provide value to schematics, see [Using input variables to customize resources](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-create-tf-configdeclare-variable). [For example](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-schematics-cli-referencesyntax_of_variablevalue) \n secure Optional Set the secure parameter to true. By default, this parameter is set to false. \n val1 Optional In the payload you can provide an environment variable that can execute in your workspace during plan, apply or destroy stage. Also values are encrypted and stored in COS. \n\n\n\nIBM Cloud Schematics supports setting up environment variable such as TF_PARALLELISM, TF_LOG. For more information about the list of environment variable and its usage, see [List of environment variables](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-set-parallelismlist-special-env-vars).\n\nExample\n\nibmcloud schematics workspace new --file example.json\n\n\n\n\n\n\n\n ibmcloud schematics refresh \n\nPerform an IBM Cloud refresh action against your workspace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-slurm?topic=hpc-slurm-schematics-cli-reference"},{"document_id":"ibmcld_10916-13226-15484","score":15.3343305588,"text":"\nSee also [host](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2002243).\n\n\n\n\n\n\n\n client secret \n\nA piece of information that is used with an application key to verify the identity of an application. An API can be configured to require that client applications supply their application secret with their application key. The application secret functions effectively as a password known only to the application. The application secret is passed by the client using an HTTP query parameter.\n\n\n\n\n\n cloud computing \n\nA computing platform where users can have access to applications or computing resources, as services, from anywhere through their connected devices. A simplified user interface or application programming interface (API), or both, makes the infrastructure supporting such services transparent to users.\n\n\n\n\n\n cloud portability \n\nThe ability to move applications and services across public or private cloud computing environments, or from different cloud providers.\n\n\n\n\n\n cloud provider \n\nAn organization that provides cloud computing resources.\n\n\n\n\n\n cloud resource name (CRN) \n\nA globally unique identifier for a specific cloud resource. The value is segmented hierarchically by version, instance, type, location, and scope, separated by colons.\n\n\n\n\n\n command-line interface (CLI) \n\nA computer interface in which the input and output are text based.\n\n\n\n\n\n community \n\nA collection of consumer organizations. It is used as a grouping construct when publishing APIs. Communities are used to restrict the visibility and accessibility of APIs.\n\n\n\n\n\n component \n\nIn source control management, a grouping of related artifacts in a stream or repository workspace. A component can contain any number of folders and files.\n\n\n\n\n\n compute \n\nInfrastructure or resources that serve as the basis for building apps in the cloud.\n\n\n\n\n\n config rule \n\nSee [configuration rule](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx3084914).\n\n\n\n\n\n configuration rule (config rule) \n\nA JSON document that defines the configuration of resources and validates the compliance based on security requirements when a resource is created or modified.\n\n\n\n\n\n confusion matrix \n\nA table that provides a detailed numeric breakdown of annotated document sets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossary"},{"document_id":"ibmcld_10916-21088-23054","score":15.2852973938,"text":"\nDC \n\nSee [data center](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2439906).\n\n\n\n\n\n dedicated cloud \n\nA private cloud computing environment that provides infrastructure with single-tenant hardware. See also [borderless](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx8439189).\n\n\n\n\n\n deployable architecture \n\nCloud automation for deploying a common architectural pattern that combines one or more cloud resources that is designed for easy deployment, scalability, and modularity. See also [module](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2030595).\n\n\n\n\n\n deployment \n\nA process that retrieves the output of a build, packages the output with configuration properties, and installs the package in a pre-defined location so that it can be tested or run. See also [stage](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2067189).\n\n\n\n\n\n DevOps \n\nA software methodology that integrates application development and IT operations so that teams can deliver code faster to production and iterate continuously based on market feedback.\n\n\n\n\n\n DevSecOps \n\nA methodology that integrates security practices with the software development and operations lifecycle. The goal of the merge is to prioritize the balance of development speed and security.\n\n\n\n\n\n dictionary \n\nA collection of words that can be used to pre-annotate documents. A new annotation is created for each word in the document text that matches a term in the dictionary. A machine learning model can be configured with one or more independent dictionaries, which are typically domain-specific, such a dictionary for pharmaceuticals and a dictionary for wealth management. See also [lemma](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx2763345), [surface form](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossaryx3271760).\n\n\n\n\n\n dictionary pre-annotator \n\nA component that identifies mentions in text that match a specific set of words.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-glossary"},{"document_id":"ibmcld_12834-4926-7276","score":15.2822809219,"text":"\n* Terraform templates for configuration\n* Helm charts for working with applications\n\n\n\nYour software can be deployed onto specified targets, including IBM Cloud\u00ae Kubernetes Service, Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, Power Systems Virtual Server, Schematics, Virtual Private Cloud and vCenter Server.\n\nThe process is as simple as selecting the Deployable software option, providing company information, creating a suitable test environment, setting up team access, and inviting team members to join. For more information, see [Getting set up to sell software](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-sw-getting-started) and [Onboarding your software](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-sw-validate).\n\n\n\n\n\n Services \n\nManaged services help run the infrastructure in your own account and to deploy instances by using the IBM Cloud. If you have a service that you want to provide, you can offer it as an integrated billing service. Offering it as an integrated billing service means that users can create an instance of your service automatically. You can onboard your service to IBM Cloud by defining your service, building pricing plans, and creating brokers.\n\nWhen you onboard your service, you must select the type of service that you are onboarding. Your service type is used for tax assessment purposes. IBM Cloud supports three types of services:\n\nSoftware as a service\n: A model of software deployment in which the software that includes business processes, enterprise applications, and collaboration tools, are provided as a service to customers through the cloud.\n\nInfrastructure as a service\n: The delivery of a compute infrastructure, including server functionality, networking functionality, data center functionality, and storage functionality as an outsourced service.\n\nPlatform as a service\n: The delivery of a computing platform, including applications, optimized middleware, development tools, and Java and Web 2.0 runtime environments, in a cloud-based environment.\n\nCategories of third-party services that fit within the service types include:\n\n\n\n* Container services that help build containerized applications\n* Storage services for persistent cloud storage and data encryption\n* AI and machine learning services (by integrating with IBM Watson)\n* Analytics services for analyzing data to deploy in cognitive applications","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-selling-clouds"},{"document_id":"ibmcld_04734-7-2373","score":15.1408758163,"text":"\nUnderstanding IaaS basics \n\nAs many organizations move to a cloud environment, either on-premises or hosted in data centers, the IT operations administrator's (IT ops admin) role is being redefined. The scope and complexity of this change increases significantly based on the type of environment that your organization wants to deploy.\n\nBefore you moved to the cloud, you worked with an inherently secure environment with systems that are connected to your private LAN or intranet. In a cloud environment, you're now expected to perform the following tasks:\n\n\n\n* Procure your system components from \"somewhere.\"\n* Understand network implications and security challenges.\n* Work with different technologies.\n* Integrate the new environment with tools that are not natively part of the cloud stack.\n* Continue to support your internal customers as if you still have an on-premises data center.\n\n\n\nIBM Cloud\u00ae is here to support you 100% on your journey. The resources available to you include comprehensive documentation, planning tools, qualified support specialists, and an active user community. Let's get you started on your journey.\n\n\n\n Video transcript \n\nWelcome to IBM Cloud! As an IT operations administrator, you had your choice of any number of cloud providers. You chose IBM Cloud because it's a leader in cloud as a service. We offer superior levels of security, functionality, integration, interoperability, and usability.\n\nUse the IBM Cloud console to get access to our catalog of over 190 unique services across several categories including Security, Compute, Network, Storage, Integration, and Data Management [Click Catalog menu item, then select from the categories listed in the transcript]. In addition to the catalog, there are a variety of tools to help you plan your hosting environment before you begin provisioning it. One tool is the [IBM Cloud Design Decision Tool](https:\/\/github.com\/ibm-cloud-architecture\/infrastructure-design-decision-tool), which helps you compare infrastructure designs so you can build the best IBM Cloud solution to suit your needs.\n\nAfter you've planned and designed your infrastructure, use the cost estimator [Click Cost estimator icon then click Review summary] to see how much your infrastructure will cost before placing your order. You can access it by clicking the Cost Estimator icon in the console menu bar.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-getting-started-tutorial"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05707-4888-6797","score":25.3502674103,"text":"\nIBM Cloud Kubernetes Service on IBM Cloud Public delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts For more information, see [IBM Cloud Kubernetes Service technology](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch).\n: You can also create your cluster in a Virtual Private Cloud (VPC), which gives you the security of a private cloud environment with isolated networking features along with the dynamic scalability of the public cloud. For more information, see [Overview of Classic and VPC infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers).\n\nIBM Cloud Private, on-premises\n: IBM Cloud Private is an application platform that can be installed locally on your own machines. You might choose to use Kubernetes in IBM Cloud Private when you need to develop and manage on-premises, containerized apps in your own controlled environment behind a firewall. For more information, see the [IBM Cloud Private product documentation](https:\/\/www.ibm.com\/docs\/en\/cloud-private\/3.2.x).\n\n\n\n\n\n Comparison of free and standard clusters \n\nReview the following table for a comparison of free and standard clusters.\n\nThe free cluster option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nFree clusters are automatically deleted after 30 days.\n\nIf you have a free cluster and want to upgrade to a standard cluster, you can [create a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusters).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov"},{"document_id":"ibmcld_04645-5074-6875","score":24.7812480927,"text":"\nFree level of service [Yes, free tier available, that re-sets every month](https:\/\/www.ibm.com\/cloud\/code-engine\/pricing) [Yes, free limited cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov) No \n Latest community Kubernetes distribution Yes. IBM Cloud Code Engine is built on IBM Cloud Kubernetes Service. Yes Partially. Support is as close as possible to the latest major version.For example, right now OpenShift 4.10 is on Kubernetes 1.23, but we offer OpenShift 4.9 right now, which is on Kubernetes 1.22. Support is typically offered on the Kubernetes N-1 version. \n Scope IBM Cloud IAM access policies to access groups for service access roles that sync to cluster RBAC Yes Yes No \n Classic infrastructure cluster on only the private network Not applicable, built on Gen2 infrastructure. Yes No \n GPU bare metal worker nodes No Yes (but only for Classic, not for VPC) Yes (but only for Classic, not for VPC) \n Integrated IBM Cloud Paks and middleware Not applicable Not applicable Yes \n Built-in containers, builds, and tooling Yes No Yes \n Integrated CI\/CD Yes (with IBM Cloud Toolchain) No Yes (with Jenkins) \n Stricter app security context set up by default Yes No Yes \n Simplified Kubernetes developer experience, with an app console that is suited for beginners Yes No Yes \n Supported operating system Worker node OS same as IKS Container level OS (if using Docker) is what is supplied in the dockerfile Container level OS (if using buildpack) supports all runtimes available on paketo.io Ubuntu 18.04 x86_64, 16.04 x86_64 (deprecated) Red Hat Enterprise Linux 7 (RHEL); however, as of 4.9, it will be CoreOS (RHCOS) \n Secured routes encrypted with Hyper Protect Crypto Services No No Yes \n Subscribe to event producers, such as Cloud Object Storage and Cron Yes Yes Yes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-deprecation_option_comparison"},{"document_id":"ibmcld_11143-7-2028","score":24.3107376099,"text":"\nNavigating the IBM Cloud console \n\nThe [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com) is the user interface that you use to manage all your IBM Cloud resources. You can create a free account, log in, access documentation, access the catalog, view pricing information, get support, or check the status of IBM Cloud components. After you log in, the menu bar contains a Navigation Menu icon ![Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/adcecdbe4e86955f88aac7f3c1e7ec3ff44992ef\/icons\/icon_hamburger.svg) and more links.\n\n\n\n Watch a tour \n\n\n\n* Video transcript\n\nWelcome to IBM Cloud, your open, secure, and enterprise-ready cloud platform with over 350 unique products for you to start building the solutions that you need today! Just log in, and you're ready to start building in the cloud.\n\nFrom the global navigation, you can explore how to get started with key technologies in IBM Cloud. Choose from technologies including serverless computing with Functions [Click Menu icon > Functions], container-based deployments on Kubernetes [Click Kubernetes to expand the options] or Red Hat OpenShift [Click OpenShift to expand the options], and VPC infrastructure [Click VPC Infrastructure to expand the options]. Developers can start with API management tools, app development starter kits, DevOps toolchains, and more to expedite and automate your app development.\n\nYou can get started creating resources through any of these guided journeys [Click Kubernetes > Clusters].\n\nOr, if you want to explore everything that IBM Cloud has to offer, go to the catalog to browse over 350 unique products [Click Catalog menu item]. Choose from our broad portfolio of managed services [Click Services], explore software products to take advantage of simplified installation [Click Software], or consult with IBM Cloud experts [Click Consulting]. If you're just here to try it out, filter the catalog by products that offer Lite plans, which are free to use [Click Services, and select the Lite pricing plan option].","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-ui"},{"document_id":"ibmcld_04031-1609-3779","score":24.1289424896,"text":"\nFor IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges. You will not be charged for the cluster that the Operational Tooling instance, also known as the console, is running on. See the [Architecture reference](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-architecture) topic for an illustration. More details on how to calculate charges are described below.\n\n\n\n Benefits of the new pricing model \n\n\n\n* No membership fees: Freedom from membership fees means that you can invest directly in your blockchain components.\n* Estimation clarity: A simple hourly pricing model makes cost estimation clear and easy by using the cost estimator tool that is available in the IBM Cloud dashboard.\n* No minimum fee required: Pay for only what you use, no minimum VPC hourly package is required, which makes it very inexpensive to get started.\n* Scalability of compute: You have the option to scale your compute up during peak usage periods or down to a minute fraction of capacity for when the compute is not needed to minimize expense.\n\n\n\nIn summary, these features remove the complexity of accounting for membership limitations or purchasing compute ahead of your needs.\n\n\n\n\n\n Find out how to preview the platform free for 30 days \n\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_14916-7-2291","score":23.9988937378,"text":"\nOverview \n\nUse IBM Cloud\u00ae Virtual Private Cloud to create your own space in IBM Cloud\u00ae. A virtual private cloud (VPC) is a secure, isolated virtual network that combines the security of a private cloud with the availability and scalability of IBM's public cloud.\n\n\n\n Logical isolation \n\nVPC gives your applications logical isolation from other networks, while providing scalability and security. To make this logical isolation possible, the VPC is divided into subnets that use a range of private IP addresses. You can create subnets in suggested prefix ranges, or bring your own public IP address range (BYOIP) to your IBM Cloud account. By default, all resources within the same VPC can communicate with each other over the private network, regardless of their subnet.\n\n\n\n\n\n Quick instance provisioning with high network performance \n\nYou can quickly provision scalable compute resources in your VPC by creating virtual server instances with the core and RAM configuration that's best for your workload. You can select from the supported stock images or custom images that were imported from IBM Cloud Object Storage. All images are cloud-init enabled. You can connect to your instance without using a password by adding SSH keys.\n\nYou can create instances with up to 80 Gbps network bandwidth per instance. Each instance can be multi-homed, that is, you can create multiple network interfaces per instance.\n\n\n\n\n\n Multi-architecture images \n\nYou can choose to create virtual server instances with different operating systems on x86_64 or s390x processor architecture. For more information, see [Images](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-images).\n\n\n\n\n\n Storage capabilities \n\nWhen you create an instance, a 100 GB block storage volume is automatically attached as a primary boot volume. To add secondary data volumes to your instance, create block storage volumes.\n\n\n\n\n\n External connectivity \n\nSeveral options are available for enabling your instances to communicate with the public internet:\n\n\n\n* To enable all instances in a subnet to send outgoing traffic, attach a public gateway to the subnet.\n* To enable communication to and from a particular instance, independent of whether the subnet is attached to a public gateway, associate the instance with a floating IP.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc"},{"document_id":"ibmcld_13067-1715-3771","score":23.7372341156,"text":"\nIBM Cloud\u00ae services are connected to a three-tiered network, segmenting public, private, and management traffic.\n\n\n\n* Private endpoints are available for most requests originating from within IBM Cloud. Private endpoints provide better performance and do not incur charges for any outgoing or incoming bandwidth even if the traffic is cross regions or across data centers. Whenever possible, it is best to use a private endpoint.\n* Public endpoints can accept requests from anywhere and charges are assessed on outgoing bandwidth. Incoming bandwidth is free. Public endpoints should be used for access not originating from an IBM Cloud cloud computing resource.\n* Direct endpoints are used in Bring-Your-Own-IP scenarios, generally for requests originating from [resources within VPCs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc). Like Private endpoints, Direct endpoints provide better performance over Public endpoints and do not incur charges for any outgoing or incoming bandwidth even if the traffic is cross regions or across data centers. Directions for connecting to IBM Cloud Object Storage from VPC are available [here](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-connecting-vpc-cos).\n\n\n\nRequests must be sent to the endpoint associated with a given bucket's location. If you aren't sure where a bucket is located, there is an [extension to the bucket listing API](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/api-reference?topic=cloud-object-storage-compatibility-api-bucket-operationscompatibility-api-list-buckets-extended) that returns the location and storage class information for all buckets in a service instance.\n\nWhen using Virtual Private Endpoints in an application that makes requests to IBM COS, it may be necessary to add some additional configuration for authentication. The IBM COS SDKs will automatically attempt to fetch an IAM token from https:\/\/iam.cloud.ibm.com\/identity\/token. If you are using a virtualized endpoint for token acquisition you will need alter the IAM endpoint appropriately.\n\n\n\n\n\n Regional Endpoints","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage?topic=cloud-object-storage-endpoints"},{"document_id":"ibmcld_14905-7-2029","score":23.5071964264,"text":"\nAbout networking \n\nIBM Cloud\u00ae Virtual Private Cloud (VPC) is a virtual network that is linked to your customer account. It gives you cloud security, with the ability to scale dynamically, by providing fine-grained control over your virtual infrastructure and your network traffic segmentation.\n\n\n\n Overview \n\nEach VPC is deployed to a single region. Within that region, the VPC can span multiple zones.\n\nSubnets in your VPC can connect to the public internet through an optional public gateway. You can assign floating IP addresses to any virtual server instance to enable it to be reachable from the internet, independent of whether its subnet is attached to a public gateway.\n\nSubnets within the VPC offer private connectivity; they can talk to each other over a private link through the implicit router. Setting up routes is not necessary. Figure 1 shows how you can subdivide a virtual private cloud with subnets and each subnet can reach the public internet.\n\nZoom\n\n![Figure showing how a VPC can be subdivided with subnets](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/vpc\/images\/vpc-experience-simple.svg)\n\nFigure 1. IBM VPC connectivity and security\n\n\n\n\n\n Terminology \n\nTo work with your VPC, review the basic concepts of region and zone as they apply to your deployment.\n\n\n\n Regions \n\nA region is an abstraction that is related to the geographic area in which a VPC is deployed. Each region contains multiple zones, which represent independent fault domains. A VPC can span multiple zones within its assigned region.\n\n\n\n\n\n Zones \n\nA zone is an abstraction that refers to the physical data center that hosts the compute, network, and storage resources, plus the related cooling and power, which provides services and applications. Zones are isolated from each other to create no shared single point of failure, improved fault tolerance, and reduced latency. Each zone is assigned a default address prefix, which specifies the address range in which subnets can be created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-networking-for-vpc"},{"document_id":"ibmcld_14870-7-1912","score":23.4268684387,"text":"\nDeployment Journey Overview \n\nIBM Cloud\u00ae Virtual Private Cloud(VPC) allows you to establish your own virtual private cloud by defining a virtual network that is logically isolated from all other public cloud tenants. The underlying software defined networking (SDN) and virtual network functions allows you to quickly establish the network constructs and on-prem connectivity needed to run your workload. The information contained within this document is meant to serve as a technical guide for beginning with a new IBM Cloud Account and leading towards a fully configured VPC network environment.\n\nWelcome to the Deployment Journey for VPC on IBM Cloud! Use the sidebar on the left to navigate between the journey points.\n\n\n\n Journey Map \n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d50364af907081c3c38f99c11f35dd9cab4b2510\/vpc-journey\/images\/overview\/journey-map.png)\n\n\n\n\n\n Assumptions \n\nThis deployment guide will be assuming the following points. Please note that while your circumstance may not be exactly identical, you will still benefit from the overall journey steps and concepts covered in this guide.\n\n\n\n* You are already familar with the concepts introduced in the \"Tour IBM Cloud\" videos available on the [Getting Started with IBM Cloud](https:\/\/cloud.ibm.com\/cloud\/get-started) page.\n* Access groups will need to be defined so only certain users have the ability to create and manage the VPC network settings (i.e. CIDR ranges, Subnet ACL rules, etc.,).\n* You have a networking background and familar with concepts such as IP Addressing, subnets, routing, etc.,\n* Focus will be on establishing the underlying network connectivity to support VPC based workloads.\n\n\n\n* Note: A separate deployment guide will cover the compute resources which runs within the VPC like IBM Kubernetes Services (IKS), Red Hat OpenShift, IBM Code Engine, and VPC Virtual Server Instances (VSIs).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc-journey?topic=vpc-journey-vpc-overview"},{"document_id":"ibmcld_14868-3827-5504","score":23.2955474854,"text":"\nInbound data transfer to IBM Cloud is free. Data transfer for [egress](https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-pricing-for-ibm-cloud-dlmetered-data-transfer-charge) varies based on region. Global routing (access to all IBM Cloud data centers globally) is free. \n\n\n\n\n\n\n\n Connection Patterns \n\nThe following pattern depicts how individual infrastructure (VPC and Classic) can be added as connections ![dl-directconnections](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d50364af907081c3c38f99c11f35dd9cab4b2510\/vpc-journey\/images\/directlink\/DL_Pattern_VPC_DirectConnections.png) In above pattern, each connections has its own VRF and connection#1 prefixes cannot communicate with connection#2 prefixes by default.\n\nThe following pattern depicts how Transit Gateway (VPC and Classic) can be added as connection and advertise all the learnt routes from VPC and Classic infrastructure across accounts ![dl-directconnections](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d50364af907081c3c38f99c11f35dd9cab4b2510\/vpc-journey\/images\/directlink\/DL_Pattern_VPC_TransitGW.png) In above pattern, transit GW will provide connections across infrastructures within IBMCloud and as well advertise all its prefixes to Directlink GW\n\n\n\n\n\n Ordering Direct Link \n\n\n\n* Detailed steps (including screenshots) to order Direct Link Dedicated are available in the [documentation](https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-how-to-order-ibm-cloud-dl-dedicated).\n* Detailed steps (including screenshots) to order Direct Link Connect are available in the [documentation](https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-how-to-order-ibm-cloud-dl-connect)\n\n\n\n\n\n\n\n Next Steps \n\nThe next step on the deployment journey is:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc-journey?topic=vpc-journey-vpc-directlink"},{"document_id":"ibmcld_14762-7-2008","score":23.2817878723,"text":"\nVirtual Private Cloud overview \n\nThe IBM Cloud\u00ae Virtual Private Cloud is a virtual network that is linked to your customer account. It gives you cloud security, with the ability to scale dynamically, by providing fine-grained control over your virtual infrastructure and your network traffic segmentation.\n\nEach VPC is deployed to a single region. Within that region, the VPC can span multiple zones.\n\nIBM Cloud virtual or IBM Cloud bare metal server presented in your VPC is attached to subnets. Subnets within the VPC offer private connectivity, thus your servers can communicate within and between the subnets by using an implicit router. Subnets in your VPC can connect to the public internet through an optional public gateway, or you can assign floating IP addresses to any network interface of the servers.\n\nThe following diagram shows an overview of IBM Cloud VPC.\n\nZoom\n\n![IBM VPC connectivity and security](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/vpc-ryo-diagrams-overview-virtual.svg)\n\nFigure 1. IBM Cloud VPC connectivity and security\n\nReview the following concepts to understand how IBM Cloud VPC is constructed. The terminology is used throughout this architecture solution.\n\nA region is an abstraction that is related to the geographic area in which a VPC is deployed. Each region contains multiple zones, which represent independent fault domains. A VPC can span multiple zones within its assigned region. A region is also often referred to a multizone region or MZR.\n\nA zone is an abstraction that refers to the physical data center, which hosts the compute, network, storage resources, and the related cooling and power, which provides services and applications. Zones are isolated from each other, so to create no shared single point of failure, improved fault tolerance, and reduced latency. Each zone is assigned a default address prefix, which specifies the range of addresses in which subnets can be created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vpc-ryo-vpc"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11163-7641-9659","score":9.372379303,"text":"\nTo see a full list of services that can use context-based restrictions to define and enforce access restrictions on their resources, see [Services integrated with context-based restrictions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-context-restrictions-whatiscbr-adopters).\n\n\n\n\n\n 25 January 2023 \n\nTime-based conditions in IAM access policies\n: IBM Cloud IAM is excited to give customers the ability to set access controls based on a specified time and date. You can now create policies that grant employees access to a resource during only their working hours, or grant automated processes temporary access for a specified duration. Implementing such limitations helps you to apply the principle of least privilege for assigning access and reduces the opportunity for attack in the event of a security breach. For more information, see [Limiting access with time-based conditions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-time-based&interface=ui).\n\nIAM Policy Management API V2 release\n: A new version (v2) of the IAM Policy Management API is now available. This version adds a new JSON schema to support a conditional policy construct and several time-based comparison operators. These operators provide the capability to restrict access based on time and date. With time-based access control, customers can establish granular policy enforcement based on a specified time period. For more information, see the [IAM Policy Management API change log](https:\/\/cloud.ibm.com\/docs\/account?topic=account-api-change-log&interface=ui)\n\n\n\n\n\n 09 January 2023 \n\nSave and share multiple estimates by using the IBM Cloud Cost Estimator\n: The IBM Cloud Cost Estimator now allows a customer to save multiple estimates to their account and share those estimates with users that belong to the same account. For more information, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\n\n\n\n\n\n\n December 2022 \n\n\n\n 15 December 2022 \n\nChecklist for getting started on IBM Cloud","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatsnew"},{"document_id":"ibmcld_03421-6867-8448","score":8.9168748856,"text":"\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE_ID\",\n\nonLoad: function(instance) {\n\/\/ Subscribe to the \"pre:send\" event.\ninstance.on({ type: \"pre:send\", handler: preSendhandler });\ninstance.render();\n}\n};\n\nsetTimeout(function(){\nconst t=document.createElement('script');\nt.src='https:\/\/web-chat.global.assistant.dev.watson.appdomain.cloud\/versions\/' +\n(window.watsonAssistantChatOptions.clientVersion || 'latest') +\n'\/WatsonAssistantChatEntry.js';\ndocument.head.appendChild(t);});\n\n<\/script>\nShow more\n\nYou can reference the $ismember context variable from your dialog. For example, the following screen capture shows a dialog node that conditions on #General_Greetings. It has multiple conditioned responses.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03313-1523-3328","score":8.5710124969,"text":"\nContext variable A variable that you can use to collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-variables). \n Dialog The component where you build the conversation that your assistant has with your customers. For each defined intent, you can author the response your assistant should return. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview). \n Digression A feature that gives the user the power to direct the conversation. It prevents customers from getting stuck in a dialog thread; they can switch topics whenever they choose. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-digressions). \n Disambiguation A feature that enables the assistant to ask customers to clarify their meaning when the assistant isn't sure what a user wants to do next. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation). \n Entity Information in the user input that is related to the user's purpose. An intent represents the action a user wants to do. An entity represents the object of that action. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities). \n Integrations Ways you can deploy your assistant to existing platforms or social media channels. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add). \n Intent The goal that is expressed in the user input, such as answering a question or processing a bill payment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"},{"document_id":"ibmcld_02882-11209-13367","score":8.4300699234,"text":"\nA node with the conversation_start condition can be used to initialize context variables or perform other tasks at the beginning of the dialog. \n false This condition is always evaluated to false. You might use this at the start of a branch that is under development, to prevent it from being used, or as the condition for a node that provides a common function and is used only as the target of a Jump to action. \n irrelevant This condition will evaluate to true if the user\u2019s input is determined to be irrelevant by the Watson Assistant service. \n true This condition is always evaluated to true. You can use it at the end of a list of nodes or responses to catch any responses that did not match any of the previous conditions. \n welcome This condition is evaluated as true during the first dialog turn (when the conversation starts), only if the initial request from the application does not contain any user input. It is evaluated as false in all subsequent dialog turns. The Welcome node is triggered by this condition. Typically, a node with this condition is used to greet the user, for example, to display a message such as Welcome to our Pizza ordering app. \n\n\n\n\n\n\n\n Condition syntax details \n\nUse one of these syntax options to create valid expressions in conditions:\n\n\n\n* Shorthand notations to refer to intents, entities, and context variables. See [Accessing and evaluating objects](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-expression-language).\n* Spring Expression (SpEL) language, which is an expression language that supports querying and manipulating an object graph at run time. See [Spring Expression Language (SpEL) language](http:\/\/docs.spring.io\/spring\/docs\/current\/spring-framework-reference\/html\/expressions.html) for more information.\n\n\n\nYou can use regular expressions to check for values to condition against. To find a matching string, for example, you can use the String.find method. See [Methods](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-methods) for more details.\n\n\n\n\n\n\n\n Responses \n\nThe dialog response defines how to reply to the user.\n\nYou can reply in the following ways:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_02934-14695-16614","score":8.3518323898,"text":"\nAs you collect answers from the user per slot, they are saved in context variables. You can use the context variables to pass the information to another node or to an application or external service for use. However, after passing the information, you must set the context variables to null to reset the node so it can start collecting information again. You cannot null the context variables within the current node because your assistant will not exit the node until the required slots are filled. Instead, consider using one of the following methods:\n\n\n\n* Add processing to the external application that nulls the variables.\n* Add a child node that nulls the variables.\n* Insert a parent node that nulls the variables, and then jumps to the node with slots.\n\n\n\n\n\nGive it a try! Follow the step-by-step [tutorial](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots).\n\n\n\n\n\n Slots usage tips \n\nThe following slot properties can help you check and set values in slot context variables.\n\n\n\nSlot properties\n\n Property name Description \n\n all_slots_filled Evaluates to true only if all of the context variables for all of the slots in the node have been set. See [Preventing a Found response from displaying when it is not needed](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slotsdialog-slots-stifle-found-responses) for a usage example. \n event.current_value Current value of the context variable for this slot. See [Replacing a slot context variable value](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slotsdialog-slots-found-handler-event-properties) for a usage example for this property and the event.previous_value property. \n event.previous_value Previous value of the context variable for this slot. \n has_skipped_slots True if any of the slots or slot handlers that are configured with a next step option that skips slots was processed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots"},{"document_id":"ibmcld_03112-1679-3500","score":8.1452150345,"text":"\nWith the stateless message API, the context is always included with each message response. For more information, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2messagestateless).\n\n\n\nImportant: One use of the context is to specify a unique user ID for each end user who interacts with the assistant. For user-based plans, this ID is used for billing purposes. (For more information, see [User-based plans](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).)\n\nThere are two types of context:\n\n\n\n* Global context: context variables that are shared by all skills used by an assistant, including internal system variables used to manage conversation flow. The global context includes the user ID, as well as other global values such as the time zone and language of the assistant.\n* Skill-specific context: context variables specific to a particular skill, including any user-defined variables needed by your application. Currently, only one skill (named main skill) is supported.\n\n\n\nUser-defined context variables that you specify in a dialog node are part of the user_defined object within the skill context when accessed using the API. Note that this structure differs from the context structure that appears in the JSON editor in the Watson Assistant user interface. For example, you might specify the following in the JSON editor:\n\n\"context\": {\n\"my_context_var\": \"this is the value\"\n}\n\nIn the v2 API, you would access this user-defined variable as follows:\n\n\"context\": {\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"my_context_var\": \"this is the value\"\n}\n}\n}\n}\n\nFor detailed information about how to access context variables using the API, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\n\n\n Example","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-client-get-context"},{"document_id":"ibmcld_01148-1369-3105","score":8.0013332367,"text":"\n: You can enforce production and consumption rate limits by settings quotas through [Administrative REST API](https:\/\/cloud.ibm.com\/apidocs\/event-streams\/adminrestlist-quotas) to prevent network saturation or monopolizing broker resources.\n\n\n\n\n\n October 2022 \n\nContext-based restrictions\n: You can use network type or context-based restrictions to restrict the network connectivity on the Enterprise plan. For more information, see [Restricting Network Access](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-restrict_access).\n\nApache Kafka upgrade\n: Upgrade to Apache Kafka version 3.1.\n\n\n\n\n\n July 2022 \n\nEnhanced support for matching schemas\n: Enhanced support for matching schemas when you use Confluent SerDes with the schema registry.\n\n\n\n\n\n May 2022 \n\nSchema registry support on the Satellite plan\n: The new [Satellite plan](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-satellite_about) now supports the [Schema registry API](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-satellite-provisioningsatellite-enable-schema-registry).\n\n\n\n\n\n April 2022 \n\nSatellite plan\n: With the new [Satellite plan](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-satellite_about), you can create a hybrid environment that brings the scalability and on-demand flexibility of public cloud services to the applications and data that run in your secure private cloud.\n\nMore topic and consumer group metrics\n: More topic and consumer group metrics are available, see [Monitoring Event Streams metrics by using IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-metrics).\n\n\n\n\n\n December 2021 \n\nApache Kafka upgrade\n: Upgrade to Apache Kafka version 2.8.\n\n\n\n\n\n October 2021 \n\nIAM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-event-streams-relnotes"},{"document_id":"ibmcld_07578-1250-3085","score":7.8837890625,"text":"\nOr you can edit them to complement other intents that you create. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog). \n Context variable A variable that you can use to collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-variables). \n Dialog The component where you build the conversation that your assistant has with your customers. For each defined intent, you can author the response your assistant should return. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview). \n Digression A feature that gives the user the power to direct the conversation. It prevents customers from getting stuck in a dialog thread; they can switch topics whenever they choose. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-digressions). \n Disambiguation A feature that enables the assistant to ask customers to clarify their meaning when the assistant isn't sure what a user wants to do next. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation). \n Entity Information in the user input that is related to the user's purpose. An intent represents the action a user wants to do. An entity represents the object of that action. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities). \n Integrations Ways you can deploy your assistant to existing platforms or social media channels. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1250-3085","score":7.8837890625,"text":"\nOr you can edit them to complement other intents that you create. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog). \n Context variable A variable that you can use to collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-variables). \n Dialog The component where you build the conversation that your assistant has with your customers. For each defined intent, you can author the response your assistant should return. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview). \n Digression A feature that gives the user the power to direct the conversation. It prevents customers from getting stuck in a dialog thread; they can switch topics whenever they choose. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-digressions). \n Disambiguation A feature that enables the assistant to ask customers to clarify their meaning when the assistant isn't sure what a user wants to do next. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation). \n Entity Information in the user input that is related to the user's purpose. An intent represents the action a user wants to do. An entity represents the object of that action. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities). \n Integrations Ways you can deploy your assistant to existing platforms or social media channels. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11726-7-2061","score":7.8523316383,"text":"\nDisconnected use for Satellite components \n\nCertain features of IBM Cloud Satellite\u00ae can be used while disconnected temporarily. See the following table to understand the disconnected use for these components.\n\n\n\n Understanding disconnected usage \n\nWhat does disconnected usage mean?\n: When Satellite Locations and Red Hat OpenShift on IBM Cloud are disconnected from the parent managed-from region in IBM Cloud, they can still run with some limitations for a certain amount of time. The limitations of disconnected usage include no security fixes and no alerts. For more information, see [Disconnected usage by component](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-disconnected-usedisconnect-usage-component).\n\nAre there additional requirements for disconnected usage?\n: Your location should still maintain network connection.\n\nHow do I set how long my access token is valid for?\n: Edit the value of the accessTokenMaxAgeSeconds parameter to set the token validity in seconds. For more information, see [Setting the disconnected usage time](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-disconnected-usedisconnect-time).\n\nWhat happens when my token expires?\n: After your token expires, you will lose the ability to work with the Location. When you run a command, you will get error messages such as error: You must be logged in to the server (Unauthorized). To recover, you must reconnect the Location and log in again to retrieve a new token. Do not reload nodes before the Location is reconnected. Reloading nodes while the Location is disconnected prevents the Location from recovering.\n\nDo I need to re-create the Location?\n: No, you don't need to re-create the Location. You can reconnect the existing Location and reauthenticate to continue working with your Location.\n\nHow do I reauthenticate?\n: Reconnect your Location first and then log in again with your credentials.\n\nDo I have to recover etcd backup?\n: No, you don't need to recover etcd backup. The Location recovers automatically after you reconnect it and reauthenticate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-disconnected-use"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14916-7-2291","score":19.5263595581,"text":"\nOverview \n\nUse IBM Cloud\u00ae Virtual Private Cloud to create your own space in IBM Cloud\u00ae. A virtual private cloud (VPC) is a secure, isolated virtual network that combines the security of a private cloud with the availability and scalability of IBM's public cloud.\n\n\n\n Logical isolation \n\nVPC gives your applications logical isolation from other networks, while providing scalability and security. To make this logical isolation possible, the VPC is divided into subnets that use a range of private IP addresses. You can create subnets in suggested prefix ranges, or bring your own public IP address range (BYOIP) to your IBM Cloud account. By default, all resources within the same VPC can communicate with each other over the private network, regardless of their subnet.\n\n\n\n\n\n Quick instance provisioning with high network performance \n\nYou can quickly provision scalable compute resources in your VPC by creating virtual server instances with the core and RAM configuration that's best for your workload. You can select from the supported stock images or custom images that were imported from IBM Cloud Object Storage. All images are cloud-init enabled. You can connect to your instance without using a password by adding SSH keys.\n\nYou can create instances with up to 80 Gbps network bandwidth per instance. Each instance can be multi-homed, that is, you can create multiple network interfaces per instance.\n\n\n\n\n\n Multi-architecture images \n\nYou can choose to create virtual server instances with different operating systems on x86_64 or s390x processor architecture. For more information, see [Images](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-images).\n\n\n\n\n\n Storage capabilities \n\nWhen you create an instance, a 100 GB block storage volume is automatically attached as a primary boot volume. To add secondary data volumes to your instance, create block storage volumes.\n\n\n\n\n\n External connectivity \n\nSeveral options are available for enabling your instances to communicate with the public internet:\n\n\n\n* To enable all instances in a subnet to send outgoing traffic, attach a public gateway to the subnet.\n* To enable communication to and from a particular instance, independent of whether the subnet is attached to a public gateway, associate the instance with a floating IP.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc"},{"document_id":"ibmcld_16729-187656-189537","score":19.3405532837,"text":"\nA Virtual Private Cloud (VPC) provides network isolation and security in the IBM Cloud. A VPC can be a building block that encapsulates a corporate division (marketing, development, accounting, ...) or a collection of microservices owned by a DevSecOps team. VPCs can be connected to an on-premises enterprise and each other. This may create the need to route traffic through centralized firewall-gateway appliances. This tutorial will walk through the implementation of a hub and spoke architecture depicted in this high-level view:\n\nVirtual Private Cloud (VPC) Transit Gateway\n\n+1\n\nDirect Link on Classic\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Centralize communication through a VPC Transit Hub and Spoke architecture - Part two](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-transit2)Centralize communication through a VPC Transit Hub and Spoke architecture - Part two\n\nA layered architecture will introduce resources and demonstrate connectivity. Each layer will add additional connectivity and resources. The layers are implemented in Terraform. It will be possible to change parameters, like number of zones, by changing a Terraform variable. A layered approach allows the tutorial to introduce small problems and demonstrate a solution in the context of a complete architecture.\n\nVirtual Private Cloud (VPC) Transit Gateway\n\n+4\n\nDirect Link on Classic,DNS Services,IBM Cloud Databases,Databases For Redis\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Connecting Locations with IBM Cloud using Direct Link](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-direct-link-tutorial)Connecting Locations with IBM Cloud using Direct Link\n\nUse a secure IBM Cloud\u00ae Direct Link connection for Satellite Link communications between your services running in an IBM Cloud Satellite\u00ae Location and IBM Cloud\u00ae.\n\nSatellite Kubernetes service\n\n+1\n\nDirect Link\n\n\n\n* 2 hours\n* 2023-07-05","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_14884-7-2123","score":19.09400177,"text":"\nAbout virtual server instances for VPC \n\nIBM Cloud\u00ae Virtual Servers for Virtual Private Cloud is an Infrastructure-as-a-Service (IaaS) offering that gives you access to all of the benefits of IBM Cloud VPC, including network isolation, security, and flexibility.\n\nWith virtual server instances for VPC, you can quickly provision instances with high network performance. When you provision an instance, you select a profile that matches the amount of memory and compute power that you need for the application that you plan to run on the instance. Instances are available on the x86 architecture. After you provision an instance, you control and manage those infrastructure resources.\n\n\n\n How are virtual server instances for VPC different from other IBM virtual server offerings? \n\nIn the IBM Cloud Virtual Servers for Classic infrastructure offering, instances use native subnet and VLAN networking to communicate to each other within a data center (and single pod). Using subnet and VLAN networking in one pod works well until you must scale up or have large virtual resource demands that require resources to be created between pods. (Adding appliances for VLAN spanning can get expensive and complicated!)\n\nIBM Cloud VPC adds a network orchestration layer that eliminates the pod boundary, creating increased capacity for scaling instances. The network orchestration layer handles all of the networking for all virtual server instances that are within a VPC across regions and zones. With the software-defined networking capabilities that VPC provides, you have more options for multi-vNIC instances and larger subnet sizes.\n\nTo review and start deploying compute resources, see the following topics:\n\n\n\nTable 1. Deployment options\n\n Deployment options Description \n\n [Virtual Servers for VPC profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profilesprofiles) IBM Cloud Virtual Servers for VPC provide the advanced security of a private cloud with the agility and ease of a public cloud. Virtual servers for VPC offer the best network performance (up to 80 Gbps), best security, and fastest provisioning times.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-advanced-virtual-servers&interface=ui"},{"document_id":"ibmcld_14905-7-2029","score":18.7310428619,"text":"\nAbout networking \n\nIBM Cloud\u00ae Virtual Private Cloud (VPC) is a virtual network that is linked to your customer account. It gives you cloud security, with the ability to scale dynamically, by providing fine-grained control over your virtual infrastructure and your network traffic segmentation.\n\n\n\n Overview \n\nEach VPC is deployed to a single region. Within that region, the VPC can span multiple zones.\n\nSubnets in your VPC can connect to the public internet through an optional public gateway. You can assign floating IP addresses to any virtual server instance to enable it to be reachable from the internet, independent of whether its subnet is attached to a public gateway.\n\nSubnets within the VPC offer private connectivity; they can talk to each other over a private link through the implicit router. Setting up routes is not necessary. Figure 1 shows how you can subdivide a virtual private cloud with subnets and each subnet can reach the public internet.\n\nZoom\n\n![Figure showing how a VPC can be subdivided with subnets](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/vpc\/images\/vpc-experience-simple.svg)\n\nFigure 1. IBM VPC connectivity and security\n\n\n\n\n\n Terminology \n\nTo work with your VPC, review the basic concepts of region and zone as they apply to your deployment.\n\n\n\n Regions \n\nA region is an abstraction that is related to the geographic area in which a VPC is deployed. Each region contains multiple zones, which represent independent fault domains. A VPC can span multiple zones within its assigned region.\n\n\n\n\n\n Zones \n\nA zone is an abstraction that refers to the physical data center that hosts the compute, network, and storage resources, plus the related cooling and power, which provides services and applications. Zones are isolated from each other to create no shared single point of failure, improved fault tolerance, and reduced latency. Each zone is assigned a default address prefix, which specifies the address range in which subnets can be created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-networking-for-vpc"},{"document_id":"ibmcld_14870-7-1912","score":18.601568222,"text":"\nDeployment Journey Overview \n\nIBM Cloud\u00ae Virtual Private Cloud(VPC) allows you to establish your own virtual private cloud by defining a virtual network that is logically isolated from all other public cloud tenants. The underlying software defined networking (SDN) and virtual network functions allows you to quickly establish the network constructs and on-prem connectivity needed to run your workload. The information contained within this document is meant to serve as a technical guide for beginning with a new IBM Cloud Account and leading towards a fully configured VPC network environment.\n\nWelcome to the Deployment Journey for VPC on IBM Cloud! Use the sidebar on the left to navigate between the journey points.\n\n\n\n Journey Map \n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d50364af907081c3c38f99c11f35dd9cab4b2510\/vpc-journey\/images\/overview\/journey-map.png)\n\n\n\n\n\n Assumptions \n\nThis deployment guide will be assuming the following points. Please note that while your circumstance may not be exactly identical, you will still benefit from the overall journey steps and concepts covered in this guide.\n\n\n\n* You are already familar with the concepts introduced in the \"Tour IBM Cloud\" videos available on the [Getting Started with IBM Cloud](https:\/\/cloud.ibm.com\/cloud\/get-started) page.\n* Access groups will need to be defined so only certain users have the ability to create and manage the VPC network settings (i.e. CIDR ranges, Subnet ACL rules, etc.,).\n* You have a networking background and familar with concepts such as IP Addressing, subnets, routing, etc.,\n* Focus will be on establishing the underlying network connectivity to support VPC based workloads.\n\n\n\n* Note: A separate deployment guide will cover the compute resources which runs within the VPC like IBM Kubernetes Services (IKS), Red Hat OpenShift, IBM Code Engine, and VPC Virtual Server Instances (VSIs).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc-journey?topic=vpc-journey-vpc-overview"},{"document_id":"ibmcld_14762-7-2008","score":18.2511348724,"text":"\nVirtual Private Cloud overview \n\nThe IBM Cloud\u00ae Virtual Private Cloud is a virtual network that is linked to your customer account. It gives you cloud security, with the ability to scale dynamically, by providing fine-grained control over your virtual infrastructure and your network traffic segmentation.\n\nEach VPC is deployed to a single region. Within that region, the VPC can span multiple zones.\n\nIBM Cloud virtual or IBM Cloud bare metal server presented in your VPC is attached to subnets. Subnets within the VPC offer private connectivity, thus your servers can communicate within and between the subnets by using an implicit router. Subnets in your VPC can connect to the public internet through an optional public gateway, or you can assign floating IP addresses to any network interface of the servers.\n\nThe following diagram shows an overview of IBM Cloud VPC.\n\nZoom\n\n![IBM VPC connectivity and security](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/vpc-ryo-diagrams-overview-virtual.svg)\n\nFigure 1. IBM Cloud VPC connectivity and security\n\nReview the following concepts to understand how IBM Cloud VPC is constructed. The terminology is used throughout this architecture solution.\n\nA region is an abstraction that is related to the geographic area in which a VPC is deployed. Each region contains multiple zones, which represent independent fault domains. A VPC can span multiple zones within its assigned region. A region is also often referred to a multizone region or MZR.\n\nA zone is an abstraction that refers to the physical data center, which hosts the compute, network, storage resources, and the related cooling and power, which provides services and applications. Zones are isolated from each other, so to create no shared single point of failure, improved fault tolerance, and reduced latency. Each zone is assigned a default address prefix, which specifies the range of addresses in which subnets can be created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vpc-ryo-vpc"},{"document_id":"ibmcld_13963-7-2267","score":17.5482234955,"text":"\nPublic virtual servers \n\nThe public IBM Cloud\u00ae Virtual Servers offerings are IBM-managed, multi-tenant virtual server deployments. They give you rapid scalability and higher-cost effectiveness with pre-defined sizes that meet all business requirements to get you up and running quickly.\n\nNewer version available! Try our Virtual Servers for VPC. For more information, see [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started).\n\nPublic virtual servers have many advantages. The following are some examples.\n\n\n\n* Global availability The public virtual server offering is available in data centers across the globe.\n* Configuration choices, rapid deployment, and scalability The public virtual server offering gives you either small or large virtual server options to meet various workload requirements.\n\n\n\nThrough extra configuration, network performance of virtual servers can be improved as compared to using the default settings. For more information, see [Configuring virtual server settings for improved network performance](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-configuring-network-performance). However, the amount of allowable network traffic for public virtual servers, which encompasses virtual server instance SAN and other network-attached storage, has no guarantee. If network traffic of a virtual server instance has a significant, negative impact on other virtual servers, that instance might restart on a new host, or in extreme cases, become disabled. This negative impact is often observed as traffic levels approach 20,000 - 30,000 packets per second (PPS). For guaranteed networking, use of the Dedicated Virtual Server offering is recommended. For more information, see the single-tenant environment, [Dedicated virtual server](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-dedicated-virtual-servers) offering.\n\nThe following families of public instances are available for this offering.\n\n\n\nTable 1. Public virtual server family selections\n\n Families Description \n\n [Balanced](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-about-virtual-server-profilesbalanced) Best for common cloud workloads that require a balance of performance and scalability.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-about-public-virtual-servers"},{"document_id":"ibmcld_13247-7-1763","score":17.4806213379,"text":"\nHosting web applications from a secure private network \n\nThis tutorial describes the use of Classic Infrastructure. Most workloads can be implemented using [IBM Cloud\u00ae Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc) resources. Use IBM Cloud VPC to create your own private cloud-like computing environment on shared public cloud infrastructure. A VPC gives an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud tenants, creating a private, secure place on the public cloud. Specifically, [vpc network load balancer](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-nlb-vs-elb), [virtual server instances](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vsi_best_practices), [security groups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-security-groups), [network ACLs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-acls) and [public gateways](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-networking-for-vpcexternal-connectivity).\n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nHosting web applications is a common deployment pattern for public cloud, where resources can be scaled on demand to meet short term and long term usage demands. Security for the application workloads is a fundamental prerequisite, to complement the resilience and scalability afforded by public cloud.\n\nThis tutorial takes you through the creation of a scalable and secure Internet facing web application hosted in private network secured using a virtual router appliance (VRA), VLANs, NAT and firewalls. The application comprises a load balancer, two web application servers and a MySQL database server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-web-app-private-network"},{"document_id":"ibmcld_13948-7-1763","score":17.4806213379,"text":"\nHosting web applications from a secure private network \n\nThis tutorial describes the use of Classic Infrastructure. Most workloads can be implemented using [IBM Cloud\u00ae Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc) resources. Use IBM Cloud VPC to create your own private cloud-like computing environment on shared public cloud infrastructure. A VPC gives an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud tenants, creating a private, secure place on the public cloud. Specifically, [vpc network load balancer](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-nlb-vs-elb), [virtual server instances](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vsi_best_practices), [security groups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-security-groups), [network ACLs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-acls) and [public gateways](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-networking-for-vpcexternal-connectivity).\n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nHosting web applications is a common deployment pattern for public cloud, where resources can be scaled on demand to meet short term and long term usage demands. Security for the application workloads is a fundamental prerequisite, to complement the resilience and scalability afforded by public cloud.\n\nThis tutorial takes you through the creation of a scalable and secure Internet facing web application hosted in private network secured using a virtual router appliance (VRA), VLANs, NAT and firewalls. The application comprises a load balancer, two web application servers and a MySQL database server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-web-app-private-network"},{"document_id":"ibmcld_09271-7-1763","score":17.4806213379,"text":"\nHosting web applications from a secure private network \n\nThis tutorial describes the use of Classic Infrastructure. Most workloads can be implemented using [IBM Cloud\u00ae Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc) resources. Use IBM Cloud VPC to create your own private cloud-like computing environment on shared public cloud infrastructure. A VPC gives an enterprise the ability to define and control a virtual network that is logically isolated from all other public cloud tenants, creating a private, secure place on the public cloud. Specifically, [vpc network load balancer](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-nlb-vs-elb), [virtual server instances](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vsi_best_practices), [security groups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-security-groups), [network ACLs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-acls) and [public gateways](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-networking-for-vpcexternal-connectivity).\n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nHosting web applications is a common deployment pattern for public cloud, where resources can be scaled on demand to meet short term and long term usage demands. Security for the application workloads is a fundamental prerequisite, to complement the resilience and scalability afforded by public cloud.\n\nThis tutorial takes you through the creation of a scalable and secure Internet facing web application hosted in private network secured using a virtual router appliance (VRA), VLANs, NAT and firewalls. The application comprises a load balancer, two web application servers and a MySQL database server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/loadbalancer-service?topic=loadbalancer-service-web-app-private-network"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1510196182,"ndcg_cut_10":0.1510196182}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02882-27313-29495","score":17.53373909,"text":"\nThis response type only returns a valid response if the assistant to which you added this dialog skill also has a search skill associated with it.\n\n\n\n2. Click Add response to add another response type to the current response.\n\nYou might want to add multiple response types to a single response to provide a richer answer to a user query. For example, if a user asks for store locations, you could show a map and display a button for each store location that the user can click to get address details. To build that type of response, you can use a combination of image, options, and text response types. Another example is using a text response type before a pause response type so you can warn users before pausing the dialog.\n\nYou cannot add more than 5 response types to a single response. Meaning, if you define three conditional responses for a dialog node, each conditional response can have no more than 5 response types added to it.\n\nA single dialog node cannot have more than one Connect to human agent or more than one Search skill response.\n3. If you added more than one response type, you can click the Move up or down arrows to arrange the response types in the order you want your assistant to process them.\n\n\n\n\n\n\n\n\n\n Conditional responses \n\nA single dialog node can provide different responses, each one triggered by a different condition. Use this approach to address multiple scenarios in a single node.\n\nThe node still has a main condition, which is the condition for using the node and processing the conditions and responses that it contains.\n\nIn this example, your assistant uses information that it collected earlier about the user's location to tailor its response, and provide information about the store nearest the user. See [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables) for more information about how to store information collected from the user.\n\n![Shows a node that shows a user ask, Where are you located, and the dialog has three different responses depending on conditions that use info from the $state context variable to specify locations in those states.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_02873-7270-8670","score":17.2052268982,"text":"\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots. It also conditions on an intent value. It defines a set of slots, one for each piece of information that you want to collect from the user. Each slot asks a question to elicit the answer from the user. It looks for a specific entity value in the user's reply to the prompt, which it then saves in a slot context variable.\n\nThis type of node is useful for collecting details you might need to perform a transaction on the user's behalf. For example, if the user's intent is to book a flight, the slots can collect the origin and destination location information, travel dates, and so on.\n\n\n\n\n\n\n\n Ready to get started? \n\nFor more information, see [Building a dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview).\n\nNext topic:[Planning the dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-plan)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build"},{"document_id":"ibmcld_03273-15771-16733","score":15.98848629,"text":"\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.\n\n\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object. Some fields that appear to be part of a single node are actually structured as separate dialog nodes in the underlying JSON object.\n\n- Each node and folder is represented as its own node.\n- Each conditional response that is associated with a single dialog node is represented as an individual node.\n- For a node with slots, each slot, slot found response, slot not found response, slot handler, and if set, the \"prompt for everything\" response is an individual node. In effect, one node with three slots might be equivalent to eleven dialog nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_02873-7-1949","score":15.7741918564,"text":"\nDialog overview \n\nThe dialog uses the intents that are identified in the user's input, plus context from the application, to interact with the user and ultimately provide a useful response.\n\nThe dialog matches intents (what users say) to responses (what the bot says back). The response might be the answer to a question such as Where can I get some gas? or the execution of a command, such as turning on the radio. The intent and entity might be enough information to identify the correct response, or the dialog might ask the user for more input that is needed to respond correctly. For example, if a user asks, Where can I get some food? you might want to clarify whether they want a restaurant or a grocery store, to dine in or take out, and so on. You can ask for more details in a text response and create one or more child nodes to process the new input.\n\nThe dialog is represented graphically in Watson Assistant as a tree. Create a branch to process each intent that you want your conversation to handle. A branch is composed of multiple nodes.\n\n\n\n Dialog nodes \n\nEach dialog node contains, at a minimum, a condition and a response.\n\n![Shows user input going to a box that contains the statement If: CONDITION, Then: RESPONSE](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/node1-empty.png)\n\n\n\n* Condition: Specifies the information that must be present in the user input for this node in the dialog to be triggered. The information is typically a specific intent. It might also be an entity type, an entity value, or a context variable value. See [Conditions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-builddialog-overview-conditions) for more information.\n* Response: The utterance that your assistant uses to respond to the user. The response can also be configured to show an image or a list of options, or to trigger programmatic actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build"},{"document_id":"ibmcld_02882-7-2075","score":15.5054016113,"text":"\nBuilding a conversational flow \n\nThe dialog defines what your assistant says in response to customers.\n\n\n\n Creating a dialog \n\nTo create a dialog, complete the following steps:\n\n\n\n1. Click the Dialog tab, and then click Create dialog.\n\nWhen you open the dialog editor for the first time, the following nodes are created for you:\n\n\n\n* Welcome: The first node. It contains a greeting that is displayed to your users when they first engage with your assistant. You can edit the greeting.\n\n\n\nThis node is not triggered in dialog flows that are initiated by users. For example, dialogs that are deployed in environments such as messaging channels where customers start the conversation do not process nodes with the welcome special condition.\n\n\n\n* Anything else: The final node. It contains phrases that are used to reply to users when their input is not recognized. You can replace the responses that are provided or add more responses with a similar meaning to add variety to the conversation. You can also choose whether you want your assistant to return each response that is defined in turn or return them in random order.\n\n\n\n2. To add more nodes to the dialog tree, click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) icon on the Welcome node, and then select Add node below.\n3. In the If assistant recognizes field, enter a condition that, when met, triggers your assistant to process the node.\n\nTo start off, you typically want to add an intent as the condition. For example, if you add open_account here, it means that you want the response that you will specify in this node to be returned to the user if the user input indicates that the user wants to open an account.\n\nAs you begin to define a condition, a box is displayed that shows you your options. You can enter one of the following characters, and then pick a value from the list of options that is displayed.\n\n\n\nCondition builder syntax\n\n Character Lists defined values for these artifact types \n\n `#` intents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_02998-5532-6964","score":15.4941978455,"text":"\nYou created a dialog node that is triggered by the welcome condition. (welcome is a special condition that functions like an intent, but does not begin with a .) It is triggered when a new conversation starts. Your node specifies that when a new conversation starts, the system should respond with the welcome message that you add to the response section of this first node.\n\n\n\n\n\n Testing the start node \n\nYou can test your dialog at any time to verify the dialog. Let's test it now.\n\n\n\n* Click the ![Try it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/try-it.png) icon to open the Try it out pane. You should see your welcome message.\n\n\n\n\n\n\n\n Adding nodes to handle intents \n\nNow let's add nodes between the Welcome node and the Anything else node that handle our intents.\n\n\n\n1. Click the More icon ![More options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab-grey.png) on the Welcome node, and then select Add node below.\n2. In the If assistant recognizes field of this node, start to type General_Greetings. Then, select the General_Greetings option.\n3. Add the response text, Good day to you!\n\n\n\n![Adding a general greeting node to the dialog.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-greeting-node.png)\n\n\n\n1. Click !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_02952-1632-3754","score":15.4837875366,"text":"\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_02882-18936-21214","score":15.3825130463,"text":"\nYou can return responses with multimedia or interactive elements such as images or clickable buttons to simplify the interaction model of your application and enhance the user experience.\n\nIn addition to the default response type of Text, for which you specify the text to return to the user as a response, the following response types are supported:\n\n\n\n* Connect to human agent: The dialog calls a service that you designate, typically a service that manages human agent support ticket queues, to pass off the conversation to a person. You can optionally include a message that summarizes the user's issue to be provided to the human agent. It is the responsibility of the external service to display a message that is shown to the user that explains that the conversation is being transferred. The dialog does not manage that communication itself. The dialog transfer does not occur when you are testing nodes with this response type in the Try it out pane. You must access a node that uses this response type from a test deployment to see how your users will experience it.\n* Image: Embeds an image into the response. The source image file must be hosted somewhere and have a URL that you can use to reference it. It cannot be a file that is stored in a directory that is not publicly accessible.\n* Option: Adds a list of one or more options. When a user clicks one of the options, an associated user input value is sent to your assistant. How options are rendered can differ depending on where you deploy the dialog. For example, in one integration channel the options might be displayed as clickable buttons, but in another they might be displayed as a dropdown list.\n* Pause: Forces the application to wait for a specified number of milliseconds before continuing with processing. You can choose to show an indicator that the dialog is working on typing a response. Use this response type if you need to perform an action that might take some time. For example, a parent node makes a Cloud Function call and displays the result in a child node. You could use this response type as the response for the parent node to give the programmatic call time to complete, and then jump to the child node to show the result. This response type does not render in the Try it out pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_02953-12940-14393","score":15.3488826752,"text":"\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\nYou can see the number of dialog nodes in a dialog skill from the assistant tile. If the skill is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object. Some fields that appear to be part of a single node are actually structured as separate dialog nodes in the underlying JSON object.\n\n\n\n* Each node and folder is represented as its own node.\n* Each conditional response that is associated with a single dialog node is represented as an individual node.\n* For a node with slots, each slot, slot found response, slot not found response, slot handler, and if set, the prompt for everything response is an individual node. In effect, one node with three slots might be equivalent to eleven dialog nodes.\n\n\n\nPrevious topic:[Controlling the dialog flow](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime)\n\nNext topic:[Dialog building tips](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tips)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_03040-43198-45083","score":15.2450218201,"text":"\nRich response types support\n: Rich response types are now supported in a dialog node with slots. You can display a list of options for a user to choose from as the prompt for a slot, for example. For more information, see [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots).\n\nImproved Entities, Dialog, and Intents page responsiveness\n: The Entities, Dialog, and Intents pages were updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\nCreating contextual entities is easier\n: The process you use to annotate entity mentions from intent user examples was improved. You can now put the intent page into annotation mode to more easily select and label mentions. For more information, see [Adding contextual entities](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entitiesentities-create-annotation-based).\n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. This capability is being introduced as a beta feature. For more details, see [Making a programmatic call from dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-webhooks).\n\nTesting improvement\n: You can now see the top three intents that were recognized in a test user input from the Try it out pane. For more details, see [Testing your dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasksdialog-tasks-test).\n\n\n\n\n\n 3 September 2019 \n\nIBM Watson\u00ae Assistant for IBM Cloud Pak\u00ae for Data version 1.3 is available\n: Watson Assistant for IBM Cloud Pak\u00ae for Data version 1.3 is compatible with IBM Cloud Pak\u00ae for Data versions 2.1.0.1 and 2.1.0.2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2371977128,"ndcg_cut_10":0.4415801104}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03010-7-2157","score":15.6116447449,"text":"\nDefining intents \n\nIntents are purposes or goals that are expressed in a customer's input, such as answering a question or processing a bill payment. By recognizing the intent expressed in a customer's input, the Watson Assistant service can choose the correct dialog flow for responding to it.\n\n\n\n Intent creation overview \n\n\n\n* Plan the intents for your application.\n\nConsider what your customers might want to do, and what you want your application to be able to handle on their behalf. For example, you might want your application to help your customers make a purchase. If so, you can add a buy_something intent. (The that is added as a prefix to the intent name helps to clearly identify it as an intent.)\n* Teach Watson about your intents.\n\nAfter you decide which business requests that you want your application to handle for your customers, you must teach Watson about them. For each business goal (such as buy_something), you must provide at least 5 examples of utterances that your customers typically use to indicate their goal. For example, I want to make a purchase.\n\nIdeally, find real-world user utterance examples that you can extract from existing business processes. The user examples should be tailored to your specific business. For example, if you are an insurance company, a user example might look more like this, I want to buy a new XYZ insurance plan.\n\nThe examples that you provide are used by your assistant to build a machine learning model that can recognize the same and similar types of utterances and map them to the appropriate intent.\n\n\n\nStart with a few intents, and test them as you iteratively expand the scope of the application.\n\n\n\n\n\n Creating intents \n\n\n\n1. Open your dialog skill. The skill opens to the Intents page.\n2. Select Create intent.\n3. In the Intent name field, type a name for the intent.\n\n\n\n* The intent name can contain letters (in Unicode), numbers, underscores, hyphens, and periods.\n* The name cannot consist of .. or any other string of only periods.\n* Intent names cannot contain spaces and must not exceed 128 characters. The following are examples of intent names:\n\n\n\n* weather_conditions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents"},{"document_id":"ibmcld_03191-3683-5706","score":13.3751153946,"text":"\nFor this Dialog runtime context which is set by a previous node or external application:\n\n{\n\"context\": {\n\"toppings_array\": [\"onion\", \"olives\", \"ham\"]\n}\n}\n\nDialog node or response condition:\n\n$toppings_array.containsIgnoreCase('HAM')\n\nResult: true because the array contains the element ham and the case is ignored.\n\n\n\n\n\n JSONArray.containsIntent(String intent_name, Double min_score, [Integer top_n]) \n\nThis method returns true if the intents JSONArray specifically contains the specified intent, and that intent has a confidence score that is equal to or higher than the specified minimum score. Optionally, you can specify a number to indicate that the intent must be included within that number of top elements in the array. The top_n parameter is ignored if you specify a negative number.\n\nReturns false if the specified intent is not in the array, does not have a confidence score that is equal to or greater than the minimum confidence score, or the array index of the intent is lower than the specified index location.\n\nThe service automatically generates an intents array that lists the intents that the service detects in the input whenever user input is submitted. The array lists all intents that are detected by the service in order of highest confidence first.\n\nYou can use this method in a node condition to not only check for the presence of an intent, but to set a confidence score threshold that must be met before the node can be processed and its response returned.\n\nFor example, use the following expression in a node condition when you want to trigger the dialog node only when the following conditions are met:\n\n\n\n* The General_Ending intent is present.\n* The confidence score of the General_Ending intent is over 80%.\n* The General_Ending intent is one of the top 2 intents in the intents array.\n\n\n\nintents.containsIntent(\"General_Ending\", 0.8, 2)\n\n\n\n\n\n JSONArray.filter(temp, \"temp.property operator comparison_value\") \n\nFilters an array by comparing each array element value to a value you specify.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methods"},{"document_id":"ibmcld_03403-1720-3144","score":13.1374673843,"text":"\nStep 2: Answer questions about the restaurant \n\nAdd an intent that recognizes when customers ask for details about the restaurant itself. An intent is the purpose or goal expressed in user input. The General_About_You intent that is provided with the General content catalog serves a similar function, but its user examples are designed to focus on queries about the assistant as opposed to the business that is using the assistant to help its customers. So, you will add your own intent.\n\n\n\n Add the about_restaurant intent \n\n\n\n1. From the Intents tab, click Create intent.\n\n![Shows the the Create intent button on the Intents page.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-ass-intent-add.png)\n2. Enter about_restaurant in the Intent name field, and then click Create intent.\n\n![Shows the #about_restaurant intent being added.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-ass-add-intent.png)\n3. Add the following user examples:\n\nTell me about the restaurant\ni want to know about you\nwho are the restaurant owners and what is their philosophy?\nWhat's your story?\nWhere do you source your produce from?\nWho is your head chef and what is the chef's background?\nHow many locations do you have?\ndo you cater or host functions on site?\nDo you deliver?\nAre you open for breakfast?\n4. Click the Close!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial"},{"document_id":"ibmcld_03334-4-1943","score":13.0655460358,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Creating intents \n\nIntents are purposes or goals that are expressed in a customer's input, such as answering a question or processing a bill payment. By recognizing the intent expressed in a customer's input, the Watson Assistant service can choose the correct dialog flow for responding to it.\n\nTo learn more about creating intents, watch the following 2 1\/2-minute video.\n\n\n\n Intent creation overview \n\n\n\n* Plan the intents for your application.\n\nConsider what your customers might want to do, and what you want your application to be able to handle on their behalf. For example, you might want your application to help your customers make a purchase. If so, you can add a buy_something intent. (The that is added as a prefix to the intent name helps to clearly identify it as an intent.)\n* Teach Watson about your intents.\n\nAfter you decide which business requests that you want your application to handle for your customers, you must teach Watson about them. For each business goal (such as buy_something), you must provide at least 5 examples of utterances that your customers typically use to indicate their goal. For example, I want to make a purchase.\n\nIdeally, find real-world user utterance examples that you can extract from existing business processes. The user examples should be tailored to your specific business. For example, if you are an insurance company, a user example might look more like this, I want to buy a new XYZ insurance plan.\n\nThe examples that you provide are used by your assistant to build a machine learning model that can recognize the same and similar types of utterances and map them to the appropriate intent.\n\n\n\nStart with a few intents, and test them as you iteratively expand the scope of the application.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"},{"document_id":"ibmcld_16727-2720-4792","score":12.407333374,"text":"\nAn intent represents the action a user wants to do. An entity represents the object of that action. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities). \n Integrations Ways you can deploy your assistant to existing platforms or social media channels. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add). \n Intent The goal that is expressed in the user input, such as answering a question or processing a bill payment. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents). \n Message A single turn within a conversation that includes a single call to the \/message API endpoint and its corresponding response. \n Monthly active user (MAU) A single unique user who interacts with an assistant one or many times in a given month. \n Preview Embeds your assistant in a chat window that is displayed on an IBM-branded web page. From the preview, you can test how a conversation flows through any and all skills that are attached to your assistant, from end to end. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-link). \n Response Logic that is defined in the Assistant responds section of a dialog node that determines how the assistant responds to the user. When the node's condition evaluates to true, the response is processed. The response can consist of an answer, a follow-up question, a webhook that sends a programmatic request to an external service, or slots which represent pieces of information that you need the user to provide before the assistant can help. The dialog node response is equivalent to a Then statement in If-Then-Else programming logic. \n Skill Does the work of the assistant. A dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offer step-by-step flows for a conversations and are made so that anybody can build them. A search skill is configured to search the appropriate external data sources for answers to customer questions.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-2720-4792","score":12.407333374,"text":"\nAn intent represents the action a user wants to do. An entity represents the object of that action. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities). \n Integrations Ways you can deploy your assistant to existing platforms or social media channels. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add). \n Intent The goal that is expressed in the user input, such as answering a question or processing a bill payment. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents). \n Message A single turn within a conversation that includes a single call to the \/message API endpoint and its corresponding response. \n Monthly active user (MAU) A single unique user who interacts with an assistant one or many times in a given month. \n Preview Embeds your assistant in a chat window that is displayed on an IBM-branded web page. From the preview, you can test how a conversation flows through any and all skills that are attached to your assistant, from end to end. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-link). \n Response Logic that is defined in the Assistant responds section of a dialog node that determines how the assistant responds to the user. When the node's condition evaluates to true, the response is processed. The response can consist of an answer, a follow-up question, a webhook that sends a programmatic request to an external service, or slots which represent pieces of information that you need the user to provide before the assistant can help. The dialog node response is equivalent to a Then statement in If-Then-Else programming logic. \n Skill Does the work of the assistant. A dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offer step-by-step flows for a conversations and are made so that anybody can build them. A search skill is configured to search the appropriate external data sources for answers to customer questions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03145-1287-2166","score":12.3633728027,"text":"\nIntents that are added from a content catalog are distinguishable from other intents by their names. Each intent name is prepended with the content catalog name.\n3. Add a content catalog to your dialog skill by clicking the Add to skill button.\n4. Go to the Intents page to see the intents that you added from the catalog listed.\n\n\n\nYour skill trains itself on the new data.\n\nAfter you add a catalog to your skill, the intents become part of your training data. If IBM makes subsequent updates to a content catalog, the changes are not automatically applied to any intents you added from a catalog.\n\n\n\n\n\n Editing content catalog intents \n\nLike any other intent, after you add content catalog intents to your skill, you can make the following changes to them:\n\n\n\n* Rename intents\n* Delete intents\n* Add, edit, or delete intent user examples\n* Move an example to a different intent","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog"},{"document_id":"ibmcld_02877-2458-4452","score":12.2892017365,"text":"\nThis method returns true if the input JSONArray contains the input value.\n\nFor this Dialog runtime context which is set by a previous node or external application:\n\n{\n\"context\": {\n\"toppings_array\": [\"onion\", \"olives\", \"ham\"]\n}\n}\n\nDialog node or response condition:\n\n$toppings_array.contains('ham')\n\nResult: True because the array contains the element ham.\n\n\n\n\n\n JSONArray.containsIntent(String intent_name, Double min_score, [Integer top_n]) \n\nThis method returns true if the intents JSONArray specifically contains the specified intent, and that intent has a confidence score that is equal to or higher than the specified minimum score. Optionally, you can specify a number to indicate that the intent must be included within that number of top elements in the array.\n\nReturns false if the specified intent is not in the array, does not have a confidence score that is equal to or higher than the minimum confidence score, or the intent is lower in the array than the specified index location.\n\nThe service automatically generates an intents array that lists the intents that the service detects in the input whenever user input is submitted. The array lists all intents that are detected by the service in order of highest confidence first.\n\nYou can use this method in a node condition to not only check for the presence of an intent, but to set a confidence score threshold that must be met before the node can be processed and its response returned.\n\nFor example, use the following expression in a node condition when you want to trigger the dialog node only when the following conditions are met:\n\n\n\n* The General_Ending intent is present.\n* The confidence score of the General_Ending intent is over 80%.\n* The General_Ending intent is one of the top two intents in the intents array.\n\n\n\nintents.containsIntent(\"General_Ending\", 0.8, 2)\n\n\n\n\n\n JSONArray.filter(temp, \"temp.property operator comparison_value\") \n\nFilters an array by comparing each array element value to a value you specify.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-methods"},{"document_id":"ibmcld_03373-2953-4766","score":11.7393789291,"text":"\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\n![Diagram of a simple exchange between a customer and an actions skill step.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/action-skill-explained.png)\n\n\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. The name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.\n* [Dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-build): A dialog is a branching conversation flow that defines how your application responds when it recognizes the defined intents and entities. You use the dialog editor to create conversations with users, providing responses based on the intents and entities that you recognize in their input.\n\n![Diagram of a basic implementation that uses intent and dialog only.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_03405-4-2057","score":11.7108678818,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding a node with slots to a dialog \n\nIn this tutorial, you will add slots to a dialog node to collect multiple pieces of information from a user within a single node. The node you create will collect the information that is needed to make a restaurant reservation.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Define the intents and entities that are needed by your dialog\n* Add slots to a dialog node\n* Test the node with slots\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 30 minutes to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-started). You will use the Watson Assistant tutorial skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\nYou can also start with a new dialog skill if you want. Just be sure to create the skill before you begin this tutorial.\n\n\n\n\n\n\n\n Step 1: Add intents and examples \n\nAdd an intent on the Intents tab. An intent is the purpose or goal that is expressed in user input. You will add a #reservation intent that recognizes user input that indicates that the user wants to make a restaurant reservation.\n\n\n\n1. From the Intents page of the tutorial skill, click Add intent.\n2. Add the following intent name, and then click Create intent:\n\nreservation\n\nThe #reservation intent is added. A number sign () is prepended to the intent name to label it as an intent. This naming convention helps you and others recognize the intent as an intent. It has no example user utterances associated with it yet.\n3. In the Add user examples field, type the following utterance, and then click Add example:\n\ni'd like to make a reservation\n4. Add these additional examples to help Watson recognize the reservation intent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.8175295904}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16410-1604-3872","score":11.5881004333,"text":"\nThe creation of a model is an iterative multiple-step process that involves several stages: knowledge curation, ground truth generation, model development, model evaluation, and runtime deployment.\n\n\n\n End-to-end domain adaptation \n\nThe following diagram summarizes the interactions between these five stages of model development and the typical activities that occur at each stage.\n\n![A summary of the five stages of model development and the activities that occur at each stage.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_flow.svg) Figure 2. A summary of the five stages of model development and the activities that occur at each stage.\n\n\n\n\n\n Knowledge curation \n\nThis stage, which is external to Knowledge Studio, refers to the process of selecting, collecting, preserving, and maintaining content relevant to a specific domain. Curation adds value to data; it transforms data into trusted information and knowledge.\n\n\n\n\n\n Ground truth generation \n\nThis stage refers to the use of Knowledge Studio tools and best practices to produce a collection of vetted data that can be used to adapt a Watson solution to a particular domain. The accuracy of this vetted data, called ground truth or gold standard documents, is critical because inaccuracies in the ground truth will correlate to inaccuracies in the applications that rely on it.\n\nAn essential part of teaching Watson about a new domain involves providing it with knowledge about entities of interest in your domain content, the relationships between them, and how the entities co-reference each other. Collecting this knowledge includes the following activities:\n\n\n\n* Involving domain subject matter experts to create the following resources, or to identify existing resources that can be re-used or modified for your domain:\n\n\n\n* Annotation guidelines and examples to help human annotators learn how words and passages in your domain content are to be annotated.\n* Type systems that define the domain-specific types (objects) and features (data classifications) that can be discovered in your domain content through text analysis. The type system controls the types of annotations that a human annotator can add to documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16468-1594-3857","score":11.3825426102,"text":"\nThe creation of a model is an iterative multiple-step process that involves several stages: knowledge curation, ground truth generation, model development, model evaluation, and runtime deployment.\n\n\n\n End-to-end domain adaptation \n\nThe following diagram summarizes the interactions between these five stages of model development and the typical activities that occur at each stage.\n\n![A summary of the five stages of model development and the activities that occur at each stage.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks_flow.svg) Figure 2. A summary of the five stages of model development and the activities that occur at each stage.\n\n\n\n\n\n Knowledge curation \n\nThis stage, which is external to Knowledge Studio, refers to the process of selecting, collecting, preserving, and maintaining content relevant to a specific domain. Curation adds value to data; it transforms data into trusted information and knowledge.\n\n\n\n\n\n Ground truth generation \n\nThis stage refers to the use of Knowledge Studio tools and best practices to produce a collection of vetted data that can be used to adapt a Watson solution to a particular domain. The accuracy of this vetted data, called ground truth or gold standard documents, is critical because inaccuracies in the ground truth will correlate to inaccuracies in the applications that rely on it.\n\nAn essential part of teaching Watson about a new domain involves providing it with knowledge about entities of interest in your domain content, the relationships between them, and how the entities co-reference each other. Collecting this knowledge includes the following activities:\n\n\n\n* Involving domain subject matter experts to create the following resources, or to identify existing resources that can be re-used or modified for your domain:\n\n\n\n* Annotation guidelines and examples to help human annotators learn how words and passages in your domain content are to be annotated.\n* Type systems that define the domain-specific types (objects) and features (data classifications) that can be discovered in your domain content through text analysis. The type system controls the types of annotations that a human annotator can add to documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_03921-77550-79807","score":11.2003498077,"text":"\nChannels replicate the structure of a blockchain network in that they contain members, peers, an ordering service, a ledger, policies, and smart contracts. But by restricting the membership, and even the knowledge of the channel, to particular subsets of the network membership, channels ensure that network members can leverage the overall structure of the network while maintaining privacy, where needed.\n\nTo join a peer from Org1 to a channel, Org1 must first be added to the consortium. After which, it can create a channel and join a peer to it. If the organization is not a member of the consortium at channel creation time, it is possible to create the channel and add the organization later by clicking the Settings button on the page of the relevant channel and editing the channel.\n\nAfter the channel has been created, subsequent organizations do not have to join the consortium before being joined to a channel by the channel administrators through a channel configuration update. However, these organizations will only be able to create their own channels if they are added to the consortium first.\n\nFor more information about channels and how to use them, see the [Hyperledger Fabric documentation](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/channels.html).\n\nWatch [Video 3](http:\/\/ibm.biz\/BlockchainPlatformSeries4) above to learn about the process to create channel and join your peer to the channel.\n\n\n\n Creating a channel: channel1 \n\nBecause the console uses peers to gather information about the channels that the peers belong to, unless an organization has joined a peer to a channel, it cannot interact with the channel.\n\nWhen you have created your CAs, identities, MSPs, ordering service, a peer, and have added your peer organization to the consortium, navigate to the Channels tab in the left navigation. This is where channel creation and management are handled.\n\nWhen you first navigate to this tab, it will be empty except for the Create channel and Join channel buttons. This is because you haven't created a channel and joined a peer to it yet.\n\n\n\n Creating the channel \n\nPerform the following steps from your console:\n\n\n\n1. Navigate to the Channels tab.\n2. Click Create channel. The create channel panel will open.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-network"},{"document_id":"ibmcld_09055-58128-59568","score":11.0392446518,"text":"\nThis workflow creates a root key using an import token, deletes the key, then restores the key.\n\nThis is a two-step process.\n\n\n\n1. Create a root key using an import token and then delete the key\n2. Create an import token, which is required to restore the key, and restore the key\n\n\n\nCreating a root key using an import token has a time limit (the -e, --expiration option). When you restore a key you need an import token. Which is why you need to go through an import token process to restore a key.\n\nStep 1 - create a root key using an import token and then delete the key\n\n create an import token that expires in 5 minutes and allows 10 retrievals\n$ ibmcloud kp import-token create -e 300 -m 10\n\nCreated Expires Max Retrievals Remaining Retrievals\n2020-06-18 12:21:59 +0000 UTC 2020-06-18 12:26:59 +0000 UTC 10 10\n\n create a random, base64-encoded, 32-byte key material\n$ KEY_MATERIAL=$(openssl rand -base64 32)\n\n$ echo $KEY_MATERIAL\n\nsADDNDE3pcJlbYXu2z5QFORvsxV1PosRiAPERrhYJdk=\n\n extract the nonce that was created by the \"kp import-token create\" command\n$ NONCE=$(ibmcloud kp import-token show | jq -r '.[\"nonce\"]')\n\n$ echo $NONCE\n\n\/QhqOsqlVPC+ZPWz\n\n extract the public key that was created by the \"kp import-token create\" command\n$ PUBLIC_KEY=$(ibmcloud kp import-token show | jq -r '.[\"payload\"]')\n\n$ echo $PUBLIC_KEY\n\nLS0tLS1CRUdJTiBQVUJMSUMgS0VZLS0t ...<redacted>... QyBLRVktLS0tLQo=\n\n encrypt the key material using the public key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_16613-0-1165","score":10.8004350662,"text":"\n\n\n\n\n\n\n  Creating table \n\nYou can generate, configure, and run DDL from the Data manager page by using the web console.\n\n\n\n1.  Log in to IBM\u00ae watsonx.data console.\n2.  From the navigation menu, select Data manager.\n3.  Select the engine from the Engine menu. Catalogs that are associated with the selected engine are listed.\n4.  Click Create and select Create table.\n5.  In the Create table form, drag a file to the box or click to upload.\n\n.CSV, .Parquet, .json, .txt are the supported data file formats. For .json file, you must enclose the content in [].\n6.  Click the data type and choose the required data types for each column. Click Next.\n7.  In the Target form, select the Engine, Catalog, and Schema in which the table is created.\n8.  Enter a name for the table in the Table name field and click Next.\n9.  Verify the details in the Summary page and scroll down to view the DDL preview.\n10. Click Create.\n11. Verify that the table creation status in the Result set is successful, indicated as true.\n12. Go to the Data manager page and select the schema under which you created the table and click the refresh icon. The newly created table is listed.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-create_table"},{"document_id":"ibmcld_00096-8640-9995","score":10.7548370361,"text":"\n* @provision.json: Structure the JSON file as shown in the following example. Use the access and secret key from the response the of Cloud Object Storage service key creation call.\n\n\n\nExample of the provision.json file\n: Sample JSON file:\n\n{\n\"default_runtime\": {\n\"spark_version\": \"3.1\" },\n\"instance_home\": {\n\"region\": \"us-south\",\n\"endpoint\": \"https:\/\/s3.direct.us-south.cloud-object-storage.appdomain.cloud\",\n\"hmac_access_key\": \"<your-hmac-access-key>\",\n\"hmac_secret_key\": \"<your-hmac-secret-key>\"}\n}\n\nExample\n: Enter:\n\nibmcloud resource service-instance-create test-ae-service ibmanalyticsengine standard-serverless-spark us-south -p @ae_provision.json\n\nResponse\n: The example returns:\n\nCreating service instance test-ae-service in resource group <Resource Group Name> of account <Account Name> as <email id>...\n\nOK\n\nService instance test-ae-service was created.\nName: test-ae-service\nID: crn:v1:bluemix:public:ibmanalyticsengine:us-south:a\/183aac93b485e:181eabe1-709781b::\nGUID: 181ea9ee01b\nLocation: us-south\nState: provisioning\nType: service_instance\nSub Type:\nService Endpoints: public\nAllow Cleanup: false\nLocked: false\nCreated at: 2022-01-03T08:40:25Z\nUpdated at: 2022-01-03T08:40:26Z\nLast Operation:\nStatus create in progress\nMessage Started create instance operation\nShow more\n2. Check the status of the Analytics Engine service:\n\nAction\n: Enter:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-cli"},{"document_id":"ibmcld_09120-32889-34053","score":10.7324762344,"text":"\nCreating key: 'my-base64-root-key', in instance: '390086ac-76fa-4094-8cf3-c0829bd69526'...\nOK\nKey ID Key Name\n5f9eef2d-53b4-42e8-8b56-c2970255210a my-base64-root-key\n\n\n\n\n\n Example 4 \n\nCreate a root key using an import token.\n\n create an import token that expires in 5 minutes and allows 10 retrievals\n$ ibmcloud kp import-token create -e 300 -m 10\n\n create a random, base64-encoded, 32-byte key material\n$ KEY_MATERIAL=$(openssl rand -base64 32)\n\n extract the nonce that was created by the \"kp import-token create\" command\n$ NONCE=$(ibmcloud kp import-token show | jq -r '.[\"nonce\"]')\n\n extract the public key that was created by the \"kp import-token create\" command\n$ PUBLIC_KEY=$(ibmcloud kp import-token show | jq -r '.[\"payload\"]')\n\n encrypt the key material using the public key\n$ ibmcloud kp import-token key-encrypt -k $KEY_MATERIAL -p $PUBLIC_KEY\n\nEncrypted Key\nqT1pyiS1Sivbmmt4doTtfZC4XuLazk7u ...<redacted>... +a\/6EqeAamo\/9vo=\n\n capture the encrypted key material\n$ ENCRYPTED_KEY=qT1pyiS1Sivbmmt4doTtfZC4XuLazk7u ...<redacted>... +a\/6EqeAamo\/9vo=\n\n encrypt the nonce\n$ ibmcloud kp import-token nonce-encrypt -k $KEY_MATERIAL -n $NONCE\n\nEncrypted Nonce IV","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08987-31569-32733","score":10.7324762344,"text":"\nCreating key: 'my-base64-root-key', in instance: '390086ac-76fa-4094-8cf3-c0829bd69526'...\nOK\nKey ID Key Name\n5f9eef2d-53b4-42e8-8b56-c2970255210a my-base64-root-key\n\n\n\n\n\n Example 4 \n\nCreate a root key using an import token.\n\n create an import token that expires in 5 minutes and allows 10 retrievals\n$ ibmcloud kp import-token create -e 300 -m 10\n\n create a random, base64-encoded, 32-byte key material\n$ KEY_MATERIAL=$(openssl rand -base64 32)\n\n extract the nonce that was created by the \"kp import-token create\" command\n$ NONCE=$(ibmcloud kp import-token show | jq -r '.[\"nonce\"]')\n\n extract the public key that was created by the \"kp import-token create\" command\n$ PUBLIC_KEY=$(ibmcloud kp import-token show | jq -r '.[\"payload\"]')\n\n encrypt the key material using the public key\n$ ibmcloud kp import-token key-encrypt -k $KEY_MATERIAL -p $PUBLIC_KEY\n\nEncrypted Key\nqT1pyiS1Sivbmmt4doTtfZC4XuLazk7u ...<redacted>... +a\/6EqeAamo\/9vo=\n\n capture the encrypted key material\n$ ENCRYPTED_KEY=qT1pyiS1Sivbmmt4doTtfZC4XuLazk7u ...<redacted>... +a\/6EqeAamo\/9vo=\n\n encrypt the nonce\n$ ibmcloud kp import-token nonce-encrypt -k $KEY_MATERIAL -n $NONCE\n\nEncrypted Nonce IV","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"},{"document_id":"ibmcld_04488-32262-33426","score":10.7324762344,"text":"\nCreating key: 'my-base64-root-key', in instance: '390086ac-76fa-4094-8cf3-c0829bd69526'...\nOK\nKey ID Key Name\n5f9eef2d-53b4-42e8-8b56-c2970255210a my-base64-root-key\n\n\n\n\n\n Example 4 \n\nCreate a root key using an import token.\n\n create an import token that expires in 5 minutes and allows 10 retrievals\n$ ibmcloud kp import-token create -e 300 -m 10\n\n create a random, base64-encoded, 32-byte key material\n$ KEY_MATERIAL=$(openssl rand -base64 32)\n\n extract the nonce that was created by the \"kp import-token create\" command\n$ NONCE=$(ibmcloud kp import-token show | jq -r '.[\"nonce\"]')\n\n extract the public key that was created by the \"kp import-token create\" command\n$ PUBLIC_KEY=$(ibmcloud kp import-token show | jq -r '.[\"payload\"]')\n\n encrypt the key material using the public key\n$ ibmcloud kp import-token key-encrypt -k $KEY_MATERIAL -p $PUBLIC_KEY\n\nEncrypted Key\nqT1pyiS1Sivbmmt4doTtfZC4XuLazk7u ...<redacted>... +a\/6EqeAamo\/9vo=\n\n capture the encrypted key material\n$ ENCRYPTED_KEY=qT1pyiS1Sivbmmt4doTtfZC4XuLazk7u ...<redacted>... +a\/6EqeAamo\/9vo=\n\n encrypt the nonce\n$ ibmcloud kp import-token nonce-encrypt -k $KEY_MATERIAL -n $NONCE\n\nEncrypted Nonce IV","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_02575-1438-3471","score":10.5675096512,"text":"\nThe POST URI used to create a resource SHOULD be the same as the GET URI for listing resources of the same kind.\n\n[4]For example, if GET \/users lists all users, and users can be created by a client, then POST \/users SHOULD create a user.\n\nThe response to a POST request which successfully and synchronously creates a resource MUST have the status code 201 Created and a Location header with the URI of the newly-created resource\n\n[5]and SHOULD include the created resource in the response body. If including the resource is expensive (in terms of bandwidth or computation), [preference headers](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-headerspreference-headers) SHOULD be supported to give the client control over whether the resource is included.\n\nFields which are not mutable or not recognized MUST result in a 400 status code and appropriate error response model.\n\n\n\n\n\n Other uses \n\nSince POST requests are the only avenue for handling unsafe, non-idempotent, or safe and body-bearing\n\n[6]operations that don't fit into another category, a POST request MAY invoke such an operation, even if it does not result in the explicit creation of a resource.\n\nIn this case, the request body MAY be permitted to be absent or have a format unrelated to any resource which can be retrieved using a GET request. When such a request is successful, it SHOULD return a 200 OK status (for a response including a description of the result) or a 204 No Content status.\n\n[7]\n\n\n\n\n\n\n\n PUT \n\nA successful PUT request SHOULD replace an existing resource or, in specific cases, create a new resource.\n\nThe resource impacted by a PUT request MUST be located at the URI used in the request.\n\n[8]For example, if PUT \/users\/bob updates a user, GET \/users\/bob MUST retrieve the same user.\n\nWhen a PUT request is successfully and synchronously used to replace an existing resource, a status of 200 OK MUST be returned.\n\n[9]\n\nFields which are not mutable or not recognized MUST result in a 400 status code and appropriate error response model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-methods"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03117-7179-9311","score":13.2028245926,"text":"\n- The conversation context is now organized into two objects:\n\n- The global context contains system-level context data shared by all skills used by the assistant.\n\n- The skill context contains any user-defined context variables used by your dialog skill.\n\nHowever, keep in mind that state data, including conversation context, is now maintained by the assistant, so your application might not need to access the context at all (see [Let the assistant maintain state](api-migration-state)).\n\nRefer to the v2 [API Reference ](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message){: external} for complete documentation of the v2 response format.\n\n Let the assistant maintain state {: api-migration-state}\n\nFor most applications, you can now remove any code included for the purpose of maintaining state. It is no longer necessary to save the context and send it back to Watson Assistant with each turn of the conversation. The context is automatically maintained by Watson Assistant and can be accessed by your dialog as before.\n\nNote that with the v2 API, the context is by default not included in responses to the client application. However, your code can still access context variables if necessary:\n\n- You can still send a context object as part of the message input. Any context variables you include are stored as part of the context maintained by Watson Assistant. (If the context variable you send already exists in the context, the new value overwrites the previously stored value.)\n\nMake sure the context object you send conforms to the v2 format. All user-defined context variables sent by your application should be part of the skill context; typically, the only global context variable you might need to set is system.user_id, which is used by Plus and Premium plans for billing purposes.\n\n- You can still retrieve context variables from either the global or skill context. To have the context object included with message responses, use the return_context property in the message input options. For more information, see [Accessing context data](\/docs\/assistant?topic=assistant-api-client-get-context).\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-migration"},{"document_id":"ibmcld_03126-5596-6966","score":12.565656662,"text":"\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n\n\n\n\n\n Do you have existing content to leverage? \n\nThe answer to many a common question is already documented somewhere in your organization's technical information collateral. If only you could find it!\n\nGive your assistant access to this information by adding a search skill to your assistant. The search skill uses Discovery to return smart answers to natural language questions.\n\n\n\n\n\n Expand your assistant's responsibilities \n\nIf you start small, and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. The built-in metrics of active user conversations help you understand what your customers are asking about and how well your assistant is able to meet their needs.\n\nNothing beats real customer data. It will tell you what areas to tackle next.\n\n\n\n\n\n Ready to start building? \n\nSee [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add) to get started.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_07578-82572-84508","score":12.5149812698,"text":"\nThe dialog node response is equivalent to a Then statement in If-Then-Else programming logic. \n Skill Does the work of the assistant. A dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offers step-by-step flows for a range of simple or complex conversations and is made so that anybody can build. A search skill is configured to search the appropriate external data sources for answers to customer inquiries. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add). \n Skill version Versions are snapshots of a skill that you can create at key points during the development lifecycle. You can deploy one version to production, while you continue to make and test improvements that you make to another version of the skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-versions). \n Slots A special set of fields that you can add to a dialog node that enable the assistant to collect necessary pieces of information from the customer. For example, the assistant can require a customer to provide valid date and location details before it gets weather forecast information on the customer's behalf. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots). \n System entity Prebuilt entities that recognize references to common things like dates and numbers. You can add these to your skill and start using them immediately. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's Try it out pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-82547-84483","score":12.5149812698,"text":"\nThe dialog node response is equivalent to a Then statement in If-Then-Else programming logic. \n Skill Does the work of the assistant. A dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offers step-by-step flows for a range of simple or complex conversations and is made so that anybody can build. A search skill is configured to search the appropriate external data sources for answers to customer inquiries. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add). \n Skill version Versions are snapshots of a skill that you can create at key points during the development lifecycle. You can deploy one version to production, while you continue to make and test improvements that you make to another version of the skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-versions). \n Slots A special set of fields that you can add to a dialog node that enable the assistant to collect necessary pieces of information from the customer. For example, the assistant can require a customer to provide valid date and location details before it gets weather forecast information on the customer's behalf. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots). \n System entity Prebuilt entities that recognize references to common things like dates and numbers. You can add these to your skill and start using them immediately. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's Try it out pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-4297-6315","score":12.4951295853,"text":"\nThe dialog node response is equivalent to a Then statement in If-Then-Else programming logic. \n Skill Does the work of the assistant. A dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offer step-by-step flows for a conversations and are made so that anybody can build them. A search skill is configured to search the appropriate external data sources for answers to customer questions. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add). \n Skill version Versions are snapshots of a skill that you can create at key points during the development lifecycle. You can deploy one version to production, while you continue to make and test improvements that you make to another version of the skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-versions). \n Slots A special set of fields that you can add to a dialog node that enable the assistant to collect necessary pieces of information from the customer. For example, the assistant can require a customer to provide valid date and location details before it gets weather forecast information on the customer's behalf. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots). \n Step A step that you add to an action represents a single interaction or exchange of information with a customer, a turn in the conversation. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actions-overviewactions-overview-steps). \n System entity Prebuilt entities that recognize references to common things like dates and numbers. You can add these to your skill and start using them immediately. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-4297-6315","score":12.4951295853,"text":"\nThe dialog node response is equivalent to a Then statement in If-Then-Else programming logic. \n Skill Does the work of the assistant. A dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offer step-by-step flows for a conversations and are made so that anybody can build them. A search skill is configured to search the appropriate external data sources for answers to customer questions. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add). \n Skill version Versions are snapshots of a skill that you can create at key points during the development lifecycle. You can deploy one version to production, while you continue to make and test improvements that you make to another version of the skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-versions). \n Slots A special set of fields that you can add to a dialog node that enable the assistant to collect necessary pieces of information from the customer. For example, the assistant can require a customer to provide valid date and location details before it gets weather forecast information on the customer's behalf. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots). \n Step A step that you add to an action represents a single interaction or exchange of information with a customer, a turn in the conversation. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actions-overviewactions-overview-steps). \n System entity Prebuilt entities that recognize references to common things like dates and numbers. You can add these to your skill and start using them immediately. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03373-4-1923","score":11.6246805191,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding skills to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nConversational skills return responses that are authored by you to answer common questions, while a search skill searches for and returns passages from existing self-service content.\n\nYou can add the following types of skills to your assistant:\n\n\n\n* Conversational skills: Understand and address questions or requests that your customers typically ask about. You provide information about the subjects or tasks that your users need help with, and how they ask about them, and the product dynamically builds a machine learning model that is tailored to understand the same and similar user requests.\n\n\n\n* Actions skill : Offers a simple interface where anyone can build a conversational flow for your assistant to follow. The complex process of training data creation occurs behind the scenes automatically. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-actions-skill)\n* Dialog skill: Offers a set of editors that you use to define both your training data and the conversation. The conversation is represented as a dialog tree. You use the graphical dialog editor to create a script of sorts for your assistant to read from when it interacts with your customers. The dialog keys off the common customer goals that you teach it to recognize, and provides useful responses. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-dialog-skill)\n\n\n\nIf you can't decide which type of conversational skill to create, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n* Search skill!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_03313-4560-6553","score":11.4589185715,"text":"\nA dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offer step-by-step flows for a conversations and are made so that anybody can build them. A search skill is configured to search the appropriate external data sources for answers to customer questions. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add). \n Skill version Versions are snapshots of a skill that you can create at key points during the development lifecycle. You can deploy one version to production, while you continue to make and test improvements that you make to another version of the skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-versions). \n Slots A special set of fields that you can add to a dialog node that enable the assistant to collect necessary pieces of information from the customer. For example, the assistant can require a customer to provide valid date and location details before it gets weather forecast information on the customer's behalf. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots). \n Step A step that you add to an action represents a single interaction or exchange of information with a customer, a turn in the conversation. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actions-overviewactions-overview-steps). \n System entity Prebuilt entities that recognize references to common things like dates and numbers. You can add these to your skill and start using them immediately. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's \"Try it out\" pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"},{"document_id":"ibmcld_03085-4-2046","score":11.2557125092,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Managing access \n\nYou can give other people access to your Watson Assistant resources, and control the level of access they get.\n\nMaybe you want one development team to have access to a test assistant and another development team to have access to a production assistant. And you want data scientists to be able to view analytics for user conversation logs from both assistants. And maybe you want a writer to be able to author the dialogue that is used by your assistant to converse with your customers. To manage who can do what with your skills and assistants, you can assign different access roles to different people.\n\n\n\n Before you grant access to others \n\nFor each person to whom you grant access to your Watson Assistant service instance, decide whether you want to give the person a role with instance-level or resource-level access. Instance-level access applies to all of the assistants and skills in a single service instance. Resource-level access applies to individual skills and assistants within a service instance only.\n\n\n\n\n\n Granting users access to your resources \n\n\n\n1. If you plan to give a user access to a single skill or assistant in your service instance, get the ID for the skill or assistant. You need to provide the ID in a later step.\n\n\n\n* To get the assistant ID, go to the Assistants page. Click the overflow menu for the assistant, and then click Settings > API Details. Copy the assistant ID and paste it somewhere that you can access it from later.\n* To get the skill ID, go to the Skills page. Click the overflow menu for the skill, and then click View API Details. Copy the skill ID and paste it somewhere that you can access it from later.\n\n\n\n2. Click the User ![User](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/user-icon2.png) icon in the page header.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control"},{"document_id":"ibmcld_02990-2887-4913","score":11.2156572342,"text":"\nMessage A single turn within a conversation that includes a single call to the \/message API endpoint and its corresponding response. \n Monthly active user (MAU) A single unique user who interacts with an assistant one or many times in a given month. \n Preview link An integration that builds embeds your assistant in a chat window that is displayed on an IBM-branded web page. From the preview link integration, you can test how a conversation flows through any and all skills that are attached to your assistant, from end to end. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-link). \n Response Logic that is defined in the Assistant responds section of a dialog node that determines how the assistant responds to the user. When the node's condition evaluates to true, the response is processed. The response can consist of an answer, a follow-up question, a webhook that sends a programmatic request to an external service, or slots which represent pieces of information that you need the user to provide before the assistant can help. The dialog node response is equivalent to a Then statement in If-Then-Else programming logic. \n Skill Does the work of the assistant. A dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offers step-by-step flows for a range of simple or complex conversations and is made so that anybody can build. A search skill is configured to search the appropriate external data sources for answers to customer inquiries. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add). \n Skill version Versions are snapshots of a skill that you can create at key points during the development lifecycle. You can deploy one version to production, while you continue to make and test improvements that you make to another version of the skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-versions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1480409555}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02873-7-1949","score":16.7562885284,"text":"\nDialog overview \n\nThe dialog uses the intents that are identified in the user's input, plus context from the application, to interact with the user and ultimately provide a useful response.\n\nThe dialog matches intents (what users say) to responses (what the bot says back). The response might be the answer to a question such as Where can I get some gas? or the execution of a command, such as turning on the radio. The intent and entity might be enough information to identify the correct response, or the dialog might ask the user for more input that is needed to respond correctly. For example, if a user asks, Where can I get some food? you might want to clarify whether they want a restaurant or a grocery store, to dine in or take out, and so on. You can ask for more details in a text response and create one or more child nodes to process the new input.\n\nThe dialog is represented graphically in Watson Assistant as a tree. Create a branch to process each intent that you want your conversation to handle. A branch is composed of multiple nodes.\n\n\n\n Dialog nodes \n\nEach dialog node contains, at a minimum, a condition and a response.\n\n![Shows user input going to a box that contains the statement If: CONDITION, Then: RESPONSE](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/node1-empty.png)\n\n\n\n* Condition: Specifies the information that must be present in the user input for this node in the dialog to be triggered. The information is typically a specific intent. It might also be an entity type, an entity value, or a context variable value. See [Conditions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-builddialog-overview-conditions) for more information.\n* Response: The utterance that your assistant uses to respond to the user. The response can also be configured to show an image or a list of options, or to trigger programmatic actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build"},{"document_id":"ibmcld_03273-15771-16733","score":16.414686203,"text":"\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.\n\n\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object. Some fields that appear to be part of a single node are actually structured as separate dialog nodes in the underlying JSON object.\n\n- Each node and folder is represented as its own node.\n- Each conditional response that is associated with a single dialog node is represented as an individual node.\n- For a node with slots, each slot, slot found response, slot not found response, slot handler, and if set, the \"prompt for everything\" response is an individual node. In effect, one node with three slots might be equivalent to eleven dialog nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_02998-5532-6964","score":16.2261867523,"text":"\nYou created a dialog node that is triggered by the welcome condition. (welcome is a special condition that functions like an intent, but does not begin with a .) It is triggered when a new conversation starts. Your node specifies that when a new conversation starts, the system should respond with the welcome message that you add to the response section of this first node.\n\n\n\n\n\n Testing the start node \n\nYou can test your dialog at any time to verify the dialog. Let's test it now.\n\n\n\n* Click the ![Try it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/try-it.png) icon to open the Try it out pane. You should see your welcome message.\n\n\n\n\n\n\n\n Adding nodes to handle intents \n\nNow let's add nodes between the Welcome node and the Anything else node that handle our intents.\n\n\n\n1. Click the More icon ![More options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab-grey.png) on the Welcome node, and then select Add node below.\n2. In the If assistant recognizes field of this node, start to type General_Greetings. Then, select the General_Greetings option.\n3. Add the response text, Good day to you!\n\n\n\n![Adding a general greeting node to the dialog.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-greeting-node.png)\n\n\n\n1. Click !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03373-4327-6061","score":15.9947414398,"text":"\n* [Dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-build): A dialog is a branching conversation flow that defines how your application responds when it recognizes the defined intents and entities. You use the dialog editor to create conversations with users, providing responses based on the intents and entities that you recognize in their input.\n\n![Diagram of a basic implementation that uses intent and dialog only.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/basic-impl.png)\n\n\n\nTo enable your dialog skill to handle more nuanced questions, define entities and reference them from your dialog.\n\n\n\n* [Entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities); An entity represents a term or object that is relevant to your intents and that provides a specific context for an intent. For example, an entity might represent a city where the user wants to find a business location, or the amount of a bill payment. The name of an entity is always prefixed with the @ character.\n\nYou can train the skill to recognize your entities by providing entity term values and synonyms, entity patterns, or by identifying the context in which an entity is typically used in a sentence. To fine tune your dialog, go back and add nodes that check for entity mentions in user input in addition to intents.\n\n\n\n![Diagram of a more complex implementation that uses intent, entity, and dialog.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/complex-impl.png)\n\nAs you add information, the skill uses this unique data to build a machine learning model that can recognize these and similar user inputs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_02882-7-2075","score":15.9359636307,"text":"\nBuilding a conversational flow \n\nThe dialog defines what your assistant says in response to customers.\n\n\n\n Creating a dialog \n\nTo create a dialog, complete the following steps:\n\n\n\n1. Click the Dialog tab, and then click Create dialog.\n\nWhen you open the dialog editor for the first time, the following nodes are created for you:\n\n\n\n* Welcome: The first node. It contains a greeting that is displayed to your users when they first engage with your assistant. You can edit the greeting.\n\n\n\nThis node is not triggered in dialog flows that are initiated by users. For example, dialogs that are deployed in environments such as messaging channels where customers start the conversation do not process nodes with the welcome special condition.\n\n\n\n* Anything else: The final node. It contains phrases that are used to reply to users when their input is not recognized. You can replace the responses that are provided or add more responses with a similar meaning to add variety to the conversation. You can also choose whether you want your assistant to return each response that is defined in turn or return them in random order.\n\n\n\n2. To add more nodes to the dialog tree, click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) icon on the Welcome node, and then select Add node below.\n3. In the If assistant recognizes field, enter a condition that, when met, triggers your assistant to process the node.\n\nTo start off, you typically want to add an intent as the condition. For example, if you add open_account here, it means that you want the response that you will specify in this node to be returned to the user if the user input indicates that the user wants to open an account.\n\nAs you begin to define a condition, a box is displayed that shows you your options. You can enter one of the following characters, and then pick a value from the list of options that is displayed.\n\n\n\nCondition builder syntax\n\n Character Lists defined values for these artifact types \n\n `#` intents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_02873-7270-8670","score":15.6411800385,"text":"\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots. It also conditions on an intent value. It defines a set of slots, one for each piece of information that you want to collect from the user. Each slot asks a question to elicit the answer from the user. It looks for a specific entity value in the user's reply to the prompt, which it then saves in a slot context variable.\n\nThis type of node is useful for collecting details you might need to perform a transaction on the user's behalf. For example, if the user's intent is to book a flight, the slots can collect the origin and destination location information, travel dates, and so on.\n\n\n\n\n\n\n\n Ready to get started? \n\nFor more information, see [Building a dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview).\n\nNext topic:[Planning the dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-plan)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build"},{"document_id":"ibmcld_02953-12940-14393","score":15.5883827209,"text":"\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\nYou can see the number of dialog nodes in a dialog skill from the assistant tile. If the skill is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object. Some fields that appear to be part of a single node are actually structured as separate dialog nodes in the underlying JSON object.\n\n\n\n* Each node and folder is represented as its own node.\n* Each conditional response that is associated with a single dialog node is represented as an individual node.\n* For a node with slots, each slot, slot found response, slot not found response, slot handler, and if set, the prompt for everything response is an individual node. In effect, one node with three slots might be equivalent to eleven dialog nodes.\n\n\n\nPrevious topic:[Controlling the dialog flow](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime)\n\nNext topic:[Dialog building tips](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tips)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"},{"document_id":"ibmcld_03071-3000-4820","score":15.5104351044,"text":"\nYou have successfully enabled the @sys-date, @sys-time, and @sys-number system entities. Now you can use them in your dialog.\n\n\n\n\n\n Step 3: Add a dialog node with slots \n\nA dialog node represents the start of a thread of dialog between your assistant and the user. It contains a condition that must be met for the node to be processed by your assistant. At a minimum, it also contains a response. For example, a node condition might look for the hello intent in user input, and respond with, Hi. How can I help you? This example is the simplest form of a dialog node, one that contains a single condition and a single response. You can define complex dialogs by adding conditional responses to a single node, adding child nodes that prolong the exchange with the user, and much more. (If you want to learn more about complex dialogs, you can complete the [Building a complex dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial) tutorial.)\n\nThe node that you will add in this step is one that contains slots. Slots provide a structured format through which you can ask for and save multiple pieces of information from a user within a single node. They are most useful when you have a specific task in mind and need key pieces of information from the user before you can perform it. See [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots) for more information.\n\nThe node you add will collect the information required to make a reservation at a restaurant.\n\n\n\n1. Click the Dialogs tab to open the dialog tree.\n2. Click the More icon ![More options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) on the #General_Greetings node, and then select Add node below.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots"},{"document_id":"ibmcld_03273-13172-14845","score":15.4672613144,"text":"\nPlan Dialog nodes per skill \n\n Enterprise 100,000 \n Premium (legacy) 100,000 \n Plus 100,000 \n Trial 25,000 \n Lite 25,000 \n\n\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\n\n\n\n\n Finding a dialog node by its node ID \n\nYou can search for a dialog node by its node ID. Enter the full node ID into the search field. You might want to find the dialog node that is associated with a known node ID for any of the following reasons:\n\n\n\n* You are reviewing logs, and the log refers to a section of the dialog by its node ID.\n* You want to map the node IDs listed in the nodes_visited property of the API message output to nodes that you can see in your dialog tree.\n* A dialog runtime error message informs you about a syntax error, and uses a node ID to identify the node you need to fix.\n\n\n\nAnother way to discover a node based on its node ID is by following these steps:\n\n\n\n1. From the Dialog page, select any node in your dialog tree.\n2. Close the edit view if it is open for the current node.\n3. In your web browser's location field, a URL should display that has syntax similar to the following:\n\nhttps:\/\/{location}.assistant.watson.cloud.ibm.com\/{location}\/{instance-id}\/skills\/{skill-id}\/build\/dialognode={node-id}\n4. Edit the URL by replacing the current {node-id} value with the ID of the node you want to find, and then submit the new URL.\n5. If necessary, highlight the edited URL again, and resubmit it.\n\n\n\nThe page refreshes, and shifts focus to the dialog node with the node ID that you specified.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_02998-4422-6015","score":15.2719144821,"text":"\nWe'll create a simple dialog that handles greeting and ending intents, each with a single node.\n\n\n\n Adding a start node \n\n\n\n1. From the Skills menu, click Dialog.\n2. Two nodes were added to the dialog for you:\n\n\n\n* Welcome: Contains a greeting that is displayed to your users when they first engage with the assistant.\n* Anything else: Contains phrases that are used to reply to users when their input is not addressed by any of the existing dialog nodes.\n\n\n\n![A new dialog with two built-in nodes](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-new-dialog.png)\n3. Click the Welcome node to open it in the edit view.\n4. Replace the default response with the text, Welcome to the Watson Assistant tutorial!.\n\n![Editing the welcome node response](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-edit-welcome-node.png)\n5. Click ![Close](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/close.png) to close the edit view.\n\n\n\nYou created a dialog node that is triggered by the welcome condition. (welcome is a special condition that functions like an intent, but does not begin with a .) It is triggered when a new conversation starts. Your node specifies that when a new conversation starts, the system should respond with the welcome message that you add to the response section of this first node.\n\n\n\n\n\n Testing the start node \n\nYou can test your dialog at any time to verify the dialog. Let's test it now.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16491-7-2260","score":14.3307666779,"text":"\nUploading resources from another workspace \n\nTo accelerate the creation of a model, you can upload resources like documents (with or without ground truth annotations), a type system, and dictionaries that you downloaded from another workspace.\n\nThe ability to separately download and upload different resources gives you flexibility when designing and creating a model. For example, you might create one workspace to design the type system and perform human annotation, and then create a separate workspace, perhaps in a separate instance of Knowledge Studio with different users, to train the machine learning model. Being able to upload the resources, including the ground truth created by human annotators, makes this scenario possible.\n\nYou cannot download and upload a machine learning model. Instead, you can download all of the artifacts that were used to create the model from one workspace and upload them into a new workspace. From the new workspace, you can run training again to recreate the model. The new model should produce similar results to the original model because they were both trained with the same set of artifacts.\n\nThe files that you download are operating system-independent. The Knowledge Studio instances where you download and upload files do not have to run the same version of Linux.\n\n\n\n Type systems \n\nTo download a type system, open the Assets> Entity Types page and click Download Types. The system creates a file named types-ID.json and prompts you to download the file to your local system. To use this type system in a new workspace, open the Entity Types page and upload the JSON file that you downloaded.\n\n\n\n\n\n Dictionaries \n\nTo download all dictionaries, select the Assets > Dictionaries page, click the Menu icon next to the Create Dictionary button, and select Download Dictionaries. For each dictionary that you download, the system creates a file named dictionary name_timestamp.csv, combines the files into a ZIP file named workspace name_dictionary_timestamp.zip, and prompts you to download the file to your local system.\n\nYou can download an individual dictionary by opening the dictionary and clicking Download. Preview-only dictionaries that you uploaded as a dictionary CSV file cannot be downloaded.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-exportimport"},{"document_id":"ibmcld_16426-7-2260","score":14.3307638168,"text":"\nUploading resources from another workspace \n\nTo accelerate the creation of a model, you can upload resources like documents (with or without ground truth annotations), a type system, and dictionaries that you downloaded from another workspace.\n\nThe ability to separately download and upload different resources gives you flexibility when designing and creating a model. For example, you might create one workspace to design the type system and perform human annotation, and then create a separate workspace, perhaps in a separate instance of Knowledge Studio with different users, to train the machine learning model. Being able to upload the resources, including the ground truth created by human annotators, makes this scenario possible.\n\nYou cannot download and upload a machine learning model. Instead, you can download all of the artifacts that were used to create the model from one workspace and upload them into a new workspace. From the new workspace, you can run training again to recreate the model. The new model should produce similar results to the original model because they were both trained with the same set of artifacts.\n\nThe files that you download are operating system-independent. The Knowledge Studio instances where you download and upload files do not have to run the same version of Linux.\n\n\n\n Type systems \n\nTo download a type system, open the Assets> Entity Types page and click Download Types. The system creates a file named types-ID.json and prompts you to download the file to your local system. To use this type system in a new workspace, open the Entity Types page and upload the JSON file that you downloaded.\n\n\n\n\n\n Dictionaries \n\nTo download all dictionaries, select the Assets > Dictionaries page, click the Menu icon next to the Create Dictionary button, and select Download Dictionaries. For each dictionary that you download, the system creates a file named dictionary name_timestamp.csv, combines the files into a ZIP file named workspace name_dictionary_timestamp.zip, and prompts you to download the file to your local system.\n\nYou can download an individual dictionary by opening the dictionary and clicking Download. Preview-only dictionaries that you uploaded as a dictionary CSV file cannot be downloaded.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-exportimport"},{"document_id":"ibmcld_15953-3971-5677","score":13.4514913559,"text":"\nYou can create virtual server instances and bare metal servers with a mix of RSA and Ed25519 SSH keys.\n\n\n\n* For Windows or VMware images, you must use the RSA SSH key type. The Ed25519 SSH key type can't be used with Windows or VMware images.\n* For Linux images, the Ed25519 SSH key type can be used only if the SSH server for the operating system supports that key type.\n\n\n\nYou can't create SSH keys within the API, you can import only an existing SSH key. You can create an SSH key within the UI. You have the option when you create an SSH key to copy the API code snippet for that key.\n\nIn the API, you can specify which type of key by using the type variable. The default type is RSA. If you try to import a Ed25519 SSH key and don't specify the ed25519 key type, the process fails.\n\n\"type\":\"ed25519\"\n\n\n\n\n\n Before you begin \n\nYou can generate an SSH key in IBM Cloud\u00ae Virtual Private Cloud when you create the SSH key on the SSH keys for VPC page. However, if you choose to import an existing SSH key file, keep the following limitations in mind.\n\n\n\n* Your SSH key must be an RSA or Ed25519 key type with a key size of either 2048 bits or 4096 bits.\n* If your Mac system generates a key size of 3072 bits (by default), run one of the following commands to make sure that the generated key is a supported size.\n\n\n\n* For RSA SSH key type, issue: ssh-keygen -t rsa -b 4096 -C \"user_ID\"\n* For Ed25519 SSH key type, issue: ssh-keygen -t ed25519 -b 4096 -C \"user_ID\"\n\n\n\n* SSH keys are generated as key pairs; one is a public key, and the other is a private key. Select the public key when you import an SSH key to your VPC. The corresponding private key remains on your local workstation and is not imported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-ssh-keys&interface=ui"},{"document_id":"ibmcld_16527-7-2082","score":12.6480941772,"text":"\nEstablishing a type system \n\nThe type system controls how content can be annotated.\n\n\n\n Type systems \n\nA type system defines things that are interesting in your domain content that you want to label with an annotation. The type system controls how content can be annotated by defining the types of entities that can be labeled and how relationships among different entities can be labeled. The model process manager typically works with subject matter experts for your domain to define the type system.\n\nIn Knowledge Studio, you can create a type system from scratch or upload an existing type system. To jump-start a workspace, you might want to upload a type system that was created for a similar domain. You can then edit the type system to add or remove entity types or redefine the relationship types.\n\nA sample type system based on the KLUE type system is provided for you to use with the Knowledge Studio tutorials. KLUE stands for Knowledge from Language Understanding and Extraction and was derived by IBM Research based on the analysis of collections of news articles. [Download ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/icons\/launch-glyph.svg)](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/en-klue2-types.json) a sample KLUE type system.\n\nMany industries, such in domains like metallurgy, geology, market intelligence, life science, electronic health records, and oncology publish dictionaries or ontologies of domain-specific terminology. Consider referencing this type of resource to get an idea of the types of entities you might want to define in your own type system.\n\n\n\n Mentions \n\nA mention is any span of text that you consider relevant in your domain data. For example, in a type system about automotive vehicles, occurrences of terms like airbag, Ford Explorer, and child restraint system might be relevant mentions.\n\n\n\n\n\n Entity types \n\nAn entity type is how you categorize a real-world thing. An entity mention is an example of a thing of that type.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-typesystem"},{"document_id":"ibmcld_07082-7-2198","score":12.5785455704,"text":"\nCreating projects \n\nA project is a convenient way to collect and manage the resources in your IBM Watson\u00ae Discovery application. You can assign a Project type and connect your data to the project by creating a collection.\n\nBefore you create a project, decide which project type best fits your needs.\n\n\n\n Project descriptions \n\n\n\nProject type use cases\n\n Need Goal Project type \n\n Which document contains the answer to my question? Find meaningful information in sources that contain a mix of structured and unstructured data, and surface it in a stand-alone enterprise search application or in the search field of a business application. Document Retrieval \n Where is the part of the contract that I need for my task? Quickly extract critical information from contracts. Document Retrieval for Contracts \n I want the chatbot I'm building to use knowledge that I own. Give a virtual assistant quick access to technical information that is stored in various external data sources and document formats to answer customer questions. Conversational Search \n I want to uncover insights I didn't know to ask about. Gain insights from pattern analysis or perform root cause analysis. Content Mining \n\n\n\nIf you created the Discovery service as part of a IBM Cloud Pak for Data as a Service deployment, the Discovery project is separate and distinct from the deployment project that is displayed in IBM Cloud.\n\nTo create a project, complete the following steps:\n\n\n\n1. Open the Projects page by selecting My Projects.\n2. Click New project. Name your project, and then choose the project type.\n\nFor more information about each type, see [Project types](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projectsproject-type).\n\nOtherwise, choose None of the above and a Custom project type is created for you.\n3. If you choose a Document Retrieval project type and your data sources are in English, decide whether to enable the Content Intelligence feature.\n\nIf your data source contains contracts, enable the feature by selecting Apply contracts enrichment. Scroll to see the checkbox, if necessary.\n4. Click Next.\n5. Choose and configure a data source or connect to an existing collection.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects"},{"document_id":"ibmcld_15953-1492-2971","score":12.4532928467,"text":"\nIn the [IBM Cloud console ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/icons\/launch-glyph.svg)](https:\/\/cloud.ibm.com\/login), you can go to menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/icons\/icon_hamburger.svg) > VPC Infrastructure > Compute > SSH keys to manage your SSH keys. From here you can create, rename, or delete keys. If you select to create a key, that key must be an RSA SSH key type. You can upload an Ed25519 SSH key type, you just can't generate one within VPC.\n\n\n\n* For Windows or VMware images, you must use the RSA SSH key type. The Ed25519 SSH key type can't be used with Windows or VMware images.\n* For Linux images, the Ed25519 SSH key type can be used only if the SSH server for the operating system supports that key type.\n\n\n\nYou can create an RSA SSH key from the UI, but Ed25519 SSH keys must be imported.\n\n\n\n\n\n SSH key types: RSA and Ed25519 in the CLI \n\nIBM Cloud\u00ae Virtual Private Cloud supports two different types of public SSH keys.\n\n\n\n* RSA\n* Ed25519\n\n\n\nOn IBM Cloud VPC, RSA is the default SSH key type. You can select to change the key type to Ed25519. The Ed25519 SSH key type enables a slightly higher performance benefit because it can give the same level of security as the RSA SSH key type with a smaller key. You can create virtual server instances and bare metal servers with a mix of RSA and Ed25519 SSH keys.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-ssh-keys&interface=ui"},{"document_id":"ibmcld_13482-4606-6631","score":12.44581604,"text":"\nAdvanced index creation is an example for using all index types and it takes longer to finish.\n\n\n\n\n\n Assigning a base location for data skipping indexes \n\nIndexes are stored in Cloud Object Storage in a bucket of your choice. Before you start to create indexes, first configure the default location, called base location, for indexes created in your Data Engine instance. When you use Hive tables, you can also configure the index location per Hive table.\n\nTo assign your base location, use the following command:\n\nALTER METAINDEX SET LOCATION <path>\n\nThe following command includes a path:\n\nALTER METAINDEX SET LOCATION cos:\/\/us-south\/mybucket\/mypath\/\n\n\n\n\n\n Creating data skipping indexes \n\nWhen you create a data skipping index on a data set, decide which columns to index, and choose an index type for each column. Your choices depend on your workload and data. In general, index those columns that are queried the most in the WHERE clause. The three supported index types are MinMax, ValueList, and BloomFilter.\n\nThe following example creates a data skipping index on the metergen data set that uses three index types:\n\nCREATE METAINDEX\nMINMAX FOR temp,\nMINMAX FOR lat,\nMINMAX FOR lng,\nBLOOMFILTER FOR vid,\nVALUELIST FOR city\nON cos:\/\/us-geo\/sql\/metergen STORED AS parquet\n\nIn the [Cloud Object Storage URI](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceCOSURI), specify the top level (the root) of the data set.\n\nIt is possible to share indexes across Data Engine accounts. Users who have READ access to the base location of an index can use it by setting their base location. However, it is important to avoid multiple users who write indexes for the same data set to the same base location. Users can avoid sharing indexes by using different base locations.\n\nData Engine charges for index creation based on the amount of data scanned. Index creation for Parquet files benefits from the availability of schema information and the possibility of column projection to limit the amount of data scanned.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-index_management"},{"document_id":"ibmcld_16454-7-2142","score":12.3783226013,"text":"\nEstablishing a type system \n\nThe type system controls how content can be annotated.\n\n\n\n Type systems \n\nA type system defines things that are interesting in your domain content that you want to label with an annotation. The type system controls how content can be annotated by defining the types of entities that can be labeled and how relationships among different entities can be labeled. The model process manager typically works with subject matter experts for your domain to define the type system.\n\nIn Knowledge Studio, you can create a type system from scratch or upload an existing type system. To jump-start a workspace, you might want to upload a type system that was created for a similar domain. You can then edit the type system to add or remove entity types or redefine the relationship types.\n\nA sample type system based on the KLUE type system is provided for you to use with the Knowledge Studio tutorials. KLUE stands for Knowledge from Language Understanding and Extraction and was derived by IBM Research based on the analysis of collections of news articles. You can download a sample KLUE type system from [here ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/en-klue2-types.json).\n\nMany industries, such in domains like metallurgy, geology, market intelligence, life science, electronic health records, and oncology publish dictionaries or ontologies of domain-specific terminology. Consider referencing this type of resource to get an idea of the types of entities you might want to define in your own type system.\n\n\n\n Mentions \n\nA mention is any span of text that you consider relevant in your domain data. For example, in a type system about automotive vehicles, occurrences of terms like airbag, Ford Explorer, and child restraint system might be relevant mentions.\n\n\n\n\n\n Entity types \n\nAn entity type is how you categorize a real-world thing. An entity mention is an example of a thing of that type. For example, the mention President Obama can be annotated as a PERSON entity type.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystem"},{"document_id":"ibmcld_16273-4536-6382","score":12.2252349854,"text":"\nThe following table shows the possible customer response types and the parameter data type compatible with each.\n\n\n\nCompatible response types for parameters\n\n Customer response type Compatible data types Notes \n\n options string A selected option is always treated as a string, even if it is a numeric value. \n number number <br>integer A floating-point number passed as the value for an integer parameter might cause an error, depending on the behavior of the REST API. \n date string Dates are rendered as YYYY-MM-DD. \n time string Times are rendered as HH:MM:SS in 24-hour format, converted to the user's time zone. \n Currency number <br>integer \n Percent number <br>integer A percent value is passed as an integer (so 75% becomes 75). \n Free text string \n Regex string \n\n\n\n\n\n Arrays \n\nIn addition to the supported customer response types, a variable can also contain an array value. If you need to pass an array parameter to an operation, you must create an array session variable:\n\n\n\n1. Create a new session variable, either using Set variable values in the step editor or from the Variables > Created by you page. (For more information about how to create a session variable, see [Creating a session variable](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-manage-infocreate-session-variable).)\n2. In the Type field, select Any.\n3. In the Initial value field, click the Use expression toggle to enable it. Enter an expression that defines an array value (such as [\"New York\", \"London\", \"Tokyo\"], [123, 456, 789], or []).\n\n\n\nBecause this variable contains an array value, your actions can use expressions with array methods to access or modify the array values. For example, you might want to create a variable that initially contains an empty array ([]) and then use the add() method to build a list one element at a time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-call-extension"},{"document_id":"ibmcld_01308-2870-4686","score":12.1992263794,"text":"\nA user can also use the IAM token endpoint to log in and retrieve their IAM token, as shown in the following example: curl -s 'https:\/\/iam.cloud.ibm.com\/identity\/token?grant_type=urn:ibm:params:oauth:grant-type:apikey&response_type=cloud_iam&apikey=<apikey>' -H'Content-Type:x-www-form-urlencoded' -XPOST\n\nThis API example uses an IAM API key to request the IAM token and returns the Bearer <token>.\n\nThen, when a user calls a Watson IoT Platform API, they can provide the authorization header Authorization: Bearer <token> in their API calls.\n\n\n\n Generating an IAM token \n\nYou can choose how to automate the creation of the IAM token, depending on how you authenticate with IBM Cloud and the type of IBM Cloud ID that you use.\n\nIf you use an unfederated ID, you can choose one of the following options for creating an IAM token:\n\n\n\n* IBM Cloud user name and password: You can create a token to fully automate the creation of your IAM access token.\n* Generate an IBM Cloud API key: Use IBM Cloud API keys, which are dependent on the IBM Cloud account that they are generated for. You cannot combine your IBM Cloud API key with a different account ID in the same IAM token. To access clusters that were created with an account other than the one your IBM Cloud API key is based on, you must log in to the account to generate a new API key.\n\n\n\nIf you use a federated ID, you can choose one of the following options for creating an IAM token:\n\n\n\n* Generate an IBM Cloud API key: IBM Cloud API keys are dependent on the IBM Cloud account they are generated for. You cannot combine your IBM Cloud API key with a different account ID in the same IAM token. To access clusters that were created with an account other than the one your IBM Cloud API key is based on, you must log in to the account to generate a new API key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/IoT?topic=IoT-cloud_iam"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03043-7-2031","score":19.264465332,"text":"\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_16364-163116-165172","score":18.7963047028,"text":"\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time. No more passing context with each API call; the session state is managed for you as part of the assistant layer.\n\n\n\nWhat is presented in the tooling as a dialog skill is effectively a wrapper for a V1 workspace. There are currently no API methods for authoring skills and assistants with the V2 API. However, you can continue to use the V1 API for authoring workspaces.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03049-3966-5647","score":18.1073169708,"text":"\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Dialog Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific skill version, add it from the skill's Versions tab instead.\n\n\n\n\n\n\n\n Downloading a dialog skill \n\nYou can download a dialog skill in JSON format. You might want to download a skill if you want to use the same dialog skill in a different instance of the Watson Assistant service, for example. You can download it from one instance and import it to another instance as a new dialog skill.\n\nTo download a dialog skill, complete the following steps:\n\n\n\n1. Find the dialog skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_13042-15810-17906","score":17.9348697662,"text":"\nFor details about how to add a search skill response type, see [Adding a Search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/) blog post.\n* My response text is surrounded by brackets: If you notice that your response text is surrounded by brackets and quotation marks ([\"My response text\"]) when you test it from the Preview, for example, you might need to change the source field that you're using in the configuration. The unexpected formatting indicates that the value is stored in the source document as an array. Any field that you extract text from must contain a value with a String data type, not an Array data type. When the chat integration shows a response that is extracted from a field that stores the data as an array, it does a straight conversion of the array value into a string, which produces a response that includes the array syntax.\n\nFor example, maybe the field in the source document contains an array with a single text value as its only array element:\n\n\"title\": [\"a single array element\"]\n\nThe array value is converted by the Watson Assistant into this string value:\n\n\"title\": \"[\"a single array element\"]\"\n\nAs a result, the string is returned in this format in the chat; the surrounding brackets and quotation marks are displayed:\n\n[\"a single array element\"]\n\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03383-15783-17879","score":17.9348697662,"text":"\nFor details about how to add a search skill response type, see [Adding a Search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/) blog post.\n* My response text is surrounded by brackets: If you notice that your response text is surrounded by brackets and quotation marks ([\"My response text\"]) when you test it from the Preview, for example, you might need to change the source field that you're using in the configuration. The unexpected formatting indicates that the value is stored in the source document as an array. Any field that you extract text from must contain a value with a String data type, not an Array data type. When the chat integration shows a response that is extracted from a field that stores the data as an array, it does a straight conversion of the array value into a string, which produces a response that includes the array syntax.\n\nFor example, maybe the field in the source document contains an array with a single text value as its only array element:\n\n\"title\": [\"a single array element\"]\n\nThe array value is converted by the Watson Assistant into this string value:\n\n\"title\": \"[\"a single array element\"]\"\n\nAs a result, the string is returned in this format in the chat; the surrounding brackets and quotation marks are displayed:\n\n[\"a single array element\"]\n\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03054-7-2020","score":17.8210868835,"text":"\nCreating a search skill \n\nAn assistant uses a search skill to route complex customer inquiries to IBM Watson\u00ae Discovery for IBM Cloud Pak\u00ae for Data. Discovery treats the user input as a search query. It finds information that is relevant to the query from a configured data source and returns it to the assistant.\n\nAdd a search skill to your assistant to prevent the assistant from having to say things like, I'm sorry. I can't help you with that. Instead, the assistant can query existing company documents or data to see whether any useful information can be found and shared with the customer.\n\n![Shows a search result in the preview link integration](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search-skill-preview-link.png)\n\nYou must have Discovery for IBM Cloud Pak for Data installed and an instance provisioned before you can complete this procedure to create a search skill. The search skill can connect only to an existing Discovery for IBM Cloud Pak for Data instance.\n\nYour search skill can connect to a single Discovery project. The project can contain multiple collections.\n\nTo learn more about how search skill can benefit your business, [read this blog post](https:\/\/medium.com\/ibm-watson\/adding-search-to-watson-assistant-99e4e81839e5).\n\n\n\n How it works \n\nThe search skill searches for information from one or more data collections that you create by using Discovery for IBM Cloud Pak for Data.\n\nDiscovery for IBM Cloud Pak for Data crawls, converts, and normalizes your unstructured data. The product applies data analysis and cognitive intuition to enrich your data such that you can more easily find and retrieve meaningful information from it later. To read more about Discovery, see the [product documentation](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-about).\n\nTypically, the type of data collection you add to Discovery and access from your assistant contains information that is owned by your company.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03373-4-1923","score":17.8057613373,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding skills to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nConversational skills return responses that are authored by you to answer common questions, while a search skill searches for and returns passages from existing self-service content.\n\nYou can add the following types of skills to your assistant:\n\n\n\n* Conversational skills: Understand and address questions or requests that your customers typically ask about. You provide information about the subjects or tasks that your users need help with, and how they ask about them, and the product dynamically builds a machine learning model that is tailored to understand the same and similar user requests.\n\n\n\n* Actions skill : Offers a simple interface where anyone can build a conversational flow for your assistant to follow. The complex process of training data creation occurs behind the scenes automatically. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-actions-skill)\n* Dialog skill: Offers a set of editors that you use to define both your training data and the conversation. The conversation is represented as a dialog tree. You use the graphical dialog editor to create a script of sorts for your assistant to read from when it interacts with your customers. The dialog keys off the common customer goals that you teach it to recognize, and provides useful responses. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-dialog-skill)\n\n\n\nIf you can't decide which type of conversational skill to create, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n* Search skill!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_03054-19820-21851","score":17.6346263885,"text":"\nClick Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses any user input that it has a high confidence it can answer correctly. You can configure the dialog such that any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead. To do so, add a search skill response type to the Anything else node.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-disable).\n* If you want a specific search query to be triggered for specific questions, add a search skill response type to the appropriate dialog node. See [Responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia) for more details.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* Anything else node: Searches an external data source for a relevant answer when none of the dialog nodes can address the user's query.\n\nInstead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help: followed by the passage returned by the search. If a search skill is linked to your assistant, then whenever the anything_else node is triggered, rather than displaying the node response, you can set it up to trigger a search instead. The assistant passes the user input as the query to your search skill, and returns the search results as the response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03381-4347-6258","score":17.6340255737,"text":"\n2. Try again to upload the edited skill into the original service instance on the plan you want.\n\n\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one dialog skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add an actions or dialog skill.\n3. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific skill version, add it from the skill's Versions page instead.\n\n\n\n\n\n\n\n Sharing a dialog skill with team members \n\nAfter you create the service instance, you can give other people access to it. Together, you can define the training data and build the dialog.\n\nOnly one person can edit an intent, entity, or a dialog node at a time. If multiple people work on the same item at the same time, then the changes made by the person who saves their changes last are the only changes applied. Changes that are made during the same time frame by someone else and are saved first are not retained. Coordinate the updates that you plan to make with your team members to prevent anyone from losing their work.\n\nTo share a dialog skill with other people, you must give them access to the service instance that hosts the skill. Note that the person you invite will be able to access any skill or assistant in this service instance.\n\n\n\n1. Click the User ![User](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/user-icon2.png) icon in the page header.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add"},{"document_id":"ibmcld_02838-1394-3297","score":17.5850448608,"text":"\n* Add Dialog Skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific dialog skill version, add it from the skill's Versions page instead.\n* Add Search Skill: For a given user query, uses the IBM Watson\u00ae Discovery service to retrieve information from a data source that you identify and shares any relevant information that it finds as the response to the user.\n\nYou must have Discovery for IBM Cloud Pak for Data installed, and an instance provisioned before you can complete the steps to create a search skill.\n\n\n\nSee [Creating a skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add).\n\n\n\n\n\n Assistant limits \n\n\n\nLimit details\n\n Assistants per service instance \n\n 100 \n\n\n\nFor information about the inactivity timeout limit, see [Changing the inactivity timeout setting](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-settings).\n\nYou can connect one skill of each type to your assistant.\n\n\n\n\n\n Deleting an assistant \n\nWhen you delete an assistant, any skills that you added to the assistant are not deleted.\n\nTo delete an assistant, follow these steps:\n\n\n\n1. From the Assistants tab, find the assistant that you want to delete.\n2. Click the ![open and close list of options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob-beta.png) icon, and then choose Delete. Confirm the deletion.\n\n\n\n\n\n\n\n Renaming an assistant \n\nYou can change the name of an assistant and its associated description after you create the assistant.\n\nTo rename an assistant, follow these steps:\n\n\n\n1. From the Assistants tab, find the assistant that you want to rename.\n2. Click the !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03054-7-2020","score":17.7742576599,"text":"\nCreating a search skill \n\nAn assistant uses a search skill to route complex customer inquiries to IBM Watson\u00ae Discovery for IBM Cloud Pak\u00ae for Data. Discovery treats the user input as a search query. It finds information that is relevant to the query from a configured data source and returns it to the assistant.\n\nAdd a search skill to your assistant to prevent the assistant from having to say things like, I'm sorry. I can't help you with that. Instead, the assistant can query existing company documents or data to see whether any useful information can be found and shared with the customer.\n\n![Shows a search result in the preview link integration](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/search-skill-preview-link.png)\n\nYou must have Discovery for IBM Cloud Pak for Data installed and an instance provisioned before you can complete this procedure to create a search skill. The search skill can connect only to an existing Discovery for IBM Cloud Pak for Data instance.\n\nYour search skill can connect to a single Discovery project. The project can contain multiple collections.\n\nTo learn more about how search skill can benefit your business, [read this blog post](https:\/\/medium.com\/ibm-watson\/adding-search-to-watson-assistant-99e4e81839e5).\n\n\n\n How it works \n\nThe search skill searches for information from one or more data collections that you create by using Discovery for IBM Cloud Pak for Data.\n\nDiscovery for IBM Cloud Pak for Data crawls, converts, and normalizes your unstructured data. The product applies data analysis and cognitive intuition to enrich your data such that you can more easily find and retrieve meaningful information from it later. To read more about Discovery, see the [product documentation](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-about).\n\nTypically, the type of data collection you add to Discovery and access from your assistant contains information that is owned by your company.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03054-28651-29202","score":16.8767414093,"text":"\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2. Open the Search Skill page, and then click to switch the toggle to Disabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_13042-23866-24405","score":16.8429737091,"text":"\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2. Open the Search skill page, and then set the switch to Disabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03383-23830-24369","score":16.8429737091,"text":"\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2. Open the Search skill page, and then set the switch to Disabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03373-5718-7567","score":16.7532615662,"text":"\n[Diagram of a more complex implementation that uses intent, entity, and dialog.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/complex-impl.png)\n\nAs you add information, the skill uses this unique data to build a machine learning model that can recognize these and similar user inputs. Each time you add or change the training data, the training process is triggered to ensure that the underlying model stays up-to-date as your customer needs and the topics they want to discuss change.\n\n\n\n\n\n Search skill ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) \n\nWhen Watson Assistant doesn't have an explicit solution to a problem, it routes the user question to a search skill to find an answer from across your disparate sources of self-service content. The search skill interacts with the IBM Watson\u00ae Discovery service to extract this information from a configured data collection.\n\nIf you already use the Discovery service, you can mine your existing data collections for source material that you can share with customers to address their questions.\n\nHowever, you do not need to have a Discovery service instance. If you choose to create a search skill, a free instance of Discovery is provisioned for you. You can then create a collection from a data source and configure your search skill to search this collection for answers to customer queries.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question gets routed to the search skill.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_03054-22692-24767","score":16.5258560181,"text":"\n* Search response type: If you add a search skill response type to a dialog node, then your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed.\n\nThis approach is useful if you want to narrow down a user query before you trigger a search. For example, the dialog branch might collect information about the type of device the customer wants to buy. When you know the make and model, you can then send a model keyword in the query that is submitted to the search skill, and get better results.\n* Search skill only: If only a search skill is linked to an assistant, and no dialog skill is linked to the assistant, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Try it out pane of the search skill.\n\nYou cannot test the full end-to-end user experience from the dialog skill's Try it out pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its Try it out pane.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, you must test it by using the API.\n\n\n\n1. From the IBM Cloud Pak for Data web client, go to the details page for the provisioned instance.\n2. Copy the URL from the \"Access information\" section of the page. You will specify this value as the {url}.\n3. Copy the bearer token also. You will need to pass the token when you make an API call.\n4. From the dialog builder in the user interface, add a search skill response type to a dialog node.\n5. Make a note of the unique ID of the assistant to which you added the dialog that you edited in the previous step.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03054-19820-21851","score":16.4391365051,"text":"\nClick Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses any user input that it has a high confidence it can answer correctly. You can configure the dialog such that any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead. To do so, add a search skill response type to the Anything else node.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-disable).\n* If you want a specific search query to be triggered for specific questions, add a search skill response type to the appropriate dialog node. See [Responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia) for more details.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* Anything else node: Searches an external data source for a relevant answer when none of the dialog nodes can address the user's query.\n\nInstead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help: followed by the passage returned by the search. If a search skill is linked to your assistant, then whenever the anything_else node is triggered, rather than displaying the node response, you can set it up to trigger a search instead. The assistant passes the user input as the query to your search skill, and returns the search results as the response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03196-46002-48092","score":16.3701477051,"text":"\nYou can trigger a search of the existing material in real time to get the latest and most up-to-date answer for your customers.\n\nTo use the search skill response type, you must create a search skill and add it to the same assistant that uses this dialog skill. For more information, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add).\n\nTo add a Search skill response type, complete the following steps:\n\n\n\n1. From the dialog node where you want to add the response type, click the dropdown menu in the Assistant responds field, and then choose Search skill.\n\nIndicates that you want to search an external data source for a relevant response.\n2. To edit the search query to pass to the Discovery service, click Customize, and then fill in the following fields:\n\n\n\n* Query: Optional. You can specify a specific query in natural language to pass to Discovery. If you do not add a query, then the customer's exact input text is passed as the query.\n\nFor example, you can specify What cities do you fly to?. This query value is passed to Discovery as a search query. Discovery uses natural language understanding to understand the query and to find an answer or relevant information about the subject in the data collection that is configured for the search skill.\n\nYou can include specific information provided by the user by referencing entities that were detected in the user's input as part of the query. For example, Tell me about @product. Or you can reference a context variable, such as Do you have flights to $destination?. Just be sure to design your dialog such that the search is not triggered unless any entities or context variables that you reference in the query have been set to valid values.\n\nThis field is equivalent to the Discovery natural_language_query parameter. For more information, see [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersnlq).\n\n\n\n* Filter: Optional. Specify a text string that defines information that must be present in any of the search results that are returned.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_03383-20671-22804","score":16.1319217682,"text":"\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-20707-22840","score":16.1319217682,"text":"\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.4584607388}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-2884-4620","score":14.3845176697,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7-1802","score":13.6862592697,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02689-1748-4183","score":13.5363483429,"text":"\nWithin your application, the isEnabled() method of the App Configuration SDK is used to activate conditional blocks of code to turn features on and off based on the state of a feature flag. Use feature flags to dark launch features into production and then switch them on only for selected users or roll them out to your users selectively and independently from deployments. Each feature flag must belong to a collection.\n\n\n\n\n\n Properties \n\nProperties are configuration parameters that don't change often, but that still need centralized management. Consolidate properties for all your app and environment components into one central cloud dashboard, with App Configuration, thus avoiding the hassle of managing multiple parameter files. Within your application, the getCurrentValue() method of the App Configuration SDK is used to access the current value of a property. Each property must belong to a collection.\n\n\n\n\n\n Segments \n\nUsing App Configuration, a single feature flag, or property, can have many values, with each value applied to a specific group of entities (users, devices, infrastructure components). Each group is called a segment. Members of a segment share one or more common attributes as defined by a set of segment rules. Segments are optional.\n\n\n\n\n\n Attribute \n\nAn attribute is a parameter that is used to define a segment. Attributes are used to create segment rules on the App Configuration dashboard, but names of the attributes and values of each attribute are defined in your code. At run time, the App Configuration SDK fetches the segment rules into your application instance and determine whether it is a part of the segment.\n\n\n\n\n\n Targeting definition \n\nFeature flags and properties are targeted to segments based on a set of rules that are called the targeting definition. With targeting, you can override the default value for a flag or property, for any segment you define.\n\n\n\n\n\n App Configuration SDK \n\nThe App Configuration SDK handles the automatic delivery of the appropriate flag state or property value into your application. It connects to the endpoints provided by the App Configuration API, fetches collections, and evaluates segment and targeting rules. Server-side SDKs connect to the App Configuration service through a web socket for real-time updates. Client-side SDKs pull values from the App Configuration service upon a lifecycle change such being opened or brought to the foreground.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-overview"},{"document_id":"ibmcld_12330-7-2140","score":12.6650104523,"text":"\nContent \n\n\n\n Languages \/ platforms \n\nEvery IBM Service that offers public APIs SHOULD offer SDKs for the languages \/ platforms most commonly used by developers that use the service.\n\n\n\n* Java, Node, Python, and Go are \"first-tier\" languages that should have SDK support.\n* iOS and Android SDKs are important for services that may be used from mobile devices.\n* Other languages that may warrant SDK support in particular domains are C#, Ruby, Scala.\n\n\n\n\n\n\n\n Basic interface \n\nThe SDK SHOULD provide a basic interface that maps directly onto the operations of the underlying API. Each method of an SDK SHOULD correspond to exactly one operation of the underlying API, and this relationship should be clear from design of the API.\n\nOperations whose functionality is fully supported by a related operation SHOULD be omitted. This can occur, for example, when an operation is exposed with both a GET and an POST method, where the GET offers a subset of the features of the POST but with a simpler interface.\n\n\n\n\n\n Methods \n\nMethods MUST employ a flexible parameter-passing design that allows optional parameters to be added to a method without causing incompatibility with applications using the prior version of the method.\n\nIn some languages this can be accomplished using standard language features like default parameter values, but in other languages (e.g. Java) the method parameters must be encapsulated into an \"options\" object.\n\n\n\n\n\n Streaming \n\nFor a language\/runtime that supports stream value types:\n\n\n\n* The SDK SHOULD allow any potentially large input value to a method to be supplied as a stream.\n* The SDK SHOULD allow the result of a method to be returned as a stream if that value may be large.\n\n\n\n\n\n\n\n Asynchronous method calls \n\nThe SDK MUST support asynchronous invocation of any method that performs a network operation. The SDK SHOULD support synchronous or pseudo-synchronous (e.g. async\/await) invocation of methods that perform network operation in languages where this method style is idiomatic.\n\n\n\n\n\n Instrumentation \n\nThe SDK SHOULD be instrumented so that relevant usage data can be collected by the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-content"},{"document_id":"ibmcld_10817-6582-8092","score":12.3522853851,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_13429-166159-168045","score":12.1597032547,"text":"\nNew UK English and Arabic models\n: The service supports more languages with its transcription models: en-UK_BroadbandModel and en-UK_NarrowbandModel for UK English, and ar-AR_BroadbandModel for Modern Standard Arabic. For more information, see [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models).\n\nNew session_closed field for session-based methods\n: In the JSON responses that it returns for errors with session-based methods, the service now also includes a new session_closed field. The field is set to true if the session is closed as a result of the error. For more information about possible return codes for any method, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nHTTP platform timeout no longer applies\n: HTTP recognition requests are no longer subject to a 10-minute platform timeout. The service now keeps the connection alive by sending a space character in the response JSON object every 20 seconds as long as recognition is ongoing. For more information, see [Timeouts](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtimeouts).\n\nRate limiting with curl command no longer needed\n: When you use the curl command to transcribe audio with the service, you no longer need to use the --limit-rate option to transfer data at a rate no faster than 40,000 bytes per second.\n\nChanges to HTTP error codes\n: The service no longer returns HTTP status code 490 for the session-based HTTP methods GET \/v1\/sessions\/{session_id}\/observe_result and POST \/v1\/sessions\/{session_id}\/recognize. The service now responds with HTTP status code 400 instead.\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile SDKs are available for the speech services. The SDKs enable mobile applications to interact with both the Speech to Text and Text to Speech services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_02674-7-1766","score":12.1323633194,"text":"\nApp Configuration server SDK for Go \n\nApp Configuration service provides SDK to integrate with your Golang web and mobile applications, microservices, and distributed environments.\n\n\n\n Prerequisites \n\nFollowing is the prerequisite for using App Configuration service SDK for Go:\n\n\n\n* Go version 1.16 or later\n\n\n\n\n\n\n\n Integrating server SDK for Go \n\nThe v1.x.x versions of the App Configuration Go SDK have been retracted.\n\nApp Configuration service provides SDK to integrate with your Golang web and mobile applications, microservices, and distributed environments. You can evaluate the values of your property and feature flag by integrating the App Configuration SDK.\n\n\n\n1. Install the SDK by using the following code from the git repository.\n\ngo get -u github.com\/IBM\/appconfiguration-go-sdk@latest\n2. In your Golang microservice or application, include the SDK module with:\n\nimport (\nAppConfiguration \"github.com\/IBM\/appconfiguration-go-sdk\/lib\"\n)\n\nRun go mod tidy to download and install the new dependency and update your Go application's go.mod file.\n3. Initialize the SDK to connect with your App Configuration service instance.\n\ncollectionId := \"airlines-webapp\"\nenvironmentId := \"dev\"\n\nappConfiguration = AppConfiguration.GetInstance()\nappConfiguration.Init(\"region\", \"guid\", \"apikey\")\nappConfiguration.SetContext(\"collectionId\", \"environmentId\")\n\nWhere,\n\n\n\n* region: Region name where the service instance is created. Use AppConfiguration.REGION_US_SOUTH for Dallas, AppConfiguration.REGION_US_EAST for Washington DC, AppConfiguration.REGION_EU_GB for London, and AppConfiguration.REGION_AU_SYD for Sydney.\n* guid: Instance ID of the App Configuration service. Get it from the service credentials section of the App Configuration service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-golang"},{"document_id":"ibmcld_02698-7-1759","score":11.9423389435,"text":"\nIntegrating SDKs \n\nThe App Configuration client SDK is available for Android, JavaScript, and React, the server SDKs for Node, Python, Go, and Java, and the admin SDK for Go, to integrate with your web and mobile applications, microservices, and distributed environments.\n\n\n\n Client-side and Server-side SDKs \n\nUnderstand the differences between the various SDKs so that you can decide between SDK types for your use case.\n\n\n\n Types of SDKs \n\nSDKs supported by App Configuration include:\n\n\n\n* Server-side SDK\n* Client-side SDK\n* Admin SDK\n\n\n\nSDKs that help evaluate feature flag and property values are broadly classified as Server-side or Client-side - based on the deployment environment. These SDKs can be integrated into your application to assess the feature or property values by considering segment targeting rules, if any.\n\nEvaluation SDKs fetch the latest configuration data from the App Configuration service and ensure that any change in the service configuration is made available to your application in real time.\n\nAdmin SDKs can be used to create and manage configurations for Environments, Collections, Feature flags, Properties, and Segments. As an option to IBM Cloud Dashboard or IBM Cloud CLI, Admin SDKs can be used to programmatically manage your service configuration from within your application.\n\nThe currently available Go language Admin SDK integrates with your Go application.\n\nDifferences between client-side and server-side SDKs:\n\n\n\nTable 1. List of App Configuration server, client, and admin SDKs\n\n SDK type Details Links to SDKs and integration docs \n\n Server side These SDKs are designed for multi-user systems and are intended to be used in a trusted environment, such as inside a corporate network or on a web server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-sdks"},{"document_id":"ibmcld_10805-1522-3235","score":11.8576564789,"text":"\nTo control inbound traffic, you might want to grant access to other users such as assigning Reader role to invoke actions. \n API key An API Key for the service ID that can be used to generate IAM tokens. You can use the tokens to authenticate the namespace with other IBM Cloud services. The API key is provided to actions as the environment variable __OW_IAM_NAMESPACE_API_KEY. \n\n\n\nYou can view a list of your service IDs by running the following command.\n\nibmcloud iam service-ids\n\nYou can view the API keys that are associated with a service ID by running the following command.\n\nibmcloud iam service-api-keys <ServiceID-12345678-1234-abcd-1234-123456789abc>\n\nDo not delete service IDs or API keys.\n\n\n\n\n\n Are there any limitations for namespaces? \n\nThe [mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk) is not supported for IAM-managed namespaces.\n\nThe names of all entities, including actions, triggers, rules, packages, and namespaces, are a sequence of characters that follow the following format:\n\n\n\n* The first character must be an alphanumeric character, or an underscore.\n* The subsequent characters can be alphanumeric, spaces, or any of the following values: _, @, ., -.\n* The last character can't be a space.\n\n\n\n\n\n\n\n What do I do if I have a Cloud Foundry-based namespace? \n\nYour Cloud Foundry-based namespaces still work. However, to take advantage of new features, you must create an IAM-enabled namespace.\n\n\n\n\n\n How do I see a list of my Cloud Functions namespaces? \n\nYou can see a list of your Cloud Functions namespaces by running the [namespace list](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_namespace_list) command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespaces"},{"document_id":"ibmcld_10820-21590-23317","score":11.7865819931,"text":"\n* For batch requests, each object change is handled individually and the trigger is fired for each successful change event.\n* All characters are permitted in an object key except for ASCII control character NUL.\n* Naming limitations for Cloud Functions triggers can be found on the [System details and limits](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-limitslimits_fullnames) page.\n\n\n\n\n\n\n\n\n\n\n\n Configuring the IBM Cloud Object Storage package \n\nAfter you have [created an IBM Cloud Object Storage service instance](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-gs-devgs-dev-provision) and [created at least one bucket](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storagegs-create-buckets), you can install the IBM Cloud Object Storage package into your namespace to work with your buckets and objects.\n\nThe installable IBM Cloud Object Storage package deploys a set of pre-built actions that you can use to work with your IBM Cloud Object Storage buckets and objects. These actions are executed in either Node.js or Python. You can select a runtime when you install the package. If you want to use a different runtime, you can use the [COS SDK](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-sdk-gs). You can also [build your own actions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-actions) or [web actions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-actions_web) to respond to the trigger.\n\nFor a list of the actions in the cloud-object-storage package, see [Available entities](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_actions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorage"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":13.5122509003,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-1426-3052","score":13.1143341064,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_04518-7-1743","score":12.1081781387,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_07551-15747-17355","score":11.4850006104,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_12332-1034-2510","score":11.1939888,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10852-44214-45420","score":11.0552206039,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_07551-14062-16080","score":10.8561124802,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10817-7-1802","score":9.5898551941,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-43319-44485","score":8.7814922333,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_16487-18882-19788","score":6.6284594536,"text":"\nGround truth is then used for training and testing a machine learning model, or it can be used as the basis for the next iteration of model development. To use ground truth in a new iteration, you must create a new annotation task.\n\n![This figure illustrates how annotations added by two human annotators become ground truth. One document, labeled document 2, is annotated by both human annotators. The annotations in this overlapping document must be adjudicated before they become ground truth.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks_datatruth.svg) Figure 3. This figure illustrates how annotations added by two human annotators become ground truth. One document, labeled document 2, is annotated by both human annotators. The annotations in this overlapping document must be adjudicated before they become ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.703918089,"ndcg_cut_10":0.8519590445}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10852-44214-45420","score":17.351064682,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_04518-1426-3052","score":15.1928806305,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-1342-3184","score":14.6321439743,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-15747-17355","score":14.3945665359,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_04518-7-1743","score":13.7407398224,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_12332-1034-2510","score":13.7274045944,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10852-43319-44485","score":11.8394937515,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_07551-14062-16080","score":11.73503685,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_05513-1226-2148","score":10.7384643555,"text":"\nWhen the embedding application provides a data source module specification, then the calling application provides a module to Cognos Dashboard Embedded, for exampling with the methods addSources() or updateModuleDefinitions(), then you can choose to provide any of the following fields in an encrypted form:\n\n\n\n* user\n* password\n* schema\n* jdbcUrl\n* sourceUrl\n* value of a header property for CSV urls\n\n\n\nBefore sending the module, your application uses the public key to encrypt the sensitive fields of the module.\n\nIf you have a string to encrypt that is longer than 245 bytes, then do the following steps:\n\n\n\n1. Divide the string that you want to encrypt in parts that are a maximum of 245 bytes.\n2. Encrypt the parts from step 1 and make sure the are base64 encoded.\n3. Concatenate the encode parts from step 2 with the colon \":\" character.\n4. Use the value from step 3 in the encrypted field.\n\n\n\nExample of a JDBCurl:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-encryptingdatasourceinformation"},{"document_id":"ibmcld_05433-15225-16568","score":10.2920389175,"text":"\n* If you are starting with source code that resides on a local workstation, you can choose to let Code Engine take care of building the image from your source and creating the job with a single CLI command. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating your job from local source code with the CLI](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-job-local-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n\n\n\nFor example, you might choose to let Code Engine handle the build of your local source while you evolve the development of your source for the job. Then, after the image is matured, you can update the job to reference the specific image that you want. You can repeat this process as needed.\n\nWhen you run your updated job, the latest version of your referenced container image is used for the job run, unless a tag is specified for the image. If a tag is specified for the image, then the tagged image is used for the job run.\n\n\n\nLooking for more code examples? Check out the [Samples for IBM Cloud Code Engine GitHub repo](https:\/\/github.com\/IBM\/CodeEngine).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-run-job-source-code"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":20.8769245148,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_11133-3534-5483","score":19.7087173462,"text":"\nApplicable Additional SDs for any service ordered using your IBM Cloud account are available at [https:\/\/www.ibm.com\/terms\/?id=i126-6605](https:\/\/www.ibm.com\/terms\/?id=i126-6605) . The additional SDs contain links to the applicable Data Sheet for each service.\n\n\n\n\n\n Exchange Rate Policy \n\nEffective 1 February 2023, IBM Cloud will adjust the exchange rates used to provide pricing in non-US dollar currencies on a monthly basis. Charges for cloud services are based on US dollars. Non-US dollar pricing is calculated by converting the US dollar rate by using market exchange rates published by leading financial institutions. Market exchange rates will be adjusted monthly, except as prohibited or controlled by applicable law.\n\nIBM uses leading financial institution benchmark rates set at the end of the month to go into effect for consumption starting the first day of the next month. The corresponding invoice will be sent 30 days later. For example, IBM will set the exchange rate at the end of January effective for consumption in February. Customers will see the impact of the new rates in their March invoice.\n\n\n\n\n\n IBM Business Associate Addendum \n\nIf you or your company is a covered entity as defined by the US Health Insurance Portability and Accountability Act (HIPAA) and intend to order Cloud Services that might process protected health information (PHI), you must accept the IBM\u00ae Business Associate Addendum (BAA) available at [https:\/\/www-03.ibm.com\/software\/sla\/sladb.nsf\/sla\/baa?OpenDocument](https:\/\/www-03.ibm.com\/software\/sla\/sladb.nsf\/sla\/baa?OpenDocument). The BAA can be digitally accepted as described in [Enabling the HIPAA Supported setting](https:\/\/cloud.ibm.com\/docs\/account?topic=account-enabling-hipaa).\n\n\n\n\n\n Legal contact information \n\nFor subpoenas or for reporting abuse on IBM Cloud, contact the following:\n\nIBM Cloud c\/o SoftLayer Inc.\n14001 North Dallas Parkway, Suite M100\nDallas, TX 75240\n214.442.0600 Main","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms"},{"document_id":"ibmcld_10805-1522-3235","score":19.077796936,"text":"\nTo control inbound traffic, you might want to grant access to other users such as assigning Reader role to invoke actions. \n API key An API Key for the service ID that can be used to generate IAM tokens. You can use the tokens to authenticate the namespace with other IBM Cloud services. The API key is provided to actions as the environment variable __OW_IAM_NAMESPACE_API_KEY. \n\n\n\nYou can view a list of your service IDs by running the following command.\n\nibmcloud iam service-ids\n\nYou can view the API keys that are associated with a service ID by running the following command.\n\nibmcloud iam service-api-keys <ServiceID-12345678-1234-abcd-1234-123456789abc>\n\nDo not delete service IDs or API keys.\n\n\n\n\n\n Are there any limitations for namespaces? \n\nThe [mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk) is not supported for IAM-managed namespaces.\n\nThe names of all entities, including actions, triggers, rules, packages, and namespaces, are a sequence of characters that follow the following format:\n\n\n\n* The first character must be an alphanumeric character, or an underscore.\n* The subsequent characters can be alphanumeric, spaces, or any of the following values: _, @, ., -.\n* The last character can't be a space.\n\n\n\n\n\n\n\n What do I do if I have a Cloud Foundry-based namespace? \n\nYour Cloud Foundry-based namespaces still work. However, to take advantage of new features, you must create an IAM-enabled namespace.\n\n\n\n\n\n How do I see a list of my Cloud Functions namespaces? \n\nYou can see a list of your Cloud Functions namespaces by running the [namespace list](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_namespace_list) command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespaces"},{"document_id":"ibmcld_02731-4670-6607","score":18.8910655975,"text":"\n: Server SDK: You can protect your back-end resources that are hosted on IBM Cloud and your web apps by using the server SDK. It extracts the access token from a request and validates it with App ID. Client SDK: You can protect your mobile apps with the Android or iOS client SDK. The client SDK communicates with your cloud resources to start the authentication process when it detects an authorization challenge.\n\nIBM Cloud\n: App ID: After successful authentication, App ID returns access and identity tokens to your app. Cloud Directory: Users can sign up for your service with their email and a password. You can then manage your users in a list view through the UI. With Cloud Directory, App ID functions as your identity provider.\n\nExternal (third party)\n: Social and enterprise identity providers: App ID supports Facebook, Google+, and SAML 2.0 Federation as identity provider options. The service arranges a redirect to the identity provider and verifies the returned authentication tokens. If the tokens are valid, the service grants access to your app.\n\n\n\n\n\n Integrations \n\nYou can use App ID with other IBM Cloud offerings.\n\nKubernetes Service\n: By configuring Ingress in a standard cluster you can secure your apps at the cluster level. Check out the [App ID authentication Ingress annotation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-comm-ingress-annotationsapp-id-authentication) or the [Announcing App ID integration to IBM Cloud Kubernetes Service](https:\/\/www.ibm.com\/cloud\/blog\/announcing-app-id-integration-ibm-cloud-kubernetes-service) blog post to get started.\n\nCloud Functions and API Connect\n: When you create your APIs with [Cloud Functions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-getting-started) and [API Connect](https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-getting-started), you can secure your applications at the gateway rather than in your app code.\n\nActivity Tracker","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-about"},{"document_id":"ibmcld_13067-1715-3771","score":18.0209064484,"text":"\nIBM Cloud\u00ae services are connected to a three-tiered network, segmenting public, private, and management traffic.\n\n\n\n* Private endpoints are available for most requests originating from within IBM Cloud. Private endpoints provide better performance and do not incur charges for any outgoing or incoming bandwidth even if the traffic is cross regions or across data centers. Whenever possible, it is best to use a private endpoint.\n* Public endpoints can accept requests from anywhere and charges are assessed on outgoing bandwidth. Incoming bandwidth is free. Public endpoints should be used for access not originating from an IBM Cloud cloud computing resource.\n* Direct endpoints are used in Bring-Your-Own-IP scenarios, generally for requests originating from [resources within VPCs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc). Like Private endpoints, Direct endpoints provide better performance over Public endpoints and do not incur charges for any outgoing or incoming bandwidth even if the traffic is cross regions or across data centers. Directions for connecting to IBM Cloud Object Storage from VPC are available [here](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-connecting-vpc-cos).\n\n\n\nRequests must be sent to the endpoint associated with a given bucket's location. If you aren't sure where a bucket is located, there is an [extension to the bucket listing API](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/api-reference?topic=cloud-object-storage-compatibility-api-bucket-operationscompatibility-api-list-buckets-extended) that returns the location and storage class information for all buckets in a service instance.\n\nWhen using Virtual Private Endpoints in an application that makes requests to IBM COS, it may be necessary to add some additional configuration for authentication. The IBM COS SDKs will automatically attempt to fetch an IAM token from https:\/\/iam.cloud.ibm.com\/identity\/token. If you are using a virtualized endpoint for token acquisition you will need alter the IAM endpoint appropriately.\n\n\n\n\n\n Regional Endpoints","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage?topic=cloud-object-storage-endpoints"},{"document_id":"ibmcld_10725-7-1914","score":17.9255867004,"text":"\nHow Cloud Functions works \n\nIBM Cloud\u00ae Functions service is an event-driven compute platform, also referred to as Serverless computing, or as Function as a Service (FaaS), that runs code in response to events or direct invocations.\n\n\n\n Cloud Functions terminology \n\nLearn the basic concepts of the technology behind Cloud Functions. Then, test your knowledge and [!take a quiz](https:\/\/quizzes.12dekrh4l1b4.us-south.codeengine.appdomain.cloud\/functions\/terms_quiz\/quiz.php)\n\n\n\nTable 1. Cloud Functions Terms\n\n Term Description \n\n Namespace [Namespaces](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespaces) contain Cloud Functions entities, such as actions and triggers, and belong to a resource group. You can let users access your Cloud Functions entities by granting them access to the namespace. \n Action An [action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-actions) is a piece of code that performs one specific task. An action can be written in the language of your choice, such as small snippets of JavaScript or Swift code or custom binary code embedded in a Docker container. You provide your action to Cloud Functions either as source code or a Docker image. An action performs work when it is directly invoked by using the Cloud Functions API, CLI, or iOS SDK. An action can also automatically respond to events from IBM Cloud services and third-party services by using a trigger. \n Sequence A set of actions can be chained together into a [sequence](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sequences) without having to write any code. A sequence is a chain of actions, invoked in order, where the output of one action is passed as input to the next action. By creating a sequence, you can combine existing actions together for quick and easy reuse. A sequence can then be invoked just like an action, through a REST API or automatically in response to events.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-about"},{"document_id":"ibmcld_11133-1287-2850","score":17.6433734894,"text":"\nApplicable Additional SDs for any service ordered using your IBM Cloud account are available at [https:\/\/www.ibm.com\/terms\/?id=i126-6605](https:\/\/www.ibm.com\/terms\/?id=i126-6605). The additional SDs contain links to the applicable Data Sheet for each service.\n\n\n\n\n\n All other accounts \n\nAs of 10 December 2020, this section describes the Terms of Use for the following types of IBM Cloud accounts:\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n* New and existing contracts for IBM Global Technology Services and Cloud Services\n* New and existing Lite accounts worldwide\n\n\n\nYour IBM Cloud account and any services that are ordered from the IBM Cloud are provided under the terms of the Service Description for IBM Cloud available at [https:\/\/www.ibm.com\/terms\/?id=i126-6605](https:\/\/www.ibm.com\/terms\/?id=i126-6605) and one of the following base agreements:\n\n\n\n* IBM Cloud Services Agreement (local country version*) for Lite accounts, non-US Dollar credit card billing, or if you select invoicing from IBM, available at [https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/) (select your country);\n* SoftLayer Cloud Service Agreement for US Dollar credit card billing, available at\n\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=softlayer#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=softlayerdetail-document)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms"},{"document_id":"ibmcld_11133-2322-4015","score":17.5318050385,"text":"\n* IBM Cloud Services Agreement (local country version*) for Lite accounts, non-US Dollar credit card billing, or if you select invoicing from IBM, available at [https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/) (select your country);\n* SoftLayer Cloud Service Agreement for US Dollar credit card billing, available at\n\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=softlayer#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=softlayerdetail-document)\n* IBM Passport Advantage Agreement you accepted upon registration and the General Terms for Cloud Offerings TOU for IBM Passport Advantage Clients, available at [http:\/\/www.ibm.com\/terms\/?id=i126-5948](http:\/\/www.ibm.com\/terms\/?id=i126-5948) ; or\n* Cloud Trial Agreement for Proof of Concept (POC) Accounts available at [http:\/\/www.ibm.com\/terms\/?id=i126-5948](http:\/\/www.ibm.com\/terms\/?id=i126-5948) ; POC accounts may be provided for assessment of specific services, solutions or both. Use of services beyond the intended scope of POC might be possible, but might be subjected to additional charges.\n* An equivalent cloud service base agreement terms signed between you and IBM\n\n\n\nApplicable Additional SDs for any service ordered using your IBM Cloud account are available at [https:\/\/www.ibm.com\/terms\/?id=i126-6605](https:\/\/www.ibm.com\/terms\/?id=i126-6605) . The additional SDs contain links to the applicable Data Sheet for each service.\n\n\n\n\n\n Exchange Rate Policy \n\nEffective 1 February 2023, IBM Cloud will adjust the exchange rates used to provide pricing in non-US dollar currencies on a monthly basis. Charges for cloud services are based on US dollars.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms"},{"document_id":"ibmcld_10766-7-2062","score":17.4391345978,"text":"\nError handing for Cloud Functions \n\nIBM Cloud\u00ae Functions provides error handling through the execution status of each function invocation. Error handling is provided by Cloud Functions for invocations that are exposed through the Cloud Functions API, SDK, CLI, or the console. For more information about the various error types, see [Action executions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-limitslimits_exec).\n\nIn addition, the Cloud Functions service automatically reports errors to the Monitoring service. You can set up the built-in integration for the Monitoring service with the IBM Cloud\u00ae Functions service to automatically react to error messages. For more information about setting up an alert through a subsequent action invocation, see [IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-alerts-notify).\n\nTo handle errors, choose one of the following options.\n\n\n\n1. Handle application errors programmatically within the action implementation itself and handle service errors through the Cloud Functions service API, CLI, SDK, or console by leveraging the automatically set Cloud Functions execution status.\n2. Use the built-in integration with the IBM Cloud Monitoring service to define a subsequent action to be invoked in response to the error. All configuration and execution occurs service-side. For more information, see [IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-notifications) and [Monitoring Cloud Functions entities with IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-monitor-functions).\n3. Handle errors programmatically by including the Composer library within the action implementation. By using the library, you can chain together a sequence of actions or define other types of control-flow logic. When you use this library, all execution of the [error-handling code occurs service-side](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_composererror-handling) and there are no additional components that you must manage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-error-handing-functions"},{"document_id":"ibmcld_07532-7-2311","score":17.4376716614,"text":"\nPush notifications \n\nEvent Notifications provides a push notification service for sending transactional and informational event notifications to mobile devices.\n\n\n\n Adding a push service destination \n\nAdd an IBM Cloud push notification destination to your instance of Event Notifications by clicking Add in the Destinations view of the Event Notifications dashboard. After a new push destination is created, you see an entry IBM Cloud push service in the Destination list. You must configure your push destination by adding credentials for Apple Push Notification Service (APNS) or Firebase Cloud Messaging (FCM).\n\nEach application and platform requires a separate push destination.\n\nYou can use Pre-production destination, as low-cost push destination, for your development and test environments. You can change the Pre-production destination to Production destination post completion of your development and testing. This feature is only available for Standard pricing plan.\n\n\n\n\n\n Using a push service destination \n\nTo use a push service destination, add it to a subscription. The subscription also needs a topic to filter events of interest from your sources. When an event lands in the topic, Event Notifications immediately routes the event notification to your registered devices.\n\nThe push service works along with an app on your users' mobile devices. You must instrument the app with the Event Notifications push SDK. The app must ensure that users consent to notifications, and then the SDK helps to register their mobile devices. For more information, see [Create an Event Notifications destination](https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-create-en-destination).\n\n\n\n\n\n Push troubleshooting and telemetry \n\nTroubleshooting and telemetry information for push notifications is available in the IBM\u00ae Log Analysis service. You can see the dispatch status as well as delivered and opened information for individual devices. For more information, see [Logging for Event Notifications](https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-logs).\n\n\n\n\n\n Push charges \n\nThe IBM Cloud push service has two components to pricing: a destination instance fee and a consumption price.\n\nThe destination instance fee is a fixed amount charged monthly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-destinations-push"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.5205067333}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10863-7246-8495","score":19.4882774353,"text":"\n\/\/ returning the result here, makes sure that the top-most promise, we returned in main() returns the combined results of all\n\/\/ chained action invokes\n\n\/\/ since the result needs to be a valid JSON object, we cannot directly return the array, so we wrap it\nreturn {\naction_results: chained_action_results\n};\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\nconsole.log('Custom SEQUENCE with openwhisk-node-js-sdk FAILED');\n\n\/\/ This last throw is absolutely important to make the top-most promise, which we initially returned at the\n\/\/ top of the main() function REJECTS with the given error. If we did not throw here, it would still RESOLVE\n\/\/ even though the code herein failed.\nthrow error;\n});\n}\nShow more\n6. Click Save.\n7. Test your action by clicking Invoke and waiting for the following output to display.\n\nExample output\n\nResults:\n{\n\"action_results\": [\n{\n\"cos_message\": \"SUCCESS\"\n},\n{\n\"cloudant_result\": \"SUCCESS\"\n},\n{\n\"cos_message\": \"SUCCESS\"\n}\n]\n}\n\nLogs:\n[\n\"2020-04-17T04:31:20.965176Z stdout: Building custom sequence, using openwhisk node-js SDK...\",\n\"2020-04-17T04:31:31.670466Z stdout: Result from cos-access {\"cos_message\":\"SUCCESS\"}\",\n\"2020-04-17T04:31:31.670501Z stdout: Now invoking db-access...\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_13455-24911-26512","score":18.4486713409,"text":"\n\"content-type\": \"audio\/l16;rate=22050\",\n\"interim_results\": true\n}\n<binary audio data>\n{\n\"action\": \"stop\"\n}\n* The service responds:\n\n{\"results\": [{\"alternatives\": {\"transcript\": \"name \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name may \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name may flour \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name the mayflower \",\n\"confidence\": 0.91}], \"final\": true}], \"result_index\": 0}\n{\"state\":\"listening\"}\n\n\n\n\n\n\n\n\n\n WebSocket return codes \n\nThe service can send the following return codes to the client over the WebSocket connection:\n\n\n\n* 1000 indicates normal closure of the connection, meaning that the purpose for which the connection was established has been fulfilled.\n* 1002 indicates that the service is closing the connection due to a protocol error.\n* 1006 indicates that the connection closed abnormally.\n* 1009 indicates that the frame size exceeded the 4 MB limit.\n* 1011 indicates that the service is terminating the connection because it encountered an unexpected condition that prevents it from fulfilling the request.\n\n\n\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_02679-8312-9928","score":18.3058681488,"text":"\nThe SDK uses the attribute values to determine whether the specified entity satisfies the targeting rules, and returns the appropriate feature flag value.\n\n\n\n\n\n\n\n Get single property \n\nconst property = appConfigClient.getProperty('property_id'); \/\/ property can be null incase of an invalid property id\n\nif (property != null) {\nconsole.log(Property Name ${property.getPropertyName()} );\nconsole.log(Property Id ${property.getPropertyId()} );\nconsole.log(Property Type ${property.getPropertyDataType()} );\n}\n\n\n\n\n\n Get all properties \n\nconst properties = appConfigClient.getProperties();\nconst property = properties['property_id'];\n\nif (property != null) {\nconsole.log(Property Name ${property.getPropertyName()} );\nconsole.log(Property Id ${property.getPropertyId()} );\nconsole.log(Property Type ${property.getPropertyDataType()} );\n}\n\n\n\n\n\n Evaluate a property \n\nYou can use the property.getCurrentValue(entityId, entityAttributes) method to evaluate the value of the property. This method returns a JSON object containing evaluated value and evaluation details.\n\nconst entityId = '<entityId>';\nconst entityAttributes = {\ncity: 'Bangalore',\ncountry: 'India',\n};\n\nconst result = property.getCurrentValue(entityId, entityAttributes);\nconsole.log(result.value); \/\/ Evaluated value of the property. The type of evaluated value will match the type of property (Boolean, String, Numeric).\nconsole.log(result.details); \/\/ a JSON object containing detailed information of the evaluation. See below\n\n\/\/ the result.details will have the following\nconsole.log(result.details.valueType); \/\/ a string value. Example: DEFAULT_VALUE","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks"},{"document_id":"ibmcld_10817-6582-8092","score":17.5549297333,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12335-0-917","score":17.3271064758,"text":"\n\n\n\n\n\n\n  Errors \n\n\n\n  Error delivery \n\nSDK methods MUST surface errors to the caller in the manner that is idiomatic for the particular language. For example, a Go SDK should return an error value from the method, but a Java SDK should raise an Exception.\n\n\n\n\n\n  Error content \n\nWhen an SDK method encounters an error, it MUST capture all relevant information about the error and return it in the error structure that is returned to the caller. Relevant information includes the entire contents of the error response and all response headers. The SDK documentation MUST clearly describe how this information is returned and how it can be accessed by the calling program.\n\nErrors that are generated within the SDK MUST give a clear and specific description of the problem. For example, if a method parameter failed a validation, the message should state which parameter is invalid and the reason it is invalid.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-errors"},{"document_id":"ibmcld_10863-6347-7636","score":17.0909519196,"text":"\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {\nconsole.log('Result from db-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Now invoking cos-access...');\n\nreturn ow.actions.invoke({\nname: 'action-tutorial\/cos-access',\nblocking: true,\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {\nconsole.log('Result from cos-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Custom SEQUENCE with openwhisk-node-js-sdk completed.');\n\n\/\/ returning the result here, makes sure that the top-most promise, we returned in main() returns the combined results of all\n\/\/ chained action invokes\n\n\/\/ since the result needs to be a valid JSON object, we cannot directly return the array, so we wrap it\nreturn {\naction_results: chained_action_results\n};\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_10863-4041-5570","score":16.6423988342,"text":"\nresolve({ cloudant_result: 'SUCCESS' });\n}, 5000);\n});\n}\nShow more\n6. Click Save.\n7. Test your action by clicking Invoke and waiting for the following output to display.\n\nExample output\n\nResults:\n{\n\"cloudant_result\": \"SUCCESS\"\n}\n\nLogs:\n[\n\"2020-04-21T01:53:36.739565Z stdout: fake db access done. Resolving Promise...\"\n]\n\n\n\n\n\nYour db-access action is ready!\n\n\n\n\n\n Step 3: Create the ow-sdk-action actionow-sdk-action action \n\nThe ow-sdk-action action is a Node.js program that calls the other two actions: cos-access and db-access. When invoked, the ow-sdk-action action code acts as a custom sequence, first calling cos-access, then db-access, and finally cos-access again. The results of each action are stored in a variable that is called chained_action_results, which is then returned at the end. When the action is invoked, follow the code comments to see what is happening.\n\n\n\n1. From the Actions page, create a third action called ow-sdk-action.\n\n\n\n1. Name your action ow-sdk-action.\n2. Select the action-tutorial package.\n3. Select Node.js 10 for the runtime.\n4. Click Create.\n5. Paste in the following code example:\n\n\/\n* main() will be run when you invoke this action\n* @param Cloud Functions actions accept a single parameter, which must be a JSON object.\n* @return The output of this action, which must be a JSON object.\n\/\nconst openwhisk = require('openwhisk');\nconst ow = openwhisk();\n\nfunction main(params) {\n\/\/ for demonstration purposes, we keep track of the individual results of each action that we invoke in our","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_02680-6103-7532","score":16.3975486755,"text":"\nval result = feature.getCurrentValue(entityId, entityAttributes) as JSONObject\nresult.get(\"key\") \/\/ returns the value of the key\n}\n\nval feature: Feature? = appConfiguration.getFeature(\"yaml-feature\")\nfeature.getFeatureDataType(); \/\/ STRING\nfeature.getFeatureDataFormat(); \/\/ YAML\nfeature.getCurrentValue(entityId, entityAttributes); \/\/ returns the stringified yaml (check Table 1)\n\n\n\n\n\n Property \n\nval property: Property? = appConfiguration.getProperty(\"json-property\")\nproperty.getPropertyDataType(); \/\/ STRING\nproperty.getPropertyDataFormat(); \/\/ JSON\n\n\/\/ Example below (traversing the returned JSONObject)\nif (property != null) {\nval result = property.getCurrentValue(entityId, entityAttributes) as JSONObject\nresult.get(\"key\") \/\/ returns the value of the key\n}\n\nval property: Property? = appConfiguration.getProperty(\"yaml-property\")\nproperty.getPropertyDataType(); \/\/ STRING\nproperty.getPropertyDataFormat(); \/\/ YAML\nproperty.getCurrentValue(entityId, entityAttributes); \/\/ returns the stringified yaml (check above Table 1)\n\n\n\n* Force fetch the configurations from server.\n\nappConfiguration.fetchConfigurations()\n\n\n\n\n\n\n\n\n\n\n\n Integrating client SDK for Android app written in Java \n\nApp Configuration service provides Android client SDK to integrate with your Android application. You can evaluate the values of your property and feature flag by integrating the SDK.\n\n\n\n1. Install the SDK by using either one of the options:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android"},{"document_id":"ibmcld_02680-5022-6382","score":16.3888492584,"text":"\nThe String data type can be of the format of a text string, JSON or YAML. Accordingly, the SDK processes each format as shown in Table 1.\n\n\n\nTable 1. Example outputs\n\n Feature or Property value Data type Data format Type of data returned by getCurrentValue() Example output \n\n true BOOLEAN not applicable java.lang.Boolean true \n 25 NUMERIC not applicable java.lang.Integer 25 \n a string text STRING TEXT java.lang.String a string text \n {\"firefox\": { <br>\"name\": \"Firefox\", <br>\"pref_url\": \"about:config\" <br>}} STRING JSON org.json.JSONObject {\"firefox\":{\"name\":\"Firefox\",\"pref_url\":\"about:config\"}} \n men: <br>- John Smith <br>- Bill Jones <br>women: <br>- Mary Smith <br>- Susan Williams STRING YAML java.lang.String `\"men:<br><br><br><br> * John Smith<br> * Bill Jones\\women:<br> * Mary Smith<br> * Susan Williams\"`<br><br><br> \n\n\n\n\n\n Feature flag \n\nval feature: Feature? = appConfiguration.getFeature(\"json-feature\")\nfeature.getFeatureDataType(); \/\/ STRING\nfeature.getFeatureDataFormat(); \/\/ JSON\n\n\/\/ Example below (traversing the returned JSONObject)\nif (feature != null) {\nval result = feature.getCurrentValue(entityId, entityAttributes) as JSONObject\nresult.get(\"key\") \/\/ returns the value of the key\n}\n\nval feature: Feature? = appConfiguration.getFeature(\"yaml-feature\")\nfeature.getFeatureDataType(); \/\/ STRING\nfeature.getFeatureDataFormat(); \/\/ YAML","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android"},{"document_id":"ibmcld_10863-5217-6577","score":16.2653808594,"text":"\n* @param Cloud Functions actions accept a single parameter, which must be a JSON object.\n* @return The output of this action, which must be a JSON object.\n\/\nconst openwhisk = require('openwhisk');\nconst ow = openwhisk();\n\nfunction main(params) {\n\/\/ for demonstration purposes, we keep track of the individual results of each action that we invoke in our\n\/\/ custom sequence and return it in the last step of the sequence as the overall action result.\n\n\/\/ Although the following .then() blocks are run asynchronously, the main() function acts as a closure that\n\/\/ makes sure that the chained_action_results variable is accessible for all .then() blocks\nconst chained_action_results = [];\n\nconsole.log('Building custom sequence, using openwhisk node-js SDK...');\nreturn ow.actions.invoke({\nname: 'action-tutorial\/cos-access',\nblocking: true,\nresult: true,\nparams: {}\n})\n.then((result) => {\nconsole.log('Result from cos-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Now invoking db-access...');\n\nreturn ow.actions.invoke({\nname: 'action-tutorial\/db-access',\nblocking: true,\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2043823976}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":27.0517654419,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-6582-8092","score":23.5203914642,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02731-4670-6607","score":22.522190094,"text":"\n: Server SDK: You can protect your back-end resources that are hosted on IBM Cloud and your web apps by using the server SDK. It extracts the access token from a request and validates it with App ID. Client SDK: You can protect your mobile apps with the Android or iOS client SDK. The client SDK communicates with your cloud resources to start the authentication process when it detects an authorization challenge.\n\nIBM Cloud\n: App ID: After successful authentication, App ID returns access and identity tokens to your app. Cloud Directory: Users can sign up for your service with their email and a password. You can then manage your users in a list view through the UI. With Cloud Directory, App ID functions as your identity provider.\n\nExternal (third party)\n: Social and enterprise identity providers: App ID supports Facebook, Google+, and SAML 2.0 Federation as identity provider options. The service arranges a redirect to the identity provider and verifies the returned authentication tokens. If the tokens are valid, the service grants access to your app.\n\n\n\n\n\n Integrations \n\nYou can use App ID with other IBM Cloud offerings.\n\nKubernetes Service\n: By configuring Ingress in a standard cluster you can secure your apps at the cluster level. Check out the [App ID authentication Ingress annotation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-comm-ingress-annotationsapp-id-authentication) or the [Announcing App ID integration to IBM Cloud Kubernetes Service](https:\/\/www.ibm.com\/cloud\/blog\/announcing-app-id-integration-ibm-cloud-kubernetes-service) blog post to get started.\n\nCloud Functions and API Connect\n: When you create your APIs with [Cloud Functions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-getting-started) and [API Connect](https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-getting-started), you can secure your applications at the gateway rather than in your app code.\n\nActivity Tracker","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-about"},{"document_id":"ibmcld_10817-2884-4620","score":21.9652519226,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-45155-46272","score":21.6497516632,"text":"\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)\n* [Invoking actions with mobile SDK from WhiskButton](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-actions-whiskbutton)\n\n\n\n\n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage)\n\n\n\n* [Packages for Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorageobstorage_packages)\n* [Setting up the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev)\n\n\n\n* [Prerequisites for working with the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragecos_changes_pre)\n* [1. Assigning the Notifications Manager role to your Cloud Functions namespace](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_auth)\n* [2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02698-2493-3586","score":20.7637042999,"text":"\n[Android SDK](https:\/\/github.com\/IBM\/appconfiguration-android-client-sdk) <br>[Documentation](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android) <br>[JavaScript SDK](https:\/\/github.com\/IBM\/appconfiguration-js-client-sdk) <br>[Documentation](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-javascript) <br>[React SDK](https:\/\/github.com\/IBM\/appconfiguration-react-client-sdk) <br>[Documentation](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-react) \n Admin SDK Admin SDK is designed to perform App Configuration service instance management. Use this SDK to create and manage App Configuration resources like Collections, Environments, Feature flags, and Properties. [App Configuration Admin SDK for Go](https:\/\/cloud.ibm.com\/apidocs\/app-configuration?code=go) \n\n\n\nFor more information about installation and technical concepts, see the 'readme file' document in the SDK.\n\nYou can also access these documents and download the SDKs from the App Configuration console under SDKs on the navigation menu.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-sdks"},{"document_id":"ibmcld_02680-7-1762","score":20.6868171692,"text":"\nApp Configuration client SDK for Android \n\nApp Configuration service provides Android client SDK to integrate with your Android application that is written in Kotlin or Java programming language.\n\n\n\n Prerequisites \n\nFollowing are the prerequisites for using the App Configuration service SDK for Android:\n\n\n\n* Android API level 22 or later\n* [Android Studio](https:\/\/developer.android.com\/studio\/index.html)\n* [Gradle](https:\/\/gradle.org\/install)\n\n\n\n\n\n\n\n Integrating client SDK for Android app written in Kotlin \n\nApp Configuration service provides Android client SDK to integrate with your Android application. You can evaluate the values of your property and feature flag by integrating the SDK.\n\n\n\n1. Install the SDK by using either one of the options:\n\n\n\n* [Download](https:\/\/github.com\/IBM\/appconfiguration-android-client-sdk) and import the package to your Android studio project.\n* Get the package through Gradle by adding the:\n\n\n\n* Add App Configuration Android client SDK dependency to Project level build.gradle file.\n\nrepositories {\nmavenCentral()\n}\n* Add App Configuration Android client SDK dependency to Module level build.gradle file.\n\ndependencies {\nimplementation \"com.ibm.cloud:appconfiguration-android-sdk:0.3.1\"\n}\n\n\n\n\n\n2. Configure the AndroidManifest.xml file for internet permission.\n\n<uses-permission android:name=\"android.permission.INTERNET\"\/>\n3. Initialize the SDK.\n\nval appConfiguration = AppConfiguration.getInstance()\n\nappConfiguration.init( application,\n\"region\",\n\"guid\",\n\"apikey\")\n\n\/\/To start the configuration fetching operation, set the collectionId and environmentId in the following way.\nappConfiguration.setContext(\"collectionId\",\"environmentId\")\n\nWhere:\n\n\n\n* region - Region name where the service instance is created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android"},{"document_id":"ibmcld_05007-8382-9570","score":20.5628318787,"text":"\n<Expiration>\n<Days>60<\/Days>\n<\/Expiration>\n<\/Rule>\n<\/LifecycleConfiguration>\nShow more\n\nCode sample for use with NodeJS COS SDK\n\nUsing the IBM Cloud\u00ae Object Storage SDKs only requires calling the appropriate functions with the correct parameters and proper configuration.\n\nvar aws = require('ibm-cos-sdk');\nvar ep = new aws.Endpoint('s3.us-south.cloud-object-storage.appdomain.cloud');\nvar config = {\nendpoint: ep,\napiKeyId: 'ZRZDoNoUseOLL7bRO8SAMPLEHPUzUL_-fsampleyYE',\nibmAuthEndpoint: 'https:\/\/iam.cloud.ibm.com\/identity\/token',\nserviceInstanceId: 'crn:v1:bluemix:public:cloud-object-storage:global:a\/<CREDENTIAL_ID_AS_GENERATED>:<SERVICE_ID_AS_GENERATED>::',\n};\nvar s3 = new aws.S3(config);\nvar date = new Date('June 16, 2019 00:00:00');\n\nvar params = {\nBucket: 'STRING_VALUE', \/* required \/\nLifecycleConfiguration: {\nRules: [ \/* required \/\n{\nStatus: 'Enabled', \/* required \/\nID: 'OPTIONAL_STRING_VALUE',\nFilter: {}, \/* required \/\nExpiration:\n{\nDate: date\n}\n},\n]\n}\n};\n\ns3.putBucketLifecycleConfiguration(params, function(err, data) {\nif (err) console.log(err, err.stack); \/\/ an error occurred\nelse console.log(data); \/\/ successful response\n});\n\nCode sample for use with Python COS SDK","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry"},{"document_id":"ibmcld_02799-4583-6045","score":20.5536403656,"text":"\nIf neither are provided, the App ID SDK tries to retrieve the application_uri of the app that is running on IBM Cloud and append a default suffix \/ibm\/cloud\/appid\/callback.\n5. By using the information obtained in the previous steps, initialize the SDK.\n\npassport.use(new WebAppStrategy({\ntenantId: \"<tenantID>\",\nclientId: \"<clientID>\",\nsecret: \"<secret>\",\noauthServerUrl: \"<oauthServerURL>\",\nredirectUri: \"<appURL>\" + CALLBACK_URL\n}));\n6. Configure passport with serialization and deserialization. This configuration step is required for authenticated session persistence across HTTP requests. For more information, see the [passport docs](http:\/\/www.passportjs.org\/docs\/).\n\npassport.serializeUser(function(user, cb) {\ncb(null, user);\n});\npassport.deserializeUser(function(obj, cb) {\ncb(null, obj);\n});\n7. Add the following code to your server.js file to issue the service redirects.\n\napp.get(CALLBACK_URL, passport.authenticate(WebAppStrategy.STRATEGY_NAME));\n8. Register your protected endpoint by adding the following code snippet into your app.js file.\n\napp.get(\u2018\/protected_resource\u2019, passport.authenticate(WebAppStrategy.STRATEGY_NAME), function(req, res) {res.json(req.user); });\n\n\n\nFor more information, see the [App ID Node.js GitHub repository](https:\/\/github.com\/ibm-cloud-security\/appid-serversdk-nodejs).\n\n\n\n\n\n\n\n Configuring the Liberty for Java SDK \n\nYou can configure App ID to work with your Liberty for Java web applications.\n\n\n\n Before you begin","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-web-apps"},{"document_id":"ibmcld_02683-7-1658","score":20.5243320465,"text":"\nApp Configuration server SDK for Java \n\nApp Configuration service provides SDKs to integrate with your applications, microservices, and distributed environments.\n\n\n\n Integrating server SDK for Java \n\nApp Configuration service provides SDK to integrate with your Java applications. You can evaluate the values of your feature flag by integrating the App Configuration SDK.\n\n\n\n1. Install the SDK in one of the following ways.\n\nUsing Maven\n\n<dependency>\n<groupId>com.ibm.cloud<\/groupId>\n<artifactId>appconfiguration-java-sdk<\/artifactId>\n<version>0.3.3<\/version>\n<\/dependency>\n\nGet the package through Gradle by adding:\n\nimplementation group: 'com.ibm.cloud', name: 'appconfiguration-java-sdk', version: '0.3.3'\n2. In your Java microservice or application, include the SDK with:\n\nimport com.ibm.cloud.appconfiguration.sdk.AppConfiguration;\n3. Initialize the SDK to connect with your App Configuration service instance.\n\nString region = AppConfiguration.REGION_US_SOUTH;\nString guid = \"guid\";\nString apikey = \"apikey\";\n\nString collectionId = \"airlines-webapp\";\nString environmentId = \"dev\";\n\nAppConfiguration appConfigClient = AppConfiguration.getInstance();\nappConfigClient.init(region, guid, apikey);\nappConfigClient.setContext(collectionId, environmentId);\n\nWhere,\n\n\n\n* region: Region name where the service instance is created. Use AppConfiguration.REGION_US_SOUTH for Dallas, AppConfiguration.REGION_US_EAST for Washington DC, AppConfiguration.REGION_EU_GB for London, and AppConfiguration.REGION_AU_SYD for Sydney.\n* guid: GUID of the App Configuration service. Get it from the service credentials section of the App Configuration service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-java"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16233-7-2298","score":22.3996219635,"text":"\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-about"},{"document_id":"ibmcld_03330-4-2191","score":21.5395698547,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_16727-19989-21995","score":20.7699642181,"text":"\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)\n* What does the \"Only one free environment is allowed per resource group\" error message mean?\n\nIf you have recently deleted a Lite instance and then receive a 400 - Only one free environment is allowed per resource group error message when creating a new environment in a new Lite instance, you need to finish deleting the original Lite instance. See [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) and follow the reclamation-delete instructions.\n* Is there size limitation on the length of Natural Language Queries (NLQ)?\n\nThe maximum query string length for a natural language query is 2048. For more information, see [Natural language query](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersnlq).\n* How do you improve query results?\n\nThe relevance of natural language query results can be improved in IBM Watson Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. For information, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n* How do you know that relevancy training is complete?\n\nFor answers to common questions about training a collection and explanations of common error and warning messages, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-19989-21995","score":20.7699642181,"text":"\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)\n* What does the \"Only one free environment is allowed per resource group\" error message mean?\n\nIf you have recently deleted a Lite instance and then receive a 400 - Only one free environment is allowed per resource group error message when creating a new environment in a new Lite instance, you need to finish deleting the original Lite instance. See [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) and follow the reclamation-delete instructions.\n* Is there size limitation on the length of Natural Language Queries (NLQ)?\n\nThe maximum query string length for a natural language query is 2048. For more information, see [Natural language query](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersnlq).\n* How do you improve query results?\n\nThe relevance of natural language query results can be improved in IBM Watson Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. For information, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n* How do you know that relevancy training is complete?\n\nFor answers to common questions about training a collection and explanations of common error and warning messages, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16728-6533-8457","score":20.4198493958,"text":"\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Build a database-driven Slackbot](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson)Build a database-driven Slackbot Solution tutorial\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Build, deploy, test and monitor a predictive machine learning model](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model)Build, deploy, test and monitor a predictive machine learning model Solution tutorial\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"},{"document_id":"ibmcld_03369-86555-88392","score":20.1884632111,"text":"\nFrench language beta support added for contextual entities\n: You can add contextual entities to French-language dialog skills. For more information about contextual entities, see [Creating entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-annotations-overview).\n\nNew API version\n: The current API version is now 2020-04-01. The following change was made with this version:\n\n\n\n* An integrations property was added to the V2 \/message context. The service now expects the context.integrations property to conform to a specific schema in which the allowed values are as follows:\n\n\n\n* chat\n* facebook\n* intercom\n* liveengage\n* salesforce\n* slack\n* service_desk\n* text_messaging\n* voice_telephony\n* zendesk\n\n\n\n\n\nIf your app uses a context.integrations property that does not conform to the schema, a 400 error code will be returned.\n\n\n\n\n\n 31 March 2020 \n\nThe web chat integration was updated\n: The update adds an isTrackingEnabled parameter. You can add this parameter and set it to false to add the X-Watson-Learning-Opt-Out header to each \/message request that originates from the web chat. For more information about the header, see [Data collection](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2data-collection). For more information about the parameter, see [Configuration](https:\/\/integrations.us-south.assistant.watson.cloud.ibm.com\/web\/developer-documentation\/api-configuration).\n\n\n\n\n\n 26 March 2020 \n\nThe Covid-19 content catalog is available in Brazilian Portuguese, French, and Spanish\n: The content catalog defines a group of intents that recognize the common types of questions people ask about the novel coronavirus. You can use the catalog to jump-start development of chatbots that can answer questions about the virus and help to minimize the anxiety and misinformation associated with it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_13160-7754-9761","score":20.165473938,"text":"\nClick on Launch Watson Assistant to get to the Watson Assistant Tool.\n3. In the welcome dialog, create a new assistant by using slackbot as Assistant name, then click Next to start personalizing.\n4. For the first question on deployment pick Web.\n5. For the other questions answer for your role or with Other \/ Not sure at this time.\n6. Click Next for the opportunity to customize the chat UI if desired.\n7. Click Next and finalize by clicking Create.\n\nThe new page includes a guided tour which you might want to complete if you are new to Watson Assistant.\n\n\n\n\n\n\n\n Step 3: Add and configure a custom extension \n\nNext, you are going to add and then configure a custom extension to Watson Assistant and the newly created assistant.\n\n\n\n1. In the dashboard on the lower left, click on Integrations, then on Build custom extension under Extensions.\n2. In the multi-step dialog click Next, then enter events as Extension name and API for events database as Extension description. Click Next.\n3. Select and upload the local file slackbot-openapi-spec.json, then click Next.\n4. The last step lets you review the extension with included servers and operations. Once done click Finish.\n5. Back on the Integrations page note the new events tile in the Extensions section. Click Add on that tile to configure the extension for the assistant.\n6. The new dialog starts with a short overview. Click Next to get to the actual configuration. In the dropdown for Authentication type select API key auth and enter your chosen API key (MY_SECRET replacement).\n7. For the Server variables use your deployment region, slackbot-backend as appname, and the Code Engine projectid of your app. Thereafter, the generated URL should match that of your Code Engine app. When done, click Next to get to the review page, then Finish and Close to get back to the Integrations page.\n\n\n\n\n\n\n\n Step 4: Create the first action \n\nFirst, you are going to create an action to retrieve information about a single event identified by its name.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"},{"document_id":"ibmcld_09228-1610-2667","score":19.5706691742,"text":"\n* [View on GitHub](https:\/\/github.com\/with-watson\/multilingual-chatbot)\n* [Try the demo](https:\/\/multilingual-chatbot.mybluemix.net\/)\n* [Read more](https:\/\/medium.com\/ibm-watson\/build-multilingual-chatbots-with-watson-language-translator-watson-assistant-8c38247e8af1)\n\n\n\n\n\n\n\n Real-time translation (Node.js) \n\nBy using Node.js and React components, you can create a web app that can be your personal translator. The app uses Watson Speech to Text, Watson Language Translator, and Watson Text to Speech services to transcribe, translate, and synthesize from your microphone to your headphones.\n\n\n\n* [Code Pattern](https:\/\/developer.ibm.com\/components\/watson-apis\/patterns\/build-a-real-time-translation-service-with-watson-api-kit)\n* [View on GitHub](https:\/\/github.com\/ibm\/watson-speech-translator)\n\n\n\n\n\n\n\n Korean Character Recognition (TensorFlow, Android) \n\nThis mobile application uses TensorFlow and Language Translator to recognize and translate handwritten Korean characters.\n\n\n\n* [View on GitHub](https:\/\/github.com\/IBM\/tensorflow-hangul-recognition)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-sample-apps"},{"document_id":"ibmcld_03037-7-1971","score":19.3654155731,"text":"\nAdvanced tasks \n\nLearn about APIs and other tools you can use to access and analyze log data.\n\n\n\n API \n\nYou can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For conversations created by using the v2 \/message API, use the instance-level endpoint to [list log events in all workspaces](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v2listalllogs), and then filter by Assistant ID. For more information about filtering logs, see [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference).\n\nThe number of days that logs are stored differs by service plan type. See [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-limits) for details.\n\nFor a Python script you can run to export logs and convert them to CSV format, download the export_logs_py.py file from the [Watson Assistant GitHub)](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py) repository.\n\n\n\n\n\n Logs-related terminology \n\nFirst, review the definitions of terms that are associated with Watson Assistant logs:\n\n\n\n* Assistant: An application - sometimes referred to as a 'chat bot' - that implements your Watson Assistant content.\n* Assistant ID: The unique identifier of an assistant.\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_13160-6371-8160","score":18.9967193604,"text":"\nReplace projectid, region, and MY_SECRET accordingly.\n\ncurl -X 'POST' 'https:\/\/slackbot-backend.projectid.region.codeengine.appdomain.cloud\/database\/recreate' -H 'accept: application\/json' -H 'API_TOKEN: MY_SECRET'\n\nThe above request should return an error message that the confirmation is missing. Now try again with a query parameter:\n\ncurl -X 'POST' 'https:\/\/slackbot-backend.projectid.region.codeengine.appdomain.cloud\/database\/recreate?confirmation=True' -H 'accept: application\/json' -H 'API_TOKEN: MY_SECRET'\n\nThe request should succeed and indicate that the database was recreated. Time for another test:\n\ncurl -X 'GET' 'https:\/\/slackbot-backend.projectid.region.codeengine.appdomain.cloud\/events' -H 'accept: application\/json' -H 'API_TOKEN: MY_SECRET'\n\n\n\n\n\n\n\n Step 2: Create an assistant \n\nIn this part of the tutorial you are going to work with the Watson Assistant service. First, you create a new assistant. Then, you create the custom extension and add it to the assistant. Thereafter, you will create actions and test them using the web preview. Finally, you integrate the chatbot with Slack and perform more tests.\n\n\n\n1. In the [IBM Cloud Resource List](https:\/\/cloud.ibm.com\/resources) open the overview of your services. Locate the instance of the Watson Assistant service under the AI \/ Machine Learning section. Click on its entry to open the service details.\n2. Click on Launch Watson Assistant to get to the Watson Assistant Tool.\n3. In the welcome dialog, create a new assistant by using slackbot as Assistant name, then click Next to start personalizing.\n4. For the first question on deployment pick Web.\n5. For the other questions answer for your role or with Other \/ Not sure at this time.\n6. Click Next for the opportunity to customize the chat UI if desired.\n7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09920-5038-6185","score":19.8997745514,"text":"\nCreate a Banking Chatbot \n\nUse Node.js and Watson to detect emotion, identify entities, and discover answers.\n\n\n\n* [Learn more ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/developer.ibm.com\/patterns\/create-cognitive-banking-chatbot\/)\n* [Get the Code ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/github.com\/IBM\/watson-banking-chatbot?cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-Get-the-Code)\n* [View the Demo ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.youtube.com\/watch?v=Jxi7U7VOMYg&cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-View-the-Demo)\n* [Build from a Starter Kit ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/console.bluemix.net\/developer\/watson\/create-project?starterKit=a5819b41-0f6f-34cb-9067-47fd16835d04&cm_sp=dw-bluemix-_-code-_-devcenter)\n\n\n\n\n\n\n\n Enrich multimedia files using Watson services \n\nBuild an app that enriches audio and visual files using IBM Watson services.\n\n\n\n* [Learn more !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-sample-apps"},{"document_id":"ibmcld_05727-14301-16089","score":17.2593803406,"text":"\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization \n\nWatson Assistant provides tools to quickly scaffold a chatbot that can provide the correct benefits information to users.\n\n\n\n\n\n Step 4: Deliver continuously across the globe \n\n\n\n* IBM Cloud\u00ae Continuous Delivery helps Developers to quickly provision an integrated toolchain, by using customizable, shareable templates with tools from IBM, third parties, and open source. Automate builds and tests, controlling quality with analytics.\n* After Developers build and test the apps in their Development and Test clusters, they use the IBM CI\/CD toolchains to deploy apps into Production clusters across the globe.\n* IBM Cloud Kubernetes Service provides easy rollout and roll-back of apps. Tailored apps are deployed to meet regional requirements through the intelligent routing and load balancing of Istio.\n* Built-in HA tools in IBM Cloud Kubernetes Service balance the workload within each geographic region, including self-healing and load balancing.\n\n\n\n\n\n\n\n\n\n Results \n\n\n\n* With tools like the chatbot, the HR team proved to their workforce that innovation was part of the corporate culture, not just buzz words.\n* Authenticity with personalization in the site addressed the changing expectations of the airline\u2019s workforce today.\n* Last-minute updates to the HR site, including ones that driven by the employees chatbot conversations, went live quickly because Developers were pushing changes at least 10 times daily.\n* With infrastructure management taken care of by IBM, the Development team was freed up to deliver the site in only 3 weeks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_uc_transport"},{"document_id":"ibmcld_16727-19989-21995","score":16.3995780945,"text":"\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)\n* What does the \"Only one free environment is allowed per resource group\" error message mean?\n\nIf you have recently deleted a Lite instance and then receive a 400 - Only one free environment is allowed per resource group error message when creating a new environment in a new Lite instance, you need to finish deleting the original Lite instance. See [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) and follow the reclamation-delete instructions.\n* Is there size limitation on the length of Natural Language Queries (NLQ)?\n\nThe maximum query string length for a natural language query is 2048. For more information, see [Natural language query](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersnlq).\n* How do you improve query results?\n\nThe relevance of natural language query results can be improved in IBM Watson Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. For information, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n* How do you know that relevancy training is complete?\n\nFor answers to common questions about training a collection and explanations of common error and warning messages, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-19989-21995","score":16.3995780945,"text":"\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)\n* What does the \"Only one free environment is allowed per resource group\" error message mean?\n\nIf you have recently deleted a Lite instance and then receive a 400 - Only one free environment is allowed per resource group error message when creating a new environment in a new Lite instance, you need to finish deleting the original Lite instance. See [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) and follow the reclamation-delete instructions.\n* Is there size limitation on the length of Natural Language Queries (NLQ)?\n\nThe maximum query string length for a natural language query is 2048. For more information, see [Natural language query](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersnlq).\n* How do you improve query results?\n\nThe relevance of natural language query results can be improved in IBM Watson Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. For information, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n* How do you know that relevancy training is complete?\n\nFor answers to common questions about training a collection and explanations of common error and warning messages, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16233-7-2298","score":16.2967262268,"text":"\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-about"},{"document_id":"ibmcld_16282-1618-3249","score":16.1406059265,"text":"\nIf the assistant or the user enters new input, then the button-generated input disappears. Therefore, if you include multiple response types in a single response, position the option response type last. Otherwise, content from subsequent responses, such as text from a text response type, will replace the button-generated text.\n* The title is automatically taken from the text of the relevant step of the action where options are listed.\n\n\n\n\n\n\n\n\n\n Chatting with the assistant \n\nTo start a chat with the assistant, complete the following steps:\n\n\n\n1. Open Facebook Messenger.\n2. Type the name of the page you created earlier.\n3. After the page comes up, click it, and then start chatting with the assistant.\n\n\n\nThe welcome action is not processed by the Facebook Messenger integration. The welcome message is not displayed in Facebook Messenger like it is in the assistant preview. It is not triggered from here because nodes with the welcome special condition are skipped in action flows that are started by users. Facebook Messenger waits for the user to initiate the conversation.\n\nThe action flow for the current session is restarted after 60 minutes of inactivity (5 minutes for Lite and Standard plans). This means that if a user stops interacting with the assistant, after 60 (or 5) minutes, any context variable values that were set during the previous conversation are set to null or back to their default values.\n\nOnly the page administrator can interact with the Facebook Messenger chatbot until after it is approved by Facebook. After the chatbot is approved by Facebook, any page visitor can interact with the chatbot.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-facebook"},{"document_id":"ibmcld_16365-7-1700","score":15.7903108597,"text":"\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_10170-14072-16125","score":15.7215442657,"text":"\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure tunnel to on-premises systems that host the benefits systems.\n* Combination of on-premises data and Red Hat OpenShift on IBM Cloud lets them access sensitive data while they adhere to regulations.\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization \n\nWatson Assistant provides tools to quickly scaffold a chatbot that can provide the correct benefits information to users.\n\n\n\n\n\n Step 4: Deliver continuously across the globe \n\n\n\n* IBM Cloud\u00ae Continuous Delivery helps Developers to quickly provision an integrated toolchain, by using customizable, shareable templates with tools from IBM, third parties, and open source. Automate builds and tests, controlling quality with analytics.\n* After Developers build and test the apps in their Development and Test clusters, they use the IBM CI\/CD toolchains to deploy apps into Production clusters across the globe.\n* Red Hat OpenShift on IBM Cloud provides easy rollout and roll-back of apps. Tailored apps are deployed to meet regional requirements through the intelligent routing and load balancing of Istio.\n* Built-in HA tools in Red Hat OpenShift on IBM Cloud balance the workload within each geographic region, including self-healing and load balancing.\n\n\n\n\n\n\n\n\n\n Results \n\n\n\n* With tools like the chatbot, the HR team proved to their workforce that innovation was part of the corporate culture, not just buzz words.\n* Authenticity with personalization in the site addressed the changing expectations of the airline\u2019s workforce today.\n* Last-minute updates to the HR site, including ones that driven by the employees chatbot conversations, went live quickly because Developers were pushing changes at least 10 times daily.\n* With infrastructure management taken care of by IBM, the Development team was freed up to deliver the site in only 3 weeks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_07223-4208-5090","score":15.7108192444,"text":"\n* [View the Demo](https:\/\/www.youtube.com\/watch?v=uigisF50F8s&feature=youtu.be)\n\n\n\n[Cognitive Banking Chatbot](https:\/\/developer.ibm.com\/patterns\/create-cognitive-banking-chatbot\/?cm_sp=Developer-_-code-_-banking_chatbot) Create a web UI chatbot using the IBM Watson Node.js SDK to include conversation interaction, anger detection, natural language understanding, and answer discovery. Answers are discovered from a collection of FAQ documents. Built as a fictional financial institution, this app calls out to simple banking services code as an example of how to include external business data in a conversation response.\n\n\n\n* [Get the Code](https:\/\/github.com\/IBM\/watson-banking-chatbot?cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-Get-the-Code)\n* [View the Demo](https:\/\/www.youtube.com\/watch?v=Jxi7U7VOMYg&cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-View-the-Demo)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sample-apps"},{"document_id":"ibmcld_16384-7-2422","score":15.6394233704,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05256-22076-24099","score":12.9136791229,"text":"\nIf you have a Service ID that you want to use, select it. If not, select Create, enter a name and description, and click Create.\n4. From the Service ID page, from the Access policies section, select Assign access.\n5. From the Assign service ID additional access section,\n\n\n\n1. Select Container Registry for type of access. Click Next.\n2. Select the type of access: All resources or Specific resources. If you specify Specific resources, you can add attributes based on resource group, geography, region, resource type, resource ID, or resource name to further restrict access. If you select a certain resource group, make sure to select Viewer access for Resource group access. Click Next.\n3. In the Roles and Actions section, select the type of access you want to grant. If you plan to use only images for your applications and jobs, select Reader. If you want to push the source code and images to Container Registry, then also select Writer. Click Review.\n4. Click Add and then Assign.\n\n\n\n\n\n\n\n\n\n Step 2 Enabling Container Registry discovery \n\nTo allow the Code Engine console to automatically discover Container registry, you must authenticate the service ID to the IAM Identity Service.\n\n\n\n1. From the Service ID page, from the Access policies section, select Assign access.\n2. From the Assign service ID additional access section,\n\n\n\n1. Select IAM Identity Service for type of access. Click Next.\n2. Select Specific resources for resource scope. Select Resource type as attribute type, keep string equals as operator and enter serviceid as value. Click Add a condition.\n3. Select Resource ID as attribute type, keep string equals as operator and put the identifier of your service ID. You can find your service ID on the Details page for the service ID or in the browser URL when configuring it. Click Next.\n4. In the Roles and Actions section, select Platform Operator access. Click Review\n5. Click Add and then Assign.\n\n\n\n\n\n\n\n\n\n Step 3 Creating an API key for a service ID \n\nCreate an API key for a service ID.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registry"},{"document_id":"ibmcld_16727-775502-777143","score":11.2218093872,"text":"\nYes, Firefox and Chrome are the recommended browsers. It is recommended that you use the latest versions with your IBM Cloud Content Delivery Network.\n* What is the purpose of providing a path when creating my CDN?\n\nIf you provide a path while creating your CDN, it allows you to isolate the files that can be served through CDN from a particular origin server.\n* My CDN is in an Error State. What do I do now?\n\nRefer to the [Troubleshooting](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-troubleshoot-cdn-working) or [Getting help and support](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-gettinghelpgettinghelp), or open a case in the [IBM Cloud console](https:\/\/%7BDomainName%7D\/).\n* Where do I find the CNAME for my CDN if I didn't provide one?\n\nClick your CDN to access the Overview page in the portal. In the upper right corner, you can see a Details section with the CName information.\n* My single file purge request for a given file path is in progress. Can I submit a new request for the same file path?\n\nNo. There can be only one active purge request for a given file path at a time.\n* Is Internet Protocol version 6 (IPv6) supported by the IBM Cloud Content Delivery Network service? How does it work?\n\nIPv6 (or dual stack support) is supported by Akamai's Edge servers. It is designed to help customers with an IPv4-only origin to accept connections from IPv6 clients, convert from IPv6 to IPv4 at the Edge, and go forward to the origin with IPv4.\n\nCreating an IBM Cloud CDN using an IPv6 address as the origin server address is not supported.\n* Are there any restrictions on what HTTP and HTTPS port numbers are allowed for Akamai?\n\nYes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_14229-7-2026","score":11.1412410736,"text":"\nGetting started with VMware as a Service \n\nIn this IBM Cloud\u00ae for VMware as a Service tutorial, we take you through the process of ordering a VMware as a Service instance by using the IBM Cloud for VMware Solutions user interface. Other operations that you can complete are also listed.\n\nThe completion time that is listed for this tutorial considers only the time that you spend ordering the artifacts for a VMware as a Service instance on the user interface. It does not consider waiting times for deployments, for example.\n\n\n\n Before you begin \n\nBefore you start to work with VMware as a Service, review the following information about browser requirements and users accounts.\n\n\n\n Browser requirements \n\nFor more information, see [Browsers](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platformbrowsers-platform).\n\n\n\n\n\n User accounts \n\nYou need an IBM Cloud account, which must meet certain requirements.\n\n\n\nTable 1. Required user accounts\n\n Account Description \n\n IBMid By using the IBMid, you can have a single login username for all IBM\u00ae products and services that you use, including IBM Cloud. VMware Solutions is provided as an infrastructure solution in the IBM Cloud catalog. To access the VMware Solutions console, you must have an IBMid.<br><br>To use your IBMid to log in to the VMware Solutions console, you must associate the IBMid with an IBM Cloud account. When you log in to the console for the first time, you are guided to either associate your existing IBMid with an IBM Cloud account, or to sign up for a new IBM Cloud account. The new IBM Cloud account is automatically associated with your IBMid. You need to go through this process only once.<br><br>If you have problems when you associate your IBMid with an IBM Cloud account, see [Why is my password incorrect?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-ts_logintoibm) \n IBM Cloud account To order and use IBM Cloud services, an IBM Cloud account is required. Billing information is associated with the IBM Cloud account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-getting-started"},{"document_id":"ibmcld_13726-43056-44925","score":10.8359584808,"text":"\nYou cannot uninstall individual Speech service components\n: The documentation now notes that you cannot uninstall individual service components (microservices) once they are installed. To remove any of the following components, you must uninstall the Watson Speech services in their entirety and reinstall only the components that you need: Speech to Text runtime, Speech to Text asynchronous HTTP, Speech to Text customization, Text to Speech runtime, and Text to Speech customization. For more information about installing the Speech services, see [Watson Speech services on IBM Cloud Pak for Data](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-data\/4.5.x?topic=services-watson-speech).\n\nNew beta spell_out_mode parameter for German voices\n: To indicate how individual characters of a string are to be spelled out, you can now include the beta spell_out_mode query parameter with a synthesis request for a German voice. By default, the service spells out individual characters at the same rate at which it synthesizes text for a language. You can use the parameter to direct the service to spell out individual characters more slowly, in groups of one, two, or three characters. Use the parameter with the SSML <say-as> element to control how the characters of a string are synthesized. For more information, see [Specifying how strings are spelled out](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-synthesis-paramsparams-spell-out-mode).\n\nKnown limitation with using the Ogg audio format with the Safari browser\n: By default, the service returns audio in the Ogg audio format with the Opus codec (audio\/ogg;codecs=opus). However, the Ogg audio format is not supported with the Safari browser. If you are using the the Text to Speech service with the Safari browser, you must specify a different format in which you want the service to return the audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes-data"},{"document_id":"ibmcld_10277-5356-7271","score":10.7151069641,"text":"\nYou can use the same subdomain in each resource or different subdomains in each resource. For example, if you use a wildcard domain, you can append a wildcard subdomain to the beginning of the domain, such as subdomain1.custom_domain.net or subdomain1.mycluster-<hash>-0000.us-south.containers.appdomain.cloud. Do not use * for your host or leave the host property empty to avoid failures during Ingress creation.\n\npath\n: Replace <app_path> with the path that your app is listening on. The path is appended to the IBM-provided or your custom domain to create a unique route to your app. When you enter this route into a web browser, network traffic is routed to the Ingress controller. The Ingress controller looks up the associated service, and the Ingress controller sends network traffic to the service. The service then forwards the traffic to the pods where the app runs. Many apps don't listen on a specific path, but use the root path and a specific port. In this case, define the root path as \/ and don't specify an individual path for your app. For http:\/\/domain\/, enter \/ as the path. For http:\/\/domain\/app1_path, enter \/app1_path as the path.\n\nname\n: Replace <app1_service> and <app2_service>, and so on, with the name of the services you created to expose your apps. If your apps are exposed by services in different projects in the cluster, include only app services that are in the same project. You must create one Ingress resource for each project where you have apps that you want to expose.\n\nport\n: The port that your service listens to. Use the same port that you defined when you created the Kubernetes service for your app.\n2. Create the Ingress resource for your cluster. Ensure that the resource deploys into the same project as the app services that you specified in the resource.\n\noc apply -f myingressresource.yaml -n <project>\n3. Verify that the Ingress resource was created successfully.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ingress-public-expose"},{"document_id":"ibmcld_16727-7341-9464","score":10.6847200394,"text":"\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* I'm being asked to log in repeatedly\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan you were using has expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* I'm getting a 401 response\n\nThe 401 response code is returned for many reasons, including:\n\n\n\n* You exceeded the API call limit for your plan for this month. For example, for Lite plans, the monthly limit for API calls 10,000 messages per month. If you reach your limit for the month, but the logs show that you have made fewer calls than the limit, remember that the Lite plan stores log information for 7 days only. The 401 response will go away as soon as the next billing cycle begins, which is the first day of the calendar month.\n* You are trying to use an instance-level API key that you created in one data center location to connect to a service instance that is hosted from another location. You must create an API key in the same data center location where your service instance is hosted.\n\n\n\n* Getting Unable to fetch access token for account message","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-7341-9464","score":10.6847200394,"text":"\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* I'm being asked to log in repeatedly\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan you were using has expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* I'm getting a 401 response\n\nThe 401 response code is returned for many reasons, including:\n\n\n\n* You exceeded the API call limit for your plan for this month. For example, for Lite plans, the monthly limit for API calls 10,000 messages per month. If you reach your limit for the month, but the logs show that you have made fewer calls than the limit, remember that the Lite plan stores log information for 7 days only. The 401 response will go away as soon as the next billing cycle begins, which is the first day of the calendar month.\n* You are trying to use an instance-level API key that you created in one data center location to connect to a service instance that is hosted from another location. You must create an API key in the same data center location where your service instance is hosted.\n\n\n\n* Getting Unable to fetch access token for account message","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_10275-9819-11672","score":10.672665596,"text":"\nYou can use the same subdomain in each resource or different subdomains in each resource. For example, if you use a wildcard domain, you can append a wildcard subdomain to the beginning of the domain, such as subdomain1.custom_domain.net.\n: Do not use * for your host or leave the host property empty to avoid failures during Ingress creation.\n\npath\n: Replace <app_path> with the path that your app is listening on. The path is appended to the IBM-provided or your custom domain to create a unique route to your app. When you enter this route into a web browser, network traffic is routed to the Ingress controller. The Ingress controller looks up the associated service, and sends network traffic to the service. The service then forwards the traffic to the pods where the app runs. Many apps don't listen on a specific path, but use the root path and a specific port. In this case, define the root path as \/ and don't specify an individual path for your app.\n: For example, to use http:\/\/domain\/, enter \/ as the path. For http:\/\/domain\/app1_path, enter \/app1_path as the path.\n\nserviceName\n: Replace <app1_service> and <app2_service>, and so on, with the name of the services you created to expose your apps. If your apps are exposed by services in different projects in the cluster, include only app services that are in the same project. You must create one Ingress resource for each project that contains apps that you want to expose.\n\nservicePort\n: The port that your service listens to. Use the same port that you defined when you created the Kubernetes service for your app.\n2. Create the Ingress resource for your cluster. Ensure that the resource deploys into the same project as the app services that you specified in the resource.\n\noc apply -f myingressresource.yaml -n <project>\n3. Verify that the Ingress resource was created successfully.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ingress-private-expose"},{"document_id":"ibmcld_03313-7474-9676","score":10.5626268387,"text":"\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n\n\n\n\n I'm being asked to log in repeatedly \n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan you were using has expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n\n\n\n\n I'm getting a 401 response \n\nThe 401 response code is returned for many reasons, including:\n\n\n\n* You exceeded the API call limit for your plan for this month. For example, for Lite plans, the monthly limit for API calls 10,000 messages per month. If you reach your limit for the month, but the logs show that you have made fewer calls than the limit, remember that the Lite plan stores log information for 7 days only. The 401 response will go away as soon as the next billing cycle begins, which is the first day of the calendar month.\n* You are trying to use an instance-level API key that you created in one data center location to connect to a service instance that is hosted from another location. You must create an API key in the same data center location where your service instance is hosted.\n\n\n\n\n\n\n\n Getting Unable to fetch access token for account message \n\nThe full message is, Assistants could not be loaded at this time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"},{"document_id":"ibmcld_01660-19249-21295","score":10.500749588,"text":"\nYou can't change your IBMid, but you can create a new one if appropriate. The [IBMid worldwide help desk](https:\/\/www.ibm.com\/ibmid\/myibm\/help\/us\/helpdesk.html) is available to help with general ID questions that aren't specific to your IBM Cloud account.\n\n\n\n\n\n Can I change my account language? \n\nThe language that is used is based on your web browser settings. To view content in your native language, update your browser's language settings. The language for specific pages must be the same language that is selected for the browser's settings.\n\n\n\n\n\n Does IBM Cloud support batch registration of users? \n\nWhen you register users for IBM Cloud, you must register each user individually. IBM Cloud doesn't support batch registration of users.\n\n\n\n\n\n What are tags? \n\nTags are key:value pairs that you use to organize your resources and service IDs or control access to them.\n\n\n\n* You can use user tags to organize and view resources and service IDs across your account and help you track usage costs.\n* You can limit access to specific resources and service IDs in your account by using access management tags.\n\n\n\nFor more information, see [Working with tags](https:\/\/cloud.ibm.com\/docs\/account?topic=account-tag).\n\n\n\n\n\n What access is required to create access management tags? \n\nYou must be the account owner or have the following roles:\n\n\n\n* Administrator on all account management services\n* Administrator on the tagging service\n\n\n\nFor more information, see [Granting users access to tag resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-access).\n\n\n\n\n\n What access is required to attach or detach tags? \n\n\n\n* To manage user tags on a resource, you must have at least the editor role for IAM-enabled resources.\n* To manage user tags on a service ID, you must have at least the editor role on the IAM Identity service.\n* To manage access management tags, you must have the administrator role on the targeted resource.\n* To manage access management tags on service IDs, you must have the administrator role on the IAM Identity service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13074-16820-18514","score":12.9712247849,"text":"\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/discovery).\n\n\n\n\n\n Enrichment language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_13074-15255-17243","score":11.8540372849,"text":"\nSee [Entity extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceentity-extraction) and [Keyword extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicekeyword-extraction) about those enrichments.\n\nThe subject, action, and object are extracted for every sentence that contains a relation.\n\n\n\n\n\n Sentiment analysis \n\nIdentifies attitude, opinions, or feelings in the content that is being analyzed. Discovery can calculate overall sentiment within a document, sentiment for user-specified targets, entity-level sentiment, quotation-level sentiment, directional-sentiment, and keyword-level sentiment. The combination of these capabilities supports a variety of use cases ranging from social media monitoring to trend analysis.\n\nExample portion of a document enriched with Sentiment Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"sentiment\": {\n\"document\": {\n\"score\": 0.459813,\n\"label\": \"positive\"\n}\n}\n\nIn the preceding example, you could query the sentiment label by accessing enriched_text.sentiment.document.label\n\nThe label is the overall sentiment of the document (positive, negative, or neutral). The sentiment label is based on the score; a score of 0.0 would indicate that the document is neutral, a positive number would indicate the document is positive, a negative number would indicate the document is negative.\n\n\n\n\n\n Emotion analysis \n\nDetects anger, disgust, fear, joy, and sadness implied in English text. Emotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_16356-7-2036","score":8.5094709396,"text":"\nDetecting trigger words \n\nUse the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent. The second group shows customers a customizable warning message.\n\nBy default, this action has two steps\u2014the Connect to agent step and the Show warning step. To see how this action works, click Set by assistant in the list of actions, and then click Trigger word detected.\n\nThis is a beta feature that is available for evaluation and testing purposes.\n\n\n\n Connect to agent \n\nThe first step of the Trigger word detected action is the Connect to agent step. The Connect to agent step goes to the Fallback action if any trigger words are detected in the customer's input. Use this step to capture any key phrases where it\u2019s important to connect a customer with a live agent rather than activate any further actions.\n\nFor example, you might add hurt and harm as trigger words for the Connect to agent step:\n\nZoom\n\n![Adding trigger words to the Connect to agent step](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/connect-to-agent-phrases.png)\n\nAdding trigger words to the Connect to agent step\n\nIn this example, a customer enters a word or phrase including hurt or harm, which triggers the Fallback action. Step 4 has:\n\n\n\n* Danger word detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-phrases"},{"document_id":"ibmcld_16313-10077-11045","score":8.4497404099,"text":"\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable. Each step sends a message to the customer, based on the error condition, and then uses the Connect to agent feature to transfer the conversation to a live agent. (For more information about this feature, see [Connecting to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-human-agent).) You can modify these steps if you want to handle an error condition in a different way.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errors"},{"document_id":"ibmcld_16364-21733-23882","score":8.2891120911,"text":"\n: Use the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent, when it\u2019s important for a customer to speak with a live agent rather than activate any further actions. The second group shows customers a customizable warning message, used to discourage customers from interacting with your assistant in unacceptable ways, such as using profanity. This action is included with all new assistants created as of this date. This is a beta feature that is available for evaluation and testing purposes. For more information, see [Detecting trigger words](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-phrases).\n\nChanges to unrecognized requests algorithm\n: In Analyze, the Recognition page lets you view groups of similar unrecognized requests. You can use the requests as example phrases in new or existing actions to address questions and issues that aren't being answered by your assistant. With this release, the criteria for grouping the requests is relaxed for customers with lesser amounts of data. Also, the group names have been improved with better grammar and to be more representative of the requests. For more information, see [Use unrecognized requests to get action recommendations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-recognition).\n\n\n\n\n\n 1 February 2023 \n\nActions templates updated with new design and new choices\n: The actions template catalog has a new design that lets you select multiple templates at the same time. It also has new and updated templates, including starter kits you can use with external services such as Google and HubSpot. For more information, see [Building actions from a template](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-templates).\n\n\n\n\n\n 26 January 2023 \n\nDisplay formats for variables\n: In Global settings for actions, Display formats lets you specify the display formats for variables that use date, time, numbers, currency, or percentages. You can also choose a default locale to use if one isn't provided by the client application.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_00371-1580-3401","score":8.2042598724,"text":"\nClick Save to save the settings. If the Detection path is unreachable, the optimal route for dynamic content acceleration is impacted.\n\n\n\n\n\n\n\n Understanding DCA concepts \n\n\n\n Detection path \n\nDetection path is used by Akamai Edge servers to find the best optimized route from Edge servers to origin. The best path to origin must be known at the time a user\u2019s request arrives at an Edge server because any inline analysis or detection would defeat the purpose of speeding up things.\n\nTo accomplish this, you are asked to place a test object on your origin. Edge servers periodically fetch the test object from the origin using each of the candidate paths, including the direct path (the default path through the internet from Edge to Origin).\n\nThe fetches of the test object are called the races. When a real request comes in, the Edge consults the most recent race data to send that request over the fastest path to the origin. You can download the provided [test object](https:\/\/public.dhe.ibm.com\/cloud\/bluemix\/network\/cdn\/route-detection-test-object.html) and upload it to the origin server, or you can use your own test object.\n\nA valid test object must:\n\n\n\n* Get HTTP 200 response without authentication\n* Not contact a database or do any back-end processing\n* Be a static text file of content-type text\/HTML\n* Be approximately the size of an average page, but no less than 8 KB\n\n\n\nDetection path is designed to work only for HTTPS domain mapping (SAN HTTPS or Wildcard HTTPS).\n\n\n\n\n\n Prefetching \n\nPrefetching is to inspect HTML responses and prefetch embedded objects in the HTML files. Prefetch works on any page that includes <img>, <script>, or <link> tags that specify relative paths. It also works when the resource hostname matches the request domain in the HTML file, and it is part of a fully qualified URI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-dynamic-content-acceleration"},{"document_id":"ibmcld_09901-0-3644","score":7.7567782402,"text":"\n\n\n\n\n\n\n  Detectable languages \n\nWhen you analyze text or a web page, Natural Language Understanding detects the source language automatically and returns the corresponding ISO 639-1 code in the response. For automatic language detection to work best, it is recommended that you use text with at least 100 characters.\n\nIf automatic language detection isn't working well for your use case, you can [manually specify the language of your content](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-overriding-language-detection) in each request.\n\nThe following table lists the detectable languages and corresponding ISO 639-1 codes.\n\n\n\n Language        ISO 639-1 code  \n\n Afrikaans       af              \n Albanian        sq              \n Amharic         am              \n Arabic          ar              \n Armenian        hy              \n Azerbaijani     az              \n Basque          eu              \n Belarusian      be              \n Bengali         bn              \n Bihari          bh              \n Bulgarian       bg              \n Catalan         ca              \n Chinese         zh              \n Croatian        hr              \n Czech           cs              \n Danish          da              \n Dhivehi         dv              \n Dutch           nl              \n English         en              \n Estonian        et              \n Fijian          fj              \n Finnish         fi              \n French          fr              \n Galician        gl              \n Ganda           lg              \n Georgian        ka              \n German          de              \n Greek           el              \n Gujarati        gu              \n Haitian Creole  ht              \n Hebrew          he              \n Hindi           hi              \n Hungarian       hu              \n Icelandic       is              \n Indonesian      id              \n Inuktitut       iu              \n Irish           ga              \n Italian         it              \n Javanese        jv              \n Japanese        ja              \n Kannada         kn              \n Khmer           km              \n Kinyarwanda     rw              \n Kirghiz         ky              \n Korean          ko              \n Latin           la              \n Laothian        lo              \n Latvian         lv              \n Lithuanian      lt              \n Macedonian      mk              \n Malay           ms              \n Malayalam       ml              \n Maltese         mt              \n Maori           mi              \n Marathi         mr              \n Nepali          ne              \n Norwegian       no              \n Oriya           or              \n Persian         fa              \n Polish          pl              \n Portuguese      pt              \n Punjabi         pa              \n Pashto          ps              \n Romanian        ro              \n Russian         ru              \n Scots Gaelic    gd              \n Serbian         sr              \n Shona           sn              \n Sinhalese       si              \n Slovak          sk              \n Slovenian       sl              \n Spanish         es              \n Swahili         sw              \n Swedish         sv              \n Tagalog         tl              \n Tamil           ta              \n Telugu          te              \n Thai            th              \n Turkish         tr              \n Ukrainian       uk              \n Urdu            ur              \n Vietnamese      vi              \n Welsh           cy              \n Wolof           wo              \n Xhosa           xh              \n Yiddish         Yi              \n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-detectable-languages"},{"document_id":"ibmcld_16171-1267-2113","score":7.7298369408,"text":"\nDetection is the process of monitoring the events occurring in your network and analyzing them for signs of possible threats to your security policies. Prevention refers to the process stopping the detected incidents. \n [On-box logging and reporting CSB statistics in J-web](https:\/\/public.dhe.ibm.com\/cloud\/bluemix\/network\/vsrx\/on-box-logging-reporting-11320.pdf) This guide describes how to enable on-box security event reporting using the set security log report CLI command. \n [Juniper searchable IPS signature database](https:\/\/threatlabs.juniper.net\/signatures\/search\/\/list\/ips?page_number=1&page_size=20) Juniper's searchable database of IPS and application signatures to help protect your environment. These signature pages describe the vulnerabilities covered, their CVE numbers, CVSS scores, and Juniper's recommendation for deployment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vsrx?topic=vsrx-supplemental-ibm-cloud-juniper-vsrx-documentation"},{"document_id":"ibmcld_00371-2967-4606","score":7.7077608109,"text":"\nDetection path is designed to work only for HTTPS domain mapping (SAN HTTPS or Wildcard HTTPS).\n\n\n\n\n\n Prefetching \n\nPrefetching is to inspect HTML responses and prefetch embedded objects in the HTML files. Prefetch works on any page that includes <img>, <script>, or <link> tags that specify relative paths. It also works when the resource hostname matches the request domain in the HTML file, and it is part of a fully qualified URI. When it is set to On, Edge servers prefetch objects with the following file extensions: aif, aiff, au, avi, bin, bmp, cab, carb, cct, cdf, class, css, doc, dcr, dtd, exe, flv, gcf, gff, gif, grv, hdml, hqx, ico, ini, jpeg, jpg, js, mov, mp3, nc, pct, pdf, png, ppc, pws, swa, swf, txt, vbs, w32, wav, wbmp, wml, wmlc, wmls, wmlsc, xsd, and zip.\n\n\n\n\n\n Image compression \n\nServing compressed images reduces the amount of content that is required to load a page. This helps offset less robust connections, such as those formed with mobile devices. If your site visitors have slow network speeds, Image Compressing technology can automatically increase compression of JPEG images to speed up loading. However, Image Compressing results in lossy compression or irreversible compression, and might affect the quality of the images on your site.\n\nImage Compression supported file extensions: .jpg, .jpeg, .jpe, .jif, .jfif, and .jfi.\n\nIn order for the feature Image Compression to work for DCA, you must make sure that the path of the image files is cacheable. See [Caching](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-dynamic-content-accelerationcaching-cache-content) to set the images cacheable.\n\n\n\n\n\n\n\n Caching","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-dynamic-content-acceleration"},{"document_id":"ibmcld_16364-20105-22224","score":7.6617293358,"text":"\n: The Confirmation and Free text response types are now set to Always ask for this information by default. For more information, see [Skipping steps, always asking steps, or never asking steps](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-collect-infocollect-info-skip-step).\n\n\n\n\n\n 13 February 2023 \n\nResponse variations\n: In actions, you can add response variations so that your assistant can respond to the same request in different ways. You can choose to rotate through the response variations sequentially or in random order. For more information, see [Adding variations](https:\/\/cloud.ibm.com\/docs\/watson-assistant\/watson-assistant?topic=watson-assistant-respondrespond-variations).\n\nMicrosoft Teams integration\n: A [Microsoft Teams integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-microsoft-teams) is now available to connect your assistant with the people, content, and tools that your business or community needs to chat, call, and collaborate.\n\n\n\n\n\n 3 February 2023 \n\nAction conditions (beta)\n: An action condition is a boolean test, based on some runtime value; the action executes only if the test evaluates as true. This test can be applied to any variable. By defining action conditions, you can do things such as control user access to actions or create date-specific actions. This is a beta feature that is available for evaluation and testing purposes. For more information, see [Adding conditions to an action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-action-conditions).\n\n\n\n\n\n 2 February 2023 \n\nDetect trigger words (beta)\n: Use the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent, when it\u2019s important for a customer to speak with a live agent rather than activate any further actions. The second group shows customers a customizable warning message, used to discourage customers from interacting with your assistant in unacceptable ways, such as using profanity. This action is included with all new assistants created as of this date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16313-7-2199","score":9.2442922592,"text":"\nProviding options when a question or request can't be answered \n\nNo matter how well your assistant is designed, sometimes customers can run into problems getting it to understand them or do what they want. Your assistant can automatically help customers recover from many such situations, and you can configure how it responds.\n\n\n\n How error conditions are handled \n\nThere are several kinds of error situations your assistant might need to recover from:\n\n\n\n* Your assistant cannot understand your customer's request\n* Your customer does not provide a valid response to a question\n* Your customer asks to talk to a live agent\n\n\n\nYour assistant can detect error conditions and give customers the chance to correct them. In addition, the built-in Fallback action provides a way to automatically connect customers to a live agent if they need more help.\n\n\n\n When the assistant can't understand your customer's request \n\nWhen you build actions, you train your assistant on what your customers might ask for. The Customer starts with section of each action provides examples of customer input that trigger the action; the assistant uses natural language processing to recognize customer input that is similar to these examples. This happens at the beginning of the conversation, or after any action has completed and the assistant is ready for another action.\n\nBut you can't anticipate every possible request, so sometimes customers will send input that your assistant can't match to any action. This might happen because the input isn't phrased in a way that the assistant can understand; it can also happen if customers ask for things that your assistant isn't designed to handle.\n\nUnrecognized input of this sort triggers the built-in No action matches action. To see how this action works, click Set by assistant in the list of actions, and then click No action matches.\n\nZoom\n\n![No action matches built-in action](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/no-action-matches.png)\n\nNo action matches built-in action\n\nBy default, this action has two steps, each step conditioned on the No action matches count session variable.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errors"},{"document_id":"ibmcld_08918-4375-6301","score":8.7233629227,"text":"\nWhy is IBM Cloud Schematics not able to provision the cluster and fails with an error that the provided name is not unique? \n\n What\u2019s happening \n\nSchematics isn't able to provision the cluster, and you are seeing the following example error message:\n\n\"code\": \"validation_unique_failed\",\n\"message\": \"Provided Name (sample-lsf-vpc) is not unique\",\n\"target\": {\n\"name\": \"name\",\n\"type\": \"field\",\n\"value\": \"sample-lsf-vpc\"\n}\n\n Why it\u2019s happening \n\nVPC resource names must be unique. If a resource exists with the same name, you might get a similar error.\n\n How to fix it \n\nDeprovision the existing resource and try again.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to provision the cluster while using a custom image? \n\nWhile using a custom image, Schematics isn't able to provision the cluster, and you are seeing one of the following error messages:\n\n What\u2019s happening \n\n\n\n* The arugment \"image\" is required, but no definition was found.\n* Unknown variable. There is no variable named \"image_id\".\n\n\n\n Why it\u2019s happening \n\nThe custom image that is used for one of the virtual server instances isn't present in the target region and zone or it is not accessible by the account and API key that is used to provision the cluster.\n\n How to fix it \n\nIf you are using a custom image for any of your virtual server instances, ensure that the custom image is available in the target region and zone and is accessible by the account and API key that is used to provision the cluster.\n\n\n\n\n\n Why am I receiving an error for my refresh token? \n\n What\u2019s happening \n\nYou are receiving a refresh token error in the generate a plan, apply a plan, and destroy resources requests: Error: The provided Refresh Token is invalid. Please provide a proper refresh token for Terraform to run the configuration. Code: 400\n\n Why it\u2019s happening \n\nYou didn't provide the correct refresh token, or you didn't provide a refresh token altogether.\n\n How to fix it","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-spectrum-lsf?topic=ibm-spectrum-lsf-troubleshooting-spectrum-lsf"},{"document_id":"ibmcld_12754-0-705","score":8.6199235916,"text":"\n\n\n\n\n\n\n  Why don't I see any results? \n\nYou've created a profile or a rule but don't see any results.\n\n  What\u2019s happening \n\nYou can't find the results for your new profile or rule in your account.\n\n  Why it\u2019s happening \n\nYou might not be able to view results for the following reasons:\n\n\n\n*  Your rule isn't associated with a specification or profile.\n*  Your attachment hasn't been evaluated yet.\n*  An error occurred during the scan.\n\n\n\n  How to fix it \n\nDepending on the reason, you might try one or more of the following options to resolve the issue.\n\n\n\n*  Verify that the attachment is created.\n*  Wait for the scan to run.\n*  Wait 24 hours for the next scan to run, or open a support ticket.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-ts-results"},{"document_id":"ibmcld_12011-6602-7815","score":8.2129192352,"text":"\nProvide a [GitHub token](https:\/\/docs.github.com\/en\/authentication\/keeping-your-account-and-data-secure\/creating-a-personal-access-token) and check to see whether the correct GitHub token has been provided in the github_token parameter in the create workspace or create blueprint API.\n\n\n\n\n\n Why is Schematics not able to clone the public GitHub repository? \n\nSchematics isn't able to clone the public GitHub repository, and you are seeing one of the following error messages:\n\n What\u2019s happening \n\n\n\n* Fatal, could not download repo, Failed to clone git repository, authentication required (or the git url is incorrect). Problems found with the Repository. Please Rectify and Retry\n* Template error: Failed to clone git repository, authentication required (or the git url is incorrect)\n\n\n\n Why it\u2019s happening \n\nYou didn't provide the correct GitHub URL, or you provided a GitHub token, which is not required to clone a public repository. A GitHub access token is only required to access a private repository.\n\n How to fix it \n\nDo not provide a GitHub token, and check to see whether the GitHub token was provided in the github_token parameter while creating a workspace or blueprint by using the public repository.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-create-fails"},{"document_id":"ibmcld_08335-4647-6685","score":8.0351686478,"text":"\nNo, any SSH connection to the bootstrap, compute, or storage nodes is only possible through the bastion node for security reasons. You would use the following command to connect to your bootstrap, compute, or storage nodes (the IP address is specific to your particular node): ssh -J ubuntu@<bastion_IP_address> vpcuser@<IP_address>\n\n\n\n\n\n Can I establish an SSH connection between compute and storage nodes? \n\nThe compute and storage clusters are created to not have the same passwordless SSH keys. This ensures that there are separate administration domains for the compute and storage clusters; therefore, SSH between nodes from different clusters is not possible.\n\n\n\n\n\n Does the Spectrum Scale offering support multiple key_pairs to establish SSH to all of the nodes? \n\nNo, the current version of the Spectrum Scale offering supports only a single key_pair that can be provided for access to all of the nodes that are part of the cluster.\n\n\n\n\n\n Can I use my own resource group to configure the resources? \n\nYes, you can provide the resource group of your choice for the deployment of your cluster's VPC resources. Due to the use of trusted profiles in this offering, you must ensure that all of the key_pair values that are specified in the deployment values are created in the same resource group.\n\n\n\n\n\n Which operating system versions are supported for the images used for the compute and storage nodes in Spectrum Scale? \n\nWith Spectrum Scale, you can use custom or stock images based on RHEL 7.9 or RHEL 8.4. For compute nodes, both RHEL 7.9 or 8.4 can be used. For storage nodes, only RHEL 8.4 is supported.\n\n\n\n\n\n Why does Spectrum Scale not allow use of the default value of 0.0.0.0\/0 for security group creation? \n\nFor security reasons, Spectrum Scale does not allow you to provide a default value that would allow network traffic from any external device. Instead, you can provide the address of your user system (for example, by using [https:\/\/ipv4.icanhazip.com\/](https:\/\/ipv4.icanhazip.com\/)) or a multiple IP address range.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-scale?topic=hpc-spectrum-scale-spectrum-scale-faqs"},{"document_id":"ibmcld_08389-5803-7968","score":8.0029888153,"text":"\nThe mappings can be found in the image-map.tf file and the scale-image-map.tf file in this public [GitHub repository](https:\/\/github.com\/IBM-Cloud\/hpc-cluster-symphony).\n\n\n\n\n\n Why does the egosh command not work if tried immediately after Schematics provisions the cluster? \n\nThis is expected behavior. Even after the Schematics web console shows that the cluster is successfully provisioned, there are still some tasks that run in the background for several minutes. Allow a few minutes (typically 2 minutes is sufficient) after the cluster gets provisioned for egosh to be available.\n\n\n\n\n\n Why does cluster creation using dedicated hosts fail sometimes with the error status of dedicated host is failed? \n\nIn some regions, dedicated hosts have a limitation on the number of virtual server instances that can be placed on them at one time. You can try to provision the cluster with a smaller number of virtual server instances to overcome this.\n\n\n\n\n\n Why does Spectrum Scale not allow use of the default value of 0.0.0.0\/0 for security group creation? \n\nFor security reasons, Spectrum Scale does not allow you to provide a default value that would allow network traffice from any external device. Instead, you can provide the address of your user system (for example, by using [https:\/\/ipv4.icanhazip.com\/](https:\/\/ipv4.icanhazip.com\/)) or a range of multiple IP addresses.\n\n\n\n\n\n Does the Spectrum Symphony offering support multiple key pairs to establish SSH to all of the nodes? \n\nYes, the Spectrum Symphony offering supports multiple single key pairs that can be provided for access to all of the nodes that are part of the cluster. In addition, Spectrum Symphony has a feature where each node of the cluster can be accessed through passwordless SSH.\n\n\n\n\n\n What storage types are available through this offering? \n\nIn the Spectrum Symphony offering, you can use Spectrum Scale scratch storage or persistent storage. A scratch storage configuration uses virtual server instances with instance storage. A persistent storage configuration uses bare metal servers with locally attached NVMe storage.\n\n\n\n\n\n Which Linux operating system is supported for worker nodes?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-symphony?topic=hpc-spectrum-symphony-spectrum-symphony-faqs"},{"document_id":"ibmcld_08391-4563-6492","score":7.7430086136,"text":"\nSchematics isn't able to provision the cluster, and you are seeing the following example error message:\n\n\"code\": \"validation_unique_failed\",\n\"message\": \"Provided Name (sample-symphony-vpc) is not unique\",\n\"target\": {\n\"name\": \"name\",\n\"type\": \"field\",\n\"value\": \"sample-symphony-vpc\"\n}\n\n Why it\u2019s happening \n\nVPC resource names must be unique. If a resource exists with the same name, you might get a similar error.\n\n How to fix it \n\nDeprovision the existing resource and try again.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to provision the cluster while using a custom image? \n\nWhile using a custom image, Schematics isn't able to provision the cluster, and you are seeing one of the following error messages:\n\n What\u2019s happening \n\n\n\n* The argument \"image\" is required, but no definition was found.\n* Unknown variable. There is no variable named \"image_id\".\n\n\n\n Why it\u2019s happening \n\nThe custom image that is used for one of the virtual server instances isn't present in the target region and zone or it is not accessible by the account and API key that is used to provision the cluster.\n\n How to fix it \n\nIf you are using a custom image for any of your virtual server instances, ensure that the custom image is available in the target region and zone and is accessible by the account and API key that is used to provision the cluster.\n\n\n\n\n\n Why am I receiving an error for my refresh token? \n\n What\u2019s happening \n\nYou are receiving a refresh token error in the generate a plan, apply a plan, and destroy resources requests: Error: The provided Refresh Token is invalid. Please provide a proper refresh token for Terraform to run the configuration. Code: 400\n\n Why it\u2019s happening \n\nYou didn't provide the correct refresh token, or you didn't provide a refresh token altogether.\n\n How to fix it \n\nCheck to see whether the refresh token that was generated by using the curl command is correct; otherwise, regenerate the refresh token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-symphony?topic=hpc-spectrum-symphony-troubleshooting-spectrum-symphony"},{"document_id":"ibmcld_08302-1330-3354","score":7.6961393356,"text":"\nYou didn't provide the correct GitHub URL, or you provided a GitHub token, which is not required to clone a public repo. A GitHub access token is only required to access a private repo.\n\n How to fix it \n\nDo not provide a GitHub token, and check to see whether the GitHub token was provided in the github_token parameter while creating a workspace by using the public repo.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to create a workspace? \n\n What\u2019s happening \n\nSchematics isn't able to create a workspace, and you are seeing the following error message: You don't have the required to create a workspace in any resource groups. You must be assigned the manager role on the Schematics service in at least one resource group. Contact your account administrator for access.\n\n Why it\u2019s happening \n\nYou don't have the required access to create a workspace in any resource groups. You must be assigned the manager role on the Schematics service in at least one resource group.\n\n How to fix it \n\nContact your account administrator and get assigned with the manager role on the Schematics service in at least one resource group.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to provision the cluster and fails with an authorization error? \n\n What\u2019s happening \n\nSchematics isn't able to provision the cluster, and you are seeing the following error message: Request is not authorized. Check your user permissions and authorizations and try again.\n\n Why it\u2019s happening \n\nYou don't have the required access to get any VPC resources provisioned.\n\n How to fix it \n\nContact your account administrator and get all of the required accesses. For more information, see [Required permissions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resource-authorizations-required-for-api-and-cli-calls).\n\n\n\n\n\n Why is IBM Cloud Schematics not able to provision the cluster and fails with an error that the provided name is not unique? \n\n What\u2019s happening \n\nSchematics isn't able to provision the cluster, and you are seeing the following example error message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-slurm?topic=hpc-slurm-troubleshooting-slurm"},{"document_id":"ibmcld_08266-1330-3354","score":7.6961393356,"text":"\nYou didn't provide the correct GitHub URL, or you provided a GitHub token, which is not required to clone a public repo. A GitHub access token is only required to access a private repo.\n\n How to fix it \n\nDo not provide a GitHub token, and check to see whether the GitHub token was provided in the github_token parameter while creating a workspace by using the public repo.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to create a workspace? \n\n What\u2019s happening \n\nSchematics isn't able to create a workspace, and you are seeing the following error message: You don't have the required to create a workspace in any resource groups. You must be assigned the manager role on the Schematics service in at least one resource group. Contact your account administrator for access.\n\n Why it\u2019s happening \n\nYou don't have the required access to create a workspace in any resource groups. You must be assigned the manager role on the Schematics service in at least one resource group.\n\n How to fix it \n\nContact your account administrator and get assigned with the manager role on the Schematics service in at least one resource group.\n\n\n\n\n\n Why is IBM Cloud Schematics not able to provision the cluster and fails with an authorization error? \n\n What\u2019s happening \n\nSchematics isn't able to provision the cluster, and you are seeing the following error message: Request is not authorized. Check your user permissions and authorizations and try again.\n\n Why it\u2019s happening \n\nYou don't have the required access to get any VPC resources provisioned.\n\n How to fix it \n\nContact your account administrator and get all of the required accesses. For more information, see [Required permissions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resource-authorizations-required-for-api-and-cli-calls).\n\n\n\n\n\n Why is IBM Cloud Schematics not able to provision the cluster and fails with an error that the provided name is not unique? \n\n What\u2019s happening \n\nSchematics isn't able to provision the cluster, and you are seeing the following example error message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-openshift?topic=hpc-openshift-troubleshooting-hpc-openshift"},{"document_id":"ibmcld_10143-7-2020","score":7.5417098999,"text":"\nWhy can't I view or work with my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n What\u2019s happening \n\nYou are not able to find a cluster. When you run ibmcloud oc cluster ls, the cluster is not listed in the output.\n\nOr, you are not able to work with a cluster. When you run ibmcloud oc cluster config or other cluster-specific commands, the cluster is not found.\n\n Why it\u2019s happening \n\nIn IBM Cloud, each resource must be in a resource group. For example, cluster mycluster might exist in the default resource group.\n\nWhen the account owner gives you access to resources by assigning you an IBM Cloud IAM platform access role, the access can be to a specific resource or to the resource group. When you are given access to a specific resource, you don't have access to the resource group. In this case, you don't need to target a resource group to work with the clusters you have access to. If you target a different resource group than the group that the cluster is in, actions against that cluster can fail. Conversely, when you are given access to a resource as part of your access to a resource group, you must target a resource group to work with a cluster in that group. If you don't target your CLI session to the resource group that the cluster is in, actions against that cluster can fail.\n\nIf you can't find or work with a cluster, you might be experiencing one of the following issues:\n\n\n\n* You have access to the cluster and the resource group that the cluster is in, but your CLI session is not targeted to the resource group that the cluster is in.\n* You have access to the cluster, but not as part of the resource group that the cluster is in. Your CLI session is targeted to this or another resource group.\n* You don't have access to the cluster.\n\n\n\n How to fix it \n\nTo check your user access permissions:\n\n\n\n1. List all your user permissions.\n\nibmcloud iam user-policies <your_user_name>\n2. Check if you have access to the cluster and to the resource group that the cluster is in.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cluster_access"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02882-7-2075","score":19.058095932,"text":"\nBuilding a conversational flow \n\nThe dialog defines what your assistant says in response to customers.\n\n\n\n Creating a dialog \n\nTo create a dialog, complete the following steps:\n\n\n\n1. Click the Dialog tab, and then click Create dialog.\n\nWhen you open the dialog editor for the first time, the following nodes are created for you:\n\n\n\n* Welcome: The first node. It contains a greeting that is displayed to your users when they first engage with your assistant. You can edit the greeting.\n\n\n\nThis node is not triggered in dialog flows that are initiated by users. For example, dialogs that are deployed in environments such as messaging channels where customers start the conversation do not process nodes with the welcome special condition.\n\n\n\n* Anything else: The final node. It contains phrases that are used to reply to users when their input is not recognized. You can replace the responses that are provided or add more responses with a similar meaning to add variety to the conversation. You can also choose whether you want your assistant to return each response that is defined in turn or return them in random order.\n\n\n\n2. To add more nodes to the dialog tree, click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) icon on the Welcome node, and then select Add node below.\n3. In the If assistant recognizes field, enter a condition that, when met, triggers your assistant to process the node.\n\nTo start off, you typically want to add an intent as the condition. For example, if you add open_account here, it means that you want the response that you will specify in this node to be returned to the user if the user input indicates that the user wants to open an account.\n\nAs you begin to define a condition, a box is displayed that shows you your options. You can enter one of the following characters, and then pick a value from the list of options that is displayed.\n\n\n\nCondition builder syntax\n\n Character Lists defined values for these artifact types \n\n `#` intents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_02998-8791-9815","score":19.0038261414,"text":"\nYou created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:\n\n\n\n* Add standard nodes with the [Building a complex dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial) tutorial.\n* Learn about slots with the [Adding a node with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots) tutorial.\n\n\n\n* Check out more [sample apps](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-sample-apps) to get ideas.\n\n\n\nWhen you're ready to deploy your assistant, see [Deploying](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-custom-app).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03184-4760-6417","score":17.6968269348,"text":"\nUse the following syntax to define the client action you want to request.\n\n{\n\"context\": {\n\"variable_name\" : \"variable_value\"\n},\n\"actions\": [\n{\n\"name\":\"<actionName>\",\n\"type\":\"client\",\n\"parameters\": {\n\"<parameter_name>\":\"<parameter_value>\",\n\"<parameter_name>\":\"<parameter_value>\"\n},\n\"result_variable\": \"<result_variable_name>\"\n}\n],\n\"output\": {\n\"text\": \"response text\"\n}\n}\nShow more\n\nThe actions array specifies the actions you want the client application to carry out. It can define up to five separate actions. Specify the following name and value pairs in the JSON array:\n\n\n\n* <actionName>: Required. The name of the action you want the client application to perform. This name can be in any format (for example, calculateRate or get_balance), but it must be a name that your client application will recognize and know how to handle. The name cannot be longer than 256 characters.\n* <type>: Indicates the type of call to make. For a client action, this property is optional (client is the default value).\n* <action_parameters>: Any parameters that are required for the client action, which are specified as a JSON object. If the action does not require any parameters, omit this property.\n* <result_variable_name>: The name of the context variable you want to use to store the JSON object that is returned by the client action. The client application is expected to use the specified variable to send the return value in the context of the next \/message input, and subsequent dialog nodes can then access it. You can specify the result_variable_name by using the following syntax:\n\n\n\n* my_result\n* $my_result\n\n\n\nThe name cannot be longer than 64 characters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-actions-client"},{"document_id":"ibmcld_16263-1764-3458","score":17.3792705536,"text":"\nIf you have an existing application that uses the v1 API to send user input directly to a workspace, migrating your app to use the v2 API is a straightforward process.\n\n\n\n\n\n Assistant ID \n\nThe v2 runtime API sends messages to an assistant. On the Assistant Settings page, find the assistant ID. Your application uses this ID to communicate with the assistant. The service credentials are the same for both the v1 and v2 APIs.\n\nCurrently, there is no API support for retrieving an assistant ID. To find the assistant ID, you must use the Watson Assistant user interface.\n\n\n\n\n\n Call the v2 runtime API \n\nAfter you create an assistant, you can update your client application to use the v2 runtime API instead of the v1 runtime API.\n\n\n\n1. Before sending the first message in a conversation, use the v2 [Create a session](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2createsession) method to create a session. Save the returned session ID:\n\n\n\n* Java\n* Python\n* Node\n\n\n\nCreateSessionOptions createSessionOptions = new CreateSessionOptions.Builder(assistantId).build();\nSessionResponse session = service.createSession(createSessionOptions).execute().getResult();\nString sessionId = session.getSessionId();\n\nsession_id = service.create_session(\nassistant_id = assistant_id\n).get_result()['session_id']\n\nservice\n.createSession({\nassistant_id: assistantId,\n})\n.then(res => {\nsessionId = res.session_id;\n})\n2. Use the v2 [Send user input to assistant](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2message) method to send user input to the assistant. Instead of specifying the workspace ID as you did with the v1 API, you specify the assistant ID and the session ID:\n\n\n\n* Java\n* Python\n* Node","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-migration"},{"document_id":"ibmcld_02850-0-1147","score":17.0321464539,"text":"\n\n\n\n\n\n\n  Integrating with a custom application \n\nBuild your own client application as the interface between the assistant and your customers.\n\nTo use the API, you need to construct the URL to use in your requests.\n\n\n\n1.  From the IBM Cloud Pak for Data web client, go to the details page for the provisioned instance.\n2.  Copy the URL from the \"Access information\" section of the page. You will specify this value as the {url}.\n\nYou might want to copy the bearer token also. You will need to pass the token when you make an API call.\n3.  From the launched application instance, go to the Assistants page. Click the More options menu for the assistant you want to use, and click Settings.\n4.  Click API details, and then copy the assistant ID. You will specify this value as the {assistant_id}.\n5.  Build a URL by using the IDs you copied. For example, the following request creates a session:\n\ncurl -H \"Authorization: Bearer eyJhb<snip>yA9g\" -X POST \"{url}\/v2\/assistants\/{assistant_id}\/sessions?version=2020-04-01 -k\"\n\n\n\n\n\n*  For API reference documentation, see [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-data-v2).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-custom-app"},{"document_id":"ibmcld_03916-39203-41294","score":16.9443378448,"text":"\nSuccessfully enrolled client \"user1\" and imported it into the wallet\n\nYou can find the wallet that was created in the identity folder of the magnetocorp directory.\n\n\n\n\n\n Step four: Use the connection profile to build a Fabric gateway \n\nThe Hyperledger Fabric [Transaction Flow](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/txflow.html) spans multiple components, with the client applications playing a unique role. Your application needs to connect to the peers that need to endorse the transaction and needs to connect to the ordering service that will order the transaction and add it into a block. You can provide the endpoints of these nodes to your application by using your connection profile to construct a Fabric gateway. The gateway then conducts the low-level interactions with your Fabric network. To learn more, visit the [Fabric gateway](https:\/\/hyperledger-fabric.readthedocs.io\/en\/release-2.2\/developapps\/gateway.html) topic in the Fabric documentation.\n\nYou have already downloaded your connection profile and used it to connect to your organization's Certificate Authority. Now we use the connection profile to build a gateway.\n\nOpen the file issue.js in a text editor. Before you edit the file, notice that it imports the FileSystemWallet and Gateway classes from fabric-network library.\n\nconst { FileSystemWallet, Gateway } = require('fabric-network')\n\nYou will need to import the path class to build the gateway from the connection profile you downloaded from your console. Add the following line to the file to import the path class:\n\nconst path = require('path');\n\nThe Gateway class is used to construct a gateway that you will use to submit your transaction.\n\nconst gateway = new Gateway()\n\nThe FileSystemWallet class is used to load the wallet you created in the previous step. Edit the following line if you changed the location of the wallet on your file system.\n\nconst wallet = new FileSystemWallet('..\/identity\/user\/isabella\/wallet');\n\nAfter you import your wallet, use the following code to pass your connection profile and wallet to the new gateway.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app"},{"document_id":"ibmcld_03966-3327-5475","score":16.7914104462,"text":"\n* Org admins: When you join a consortium that is hosted by an ordering service, you provide the signing certificates of identities that will become the administrators for your organization. You can use these identities to create or edit channels.\n* Peer or orderer admins: IBM Blockchain Platform nodes are deployed with the signing certificates of component administrators identities inside of them. These certificates allow the admins to operate the component from a remote client or by using the console.\n* Applications: Your applications need to sign their transactions before submitting them to be validated by the network. You need to create identities you can use to sign transactions from your client applications.\n\n\n\nYou can use the console to create these identities by using the [registration process](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identitiesibp-console-identities-register). After you register your admin identities, you need to issue each identity a signing certificate and private key, provide the signing certificate to your organization MSP definition, and add the identity to your console wallet. You can complete these steps for one admin identity when you [create your organization MSP](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-organizationsconsole-organizations-create-msp). You can use separate identities as org admins or node admins, or you can use one identity to do both tasks. The [Build a network tutorial](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-networkibp-console-build-network) uses one identity to be an admin for each organization created in the tutorial.\n\n\n\n\n\n Associating the identity of the CA admin \n\nBefore you can create identities, you need to associate the identity of the CA admin. Open your CA on the Nodes tab. If you are using the CA for the first time, you can click the Associate identity button to generate the CA admin identity and import it into your console wallet. On the Associate identity side panel, provide the Enroll ID and Enroll secret of the CA admin that you provided when you created the CA.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_02952-7-2097","score":16.7262592316,"text":"\nConnecting customers with support \n\nNo matter where you deploy your assistant, give your customers a way to get additional support when they need it.\n\nBuild your dialog to recognize when customers need help that cannot be provided by the assistant. Add logic that can connect your customers to whatever type of professional support you offer. Your solutions might include:\n\n\n\n* A toll-free phone number to a call center that is manned by human agents\n* An online support ticket form that customers fill out and submit\n* A service desk solution that is configured to work with your custom client application. The built-in Zendesk and Salesforce integrations aren\u2019t supported.\n\n\n\nDesign your dialog to recognize customer requests for help and address them. Add an intent that understands the customer request, and then add a dialog branch that handles the request.\n\nYou might add an intent and use it in a dialog node like these example intents:\n\n\n\nAlternative support request intent examples\n\n Intent name Intent user example 1 Intent user example 2 Response from dialog node that conditions on intent \n\n call_support How do I reach support? What's your toll-free number? Call 1-800-555-0123 to reach a call center agent at any time. \n support_ticket How do I get help? Who can help me with an issue I'm having? Go to [Support Center](https:\/\/example.com\/support) and open a support ticket. \n\n\n\n\n\n Adding chat transfer support \n\nDesign your dialog so that it can transfer customers to human agents. Consider adding support for initiating a transfer in the following scenarios:\n\n\n\n* Any time a user asks to speak to a person.\n\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_02898-0-1202","score":16.5459003448,"text":"\n\n\n\n\n\n\n  Planning the dialog \n\nLearn how to approach building a dialog.\n\n\n\n*  Plan out the design of the dialog that you want to build before you add a single dialog node. Sketch it out on paper, if necessary.\n*  Whenever possible, base your design decisions on data from real-world evidence and behaviors. Do not add nodes to handle a situation that someone thinks might occur.\n*  Avoid copying business processes as-is. They are rarely conversational.\n*  If people already use a process, examine how they approach it. People typically optimize the process from a conversational perspective.\n*  Decide on the tone, personality, and positioning of your assistant. Consistently reflect these choices in the dialog you create.\n*  Never misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it.\n*  Not everything has to be a conversation. Sometimes a web form works better.\n\n\n\nPrevious topic:[Dialog overview](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build)\n\nNext topic:[Building a conversational flow](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview)\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-plan"},{"document_id":"ibmcld_03916-20630-22092","score":16.4944152832,"text":"\nOnce the network operator provides the enroll ID and secret of the application identity and the network connection profile, an application developer can use the Fabric SDKs or the Fabric CA client to generate client-side certificates. You can use the following steps to enroll an application identity by using the [Fabric SDK for Node.js](https:\/\/hyperledger.github.io\/fabric-sdk-node\/release-2.2\/index.html).\n\n\n\n1. Save the connection profile to your local system and rename it connection.json.\n2. Save the following code block as enrollUser.js in the same directory as your connection profile:\n\n'use strict';\n\nconst FabricCAServices = require('fabric-ca-client');\nconst { FileSystemWallet, X509WalletMixin } = require('fabric-network');\nconst fs = require('fs');\nconst path = require('path');\n\nconst ccpPath = path.resolve(__dirname, 'connection.json');\nconst ccpJSON = fs.readFileSync(ccpPath, 'utf8');\nconst ccp = JSON.parse(ccpJSON);\n\nasync function main() {\ntry {\n\n\/\/ Create a new CA client for interacting with the CA.\nconst caURL = ccp.certificateAuthorities['<CA_Name>'].url;\nconst ca = new FabricCAServices(caURL);\n\n\/\/ Create a new file system based wallet for managing identities.\nconst walletPath = path.join(process.cwd(), 'wallet');\nconst wallet = new FileSystemWallet(walletPath);\nconsole.log(Wallet path: ${walletPath});\n\n\/\/ Check to see if we've already enrolled the admin user.\nconst userExists = await wallet.exists('user1');\nif (userExists) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.296081911,"ndcg_cut_10":0.296081911}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06030-8682-10315","score":14.8345575333,"text":"\nVerify that you can access the public IP address the worker node through the node port. Note: Because worker nodes in VPC clusters don't have a public IP address, you can access an app through a NodePort only if you are connected to your private VPC network, such as through a VPN connection. Then, you can use the worker node's private IP address and NodePort: <worker_private_IP>:<NodePort>.\n\ncurl --connect-timeout 10 <worker_IP>:<NodePort>\n\nThe following example output confirms that the request to your app came through the private IP address 10.1.1.1 for the worker node and the 31024 node port. The webserver-855556f688-xd849 app pod received the curl request:\n\nHostname: webserver-855556f688-xd849\nPod Information:\n-no pod information available-\nServer values:\nserver_version=nginx: 1.13.3 - lua: 10008\nRequest Information:\nclient_address=1.1.1.1\nmethod=GET\nreal path=\/\nquery=\nrequest_version=1.1\nrequest_scheme=http\nrequest_uri=http:\/\/10.1.1.1:8080\/\nRequest Headers:\naccept=\/\nhost=10.1.1.1:31024\nuser-agent=curl\/7.60.0\nRequest Body:\n-no body in request-\n\n\n\n\n\nAt this point, your app is exposed from multiple IP addresses and ports. Most of these IPs are internal to the cluster and can be accessed only over the private network. Only the public node port and public NLB port are exposed to the public internet.\n\nNext, you can start creating and applying Calico policies to block public traffic.\n\n\n\n\n\n Step 2: Block all incoming traffic to all node ports \n\nTo secure the PR firm's cluster, you must block public access to both the NLB service and node ports that are exposing your app. Start by blocking access to node ports.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-policy_tutorial"},{"document_id":"ibmcld_10510-17837-19983","score":14.3781080246,"text":"\nWorker nodes carry the deployments and services that make up your app. When you host workloads in the public cloud, you want to ensure that your app is protected from being accessed, changed, or monitored by an unauthorized user or software.\n\n\n\n Who owns the worker node and am I responsible to secure it? \n\nThe ownership of a worker node depends on the type of cluster that you create and the infrastructure provider that you choose.\n\n\n\n* Classic clusters: Worker nodes are provisioned in to your IBM Cloud account. The worker nodes are dedicated to you and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n* VPC clusters: Worker nodes are provisioned in to an IBM Cloud account that is owned by IBM to enable monitoring of malicious activities and apply security updates. You can't access your worker nodes by using the VPC dashboard. However, you can manage your worker nodes by using the IBM Cloud Kubernetes Service console, CLI, or API. The virtual machines that make up your worker nodes are dedicated to you and you are responsible to request timely updates so that your worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n\n\n\nFor more information, see [Your responsibilities by using Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iks).\n\nUse the ibmcloud oc worker update[command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_update) regularly (such as monthly) to deploy updates and security patches to the operating system and to update the Red Hat OpenShift version that your worker nodes run. When updates are available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the ibmcloud oc clusters ls or ibmcloud oc workers ls --cluster <cluster_name> commands. Worker node updates are provided by IBM as a full worker node image that includes the latest security patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_06079-10297-12436","score":14.0134849548,"text":"\nWorker node With IBM Cloud Kubernetes Service, the virtual machines that your cluster manages are instances that are called worker nodes. These worker nodes virtual machines and all the worker node components are dedicated to you only and are not shared with other IBM customers. However, the underlying hardware is shared with other IBM customers. For more information, see [Virtual machines](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesvm). You manage the worker nodes through the automation tools that are provided by IBM Cloud Kubernetes Service, such as the API, CLI, or console. Unlike classic clusters, you don't see VPC compute worker nodes in your infrastructure portal or separate infrastructure bill, but instead manage all maintenance and billing activity for the worker nodes from IBM Cloud Kubernetes Service. Worker nodes include the same [components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-archworker-components) as described in the Classic architecture. Community Kubernetes worker nodes run on Ubuntu 18.04 x86_64, 16.04 x86_64 (deprecated). \n Cluster networking Your worker nodes are created in a VPC subnet in the zone that you specify. By default, the public and private cloud service endpoints for your cluster are enabled. Communication between the master and worker nodes is over the private network. Authenticated external users can communicate with the master over the public network, such as to run kubectl commands. You can optionally set up your cluster to communicate with on-prem services by setting up a VPC VPN on the private network. \n App networking You can create a Kubernetes LoadBalancer service for your apps in the cluster, which automatically provisions a VPC load balancer in your VPC outside the cluster. The load balancer is multizonal and routes requests for your app through the private NodePorts that are automatically opened on your worker nodes. For more information, see [Exposing apps with VPC load balancers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-lbaas). Calico is used as the cluster networking policy fabric.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch"},{"document_id":"ibmcld_06079-4312-6353","score":13.9531793594,"text":"\nOut of the box, your worker nodes are set up with an IBM-managed container runtime, separate compute resources, networking, and a volume service. The built-in security features provide isolation, resource management capabilities, and worker node security compliance.\n\nThe worker nodes and all the worker node components are dedicated only to you, and are not shared with other IBM customers. However, if you use a worker node virtual machine, the underlying hardware might be shared with other customers depending on the level of hardware isolation that you choose. For more information, see [Virtual machines](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesvm).\n\nModifying default worker node components such as the kubelet is not supported and might cause unexpected results.\n\nThe following tables describe the components of a worker node.\n\n\n\n\n\n kube-system namespace \n\nibm-master-proxy\n: The ibm-master-proxy forwards requests from the worker node to the IP addresses of the highly available master replicas. In single zone clusters, the master has three replicas on separate hosts with one master IP address and domain name. For clusters that are in a multizone-capable zone, the master has three replicas that are spread across zones. As such, each master has its own IP address that is registered with DNS, with one domain name for the entire cluster master.\n\nkonnectivity-agent\n: The Konnectivity agent works with the Konnectivity server to securely connect the master to the worker node. This connection supports apiserver proxy calls to your pods and services, and kubectl exec, attach, and logs calls to the kubelet.\n\nkubelet\n: The kubelet is a pod that runs on every worker node and is responsible for monitoring the health of pods that run on the worker node and for watching the events that the Kubernetes API server sends. Based on the events, the kubelet creates or removes pods, ensures liveness and readiness probes, and reports back the status of the pods to the Kubernetes API server.\n\ncoredns","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch"},{"document_id":"ibmcld_05970-12311-13510","score":13.7790708542,"text":"\nIn this example, the NLB has a virtual IP address of 169.61.23.130 and runs on the worker node that has the 10.73.13.25 private IP address. Requests are handled by the NLBs in various zones in a round-robin cycle.\n3. The NLB encapsulates the client request packet (labeled as \"CR\" in the image) inside an IPIP packet (labeled as \"IPIP\"). The client request packet retains the client IP as its source IP address. The IPIP encapsulating packet uses the worker 10.73.14.25 IP as its source IP address.\n4. The NLB routes the IPIP packet to a worker that an app pod is on and that has the private IP address 10.73.13.26. Note that each NLB routes requests to the app instances in its own zone and to app instances in other zones. Additionally, if multiple app instances are deployed in one zone, the NLB routes the requests between the app pods in the zone.\n5. Worker 10.73.14.26 unpacks the IPIP encapsulating packet, and then unpacks the client request packet. The client request packet is forwarded to the app pod on that worker node.\n6. Worker 10.73.14.26 then uses the source IP address from the original request packet, the client IP, to return the app pod's response packet directly to the client.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-loadbalancer-about"},{"document_id":"ibmcld_06063-18145-20200","score":13.67100811,"text":"\n* VPC clusters: Worker nodes are provisioned in to an IBM Cloud account that is owned by IBM to enable monitoring of malicious activities and apply security updates. You can't access your worker nodes by using the VPC dashboard. However, you can manage your worker nodes by using the IBM Cloud Kubernetes Service console, CLI, or API. The virtual machines that make up your worker nodes are dedicated to you and you are responsible to request timely updates so that your worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n\n\n\nFor more information, see [Your responsibilities by using IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks).\n\nUse the ibmcloud ks worker update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_update) regularly (such as monthly) to deploy updates and security patches to the operating system and to update the Kubernetes version that your worker nodes run. When updates are available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the ibmcloud ks clusters ls or ibmcloud ks workers ls --cluster <cluster_name> commands. Worker node updates are provided by IBM as a full worker node image that includes the latest security patches. To apply the updates, the worker node must be reimaged and reloaded with the new image. Keys for the root user are automatically rotated when the worker node is reloaded.\n\n\n\n\n\n How does my worker node setup look? \n\nThe following image shows the components that are set up for every worker node to protect your worker node from malicious attacks.\n\nThe image does not include components that ensure secure end-to-end communication to and from the worker node. For more information, see [network security](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork).\n\nZoom\n\n![Worker node setup in IBM Cloud Kubernetes Service excluding network security.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_10208-27425-28322","score":13.6550788879,"text":"\nIf you disable or delete the root key, your worker nodes enter a critical state until you restore the root key and [reboot](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_reboot) the worker nodes.\n\n\n\nThe encryption for the disks of the worker nodes in your worker pool are now managed by the root key in your KMS provider. If you created a cluster, the worker pool is the default worker pool.\n\n\n\n\n\n Satellite worker nodes \n\nSatellite: The encryption of the OS disk and secondary disk is managed at the IAAS layer of the platform Satellite is deployed on. The encryption of persistent storage volumes utilized within the cluster is managed at the persistent storage plug-in level and backing storage device level. For more information about encryption for storage devices or plug-ins, see the device provider documentation or the storage plug-in documentation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-encryption"},{"document_id":"ibmcld_10414-3274-5177","score":13.4482851028,"text":"\nIn your VPC infrastructure dashboard, the VPC load balancer reports as healthy only the two worker nodes that run the Ingress controller replica pods, because these worker nodes are configured as the listeners for the VPC load balancer. Even though only the listener worker nodes are reported as healthy, the listeners' backend pool of worker nodes is kept up-to-date by Red Hat OpenShift on IBM Cloud so that all worker nodes in your cluster can still receive requests from the VPC load balancer.\n\n\n\n Traffic flow in a classic single-zone cluster \n\nThe following diagram shows how a router directs network traffic from the internet to an app in a single-zone, classic cluster.\n\nZoom\n\n![Expose an app in a single-zone Red Hat OpenShift cluster by using a router](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/openshift\/images\/roks-router.png)\n\nFigure 1. Expose an app in a single-zone cluster by using a router\n\n\n\n1. A request to your app uses the route hostname that you set up for your app.\n2. A DNS service resolves the subdomain to the portable public IP address of router service.\n3. The router receives the request, and forwards it to the private IP address of the app pod over the private network. The source IP address of the request package is changed to the public IP address of the worker node where the router pod runs. If multiple app instances are deployed in the cluster, the router sends the requests between the app pods.\n4. When the app returns a response packet, it uses the IP address of the worker node where the router that forwarded the client request exists. The router then sends the response packet through the load balancer service to the client.\n\n\n\n\n\n\n\n Traffic flow in a classic multizone cluster \n\nThe following diagram shows how a router directs network traffic from the internet to an app in a multizone, classic cluster.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_routes"},{"document_id":"ibmcld_06010-7-1853","score":13.3249702454,"text":"\nPlanning your worker node setup \n\nIBM Cloud\u00ae Kubernetes Service provides different worker node flavors and isolation levels so that you can choose the flavor and isolation that best meet the requirements of the workloads that you want to run in the cloud.\n\nA worker node flavor describes the compute resources, such as CPU, memory, and disk capacity that you get when you provision your worker node. Worker nodes of the same flavor are grouped in worker node pools. The total number of worker nodes in a cluster determine the compute capacity that is available to your apps in the cluster.\n\nWant to save on your classic worker node costs? [Create a reservation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-reservations) to lock in a discount over 1 or 3 year terms! Then, create your worker pool by using the reserved instances. Note that autoscaling can't be enable on worker pools that use reservations.\n\nTrying to plan how many worker nodes your need in your cluster? Check out [Sizing your Kubernetes cluster to support your workload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategysizing) to find information about the default worker node setup and how you can determine the resource requirements of your workloads.\n\n\n\n Available hardware for worker nodes \n\nThe worker node flavors and isolation levels that are available to you depend on your container platform, cluster type, the infrastructure provider that you want to use, and the IBM Cloud Kubernetes Service location where you want to create your cluster.\n\nZoom\n\n![Hardware options for worker nodes in a standard cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/cs_clusters_hardware.png)\n\nFigure 1. Hardware options for worker nodes in a standard cluster\n\n\n\n What flavors are available to me?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodes"},{"document_id":"ibmcld_06007-29613-30996","score":13.286356926,"text":"\nIf your app workload requires other IBM Cloud services that support private cloud service endpoints, your worker nodes can automatically, securely communicate with these services over the private VPC network.\n\n\n\n\n\n External communication to apps that run on worker nodes \n\nAfter you test your app, you can expose it to the private network by creating a private Kubernetes LoadBalancer service or using the default private Ingress application load balancers (ALBs). The VPC load balancer that is automatically created in your VPC outside of your cluster when you use one of these services routes traffic to your app. Note that the VPC load balancer exposes your app to the private network only so that any on-premises system with a connection to the VPC subnet can access the app. You can improve the security of your cluster and control public traffic apps by modifying the default VPC security group for your cluster. Security groups consist of rules that define which inbound traffic is permitted for your worker nodes.\n\nReady to get started with a cluster for this scenario? After you plan your [high availability](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clusters) and [worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodes) setups, see [Creating VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusters).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basics"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.530721274,"ndcg_cut_10":0.6978817289}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10510-41925-44031","score":20.487197876,"text":"\nVPC clusters: VPC security groups are applied to the network interface of a single virtual server to filter traffic at the hypervisor level. You can add inbound and outbound rules to the default security group for your cluster to manage inbound and outbound traffic to a VPC cluster. For more information about the security groups, including the default settings, see [Controlling traffic with VPC security groups](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group&interface=ui).\n\nBecause the worker nodes of your VPC cluster exist in a service account and are not listed in the VPC infrastructure dashboard, you can't create a security group and apply it to your worker node instances. You can only modify existing security groups that are created for you.\n\n\n\n\n\n How can I do TLS termination with LoadBalancer and Ingress services? \n\nThe Ingress service offers TLS termination at two points in the traffic flow:\n\n\n\n* Decrypt package upon arrival: By default, the Ingress ALB load balances HTTP network traffic to the apps in your cluster. To also load balance incoming HTTPS connections, you can configure the ALB to decrypt the network traffic and forward the decrypted request to the apps that are exposed in your cluster. If you use the IBM-provided Ingress subdomain, you can use the IBM-provided TLS certificate. If you use a custom domain, you can use your own TLS certificate to manage TLS termination.\n* [Re-encrypt package before you forward it to upstream apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-comm-ingress-annotationsssl-services-support): The ALB decrypts HTTPS requests before forwarding traffic to your apps. If you have apps that require HTTPS and need traffic to be encrypted before it is forwarded to those upstream apps, you can use the ssl-services annotation. If your upstream apps can handle TLS, you can optionally provide a certificate that is contained in a one-way or mutual-authentication TLS secret.\n\n\n\n\n\n\n\n\n\n Persistent storage \n\nReview supported options for encrypting and protecting your data on persistent storage in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_06007-7-1994","score":20.2188835144,"text":"\nUnderstanding network basics of VPC clusters \n\nWhen you create your cluster, you must choose a networking setup so that certain cluster components can communicate with each other and with networks or services outside of the cluster.\n\n\n\n* [Worker-to-worker communication](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-worker-worker): All worker nodes must be able to communicate with each other on the private network through VPC subnets.\n* [Worker-to-master and user-to-master communication](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-workeruser-master): Your worker nodes and your authorized cluster users can communicate with the Kubernetes master securely over virtual private endpoints or cloud service endpoints.\n* [Worker communication to other services or networks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-worker-services-onprem): Allow your worker nodes to securely communicate with other IBM Cloud services, such as IBM Cloud\u00ae Container Registry, to on-premises networks, to other VPCs, or to classic infrastructure resources.\n* [External communication to apps that run on worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-external-workers): Allow public or private requests into the cluster as well as requests out of the cluster to a public endpoint.\n\n\n\n\n\n Worker-to-worker communication using VPC subnets \n\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basics"},{"document_id":"ibmcld_10442-7-1871","score":20.0618419647,"text":"\nUnderstanding network basics of VPC clusters \n\nWhen you create your cluster, you must choose a networking setup so that certain cluster components can communicate with each other and with networks or services outside of the cluster.\n\n\n\n* [Worker-to-worker communication](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basicsvpc-worker-worker): All worker nodes must be able to communicate with each other on the private network through VPC subnets.\n* [Worker-to-master and user-to-master communication](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basicsvpc-workeruser-master): Your worker nodes and your authorized cluster users can communicate with the Kubernetes master securely over virtual private endpoints or cloud service endpoints.\n* [Worker communication to other services or networks](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basicsvpc-worker-services-onprem): Allow your worker nodes to securely communicate with other IBM Cloud services, such as IBM Cloud\u00ae Container Registry, to on-premises networks, to other VPCs, or to classic infrastructure resources.\n* [External communication to apps that run on worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basicsvpc-external-workers): Allow public or private requests into the cluster as well as requests out of the cluster to a public endpoint.\n\n\n\n\n\n Worker-to-worker communication using VPC subnets \n\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basics"},{"document_id":"ibmcld_06294-7-1823","score":19.8647975922,"text":"\nCreating a cluster in your Virtual Private Cloud (VPC) \n\nCreate an IBM Cloud\u00ae Kubernetes Service cluster in your Virtual Private Cloud (VPC).\n\nWith IBM Cloud Kubernetes Service clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc). VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of IBM Cloud Kubernetes Service [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality. You can create only standard clusters for VPC.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create an IBM Cloud Kubernetes Service cluster in a Virtual Private Cloud (VPC). Then, you deploy an app and expose the app publicly by using a load balancer.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in IBM Cloud Kubernetes Service in VPC for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.\n\nPermissions\n: If you are the account owner, you already have the required permissions to create a cluster and can continue to the next step. Otherwise, ask the account owner to [set up the API key and assign you the minimum user permissions in IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_referencecluster_create_permissions).\n\nCommand-line tools\n: For quick access to your resources from the command line, try the [IBM Cloud Shell](https:\/\/cloud.ibm.com\/shell). Otherwise, set up your local command-line environment by completing the following steps.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc_ks_tutorial"},{"document_id":"ibmcld_16098-7-1823","score":19.8647975922,"text":"\nCreating a cluster in your Virtual Private Cloud (VPC) \n\nCreate an IBM Cloud\u00ae Kubernetes Service cluster in your Virtual Private Cloud (VPC).\n\nWith IBM Cloud Kubernetes Service clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc). VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of IBM Cloud Kubernetes Service [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality. You can create only standard clusters for VPC.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create an IBM Cloud Kubernetes Service cluster in a Virtual Private Cloud (VPC). Then, you deploy an app and expose the app publicly by using a load balancer.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in IBM Cloud Kubernetes Service in VPC for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.\n\nPermissions\n: If you are the account owner, you already have the required permissions to create a cluster and can continue to the next step. Otherwise, ask the account owner to [set up the API key and assign you the minimum user permissions in IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_referencecluster_create_permissions).\n\nCommand-line tools\n: For quick access to your resources from the command line, try the [IBM Cloud Shell](https:\/\/cloud.ibm.com\/shell). Otherwise, set up your local command-line environment by completing the following steps.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc_ks_tutorial"},{"document_id":"ibmcld_10442-1449-3496","score":19.7948055267,"text":"\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone. After the worker node is provisioned, the worker node IP address persists after a reboot operation, but the worker node IP address changes after replace and update operations.\n\nSubnets provide a channel for connectivity among the worker nodes within the cluster. Additionally, any system that is connected to any of the private subnets in the same VPC can communicate with workers. For example, all subnets in one VPC can communicate through private layer 3 routing with a built-in VPC router. If you have multiple clusters that must communicate with each other, you can create the clusters in the same VPC. However, if your clusters don't need to communicate, you can achieve better network segmentation by creating the clusters in separate VPCs. You can also create [access control lists (ACLs)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-acls) for your VPC subnets to mediate traffic on the private network. ACLs consist of inbound and outbound rules that define which ingress and egress is permitted for each VPC subnet.\n\nWhen you create a VPC cluster and enable both the public and private cloud service endpoints during cluster creation, the public cloud service endpoint is used by default for access to components such as the Red Hat OpenShift web console for your cluster. In order for console pods to establish a secure, public connection over the internet through the public service endpoint, you must enable a public gateway on each VPC subnet that your worker nodes are deployed to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basics"},{"document_id":"ibmcld_06007-1457-3349","score":19.6306819916,"text":"\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone. After the worker node is provisioned, the worker node IP address persists after a reboot operation, but the worker node IP address changes after replace and update operations.\n\nSubnets provide a channel for connectivity among the worker nodes within the cluster. Additionally, any system that is connected to any of the private subnets in the same VPC can communicate with workers. For example, all subnets in one VPC can communicate through private layer 3 routing with a built-in VPC router. If you have multiple clusters that must communicate with each other, you can create the clusters in the same VPC. However, if your clusters don't need to communicate, you can achieve better network segmentation by creating the clusters in separate VPCs. You can also create [access control lists (ACLs)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-acls) for your VPC subnets to mediate traffic on the private network. ACLs consist of inbound and outbound rules that define which ingress and egress is permitted for each VPC subnet.\n\nIf your worker nodes must access a public endpoint outside of the cluster, you can enable a public gateway on the VPC subnet that the worker nodes are deployed to. A public gateway can be attached to or detached from a subnet at any time.\n\nThe default IP address range for VPC subnets is 10.0.0.0 \u2013 10.255.255.255.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basics"},{"document_id":"ibmcld_05851-2919-4667","score":19.4385280609,"text":"\nWith IBM Cloud Kubernetes Service, you can create a standard cluster in a [Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started). A VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud.\n\nBefore you can create a VPC cluster, you must have a VPC and at least one VPC subnet that you provision by using the IBM Cloud console, CLI, or API. You manage these resources in the VPC dashboard directly. When you create your cluster, worker nodes are automatically provisioned as [Virtual Servers for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-advanced-virtual-servers) instances and you can view and manage these instances in IBM Cloud Kubernetes Service only.\n\nTo add persistent storage to your VPC cluster, you can use the [Block Storage for VPC add-on](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-block). The add-on sets up pre-defined Kubernetes storage classes, the storage provider, and the storage driver in your cluster so that you can provision Block Storage for VPC by using Kubernetes persistent volume claims (PVCs).\n\nTo secure your cluster network traffic, you can modify the default security group for your worker nodes. For more information, see [Security in your IBM Cloud VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-security-in-your-vpc).\n\nTo connect to a different VPC or to an on-prem data center, use the [VPN for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpn-onprem-example) service.\n\n\n\n\n\n\n\n Kubernetes community and open source integrations \n\nBecause you own the standard clusters that you create in IBM Cloud Kubernetes Service, you can choose to install third-party solutions to add extra capabilities to your cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ibm-3rd-party-integrations"},{"document_id":"ibmcld_10258-2744-4496","score":19.2549247742,"text":"\nWith Red Hat OpenShift on IBM Cloud, you can create a standard cluster in a [Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started). A VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud.\n\nBefore you can create a VPC cluster, you must have a VPC and at least one VPC subnet that you provision by using the IBM Cloud console, CLI, or API. You manage these resources in the VPC dashboard directly. When you create your cluster, worker nodes are automatically provisioned as [Virtual Servers for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-advanced-virtual-servers) instances and you can view and manage these instances in Red Hat OpenShift on IBM Cloud only.\n\nTo add persistent storage to your VPC cluster, you can use the [Block Storage for VPC add-on](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-block). The add-on sets up pre-defined Kubernetes storage classes, the storage provider, and the storage driver in your cluster so that you can provision Block Storage for VPC by using Kubernetes persistent volume claims (PVCs).\n\nTo secure your cluster network traffic, you can modify the default security group for your worker nodes. For more information, see [Security in your IBM Cloud VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-security-in-your-vpc).\n\nTo connect to a different VPC or to an on-prem data center, use the [VPN for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpn-onprem-example) service.\n\n\n\n\n\n\n\n Kubernetes community and open source integrations \n\nBecause you own the standard clusters that you create in Red Hat OpenShift on IBM Cloud, you can choose to install third-party solutions to add extra capabilities to your cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations"},{"document_id":"ibmcld_11554-1776-3838","score":19.2427406311,"text":"\nVPC infrastructure contains a number of Infrastructure-as-a-Service (IaaS) offerings, including Virtual Servers for VPC. Use the following information to understand a simple use case for planning, creating, and configuring resources for your VPC, and learn about more VPC overviews and VPC tutorials. For more information about VPC, see [Getting started with Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started).\n\n\n\n\n\n SAP products architecture on IBM Cloud VPC \n\nA [Virtual Private Cloud (VPC)](https:\/\/www.ibm.com\/cloud\/learn\/vpc?mhsrc=ibmsearch_a&mhq=VPC) contains one of the most secure and reliable cloud environments for SAP applications within your own VPC with its included virtual server instances. This represents an Infrastructure as a Service (IaaS) within IBM Cloud that offers all of the benefits of isolated, secure, and flexible virtual cloud infrastructure from IBM. In comparison, the IBM Cloud classic infrastructure virtual servers offering uses virtual instances with native and VLAN networking to communicate to each other within a data center; however, the instances are restricted in one well-working pod by using subnet and VLAN networking as a gap scale up of virtual resources should rely between the pods. What\u2019s new with IBM Cloud VPC is a network orchestrator layer concept that eliminates the pod boundaries and restrictions, so this new concept handles all the networking for every virtual instance running within VPC across regions and zones.\n\n\n\n\n\n 1. Highly available system for SAP NetWeaver on IBM Cloud VPC \n\nIn a highly available (HA) system, every instance can run on a separate IBM Cloud virtual server instance. The cluster HA configuration for the SAP application server consists of two virtual server instances, each of them located in the same zone within the region by using placement groups. Placement groups assure that both cluster resources and cloud resources are also located in different compute nodes as specified in the following placement groups section.\n\nZoom\n\n![Figure 1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-automate-sap-ha-deployment-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.383649139,"ndcg_cut_10":0.5316900945}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05628-4-2149","score":22.6723194122,"text":"\n* UI\n* CLI\n* Terraform\n\n\n\n\n\n\n\n Creating classic clusters \n\nClassic infrastructure\n\nUse the IBM Cloud CLI or the IBM Cloud console to create a fully customizable standard cluster with your choice of hardware isolation and access to features like multiple worker nodes for a highly available environment.\n\nRed Hat OpenShift on IBM Cloud clusters are created with a public only or both a public and private service endpoint. Public service endpoints can't be disabled, and therefore, you can't convert a public Red Hat OpenShift cluster to a private one. If you want your cluster to remain private, see [Planning your cluster network setup](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-pgw).\n\n\n\n Creating a classic cluster in the console \n\nCreate your single zone or multizone classic Kubernetes cluster by using the IBM Cloud console. Follow the console instructions to make the following cluster configurations. To begin creating your cluster, navigate to the [Kubernetes clusters console](https:\/\/cloud.ibm.com\/kubernetes\/clusters) and click Create cluster.\n\nLocation details\n: When you create a cluster, its resources remain in the location that you deploy the cluster to.\n: \n\n* Resource group: A cluster can be created in only one resource group, and after the cluster is created, you can't change its resource group. To create clusters in a resource group other than the default, you must have at least the [Viewer role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms) for the resource group.\n\n\n\n: \n\n* Geography: Select an area to create the cluster in, such as North America. The geography helps filter the Availability and Metro values that you can select in the console.\n\n\n\n: \n\n* Availability: A cluster can be created with a Single zone or Multizone configuration. A multizone cluster provides high availability, with the Kubernetes master deployed in a multizone-capable zone and three replicas of the master spread across different zones.\n\n\n\n* For multizone clusters, choose a Metro location. For the best performance, select the metro location that is physically closest to you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classic&interface=ui"},{"document_id":"ibmcld_06286-20854-22390","score":22.4142971039,"text":"\nFor each zone in which you plan to create subnets, create one or more address prefixes. The address prefixes must be within one of the following ranges: 10.0.0.0 - 10.255.255.255, 172.17.0.0 - 172.17.255.255, 172.21.0.0 - 172.31.255.255, 192.168.0.0 - 192.168.254.255.\n\n\n\n3. Create subnets that use your address prefixes.\n\n\n\n1. From the [VPC subnet dashboard](https:\/\/cloud.ibm.com\/vpc\/network\/subnets), click Create.\n2. Enter a name for your subnet and select the name of your classic access VPC.\n3. Select the location and zone where you want to create the subnet.\n4. Select the address prefix that you created for this zone.\n5. Specify the number of IP addresses to create. VPC subnets provide IP addresses for your worker nodes and load balancer services in the cluster, so [create a VPC subnet with enough IP addresses](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-subnetsvpc_basics_subnets), such as 256. You can't change the number of IPs that a VPC subnet has later.\n6. Choose if you want to attach a public network gateway to your subnet. A public network gateway is required when you want your cluster to access public endpoints, such as a public URL of another app, or an IBM Cloud service that supports public cloud service endpoints only.\n7. Click Create subnet.\n\n\n\n4. Use the subnets to [create a cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2). Do not delete the subnets that you attach to your cluster during cluster creation or when you add worker nodes in a zone.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-subnets"},{"document_id":"ibmcld_10442-1449-3496","score":22.2977714539,"text":"\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone. After the worker node is provisioned, the worker node IP address persists after a reboot operation, but the worker node IP address changes after replace and update operations.\n\nSubnets provide a channel for connectivity among the worker nodes within the cluster. Additionally, any system that is connected to any of the private subnets in the same VPC can communicate with workers. For example, all subnets in one VPC can communicate through private layer 3 routing with a built-in VPC router. If you have multiple clusters that must communicate with each other, you can create the clusters in the same VPC. However, if your clusters don't need to communicate, you can achieve better network segmentation by creating the clusters in separate VPCs. You can also create [access control lists (ACLs)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-acls) for your VPC subnets to mediate traffic on the private network. ACLs consist of inbound and outbound rules that define which ingress and egress is permitted for each VPC subnet.\n\nWhen you create a VPC cluster and enable both the public and private cloud service endpoints during cluster creation, the public cloud service endpoint is used by default for access to components such as the Red Hat OpenShift web console for your cluster. In order for console pods to establish a secure, public connection over the internet through the public service endpoint, you must enable a public gateway on each VPC subnet that your worker nodes are deployed to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basics"},{"document_id":"ibmcld_10501-5448-7369","score":22.2505474091,"text":"\nWhen you create the cluster, the cluster master is automatically created in your Satellite location control plane, and your worker pool is automatically assigned available hosts that match your worker node request.\n11. Wait for the cluster to reach a Normal state.\n\nIf you don't have any available and matching hosts in your Satellite location, the cluster is still created but enters a Warning state. [Attach hosts](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-attach-hosts) to your Satellite location so that hosts can be assigned as worker nodes to the worker pool. If the hosts are not automatically assigned, you can also manually [assign Satellite hosts to your cluster](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-assigning-hostshost-assign-manual). Ensure that hosts are assigned as worker nodes in each zone of your default worker pool.\n12. From the [Red Hat OpenShift clusters console](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift), verify that your cluster reaches a Normal state.\n13. [Access your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_clusteraccess_cluster_sat) to access the Red Hat OpenShift web console or to run oc and kubectl commands from the CLI. If you enabled Satellite Config access, you must complete this step to synchronize the permissions.\n\nIf your location hosts have private network connectivity only, or if you use Amazon Web Services, Google Cloud Platform, or Microsoft Azure hosts, you must be connected to your hosts' private network, such as through VPN access, to connect to your cluster and access the Red Hat OpenShift web console. Alternatively, if your hosts have public network connectivity, you can test access to your cluster by changing your cluster's and location's DNS records to [use your hosts' public IP addresses](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_clustersat_public_access).\n14.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-satellite-clusters"},{"document_id":"ibmcld_05819-1301-3152","score":22.2342300415,"text":"\nGive your cluster a unique name, such as mycluster-free.\n4. Select a resource group to create the cluster in, such as default.\n5. In the Summary pane, review the order summary and then click Create. A worker pool is created that contains one worker node in the default resource group.\n\n\n\nThe worker node can take a few minutes to provision, but you can see the progress in the Worker nodes tab. When the status reaches Ready, you can start working with your cluster by [deploying your first app](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-starteddeploy-app)!\n\n\n\n\n\n Creating a VPC cluster in the IBM Cloud console \n\nCreate a standard VPC cluster by using the IBM Cloud console. For more detailed information about your cluster customization options, see [Creating a standard VPC cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2&interface=ui).\n\nVPC clusters can be created as standard clusters only, and as such incur costs. Be sure to review the order summary at the end of this tutorial to review the costs for your cluster. To keep your costs to a minimum, set up your cluster as a single zone cluster with one worker node only.\n\n\n\n1. Create a Virtual Private Cloud (VPC) on generation 2 compute.\n\n\n\n1. Navigate to the [VPC create console](https:\/\/cloud.ibm.com\/vpc\/provision\/vpc).\n2. Give the VPC a name and select a resource group to deploy the VPC into.\n3. Give the VPC subnet a name and select the location where you want to create the cluster.\n4. Attach a public gateway to your subnet so that you can access public endpoints from your cluster. This public gateway is used later on to access container images from Docker Hub.\n5. Click Create virtual private cloud.\n\n\n\n2. From the [IBM Cloud Kubernetes Service dashboard](https:\/\/cloud.ibm.com\/kubernetes\/clusters), click Create cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-started"},{"document_id":"ibmcld_10085-4-2104","score":22.1511745453,"text":"\n* UI\n* CLI\n* Terraform\n\n\n\n\n\n\n\n Creating classic clusters \n\nClassic infrastructure\n\nUse the IBM Cloud CLI or the IBM Cloud console to create a fully customizable standard cluster with your choice of hardware isolation and access to features like multiple worker nodes for a highly available environment.\n\nRed Hat OpenShift on IBM Cloud clusters are created with a public only or both a public and private service endpoint. Public service endpoints can't be disabled, and therefore, you can't convert a public Red Hat OpenShift cluster to a private one. If you want your cluster to remain private, see [Planning your cluster network setup](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-pgw).\n\n\n\n Creating a classic cluster in the console \n\nCreate your single zone or multizone classic Red Hat OpenShift cluster by using the IBM Cloud console. Follow the console instructions to make the following cluster configurations. To begin creating your cluster, navigate to the [Red Hat OpenShift clusters console](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift) and click Create cluster.\n\nLocation details\n: When you create a cluster, its resources remain in the location that you deploy the cluster to.\n: \n\n* Resource group: A cluster can be created in only one resource group, and after the cluster is created, you can't change its resource group. To create clusters in a resource group other than the default, you must have at least the [Viewer role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms) for the resource group.\n\n\n\n: \n\n* Geography: Select an area to create the cluster in, such as North America. The geography helps filter the Availability and Metro values that you can select in the console.\n\n\n\n: \n\n* Availability: A cluster can be created with a Single zone or Multizone configuration. A multizone cluster provides high availability, with the Red Hat OpenShift master deployed in a multizone-capable zone and three replicas of the master spread across different zones.\n\n\n\n* For multizone clusters, choose a Metro location.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-classic"},{"document_id":"ibmcld_05819-2721-4544","score":22.1263656616,"text":"\nGive the VPC subnet a name and select the location where you want to create the cluster.\n4. Attach a public gateway to your subnet so that you can access public endpoints from your cluster. This public gateway is used later on to access container images from Docker Hub.\n5. Click Create virtual private cloud.\n\n\n\n2. From the [IBM Cloud Kubernetes Service dashboard](https:\/\/cloud.ibm.com\/kubernetes\/clusters), click Create cluster.\n3. Configure your VPC environment.\n\n\n\n1. Select the Standard plan.\n2. Select Kubernetes as your container platform and select the Kubernetes version 1.26 or later.\n3. Select VPC infrastructure.\n4. From the Virtual private cloud drop-down menu, select the VPC that you created earlier.\n\n\n\n4. Configure the Location details for your cluster.\n\n\n\n1. Select the Resource group that you want to create your cluster in. You can't change the resource group later.\n2. Select the zones to create your cluster in. The zones are filtered based on the VPC that you selected, and include the subnets that you previously created.\n\n\n\n5. Configure your Worker pool setup.\n\n\n\n1. If you want a larger size for your worker nodes, click Change flavor. Otherwise, leave the default 4 vCPUs \/ 16 GB flavor selected.\n2. Set how many worker nodes to create per zone, such as 2.\n\n\n\n6. Review the rest of the cluster details, such as the service endpoint, cluster name, and tags.\n7. In the Summary pane, review your order summary and then click Create.\n\n\n\nThe worker node can take a few minutes to provision, but you can see the progress in the Worker nodes tab. When the status reaches Ready, you can start working with your cluster by [deploying your first app](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-starteddeploy-app)!\n\n\n\n\n\n Creating classic clusters in the IBM Cloud Kubernetes Service CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-started"},{"document_id":"ibmcld_11920-17943-19721","score":22.0775337219,"text":"\nThe cluster name must start with a letter, can contain letters, numbers, and hyphen (-), and must be 35 characters or fewer.\n9. Click Create. When you create the cluster, the cluster master is automatically created in your Satellite location control plane, and your worker pool is automatically assigned available hosts that match your worker node request.\n10. Wait for the cluster to reach a Normal state.\n\nIf you don't have any available and matching hosts in your Satellite location, the cluster is still created but enters a Warning state. [Attach hosts](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-attach-hosts) to your Satellite location so that hosts can be assigned as worker nodes to the worker pool. If the hosts are not automatically assigned, you can also manually [assign Satellite hosts to your cluster](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-assigning-hostshost-assign-manual). Ensure that hosts are assigned as worker nodes in each zone of your default worker pool.\n11. From the [Red Hat OpenShift clusters console](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift), verify that your cluster reaches a Normal state.\n12. [Access your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_clusteraccess_cluster_sat) to access the Red Hat OpenShift web console or to run oc and kubectl commands from the CLI. If you enabled Satellite Config access, you must complete this step to synchronize the permissions.\n\nIf your location hosts have private network connectivity only, or if you use Amazon Web Services, Google Cloud Platform, or Microsoft Azure hosts, you must be connected to your hosts' private network, such as through VPN access, to connect to your cluster and access the Red Hat OpenShift web console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-tenancy-model"},{"document_id":"ibmcld_10085-11521-13470","score":22.0537719727,"text":"\n: Specify the IBM Cloud zone ID that you chose earlier and that you want to use to create your cluster.\n\n--flavor <flavor>\n: Specify the flavor for your worker node that you chose earlier.\n\n--hardware <shared_or_dedicated>\n: Specify with the level of hardware isolation for your worker node. Use dedicated to have available physical resources dedicated to you only, or shared to allow physical resources to be shared with other IBM customers. The default is shared. This value is optional for VM standard clusters. For bare metal flavors, specify dedicated.\n\n--public-vlan <public_vlan_id>\n: If you already have a public VLAN set up in your IBM Cloud infrastructure account for that zone, enter the ID of the public VLAN that you retrieved earlier. If you don't have a public VLAN in your account, don't specify this option. IBM Cloud Kubernetes Service automatically creates a public VLAN for you. Private VLAN routers always begin with bcr (back-end router) and public VLAN routers always begin with fcr (front-end router). When you create a cluster and specify the public and private VLANs, the number and letter combination after those prefixes must match.\n\n--private-vlan <private_vlan_id>\n: If you already have a private VLAN set up in your IBM Cloud infrastructure account for that zone, enter the ID of the private VLAN that you retrieved earlier. If you don't have a private VLAN in your account, don't specify this option. IBM Cloud Kubernetes Service automatically creates a private VLAN for you. Private VLAN routers always begin with bcr (back-end router) and public VLAN routers always begin with fcr (front-end router). When you create a cluster and specify the public and private VLANs, the number and letter combination after those prefixes must match.\n\n--name <name>\n: Specify a name for your cluster. The name must start with a letter, can contain letters, numbers, periods (.), and hyphen (-), and must be 35 characters or fewer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-classic"},{"document_id":"ibmcld_11727-1532-3355","score":22.0148029327,"text":"\nCreate the cluster with the following features.\n\n\n\n* Classic clusters:\n\n\n\n* Zone: Any [multizone-capable zone](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zoneszones-mz)\n* Worker node flavor: Any classic infrastructure flavor\n* Network connectivity: Public and private VLANs\n* Worker pool: At least 2 worker nodes\n* Version: 1.20.7 or later\n* Cloud service endpoints: Both public and private endpoints\n* Subnets: Include subnets in the --pod-subnet and --service-subnet options if the default ranges conflict with the Satellite location\u2019s subnet that you set up in your on-premises data center or in a different cloud provider\n\n\n\n* VPC clusters:\n\n\n\n* Zone: Any [multizone-capable VPC zone](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zoneszones-vpc)\n* Worker node flavor: Any VPC infrastructure flavor\n* Version: 1.20.7 or later\n* Worker pool: At least 2 worker nodes\n* Subnets: Include subnets in the --pod-subnet and --service-subnet options if the default ranges conflict with the Satellite location\u2019s subnet that you set up in your on-premises data center or in a different cloud provider\n* Cloud service endpoints: Do not specify the --disable-public-service-endpoint option to ensure that both public and private endpoints are created\n\n\n\n\n\n4. Spread the default worker pool across zones to increase the availability of your [classic](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workersadd_zone) or [VPC](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workersvpc_add_zone) cluster. Ensure that at least 2 worker nodes exist in each zone, so that the private ALBs that you configure in subsequent steps are highly available and can properly receive version updates.\n5. Set the IBM Cloud Kubernetes Service cluster as the context for this session.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-dl-iks-classic"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12095-7-2147","score":20.7747440338,"text":"\nGeneral \n\nAnswers to common questions about the IBM Cloud Schematics are classified into following section.\n\n\n\n What is IBM Cloud Schematics and how does it work? \n\nIBM Cloud Schematics provides powerful tools to automate your cloud infrastructure provisioning and management process, the configuration and operation of your cloud resources, and the deployment of your app workloads.\n\nTo do so, Schematics uses open source projects, such as Terraform, Ansible, Red Hat OpenShift, Operators, and Helm, and delivers these capabilities to you as a managed service. Rather than installing each open source project on your system, and learn the API or CLI. You can declare the tasks that you want to run in IBM Cloud and watch Schematics run these tasks for you.\n\nFor more information about how Schematics Works, see [About IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-learn-about-schematics).\n\n\n\n\n\n What is Infrastructure as Code? \n\nInfrastructure as Code (IaC) helps you codify your cloud environment so that you can automate the provisioning and management of your resources in the cloud. Rather than manually provisioning and configuring infrastructure resources or by using scripts to adjust your cloud environment, you use a high-level scripting language to specify your resource and its configuration. Then, you use tools like Terraform to provision the resource in the cloud by using its API. Your infrastructure code is treated the same way as your app code so that you can apply DevOps core practices such as version control, testing, and continuous monitoring.\n\n\n\n\n\n What am I charged for when I use Schematics? \n\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-faq"},{"document_id":"ibmcld_12098-7-1814","score":20.5341739655,"text":"\nSoftware deployment in IBM Cloud Schematics \n\nTry out one of the IBM\u00ae provided software templates to quickly spin up a classic Virtual Server Instance (VSI), and automatically configure the instance to connect to an IBM Cloud\u00ae Databases for PostgreSQL instance.\n\nWith IBM Cloud Schematics, you can choose from a wide variety of [software and infrastructure templates](https:\/\/cloud.ibm.com\/catalogsoftware) that you can use to set up IBM Cloud services, and to install IBM and Third party software. The templates are applied by using the built-in Terraform, Ansible, Helm, CloudPak, and Operator capabilities in Schematics.\n\nAs part of this getting started tutorial, you create a Schematics Workspaces that points to the [VSI database](https:\/\/cloud.ibm.com\/catalogabout) template. Then, you run this template and watch Schematics provision your VSI and your IBM Cloud Databases for PostgreSQL instance. IBM Cloud Databases for PostgreSQL is a fully managed database offering in IBM Cloud that supports storing of non-relational and relational data types. For more information about this offering, see [What is PostgreSQL?](https:\/\/www.ibm.com\/cloud\/databases-for-postgresql).\n\nThis getting started tutorial incurs costs. You must have an [IBM Cloud Pay-As-You-Go or Subscription](https:\/\/cloud.ibm.com\/registration) account to proceed. Make sure that you review pricing information for [classic VSIs](https:\/\/cloud.ibm.com\/gen1\/infrastructure\/provision\/vs) and [PostgreSQL](https:\/\/cloud.ibm.com\/databases\/databases-for-postgresql\/create).\n\n\n\n Before you begin \n\nBefore you can use this template, you must complete the following tasks.\n\n\n\n* Make sure that you have the permissions to [create classic virtual servers](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-managing-device-access).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-get-started-software"},{"document_id":"ibmcld_11163-67115-69086","score":19.7876548767,"text":"\nFor more information about this new enhancement, see [Invite User Flow and Transparent Actions](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/invite-user-flow-and-transparent-actions).\n\n\n\n\n\n 03 October 2019 \n\nCloud Paks and Schematics templates\n: With the deployment power of the IBM Cloud Schematics service, we now deliver bundled solutions through packaged software and deployable automation scripts that empower you to build, manage, and modernize your cloud architectures faster and more securely. The first release of these offerings include IBM Cloud Paks and a handful of useful Terraform-based templates.\n\nFrom the [catalog](https:\/\/cloud.ibm.com\/catalog), filter by the offering type and deployment target to find what you're looking for faster. Select Cloud Paks and Terraform to check out the new offerings that are available.\n\n\n\n\n\n\n\n September 2019 \n\n\n\n 23 September 2019 \n\nTerm-based model for IBM Cloud support subscriptions\n: New subscriptions for IBM Cloud support now follow the same term-based model as subscriptions for IBM Cloud platform services. Rather than credit being valid in monthly increments, credit is now available up front for an entire subscription term, which can be up to one year's worth of credit. You now have more flexibility to use your support credit when you need it, and the chances of incurring monthly overages are reduced. When you buy or renew a support subscription, any existing active support subscriptions are converted to this new flexible model for the remainder of their term. For more information, see [Support subscriptions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssupport-subscriptions).\n\nYou can also now view your support subscriptions in the IBM Cloud console so you can keep track of your available credit. For more information, see [Viewing your support costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-support).\n\n\n\n\n\n 12 September 2019 \n\nRedirecting SoftLayer to IBM Cloud","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatsnew"},{"document_id":"ibmcld_12095-1659-3450","score":19.712884903,"text":"\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account. If you are about to reach the service limit for your account, the resource is not provisioned until you increase the service quota, or remove existing services first.\n\nThe Schematics ibmcloud terraform command usage displays warning and deprecation message as Alias Terraform are deprecated. Use schematics or sch in your command.\n\n\n\n\n\n Does IBM Cloud Schematics support multiple Terraform provider versions? \n\nYes, IBM Cloud Schematics supports multiple Terraform provider versions. You need to add Terraform provider block with the right provider version. By default the provider run current version 1.21.0, and previous four versions such as 1.20.1, 1.20.0, 1.19.0, 1.18.0 are supported.\n\nExample for a multiple provider configuration:\n\nterraform{\nrequired_providers{\nibm = \">= 1.21.0\" \/\/ Error !! version unavailable.\nibm = \">= 1.20.0\" \/\/ Execute against latest version.\nibm = \"== 1.20.1\" \/\/ Executes version v1.20.1.\n}\n}\n\nCurrently, version 1.21.0 is released. For more information, see [provider version](https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-setup_cliinstall_provider).\n\n\n\n\n\n How do I generate IAM access token, if client ID bx is used? \n\nTo create IAM access token, use export IBMCLOUD_API_KEY=<ibmcloud_api_key> and run the command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-faq"},{"document_id":"ibmcld_07578-623552-625809","score":19.2964172363,"text":"\nIBM Cloud Schematics provides powerful tools to automate your cloud infrastructure provisioning and management process, the configuration and operation of your cloud resources, and the deployment of your app workloads.\n\nTo do so, Schematics uses open source projects, such as Terraform, Ansible, Red Hat OpenShift, Operators, and Helm, and delivers these capabilities to you as a managed service. Rather than installing each open source project on your system, and learn the API or CLI. You can declare the tasks that you want to run in IBM Cloud and watch Schematics run these tasks for you.\n\nFor more information about how Schematics Works, see [About IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-learn-about-schematics).\n* What is Infrastructure as Code?\n\nInfrastructure as Code (IaC) helps you codify your cloud environment so that you can automate the provisioning and management of your resources in the cloud. Rather than manually provisioning and configuring infrastructure resources or by using scripts to adjust your cloud environment, you use a high-level scripting language to specify your resource and its configuration. Then, you use tools like Terraform to provision the resource in the cloud by using its API. Your infrastructure code is treated the same way as your app code so that you can apply DevOps core practices such as version control, testing, and continuous monitoring.\n* What am I charged for when I use Schematics?\n\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account. If you are about to reach the service limit for your account, the resource is not provisioned until you increase the service quota, or remove existing services first.\n\nThe Schematics ibmcloud terraform command usage displays warning and deprecation message as Alias Terraform are deprecated.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-623510-625767","score":19.2964172363,"text":"\nIBM Cloud Schematics provides powerful tools to automate your cloud infrastructure provisioning and management process, the configuration and operation of your cloud resources, and the deployment of your app workloads.\n\nTo do so, Schematics uses open source projects, such as Terraform, Ansible, Red Hat OpenShift, Operators, and Helm, and delivers these capabilities to you as a managed service. Rather than installing each open source project on your system, and learn the API or CLI. You can declare the tasks that you want to run in IBM Cloud and watch Schematics run these tasks for you.\n\nFor more information about how Schematics Works, see [About IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-learn-about-schematics).\n* What is Infrastructure as Code?\n\nInfrastructure as Code (IaC) helps you codify your cloud environment so that you can automate the provisioning and management of your resources in the cloud. Rather than manually provisioning and configuring infrastructure resources or by using scripts to adjust your cloud environment, you use a high-level scripting language to specify your resource and its configuration. Then, you use tools like Terraform to provision the resource in the cloud by using its API. Your infrastructure code is treated the same way as your app code so that you can apply DevOps core practices such as version control, testing, and continuous monitoring.\n* What am I charged for when I use Schematics?\n\nIBM Cloud Schematics Workspaces are provided to you at no cost. However, when you decide to apply your Terraform template in IBM Cloud by clicking Apply plan from the workspace details page or running the ibmcloud schematics apply command, you are charged for the IBM Cloud resources that are described in your Terraform template. Review available service plans and pricing information for each resource that you are about to create. Some services come with a limit per IBM Cloud account. If you are about to reach the service limit for your account, the resource is not provisioned until you increase the service quota, or remove existing services first.\n\nThe Schematics ibmcloud terraform command usage displays warning and deprecation message as Alias Terraform are deprecated.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12581-17606-19704","score":18.8232002258,"text":"\nIf you are validating a deployable architecture that references modules from the catalog, make sure that the modules were onboarded to the catalog.\n\n\n\n1. From the Validate version page, enter the name of your Schematics service, select a resource group, select a Schematics region, and click Next.\n\nIn the Tags field, you can enter a name of a specific tag to attach to your template. This tag is put on the IBM Cloud Schematics workspace. Tags provide a way to organize, track usage costs, and manage access to the resources in your account.\n2. From the input variables section, review your parameter values, and click Next.\n3. In the Validation version section, select I have read and agree to the following license agreements.\n4. Click Validate.\n\nTo monitor the progress of the validation process, click View logs.\n\n\n\n\n\n\n\n Validating a test deployment by using the CLI \n\nTo validate a version of your deployable architecture into an existing product, run the [ibmcloud catalog offering version validate](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-pluginvalidate-offering) command:\n\nibmcloud catalog offering version validate --vl <VERSION_LOCATOR>\n\n\n\n\n\n Reviewing cost by using the CLI \n\nReview the cost of your deployable architecture by using the console. To view the steps, see [Reviewing or defining cost by using the console](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-onboard-custom&interface=uicustom-cost-ui).\n\n\n\n\n\n Reviewing or defining cost by using the console \n\nYou can review the estimated starting cost of your product. If you included the resource metadata in your source repository, the information is parsed during validation and pulled into a starting cost per hour (USD) summary table. The table is displayed in the catalog for customers to compare across variations of a deployable architecture or to get a general idea of what a base configuration of your deployable architecture might cost.\n\nThe summary table lists the resources that your product uses and their estimated costs. Starting cost is an estimate based on available data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-onboard-custom"},{"document_id":"ibmcld_12104-9776-11234","score":18.8036880493,"text":"\nSoftware deployments with Schematics\n\n\n\n1. Choose a template: The [IBM software solutions catalog](https:\/\/cloud.ibm.com\/catalogsoftware) offers a wide variety of infrastructure and software templates that you can choose from. These templates help to quickly install software, such as IBM Cloud Paks, IBM\u00ae WebSphere Application Server for IBM Cloud\u00ae, or Kibana and Grafana into the target service of your choice.\n2. Configure your workspace and target: When you choose one of the provided templates, you must select the target where you want to install the template. Depending on the template that you choose, the target can be an IBM Cloud Kubernetes Service cluster, a Red Hat OpenShift on IBM Cloud cluster, or a classic or Virtual Servers for VPC. Because Schematics is used to install the software, you must configure the workspace that is automatically created for you.\n3. Run the template: When you run the template, Schematics uses the built-in Terraform, Ansible, Helm, OpenShift Operator, or Cloud Pak capabilities to install your software or spin up infrastructure resources. You can use your workspace to monitor the progress of your template execution.\n\n\n\n\n\n\n\n Next steps \n\n\n\n* Explore blueprint samples by using Schematics [tutorials](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-provisioning-terraform-template).\n* Click [here](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-how-it-works) to revisit the Schematics use cases.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-how-it-works"},{"document_id":"ibmcld_12104-8356-10191","score":18.5397415161,"text":"\nBrowse the [IBM software solutions catalog](https:\/\/cloud.ibm.com\/catalogsoftware) and choose among a wide range of software and infrastructure templates that you can use to set up cloud resources, and to install IBM and Third party software in your IBM Cloud Kubernetes Service cluster, Red Hat OpenShift on IBM Cloud cluster, or a classic or Virtual Servers for VPC.\n\nSoftware templates are installed by using the built-in Terraform, Ansible, Helm, Red Hat OpenShift on IBM Cloud Operator, and Cloud Pak capabilities in Schematics. When you choose to install one of the provided templates, you create a Schematics Workspaces and choose the target service or host where you want run the installation. You can review which of the integrated technologies in Schematics is used to install your template.\n\nYou can also create your own software and infrastructure templates and import them in to your own private catalog in IBM Cloud. For more information, see [Adding products to a private catalog](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog)\n\nTo get started with software deployment in Schematics, see the [Getting started tutorial](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-get-started-software).\n\nZoom\n\n![Software deployments with Schematics](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ba89e173287b28d1453d2a327d8a1f74ae2f1662\/schematics\/images\/software_flow.png)\n\nFigure 3. Software deployments with Schematics\n\n\n\n1. Choose a template: The [IBM software solutions catalog](https:\/\/cloud.ibm.com\/catalogsoftware) offers a wide variety of infrastructure and software templates that you can choose from. These templates help to quickly install software, such as IBM Cloud Paks, IBM\u00ae WebSphere Application Server for IBM Cloud\u00ae, or Kibana and Grafana into the target service of your choice.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-how-it-works"},{"document_id":"ibmcld_12321-1562-3328","score":18.4561862946,"text":"\nPrerequisites \n\nAbout IBM Cloud Schematics\n\n[IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-getting-started) is an IBM Cloud automation tool. It provides simplified provisioning, orchestrating Infrastructure as Code (IaC), templates, and managing IBM Cloud resources in your IBM Cloud environment by using various resources tools such as Terraform, Helm. IaC helps you codify your cloud environment to automate the provisioning, speeds deployment, and managing your resources. The infrastructure is treated the same way as your app code, so that you can automate the DevOps core practices such as version control, testing, continuous integration, and deployment.\n\nAbout DevOps toolchain\n\nA DevOps toolchain is a set of tools that automates the tasks of developing and deploying your app. A toolchain is a set of tool integrations that support development, deployment, and operations tasks. The collective power of a toolchain is greater than the sum of its individual tool integrations.\n\nFor the information, see [DevOps toolchain](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-devops-toolchains). The Schematics option enables the continuous delivery of your infrastructure configurations as well with IBM Cloud toolchain.\n\nComplete the following prerequisites for the tutorial:\n\n\n\n* If you do not have IBM Cloud account, create an IBM Cloud account, and pay as you use. For more information about managing IBM Cloud account, see [Managing IBM Cloud account](https:\/\/cloud.ibm.com\/registration).\n* Install the [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-setup-cliinstall-schematics-cli) and the [Schematics CLI plug-in](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-setup-cliinstall-schematics-plugin).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspace-continuous-deployment"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.4776237035,"ndcg_cut_10":0.6447841585}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04031-1609-3779","score":20.4857120514,"text":"\nFor IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges. You will not be charged for the cluster that the Operational Tooling instance, also known as the console, is running on. See the [Architecture reference](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-architecture) topic for an illustration. More details on how to calculate charges are described below.\n\n\n\n Benefits of the new pricing model \n\n\n\n* No membership fees: Freedom from membership fees means that you can invest directly in your blockchain components.\n* Estimation clarity: A simple hourly pricing model makes cost estimation clear and easy by using the cost estimator tool that is available in the IBM Cloud dashboard.\n* No minimum fee required: Pay for only what you use, no minimum VPC hourly package is required, which makes it very inexpensive to get started.\n* Scalability of compute: You have the option to scale your compute up during peak usage periods or down to a minute fraction of capacity for when the compute is not needed to minimize expense.\n\n\n\nIn summary, these features remove the complexity of accounting for membership limitations or purchasing compute ahead of your needs.\n\n\n\n\n\n Find out how to preview the platform free for 30 days \n\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_10116-16035-17814","score":19.6644954681,"text":"\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zoneszones-vpc) that you create the cluster in. The uplift charge is a percentage (%) of the hourly rate (r), and is added to the hourly rate of the worker node. The total hourly rate cost for a worker node can be calculated as r + (r \u00d7 %). In the [Red Hat OpenShift cluster creation console](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/create?platformType=openshift), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month. For more information, expand the Sustained usage discounts on IBM Cloud Virtual Servers for VPC section on the [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs) page.\n\n\n\n\n\n\n\n Estimating costs \n\nSee [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as tiered pricing for increased hourly usage. For more information, see [Understanding costs for your clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costscosts-for-clusters).\n\n\n\n\n\n Managing costs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_11408-13151-14243","score":19.2566337585,"text":"\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change. To calculate your pricing, use the [IBM cost estimator](https:\/\/cloud.ibm.com\/estimator) in IBM Cloud console.\n\n\n\n\n\n End of billing \n\nThe monthly billing cycle ends when you delete the LPAR. If you scale your infrastructure up and down in response to workload requirements, your billing follows the timing of the LPAR provision change. If you stop the LPAR, the billing process is not stopped. You must delete the LPAR to stop the billing cycle.\n\nYou are still charged if the VM is in a suspended state. When your VM is inactive, you can use Dynamic Logical Partitioning (DLPAR) to resize it to a minimal state. You can drastically decrease the price per hour by reducing the VM's core count and memory.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_05666-7536-9272","score":18.6807785034,"text":"\n* VPC clusters: A Load Balancer for VPC is automatically created in your VPC for your cluster. For cost information, see [Pricing for Load Balancer for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n\n\n Storage \n\nWhen you provision storage, you can choose the storage type and storage class that is correct for your use case. Charges vary depending on the type of storage, the location, and the specs of the storage instance. Some storage solutions, such as file and block storage offer hourly and monthly rates that you can choose from.\n\nTo choose the correct storage solution, see [Planning highly available persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan). For more information, see:\n\n\n\n* [File Storage for Classic](https:\/\/www.ibm.com\/products\/file-storage)\n* [Block Storage for Classic](https:\/\/www.ibm.com\/products\/block-storage)\n* [File Storage for VPC](https:\/\/www.ibm.com\/products\/file-storage)\n* [Block Storage for VPC](https:\/\/www.ibm.com\/products\/block-storage)\n* [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage)\n* [Portworx Enterprise pricing](https:\/\/cloud.ibm.com\/catalog\/services\/portworx-enterprise)\n\n\n\n\n\n\n\n IBM Cloud services \n\nEach service that you integrate with your cluster has its own pricing model. Review each product documentation and use the IBM Cloud console to [estimate costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\nOperators and other [third-party integrations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_09887-1649-3273","score":18.4874229431,"text":"\nA billable queue manager is charged based on the number of Virtual Processor Core (VPC) hours that it is active - for example, a Large size queue manager is charged at four times (4x) the rate of a Small size queue manager. The hourly cost is dependent on your local currency and can be seen in the Pricing Plan at the bottom of the [MQ service catalog page](https:\/\/cloud.ibm.com\/catalog\/services\/mq), where you can select your country or region.\n\nYou can see details of your billable usage in the [IBM Cloud usage dashboard](https:\/\/cloud.ibm.com\/account\/usage) at the Account or Resource Group level.\n\nIf you cannot see your MQ usage on the dashboard, but have deployed a billable queue manager, ensure you have selected to view the usage for your resource group, e.g. Under the Usage Dashboard title, in the Group: dropdown menu, select Resource Groups then default.\n\n\n\n\n\n Queue manager resources \n\nThe following table provides information about the resources available to each queue manager size and performance results based on testing:\n\n\n\n Lite<br><br>[1] Extra Small Small Medium Large \n\n VPC <br><br> * <br><br><br> 0.5 1 2 4 \n Memory (RAM GB) <br><br> * <br><br><br> 1 1 2 4 \n Disk Size (GB) <br><br> * <br><br><br> 20 20 40 40 \n Disk performance (IO operations per second - IOPS) <br><br> * <br><br><br> 80 200 400 400 \n TCP non-persistent message throughput <br><br>[2] 10000 <br>per month 800 <br>per second 1500 <br>per second 3000 <br>per second 6000 <br>per second \n TCP persistent message throughput <br><br>[3] 10000 <br>per month 50 <br>per second 100 <br>per second 400 <br>per second 1000 <br>per second","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-qm_sizes"},{"document_id":"ibmcld_10116-10237-12114","score":18.4745941162,"text":"\n[Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/icons\/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.\n* Pay-As-You-Go for VM: Because VMs are billed at an hourly rate, your VM worker node machines have a Pay-As-You-Go allocation of outbound networking based on GB usage.\n* Included bandwidth and tiered packages for BM: Bare metal worker nodes might come with a certain allocation of outbound networking per month that varies by geography: 20 TB for North America and Europe, or 5 TB for Asia Pacific and South America. After you exceed your included bandwidth, you are charged according to a tiered usage scheme for your geography. If you exceed a tier allotment, you might also be charged a standard data transfer fee. For more information, see [Bandwidth packages](https:\/\/www.ibm.com\/cloud\/bandwidth).\n\n\n\nVPC clusters: For more information about how internet data transfer works in your Virtual Private Cloud, see [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n Subnet IP addresses \n\nSubnets for Red Hat OpenShift on IBM Cloud clusters vary by infrastructure provider.\n\nClassic clusters: When you create a standard cluster, a portable public subnet with 8 public IP addresses is ordered and charged to your account monthly. For pricing information, see the [Subnets and IPs](https:\/\/cloud.ibm.com\/docs\/subnets) documentation or estimate your costs in the [classic subnets console)](https:\/\/cloud.ibm.com\/classic\/network\/subnet\/provision). If you already have available portable public subnets in your infrastructure account, you can use these subnets instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_05666-4707-6582","score":18.0774307251,"text":"\n[Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.\n* Pay-As-You-Go for VM: Because VMs are billed at an hourly rate, your VM worker node machines have a Pay-As-You-Go allocation of outbound networking based on GB usage.\n* Included bandwidth and tiered packages for BM: Bare metal worker nodes might come with a certain allocation of outbound networking per month that varies by geography: 20 TB for North America and Europe, or 5 TB for Asia Pacific and South America. After you exceed your included bandwidth, you are charged according to a tiered usage scheme for your geography. If you exceed a tier allotment, you might also be charged a standard data transfer fee. For more information, see [Bandwidth packages](https:\/\/www.ibm.com\/cloud\/bandwidth).\n\n\n\nVPC clusters: For more information about how internet data transfer works in your Virtual Private Cloud, see [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n Subnet IP addresses \n\nSubnets for IBM Cloud Kubernetes Service clusters vary by infrastructure provider.\n\nClassic clusters: When you create a standard cluster, a portable public subnet with 8 public IP addresses is ordered and charged to your account monthly. For pricing information, see the [Subnets and IPs](https:\/\/cloud.ibm.com\/docs\/subnets) documentation or estimate your costs in the [classic subnets console)](https:\/\/cloud.ibm.com\/classic\/network\/subnet\/provision). If you already have available portable public subnets in your infrastructure account, you can use these subnets instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_05666-3176-5101","score":17.8868484497,"text":"\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.\n* Longer ordering process: After you order or cancel a bare metal server, the process is completed manually in your IBM Cloud infrastructure account. Therefore, it can take more than one business day to complete.\n\nVPC Generation 2 only: Prices vary by region where the underlying worker node infrastructure resides, and you can get sustained usage discounts. For more information, see [What are the regional uplift charges and sustained usage discounts for VPC worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costscharges_vpc_gen2).\n\n\n\nFor more information about worker node specifications, see [Available hardware for worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesplanning_worker_nodes).\n\n\n\n\n\n Public bandwidth \n\nBandwidth refers to the public data transfer of inbound and outbound network traffic, both to and from IBM Cloud resources in data centers around the globe.\n\nClassic clusters: Public bandwidth is charged per GB. You can review your current bandwidth summary by logging into the [IBM Cloud console](https:\/\/cloud.ibm.com\/), from the menu ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_05666-8826-10757","score":17.6421489716,"text":"\nReview each product documentation and use the IBM Cloud console to [estimate costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\nOperators and other [third-party integrations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers. Keep in mind that you are responsible for additional charges and how these services operate in your cluster, from deployment and maintenance to integration with your apps. If you have issues with an operator or third-party integration, work with the appropriate provider to troubleshoot the issue.\n\n\n\n\n\n VPC worker nodes \n\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zoneszones-vpc) that you create the cluster in. The uplift charge is a percentage (%) of the hourly rate (r), and is added to the hourly rate of the worker node. The total hourly rate cost for a worker node can be calculated as r + (r \u00d7 %). In the [Kubernetes cluster creation console](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/create), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_14886-1801-3922","score":17.2366085052,"text":"\nBenefits \n\n\n\n BYOL \n\nRenting licenses can get expensive. Bringing your own license is an option for IBM Cloud Bare Metal Servers for VPC.\n\n\n\n\n\n Rapid scaling \n\nScale your dedicated, bare metal server environment for your needs quickly. Often, in 10 minutes or less when resources are available.\n\n\n\n\n\n Network orchestration \n\nA network orchestration layer handles the networking for all bare metal servers that are within an IBM Cloud VPC across regions and zones. Create multiple, virtual private clouds in multizone regions. Network orchestration also helps improve security, reduce latency, and increase high availability.\n\nYou are responsible for security on your bare metal server. That means upgrading or patching the operating system as needed to make sure that vulnerabilities are addressed in a timely manner. Bare metal servers with associated floating IP addresses are internet-facing and you need to take appropriate precautions. For more information, see [Understanding your responsibilities](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-responsibilities-vpcsecurity-compliance).\n\n\n\n\n\n\n\n Pricing options \n\nPay-as-you-go bandwidth is per gigabyte. Your billing charges accrue from provision to cancellation, and are billed in arrears. Total pricing includes bare metal server instance profiles and software, internet data transfers, and optional VPC services. Each additional component is priced separately and included as part of your total IBM Cloud VPC charge. Service tiers are bound to your account, not to any specific VPC.\n\nFor more information about pricing, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricingtab_2651670).\n\n\n\n\n\n Bare Metal Servers for VPC versus bare metal server on classic infrastructure \n\nWith Bare Metal Servers for VPC, you can enjoy the security and performance of the private cloud with the flexibility and scalability of the public cloud. Compared to the classic bare metal infrastructures, Bare Metal Servers for VPC provides better connectivity and networking throughput by using VPC concepts.\n\nBare Metal Servers for VPC has local NVMe, which you can use to create VMWare vSAN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-bare-metal-servers"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04031-6179-7910","score":20.9955196381,"text":"\n[Elements of pricing](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/elements-of-pricing.svg)\n\nFigure 1. Elements of pricing\n\n\n\n* IBM Blockchain Platform: Based on a flat rate of $0.29 USD\/VPC-hour. This fee represents the charge for your blockchain component VPC allocation in your Kubernetes cluster.\n* IBM Cloud Kubernetes Service: While you can link your IBM Blockchain Platform service instance to either an IBM Cloud Kubernetes service cluster or an OpenShift cluster, this pricing model is based on the usage of an IBM Cloud Kubernetes service cluster. The IBM Cloud Kubernetes service uses a tiered pricing model that is visible in IBM Cloud when you provision your paid cluster. This includes the charges for your compute, that is, CPU and memory. IBM Cloud Kubernetes Services are priced on a tiered model that is based on the number of hours of usage per month. Therefore, when you examine pricing plans, consider that 24x7 usage is equivalent to 720 hours per month. Refer to the table on the [Kubernetes Service Catalog page](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about) for more details on cluster pricing. Customers who are interested in pricing OpenShift clusters can review [Red Hat OpenShift on IBM Cloud Pricing](https:\/\/www.ibm.com\/cloud\/openshift\/pricing).\n* Storage: Choose the storage plan that works for your needs. See [Understanding Kubernetes storage basics](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kube_conceptskube_concepts) to learn more about your storage class options and how much they [cost](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing). The IBM Blockchain Platform nodes use the default storage class for the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_04031-8842-10444","score":20.6199474335,"text":"\nBoth examples assume an IBM Cloud Kubernetes service cluster and the default CouchDB database is used as the peer database. It also assumes peers are deployed with Fabric v2.x images instead of Fabric v1.4 images.\n\n\n\n* The Test network scenario is suitable for getting started with your first use case with IBM Blockchain and testing smart contracts.\n* The Join a network scenario includes two peers, and a Certificate Authority (CA) that is required for organization membership.\n\n\n\n* These peers can join a production IBM Blockchain Platform network that is hosted elsewhere.\n* Nodes can always be dialed back to a minimal utilization state (0.001 CPU) when they are not in use to [lower costs](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-govern-components).\n* Because this scenario could be used for a production environment:\n\n\n\n* The default compute resources have been doubled to provide greater capacity.\n* The [Silver](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-file_storagefile_storageclass_reference) storage class is chosen for faster performance.\n\n\n\n\n\n\n\n\n\nTable 1. Pricing examples for a test network and joining a network\n\n Pricing options** (1 VPC = 1 CPU = 1 vCPU) Test Network Join a Network \n\n CPU allocation 1.25 vCPU <br>Includes: <br>- 1 peer (0.7 vCPU) <br>- 2 CAs (0.1 vCPU x 2) <br>- 1 ordering node (0.35 vCPU) 2.9 vCPU <br>Includes: <br>- 2 peers (for HA) <br>(2x default compute = 2 x 0.7 x 2) <br>- 1 CA (0.1) <br> \n Hourly cost: IBM Blockchain Platform $0.46 USD <br>(1.25 vCPU x $0.29 USD\/VPC-hr) $0.81 USD <br>(2.9 vCPUx $0.29 USD\/VPC-hr )","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_10543-1357-3177","score":20.2399253845,"text":"\nbillingType: \"hourly\" The default billing policy used. User can override this default\nencrypted: \"false\" By default, all PVC using this class will only be provider managed encrypted. The user can override this default\nencryptionKey: \"\" If encrypted is true, then a user must specify the encryption key used associated KP instance\nresourceGroup: \"\" Use resource group if specified here. else use the one mentioned in storage-secrete-store\nzone: \"\" By default, the storage vpc driver will select a zone. The user can override this default\ntags: \"\" A list of tags \"a, b, c\" that will be created when the volume is created. This can be overidden by user\nclassVersion: \"1\"\nuid: \"\" The initial user identifier for the file share.\ngid: \"\" The initial group identifier for the file share.\nreclaimPolicy: \"Delete\"\nallowVolumeExpansion: true\nShow more\n\nname\n: Enter a name for your storage class.\n\nprofile\n: Enter the profile that you selected in the previous step, or enter custom to use a custom IOPs value. To find supported storage sizes for a specific profile, see [Tiered IOPS profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles). Any PVC that uses this storage class must specify a size value that is within this range.\n\nencrypted\n: In the parameters, enter true to create a storage class that sets up encryption for your File Storage for VPC volume. If you set this option to true, you must provide the root key CRN of your Key Protect service instance that you want to use in parameterencryptionKey.\n\nencryptionKey\n: If you entered true for parameters.encrypted, then enter the root key CRN of your Key Protect service instance that you want to use to encrypt your File Storage for VPC volume.\n\nzone\n: In the parameters, enter the VPC zone where you want to create the Block Storage for VPC instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-file-vpc-managing"},{"document_id":"ibmcld_04031-1609-3779","score":19.8807792664,"text":"\nFor IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges. You will not be charged for the cluster that the Operational Tooling instance, also known as the console, is running on. See the [Architecture reference](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-architecture) topic for an illustration. More details on how to calculate charges are described below.\n\n\n\n Benefits of the new pricing model \n\n\n\n* No membership fees: Freedom from membership fees means that you can invest directly in your blockchain components.\n* Estimation clarity: A simple hourly pricing model makes cost estimation clear and easy by using the cost estimator tool that is available in the IBM Cloud dashboard.\n* No minimum fee required: Pay for only what you use, no minimum VPC hourly package is required, which makes it very inexpensive to get started.\n* Scalability of compute: You have the option to scale your compute up during peak usage periods or down to a minute fraction of capacity for when the compute is not needed to minimize expense.\n\n\n\nIn summary, these features remove the complexity of accounting for membership limitations or purchasing compute ahead of your needs.\n\n\n\n\n\n Find out how to preview the platform free for 30 days \n\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_03994-15948-17676","score":19.8778419495,"text":"\nIf you do not want to use the default File Storage that is pre-selected for you when you provision a Kubernetes cluster in IBM Cloud, you can provision storage of your choice. See this topic on [Persistent storage considerations](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iksibp-console-storage) to learn more.\n* If you decide to include IBM Cloud multi-zone support in your Kubernetes cluster on IBM Cloud, you must provision your own storage. See [Using Multizone (MZR) clusters with IBM Blockchain Platform](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iksibp-console-mzr) for more details.\n* You can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster. Performance will be limited by throughput, storage and functionality. IBM Cloud will delete your cluster after 30 days and you cannot migrate any nodes or data from a free cluster to a paid cluster. If you choose a paid Kubernetes cluster instead of the limited free cluster, you will incur charges for the Kubernetes service to your IBM Cloud account.\n* Kubernetes clusters that are configured with private VLANs are not supported.\n\n\n\n\n\n\n\n License and pricing \n\nIBM Blockchain Platform for IBM Cloud introduces a new hourly pricing model based on virtual processor core (VPC) usage. The simplified model is based on the amount of CPU (or VPC) that your IBM Blockchain Platform nodes consume on an hourly basis, at a flat rate of $0.29 USD\/VPC-hour, where 1 VPC = 1 CPU. See this topic on [Pricing](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing) for more details.\n\n\n\n\n\n Getting started","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overview"},{"document_id":"ibmcld_10116-13064-14929","score":19.8090362549,"text":"\n* VPC clusters: A Load Balancer for VPC is automatically created in your VPC for your cluster. For cost information, see [Pricing for Load Balancer for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n\n\n Default storage for images \n\nTo store images in the internal registry, Red Hat OpenShift on IBM Cloud creates a storage instance that varies by infrastructure provider.\n\n\n\n* Classic clusters: A classic IBM Cloud File Storage for Classic volume is automatically created for you. Your file storage volume is provisioned with an ibmc-file-gold storage class of 100 GB capacity at 10 IOPS\/GB, and billed at an hourly rate. If you need more image storage capacity, you can [update the volume size](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryopenshift_internal_registry), which modifies the cost.\n* VPC clusters: A bucket in an existing IBM Cloud Object Storage instance is created for you. For more information, see [Billing and pricing in the Object Storage documentation](https:\/\/www.ibm.com\/cloud\/object-storage).\n\n\n\n\n\n\n\n Storage for apps \n\nWhen you provision storage, you can choose the storage type and storage class that is correct for your use case. Charges vary depending on the type of storage, the location, and the specs of the storage instance. Some storage solutions, such as file and block storage offer hourly and monthly rates that you can choose from.\n\nTo choose the correct storage solution, see [Planning highly available persistent storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan). For more information, see:\n\n\n\n* [File Storage for Classic](https:\/\/www.ibm.com\/products\/file-storage)\n* [Block Storage for Classic](https:\/\/www.ibm.com\/products\/block-storage)\n* [File Storage for VPC](https:\/\/www.ibm.com\/products\/file-storage)\n* [Block Storage for VPC](https:\/\/www.ibm.com\/products\/block-storage)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_11613-3252-5201","score":19.3355522156,"text":"\nProfile name Naming convention component What it means \n\n mx2-16x128 m Memory Optimized family \n x Intel x86_64 CPU Architecture \n 2 The generation for the underlying hardware \n \u2014 spacer \n 16 16 vCPU \n x spacer \n 128 128 GiB RAM \n\n\n\n\n\n\n\n Profiles available on Hourly Consumption Billing \n\nAll IBM Cloud Virtual Servers for VPC are available with Hourly Consumption Billing, which includes Suspend Discounts and Sustained Usage Discounts. With Suspend Discounts, storage charges occur only if the server is in Shutdown state. With Sustained Usage Discount, the more a server is used, the less the cost per hour.\n\n\n\n\n\n Storage specifications \n\nWhen the virtual server profiles for SAP HANA are initially provisioned, the servers all have one pre-configured volume (vda) attached with the following basic layout:\n\n\n\nTable 4. Storage configuration of the default virtual server deployment (boot volume)\n\n File system Partition Storage type size (GB) Nr. of <br>IOPS \n\n \/ vda1 Pre-configured boot volume 100 3,000 \n \/boot vda2 Pre-configured boot volume 0.25 3,000 \n\n\n\nTo fulfill the size and I\/O requirements for SAP NetWeaver or SAP AnyDB, more [IBM\u00ae Cloud Block Storage for Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about) volumes need to be added as data volumes to the virtual server configuration.\n\nBlock Storage Volumes for Virtual Servers can be created based on different volume profiles that provide different levels of IOPS per gigabyte (IOPS\/GB). For more information, see [IOPS tiers](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profilestiers) for details.\n\nYou must consider the total IOPS required for your installation and the performance characteristics of your database. One option is to colocate multiple directories into a single large volume with high IOPS, versus isolating directories into individual small volumes with an insufficient number of IOPS for the workload characteristics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-nw-iaas-offerings-profiles-intel-vs-vpc"},{"document_id":"ibmcld_04031-10086-11557","score":18.8888549805,"text":"\nCPU allocation 1.25 vCPU <br>Includes: <br>- 1 peer (0.7 vCPU) <br>- 2 CAs (0.1 vCPU x 2) <br>- 1 ordering node (0.35 vCPU) 2.9 vCPU <br>Includes: <br>- 2 peers (for HA) <br>(2x default compute = 2 x 0.7 x 2) <br>- 1 CA (0.1) <br> \n Hourly cost: IBM Blockchain Platform $0.46 USD <br>(1.25 vCPU x $0.29 USD\/VPC-hr) $0.81 USD <br>(2.9 vCPUx $0.29 USD\/VPC-hr ) \n Hourly cost: IBM Cloud Kubernetes cluster $0.29 USD <br>(Compute: 4 x 16 lowest tier; 1 worker node; 1 zone) $0.29 USD <br>(Compute: 4 x 16 lowest tier; 1 worker node; 1 zone) \n Hourly cost: Storage $0.06 USD <br>340GB <br>[Bronze](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing) <br>2 IOPS\/GB $0.09 USD <br>420GB <br>[Silver](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing) <br>4 IOPS\/GB \n Total hourly cost $0.71 USD $1.19 USD \n\n\n\n** [Preview the IBM Blockchain Platform at no charge](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing-free) for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster. Performance is limited by throughput, storage and functionality. IBM Cloud will delete your Kubernetes cluster after 30 days and you cannot migrate any nodes or data from a free cluster to a paid cluster.\n\nYour actual costs will vary depending on additional factors such as transaction rate, the number of channels you require, the payload size on the transactions, and the maximum number of concurrent transactions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_05666-7536-9272","score":18.794921875,"text":"\n* VPC clusters: A Load Balancer for VPC is automatically created in your VPC for your cluster. For cost information, see [Pricing for Load Balancer for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n\n\n Storage \n\nWhen you provision storage, you can choose the storage type and storage class that is correct for your use case. Charges vary depending on the type of storage, the location, and the specs of the storage instance. Some storage solutions, such as file and block storage offer hourly and monthly rates that you can choose from.\n\nTo choose the correct storage solution, see [Planning highly available persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan). For more information, see:\n\n\n\n* [File Storage for Classic](https:\/\/www.ibm.com\/products\/file-storage)\n* [Block Storage for Classic](https:\/\/www.ibm.com\/products\/block-storage)\n* [File Storage for VPC](https:\/\/www.ibm.com\/products\/file-storage)\n* [Block Storage for VPC](https:\/\/www.ibm.com\/products\/block-storage)\n* [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage)\n* [Portworx Enterprise pricing](https:\/\/cloud.ibm.com\/catalog\/services\/portworx-enterprise)\n\n\n\n\n\n\n\n IBM Cloud services \n\nEach service that you integrate with your cluster has its own pricing model. Review each product documentation and use the IBM Cloud console to [estimate costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\nOperators and other [third-party integrations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_05784-66784-69020","score":18.6333732605,"text":"\n: For storage that was [statically provisioned](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kube_conceptsstatic_provisioning), VPC Block Storage, or storage that you provisioned with a storage class that sets reclaimPolicy: Retain, you must manually remove the PVC, PV, and the storage instance to avoid further charges.\n\nHow does the billing stop after I delete my storage?\n: Depending on what storage components you delete and when, the billing cycle might not stop immediately. If you delete the PVC and PV, but not the storage instance in your IBM Cloud account, that instance still exists and you are charged for it.\n\nIf you delete the PVC, PV, and the storage instance, the billing cycle stops depending on the billingType that you chose when you provisioned your storage and how you chose to delete the storage.\n\n\n\n* When you manually cancel the persistent storage instance from the IBM Cloud console or the ibmcloud sl CLI, billing stops as follows:\n\n\n\n* Hourly storage: Billing stops immediately. After your storage is canceled, you might still see your storage instance in the console for up to 72 hours.\n* Monthly storage: You can choose between immediate cancellation or cancellation on the anniversary date. In both cases, you are billed until the end of the current billing cycle, and billing stops for the next billing cycle. After your storage is canceled, you might still see your storage instance in the console or the CLI for up to 72 hours.\n\n\n\n* Immediate cancellation: Choose this option to immediately remove your storage. Neither you nor your users can use the storage anymore or recover the data.\n\n\n\n* Anniversary date: Choose this option to cancel your storage on the next anniversary date. Your storage instances remain active until the next anniversary date and you can continue to use them until this date, such as to give your team time to make backups of your data.\n\n\n\n* When you dynamically provisioned the storage with a storage class that sets reclaimPolicy: Delete and you choose to remove the PVC, the PV and the storage instance are immediately removed. For hourly billed storage, billing stops immediately. For monthly billed storage, you are still charged for the remainder of the month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-file_storage"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1681275363,"ndcg_cut_10":0.285643641}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01660-8584-10307","score":28.2296142578,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_01705-7-1620","score":25.5436000824,"text":"\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_16727-1079289-1081125","score":25.3781204224,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":25.3781204224,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_00558-1499-3456","score":24.2737617493,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_16727-1077752-1079681","score":24.1911849976,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1075256-1077185","score":24.1911849976,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12904-1535-3460","score":23.9790554047,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_01660-7085-8964","score":23.9437923431,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_12904-7-1919","score":23.5179538727,"text":"\nPlans and provisioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Standard is IBM Cloudant's most feature-rich offering, receiving updates and new features first. Pricing is based on provisioned throughput capacity that is allocated and data storage that is used, making it suitable for any required load.\n\nThe free [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) includes a fixed amount of throughput capacity and data for development and evaluation purposes. The paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan) offers configurable provisioned throughput capacity and data storage pricing that scales as your application requirements change. An optional [Dedicated Hardware plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicdedicated-hardware-plan) is also available for an extra monthly fee to run one or more of your Standard plan instances on a dedicated hardware environment. The dedicated hardware environment is for your sole use. If a Dedicated Hardware plan instance is provisioned within a US location, you can optionally select a [HIPAA](https:\/\/en.wikipedia.org\/wiki\/Health_Insurance_Portability_and_Accountability_Act) -compliant configuration.\n\n\n\n Plans \n\nYou can select which plan to use when you [provision your IBM Cloudant service instance](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioning-a-cloudant-nosql-db-instance-on-ibm-cloud). The available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.8772153153,"ndcg_cut_10":0.8772153153}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01705-14609-15453","score":23.484910965,"text":"\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite%20lite) that has a Lite plan.\n* After 10 days of no development activity, your apps go to sleep. You can wake up your apps by continuing to work on them.\n* After 30 days of no development activity, your service instances with Lite plans are deleted\n\n\n\nOnly Lite accounts created before 12 August 2021 can use 186 GBH of free buildpacks and Cloud Foundry apps with up to 256 MB of free instantaneous runtime memory per month. The use of one org in one IBM Cloud region is supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_01705-13208-15001","score":21.7527523041,"text":"\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/Lite.svg) in the catalog. To gain access to all Free plans, you can go ahead and [upgrade to a Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqschangeacct) by adding your credit card information.\n\nStarting 25 October 2021, all new accounts are created as Pay-As-You-Go based on an update to our account registration process. As part of this update, you're asked to provide credit card information for identity verification. You have full access to the catalog, including all Free and Lite plans, and you get a $200 credit that you can apply in your first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nLite accounts have access to a single resource group that's created for you with the name Default. All of your service's instances are automatically added to this resource group. You can update the name of this resource group at any time. See [Renaming a resource group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgsrename_rgs) for the detailed steps.\n\n\n\n What's available in a lite account? \n\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite%20lite) that has a Lite plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_11149-20909-23050","score":20.6694145203,"text":"\nIf you have a Lite account, you can have only one resource group, but with a a Pay-As-You-Go or Subscription account, you can create more than one resource group. If an account is suspended, the corresponding resource group is suspended as well, and all resources within the resource group are suspended.\n\n\n\n\n\n Managing Infrastructure as Code (IaC) deployments with projects \n\nIBM Cloud\n\nprojectsare a named collection of configurations that are used to manage related resources and Infrastructure as Code (IaC) deployments across accounts. They enable teams to configure, deploy, and monitor deployments by using DevOps best practices. If you select a deployable architecture from the catalog, you can add it to a project to configure and deploy it into your different environments. For more information, see [Learn about IaC deployments with projects](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-understanding-projects).\n\n\n\n\n\n Searching and tagging resources \n\nThe search service is a global and shared resource properties repository that is integrated within the IBM Cloud platform. It is used for storing and searching a cloud resource's attributes, and it categorizes and classifies resources. Resources are uniquely identified by a [Cloud Resource Name (CRN)](https:\/\/cloud.ibm.com\/docs\/account?topic=account-crn) identifier. The properties of a resource include tags and system properties. Both properties are defined within an IBM Cloud billing account, and span across many regions.\n\nThis service also manages tags that are associated with a resource. You can create, delete, search, attach, or detach tags with the Tagging API. Tags are uniquely identified by a CRN identifier. Tags have a name, which must be unique within a billing account. You can create tags in key:value pairs or label format.\n\n\n\n\n\n Monitoring your resources \n\nObservability offers a single location where you can monitor and observe your applications and services in IBM Cloud.\n\nWith the IBM\u00ae Log Analysis service, you can add log management capabilities to your IBM Cloud architecture and you can manage system and application logs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatis-platform"},{"document_id":"ibmcld_16727-1079289-1081125","score":20.5433769226,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":20.5433769226,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01644-1425-2426","score":20.4473667145,"text":"\nIf there's any way we can assist you before you decide to close your account, [reach out to us](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n* To close a Lite account, go to Manage > Account, select Account settings in the IBM Cloud console. From the account settings page, click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* If you want to close a Pay-As-You-Go or Subscription account, contact [Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). A support case is required for account security and documentation purposes. After your Pay-As-You-Go account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account_settings"},{"document_id":"ibmcld_02301-7-1933","score":20.2013130188,"text":"\nUpgrading your account \n\nLite accounts make it easy to get started with IBM Cloud\u00ae and try out services. When you are ready for more, you can upgrade your account to a Pay-As-You-Go, or Subscription account to unlock the entire catalog of production-ready services.\n\nYou can check your current account type by going to Manage > Account > Account settings in the IBM Cloud console and looking in the Account Type section.\n\nNot sure which type of account you want to upgrade to? Get detailed information about the benefits of each account type in [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\nTo upgrade your account, you must have an access policy with the Editor role or higher on all account management services. For more information about IAM roles for managing accounts, see [Platform management roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userrolesplatformroles).\n\n\n\n Upgrading to a Pay-As-You-Go account \n\nWith a Pay-As-You-Go account, you pay for only what you use beyond the free runtime and service allowances. After you upgrade, you can continue to use any instances that you created with your Lite account.\n\nTo upgrade to a Pay-As-You-Go account, complete the following steps.\n\n\n\n1. Go to Manage > Account in the IBM Cloud console.\n2. Select Account settings, and click Add credit card.\n3. Enter your payment information, click Next, and submit your information.\n\n\n\nAfter your payment information is processed, your account is upgraded, and you can explore and access the full IBM Cloud catalog. For any billable services that you use beyond any free allowances, you receive a monthly invoice.\n\nIf you're upgrading to reactivate a deactivated account, your account might take a few days to be fully available. If your account continues to be in a pending state, see [Why can't I upgrade my account?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-ts_upgrade_cc) for help.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account"},{"document_id":"ibmcld_01660-7085-8964","score":20.1742553711,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_01660-8584-10307","score":20.1417293549,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_00558-1499-3456","score":19.8809871674,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.5012658353,"ndcg_cut_10":0.5012658353}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01660-8584-10307","score":22.8387088776,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":21.7264556885,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":21.7264556885,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01705-7-1620","score":21.2880077362,"text":"\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_01660-7085-8964","score":20.2437515259,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_04488-133306-134586","score":20.0824928284,"text":"\ncreate a Cloud Object Storage (COS) instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\nCreating service instance my-cos-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-cos-1 was created.\nName: my-cos-1\nID: crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8::\nGUID: 4b636e74-f3ca-40bb-80b8-3bd21801ccb8\nLocation: global\nState: active\nType: service_instance\nSub Type:\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation: Status create succeeded Message Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\nCreating service instance my-kms-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-kms-1 was created.\nName: my-kms-1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_07578-1075256-1077185","score":20.0166797638,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1077752-1079681","score":20.0166797638,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11142-7-1829","score":19.5780258179,"text":"\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https:\/\/cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free"},{"document_id":"ibmcld_01705-14609-15453","score":19.4677524567,"text":"\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite%20lite) that has a Lite plan.\n* After 10 days of no development activity, your apps go to sleep. You can wake up your apps by continuing to work on them.\n* After 30 days of no development activity, your service instances with Lite plans are deleted\n\n\n\nOnly Lite accounts created before 12 August 2021 can use 186 GBH of free buildpacks and Cloud Foundry apps with up to 256 MB of free instantaneous runtime memory per month. The use of one org in one IBM Cloud region is supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01623-7-1977","score":22.6615257263,"text":"\nSetting up your IBM Cloud account \n\nThis tutorial walks you through the steps for setting up an account in IBM Cloud\u00ae. By completing this tutorial, you learn how to set up account authentication, manage your account settings, effectively organize resources in your account, and control access to resources.\n\nThis tutorial focuses on how to set up a Pay-As-You-Go account. For more information about setting up accounts in an enterprise hierarchy, see [Setting up an enterprise](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial).\n\n\n\n Step 1: Create your account \n\nFirst, create an account by using your existing IBMid or a new IBMid. If your company is registered to use a federated ID for single sign-on (SSO), you can use your federated ID instead.\n\n\n\nTable 1. ID options for creating an account\n\n Login ID Details \n\n Existing IBMid If you already have an IBMid, sign up for IBM Cloud with your existing credentials that you use for other IBM\u00ae products and services. \n New IBMid If you don't yet have an IBMid, you can create one when you sign up. With an IBMid, you can use one username to log in to all IBM products and services, including IBM Cloud. \n Federated ID If your company already requested to register the user credentials from your company's domain with IBM, you can sign up for IBM Cloud by using the credentials that you already use for your company's login. You must enter a phone number when you sign up. \n\n\n\n\n\n Using your IBMid \n\nIf you're not a part of a company that uses a federated ID, use your IBMid to create your account.\n\n\n\n1. Go to the [IBM Cloud login page](https:\/\/cloud.ibm.com\/), and click Create an IBM Cloud account.\n2. Enter your IBMid email address. If you don't have an existing IBMid, an ID is created based on the email that you enter.\n3. Complete the remaining fields with your information.\n\nYou are prompted for your credit card information to verify your identity and secure your account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started"},{"document_id":"ibmcld_01885-3310-5668","score":22.1771526337,"text":"\nAccess policies can only be set for IAM-enabled services and account management services (clicks \"Assign access\" button on the Access policies tab for the created access group, then highlights two tiles for IAM-enabled services and Account management services). Cloud Foundry and Classic Infrastructure are separate.\n\nThe role defines the level of access granted to a user (Starts creating a policy by selecting All identity and access enabled services, then scrolling the available roles that display). The most commonly used roles are viewer, editor, and administrator. The viewer role provides the least amount of access for viewing instances and resource groups. The editor role allows more access to create, edit, delete, and bind service instances. While the administrator includes everything for working with a service instance and can also assign access to others.\n\nTo make assigning access as easy as possible, you can organize resources into a resource group and users and service IDs into an access group. After you set up each one, you can then create access policies for the access groups to give users access to the resources you\u2019ve created.\n\nTo get started, click \u201cManage\u201d in the IBM Cloud console, then click \u201cAccess (IAM)\u201d and select \u201cAccess Groups.\u201d\n\nThen, select the name of the access group that you want to assign access.\n\nSelect the \u201cAccess policies\u201d tab, and then click \u201cAssign access.\u201d\n\nNow you will select the type of access that you want to assign (clicks IAM services, selects All identity and access-enabled services, selects Administrator platform role, selects Reader service role). Then, click \u201cAdd\u201d and \u201cAssign.\u201d (Then, clicks \"Invite\" button.)\n\nInviting users to the access group is easy. You can add users directly to each access group by clicking on \u201cUsers\u201d and the blue \u201cInvite Users\u201d button.\n\nThank you for watching this installment of the IBM Cloud Console Guide.\n\n\n\n\n\n\n\n Before you begin \n\nTo manage or create new access groups, you must have the following type of access:\n\n\n\n* Account owner\n* Administrator or editor on the IAM Access Groups account management service in the account\n* Administrator or editor for the All Account Management services\n\n\n\nAdditionally, an administrator or editor can be assigned access to manage an individual group by creating an access policy where the resource is the Access group ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-groups&interface=ui"},{"document_id":"ibmcld_12564-3310-5668","score":22.1771526337,"text":"\nAccess policies can only be set for IAM-enabled services and account management services (clicks \"Assign access\" button on the Access policies tab for the created access group, then highlights two tiles for IAM-enabled services and Account management services). Cloud Foundry and Classic Infrastructure are separate.\n\nThe role defines the level of access granted to a user (Starts creating a policy by selecting All identity and access enabled services, then scrolling the available roles that display). The most commonly used roles are viewer, editor, and administrator. The viewer role provides the least amount of access for viewing instances and resource groups. The editor role allows more access to create, edit, delete, and bind service instances. While the administrator includes everything for working with a service instance and can also assign access to others.\n\nTo make assigning access as easy as possible, you can organize resources into a resource group and users and service IDs into an access group. After you set up each one, you can then create access policies for the access groups to give users access to the resources you\u2019ve created.\n\nTo get started, click \u201cManage\u201d in the IBM Cloud console, then click \u201cAccess (IAM)\u201d and select \u201cAccess Groups.\u201d\n\nThen, select the name of the access group that you want to assign access.\n\nSelect the \u201cAccess policies\u201d tab, and then click \u201cAssign access.\u201d\n\nNow you will select the type of access that you want to assign (clicks IAM services, selects All identity and access-enabled services, selects Administrator platform role, selects Reader service role). Then, click \u201cAdd\u201d and \u201cAssign.\u201d (Then, clicks \"Invite\" button.)\n\nInviting users to the access group is easy. You can add users directly to each access group by clicking on \u201cUsers\u201d and the blue \u201cInvite Users\u201d button.\n\nThank you for watching this installment of the IBM Cloud Console Guide.\n\n\n\n\n\n\n\n Before you begin \n\nTo manage or create new access groups, you must have the following type of access:\n\n\n\n* Account owner\n* Administrator or editor on the IAM Access Groups account management service in the account\n* Administrator or editor for the All Account Management services\n\n\n\nAdditionally, an administrator or editor can be assigned access to manage an individual group by creating an access policy where the resource is the Access group ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-groups"},{"document_id":"ibmcld_01802-0-2084","score":22.1747398376,"text":"\n\n\n\n\n\n\n  Managing multiple accounts with your IBMid \n\nAs the owner or administrator of an IBM Cloud\u00ae account, you can create and manage multiple accounts that are associated with a single IBMid to access and manage details about each account from one email address. For example, you might be responsible for managing several departments in your company that have different billing requirements. By creating multiple accounts, you can switch between them without having to log in and out of the IBM Cloud console each time.\n\nOnly Pay-As-You-Go and Subscription accounts can create multiple accounts by using one email. Lite accounts can create only one account per email.\n\nManaging multiple accounts with a single IBMid is different from using an enterprise account. With an enterprise account, you can have several child accounts attached to a parent account, and all associated charges roll up to the parent account in the enterprise. See [What is an enterprise?](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise) for more information.\n\nTo create multiple accounts associated with your IBMid, complete the following steps:\n\n\n\n1.  In the console, go to the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/i-avatar-icon.svg) > Log out, and click Log out.\n2.  From the login screen, click Create an account.\n3.  From the registration page, enter your email address, complete the necessary information, and click Create account.\n\n\n\nAfter you create the accounts, you can switch to a specific account from the console menu bar as shown in the following image.\n\nZoom\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/account\/images\/account-faq.svg)\n\nFigure 1. Using the account selector to switch accounts\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-mult-accounts"},{"document_id":"ibmcld_01874-1664-3794","score":22.1429309845,"text":"\nAny user that uses your email domain can create their own IBMid, and the password they create is managed by IBMid. They can create an IBM Cloud account and invite other users with an IBMid to their account. They can also access other IBM web offerings by using that same IBMid.\n\nFederated IBMid users\n: Enterprise customers often connect their internal user directory, or IdP, with IBMid so that their employees don't need to manage an additional password. Instead, they can reuse their normal login to their IdP to log in to IBM web offerings, including IBM Cloud. Connecting an external IdP with IBMid is called federation, and the technical underlying protocol is called SAML. Those users are often referenced as federated IBMid users. As IBMid is federating with multiple enterprise customers at the same time, one prerequisite of a successful federation is a unique email address for each IBMid user.\n\nIBM Cloud App ID users\n: Instances of the IBM Cloud App ID can also connect to an IdP. An App ID instance can connect to onlyone external IdP using SAML, and therefore a unique email address isn't required.\n\n\n\n\n\n IBM Cloud account owners \n\nTo create an IBM Cloud account, you need an IBMid user that will be the IBM Cloud account owner. You can create this IBMid user during the [IBM Cloud account registration process](https:\/\/cloud.ibm.com\/registration), or you use an existing IBMid user. We recommend creating the account by using a [functional ID](https:\/\/cloud.ibm.com\/docs\/account?topic=account-identity-overviewfunctionalid-bestpract) or service account with a valid email address, this can help simplify account ownership continuity in your organization.\n\nFor any additional members of your IBM Cloud account, you have the option to use normal or federated IBMid users as IBM Cloud account members. Alternatively, you can connect your IdP to your IBM Cloud account by using an IBM Cloud App ID service instance. All users that log in through that IBM Cloud App ID service instance are added to your account automatically, so you don't need to invite those users.\n\n\n\n\n\n How do you onboard IBM Cloud account members?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-federation-option-for-you"},{"document_id":"ibmcld_01388-1400-3142","score":22.1386852264,"text":"\nYou can choose to create a second IBM Cloud account, or you can work with a colleague that has an IBM Cloud account.\n* Ensure that you have the correct access permissions for adding and removingnamespaces, see [Access roles for configuring IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n\n\n Step 1: Authorize a user to configure the registry \n\nAdd a second user to your account and grant them the ability to configure IBM Cloud Container Registry.\n\n\n\n1. Add User B to User A's account.\n\n\n\n1. Log in to User A's account, by running the following command.\n\nibmcloud login\n2. Invite User B to access User A's account by running the following command, where <user.b@example.com> is User B's email address.\n\nibmcloud account user-invite <user.b@example.com>\n3. Get User A's Account ID by running the following command.\n\nibmcloud target\n\nMake a note of the Account ID that is in the parentheses ( ) in the Account row.\n\n\n\n2. Prove that User B can target User A's account but can't do anything with IBM Cloud Container Registry yet.\n\n\n\n1. Log in as User B and target User A's account by running the following command, where <YourAccountID> is User A's Account ID.\n\nibmcloud login -c <YourAccountID>\n2. Try to edit your registry quota to 4 GB of traffic by running the following command.\n\nibmcloud cr quota-set --traffic=4000\n\nThe command fails because User B doesn't have the correct access.\n\n\n\n3. Grant User B the Manager role so that User B can configure IBM Cloud Container Registry.\n\n\n\n1. Log back in to your account as yourself, User A, by running the following command.\n\nibmcloud login\n2. Create a policy that grants the Manager role to User B by running the following command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access"},{"document_id":"ibmcld_01623-1601-3527","score":22.0955924988,"text":"\nGo to the [IBM Cloud login page](https:\/\/cloud.ibm.com\/), and click Create an IBM Cloud account.\n2. Enter your IBMid email address. If you don't have an existing IBMid, an ID is created based on the email that you enter.\n3. Complete the remaining fields with your information.\n\nYou are prompted for your credit card information to verify your identity and secure your account. You can [try out IBM Cloud for free](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free) and pay only for the billable services that you choose to use, with no long-term contracts or commitments.\n4. Click Create account.\n5. Confirm your account by clicking the link in the confirmation email that's sent to your provided email address.\n\n\n\nSee [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts) to compare and choose an account type.\n\n\n\n\n\n Personal use availability \n\n\n\n\n\n Personal use availability \n\nThe following table shows the countries where personal use of our platform that is not related to business, trade, craft, or professional purposes are not supported\n\nAfrica\n\nAsia\n\nEurope\n\n\n\nTable 2. Countries in Africa that are not supported\n\n Country \n\n Algeria \n Cameroon \n Canary Islands \n Egypt \n Ghana \n Ivory Coast \n Kenya \n Mauritania \n Nigeria \n Seychelles \n Tanzania \n Uganda \n\n\n\nIBM\u00ae Norway and IBM\u00ae Switzerland are able to contract with local customers to offer personal use accounts.\n\nTo work with a local Business Partner, go to the [IBM Business Partner Directory](https:\/\/www.ibm.com\/partnerworld\/bpdirectory\/). Customers are not required to have a VAT ID to work with a local Business Partner.\n\n\n\n\n\n Using a federated ID \n\nA federated ID is an ID within a company's domain that is registered with IBM so that the domain and user credentials can be used to access IBM web applications. You can sign up for IBM Cloud with a federated ID only if your company is already registered with IBM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started"},{"document_id":"ibmcld_11472-2693-4203","score":21.8031368256,"text":"\nStep 3: Integrate the App ID instance as the ID provider for the administrator's account \n\n\n\n1. Go to [Manage \u2192 Access (IAM) \u2192 Identity Providers](https:\/\/cloud.ibm.com\/iam\/identity-providers). For Type, choose IBM Cloud App ID, then click Create.\n2. Specify a name and select the App ID instance from the drop-down list.\n3. Select the checkbox to enable the ID provider.\n\nZoom\n\n![Create identity provider](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5f399fa794584e8a662591b494b9a99aa927c74c\/quantum-computing\/images\/org-guide-idp-reference.png)\n\nFigure 3. Create identity provider page\n4. The default IdP URL is shown. Share this URL with users when they need to log in.\n\n\n\n\n\n\n\n Step 4: Add Users \n\nWhen you use App ID as ID provider with the Cloud directory, you can create users in the IBM Cloud user interface.\n\n\n\n1. Open the App ID instance page from the [resource list](https:\/\/cloud.ibm.com\/resources) Services and software section.\n2. Go to Manage Authentication \u2192 Cloud Directory \u2192 Users, and click Create User. Enter the user details.\n\n\n\n\n\n\n\n Step 5: Create or modify users' project assignments \n\n\n\n1. Go to [Manage \u2192 Access (IAM) \u2192 Users](https:\/\/cloud.ibm.com\/iam\/users) and click the user.\n\nZoom\n\n![Change User Access](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5f399fa794584e8a662591b494b9a99aa927c74c\/quantum-computing\/images\/org-guide-manage-user.png)\n\nFigure 11. Change User Access\n\nIf you don't see the user that you want to manage, verify that they logged in to IBM Cloud at least once.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-appid-cloud-org"},{"document_id":"ibmcld_01660-1531-3476","score":21.7264289856,"text":"\nHow do I get help with issues with creating an account? \n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https:\/\/watson.service-now.com\/x_ibmwc_open_case_app.do!\/create).\n\n\n\n\n\n Why is a VAT ID required when I create an account? \n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n\n\n\n\n\n How do I update my credit card? \n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.\n\nBased on your account type, you might manage your credit card outside of the console. To manage your credit card outside of the console, complete the following steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_00959-6326-8078","score":21.6650695801,"text":"\nFor more information about IBM Cloud accounts, see [Setting up your IBM Cloud account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started) and [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account).\n* A [Kubernetes cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-started) and an API key. You can create these resources by using either the UI or the CLI. The cluster might take some time to provision. As the cluster is created, it progresses through the Deploying, Pending, and Ready stages. For more information about Kubernetes clusters, see [Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusters). Although you can use Rolling and Blue-Green deployments for Lite plans, you must create a Kubernetes cluster for Standard plans.\n* An instance of the [Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-getting-started) service.\n* Optional. Secrets that are stored in a secrets management vault and managed centrally from a single location. For more information about choosing from the various secrets management and data protection offerings, see [Managing IBM Cloud secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manage-secrets-ibm-cloud). If you don't already have an instance of the secrets management vault provider of your choice, create one.\n* Optional. A namespace that is created by using the container registry command line. To create a namespace, type the following command from the command line:\n\nibmcloud cr namespace-add <my namespace>\n\nAlternatively, you can create a namespace on the [Container Registry](https:\/\/cloud.ibm.com\/registry\/namespaces) page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-kubernetes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.156426242}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03729-3519-5413","score":25.3145332336,"text":"\nThese resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings\n* Encrypted data storage limit, for example 1 GB\n* Provisioned throughput capacity\n\n\n\nYou can easily find services for Lite plans in the catalog. By default, all services with a Lite plan are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/Lite.svg). Select a service to view the quota details for the associated Lite plan.\n\n\n\n\n\n Charges for compute resources \n\nYou're charged for the time that your apps run and the memory that's used in GB-hours. GB-hours is the calculation of the number of application instances that are multiplied by the memory per instance and by the hours that the instances run. You can customize the number of instances and the amount of memory per instance based on your needs. You can also add memory or instances to scale for more users. To get the amount charged, take your application instances that are multiplied by memory per instance and by hours running.\n\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_16727-1079289-1081125","score":25.019733429,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":25.019733429,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03729-1672-3956","score":24.1931114197,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_01660-8584-10307","score":22.3362083435,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_16727-1042765-1044817","score":20.8820858002,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1042894-1044946","score":20.8820858002,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_07578-1075256-1077185","score":20.6776542664,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1077752-1079681","score":20.6776542664,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01660-7085-8964","score":20.4943313599,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01660-8584-10307","score":22.6649112701,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_00558-1499-3456","score":22.4091625214,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-1535-3460","score":22.2040958405,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-7-1919","score":21.8318405151,"text":"\nPlans and provisioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Standard is IBM Cloudant's most feature-rich offering, receiving updates and new features first. Pricing is based on provisioned throughput capacity that is allocated and data storage that is used, making it suitable for any required load.\n\nThe free [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) includes a fixed amount of throughput capacity and data for development and evaluation purposes. The paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan) offers configurable provisioned throughput capacity and data storage pricing that scales as your application requirements change. An optional [Dedicated Hardware plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicdedicated-hardware-plan) is also available for an extra monthly fee to run one or more of your Standard plan instances on a dedicated hardware environment. The dedicated hardware environment is for your sole use. If a Dedicated Hardware plan instance is provisioned within a US location, you can optionally select a [HIPAA](https:\/\/en.wikipedia.org\/wiki\/Health_Insurance_Portability_and_Accountability_Act) -compliant configuration.\n\n\n\n Plans \n\nYou can select which plan to use when you [provision your IBM Cloudant service instance](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioning-a-cloudant-nosql-db-instance-on-ibm-cloud). The available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_01705-7-1620","score":21.6896324158,"text":"\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_07152-7-1723","score":21.6281967163,"text":"\nDiscovery pricing plans \n\nIBM Watson\u2122 Discovery offers three plans -- Lite, Advanced, and Premium -- that provide different levels of resources and capabilities to suit your needs.\n\nFor more information about Premium plans that were created after 16 July 2020 or about Plus plans (including Plus Trial), see [these docs](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-pricing-plans).\n\nPrivate data use cases have the following features, limits, and prices:\n\n\n\n Lite \n\n\n\n Size Number of Docs* Price \n\n N\/A 1,000 docs total Free \n\n\n\nThe Lite plan is a starter plan, so do not use it in your production environment. When you upgrade to a paid plan, you can keep all ingested documents. Lite plan instances are deleted after 30 days of inactivity.\n\nAttributes:\n\n\n\n* 1 environment\n* Up to 2 collections\n* Free NLU enrichments**\n\n\n\nAdditional options:\n[Custom Models](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-integrating-with-wks):\nOne IBM Watson\u2122 Knowledge Studio model included. Additional models: Not available\n[Element Classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification)***: 500 pages included per month. Additional pages: Not available\n[News Queries](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-watson-discovery-news): 200 News queries included per month. Additional queries: Not available\n[Query Expansions](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsquery-expansion): 500 query expansions with 1,000 total terms. Additional expansions: Not available\n[Document splitting](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicedoc-segmentation): 250 segments per plan. Additional segments: Not available","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans"},{"document_id":"ibmcld_01029-0-4062","score":21.2455196381,"text":"\n\n\n\n\n\n\n  Free Lite plan \n\nThe IBM\u00ae Db2\u00ae on Cloud Lite plan provides basic resources for you to develop or learn about Db2 without charge.\n\nThere is no time limit on the Lite plan, but users must re-extend their Lite plan every 30 days.\n\nOnly community support is available.\n\n\n\n  Architecture \n\nUnlike other Db2 on Cloud plans, the free Db2 on Cloud Lite plan runs on a multi-tenant system.\n\nThe Lite plan uses one database schema.\n\nFor more information about the free Db2 on Cloud Lite plan, see the [FAQ](https:\/\/ibm.biz\/db2oc_free_plan_faq).\n\n\n\n\n\n  Regional availability \n\nThe Lite plan is available in the Dallas and London regions. If you do not see the Lite plan listed in the catalog, select either Dallas or London region.\n\n\n\n\n\n  Restrictions \n\nIt is recommended that you use an enterprise-level service plan rather than a Lite service plan for mission-critical or performance-sensitive workloads.\n\nThe following table contains Db2 on Cloud Lite plan restrictions:\n\n\n\nTable 1. Db2 on Cloud Lite plan restrictions\n\n Category                Item                                                                   Restriction                                                                                              \n\n Resources               Storage                                                                200 MB of storage per user                                                                               \n                         Connections                                                            15 connections per user                                                                                  \n                         Performance                                                            Performance might fluctuate due to workloads run by other users on the multi-tenant system               \n Features & functions    Federation                                                             Not supported                                                                                            \n                         Oracle compatibility                                                   Not supported                                                                                            \n                         User-defined extensions (UDFs)                                         Not supported on any Db2 on Cloud plans, including the Lite plan                                         \n                         User management                                                        User not given administrative authority                                                                  \n                         Row and column access control (RCAC)                                   Not supported                                                                                            \n                         IBM InfoSphere Data Replication for use in loading data                Not supported                                                                                            \n Networking environment  IBM Cloud Integrated Analytics                                         Not supported                                                                                            \n                         IBM Cloud Dedicated                                                    Not supported                                                                                            \n Security compliances    Health Information Portability and Accountability Act of 1996 (HIPAA)  Not supported. Refer to your Service Description.                                                        \n                         EU General Data Protection Regulation (GDPR)                           Not supported. Refer to your Service Description.                                                        \n Account management      Reactivation                                                           Reactivation required every 30 days. If not reactivated, Lite plan services are deleted 60 days later.   \n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-free_plan"},{"document_id":"ibmcld_00558-7-1874","score":21.2452526093,"text":"\nPlans and provisioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Standard is IBM Cloudant's most feature-rich offering, receiving updates and new features first. Pricing is based on provisioned throughput capacity that is allocated and data storage that is used, making it suitable for any required load.\n\nThe free [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) includes a fixed amount of throughput capacity and data for development and evaluation purposes. The paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan) offers configurable provisioned throughput capacity and data storage pricing that scales as your application requirements change. An optional [Dedicated Hardware plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicdedicated-hardware-plan) is also available for an extra monthly fee to run one or more of your Standard plan instances on a dedicated hardware environment. The dedicated hardware environment is for your sole use. If a Dedicated Hardware plan instance is provisioned within a US location, you can optionally select a [HIPAA](https:\/\/en.wikipedia.org\/wiki\/Health_Insurance_Portability_and_Accountability_Act) -compliant configuration.\n\n\n\n Plans \n\nYou can select which plan to use when you [provision your IBM Cloudant service instance](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioning-a-cloudant-nosql-db-instance-on-ibm-cloud). The available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_13038-7-1578","score":21.0327949524,"text":"\nService plans \n\nDifferent pricing plans are available that you can choose for an IBM Cloud Activity Tracker instance. Each plan defines the number of days that data is retained for search, the number of users allowed to manage the data, and the features that are enabled.\n\n\n\nTable 1. List of service plans\n\n Plan Number of days that data is available for seach Number of users per plan Plan Name Plan ID \n\n HIPAA 30 day Event Search 30 25 hipaa-30-day 254d26dc-3ef5-4006-912c-954186a0d033 \n 30 day Event Search 30 Unlimitted 30-day e914263e-8b62-475e-8206-938e3a31ad26 \n 14 day Event Search 14 Unlimitted 14-day b7f77c86-adde-4e32-8a1b-daba35b1d4fa \n 7 day Event Search 7 Unlimitted 7-day 9aae7491-5cb6-43eb-9b7a-3e0456c781f0 \n Lite[] Data is not available for search 1 lite 6efc5a58-4289-4632-867f-5a25e817bfe9 \n\n\n\n[] In the lite plan, the log line is not formatted.\n\nIBM Cloud Activity Tracker offers a Lite plan that you can use to view your events as they pass through the system. You can view events by using event tailing. You can also design filters to prepare for upgrading to a longer retention period plan. You cannot use an instance on the Lite plan to receive streamed data. This plan has a 0-day retention period.\n\n\n\n Features by plan \n\nThe following tables outline the different features that are included in each service plan:\n\n\n\nTable 2. List of features available that are available for each service plan\n\n Feature HIPAA 30 day Event Search plan 30 day Event Search plan 14 day Event Search plan 7 day Event Search plan Lite plan \n\n Live streaming tail !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/activity-tracker?topic=activity-tracker-service_plan"},{"document_id":"ibmcld_07578-1076793-1078629","score":21.0234889984,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2371977128,"ndcg_cut_10":0.2371977128}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01029-0-4062","score":23.3079948425,"text":"\n\n\n\n\n\n\n  Free Lite plan \n\nThe IBM\u00ae Db2\u00ae on Cloud Lite plan provides basic resources for you to develop or learn about Db2 without charge.\n\nThere is no time limit on the Lite plan, but users must re-extend their Lite plan every 30 days.\n\nOnly community support is available.\n\n\n\n  Architecture \n\nUnlike other Db2 on Cloud plans, the free Db2 on Cloud Lite plan runs on a multi-tenant system.\n\nThe Lite plan uses one database schema.\n\nFor more information about the free Db2 on Cloud Lite plan, see the [FAQ](https:\/\/ibm.biz\/db2oc_free_plan_faq).\n\n\n\n\n\n  Regional availability \n\nThe Lite plan is available in the Dallas and London regions. If you do not see the Lite plan listed in the catalog, select either Dallas or London region.\n\n\n\n\n\n  Restrictions \n\nIt is recommended that you use an enterprise-level service plan rather than a Lite service plan for mission-critical or performance-sensitive workloads.\n\nThe following table contains Db2 on Cloud Lite plan restrictions:\n\n\n\nTable 1. Db2 on Cloud Lite plan restrictions\n\n Category                Item                                                                   Restriction                                                                                              \n\n Resources               Storage                                                                200 MB of storage per user                                                                               \n                         Connections                                                            15 connections per user                                                                                  \n                         Performance                                                            Performance might fluctuate due to workloads run by other users on the multi-tenant system               \n Features & functions    Federation                                                             Not supported                                                                                            \n                         Oracle compatibility                                                   Not supported                                                                                            \n                         User-defined extensions (UDFs)                                         Not supported on any Db2 on Cloud plans, including the Lite plan                                         \n                         User management                                                        User not given administrative authority                                                                  \n                         Row and column access control (RCAC)                                   Not supported                                                                                            \n                         IBM InfoSphere Data Replication for use in loading data                Not supported                                                                                            \n Networking environment  IBM Cloud Integrated Analytics                                         Not supported                                                                                            \n                         IBM Cloud Dedicated                                                    Not supported                                                                                            \n Security compliances    Health Information Portability and Accountability Act of 1996 (HIPAA)  Not supported. Refer to your Service Description.                                                        \n                         EU General Data Protection Regulation (GDPR)                           Not supported. Refer to your Service Description.                                                        \n Account management      Reactivation                                                           Reactivation required every 30 days. If not reactivated, Lite plan services are deleted 60 days later.   \n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-free_plan"},{"document_id":"ibmcld_01183-7-2154","score":23.2834911346,"text":"\nChoosing your plan \n\nEvent Streams is available as Lite plan, Standard plan, Enterprise plan, or Satellite plan depending on your requirements.\n\nFor information about Event Streams plan pricing, see the [catalog](https:\/\/cloud.ibm.com\/catalog). Search for Event Streams, then click the Event Streams tile to go to the provisioning page.\n\n\n\n Lite plan \n\nThe Lite plan is free for users who want to try out Event Streams or build a proof-of-concept. Do not use the Lite plan for production use. It offers shared access to a multi-tenant Event Streams cluster.\n\n\n\n\n\n Standard plan \n\nThe Standard plan is appropriate if you require event ingest and distribution capabilities but do not require any additional benefits of the Enterprise plan. The Standard plan offers shared access to a multi-tenant Event Streams cluster that seamlessly autoscales as you increase the number of partitions you are using for your workload.\n\nThe architecture is highly available by default. The service is distributed across three availability zones, which means that the cluster is resilient to the failure of a single zone or any component within that zone.\n\n\n\n\n\n Enterprise plan \n\nThe Enterprise plan is appropriate if data isolation, performance, and increased retention are important considerations. The Enterprise plan includes the following features:\n\n\n\n* Exclusive access to a single-tenant Event Streams service instance deployed in a highly available multi zone region (MZR).\n* Option to provision a single-tenant Event Streams service instance in a geographically local but single zone location [(SZR)](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-slasla_szr).\n* Scaling options to customize throughput, storage capacity, or both.\n\n\n\nThe architecture is highly available when you choose to deploy into a multi-zone region. The service is distributed across three availability zones, which means that the cluster is resilient to the failure of a single zone or any component within that zone.\n\n\n\n\n\n Satellite plan \n\nThe IBM Cloud Satellite\u00ae plan is appropriate if you want to deploy an Enterprise plan into Satellite locations of your own choice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose"},{"document_id":"ibmcld_00558-1499-3456","score":23.0177440643,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_01660-8584-10307","score":23.0070858002,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_01705-14609-15453","score":22.992641449,"text":"\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite%20lite) that has a Lite plan.\n* After 10 days of no development activity, your apps go to sleep. You can wake up your apps by continuing to work on them.\n* After 30 days of no development activity, your service instances with Lite plans are deleted\n\n\n\nOnly Lite accounts created before 12 August 2021 can use 186 GBH of free buildpacks and Cloud Foundry apps with up to 256 MB of free instantaneous runtime memory per month. The use of one org in one IBM Cloud region is supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_12904-1535-3460","score":22.7001361847,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_01705-11723-13541","score":22.4370422363,"text":"\nWhen your service bundle expires or you use all of the credit, you can continue to use any of the services, with usage charged at the Pay-As-You Go rate.\n\n\n\n\n\n Expiring subscriptions \n\nWhen your subscription is about to expire, you are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After your subscription expires, your account is converted to a Pay-As-You-Go account, which means you pay only for billable services that you use with no contracts or commitments. In addition, the discounts that are associated with your subscription account won't apply to the Pay-As-You-Go account. Go to the [Subscriptions](https:\/\/cloud.ibm.com\/billing\/subscriptions) page to check whether any of your subscriptions are approaching their expiration date.\n\nYou can work with [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to renew your subscription account.\n\n\n\n\n\n\n\n Enterprise Savings Plan billing model \n\nIBM Cloud customers can sign up for the Enterprise Savings Plan billing model. With this billing model, you commit to spend a certain amount on IBM Cloud and you also receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount. For more information about the billing model, see [Enterprise Savings Plan pricing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use).\n\n\n\n\n\n Lite account \n\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/Lite.svg) in the catalog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_01148-5517-7002","score":22.3570022583,"text":"\n: Release of the [Lite plan](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_chooseplan_lite) in US-South allowing users to provision a minimal Event Streams instance for free.\n\n\n\n\n\n 1 July 2019 \n\nUpdates to Enterprise plan\n: Apache Kafka version upgrade.\n: Support for Cloud Service Endpoints.\n\nKafka version upgrade\n: Event Streams Enterprise supports version 2.2 of Apache Kafka to align with our recently released and upgraded Standard plan.\n: This update for Event Streams is nondisruptive and was tested with our supported Kafka client list.\n: If your Kafka client is not on this list, then while we expect the upgrade to be nondisruptive, these clients were not tested and we cannot offer any support statement for these clients. If this is a concern, do any extra testing that you require.\n: Note: The Standard plan is already updated to Apache Kafka version 2.2 and can be used for extra testing.\n\nSupport for Cloud service endpoints\n: Event Streams supports Cloud service endpoints.\n: This capability means that any data that you publish or consume from the Event Streams service is over the private network and not public interfaces.\n\n\n\n\n\n 14 May 2019 \n\nNew Standard plan\n: Support for Apache Kafka version 2.2.\n: Support for fine-grained authorization to topic level.\n: Support for availability zones to further increase the resiliency of the service.\n: A brand new IBM\u00ae Design Thinking-led developer and user experience.\n: Available in the US-South region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-event-streams-relnotes"},{"document_id":"ibmcld_03749-1776-3774","score":22.2440509796,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/enterprise-billing-usage.svg)\n\nFigure 1.Enterprise billing and usage management\n\n\n\n\n\n Billing options \n\nEnterprises require subscription billing or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). In subscription billing, you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate. The Enterprise Savings Plan billing model is similar to subscription billing. You commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nThe account that you use to create the enterprise must be a [Subscription account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). After the enterprise is created, you can add more accounts to the enterprise. If you add a Lite or trial account, the account is automatically upgraded to a Pay-As-You-Go account.\n\nSome Pay-As-You-Go accounts can't be directly imported into an enterprise, such as many Pay-As-You-Go accounts that are billed in United States dollars (USD). However, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency. All accounts must use the enterprise billing currency before you add them to the enterprise. Existing accounts that are imported into the enterprise no longer separately manage their billing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"},{"document_id":"ibmcld_07122-1149-3205","score":22.1261444092,"text":"\nFor information about upgrading from a Lite to an Advanced v1 plan, see [Upgrading your service](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-upgrading-your-planservice) in the v1 documentation.\n\nEven though you can use the Plus plan for the first 30 days at no charge, you must have a paid account to create a Plus plan. For more information about creating a paid account, see [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account).\n\n\n\n1. How you upgrade depends on your plan.\n\n\n\n* If you decide you want to keep the Plus plan after using the 30-day free trial, no action is required.\n\nAfter 30 days of using the Plus plan at no cost, you are charged for it.\n* If you decide you do not want to continue using the Plus plan, delete the Plus plan service instance before the 30-day trial period ends. You can delete the service instance from the [IBM Cloud Resource list](https:\/\/cloud.ibm.com\/resources).\n\nThe number of days that are left in your trial is displayed in the page header.\n* To upgrade a Plus plan to an Enterprise plan, complete the following steps:\n\n\n\n* Open the service page for your Plus plan service instance from the [IBM Cloud Resource list](https:\/\/cloud.ibm.com\/resources).\n* Click Upgrade.\n* Choose the Enterprise plan, and then click Save.\n* Give the upgrade process time to finish.\n\nThe time it takes to convert the plan varies depending on the amount of data in your existing Plus plan service instance. It takes at least 20 minutes and, for instances with large amounts of data, can take more than a day to complete. The IBM Cloud page does not show progress information and doesn't indicate when the plan upgrade process is finished. To check whether the new plan is in effect, you must refresh the service instance overview page, and then check for the new plan name to be displayed in the Plan tile.\n\nDuring the plan upgrade process, you can continue to submit search queries in your existing projects. However, avoid the following actions:\n\n\n\n* Adding new projects or collections","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-upgrade"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01705-7074-9036","score":21.1424884796,"text":"\nAlso, with a Pay-As-You-Go account, you can order Advanced or Premium support plans to get extra help with your production workloads. Learn more in [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n\nA subset of Pay-As-You-Go accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use).\n\n\n\n\n\n Subscription account \n\nSubscription accounts offer many of the same benefits as Pay-As-You-Go accounts, including access to the full IBM Cloud catalog and the ability to create multiple resource groups. In addition, Subscription accounts provide discounts for platform services and support and more consistent billing through subscriptions. You can also [set up spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) to get notified when your account or a particular service reaches a specific spending threshold that you set.\n\nWhen you purchase a subscription, you commit to a minimum spending amount for a certain period of time and receive a discount on the overall cost. For example, if you commit to spend $1,000 a month for 6 months, you might get a 5% discount. For the duration of the subscription, you get $6,000 of usage but pay only $5,700 for it. The larger the subscription, the better the discount.\n\nLarge organizations and other users with large cloud workloads can benefit from the savings and predictable billing that are provided by subscriptions. IBM Cloud offers multiple types of subscriptions to fit your usage needs.\n\nA subset of subscription accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountscommitment-model).\n\n\n\n Platform subscriptions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_02361-4487-6654","score":21.0062980652,"text":"\nEach account retains the features of a stand-alone account, and you can still manage billing and payments from the enterprise account.\n\nIn addition to these benefits, when you look into auditing and how it fits with any of these management strategies, consider the following that will be covered later in more detail:\n\n\n\n* Auditing events are collected and available per location (region) through 1 single auditing instance. You do not have the ability to split events from different services running in the same region to multiple instances. If you run your development, test, and production services in a stand-alone account, all those events will be available through the same auditing instance, and any user with permissions to view events in that instance will be able to see everything.\n* The auditing instance in Frankfurt collects events from global services such as IAM.\n\n\n\nDefine an enterprise account management strategy to add an additional layer of isolation to resources.\n\n\n\n\n\n Configure account settings for compliance \n\nAcross every industry, organizations require tight controls and visibility into where their data is stored and processed.\n\nIndicate to IBM your compliance requirements by enabling your IBM Cloud account or IBM Cloud Entreprise account as HIPAA or EU supported.\n\nIn the IBM Cloud, you can configure your account for EU support and for HIPAA support:\n\n\n\n* You might choose to enable the EU Supported setting, for example, if you use resources to process personal data for European citizens. For more information, see [Set the EU-Supported flag on in your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-eu-hipaa-supportedbill_eusupported).\n* You might choose to enable the HIPAA Supported setting if you plan to include Protected Health Information (PHI) in HIPAA-enabled services. For more information, see [Set the HIPAA flag on in your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-eu-hipaa-supportedenabling-hipaa).\n\n\n\nOnly the account owner can enable the account to be EU supported and HIPAA supported.\n\n\n\n HIPAA \n\nIf you're the account owner, you can enable your IBM Cloud\u00ae account to be HIPAA supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_09275-3980-6231","score":20.965970993,"text":"\nFor example, you might have a stand-alone account where you run your development, pre-production, and production services and applications.\n\nBy using an enterprise management account strategy, you achieve greater isolation of resources. When you configure a multitiered hierarchy of accounts, you get the flexibility to separate your development environments into separate tiers, or isolate by Line of Business (LoB) applications and services, or a combination of both. Each account retains the features of a stand-alone account, and you can still manage billing and payments from the root enterprise account.\n\nIn addition to these benefits, when you look into logging and how it fits with any of these management strategies, consider the following facts that will be covered later on in the topic in more detail:\n\n\n\n* Service platform logs are collected and available per location (region) through 1 single logging instance. You do not have the ability to split logs from different services running in the same region to multiple instances. If you run your development, test, and production services in a stand-alone account, all those logs will be available through the same logging instance, and any user with permissions to view logs in that instance will be able to see everything.\n* You can configure other log sources in IBM Cloud and on-premisses to forward logs to any logging instance in your account.\n\n\n\nDefine an enterprise account management strategy to add an additional layer of isolation to resources in addition to stand-alone accounts.\n\n\n\n\n\n Configure account settings for compliance \n\nAcross every industry, organizations require tight controls and visibility into where their data is stored and processed.\n\nIndicate to IBM your compliance requirements by enabling your IBM Cloud account or IBM Cloud Entreprise account as HIPAA or EU supported.\n\nIn the IBM Cloud, you can configure your account for EU support and for HIPAA support:\n\n\n\n* You might choose to enable the EU Supported setting, for example, if you use resources to process personal data for European citizens. For more information, see [Set on the EU-Supported flag in your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-eu-hipaa-supportedbill_eusupported).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoption"},{"document_id":"ibmcld_11163-68646-70819","score":20.9290504456,"text":"\nFor more information, see [Support subscriptions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssupport-subscriptions).\n\nYou can also now view your support subscriptions in the IBM Cloud console so you can keep track of your available credit. For more information, see [Viewing your support costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-support).\n\n\n\n\n\n 12 September 2019 \n\nRedirecting SoftLayer to IBM Cloud\n: SoftLayer account owners who previously didn't have access to the IBM Cloud platform can now manage their infrastructure, services, and applications from one location: [cloud.ibm.com](https:\/\/cloud.ibm.com).\n\n\n\n\n\n\n\n July 2019 \n\n\n\n 25 July 2019 \n\nIBM Cloud enterprises for centrally managing multiple accounts\n: You can now centrally manage billing and usage for multiple accounts by creating an IBM Cloud enterprise. With an enterprise, you can create a multitiered hierarchy of accounts by organizing related accounts into account groups. Enterprises simplify management of multiple accounts with the following key features:\n\n\n\n* Consolidated billing means that you can manage billing, invoicing, and payment for all accounts from a single place, the enterprise account.\n* Subscription credit is aggregated into a credit pool and shared with all accounts in the enterprise. Not only is tracking your subscriptions easier, but you can get fewer, larger subscriptions for a better discount because the credit is shared.\n* Top-down usage reporting gives you a unified view of usage costs from all accounts, organized according to your enterprise hierarchy.\n\n\n\nIf you have multiple accounts, at least one of which is a Subscription account, you can create an enterprise. See [What is an enterprise?](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise) and [Introducing IBM Cloud Enterprises](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/introducing-ibm-cloud-enterprises) for more information.\n\nSubscriptions page for tracking subscription credit spending\n: If you have a Subscription account, you can now view all of your subscriptions and analyze your credit spending on the Subscriptions page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatsnew"},{"document_id":"ibmcld_01705-8543-10743","score":20.8678302765,"text":"\nLarge organizations and other users with large cloud workloads can benefit from the savings and predictable billing that are provided by subscriptions. IBM Cloud offers multiple types of subscriptions to fit your usage needs.\n\nA subset of subscription accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountscommitment-model).\n\n\n\n Platform subscriptions \n\nWhen you purchase a subscription for the IBM Cloud platform, you get discounted credit that pays for services and other resources that you create from the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog).\n\nYour resource usage is deducted from your total subscription amount. Even if your usage varies from month to month, you get predictable, consistent billing. If your usage exceeds your total subscription amount, you're charged the non-discounted rate for the overage. For more information about tracking your subscription usage, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYour subscription applies to most services in the catalog. However, some services use a specific pricing plan that requires you to purchase it separately.\n\n\n\n\n\n Support subscriptions \n\nBasic support is included with your Subscription account. If you want to enhance your support experience for production-critical resources, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to purchase a support subscription for an Advanced or Premium support plan. With a support subscription, you commit to a monthly spending amount that goes towards your support costs.\n\nSupport subscription credit is separate from any platform or service subscription credit in your account and can't be spent on resource usage. For more information, see [How subscription credit is spent](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptionssubscription-basics).\n\n\n\n\n\n Service bundle subscriptions \n\nService bundle subscriptions give you access and credit toward a set of services within a particular domain that are targeted for popular use cases.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_08069-7-2230","score":20.5162944794,"text":"\nBasic, Advanced, and Premium Support plans \n\nYou can choose a Basic, Advanced, or Premium support plan to customize your IBM Cloud\u00ae support experience for your business needs. The level of support that you select determines the severity that you can assign to support cases and your level of access to the tools available in the Support Center.\n\nIf you have free support, you're provided technical support through [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud?tab=Newest). Also, with a Lite account and free support, you can open cases that are related to access management, accounts, and billing and usage. If you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative.\n\nInitial response Service Level Objectives (SLO) do not apply to any billing, invoice, or sales related inquiry or cases.\n\nThe following table shows the support types available for Pay-As-You-Go accounts, Subscription accounts, and the Enterprise Savings Plan billing model. For more information about accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\nTable 1. Support plans\n\n Basic Support Advanced Support Premium Support \n\n Description Basic business protection that is included with your IBM Cloud Pay-As-You-Go or Subscription account Prioritized case handling and support experience that is aligned with your business needs for your Pay-As-You-Go account, Subscription account, or Enterprise Savings Plan billing model Client engagement that is aligned with your business outcomes to accelerate time-to-value for your Pay-As-You-Go account, Subscription account, or Enterprise Savings Plan billing model \n Availability 24 x 7 access to the IBM Cloud technical support team through cases <br>Phone and chat are available only for Pay-As-You-Go and Subscription accounts 24 x 7 access to the IBM Cloud technical support team through cases, phone, and chat 24 x 7 access to the IBM Cloud technical support team through cases, phone, and chat \n [Case severity](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity) Not applicable Case severity ranking available Case severity ranking available","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans"},{"document_id":"ibmcld_12561-4-2339","score":20.4734172821,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Viewing usage in an enterprise \n\nYou can track resource and support costs from accounts in your IBM Cloud\u00ae enterprise by viewing their usage. The accounts and account groups that you can view usage for depend on your assigned access.\n\nIBM Cloud enterprises enable you to centrally manage multiple IBM Cloud accounts. As an enterprise user, you can keep an eye on resource usage and the associated costs for any account in the enterprise. See [What is an enterprise?](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise) for more information.\n\n\n\n Required access for viewing enterprise usage \n\nIn an enterprise, access to usage information is controlled by the Enterprise service. To view usage information, users must be invited to the enterprise account and have the Usage Reports Viewer, Editor, or Administrator role on the Enterprise service. The Usage Reports Viewer role provides access only to viewing usage reports, while the Editor and Administrator roles enable additional enterprise management actions. In keeping with security best practices, assign the least amount of access that is needed for the user to complete their task. For more information, see [Enterprise actions and roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-servicesenterprise-account-management).\n\nYou can give users granular access so that they can view usage for a certain account or account group. For example, say that your enterprise has account groups for each department, and each department has account groups for each team. You can scope the access so that each enterprise user can see only the information that is needed to fulfill their job role.\n\n\n\n* Your financial officer needs to view usage for the entire enterprise so that they can track and recover costs for each department, but they don't need to create accounts or account groups. Assign them the Usage Reports Viewer role for the enterprise.\n* Each department lead needs to view usage for their department, and they also need to create and manage accounts and account groups for their teams. Assign each department lead the Editor role for their department's account group.\n* Each team lead needs to view their team's usage, but you want them to get department approval to add new accounts to their team.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-usage"},{"document_id":"ibmcld_12623-7-2328","score":20.3853397369,"text":"\nWhat is an enterprise? \n\nIBM Cloud\u00ae\n\nenterprisesprovide a way to centrally manage billing and resource usage across multiple accounts. Within an enterprise, you create a multitiered hierarchy of accounts, with billing and payments for all accounts managed at the enterprise level.\n\nWhen compared to using multiple stand-alone accounts, enterprises offer the following key benefits:\n\n\n\n* Centralized account management: View your entire enterprise hierarchy at a glance, without needing to switch accounts. You can add existing accounts or create new accounts directly within the enterprise.\n* Consolidated subscription billing: Track your subscriptions and credit spending for all accounts from a single view. Your subscription credit is pooled and shared among accounts in the enterprise.\n* Top-down usage reporting: From your enterprise account, you can view usage of all accounts in your enterprise, which is organized by account group.\n\n\n\n\n\n Watch and learn \n\n\n\n* Video transcript\n\nYour IBM Cloud account is your home for collaboration in the cloud. As you scale up your workloads, you might find that you're managing multiple IBM Cloud accounts. For example, your company might have many teams, each with one or more of their own accounts for development, testing, and production environments. Or, you might isolate certain workloads in separate accounts to meet security or compliance guidelines. As the number of accounts grows, it can become more difficult to track resource usage and associated costs.\n\nIBM Cloud enterprises offer a simpler way to centrally manage billing and usage across multiple accounts. Within an enterprise, you can create a multi-tiered hierarchy of accounts by adding new or existing accounts and nesting them in account groups. How you structure your enterprise is up to you. For example, for a large organization, you might organize your accounts by geography, or by department. You can choose the structure that best fits how you want to track your usage. If your teams change, no problem - you can move accounts within the enterprise as needed.\n\nConsolidated billing simplifies invoicing and payment within your enterprise. Usage costs are deducted from a subscription credit pool that's shared between all accounts, so you can add and manage subscription credit from a single place.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise&interface=ui"},{"document_id":"ibmcld_03749-3299-5633","score":20.3821544647,"text":"\nHowever, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency. All accounts must use the enterprise billing currency before you add them to the enterprise. Existing accounts that are imported into the enterprise no longer separately manage their billing. As a result, subscription credit can't be added to individual child accounts. Subscription credit must be added to the enterprise account, where it becomes part of the enterprise credit pool.\n\n\n\n Billing transition when importing accounts \n\nWhen you import an existing account to an enterprise, its billing and invoicing transitions to being managed by the enterprise account. This transition includes the following changes to the account.\n\n\n\n* For Subscription accounts that are added, the account type is changed to Pay-As-You-Go. This change reflects that the account does not have its own subscriptions, but it still has full access to production-ready, billable services.\n* Subscriptions and promotions from each account are moved to the enterprise account, where they become part of the credit pool. After the move, each subscription has the same remaining credit and term period, but the subscription is given a new unique ID.\n* Access to billing and payment information for future billing periods is restricted to users in the enterprise account. Users in a child account can't access billing and payment information, such as invoices, payments, or subscriptions, even if they previously had access in the account. To view or manage billing, users need to be invited to the enterprise account and given access to the Billing service in that account.\n* Usage is invoiced to the enterprise account for the entire month when the account was added. For example, if you add an account to the enterprise on 15 June, all of the usage for the month of June is reflected in the July invoice.\n\n\n\n\n\n\n\n Shared credit pool \n\nThe enterprise credit pool consolidates credit from all accounts in the enterprise and shares it with the accounts. The pool includes credit from all sources, including platform subscription credit, promotional credit, and support credit.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"},{"document_id":"ibmcld_12623-5165-7280","score":20.3709831238,"text":"\nEnterprises require [subscription billing](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). Subscription billing means that you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate. Subscription credit, as well as credit from any promotions, is added to the enterprise credit pool, which is shared across all accounts in the enterprise. As accounts use resources, credit is spent from the credit pool. The Pay as you go with Committed Use billing model is similar to the billing model for Subscription accounts. You commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nZoom\n\n![A diagram that shows that credit from accounts is added to the enterprise credit pool, which is managed by the billing administrator in the enterprise account.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d4595e5202a9a27767cf034e81b038cdf772e0d5\/secure-enterprise\/images\/enterprise-billing.svg)\n\nFigure 2. Enterprise billing management\n\nBecause billing is consolidated, enterprises make managing invoicing and payments across multiple accounts easier with these key benefits:\n\n\n\n* A credit pool of subscriptions that span multiple accounts, so you can size your subscriptions for all of your usage rather than usage per account\n* A single invoice for all usage within the enterprise, so understanding costs is easier\n* A single place to manage payment methods, so you can update once for all accounts\n\n\n\nLearn more in [Centrally manage billing and usage with enterprises](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise).\n\n\n\n\n\n Enterprise support \n\nThe level of support that is assigned to an IBM Cloud enterprise defaults to the highest support plan within the enterprise.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.156426242}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-7-2136","score":16.8417263031,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-7-2136","score":16.8417263031,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_02361-24500-26305","score":14.1497974396,"text":"\n[Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_16727-459832-462063","score":14.0364665985,"text":"\nThis fact is a price of scalability and data resilience.\n\nIt is best to structure your data so that resolving conflicts is quick and does not involve operator assistance. This practice helps your databases to hum along smoothly. The ability to automatically resolve conflicts without user involvement significantly improves their experience and reduces the support burden on your organization.\n\nHow you resolve conflicts is application-specific. See the following tips for more ways to improve the process:\n\n\n\n* Avoid invariants across document fields if possible. Avoiding invariants makes it more likely that a simple merge operation, if you take the changed field from each conflicted document revision, is suitable. This practice makes simpler and more robust application code.\n* Allow documents to be independent. If you have to retrieve other documents to work out the correct resolution, it increases latency in conflict resolution. There's also a chance you get a version of the other documents that aren't consistent with the document you're resolving, making correct resolution difficult.\n\n\n\n\n\n\n\nHeavily conflicted documents exert a heavy toll on the database. Building in the capability to resolve conflicts from the beginning is a great help in avoiding pathologically conflicted documents.\n\n\n\n\n\nThese tips demonstrate how modeling data affects your application\u2019s performance. IBM Cloudant\u2019s data store has some specific characteristics, both to watch out for and to take advantage of, that ensure the database performance scales as your application grows. IBM Cloudant support understands the shift can be confusing, so they are always available to give advice.\n\nFor more information, see the [data model for Foundbite](https:\/\/cloudant.com\/blog\/foundbites-data-model-relational-db-vs-nosql-on-cloudant\/), or the [example from our friends at Twilio](https:\/\/www.twilio.com\/blog\/2013\/01\/building-a-real-time-sms-voting-app-part-3-scaling-node-js-and-couchdb.html).\n\n\n\n* When must I make my documents immutable?\n\nIf you're changing the same piece of state at a rate of once per second or more, consider making your documents immutable. This practice significantly reduces the chance that you create conflicted documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-459850-462081","score":14.0364665985,"text":"\nThis fact is a price of scalability and data resilience.\n\nIt is best to structure your data so that resolving conflicts is quick and does not involve operator assistance. This practice helps your databases to hum along smoothly. The ability to automatically resolve conflicts without user involvement significantly improves their experience and reduces the support burden on your organization.\n\nHow you resolve conflicts is application-specific. See the following tips for more ways to improve the process:\n\n\n\n* Avoid invariants across document fields if possible. Avoiding invariants makes it more likely that a simple merge operation, if you take the changed field from each conflicted document revision, is suitable. This practice makes simpler and more robust application code.\n* Allow documents to be independent. If you have to retrieve other documents to work out the correct resolution, it increases latency in conflict resolution. There's also a chance you get a version of the other documents that aren't consistent with the document you're resolving, making correct resolution difficult.\n\n\n\n\n\n\n\nHeavily conflicted documents exert a heavy toll on the database. Building in the capability to resolve conflicts from the beginning is a great help in avoiding pathologically conflicted documents.\n\n\n\n\n\nThese tips demonstrate how modeling data affects your application\u2019s performance. IBM Cloudant\u2019s data store has some specific characteristics, both to watch out for and to take advantage of, that ensure the database performance scales as your application grows. IBM Cloudant support understands the shift can be confusing, so they are always available to give advice.\n\nFor more information, see the [data model for Foundbite](https:\/\/cloudant.com\/blog\/foundbites-data-model-relational-db-vs-nosql-on-cloudant\/), or the [example from our friends at Twilio](https:\/\/www.twilio.com\/blog\/2013\/01\/building-a-real-time-sms-voting-app-part-3-scaling-node-js-and-couchdb.html).\n\n\n\n* When must I make my documents immutable?\n\nIf you're changing the same piece of state at a rate of once per second or more, consider making your documents immutable. This practice significantly reduces the chance that you create conflicted documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_04866-4961-6763","score":14.0084085464,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-4961-6763","score":14.0084085464,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_06808-1384-2991","score":13.8767976761,"text":"\n[Learn more](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidencecd-devsecops-cos-bucket-resiliency).\n\n\n\n\n\n Naming your bucket \n\nCloud Object Storage object names consist of the following components:\n\n{NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} \/ {FILE_NAME} _ {HASH}\n\n\n\n Examples: \n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/evidences\/build-vulnerability-advisor.json_362c06afa88b3f304878f0d0979e834f\n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/artifacts\/app-image-va-report.json_b3f30487f0d0979e834f362c06afaaa8\n\nThe name component {NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} is useful as a prefix when you're looking for collected data from a certain pipeline run.\n\n\n\n\n\n Retention policy \n\nYou can set Cloud Object Storage buckets to enforce a retention policy or period for uploaded objects, otherwise known as [Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable). Immutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a Write-One-Read-Many (WORM), non-erasable, and non-rewritable manner. You cannot change or delete objects in protected buckets within the retention period, or delete protected buckets with objects themselves until the retention period is over. The policy is enforced until the end of a retention period and the removal of any legal holds.\n\nIt is recommended that teams set a retention policy for the buckets that are used as their evidence locker that stores every object for a minimum of 365 days.\n\n\n\n\n\n\n\n Audit event log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidence"},{"document_id":"ibmcld_04862-7-1848","score":13.8580570221,"text":"\nUsing Aspera high-speed transfer \n\nAspera high-speed transfer overcomes the limitations of traditional FTP and HTTP transfers to improve data transfer performance under most conditions, especially in networks with high latency and packet loss.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nInstead of the standard HTTP PUT operation, Aspera high-speed transfer uploads the object by using the [FASP protocol](https:\/\/www.ibm.com\/products\/aspera\/technology). Using Aspera high-speed transfer for uploads and downloads offers the following benefits:\n\n\n\n* Faster transfer speeds\n* Transfer large object uploads over 200 MB in the console and 1 GB by using an SDK or library\n* Upload entire folders of any type of data, such as multi-media files, disk images, and any other structured or unstructured data\n* Customize transfer speeds and default preferences\n* Transfers can be viewed, paused, resumed, or cancelled independently\n\n\n\nAspera high-speed transfer is available in the IBM Cloud [console](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-asperaaspera-console) and can also be used programmatically by using an [SDK](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-asperaaspera-sdk).\n\nAspera high-speed transfer is available in certain regions only. See [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availability) for more details.\n\nIt isn't possible to use Aspera high-speed transfer if a targeted bucket has an [Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) policy.\n\n\n\n Using the console","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-aspera"},{"document_id":"ibmcld_07990-1593-3803","score":13.7215023041,"text":"\nThe storage should be configured as \u201cimmutable object storage.\u201d Retention policies are should be applied to the storage, so that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. The policy is set and enforced for a 12-month (minimum) retention period.\n\n\n\n* Authenticating users with MFA using a physical hardware-based security key that generates a six-digit numerical code. A smart card or hardware token designed and operated to FIPS 140-2 level 2 or above or equivalent (e.g., ANSI X9.24, ISO 13491-1:2007) is recommended.\n* Locking user accounts after three (3) consecutive failed logon attempts within 15 minutes.\n* Locking user accounts for 30 minutes when there have been more than three unsuccessful logon attempts. After the lockout period ends, the user will be able to reset their password. Internal privileged accounts must remain locked until released by an administrator.\n* Session timeout after 15 minutes of inactivity.\n* Providing a system use notification banner from either the bastion or the target system. The warning banner is displayed before the system grants access to the user and the usage conditions must be approved before proceeding. The banner will provide privacy and security notices consistent with applicable customer policies, regulations, standards, and guidance. The warning banner will state that:\n\n\n\n* Users are accessing a financial services information system.\n* Information system usage may be monitored, recorded, and subject to audit.\n* Unauthorized use of the information system is prohibited and subject to criminal and civil penalties.\n* Use of the information system indicates consent to monitoring and recording.\n\n\n\n\n\n\n\n Set up a bastion host \n\nYou need to install and manage your own bastion solution within your management VPC. There are various ways a bastion solution can be implemented. For one example that uses Teleport Enterprise Edition, see [Setting up a bastion host for secure connectivity](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-bastion-tutorial-teleport).\n\n\n\n\n\n Related controls in IBM Cloud Framework for Financial Services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-bastion"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.5,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.6366824387,"ndcg_cut_10":0.7668091221}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-6428-8391","score":14.2580003738,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-6428-8442","score":13.2036380768,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_14708-3638-5837","score":10.2312364578,"text":"\nThe [Compliance assessment report (by Cohasset)](https:\/\/www.veeam.com\/wp-compliance-assessment-report-cohasset.html) describes the settings that must be configured to become compliant with the following regulations:\n\n\n\n* FINRA Rule 4511.\n* SEC Rule 17a-4(f).\n* CFTC Rule 1 .31 (c)-(d).\n\n\n\nThe previous assessment report considers the following details as best practice for a Linux hardened repository:\n\n\n\n* The Linux hardened repository can be independent or Scale-out backup repository. A repository that retains immutable backup files for compliance with SEC 17a-4(f) must be configured as a stand-alone backup repository as a Veeam Scale-Out backup Repository is not compliant with this rule.\n* It is recommended that the name and description attributes for the repository include the word \u201cimmutable\" when the Linux hardened repository feature is enabled.\n* To protect against the possibility of premature deletion of backup files that can result from accelerating the system time clock, Linux OS must be configured to synchronize with a secure time source. For example, with a network time protocol (NTP) clock.\n* Ensure separation of duties by assigning management of Linux hardened repositories to a team other than backup administrators.\n* Veeam recommends XFS for performance and space efficiency reasons (block cloning support). Due to the requirement for periodic full backups, means that due to fast cloning, synthetic full backups take no physical disk space, except for metadata.\n* Only backup job configurations with forward incremental with synthetic or active full are supported. Forward incremental with synthetic full is the default backup job setting.\n* For backup copy jobs, GFS must be enabled.\n* Encryption of backup files is available as follows:\n\n\n\n* When configured in a backup job, Veeam Backup and Replication can use 256-bit AES block cypher encryption.\n* For data in transit, a global network traffic rule can be configured to enable all traffic to be encrypted through 256-bit AES encryption. When enable and two backup infrastructure components need to communicate, a dynamic key is generated by the backup server and communicated to each node over a secure channel.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr"},{"document_id":"ibmcld_04488-129621-131432","score":7.2631540298,"text":"\nYou can set an environment variable instead of specifying -i with the following command: $ export KP_INSTANCE_ID=<INSTANCE_ID>.\n\n\n\n\n\n\n\n Optional parameters \n\n\n\n* REGION\n\nSpecify a regional endpoint. This parameter is optional and if not specified, you are prompted to select a regional endpoint from a list.\n* -u, --unset\n\nUnset (remove) the regional endpoiont.\n\n\n\n\n\n\n\n\n\n kp registrations \n\nRegistrations are associations between root keys and other cloud resources, such as Cloud Object Storage (COS) buckets or Cloud Databases deployments.\n\nFor example, in Key Protect you create a root key, which is used by COS to protect data at rest.\n\nThe relationship between other cloud resources and Key Protect is called a registration.\n\nDo not delete a root key if there are resources, such as COS buckets and objects, that rely on the root key. Deleting the root key means you cannot recover those resources. This is known as \"crypto shredding\" and there is no recovery from this action.\n\nibmcloud kp registrations\n-i, --instance-id INSTANCE_ID\n[-r, --key-ring KEY_RING_ID]\n[-c, --crn-query CRN_PATTERN]\n[-k, --key-id KEY_ID_OR_ALIAS]\n[-o, --output OUTPUT]\n\n\n\n Examples \n\nThese are examples of kp registrations.\n\nRegistration examples show numerous Cloud Resource Names (CRNs). CRNs follow this format:\n\ncrn:version:cname:ctype:service-name:location:scope:service-instance:resource-type:resource\n\nSee [Cloud Resource Names](https:\/\/cloud.ibm.com\/docs\/account?topic=account-crn) for an in-depth explanation of CRN fields.\n\n\n\n Example 1 \n\nList all registrations, which may include cloud resources such as databases, storage, compute, containers, or messaging.\n\nThis example shows the registration between Cloud Object Storage (COS) and Key Protect.\n\n view all registrations\n$ ibmcloud kp registrations --output json\n\n[","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_05171-29436-30825","score":7.0398445129,"text":"\napp.set('view engine', 'ejs');\napp.use(bodyParser.json());\n\nvar title = 'COS Image Gallery Web Application';\n\/\/ Serve index.ejs\napp.get('\/', function (req, res) {\nres.render('index', {status: '', title: title});\n});\n\n\/\/...\n\nThe following figure shows what the index view template when rendered and sent to the browser. If you are using ,nodemon you might have noticed that your browser refreshed when you saved your changes.\n\nZoom\n\n![uploadimageview](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/63322f2f3a72050206eb05ba7f590fdcb741105c\/cloud-object-storage\/images\/web-app-tutorial-018-templates.jpg)\n\nFigure 8. Your updated web app by using templates and views for displays\n\nOur view templates share HTML code between the <head>...<\/head>; tags, so we placed it into a separate include template. This template (head-inc.ejs) contains a scriptlet (a binding for a JavaScript variable) for the page title on line 1. The title variable is set in app.js, and passed in as data for our view template in the line below that. Otherwise, we are simply using some CDN addresses to pull in Bootstrap CSS, Bootstrap JavaScript, and JQuery. Finally, we add a custom static styles.css file from our pubic\/stylesheets directory.\n\n<title><%=title%><\/title>\n<meta charset=\"utf-8\">\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-web-application"},{"document_id":"ibmcld_16727-683792-684829","score":6.9558992386,"text":"\nparameters = jsonencode([])\n}\n}\n\n* How do I associate a public gateway while creating multiple zones with a Subnet for each zone?\n\n\n{\n\n\"StatusCode\": 400,\n\"Headers\": {\n\n\"Cache-Control\": [\"max-age=0, no-cache, no-store, must-revalidate\"],\n\"Cf-Cache-Status\": [\"DYNAMIC\"],\n\"Cf-Ray\": [\"6ab6a5e86ac41b69-DEL\"],\n\"Connection\": [\"keep-alive\"],\n\"Content-Length\": [\"261\"],\n\"Content-Type\": [\"application\/json; charset=utf-8\"],\n\"Date\": [\"Tue, 09 Nov 2021 11:19:47 GMT\"],\n\"Expect-Ct\": [\"max-age=604800, report-uri=\"https:\/\/report-uri.cloudflare.com\/cdn-cgi\/beacon\/expect-ct\"\"],\n\"Expires\": [\"-1\"],\n\"Pragma\": [\"no-cache\"],\n\"Server\": [\"cloudflare\"],\n\"Strict-Transport-Security\": [\"max-age=31536000; includeSubDomains\"],\n\"Vary\": [\"Accept-Encoding\"],\n\"X-Content-Type-Options\": [\"nosniff\"],\n\"X-Request-Id\": [\"37b94c40-a4bf-4942-a0da-45dc5434d610\"],\n\"X-Xss-Protection\": [\"1; mode=block\"]\n},\n\"Result\": {\n\n\"errors\": [{\n\n\"code\": \"bad_field\",\n\"message\": \"Failed to attach public gateway of different zone to the subnet\",\n\"target\": {\n\n\"name\": \"public_gateway.id\",","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-683834-684871","score":6.9558992386,"text":"\nparameters = jsonencode([])\n}\n}\n\n* How do I associate a public gateway while creating multiple zones with a Subnet for each zone?\n\n\n{\n\n\"StatusCode\": 400,\n\"Headers\": {\n\n\"Cache-Control\": [\"max-age=0, no-cache, no-store, must-revalidate\"],\n\"Cf-Cache-Status\": [\"DYNAMIC\"],\n\"Cf-Ray\": [\"6ab6a5e86ac41b69-DEL\"],\n\"Connection\": [\"keep-alive\"],\n\"Content-Length\": [\"261\"],\n\"Content-Type\": [\"application\/json; charset=utf-8\"],\n\"Date\": [\"Tue, 09 Nov 2021 11:19:47 GMT\"],\n\"Expect-Ct\": [\"max-age=604800, report-uri=\"https:\/\/report-uri.cloudflare.com\/cdn-cgi\/beacon\/expect-ct\"\"],\n\"Expires\": [\"-1\"],\n\"Pragma\": [\"no-cache\"],\n\"Server\": [\"cloudflare\"],\n\"Strict-Transport-Security\": [\"max-age=31536000; includeSubDomains\"],\n\"Vary\": [\"Accept-Encoding\"],\n\"X-Content-Type-Options\": [\"nosniff\"],\n\"X-Request-Id\": [\"37b94c40-a4bf-4942-a0da-45dc5434d610\"],\n\"X-Xss-Protection\": [\"1; mode=block\"]\n},\n\"Result\": {\n\n\"errors\": [{\n\n\"code\": \"bad_field\",\n\"message\": \"Failed to attach public gateway of different zone to the subnet\",\n\"target\": {\n\n\"name\": \"public_gateway.id\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_08843-12290-13332","score":6.9551386833,"text":"\nparameters = jsonencode([])\n}\n}\n\n\n\n\n\n\n How do I associate a public gateway while creating multiple zones with a Subnet for each zone? \n\n\n{\n\n\"StatusCode\": 400,\n\"Headers\": {\n\n\"Cache-Control\": [\"max-age=0, no-cache, no-store, must-revalidate\"],\n\"Cf-Cache-Status\": [\"DYNAMIC\"],\n\"Cf-Ray\": [\"6ab6a5e86ac41b69-DEL\"],\n\"Connection\": [\"keep-alive\"],\n\"Content-Length\": [\"261\"],\n\"Content-Type\": [\"application\/json; charset=utf-8\"],\n\"Date\": [\"Tue, 09 Nov 2021 11:19:47 GMT\"],\n\"Expect-Ct\": [\"max-age=604800, report-uri=\"https:\/\/report-uri.cloudflare.com\/cdn-cgi\/beacon\/expect-ct\"\"],\n\"Expires\": [\"-1\"],\n\"Pragma\": [\"no-cache\"],\n\"Server\": [\"cloudflare\"],\n\"Strict-Transport-Security\": [\"max-age=31536000; includeSubDomains\"],\n\"Vary\": [\"Accept-Encoding\"],\n\"X-Content-Type-Options\": [\"nosniff\"],\n\"X-Request-Id\": [\"37b94c40-a4bf-4942-a0da-45dc5434d610\"],\n\"X-Xss-Protection\": [\"1; mode=block\"]\n},\n\"Result\": {\n\n\"errors\": [{\n\n\"code\": \"bad_field\",\n\"message\": \"Failed to attach public gateway of different zone to the subnet\",\n\"target\": {\n\n\"name\": \"public_gateway.id\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-faqs"},{"document_id":"ibmcld_00028-3354-4853","score":6.7224464417,"text":"\nfor param in params:\nprint(param)\nendpoint = params[0]\nbucket_name = params[1]\nlog_config_file = params[2]\naccess_key = params[3]\nsecret_key = params[4]\ncos = cos_utils.get_cos_object(access_key, secret_key, endpoint)\n\nretCode = cos_utils.download_file(log_config_file, cos, bucket_name, \"{}\/{}\".format(install_path, log_config_file))\nif (retCode != 0):\nprint(\"non-zero return code while downloading file {}\".format(str(retCode)))\nsys.exit(retCode)\nelse:\nprint(\"Successfully downloaded file...\")\nShow more\n\n\n\n\n\n\n\n Using the library set created using script based customization \n\nWhen you use a library set that you created using a script, you need to include the path of the library in certain environment variables so that the library set can be accessed by your Spark application.\n\nFor example, if your custom library is a .so file, you need to add \"EXTRA_LD_LIBRARY_PATH\" to the \"env\" section of the Spark application submit call, with the value \/home\/spark\/shared\/user-libs\/<libraryset_name>\/custom\/<subdir_if_applicable>. This prepends \"EXTRA_LD_LIBRARY_PATH\" to \"LD_LIBRARY_PATH\", ensuring that this is the first path to the .so file that is searched.\n\nIf your custom library is a JAR file and you need it to be accessible on the Spark classpath, you must specify the JAR file in the extra classpath for driver\/executor depending on where you require the JAR file. For example, to add it in front of the driver classpath, add the following property, where the library set name is java_library:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-cust-script"},{"document_id":"ibmcld_04174-9520-10475","score":6.6246109009,"text":"\nOne of true, false.\n* logpull_options: The configuration string. For example, timestamps=rfc3339&timestamps=rfc3339\n* dataset: The dataset that is pulled. One of http_requests, range_events, firewall_events.\n* frequency: The frequency at which CIS sends batches of logs to your destination. One of high, low.\n\n\n\n\n\n3. When all variables are initiated, create the logpush job:\n\n\n\n* Log Analysis example\n\n{\n\"logdna\": {\n\"hostname\": \"example.com\",\n\"ingress_key\": \"\",\n\"region\": \"us-east\"\n},\n\"dataset\": \"range_events\",\n\"enabled\": false,\n\"name\": \"CIS-Range-LogDNA\",\n\"frequency\": \"low\",\n\"logpull_options\": \"fields=RayID,ZoneID&timestamps=rfc3339\"\n}\n* COS example\n\n{\n\"cos\": {\n\"bucket_name\": \"example_bucket\",\n\"path\": \"temp\/\",\n\"id\": \"cos_instance_id\",\n\"region\": \"us-east\"\n},\n\"dataset\": \"firewall_events\",\n\"enabled\": false,\n\"name\": \"CIS-Firewall-COS\",\n\"frequency\": \"low\",\n\"logpull_options\": \"fields=RayID,ZoneID&timestamps=rfc3339\",\n\"ownership_challenge\": \"xxxxxxx\"\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-logpush"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-1541-3629","score":27.1642398834,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-1541-3629","score":27.1642398834,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04991-50585-52328","score":24.8768863678,"text":"\nX-Clv-Request-Id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\nServer: Cleversafe\/3.14.9.53\nX-Clv-S3-Version: 2.5\nx-amz-request-id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\n\nThe server responds with 204 No Content.\n\n\n\n\n\n Add a retention policy on an existing bucket \n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. The service also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nFind out more about Immutable Object Storage in the [documentation](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable).\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nThis operation does not make use of extra query parameters. The required Content-MD5 header needs to be the binary representation of a base64-encoded MD5 hash. The following snippet shows one way to achieve the content for that particular header.\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nNot all operations are supported in Satellite environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-compatibility-api-bucket-operations"},{"document_id":"ibmcld_04831-50613-52356","score":24.8768863678,"text":"\nX-Clv-Request-Id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\nServer: Cleversafe\/3.14.9.53\nX-Clv-S3-Version: 2.5\nx-amz-request-id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\n\nThe server responds with 204 No Content.\n\n\n\n\n\n Add a retention policy on an existing bucket \n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. The service also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nFind out more about Immutable Object Storage in the [documentation](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable).\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nThis operation does not make use of extra query parameters. The required Content-MD5 header needs to be the binary representation of a base64-encoded MD5 hash. The following snippet shows one way to achieve the content for that particular header.\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nNot all operations are supported in Satellite environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/api-reference?topic=cloud-object-storage-compatibility-api-bucket-operations"},{"document_id":"ibmcld_05032-7-2136","score":24.2834510803,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-7-2136","score":24.2834510803,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05075-5285-7227","score":23.696269989,"text":"\n* You will need to pick a region where Object Lock is supported, refer to [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-service-availability) for details.\n* A maximum default retention period of 100 years (or 36500 days) is supported.\n* When using the console, it is also possible to set a Retain Until Date in months, in addition to days or years.\n\n\n\nThe retention period for an object cannot be decreased. If you are using default retention for validation testing please use a lower duration (such as 1 day) as the default retention, increasing it to your desired setting as needed.\n\n\n\n Creating and setting up your new bucket for use with Object Lock \n\n\n\n1. Navigate to your desired Object Storage instance and use Create Bucket with Customize your bucket option\n2. Enter the required bucket configuration details as per your use case requirements\n3. Navigate to the Object Versioning section and set it to Enabled\n4. Look for Immutability, and under Object Lock click Add\n5. Set Object Lock to Enabled\n6. Optionally, set a default retention period.\n7. Click on Save\n8. Proceed with rest of the configuration settings and click Create bucket\n\n\n\n\n\n\n\n Enabling Object Lock on an existing bucket: \n\nA bucket can be set for Object Lock use as follows:\n\n\n\n1. Navigate to your bucket Configuration section\n2. Click on Object Versioning\n3. At the Object Versioning section click on Edit, set the configuration option to Enabled and Save\n4. Navigate to Object Lock section, click on Add\n5. Set Object Lock to Enabled\n6. Optionally, set a default retention period.\n7. Click on Save\n\n\n\n\n\n\n\n Adding a Retain Until Date or Legal Hold to an object \n\n\n\n1. Navigate to the bucket with the target object\n2. Toggle Display Versions\n3. Go to the details of the target version\n4. Add a retention period and\/or toggle on a legal hold.\n\n\n\n\n\n\n\n\n\n Using Object Lock for business continuity and disaster recovery","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview"},{"document_id":"ibmcld_06808-1384-2991","score":22.9985160828,"text":"\n[Learn more](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidencecd-devsecops-cos-bucket-resiliency).\n\n\n\n\n\n Naming your bucket \n\nCloud Object Storage object names consist of the following components:\n\n{NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} \/ {FILE_NAME} _ {HASH}\n\n\n\n Examples: \n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/evidences\/build-vulnerability-advisor.json_362c06afa88b3f304878f0d0979e834f\n\nci\/48decaa9-9042-498f-b58d-3577e0ac0158\/artifacts\/app-image-va-report.json_b3f30487f0d0979e834f362c06afaaa8\n\nThe name component {NAMESPACE} \/ {PIPELINE_RUN_ID} \/ {TYPE} is useful as a prefix when you're looking for collected data from a certain pipeline run.\n\n\n\n\n\n Retention policy \n\nYou can set Cloud Object Storage buckets to enforce a retention policy or period for uploaded objects, otherwise known as [Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable). Immutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a Write-One-Read-Many (WORM), non-erasable, and non-rewritable manner. You cannot change or delete objects in protected buckets within the retention period, or delete protected buckets with objects themselves until the retention period is over. The policy is enforced until the end of a retention period and the removal of any legal holds.\n\nIt is recommended that teams set a retention policy for the buckets that are used as their evidence locker that stores every object for a minimum of 365 days.\n\n\n\n\n\n\n\n Audit event log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidence"},{"document_id":"ibmcld_04866-3142-5463","score":22.9903450012,"text":"\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-3142-5463","score":22.9903450012,"text":"\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.5,"ndcg_cut_5":0.5,"ndcg_cut_10":0.5}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05032-7-2136","score":21.3286705017,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-7-2136","score":21.3286705017,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-4961-6763","score":19.5155525208,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-4961-6763","score":19.5155525208,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05169-7627-9308","score":18.9800930023,"text":"\nThe IBM COS implementation of Immutable Object Storage (i.e. retention policies) is not permitted in buckets with versioning enabled. Attempts to create a retention policy will fail, as will attempts to enable versioning on a bucket with an retention policy. IBM COS does not support AWS S3 APIs for object locking, retention, or legal holds.\n\n\n\n\n\n\n\n Supported S3 APIs \n\nThe following set of REST APIs can interact with versioning in some way:\n\n\n\n* GET Object\n* HEAD Object\n* DELETE Object\n* GET Object ACL\n* PUT Object ACL\n* Upload Part Copy\n* Restore Object\n* DELETE Objects\n* List Object Versions\n* PUT Bucket Versioning\n* GET Bucket Versioning\n* PUT Object\n* POST Object\n* Copy Object\n* Complete Multipart Upload\n* PUT Object Tagging\n* GET Object Tagging\n* DELETE Object Tagging\n* PUT Bucket Lifecycle\n* GET Bucket Lifecycle\n* DELETE Bucket Lifecycle\n\n\n\n\n\n\n\n REST API examples \n\nThe following examples are shown using cURL for ease of use. Environment variables are used to represent user specific elements such as $BUCKET, $TOKEN, and $REGION. Note that $REGION would also include any network type specifications, so sending a request to a bucket in us-south using the private network would require setting the variable to private.us-south.\n\n\n\n Enable versioning on a bucket \n\n=======\n\ncurl -X \"PUT\" \"https:\/\/$BUCKET.s3.$REGION.cloud-object-storage.appdomain.cloud\/?versioning\" -H 'Authorization: bearer $TOKEN' -H 'Content-MD5: 8qj8HSeDu3APPMQZVG06WQ==' -H 'Content-Type: text\/plain; charset=utf-8' -d $'<VersioningConfiguration>\n<Status>Enabled<\/Status>\n<\/VersioningConfiguration>'\n\nA successful request returns a 200 response.\n\n\n\n\n\n Suspend versioning on a bucket \n\n=======","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-versioning"},{"document_id":"ibmcld_05010-7-1832","score":18.862033844,"text":"\nFAQ - General \n\nFrequently asked questions can produce helpful answers and insight into best practices for working with IBM Cloud\u00ae Object Storage.\n\n\n\n How can I find out the total size of my bucket by using the API? \n\nYou can use the [Resource Configuration API](https:\/\/cloud.ibm.com\/apidocs\/cos\/cos-configurationreturns-metadata-for-the-specified-bucket) to get the bytes used for a given bucket.\n\n\n\n\n\n How can I view my buckets? \n\nYou can view and navigate your buckets using the console, CLI or the API.\n\nFor example, the CLI command ibmcloud cos buckets will list all buckets associated with the targeted service instance.\n\n\n\n\n\n Can I migrate data from AWS S3 into IBM Cloud Object Storage? \n\nYes, you can use your existing tools to read and write data into IBM Cloud Object Storage. You need to configure HMAC credentials allow your tools to authenticate. Not all S3-compatible tools are currently unsupported. For details, see [Using HMAC credentials](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-uhc-hmac-credentials-main).\n\n\n\n\n\n Can I use AWS S3 SDKs with IBM Cloud Object Storage? \n\nYes, IBM COS SDKs are based on the official AWS S3 API SDKs, but are modified to use IBM Cloud features, such as IAM, Key Protect, Immutable Object Storage, and others. When using these SDKs, use HMAC authorization and an explicit endpoint. For details, see [About IBM COS SDKs](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-sdk-about).\n\n\n\n\n\n Is there a 100-bucket limit to an account? What happens if I need more? \n\nYes, 100 is the current bucket limit. Generally, prefixes are a better way to group objects in a bucket, unless the data needs to be in a different region or storage class. For example, to group patient records, you would use one prefix per patient.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq"},{"document_id":"ibmcld_05126-7854-8791","score":18.7880363464,"text":"\nYou can manage your keys manually by supplying your own encryption keys - referred to as Server-Side Encryption with Customer-Provided Keys (SSE-C).\n\n\n\n\n\n Archive rules \n\nIBM Cloud\u00ae Object Storage Archive is a low-cost option for data that is rarely accessed. You can migrate data from any of the storage tiers (Standard, Vault, Cold Vault, and Flex) to a long-term offline archive.\n\n\n\n\n\n Retention policies \n\nImmutable Object Storage maintains data integrity in a WORM (Write-Once-Read-Many) manner. Objects can't be modified until the end of their retention period and the removal of any legal holds.\n\n\n\n\n\n Aspera high-speed transfer \n\nAspera high-speed transfer improves data transfer performance under most conditions, especially in networks with high latency or packet loss. Instead of the standard HTTP PUT, Aspera high-speed transfer uploads the object by using the [FASP protocol](https:\/\/www.ibm.com\/products\/aspera\/technology).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-sdk-about"},{"document_id":"ibmcld_04869-7924-8861","score":18.7880363464,"text":"\nYou can manage your keys manually by supplying your own encryption keys - referred to as Server-Side Encryption with Customer-Provided Keys (SSE-C).\n\n\n\n\n\n Archive rules \n\nIBM Cloud\u00ae Object Storage Archive is a low-cost option for data that is rarely accessed. You can migrate data from any of the storage tiers (Standard, Vault, Cold Vault, and Flex) to a long-term offline archive.\n\n\n\n\n\n Retention policies \n\nImmutable Object Storage maintains data integrity in a WORM (Write-Once-Read-Many) manner. Objects can't be modified until the end of their retention period and the removal of any legal holds.\n\n\n\n\n\n Aspera high-speed transfer \n\nAspera high-speed transfer improves data transfer performance under most conditions, especially in networks with high latency or packet loss. Instead of the standard HTTP PUT, Aspera high-speed transfer uploads the object by using the [FASP protocol](https:\/\/www.ibm.com\/products\/aspera\/technology).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-sdk-about"},{"document_id":"ibmcld_02361-24500-26305","score":18.5745563507,"text":"\n[Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_04866-1541-3629","score":18.5433712006,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.9674679835,"ndcg_cut_10":0.9674679835}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-1672-3877","score":16.9601173401,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":15.9786195755,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":12.9556941986,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04146-2946-5057","score":11.2367038727,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04146-1603-3385","score":10.6717710495,"text":"\nhttp.request.method String POST The HTTP method, in upper case \n http.request.uri String \/articles\/index?section=539061&expand=comments The absolute URI of the request \n http.request.uri.path String \/articles\/index The path of the request \n http.request.uri.query String section=539061&expand=comments The whole query string, minus the delimiting prefix \"?\" \n http.user_agent String Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/65.0.3325.181 Safari\/537.36 The whole HTTP user agent \n http.x_forwarded_for String The full X-Forwarded-For HTTP header \n ip.src IP address 93.155.208.22 The client TCP IP address, which can be adjusted to reflect the real client IP of the original client as applicable (for example, using HTTP headers like X-Forwarded-For or X-Real-IP) \n ip.geoip.asnum Number 222 The [Autonomous System](https:\/\/ibm.biz\/BdzqdD) (AS) number \n ip.geoip.country String GB The [2-letter country code](https:\/\/www.iso.org\/obp\/ui\/search\/code\/) \n ssl Boolean true Whether the HTTP connection to the client is encrypted \n\n\n\nThese standard fields follow the naming convention of the Wireshark display field reference. However, some subtle variations might exist in the preceding example values.\n\nIn addition to the standard fields, the following Cloudflare-defined fields are also available:\n\n\n\nTable 2. Available Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_08001-18752-20657","score":9.1459550858,"text":"\n* Move the iRules that you want to enable to the Enabled section.\n\n\n\n10. Under the Policies section:\n\n\n\n* Click Manage.\n* Move the policy that you want to enable to the Enabled section.\n\n\n\n\n\n\n\n\n\n\n\n Step 11: Configure WAF on the virtual server \n\n\n\n Enable license \n\n\n\n1. Under System > License, click the Module Allocation tab.\n2. If Application Security (ASM) is not enabled, enable it with the Nominal selection.\n3. BIG-IP restarts.\n4. When the restart completes, log back into BIG-IP.\n\n\n\n\n\n\n\n Set up WAF \n\n\n\n1. Go to Security > Guided Configuration.\n2. Click Web Application Protocol and then Web Application Comprehensive Protection.\n3. Click Next.\n4. Under Security Layers* do the following:\n\n\n\n1. Enter a configuration name.\n2. Enable any security layers that you would like. The security layers of Security Policy and Behavioral Analysis DoS should at least be enabled.\n3. Click Save and Next.\n\n\n\n5. Under Web Application Security Policy Properties:\n\n\n\n1. Set the following:\n\n\n\n\n\n* Select Enforcement Mode: Blocking\n* Select type of policy to protect application: Generic\n* Application Language: Select the language encoding for your web application\n\n\n\n\n\n1. Click Save and Next.\n\n\n\n6. Under Bot Defense Properties\n\n\n\n1. Set the following:\n\n\n\n\n\n* Select Enforcement Mode: Blocking\n* Profile Template: Balanced\n\n\n\n\n\n1. Click Save and Next.\n\n\n\n7. Under DoS Profile Properties\n\n\n\n1. Set the following under Operation Mode:\n\n\n\n\n\n* Operation Mode: Blocking\n* Verify that Bad actors behavior detection and Request signature detection are selected\n\n\n\n\n\n1. Set the following under Mitigation Mode:\n\n\n\n\n\n* Mitigation Mode: Standard\n\n\n\n\n\n1. Click Save and Next.\n\n\n\n8. Under Virtual Server Properties\n\n\n\n1. Check Assign Policy to Virtual Server(s).\n2. Under Virtual Server select Use Existing.\n3. Under Assign Virtual Servers, move the virtual server that you created previously over from Available to Selected.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-waf-tutorial"},{"document_id":"ibmcld_04105-5067-6335","score":8.9270057678,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":8.8515825272,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_05088-7-1758","score":8.3075208664,"text":"\nUsing Python \n\nPython support is provided through a fork of the boto3 library with features to make the most of IBM Cloud\u00ae Object Storage.\n\nIt can be installed from the Python Package Index through pip install ibm-cos-sdk.\n\nSource code can be found at [GitHub](https:\/\/github.com\/ibm\/ibm-cos-sdk-python\/).\n\nThe ibm_boto3 library provides complete access to the IBM Cloud\u00ae Object Storage API. Endpoints, an API key, and the instance ID must be specified during creation of a service resource or low-level client as shown in the following basic examples.\n\nThe service instance ID is also referred to as a resource instance ID. The value can be found by creating a [service credential](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/iam?topic=cloud-object-storage-service-credentials), or through the CLI.\n\nDetailed documentation can be found at [here](https:\/\/ibm.github.io\/ibm-cos-sdk-python\/).\n\n\n\n Upgrading from 1.x.x \n\nThe 2.0 version of the SDK introduces a namespacing change that allows an application to use the original boto3 library to connect to AWS resources within the same application or environment. To migrate from 1.x to 2.0, some changes are necessary.\n\n1. Update the requirements.txt, or from PyPI via pip install -U ibm-cos-sdk. Verify no older versions exist with pip list | grep ibm-cos.\n2. Update any import declarations from boto3 to ibm_boto3.\n3. If needed, reinstall the original boto3 by updating the requirements.txt, or from PyPI via pip install boto3.\n\n\n\n\n\n Creating a client and sourcing credentials \n\nTo connect to COS, a client is created and configured using credential information (API key and service instance ID). These values can also be automatically sourced from a credentials file or from environment variables.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_05088-1319-3169","score":8.1110191345,"text":"\nUpdate any import declarations from boto3 to ibm_boto3.\n3. If needed, reinstall the original boto3 by updating the requirements.txt, or from PyPI via pip install boto3.\n\n\n\n\n\n Creating a client and sourcing credentials \n\nTo connect to COS, a client is created and configured using credential information (API key and service instance ID). These values can also be automatically sourced from a credentials file or from environment variables.\n\nAfter generating a [Service Credential](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/iam?topic=cloud-object-storage-service-credentials), the resulting JSON document can be saved to \/.bluemix\/cos_credentials. The SDK will automatically source credentials from this file unless other credentials are explicitly set during client creation. If the cos_credentials file contains HMAC keys the client authenticates with a signature, otherwise the client uses the provided API key to authenticate by using a bearer token (using an API key still requires the config=Config(signature_version=\"oauth\") to be included during client creation).\n\nIf migrating from AWS S3, you can also source credentials data from \/.aws\/credentials in the format:\n\n[default]\naws_access_key_id = {API_KEY}\naws_secret_access_key = {SERVICE_INSTANCE_ID}\n\nIf both \/.bluemix\/cos_credentials and \/.aws\/credentials exist, cos_credentials takes preference.\n\n\n\n Gather required information \n\nThe following variables appear in the examples:\n\n\n\n* bucket_name must be a [unique and DNS-safe](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/api-reference?topic=cloud-object-storage-compatibility-api-bucket-operationscompatibility-api-new-bucket) string. Because bucket names are unique across the entire system, these values need to be changed if this example is run multiple times. Note that names are reserved for 10 - 15 minutes after deletion.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-3403-5572","score":19.2686977386,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":18.6894931793,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04105-5067-6335","score":16.5690135956,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04113-1734-4014","score":15.8711519241,"text":"\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:\n\n\n\n* Select Security Level to Essentially off\n* Select TLS to Off\n* Select Browser Integrity Check to Off\n\n\n\n* Select Provision Resource\n\n\n\n* Alternatively, you can turn off Web Application Firewall globally from the Security page.\n\n\n\n\n\n What does the Browser Integrity Check do? \n\nThe browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks visitors that do not have a user agent, or who add a non-standard user agent (this tactic is commonly used by abuse bots, crawlers, or APIs).\n\n\n\n\n\n\n\n Best practice 4: Configure your security settings as strictly as possible \n\nCIS provides some options for encrypting your traffic. As a reverse proxy the TLS connection is terminated at Cloudflare and a new TLS connection is opened to your origin servers. For your termination with CIS, you can upload a custom certificate from your account, you can use a wildcard certificate provisioned for you by CIS, or both.\n\n\n\n Upload a custom certificate \n\nYou can upload your public and private key when you create an Enterprise domain. If you upload your own certificate, you gain immediate compatibility with encrypted traffic, and you maintain control over your certificate (for example, an Extended Validation (EV) certificate). Remember that you'll be responsible for managing your certificate if you upload a custom certificate. For example, IBM CIS won't track the certificate expiration dates.\n\n\n\n\n\n Alternatively, use a certificate provisioned by CIS \n\nIBM CIS has partnered with several Certificate Authorities (CAs) to provide domain wildcard certificates for our customers, by default. Manual verification could be required for setting up these certificates, and your support team can help you perform these additional steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup"},{"document_id":"ibmcld_04146-2946-5057","score":15.2451763153,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04105-1672-3877","score":15.0732002258,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04334-39121-41053","score":14.6438827515,"text":"\nValid values for group are all, domain, reliability, performance, security. This option is mutually exclusive with -f, --feature.\n\n-f, --feature\n: Feature of domain settings to check. This option is mutually exclusive with g, --group. Valid values are as follow:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination in the BoringSSL format. This command only lists ciphers specifically whitelisted by customers. If no ciphers are whitelisted, the list is empty and the default ciphers are used. See [TLS Options](\/docs\/cis? topic=cis-cis-tls-options#cipher-suites) for the list of default ciphers.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-43529-45385","score":14.5233974457,"text":"\nUpdate a feature for the domain.\n\nibmcloud cis domain-settings-update DNS_DOMAIN_ID (-f, --feature FEATURE) (-v, --value VALUE) [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required. -f, --feature value\n: Feature of domain settings to update. Required. Valid values:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination. These ciphers must be in the BoringSSL format.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.\n* image_size_optimization: Improve image load time by optimizing images hosted on your domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04107-6095-8145","score":14.316400528,"text":"\nThis tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.\n* Always use HTTPS - Redirects all visitors to the HTTPS version.\n* Email obfuscation - Prevents spam from harvesters and bots that try to access email addresses on your pages.\n* Automatic HTTPS rewrites - Helps fix mixed content by changing http to https for all resources (or links) on your website that can be served with HTTPS.\n* Opportunistic encryption - Allows browsers to benefit from the improved performance of HTTP\/2 by informing them that your site is available over an encrypted connection.\n* Universal SSL - Activates universal SSL certificates from your zone to the edge.\n* True client IP header - Sends the user's IP address in the True-Client-IP header.\n\n\n\n\n\n\n\n Security standards and platform \n\n\n\n* TLS (SHA2 and SHA1)\n* IPv4 and IPv6\n* HTTP\/2\n\n\n\n\n\n\n\n Network attacks and mitigation \n\nGenerally, attacks fall into two categories:\n\n\n\nTable 1. Types of network attacks\n\n Layer-3 or Layer-4 attacks Layer-7 attacks \n\n These attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04107-4464-6614","score":13.9686803818,"text":"\n* Specific URLs - For example, you can allow IP 1.2.3.4 access to directory example.com\/foo\/ and allow IP 5.6.7.8 access to directory example.com\/bar\/, but not allow the reverse.\n\n\n\nThis capability is useful when you need more granularity in your access rules because, with IP rules, you can either apply the block to all subdomains of the current domain, or all domains on your account. You cannot specify URIs.\n\n\n\n\n\n\n\n Firewall rules \n\nCreate rules that examine incoming HTTP traffic against a set of filters to block, challenge, log, or allow matching requests.\n\nIn general, firewall rules are designed for properties that are exposed in OSI Layer-7 (HTTP), such as request headers and body content characteristics. Therefore, firewall rules apply to HTTP\/HTTPS [Range](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-range) apps.\n\n\n\n\n\n Events \n\nView events that are triggered by an active web application firewall rule. For each event, you can change the triggered action based on the requesting IP address, or the requesting region as a whole.\n\n\n\n\n\n Range \n\nExtend the power of CIS DDoS, TLS, and IP firewall to your web servers and your TCP-based services by using Range applications, keeping them online and secure.\n\n\n\n\n\n Advanced security \n\nAdvanced security settings include the following features, which you can change, enable, or disable.\n\n\n\n* Browser integrity check - The browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks or challenges visitors that do not have a user agent, or who add a nonstandard user agent. This tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-5067-6335","score":26.2202262878,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":22.6504020691,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":21.7458667755,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04175-0-1274","score":19.392950058,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04170-1738-2974","score":19.2064666748,"text":"\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed. Your CSP should allow scripts that are served from your origin domain (script-src self).\n* If your CSP uses a nonce for script tags, CIS adds these nonces to the scripts it injects by parsing your CSP response header.\n* If your CSP does not use nonce for script tags and JavaScript Detection is enabled, you might see a console error such as\n\nRefused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self'\". Either the 'unsafe-inline' keyword, a hash ('sha256-b123b8a70+4jEj+d6gWI9U6IilUJIrlnRJbRR\/uQl2Jc='), or a nonce ('nonce-...') is required to enable inline execution.\n* It is not recommended to use unsafe-inline. Instead, it is recommend that you use CSP nonces in script tags which are parsed and supported in the CDN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04113-1734-4014","score":18.7458705902,"text":"\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:\n\n\n\n* Select Security Level to Essentially off\n* Select TLS to Off\n* Select Browser Integrity Check to Off\n\n\n\n* Select Provision Resource\n\n\n\n* Alternatively, you can turn off Web Application Firewall globally from the Security page.\n\n\n\n\n\n What does the Browser Integrity Check do? \n\nThe browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks visitors that do not have a user agent, or who add a non-standard user agent (this tactic is commonly used by abuse bots, crawlers, or APIs).\n\n\n\n\n\n\n\n Best practice 4: Configure your security settings as strictly as possible \n\nCIS provides some options for encrypting your traffic. As a reverse proxy the TLS connection is terminated at Cloudflare and a new TLS connection is opened to your origin servers. For your termination with CIS, you can upload a custom certificate from your account, you can use a wildcard certificate provisioned for you by CIS, or both.\n\n\n\n Upload a custom certificate \n\nYou can upload your public and private key when you create an Enterprise domain. If you upload your own certificate, you gain immediate compatibility with encrypted traffic, and you maintain control over your certificate (for example, an Extended Validation (EV) certificate). Remember that you'll be responsible for managing your certificate if you upload a custom certificate. For example, IBM CIS won't track the certificate expiration dates.\n\n\n\n\n\n Alternatively, use a certificate provisioned by CIS \n\nIBM CIS has partnered with several Certificate Authorities (CAs) to provide domain wildcard certificates for our customers, by default. Manual verification could be required for setting up these certificates, and your support team can help you perform these additional steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup"},{"document_id":"ibmcld_04177-7-2309","score":17.9577217102,"text":"\nManaging your CIS deployment \n\nYou'll begin by using the Overview screen as your working base of operations. It shows all of the current parameters for your deployment.\n\nOnce you've set up your DNS and configured it, you are ready to go!\n\n\n\n Using the Overview screen \n\nUsing the Overview screen, you can see the status of all your selections. Each setting links to the section of the user interface where the setting is configured. To modify any selection, you can navigate by clicking the link for the setting. For example, to change the load balancer configuration or add a new load balancer, click the Load Balancer field.\n\nOn the Overview screen, you might see that your domain name configuration is in Pending status, or in Active status. Pending status indicates that your domain is not fully set up, yet. You have to update your DNS provider or registrar with the name servers that are provided as part of the setup process.\n\nEnterprise only: The Service Details section of the Overview also allows you to add additional domains to your instance of CIS, and to switch between multiple domains.\n\n\n\n\n\n Changing the Service mode \n\nIn the Service Mode section of the Overview page is a list menu to select one of two modes:\n\n\n\n* Defense Mode helps protect against existing or predicted DNS attacks. This mode prevents all traffic from reaching your origin servers through your domain.\n* Pause Service disables all security and performance benefits to your domain. DNS functions still resolve for your website, but traffic is sent directly to configured origins.\n\n\n\n\n\n Setting up Service mode \n\n\n\n1. Select the mode you want from the list menu.\n2. Click Activate mode.\n3. Confirm or cancel the selection in the confirmation pop-up.\n\n\n\nA notification appears on all pages to show that either Pause Service or Defense Mode is active. To return to normal operation, click Deactivate mode in the notification banner.\n\n\n\n\n\n\n\n Configuring and managing your DNS \n\nGo to the Reliability section, click the DNS tab and add a record. Type in the information about your DNS record and then click Add record to implement your changes.\n\nAfter creating your records, consider turning on the Proxy setting. Most of the features of CIS require that the internet traffic to your site flow through CIS infrastructure.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-cis-deployment"},{"document_id":"ibmcld_04178-7-2164","score":17.0665187836,"text":"\nManaging your CIS deployment for best performance \n\nIBM Cloud\u00ae Internet Services (CIS) can provide the fastest experience for your customers because it optimizes your images, and it stores your web content as near as possible to your end-users. Your content is loaded from proxied edge servers (which reduces latency).\n\nWith CIS, you can enhance your site's performance further by using best practices to speed up the loading of your web content. Here are some specific best practices for enhancing the performance of your web content within CIS.\n\nRecommended and best practices:\n\n\n\n* Cache as much of your static and semi-static web content as possible\n* For event-driven content, purge your cache using the API\n\n\n\n\n\n Best practice 1: Cache as much static and semi-static content as possible \n\n\n\n* Enable Cache Everything for static HTML web pages\n* Use conservative Time-to-live (TTL) for your content that changes occasionally\n\n\n\n\n\n Utilize conservative TTLs (Time-to-Lives) for content that changes occasionally \n\nIf content rarely changes, you can set a conservative TTL to utilize our cache as much as possible. If you have a high percentage of re-validation requests, you could increase the TTLs of your content without negatively affecting your customers. By using the cache more effectively, you'll increase performance because you'll revalidate less often.\n\n\n\n\n\n How do I tell if items are being cached? \n\nCIS adds the response header CF-Cache-Status when it attempts to cache an object. If caching is successful, the value of this header indicates its status with one of these keywords:\n\n\n\n* MISS: The asset was not yet in the cache or the TTL had expired (that is, it had reached the cache-control maximum age of 0).\n* HIT: The asset was delivered from the cache.\n* EXPIRED: This asset was delivered from cache, but the next request requires revalidation.\n* REVALIDATED: The asset was delivered from cache. The TTL was expired, but an If-Modified-Since request to the origin indicated that the asset had not changed. Therefore, the version in cache is considered valid again.\n\n\n\n\n\n\n\n\n\n Best practice 2: For event-driven content, purge your cache","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-cis-deployment-for-best-performance"},{"document_id":"ibmcld_12457-6188-7983","score":16.8322067261,"text":"\nYou need the Cloud Resource Name (CRN) of the CIS instance that contains your domains, and an API key with the correct level of access to your instance. The API key must grant Secrets Manager the ability to view the CIS instance, access its domains, and manage TXT records.\n\nIf the CIS instance is located in an account that allows access to only specific IP addresses, you must also update the IP address restrictions in the account to allow incoming requests from Secrets Manager. For more information, see [Managing access with context-based restrictions](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-access-control-cbr).\n\nTo assign access, you can use the Access (IAM) section of the console.\n\n\n\n1. Log in to the account in which your CIS instance is located.\n2. Click Manage > Access (IAM), and select Service IDs.\n3. [Create a service ID API key](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceidapikeys) or select an existing one.\n4. Assign the required access to view the CIS instance, access its domains, and manage TXT records.\n\n\n\n1. In the row of the service ID, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/icons\/actions-icon-vertical.svg)> Assign access.\n2. Click the Access policy tile.\n3. From the list of services, select Internet Services and click Next.\n4. Select Resources based on selected attributes.\n5. In the Service instance field, select your CIS instance.\n6. In the Roles and actions section, select the Manager role. If you want to grant the service ID the ability to access the CIS instance from the Resource list in the IBM Cloud console, you can also assign the Viewer platform role.\n7. Click Review > Add > Assign to complete the access assignment.\n\n\n\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-prepare-order-certificates&interface=ui"},{"document_id":"ibmcld_04169-0-2221","score":16.8279399872,"text":"\n\n\n\n\n\n\n  Managing access for CIS \n\nAccess to IBM Cloud\u00ae Internet Services service instances for users in your account is controlled by IBM Cloud Identity and Access Management (IAM). Every user that accesses the (CIS) service in your account must be assigned an access policy with an IAM role defined. The policy determines what actions a user can perform within the context of the service or instance that you select. The allowable actions are customized and defined by the IBM Cloud service as operations that are allowed to be performed on the service. The actions are then mapped to IAM user roles.\n\nPolicies enable access to be granted at different levels. Some of the options include the following:\n\n\n\n*  Access across all instances of the service in your account\n*  Access to an individual service instance in your account\n\n\n\nAfter you define the scope of the access policy, you assign a role, which determines the user's level of access.\n\nReview the following table that outlines what actions each role allows within the (CIS) service. The platform and service roles for CIS are listed under \"Internet Services\". If you're using the CLI or API to assign access, use internet-svcs for the service name.\n\nPlatform management roles enable users to perform tasks on service resources at the platform level, for example, assign user access for the service and create or delete instances.\n\nFor more information about IAM roles, see [Getting Started with IAM](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-iam-getting-started).\n\n\n\nTable 1. IAM user roles and actions\n\n Platform management role      Description of actions                                     \n\n Manager                       Create and delete instances, domains, and configurations.  \n Reader                        View information about instances and domains.              \n Service Configuration Reader  Read services configuration for Governance management.     \n Writer                        Change existing configurations.                            \n\n\n\nFor information about assigning user roles in the console, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resourcesassign-access-resources).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-iam-and-cis"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04175-0-1274","score":25.8542289734,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_16511-1688-3640","score":23.3140487671,"text":"\nWhen you deploy the machine learning model, you select the version of it that you want to deploy.\n\n\n\n\n\n Procedure \n\nTo deploy a machine learning model, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Versions.\n3. Choose the version of the model that you want to deploy.\n\nIf there is only one working version of the model, create a snapshot of the current model. This versions the model, which enables you to deploy one version, while you continue to improve the current version. The option to deploy does not appear until you create at least one version.\n\nEach version can be deployed to any number of service instances. Each deployed instance of a model version is given a unique Model ID, but is identical in all other ways.\n4. Click Deploy, choose to deploy it to Discovery, and then click Next.\n5. Select the IBM Cloud space and instance. If necessary, select a different region.\n6. Click Deploy.\n7. The deployment process might take a few minutes. To check the status of the deployment, click Status on the Versions tab next to the version that you deployed.\n\nIf the model is still being deployed, the status indicates \"deploying\". After deployment completes, the status changes to \"available\" or \"deployed\" if the deployment was successful, or \"error\" if problems occurred.\n\nOnce available, make a note of the model ID (model_id).\n\n\n\n\n\n\n\n What to do next \n\nTo use the model, you must export the model, and then import it into Discovery.\n\n\n\n1. Select Machine Learning Model > Versions.\n2. Click Export current model.\n\nIf you have a Lite plan subscription, no export option is available.\n\nThe model is saved as a ZIP file, and you are prompted to download the file.\n3. Download the file to your local system.\n4. From the Discovery service, follow the steps to create a Machine Learning enrichment, which include uploading the ZIP file.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-ml"},{"document_id":"ibmcld_16451-3317-5174","score":22.965429306,"text":"\nClick View Ground Truth for the training set or test set to see the annotations that were added through pre-annotation and by human annotators. The ground truth editor opens. Click to open individual documents and see how the mentions, relations, and coreferenced mentions were annotated.\n3. On the Performance page, click View Decoding Results to see the annotations that the machine learning model added to documents in the test set. This button is available only after you evaluate the model. By viewing results, you can see how well the machine learning model labeled mentions, relations, and coreferenced mentions in the test data.\n4. If you want to change how the documents are divided between training, test, and blind data sets, click Performance > Train and evaluate > Edit Settings. For example, if initial results seem acceptable, you might want to increase the number of documents in the test set to further test the machine learning model's results. You can change the ratio for how documents are automatically divided for different purposes, or you can select specific document sets to use as training data, test data, and blind data.\n5. If you made any changes, click Train & Evaluate to retrain the model and re-evaluate the annotations.\n\n\n\n\n\n\n\n\n\n Deleting a machine learning model \n\nYou cannot delete a machine learning model.\n\nYou can delete the workspace that was used to develop the model, but you cannot delete the model itself. Deleting a model is not the best approach. Instead, update or replace the artifacts that are used to train the model. Even if the model is not producing the results you expect, you can continue to refine it. Each time you create a new version, the model is built anew. You can edit artifacts like dictionaries and the type system, and choose to use different annotation sets when you train the next version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-train-ml"},{"document_id":"ibmcld_16524-3358-5215","score":22.965429306,"text":"\nClick View Ground Truth for the training set or test set to see the annotations that were added through pre-annotation and by human annotators. The ground truth editor opens. Click to open individual documents and see how the mentions, relations, and coreferenced mentions were annotated.\n3. On the Performance page, click View Decoding Results to see the annotations that the machine learning model added to documents in the test set. This button is available only after you evaluate the model. By viewing results, you can see how well the machine learning model labeled mentions, relations, and coreferenced mentions in the test data.\n4. If you want to change how the documents are divided between training, test, and blind data sets, click Performance > Train and evaluate > Edit Settings. For example, if initial results seem acceptable, you might want to increase the number of documents in the test set to further test the machine learning model's results. You can change the ratio for how documents are automatically divided for different purposes, or you can select specific document sets to use as training data, test data, and blind data.\n5. If you made any changes, click Train & Evaluate to retrain the model and re-evaluate the annotations.\n\n\n\n\n\n\n\n\n\n Deleting a machine learning model \n\nYou cannot delete a machine learning model.\n\nYou can delete the workspace that was used to develop the model, but you cannot delete the model itself. Deleting a model is not the best approach. Instead, update or replace the artifacts that are used to train the model. Even if the model is not producing the results you expect, you can continue to refine it. Each time you create a new version, the model is built anew. You can edit artifacts like dictionaries and the type system, and choose to use different annotation sets when you train the next version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-train-ml"},{"document_id":"ibmcld_16495-1699-3728","score":21.9802436829,"text":"\nTo take a snapshot of the current version, click Machine Learning Model > Versions, and then click Take Snapshot. The resources in version 1.0 are frozen, and a new version, labeled 1.1, becomes the current version. For each new version that you create, the minor version number is incremented, for example, 1.0 becomes 1.1 and then becomes 1.2.\n4. Revise the workspace resources as needed, re-train, and re-evaluate the model.\n5. If you are pleased with the performance results and want to store the new version before making future changes, create another version. Continue revising resources and re-training the model as needed, creating a new version for each iteration that you want to retain.\n6. If performance results are worse, and you want to revert to a previous version before testing any further:\n\n\n\n1. Open the Assets > Dictionaries page and download any dictionaries that you want to re-use in the restored model.\n2. Click Machine Learning Model > Versions and click Promote for the version that you want to restore. The version that you promote becomes the current version, and the version number changes to 2.0. When you promote a version, the major version number is incremented and the minor version number becomes 0, for example, 1.1 becomes 2.0.\n3. Open the Dictionaries page and upload the dictionaries that you downloaded.\n4. If testing of the new version requires changes to ground truth, open the Machine Learning Model > Annotations page. Click the Annotation Tasks tab and create a new annotation task.\n\n\n\n\n\n\n\n\n\n\n\n Modifying a type system without losing human annotations \n\nYou might need to make modifications while you train a model, based on the performance statistics. But, generally, you want the type system to be as close to final as possible before you begin large-scale annotation tasks. If you change the type system after human annotators began their work, they must revisit the documents that they annotated. They must assess the applicability of the type system changes.\n\n\n\n About this task","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-improve-ml"},{"document_id":"ibmcld_16437-1699-3728","score":21.9802341461,"text":"\nTo take a snapshot of the current version, click Machine Learning Model > Versions, and then click Take Snapshot. The resources in version 1.0 are frozen, and a new version, labeled 1.1, becomes the current version. For each new version that you create, the minor version number is incremented, for example, 1.0 becomes 1.1 and then becomes 1.2.\n4. Revise the workspace resources as needed, re-train, and re-evaluate the model.\n5. If you are pleased with the performance results and want to store the new version before making future changes, create another version. Continue revising resources and re-training the model as needed, creating a new version for each iteration that you want to retain.\n6. If performance results are worse, and you want to revert to a previous version before testing any further:\n\n\n\n1. Open the Assets > Dictionaries page and download any dictionaries that you want to re-use in the restored model.\n2. Click Machine Learning Model > Versions and click Promote for the version that you want to restore. The version that you promote becomes the current version, and the version number changes to 2.0. When you promote a version, the major version number is incremented and the minor version number becomes 0, for example, 1.1 becomes 2.0.\n3. Open the Dictionaries page and upload the dictionaries that you downloaded.\n4. If testing of the new version requires changes to ground truth, open the Machine Learning Model > Annotations page. Click the Annotation Tasks tab and create a new annotation task.\n\n\n\n\n\n\n\n\n\n\n\n Modifying a type system without losing human annotations \n\nYou might need to make modifications while you train a model, based on the performance statistics. But, generally, you want the type system to be as close to final as possible before you begin large-scale annotation tasks. If you change the type system after human annotators began their work, they must revisit the documents that they annotated. They must assess the applicability of the type system changes.\n\n\n\n About this task","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-ml"},{"document_id":"ibmcld_16511-4920-6949","score":21.9795532227,"text":"\nAbout this task \n\nWhen you deploy the machine learning model, you select the version of it that you want to deploy.\n\n\n\n\n\n Procedure \n\nTo deploy a machine learning model to the Natural Language Understanding service, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Versions.\n3. Choose the version of the model that you want to deploy.\n\nIf there is only one working version of the model, create a snapshot of the current model. This versions the model, which enables you to deploy a version, while you continue to improve the current version. The option to deploy does not appear until you create at least one version.\n\nEach version can be deployed to any number of service instances. Each deployed instance of a model version is given a unique Model ID but is identical in all other ways.\n4. Click Deploy, choose to deploy it to Natural Language Understanding, and then click Next.\n5. Select the IBM Cloud space and instance. If necessary, select a different region.\n6. Click Deploy.\n7. The deployment process might take a few minutes. To check the status of the deployment, click Status on the Versions tab next to the version that you deployed. If the model is still being deployed, the status indicates \"publishing\". After deployment completes, the status changes to \"available\" if the deployment was successful, or \"error\" if problems occurred.\n\nOnce available, make a note of the model ID (model_id). You will provide this ID to the Natural Language Understanding service to enable the service to use your custom model.\n\n\n\n\n\n\n\n What to do next \n\nYou can list deployed model in the Natural Language Understanding service instance by calling the following API method.\n\ncurl --user \"apikey:{apikey}\" \"{url}\/v1\/models?version=2018-11-16\"\n\nAny deployed models will be returned in an array similar to the following one:\n\n{\n\"models\": [\n{\n\"workspace_id\": \"{workspace_id}\",\n\"version_description\": \"{version_description}\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-ml"},{"document_id":"ibmcld_16495-7-2129","score":21.4651889801,"text":"\nMaking machine learning model improvements \n\nAfter you determine areas in which the model is having trouble, take steps to improve its performance.\n\n\n\n Creating model versions \n\nAfter you create a machine learning model, you can take a snapshot to keep a backup version of the current resources in case you want to restore the resources in a future iteration.\n\n\n\n About this task \n\nThe F1 score provides an indication of the quality of the model. If the model performance results are good, you might want to store a version of the component before changing any of the resources. If changes that you make result in poorer quality, you can revert to a version that you stored. When you revert to an older version, all annotation tasks are archived because they are no longer valid.\n\nYou can have a maximum of 10 versions of a workspace. If you reach that limit, delete older versions or versions that you no longer need before creating a new version.\n\nWhen you create a new version, the following resources are captured:\n\n\n\n* Type system\n* Corpus\n* Ground truth\n* Machine learning model\n* Machine learning model evaluation results\n\n\n\nThe following resources are excluded:\n\n\n\n* Annotation tasks, because they are temporal by design, used only for determining ground truth\n* Dictionaries, because dictionaries can be large, and various types of dictionaries are managed in different ways\n\n\n\n\n\n\n\n Procedure \n\nTo create and restore machine learning model versions:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Performance. Performance statistics about the current version, labeled version 1.0, are displayed.\n3. To take a snapshot of the current version, click Machine Learning Model > Versions, and then click Take Snapshot. The resources in version 1.0 are frozen, and a new version, labeled 1.1, becomes the current version. For each new version that you create, the minor version number is incremented, for example, 1.0 becomes 1.1 and then becomes 1.2.\n4. Revise the workspace resources as needed, re-train, and re-evaluate the model.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-improve-ml"},{"document_id":"ibmcld_16437-7-2129","score":21.4651832581,"text":"\nMaking machine learning model improvements \n\nAfter you determine areas in which the model is having trouble, take steps to improve its performance.\n\n\n\n Creating model versions \n\nAfter you create a machine learning model, you can take a snapshot to keep a backup version of the current resources in case you want to restore the resources in a future iteration.\n\n\n\n About this task \n\nThe F1 score provides an indication of the quality of the model. If the model performance results are good, you might want to store a version of the component before changing any of the resources. If changes that you make result in poorer quality, you can revert to a version that you stored. When you revert to an older version, all annotation tasks are archived because they are no longer valid.\n\nYou can have a maximum of 10 versions of a workspace. If you reach that limit, delete older versions or versions that you no longer need before creating a new version.\n\nWhen you create a new version, the following resources are captured:\n\n\n\n* Type system\n* Corpus\n* Ground truth\n* Machine learning model\n* Machine learning model evaluation results\n\n\n\nThe following resources are excluded:\n\n\n\n* Annotation tasks, because they are temporal by design, used only for determining ground truth\n* Dictionaries, because dictionaries can be large, and various types of dictionaries are managed in different ways\n\n\n\n\n\n\n\n Procedure \n\nTo create and restore machine learning model versions:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Performance. Performance statistics about the current version, labeled version 1.0, are displayed.\n3. To take a snapshot of the current version, click Machine Learning Model > Versions, and then click Take Snapshot. The resources in version 1.0 are frozen, and a new version, labeled 1.1, becomes the current version. For each new version that you create, the minor version number is incremented, for example, 1.0 becomes 1.1 and then becomes 1.2.\n4. Revise the workspace resources as needed, re-train, and re-evaluate the model.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-ml"},{"document_id":"ibmcld_07028-1792-3496","score":21.0808963776,"text":"\nTo add a Machine Learning model, complete the following steps:\n\n\n\n1. Create the model and export it from the tool you use to create it.\n\nFor more information, see the following documentation:\n\n\n\n* Knowledge Studio for IBM Cloud Pak\u00ae for Data\n\n\n\n* [Creating a rule-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-rule-annotator)\n* [Creating a machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-ml_annotator)\n\n\n\n* Knowledge Studio for IBM Cloud\n\n\n\n* [Creating a rule-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-rule-annotator)\n* [Creating a machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-ml_annotator)\n\n\n\n* [Watson Explorer Content Analytics Studio](https:\/\/www.ibm.com\/docs\/en\/watson-explorer\/12.0.x?topic=analytics-content-studio-advanced-text)\n\nYou must export the model from Watson Explorer Content Analytics Studio as a UIMA PEAR file. For more information, see: [Creating Custom PEAR Files for use with Lexical Analysis Streams](https:\/\/www.ibm.com\/docs\/en\/watson-explorer\/12.0.x?topic=las-creating-custom-pear-files-use-lexical-analysis-streams).\n* [Discovery entity extractor](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-entity-extractorentity-extractor-export)\n\n\n\n2. From the Teach domain concepts section of the Improvement tools panel, and then click Import machine learning models.\n3. Specify a name for the model, and then choose the language that was used to define the model.\n4. Click Upload to browse for the file that you exported earlier.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain-ml"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-3403-5572","score":18.6624240875,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-1672-3877","score":15.2224178314,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":14.4772462845,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_03109-10370-12635","score":13.6717433929,"text":"\nWhen the web chat widget is being interacted with by a user, we track the features that are being used, and events such as how many times the widget is opened and how many users start conversations. This information does not include Assistant training data or the content of any chat interactions. The information being sent to Amplitude is not Content as defined in the Cloud Service Agreement (CSA); it is Account Usage Information as described in Section 9.d of the CSA and is handled accordingly as described in the [IBM Privacy Statement](https:\/\/www.ibm.com\/privacy). The purpose of this information gathering is limited to establishing statistics about use and effectiveness of the web chat and making general improvements.\n\n\n\n\n\n Private network endpoints \n\nYou can set up a private network for Watson Assistant instances that are part of a Plus or Enterprise service plan. Using a private network prevents data from being transferred over the public internet, and ensures greater data isolation.\n\n![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) This feature is available only to users of paid plans.\n\nPrivate network endpoints support routing services over the IBM Cloud private network instead of the public network. A private network endpoint provides a unique IP address that is accessible to you without a VPN connection.\n\nFor implementation details, see [Public and private network endpoints](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-public-private-endpoints).\n\n\n\n Important private network endpoint notes \n\n\n\n* The integrations that are provided with the product require endpoints that are available on the public internet. Therefore, any built-in integrations you add to your assistant will have public endpoints. If you only want to connect to a client application or messaging channel over the private network, then you must build your own custom client application or channel integration.\n* Before you can use a search integration or search skill, you must create a Discovery instance with a private network endpoint. The list of Discovery instances that are displayed for you to connect to includes only instances with private network endpoints.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-securing"},{"document_id":"ibmcld_03422-1615-3407","score":13.5841398239,"text":"\nThe process you use to add the web chat to your website is simple. Its simplicity also means it can be misused. That's why it's important to verify that the messages sent to your assistant are coming from authorized users only.\n\nBefore you enable security, complete the following steps:\n\n\n\n1. Create a RS256 private\/public key pair.\n\nYou can use a tool such as the OpenSSL command line or PuTTYgen.\n\n\n\n* For example, to create the key pair: openssl genrsa -out key.pem 2048\n\n\n\n2. Use your private key to sign a JSON Web Token (JWT). You will pass the token with the messages that are sent from your website as proof of their origin.\n\nThe JWT payload must specify values for the following claims:\n\n\n\n* iss: Represents the issuer of the JWT. This value is a case-sensitive string.\n* sub: Represents the principal that is the subject of the JWT. This value must either be scoped to be locally unique in the context of the issuer or be globally unique. The value you specify for sub is used as the user_id.\n\nThe user ID that is specified in the sub claim is also sent in the customer_id section of the X-Watson-Metadata HTTP header. The customer_id can be used to make requests to delete user data. Because the ID is sent in a header field, the syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2) (all visible ASCII characters). For more information about deleting user data, see [Labeling and deleting data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-information-securityinformation-security-gdpr-wa).\n* exp: Represents the expiration time on or after which the JWT cannot be accepted for processing. Many libraries set this value for you automatically. Set a short-lived exp claim with whatever library you use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security"},{"document_id":"ibmcld_06495-1302-2848","score":13.4000463486,"text":"\n* If you don't specify a user, the Connections commands return information for the admin user, by default.\n* If you don't specify an endpoint-type, the connection string returns the public endpoint by default.\n* If your deployment has only a private endpoint, specify --endpoint-type private or the commands return an error. The user and endpoint type is not enforced. You can use any user on your deployment with either endpoint (if both exist on your deployment).\n\n\n\n\n\n\n\n\n\n Getting Connection Strings in the API \n\nTo retrieve users' connection strings from the [Cloud Databases API](https:\/\/cloud.ibm.com\/apidocs\/cloud-databases-api\/cloud-databases-api-v5introduction), use the [Connections endpoint](https:\/\/cloud.ibm.com\/apidocs\/cloud-databases-api\/cloud-databases-api-v5getconnection). To create the connection strings, ensure that the path includes the specific user and endpoint type (public or private) that should be used. The user and endpoint type are not restricted or enforced. You have the flexibility to utilize any user available in your deployment, along with either endpoint (if both are present in your deployment).\n\nThe API command looks like:\n\ncurl -X GET -H \"Authorization: Bearer <>\" 'https:\/\/api.{region}.databases.cloud.ibm.com\/v5\/ibm\/deployments\/{id}\/users\/{userid}\/connections\/{endpoint_type}'\n\nRemember to replace {region}, {id}, {userid}, and {endpoint_type} with the appropriate values.\n\n\n\n\n\n Additional Users and Connection Strings \n\nAccess to your Databases for MongoDB deployment is not limited to the admin user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-connection-strings"},{"document_id":"ibmcld_02421-4509-6263","score":13.106836319,"text":"\n{\"error\":\"Nothing to configure\",\"code\":\"BadRequest\",\"status\":\"error\"}\n\n\n\n\n\n Deleting views \n\nWhen you delete a view, consider the following information:\n\n\n\n* You must specify the ID of the view that you plan to delete.\n* You delete the view and all the alerts that are configured for the view.\n\n\n\n\n\n\n\n\n\n API methods \n\nThe following table outlines the actions that you can run to manage views and alerts programmatically:\n\n\n\nTable 1. Configuration API endpoints\n\n Action Request URL \n\n Create a view and attach an alert to a view. POST <ENDPOINT>\/v1\/config\/view \n Get all configured views and alerts GET <ENDPOINT>\/v1\/config\/view \n Modify an existing view and the alerts that are attached to the view. PUT <ENDPOINT>\/v1\/config\/view\/<VIEWID> \n Delete a view and its associated alerts. DELETE <ENDPOINT>\/v1\/config\/view\/<VIEWID> \n\n\n\nWhere <VIEWID> represents the ID of a view.\n\n\n\n\n\n Endpoint URL \n\nDepending on [your account settings](https:\/\/cloud.ibm.com\/docs\/account?topic=account-service-endpoints-overview), you can use public or private endpoints to manage views and alerts programmatically. For information about endpoints per region, see [API endpoints](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-endpointsendpoints_api).\n\n\n\n\n\n Authentication \n\nWhen you manage views and alerts programmatically, you must use a service key. Authorization to the Configuration API is enforced by using a service key.\n\nA service key is a unique code that is passed in an API request to identify the calling application or user. The service key is specific to an auditing instance. For more information on how to generate a service key, see [Managing service keys](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-service_keys).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-config-api"},{"document_id":"ibmcld_12323-13061-14682","score":13.0986042023,"text":"\nCan you enable the TRACE to help DEBUG Schematics API while running workspace list command? \n\nNo, currently Schematics do not support this feature while running IBMCLOUD_TRACE=true ibmcloud schematics workspace list command.\n\n\n\n\n\n How do I resolve errors listing workspaces \n\nWhen listing or retrieving workspaces the following error may be received. Error while retrieving Schematics Instance for the given account.\n\nError:\nBad status code [400] returned when getting workspace from Schematics: {\"requestid\":\"fe5f0d6d-1d43-4643-a689-35d090463ce8\",\"timestamp\":\"2022-01-25T20:23:54.727208017Z\",\"messageid\":\"M1070\",\"message\":\"Error while retrieving Schematics Instance for the given account.\",\"statuscode\":400}\n\nYou might have insufficient access for the workspaces in specified location to fetch the instance. Do check the permission that is provided for your account and the locations where your instance need to be created. For more information, see [Where is my information stored?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-secure-datapi-location)\n\n\n\n\n\n How can I use (IBM) GitLab repositories? \n\nYes, You can access the private (IBM) GitLab repository by using Schematics with the privileges.\n\n\n\n* If the private (IBM) GitLab repository git.cloud.ibm.com access token is not needed as the IAM token is used.\n* If the public GitLab gitlab.com, read_repository, and read_api access are needed to validate the branch name for private repository.\n\n\n\nYou can use the sample Terraform code block to configure the GitLab repository details.\n\n\"template_repo\": {\n\"url\": \"<gitlab_source_repo_url>\",\n\"branch\": \"\"\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-workspaces-faq"},{"document_id":"ibmcld_04146-1603-3385","score":12.9201364517,"text":"\nhttp.request.method String POST The HTTP method, in upper case \n http.request.uri String \/articles\/index?section=539061&expand=comments The absolute URI of the request \n http.request.uri.path String \/articles\/index The path of the request \n http.request.uri.query String section=539061&expand=comments The whole query string, minus the delimiting prefix \"?\" \n http.user_agent String Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/65.0.3325.181 Safari\/537.36 The whole HTTP user agent \n http.x_forwarded_for String The full X-Forwarded-For HTTP header \n ip.src IP address 93.155.208.22 The client TCP IP address, which can be adjusted to reflect the real client IP of the original client as applicable (for example, using HTTP headers like X-Forwarded-For or X-Real-IP) \n ip.geoip.asnum Number 222 The [Autonomous System](https:\/\/ibm.biz\/BdzqdD) (AS) number \n ip.geoip.country String GB The [2-letter country code](https:\/\/www.iso.org\/obp\/ui\/search\/code\/) \n ssl Boolean true Whether the HTTP connection to the client is encrypted \n\n\n\nThese standard fields follow the naming convention of the Wireshark display field reference. However, some subtle variations might exist in the preceding example values.\n\nIn addition to the standard fields, the following Cloudflare-defined fields are also available:\n\n\n\nTable 2. Available Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_16255-9219-11036","score":12.9108133316,"text":"\nAs an example, to delete any message data associated with a user that has the customer ID abc from your Watson Assistant instance, send the following cURL command:\n\ncurl -X DELETE -u \"apikey:3Df... ...Y7Pc9\" \"{url}\/v2\/user_data?customer_id=abc&version=2020-04-01\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2service-endpoint).\n\nAn empty JSON object {} is returned.\n\nFor more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2deleteuserdata).\n\nNote: Delete requests are processed in batches and may take up to 24 hours to complete.\n\n\n\n\n\n\n\n Web chat usage data \n\nThe Watson Assistant web chat sends limited usage data to the [Amplitude service](https:\/\/amplitude.com\/). When the web chat widget is being interacted with by a user, we track the features that are being used, and events such as how many times the widget is opened and how many users start conversations. This information does not include Assistant training data or the content of any chat interactions. The information being sent to Amplitude is not Content as defined in the Cloud Service Agreement (CSA); it is Account Usage Information as described in Section 9.d of the CSA and is handled accordingly as described in the [IBM Privacy Statement](https:\/\/www.ibm.com\/privacy). The purpose of this information gathering is limited to establishing statistics about use and effectiveness of the web chat and making general improvements.\n\n\n\n\n\n Private network endpoints \n\nYou can set up a private network for Watson Assistant instances that are part of a Plus or Enterprise service plan. Using a private network prevents data from being transferred over the public internet, and ensures greater data isolation.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-securing"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-3403-5572","score":17.7518615723,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":17.5831394196,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-1672-3877","score":15.9842672348,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04186-16084-17604","score":12.8357191086,"text":"\nFor a secured connection with HTTPS, you can either obtain a certificate from [Let's Encrypt](https:\/\/letsencrypt.org\/) as described in the following [IBM Cloud\u00ae blog](https:\/\/www.ibm.com\/cloud\/blog\/secure-apps-on-ibm-cloud-with-wildcard-certificates) or through [IBM Cloud Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-public-certificates&interface=ui).\n\n\n\n\n\n Increase performance and protect from Denial of Service attacks \n\nA distributed denial of service ([DDoS](https:\/\/en.wikipedia.org\/wiki\/Denial-of-service_attack)) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. CIS is equipped to protect your domain from DDoS.\n\n\n\n1. In the CIS dashboard, select Reliability > Global Load Balancer.\n2. Locate the GLB you created in the Load Balancers table.\n3. Enable the Security and Performance features in the Proxy column:\n\nZoom\n\n![CIS Proxy Toggle ON](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-proxy.png)\n\nCIS Proxy Toggle ON\n\n\n\nYour GLB is now protected. An immediate benefit is that the origin IP addresses of your clusters will be hidden from the clients. If CIS detects a threat for an upcoming request, the user may see a screen like this one before being redirected to your application:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cis"},{"document_id":"ibmcld_01391-16119-17644","score":12.7684841156,"text":"\nFor a secured connection with HTTPS, you can either obtain a certificate from [Let's Encrypt](https:\/\/letsencrypt.org\/) as described in the following [IBM Cloud\u00ae blog](https:\/\/www.ibm.com\/cloud\/blog\/secure-apps-on-ibm-cloud-with-wildcard-certificates) or through [IBM Cloud Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-public-certificates&interface=ui).\n\n\n\n\n\n Increase performance and protect from Denial of Service attacks \n\nA distributed denial of service ([DDoS](https:\/\/en.wikipedia.org\/wiki\/Denial-of-service_attack)) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. CIS is equipped to protect your domain from DDoS.\n\n\n\n1. In the CIS dashboard, select Reliability > Global Load Balancer.\n2. Locate the GLB you created in the Load Balancers table.\n3. Enable the Security and Performance features in the Proxy column:\n\nZoom\n\n![CIS Proxy Toggle ON](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-proxy.png)\n\nCIS Proxy Toggle ON\n\n\n\nYour GLB is now protected. An immediate benefit is that the origin IP addresses of your clusters will be hidden from the clients. If CIS detects a threat for an upcoming request, the user may see a screen like this one before being redirected to your application:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"},{"document_id":"ibmcld_04107-6095-8145","score":12.514787674,"text":"\nThis tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.\n* Always use HTTPS - Redirects all visitors to the HTTPS version.\n* Email obfuscation - Prevents spam from harvesters and bots that try to access email addresses on your pages.\n* Automatic HTTPS rewrites - Helps fix mixed content by changing http to https for all resources (or links) on your website that can be served with HTTPS.\n* Opportunistic encryption - Allows browsers to benefit from the improved performance of HTTP\/2 by informing them that your site is available over an encrypted connection.\n* Universal SSL - Activates universal SSL certificates from your zone to the edge.\n* True client IP header - Sends the user's IP address in the True-Client-IP header.\n\n\n\n\n\n\n\n Security standards and platform \n\n\n\n* TLS (SHA2 and SHA1)\n* IPv4 and IPv6\n* HTTP\/2\n\n\n\n\n\n\n\n Network attacks and mitigation \n\nGenerally, attacks fall into two categories:\n\n\n\nTable 1. Types of network attacks\n\n Layer-3 or Layer-4 attacks Layer-7 attacks \n\n These attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04170-7-2189","score":11.8005781174,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04136-7-2226","score":11.7970285416,"text":"\nDealing with Distributed Denial of Service attacks \n\nDistributed Denial of Service (DDoS) attacks are among the most common types of internet attacks that your website or host can encounter.\n\n\n\n What is a DDoS attack? \n\nA distributed denial of service (DDoS) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. DDoS attacks achieve effectiveness by utilizing many compromised computer systems as sources of attack traffic. Exploited machines can include computers and other networked resources such as IoT devices. From a high level, a DDoS attack is like a traffic jam clogging up a highway, preventing regular traffic from arriving at its destination.\n\n\n\n\n\n How DDoS attacks work \n\nAn attacker gains control of a network of online machines to carry out a DDoS attack. Computers and other machines (such as IoT devices) are infected with malware, turning each one into a bot (or zombie). The attacker controls the group of bots, which is called a botnet.\n\nAfter establishing a botnet, the attacker directs the machines by sending updated instructions to each bot using remote control. A targeted IP address can receive requests from a multitude of bots, causing the targeted server or network to overflow capacity. This creates a denial-of-service to normal traffic. Because each bot is a legitimate internet device, separating the attack traffic from normal traffic can be difficult.\n\n\n\n\n\n Common types of DDoS attacks \n\nDDoS attack vectors target varying components of a network connection. While nearly all DDoS attacks involve overwhelming a target device or network with traffic, attacks can be divided into three categories. An attacker can use one or multiple attack vectors, and might even cycle through these attack vectors based on countermeasures taken by the target.\n\nCommon types are:\n\n\n\n* Application layer attacks (Layer 7)\n* Protocol attacks (Layer 3 and Layer 4)\n* Volumetric attacks (amplification attacks)\n\n\n\n\n\n Application layer attacks \n\nAn application layer attack is sometimes referred to as a Layer-7 DDoS attack (in reference to the 7th layer of the OSI model).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-distributed-denial-of-service-ddos-attack-concepts"},{"document_id":"ibmcld_07902-1732-3843","score":11.7402410507,"text":"\nInformation system entry and exit points include, for example, firewalls, electronic mail servers, web servers, proxy servers, remote-access servers, workstations, notebook computers, and mobile devices. Malicious code includes, for example, viruses, worms, Trojan horses, and spyware. Malicious code can also be encoded in various formats (e.g., UUENCODE, Unicode), contained within compressed or hidden files, or hidden in files using steganography. Malicious code can be transported by different means including, for example, web accesses, electronic mail, electronic mail attachments, and portable storage devices. Malicious code insertions occur through the exploitation of information system vulnerabilities. Malicious code protection mechanisms include, for example, anti-virus signature definitions and reputation-based technologies. A variety of technologies and methods exist to limit or eliminate the effects of malicious code. Pervasive configuration management and comprehensive software integrity controls may be effective in preventing execution of unauthorized code. In addition to commercial off-the-shelf software, malicious code may also be present in custom-built software. This could include, for example, logic bombs, back doors, and other types of cyber attacks that could affect organizational missions\/business functions. Traditional malicious code protection mechanisms cannot always detect such code. In these situations, organizations rely instead on other safeguards including, for example, secure coding practices, configuration management and control, trusted procurement processes, and monitoring practices to help ensure that software does not perform functions other than the functions intended. Organizations may determine that in response to the detection of malicious code, different actions may be warranted. For example, organizations can define actions in response to malicious code detection during periodic scans, actions in response to detection of malicious downloads, and\/or actions in response to detection of maliciousness when attempting to open or execute files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-si-3"},{"document_id":"ibmcld_12946-3098-5236","score":11.7177782059,"text":"\nUsers of Git Project Access Tokens with the Developer (or greater) role are counted as authorized users. These users appear in the list of authorized users as bot users.\n\n\n\nUsers with the Guest or Reporter roles are not automatically added to the authorized users list. To prevent users from accessing toolchains and automatically being added to the authorized user list for a Continuous Delivery service instance, complete the following actions:\n\n\n\n* Remove the user's access to the toolchain from IAM.\n* Remove Developer access from all Git Repos and Issue Tracking repos that are attached to all of the toolchains in the resource group by removing their repo access or downgrading their role to Guest or Reporter.\n\n\n\nThe specific activities that are used to automatically count users, and the method for counting those users might change over time. However, the process for counting users will continue to comply with the terms of Continuous Delivery plans. You can also manually add users to the list of authorized users, at any time.\n\nFor more information about using IAM to manage access to toolchains in a resource group or the toolchain itself, see [Managing user access to toolchains with Identity and Access Management](https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-toolchains-iam-security). For more information about managing access to a Git Repos and Issue Tracking repo, see [Project's members](https:\/\/us-south.git.cloud.ibm.com\/help\/user\/project\/members\/index.md).\n\nThe method that you use to organize toolchains within resource groups directly impacts user access and billing. When a user uses toolchains in multiple regions or resource groups, they are counted and billed for each Continuous Delivery service instance within each unique pairing of region and resource group.\n\nYou can manage the list of authorized users on the Manage tab within the Continuous Delivery service instance.\n\n\n\n1. Go to the [Resource list](https:\/\/cloud.ibm.com\/resources) for your IBM Cloud account.\n2. In the Name column, in the filter text box, type Continuous Delivery to view your existing services.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-limitations_usage"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09059-2794-4456","score":16.5551319122,"text":"\nTo protect your privacy, ensure that the key name does not contain personally identifiable information (PII), such as your name or location. Note that key names do not need to be unique. \n Key alias Optional. [Key aliases](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-key-alias) are ways to describe a key that allow them to be identified and grouped beyond the limits of a display name. Keys can have up to five aliases. \n Key ring Optional. [Key rings](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys) are groupings of keys that allow those groupings to be managed independently as needed. Every key must be a part of a key ring. If no key ring is selected, keys are placed in the default key ring. Note that to place the key you're creating in a key ring, you must have the Manager role over that key ring. For more information about roles, check out [Managing user access](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-access). \n Rotation policy Optional. If you hold the [Manager role](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-access), you can set a rotation policy for the key at key-creation time. If an [instance policy](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-policies-instance) exists to create rotation policies on keys by default, you can also overwrite that policy at key-creation time to a different interval. Note that if your instance has a rotation policy enabled and you Disable the rotation policy at key creation time, the policy is still written to your key in a Disabled state. If you want to enable this policy later, you can do so.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-root-keys"},{"document_id":"ibmcld_09109-6121-7923","score":16.2343788147,"text":"\n<br> <br>Important: To protect your privacy, do not store your personal data as metadata for your key. <br> <br>Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies. registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. \n key_description Optional.An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_material Required.The base64-encoded key material, such as a symmetric key, that you want to manage in the service. For more information, check out [Base64 encoding your key material](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-standard-keyshow-to-encode-standard-key-material). <br> <br>Ensure that the key material meets the following requirements: <br>A standard key can be up to 7,500 bytes in size. The key must be base64-encoded. \n key_type A boolean value that determines whether the key material can leave the service. <br> <br>When you set the extractable attribute to true, the service designates the key as a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-standard-keys"},{"document_id":"ibmcld_08515-6389-8309","score":16.1183547974,"text":"\nTo protect your privacy, do not store your personal data as metadata for your key. \n key_description An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_material The base64 encoded key material, such as an existing key-wrapping key, that you want to store and manage in the service. For more information, see [Base64 encoding your key material](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-import-root-keysencode-key-material-root-key). Ensure that the key material meets the following requirements:<br><br><br><br> * The key must be 16, 24, or 32 bytes long, corresponding to 128, 192, or 256 bits.<br> * The key must be base64-encoded.<br><br><br> \n key_type A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to false, the service designates the key as a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https:\/\/www.nist.gov\/publications\/guide-protecting-confidentiality-personally-identifiable-information-pii).\n\nA successful POST api\/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Hyper Protect Crypto Services key management service API.\n3. Optional: Verify that the key was added by running the following call to browse the keys in your Hyper Protect Crypto Services service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-import-root-keys"},{"document_id":"ibmcld_08432-6308-8159","score":15.3540973663,"text":"\nA unique, human-readable name for easy identification of your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional. One or more unique, human-readable aliases assigned to your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key.<br><br>Each alias must be alphanumeric, case-sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Hyper Protect Crypto Services reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be 2 - 90 characters (inclusive). \n key_description Optional: An extended description of your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS Optional: The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service.<br><br>When you set the extractable attribute to false, the service creates a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https:\/\/nvlpubs.nist.gov\/nistpubs\/Legacy\/SP\/nistspecialpublication800-122.pdf).\n\nIf you set the expirationDate in your request, the key is moved to the deactivated state within 1 hour past the key's expiration date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-create-root-keys"},{"document_id":"ibmcld_09059-7769-9779","score":15.033821106,"text":"\nA human-readable name for convenient identification of your key. Important: To protect your privacy, do not store your personal data as metadata for your key. \n alias_list One or more unique, human-readable aliases assigned to your key. Important: To protect your privacy, do not store your personal data as metadata for your key. Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be between 2 - 90 characters (inclusive). \n key_description An extended description of your key. Important: To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional. The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to false, the service creates a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.\n\nIf the expirationDate is provided in your create key request, the key will transition to the deactivated state within one hour past the key's expiration date.\n\nA successful POST api\/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Key Protect API.\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-root-keys"},{"document_id":"ibmcld_08433-6344-8271","score":15.0080633163,"text":"\nOne or more unique, human-readable aliases assigned to your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key.<br><br>Each alias must be alphanumeric, case-sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Hyper Protect Crypto Services reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be 2 - 90 characters (inclusive). \n key_description Optional: An extended description of your key.<br><br>Important: To protect your privacy, do not store your personal data as metadata for your key. \n YYYY-MM-DD<br><br>HH:MM:SS.SS Optional: The date and time that the key expires in the system, in RFC 3339 format. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service.<br><br>When you set the extractable attribute to true, the service creates a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service. For more examples of PII, see section 2.2 of the [NIST Special Publication 800-122](https:\/\/nvlpubs.nist.gov\/nistpubs\/Legacy\/SP\/nistspecialpublication800-122.pdf).\n\nA successful POST \/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Hyper Protect Crypto Services key management service API.\n3. Optional: Verify that the key was created by running the following call to get the keys in your Hyper Protect Crypto Services service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-create-standard-keys"},{"document_id":"ibmcld_04519-20259-21874","score":14.9908809662,"text":"\nTo protect your privacy, do not use personal data, such as your name or location, as a description for your secret group.\n\nThe maximum length is 1024 characters. The minimum length is 0 characters. The value must match regular expression \/(.?)\/.\n\n--labels ([]string)\n: Labels that you can use to search secrets in your instance. Only 30 labels can be created.\n\nLabel can be between 2-30 characters, including spaces.\n\nTo protect your privacy, do not use personal data, such as your name or location, as a label for your secret.\n\nThe list items must match regular expression \/(.?)\/. The maximum length is 30 items. The minimum length is 0 items.\n\n--custom-metadata (generic map)\n: The secret metadata that a user can customize.\n\n--expiration-date (strfmt.DateTime)\n: The date when the secret material expires. The date format follows the RFC 3339 format.\n\n--ttl (string)\n: The time-to-live (TTL) or lease duration to assign to credentials that are generated.\n\nFor iam_credentials secrets, the TTL defines for how long each generated API key remains valid. The value can be either an integer that specifies the number of seconds, or the string representation of a duration, such as 120m or 24h.\n\nThe minimum duration is 1 minute. The maximum is 90 days.\n\nThe maximum length is 10 characters. The minimum length is 2 characters. The value must match regular expression \/^[0-9]+[s,m,h,d]{0,1}$\/.\n\n--rotation ([RotationPolicy](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-secrets-manager-clicli-rotation-policy-example-schema))\n: This field indicates whether Secrets Manager rotates your secrets automatically.\n\n\n\n\n\n Example","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-secrets-manager-cli"},{"document_id":"ibmcld_09060-6596-8123","score":14.8847408295,"text":"\nTo protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_type Optional.A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to true, the service creates a standard key that you can store in your apps or services. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.\n\nA successful POST api\/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Key Protect API.\n\nOptional: Verify that the key was created by running the following call to get the keys in your Key Protect service instance.\n\n$ curl -X GET \"https:\/\/<regon>.kms.cloud.ibm.com\/api\/v2\/keys\" -H \"accept: application\/vnd.ibm.collection+json\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\"\n\n\n\n\n\n What's next \n\n\n\n* To find out more about programmatically managing your keys, [check out the Key Protect API reference doc](https:\/\/cloud.ibm.com\/apidocs\/key-protect).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-standard-keys"},{"document_id":"ibmcld_12358-20397-22058","score":14.52850914,"text":"\nTo protect your privacy, do not use personal data, such as your name or location, as a description for your secret group.\n\nThe maximum length is 1024 characters. The minimum length is 0 characters. The value must match regular expression \/(.?)\/.\n\n--labels ([]string)\n: Labels that you can use to search secrets in your instance. Only 30 labels can be created.\n\nLabel can be between 2-30 characters, including spaces.\n\nTo protect your privacy, do not use personal data, such as your name or location, as a label for your secret.\n\nThe list items must match regular expression \/(.?)\/. The maximum length is 30 items. The minimum length is 0 items.\n\n--custom-metadata (generic map)\n: The secret metadata that a user can customize.\n\n--expiration-date (strfmt.DateTime)\n: The date when the secret material expires. The date format follows the RFC 3339 format.\n\n--ttl (string)\n: The time-to-live (TTL) or lease duration to assign to credentials that are generated.\n\nFor iam_credentials secrets, the TTL defines for how long each generated API key remains valid. The value can be either an integer that specifies the number of seconds, or the string representation of a duration, such as 120m or 24h.\n\nThe minimum duration is 1 minute. The maximum is 90 days.\n\nThe maximum length is 10 characters. The minimum length is 2 characters. The value must match regular expression \/^[0-9]+[s,m,h,d]{0,1}$\/.\n\n--rotation ([RotationPolicy](https:\/\/cloud.ibm.com\/docs\/secrets-manager-cli-plugin?topic=secrets-manager-cli-plugin-secrets-manager-clicli-rotation-policy-example-schema))\n: This field indicates whether Secrets Manager rotates your secrets automatically.\n\n\n\n\n\n Example","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager-cli-plugin?topic=secrets-manager-cli-plugin-secrets-manager-cli"},{"document_id":"ibmcld_12397-20364-22014","score":14.4275064468,"text":"\nTo protect your privacy, do not use personal data, such as your name or location, as a description for your secret group.\n\nThe maximum length is 1024 characters. The minimum length is 0 characters. The value must match regular expression \/(.?)\/.\n\n--labels ([]string)\n: Labels that you can use to search secrets in your instance. Only 30 labels can be created.\n\nLabel can be between 2-30 characters, including spaces.\n\nTo protect your privacy, do not use personal data, such as your name or location, as a label for your secret.\n\nThe list items must match regular expression \/(.?)\/. The maximum length is 30 items. The minimum length is 0 items.\n\n--custom-metadata (generic map)\n: The secret metadata that a user can customize.\n\n--expiration-date (strfmt.DateTime)\n: The date when the secret material expires. The date format follows the RFC 3339 format.\n\n--ttl (string)\n: The time-to-live (TTL) or lease duration to assign to credentials that are generated.\n\nFor iam_credentials secrets, the TTL defines for how long each generated API key remains valid. The value can be either an integer that specifies the number of seconds, or the string representation of a duration, such as 120m or 24h.\n\nThe minimum duration is 1 minute. The maximum is 90 days.\n\nThe maximum length is 10 characters. The minimum length is 2 characters. The value must match regular expression \/^[0-9]+[s,m,h,d]{0,1}$\/.\n\n--rotation ([RotationPolicy](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-clicli-rotation-policy-example-schema))\n: This field indicates whether Secrets Manager rotates your secrets automatically.\n\n\n\n\n\n Example","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-cli"}],"retriever_scores":{"recall_1":0.2,"recall_3":0.6,"recall_5":0.6,"recall_10":0.8,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":0.7227265726,"ndcg_cut_10":0.829719705}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01535-4585-6962","score":26.3504638672,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4546-6910","score":26.1467895508,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_07971-2155-4528","score":22.697221756,"text":"\n* Document and evidence the execution of the system\/service and security testing\/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https:\/\/github.com\/IBM\/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-development-processes"},{"document_id":"ibmcld_09410-1574-3779","score":22.6961555481,"text":"\n* IBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM.\n* The IBM Cloud Container Registry includes Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\n\n\nTo get details about the logging agent images, see [Getting information about logging agent images](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent_image).\n\n\n\n Resource Limits for agents deployed on Kubernetes \n\nThe agent is deployed as a Kubernetes DaemonSet, creating one pod for each node selected. The agent collects logs of all the pods in the node. The resource requirements of the agent are in direct relation to the number of pods for each node and the amount of logs produced for each pod.\n\nThe agent requires at least 128 MB and no more than 512 MB of memory. It requires at least twenty millicpu (20m).\n\nDifferent features can also increase resource utilization. When line exclusion, inclusion or redaction rules are specified, you can expect additional CPU consumption for each line and regex rule defined. When Kubernetes event logging is enabled (disabled by default), additional CPU usage will occur on the oldest agent pod.\n\nPlacing traffic shaping or CPU limits on the agent is not recommended to ensure data can be sent to the log ingestion service.\n\n\n\n\n\n Understanding image tags \n\nThe tag that is associated to a logging image indicates whether the logging agent is automatically updated.\n\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_01447-1492-3786","score":22.0952911377,"text":"\nVulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nReview the following table to find an overview of benefits of using Container Registry.\n\n\n\nTable 1. Container Registry benefits\n\n Benefit Description \n\n Highly available and scalable private registry. Set up your own image namespace in a multi-tenant, highly available, scalable, encrypted private registry that is hosted and managed by IBM.<br><br>Store your private Docker images and share them with users in your IBM Cloud account. \n Image security compliance with Vulnerability Advisor. Benefit from automatic scanning of images in your namespace.<br><br>Review recommendations that are specific to the operating system to fix potential vulnerabilities and protect your containers from being compromised. \n Quota limits for storage and pull traffic. Benefit from free storage and pull traffic to your private images until you reach your free quota.<br><br>Set custom quota limits for the amount of storage and pull traffic per month to avoid exceeding your preferred payment level. \n\n\n\n\n\n Service plans \n\nYou can choose between the free or standard Container Registry service plans to store your Docker images and make these images available to users in your IBM Cloud account.\n\nThe IBM Cloud Container Registry service plan determines the amount of storage and pull traffic that you can use for your private images. The service plan is associated with your IBM Cloud account, and limits for storage and image pull traffic apply to all namespaces that you set up in your account.\n\nService plans are scoped to the specific registry instance (one of the regional registries or the global registry) that you're currently working with. Plan settings must all be managed separately for your account in each registry instance. For more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\nThe following table shows available IBM Cloud Container Registry service plans and their characteristics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"},{"document_id":"ibmcld_06004-36463-38401","score":21.4277057648,"text":"\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, encrypt traffic between app microservices, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images. When you add an image to your organization's IBM Cloud Container Registry namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n\nKubernetes secrets\n: When you deploy your app, don't store confidential information, such as credentials or keys, in the YAML configuration file, configmaps, or scripts. Instead, use [Kubernetes secrets](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitypi), such as an image pull secret for registry credentials. You can then reference these secrets in your deployment YAML file.\n\nSecret encryption\n: You can encrypt the Kubernetes secrets that you create in your cluster by using a key management service (KMS) provider. To get started, see [Encrypt secrets by using a KMS provider](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionkeyprotect) and [Verify that secrets are encrypted](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionverify_kms).\n\nMicroservice traffic encryption","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy"},{"document_id":"ibmcld_10439-40150-42016","score":21.349981308,"text":"\nAs you plan how many Service objects you need in your cluster, keep in mind that Kubernetes uses iptables to handle networking and port forwarding rules. If you run many services in your cluster, such as 5000, performance might be impacted.\n\n\n\n\n\n\n\n Securing apps \n\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images. When you add an image to your organization's IBM Cloud Container Registry namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n\nKubernetes secrets\n: When you deploy your app, don't store confidential information, such as credentials or keys, in the YAML configuration file, configmaps, or scripts. Instead, use [Kubernetes secrets](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitypi), such as an image pull secret for registry credentials. You can then reference these secrets in your deployment YAML file.\n\nSecret encryption\n: You can encrypt the Kubernetes secrets that you create in your cluster by using a key management service (KMS) provider.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deploy"},{"document_id":"ibmcld_01533-6329-8623","score":21.1889572144,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":21.1889572144,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_10510-58427-60403","score":21.1348514557,"text":"\nPush images with trusted content only Ensure the integrity of your images by enabling [content trust](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_trustedcontentregistry_trustedcontent) in your image repository. With trusted content, you can control who can sign images as trusted and push images to a specific registry namespace. After trusted signers push an image to a registry namespace, users can pull the signed content so that they can verify the publisher and the integrity of the image. \n Automatic vulnerability scans When you use IBM Cloud Container Registry, you can leverage the built-in security scanning that is provided by [Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_registry_cli). Every image that is pushed to your registry namespace is automatically scanned for vulnerabilities against a database of known CentOS, Debian, Red Hat, and Ubuntu issues. If vulnerabilities are found, Vulnerability Advisor provides instructions for how to resolve them to ensure image integrity and security. \n Block deployments from vulnerable images or untrusted users Create an admission controller with custom policies so that you can verify container images before you deploy them. With the [open source Portieris project](https:\/\/github.com\/IBM\/portieris), you control where the images are deployed from and ensure that they meet content trust requirements. If a deployment does not meet the policies that you set, the admission controller blocks the deployment in your cluster. \n\n\n\nWhat options do I have to scan running containers for vulnerabilities?\n: You can install third-party solutions in your cluster, such as [Twistlock](https:\/\/www.paloaltonetworks.com\/prisma\/cloud) or [StackRox](https:\/\/www.redhat.com\/en\/technologies\/cloud-computing\/openshift\/advanced-cluster-security-kubernetes) to scan running containers and block malicious activities when they are detected.\n\n\n\n\n\n Container isolation and security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01535-4585-6962","score":22.4829006195,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4546-6910","score":22.4518432617,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01533-6329-8623","score":18.8846111298,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":18.8846111298,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01415-6473-8616","score":18.6564350128,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_07971-2155-4528","score":18.6321048737,"text":"\n* Document and evidence the execution of the system\/service and security testing\/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https:\/\/github.com\/IBM\/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-development-processes"},{"document_id":"ibmcld_09410-1574-3779","score":18.5596237183,"text":"\n* IBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM.\n* The IBM Cloud Container Registry includes Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\n\n\nTo get details about the logging agent images, see [Getting information about logging agent images](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent_image).\n\n\n\n Resource Limits for agents deployed on Kubernetes \n\nThe agent is deployed as a Kubernetes DaemonSet, creating one pod for each node selected. The agent collects logs of all the pods in the node. The resource requirements of the agent are in direct relation to the number of pods for each node and the amount of logs produced for each pod.\n\nThe agent requires at least 128 MB and no more than 512 MB of memory. It requires at least twenty millicpu (20m).\n\nDifferent features can also increase resource utilization. When line exclusion, inclusion or redaction rules are specified, you can expect additional CPU consumption for each line and regex rule defined. When Kubernetes event logging is enabled (disabled by default), additional CPU usage will occur on the oldest agent pod.\n\nPlacing traffic shaping or CPU limits on the agent is not recommended to ensure data can be sent to the log ingestion service.\n\n\n\n\n\n Understanding image tags \n\nThe tag that is associated to a logging image indicates whether the logging agent is automatically updated.\n\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_01447-1492-3786","score":18.3091411591,"text":"\nVulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nReview the following table to find an overview of benefits of using Container Registry.\n\n\n\nTable 1. Container Registry benefits\n\n Benefit Description \n\n Highly available and scalable private registry. Set up your own image namespace in a multi-tenant, highly available, scalable, encrypted private registry that is hosted and managed by IBM.<br><br>Store your private Docker images and share them with users in your IBM Cloud account. \n Image security compliance with Vulnerability Advisor. Benefit from automatic scanning of images in your namespace.<br><br>Review recommendations that are specific to the operating system to fix potential vulnerabilities and protect your containers from being compromised. \n Quota limits for storage and pull traffic. Benefit from free storage and pull traffic to your private images until you reach your free quota.<br><br>Set custom quota limits for the amount of storage and pull traffic per month to avoid exceeding your preferred payment level. \n\n\n\n\n\n Service plans \n\nYou can choose between the free or standard Container Registry service plans to store your Docker images and make these images available to users in your IBM Cloud account.\n\nThe IBM Cloud Container Registry service plan determines the amount of storage and pull traffic that you can use for your private images. The service plan is associated with your IBM Cloud account, and limits for storage and image pull traffic apply to all namespaces that you set up in your account.\n\nService plans are scoped to the specific registry instance (one of the regional registries or the global registry) that you're currently working with. Plan settings must all be managed separately for your account in each registry instance. For more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\nThe following table shows available IBM Cloud Container Registry service plans and their characteristics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"},{"document_id":"ibmcld_01535-4-2366","score":18.1629295349,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4-2366","score":18.1629295349,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.4,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.200136681}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01535-4-2366","score":19.57954216,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4-2366","score":19.57954216,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01329-59746-61590","score":19.3903923035,"text":"\nFor more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.\n\nFor information about supported Docker base images, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\nFor more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui).\n\n--extended, -e\n: (Optional) The command output shows additional information about fixes for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01442-1679-3832","score":18.9754161835,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-1679-3819","score":18.8838405609,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01533-6329-8623","score":18.8080787659,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":18.8080787659,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4546-6910","score":18.8080749512,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01442-7-2257","score":18.7833042145,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-7-2257","score":18.7833042145,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.75,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1510196182,"ndcg_cut_10":0.3813808643}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01441-1679-3819","score":20.0648593903,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-1679-3832","score":20.0393257141,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01535-6381-8675","score":19.591386795,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":19.591386795,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01533-4-2366","score":19.3771190643,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4-2366","score":19.3771190643,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01329-58331-60199","score":19.2688350677,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01410-2747-3497","score":19.226808548,"text":"\nVersion 1.0.0 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability Advisor v4 is now available, see [Vulnerability Advisor 4 is available from Container Registry plug-in 1.0.0](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes15sep2022_va_version_4).\n* Image and digest list output no longer includes security status by default. You can either add the --va argument to include security status for all the listed images, or you can use the ibmcloud cr va command to query security status for an individual image.\n\n\n\n\n\n\n\n Version 0.1.582 \n\nVersion 0.1.582 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_change_log"},{"document_id":"ibmcld_04340-57846-59619","score":19.1046161652,"text":"\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-containerregcli"},{"document_id":"ibmcld_01441-7-2257","score":18.7905635834,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01441-1679-3819","score":18.6591091156,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-1679-3832","score":18.632938385,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-7-2257","score":17.8216171265,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":17.8216171265,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":17.5379486084,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":17.5379486084,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01329-58331-60199","score":17.5361614227,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_16727-367382-369550","score":17.4383144379,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-367408-369576","score":17.4383144379,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01471-7-1919","score":16.7393779755,"text":"\nRelease notes for Container Registry \n\nLearn about the changes to IBM Cloud\u00ae Container Registry and Vulnerability Advisor. The changes are grouped by date.\n\n\n\n 19 June 2023 \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023\n: For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\n\n\n 19 May 2023 \n\nUpdate Vulnerability Advisor to version 4 by 19 June 2023\n: The Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\nFor more information, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4).\n\n\n\n\n\n 26 April 2023 \n\nUsing Portieris to block the deployment of images with issues is deprecated.\n: The use of Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n\n\n 11 November 2022 \n\nChange to virtual private endpoints\n: Virtual private endpoints are changing.\n\nOn 11 November 2022, virtual private endpoints (VPEs) for IBM Cloud Container Registry are being updated and the existing VPE version is being deprecated on 15 December 2022. If you use Container Registry VPE gateways, you must create new VPE gateways and remove your VPE gateways that were created before 11 November 2022 at the earliest opportunity so that you pick up these changes. VPE gateways that were created before 11 November 2022 are deprecated and will not work after 15 December 2022.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.3487022475}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01535-4585-6962","score":24.9504795074,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4546-6910","score":24.6276321411,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_06004-36463-38401","score":23.2923431396,"text":"\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, encrypt traffic between app microservices, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images. When you add an image to your organization's IBM Cloud Container Registry namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n\nKubernetes secrets\n: When you deploy your app, don't store confidential information, such as credentials or keys, in the YAML configuration file, configmaps, or scripts. Instead, use [Kubernetes secrets](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitypi), such as an image pull secret for registry credentials. You can then reference these secrets in your deployment YAML file.\n\nSecret encryption\n: You can encrypt the Kubernetes secrets that you create in your cluster by using a key management service (KMS) provider. To get started, see [Encrypt secrets by using a KMS provider](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionkeyprotect) and [Verify that secrets are encrypted](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionverify_kms).\n\nMicroservice traffic encryption","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy"},{"document_id":"ibmcld_07971-2155-4528","score":23.1810531616,"text":"\n* Document and evidence the execution of the system\/service and security testing\/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https:\/\/github.com\/IBM\/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-development-processes"},{"document_id":"ibmcld_10510-58427-60403","score":22.1403675079,"text":"\nPush images with trusted content only Ensure the integrity of your images by enabling [content trust](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_trustedcontentregistry_trustedcontent) in your image repository. With trusted content, you can control who can sign images as trusted and push images to a specific registry namespace. After trusted signers push an image to a registry namespace, users can pull the signed content so that they can verify the publisher and the integrity of the image. \n Automatic vulnerability scans When you use IBM Cloud Container Registry, you can leverage the built-in security scanning that is provided by [Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_registry_cli). Every image that is pushed to your registry namespace is automatically scanned for vulnerabilities against a database of known CentOS, Debian, Red Hat, and Ubuntu issues. If vulnerabilities are found, Vulnerability Advisor provides instructions for how to resolve them to ensure image integrity and security. \n Block deployments from vulnerable images or untrusted users Create an admission controller with custom policies so that you can verify container images before you deploy them. With the [open source Portieris project](https:\/\/github.com\/IBM\/portieris), you control where the images are deployed from and ensure that they meet content trust requirements. If a deployment does not meet the policies that you set, the admission controller blocks the deployment in your cluster. \n\n\n\nWhat options do I have to scan running containers for vulnerabilities?\n: You can install third-party solutions in your cluster, such as [Twistlock](https:\/\/www.paloaltonetworks.com\/prisma\/cloud) or [StackRox](https:\/\/www.redhat.com\/en\/technologies\/cloud-computing\/openshift\/advanced-cluster-security-kubernetes) to scan running containers and block malicious activities when they are detected.\n\n\n\n\n\n Container isolation and security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_10439-40150-42016","score":22.1066818237,"text":"\nAs you plan how many Service objects you need in your cluster, keep in mind that Kubernetes uses iptables to handle networking and port forwarding rules. If you run many services in your cluster, such as 5000, performance might be impacted.\n\n\n\n\n\n\n\n Securing apps \n\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images. When you add an image to your organization's IBM Cloud Container Registry namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n\nKubernetes secrets\n: When you deploy your app, don't store confidential information, such as credentials or keys, in the YAML configuration file, configmaps, or scripts. Instead, use [Kubernetes secrets](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitypi), such as an image pull secret for registry credentials. You can then reference these secrets in your deployment YAML file.\n\nSecret encryption\n: You can encrypt the Kubernetes secrets that you create in your cluster by using a key management service (KMS) provider.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deploy"},{"document_id":"ibmcld_09410-1574-3779","score":21.4173374176,"text":"\n* IBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM.\n* The IBM Cloud Container Registry includes Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\n\n\nTo get details about the logging agent images, see [Getting information about logging agent images](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent_image).\n\n\n\n Resource Limits for agents deployed on Kubernetes \n\nThe agent is deployed as a Kubernetes DaemonSet, creating one pod for each node selected. The agent collects logs of all the pods in the node. The resource requirements of the agent are in direct relation to the number of pods for each node and the amount of logs produced for each pod.\n\nThe agent requires at least 128 MB and no more than 512 MB of memory. It requires at least twenty millicpu (20m).\n\nDifferent features can also increase resource utilization. When line exclusion, inclusion or redaction rules are specified, you can expect additional CPU consumption for each line and regex rule defined. When Kubernetes event logging is enabled (disabled by default), additional CPU usage will occur on the oldest agent pod.\n\nPlacing traffic shaping or CPU limits on the agent is not recommended to ensure data can be sent to the log ingestion service.\n\n\n\n\n\n Understanding image tags \n\nThe tag that is associated to a logging image indicates whether the logging agent is automatically updated.\n\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_01415-6473-8616","score":21.198841095,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_06063-53153-55320","score":21.1553630829,"text":"\nImage Vulnerability Scanner: By default, Vulnerability Advisor scans images that are stored in IBM Cloud Container Registry to find potential security vulnerabilities. For more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n4. IBM Cloud Security and Compliance Center: When you enable IBM Cloud Security and Compliance Center, you can view reports about suspicious incoming and outgoing network traffic. For more information, see [What is IBM Cloud Security and Compliance Center?](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n5. IBM Cloud\u00ae Secrets Manager: You can store your Ingress and Kubernetes secrets in IBM Cloud\u00ae Secrets Manager. When you integrate Secrets Manager into your cluster, you set a default Secrets Manager instance where all Ingress subdomain secrets are uploaded. For more information, see [Setting up Secrets Manager in your Kubernetes Service cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-secrets-mgr).\n\n\n\n\n\n\n\n Image and registry \n\nEvery deployment is based on an image that holds the instructions for how to spin up the container that runs your app. These instructions include the operating system inside the container and extra software that you want to install. To protect your app, you must protect the image and establish checks to ensure the image's integrity.\n\nShould I use a public or a private registry to store my images?\n: Public registries, such as Docker Hub, can be used to get started with Docker images and Kubernetes to create your first containerized app in a cluster. But when it comes to enterprise applications, avoid registries that you don't know or don't trust to protect your cluster from malicious images. Keep your images in a private registry, like the one provided in IBM Cloud Container Registry and make sure to control access to the registry and the image content that can be pushed.\n\nWhy is it important to check images against vulnerabilities?\n: Research shows that most malicious attacks leverage known software vulnerabilities and weak system configurations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_01447-1492-3786","score":21.061422348,"text":"\nVulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nReview the following table to find an overview of benefits of using Container Registry.\n\n\n\nTable 1. Container Registry benefits\n\n Benefit Description \n\n Highly available and scalable private registry. Set up your own image namespace in a multi-tenant, highly available, scalable, encrypted private registry that is hosted and managed by IBM.<br><br>Store your private Docker images and share them with users in your IBM Cloud account. \n Image security compliance with Vulnerability Advisor. Benefit from automatic scanning of images in your namespace.<br><br>Review recommendations that are specific to the operating system to fix potential vulnerabilities and protect your containers from being compromised. \n Quota limits for storage and pull traffic. Benefit from free storage and pull traffic to your private images until you reach your free quota.<br><br>Set custom quota limits for the amount of storage and pull traffic per month to avoid exceeding your preferred payment level. \n\n\n\n\n\n Service plans \n\nYou can choose between the free or standard Container Registry service plans to store your Docker images and make these images available to users in your IBM Cloud account.\n\nThe IBM Cloud Container Registry service plan determines the amount of storage and pull traffic that you can use for your private images. The service plan is associated with your IBM Cloud account, and limits for storage and image pull traffic apply to all namespaces that you set up in your account.\n\nService plans are scoped to the specific registry instance (one of the regional registries or the global registry) that you're currently working with. Plan settings must all be managed separately for your account in each registry instance. For more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\nThe following table shows available IBM Cloud Container Registry service plans and their characteristics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01390-0-434","score":21.8083686829,"text":"\n\n\n\n\n\n\n  Managing security and compliance for Container Registry \n\nIBM Cloud\u00ae Container Registry is integrated with the Security and Compliance Center to help you manage security and compliance for your organization.\n\nFor more information about managing security and compliance, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-manage-security-compliance"},{"document_id":"ibmcld_01447-7-2032","score":21.3258972168,"text":"\nAbout Container Registry \n\nUse IBM Cloud\u00ae Container Registry to store and access private container images in a highly available and scalable architecture.\n\nIBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image\n\nregistrythat is hosted and managed by IBM. You can use Container Registry by setting up your own imagenamespaceand pushing container images to your namespace.\n\nZoom\n\n![Diagram showing how you can interact with IBM Cloud Container Registry.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/images\/about_container_registry_v2.svg)\n\nFigure 1. How Container Registry interacts with your images\n\nA Docker image is the basis for every container that you create. An image is created from a\n\nDockerfile, which is a file that contains instructions to build the image. A Dockerfile might reference build artifacts in its instructions that are stored separately, such as an app, the configuration of the app, and its dependencies. Images are typically stored in a registry that can either be accessible by the public (public registry) or set up with limited access for a small group of users (private registry). By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nReview the following table to find an overview of benefits of using Container Registry.\n\n\n\nTable 1. Container Registry benefits\n\n Benefit Description \n\n Highly available and scalable private registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"},{"document_id":"ibmcld_01408-7-1878","score":20.9332866669,"text":"\nIBM Cloud Container Registry architecture and workload \n\nIBM Cloud\u00ae Container Registry is a multi-tenant, highly available, scalable, and encrypted private image\n\nregistrythat is hosted and managed by IBM.\n\nBoth the control plane (management of images and configuration) and data plane (pushing and pulling your images) are multi-tenant. All parts of the service are hosted in an IBM service account, which is not shared with users or other services.\n\nIn each regional instance of the [registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_registry), the service runs in three physically separate data centers to ensure availability. All data and the configuration for each instance of the registry is retained within the region in which it is hosted. The global instance is also hosted in physically separate data centers. The data centers might not be in the same region as each other. For more information about regions, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\nIBM Cloud Container Registry runs in IBM Cloud Kubernetes Service clusters, and uses IBM Cloud Object Storage to store images. Image data in IBM Cloud Object Storage is encrypted at rest.\n\nZoom\n\n![Diagram showing deployment.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/images\/container_registry_architecture_mul.svg)\n\nFigure 1. Diagram showing deployment\n\n\n\n Segmentation of data \n\nSegmentation of data within IBM Cloud Container Registry is achieved by using private\n\nnamespaces, which are strictly owned by single accounts.\n\nYou can control access to [namespaces](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace) within the account by using Cloud Identity and Access Management (IAM) access policies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_architecture"},{"document_id":"ibmcld_09410-1574-3779","score":20.7232189178,"text":"\n* IBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM.\n* The IBM Cloud Container Registry includes Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\n\n\nTo get details about the logging agent images, see [Getting information about logging agent images](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent_image).\n\n\n\n Resource Limits for agents deployed on Kubernetes \n\nThe agent is deployed as a Kubernetes DaemonSet, creating one pod for each node selected. The agent collects logs of all the pods in the node. The resource requirements of the agent are in direct relation to the number of pods for each node and the amount of logs produced for each pod.\n\nThe agent requires at least 128 MB and no more than 512 MB of memory. It requires at least twenty millicpu (20m).\n\nDifferent features can also increase resource utilization. When line exclusion, inclusion or redaction rules are specified, you can expect additional CPU consumption for each line and regex rule defined. When Kubernetes event logging is enabled (disabled by default), additional CPU usage will occur on the oldest agent pod.\n\nPlacing traffic shaping or CPU limits on the agent is not recommended to ensure data can be sent to the log ingestion service.\n\n\n\n\n\n Understanding image tags \n\nThe tag that is associated to a logging image indicates whether the logging agent is automatically updated.\n\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_01376-0-968","score":20.5958118439,"text":"\n\n\n\n\n\n\n  Getting help and support for Container Registry \n\nIf you experience an issue or have questions when you are using IBM Cloud\u00ae Container Registry, you can use the following resources before you open a support case.\n\n\n\n*  Review the [FAQs](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui) in the product documentation.\n*  Review the [troubleshooting documentation](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-ts_index&interface=ui) to troubleshoot and resolve common issues.\n*  Check the status of the IBM Cloud platform and resources by going to the [Status page](https:\/\/cloud.ibm.com\/status).\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case). And, if you're looking to provide feedback, see [Submitting feedback](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-feedback).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support"},{"document_id":"ibmcld_01393-7-1816","score":20.5513267517,"text":"\nAccessing Container Registry \n\nTo access your IBM Cloud\u00ae Container Registry namespaces so that you can push and pull images, use IBM Cloud\u00ae Identity and Access Management (IAM).\n\nAll accounts require IAM access policies. To set up and manage IAM access policies, see [Defining IAM access policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-useruser).\n\nAccess to IBM Cloud Container Registry is either [automated](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_accessregistry_access_automating), which typically uses [API keys](https:\/\/cloud.ibm.com\/docs\/account?topic=account-manapikey), or [interactive](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_accessregistry_access_interactive), which typically uses bearer tokens.\n\nIf you have an IAM access policy, but you are getting Access denied errors, see [Why am I getting Access denied errors?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-access-denied) for assistance.\n\nIf you want to use your container images in Kubernetes deployments, see [Using an image pull secret to access images in other IBM Cloud accounts or external private registries from nondefault Kubernetes namespaces](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-registryother).\n\n\n\n Accessing your namespaces in automation \n\nYou can use service ID API keys to automate the pushing and pulling of container images to and from your namespaces.\n\nAPI keysare linked to user IDs or service IDs in your account and you can use them across IBM Cloud\u00ae. You can use an API key in the CLI or as part of automation to authenticate as your user or service identity. A [user API key](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_accessregistry_access_user_apikey_create) is associated with a user and their access policies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_access"},{"document_id":"ibmcld_05256-7-2204","score":20.4889392853,"text":"\nAccessing container registries \n\nImages that are used by IBM Cloud\u00ae Code Engine are typically stored in a registry that can either be accessible by the public (public registry) or set up with limited access for a small group of users (private registry).\n\nA container registry, or registry, is a service that stores container images. For example, IBM Cloud Container Registry and Docker Hub are container registries. A container registry can be public or private. A container registry that is public does not require credentials to access. In contrast, accessing a private registry does require credentials.\n\nCode Engine requires access to container registries to complete the following actions:\n\n\n\n* To retrieve (or \"pull\") a container image to run an app or job\n* To store a newly created container image as an output of an image build\n* To store and retrieve local files when a build is run from local source\n\n\n\nCode Engine handles many of the underlying details of the interactions between the system and your registry.\n\nTo pull images from a registry, Code Engine uses a special type of Kubernetes secret that is called an imagePullSecret. This image pull secret stores the credentials to access a container registry. When you add access to a container registry with Code Engine to pull images, you are creating an image pull secret. For more information about image pull secrets, see [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/home\/).\n\n\n\n Types of image registries \n\nImages are typically stored in a registry that can either be accessible by the public (public registry) or set up with limited access for a small group of users (private registry).\n\nPublic registries, such as public Docker Hub, can be used to get started with Docker and Code Engine to create your first application or job. But when it comes to enterprise workloads, use a private registry, such as the one provided in IBM Cloud Container Registry to protect your images from being used by unauthorized users. For private registries, use registry secrets to ensure that the credentials are available to gain access to the private registry.\n\n\n\nTable 1. Public and private image registry types\n\n Registry Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registry"},{"document_id":"ibmcld_05278-227004-228776","score":20.4448108673,"text":"\nFor example, IBM Cloud Container Registry and Docker Hub are container registries. A container registry can be public or private. A container registry that is public does not require credentials to access. In contrast, accessing a private registry does require credentials.\n\nYou must be within the context of a [project](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-project) before you use registry commands.\n\nFor more information about accessing registries, see [Adding access to a private container registry](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registry).\n\nTo see CLI help for the registry commands, run ibmcloud ce registry -h.\n\nBeginning with CLI version 1.42.0, defining and working with secrets in the CLI is unified under the secret command group. See [ibmcloud ce secret](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-secret-create) commands. Use the --format option to specify the category of secret, such as basic_auth, generic, ssh, tls, or registry. While you can continue to use the registry command group, take advantage of the unified secret command group. To create a secret to access a container registry, use the [ibmcloud ce secret create --format registry](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-secret-create) command. To learn more about working with secrets in Code Engine, see [Working with secrets](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret).\n\n\n\n ibmcloud ce registry create \n\nCreate an image registry access secret.\n\nibmcloud ce registry create --name NAME (--password PASSWORD | --password-from-file PASSWORD_FILE | --password-from-json-file) [--email EMAIL] [--output OUTPUT] [--quiet] [--server SERVER] [--username USERNAME]\n\n\n\n Command Options","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cli"},{"document_id":"ibmcld_01466-4298-5603","score":20.431646347,"text":"\nFor more information, see [Automating access to IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_access).\n\n\n\n\n\n\n\n Enforcing access to your account over a private network \n\nYou can prevent or allow image pulls or pushes over public network connections for your account by using the [ibmcloud cr private-only](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_private_only) command.\n\nYou can also use this command to check whether the use of private connections is set for your account.\n\nAfter you enable the use of private connections on your account, any attempts to pull and push images or access signatures over the public network are rejected.\n\nBecause the use of private connections doesn't apply to the management API, you can still use the CLI over a public connection.\n\n\n\n* To prevent image pulls or pushes over public network connections for your account, run the following command.\n\nibmcloud cr private-only --enable\n* To reinstate image pulls or pushes over public network connections for your account, run the following command.\n\nibmcloud cr private-only --disable\n* To check whether the use of public connections is prevented for image pushes or pulls in your account, run the following command.\n\nibmcloud cr private-only --status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_private"},{"document_id":"ibmcld_04335-195545-197316","score":20.4000053406,"text":"\nFor example, IBM Cloud Container Registry and Docker Hub are container registries. A container registry can be public or private. A container registry that is public does not require credentials to access. In contrast, accessing a private registry does require credentials.\n\nYou must be within the context of a [project](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-clicli-project) before you use registry commands.\n\nFor more information about accessing registries, see [Adding access to a private container registry](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registry).\n\nTo see CLI help for the registry commands, run ibmcloud ce registry -h.\n\nBeginning with CLI version 1.42.0, defining and working with secrets in the CLI is unified under the secret command group. See [ibmcloud ce secret](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-secret-create) commands. Use the --format option to specify the category of secret, such as basic_auth, generic, ssh, tls, or registry. While you can continue to use the registry command group, take advantage of the unified secret command group. To create a secret to access a container registry, use the [ibmcloud ce secret create --format registry](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-secret-create) command. To learn more about working with secrets in Code Engine, see [Working with secrets](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret).\n\n\n\n ibmcloud ce registry create \n\nCreate an image registry access secret.\n\nibmcloud ce registry create --name NAME (--password PASSWORD | --password-from-file PASSWORD_FILE | --password-from-json-file) [--email EMAIL] [--output OUTPUT] [--quiet] [--server SERVER] [--username USERNAME]\n\n\n\n Command Options \n\n-n, --name","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cli"}],"retriever_scores":{"recall_1":0.2,"recall_3":0.6,"recall_5":0.6,"recall_10":0.6,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":0.7227265726,"ndcg_cut_10":0.7227265726}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01388-7-1807","score":25.5409832001,"text":"\nGranting access to Container Registry resources tutorial \n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nAll accounts require IAM access policies. To set up and manage IAM access policies, see [Defining IAM access policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-useruser).\n\nFor more information about how to use IAM to manage access to your resources, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\n\n\n Before you begin \n\nBefore you begin, you must complete the following tasks:\n\n\n\n* Complete the instructions in [Getting started with IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started).\n* Ensure that you have the most recent version of the container-registry CLI plug-in for the IBM Cloud CLI, see [Updating the container-registry CLI plug-in](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_cli_update).\n* Ensure that you have access to two [IBM Cloud accounts](https:\/\/cloud.ibm.com\/login) that you can use for this tutorial, one for User A and one for User B, each must use a unique email address. You work in your own account, User A, and invite another user, User B, to use your account. You can choose to create a second IBM Cloud account, or you can work with a colleague that has an IBM Cloud account.\n* Ensure that you have the correct access permissions for adding and removingnamespaces, see [Access roles for configuring IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n\n\n Step 1: Authorize a user to configure the registry","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access"},{"document_id":"ibmcld_01377-13470-15034","score":24.9272117615,"text":"\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-13496-15060","score":24.9272117615,"text":"\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_05256-14584-16240","score":22.8467159271,"text":"\nIf you want to pull images from the shared account to your own account, then you must be [authorized to access IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registryauthorities-registry).\n\n\n\n\n\n Accessing images in a different account \n\nYou can assign IBM Cloud IAM access policies to users or a service ID to restrict permissions to specific registry image namespaces or actions (such as push or pull). Then, create an API key and store these registry credentials in Code Engine.\n\nFor example, to access images in other IBM Cloud accounts, [create an API key](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registryimages-your-account-api-key) that stores the IBM Cloud Container Registry credentials of a user or service ID in that account. Then, in Code Engine, use that key to [create access](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registryadd-registry-access-ce) in your account.\n\n\n\n\n\n Accessing images in a private Docker Hub account \n\nTo access images in a private Docker Hub account, create registry access by providing your password or an access token. By using an access token, you can more easily grant and revoke access to your Docker Hub account without requiring a password change. For more information about access tokens and Docker Hub, see [Managing access tokens](https:\/\/docs.docker.com\/docker-hub\/access-tokens\/).\n\nAfter you decide whether to use your password directly or to create an access token, [create your registry access](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registryadd-registry-access-ce).\n\n\n\n\n\n Add registry access to Code Engine","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registry"},{"document_id":"ibmcld_05256-7-2204","score":22.2592201233,"text":"\nAccessing container registries \n\nImages that are used by IBM Cloud\u00ae Code Engine are typically stored in a registry that can either be accessible by the public (public registry) or set up with limited access for a small group of users (private registry).\n\nA container registry, or registry, is a service that stores container images. For example, IBM Cloud Container Registry and Docker Hub are container registries. A container registry can be public or private. A container registry that is public does not require credentials to access. In contrast, accessing a private registry does require credentials.\n\nCode Engine requires access to container registries to complete the following actions:\n\n\n\n* To retrieve (or \"pull\") a container image to run an app or job\n* To store a newly created container image as an output of an image build\n* To store and retrieve local files when a build is run from local source\n\n\n\nCode Engine handles many of the underlying details of the interactions between the system and your registry.\n\nTo pull images from a registry, Code Engine uses a special type of Kubernetes secret that is called an imagePullSecret. This image pull secret stores the credentials to access a container registry. When you add access to a container registry with Code Engine to pull images, you are creating an image pull secret. For more information about image pull secrets, see [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/home\/).\n\n\n\n Types of image registries \n\nImages are typically stored in a registry that can either be accessible by the public (public registry) or set up with limited access for a small group of users (private registry).\n\nPublic registries, such as public Docker Hub, can be used to get started with Docker and Code Engine to create your first application or job. But when it comes to enterprise workloads, use a private registry, such as the one provided in IBM Cloud Container Registry to protect your images from being used by unauthorized users. For private registries, use registry secrets to ensure that the credentials are available to gain access to the private registry.\n\n\n\nTable 1. Public and private image registry types\n\n Registry Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registry"},{"document_id":"ibmcld_05256-20669-22477","score":22.2363891602,"text":"\nFor Container Registry, the server name is <region>.icr.io. For example, us.icr.io. For [Docker Hub](https:\/\/hub.docker.com\/), the value is https:\/\/index.docker.io\/v1\/. \n --username Enter the username to access the registry server. For Container Registry, it is iamapikey. For Docker Hub, it is your Docker ID. \n --password Enter the password. For Container Registry, the password is your API key. For Docker Hub, you can use your Docker Hub password or an [access token](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registryaccess-private-docker-hub). \n\n\n\n\n\n\n\n\n\n Authorizing access to Container Registry with service ID \n\nBefore you can add access to a service ID in a different account, you must first authorize access to the service ID.\n\nWhen you create a service ID, you can restrict access to a regional IBM Cloud Container Registry or even a specific namespace within that IBM Cloud Container Registry account.\n\n\n\n Authorizing access to Container Registry with service ID from the console \n\nTo pull or push images from or to IBM Cloud Container Registry, you must create a service ID, create an access policy for the service ID, and then create an API key to store the credentials.\n\n\n\n Step 1 Create or identify a service ID and authorize it to the IBM Cloud Container Registry service \n\n\n\n1. Launch [Access (IAM) Overview](https:\/\/cloud.ibm.com\/iam\/overview).\n2. Select Service IDs.\n3. If you have a Service ID that you want to use, select it. If not, select Create, enter a name and description, and click Create.\n4. From the Service ID page, from the Access policies section, select Assign access.\n5. From the Assign service ID additional access section,\n\n\n\n1. Select Container Registry for type of access. Click Next.\n2. Select the type of access: All resources or Specific resources.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-add-registry"},{"document_id":"ibmcld_01377-8075-10005","score":22.0236549377,"text":"\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-8101-10031","score":22.0236549377,"text":"\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_01377-4-1879","score":21.983537674,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Managing IAM access for Container Registry \n\nAccess to IBM Cloud\u00ae Container Registry for users in your account is controlled by IBM Cloud\u00ae Identity and Access Management (IAM).\n\nEvery user that accesses the IBM Cloud Container Registry service in your account must be assigned an IAM\n\naccess policywith an IAM role. A user can also be a member of an [access group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-groups) with assigned IAM access policies that grant an IAM role. Review the following roles, actions, and more to help determine the best way to assign access to Container Registry.\n\nFor more information about IAM, see [How IBM Cloud Identity and Access Management works](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamoverviewiamoverview).\n\nTry out the tutorial [Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access).\n\n\n\n Access policies \n\nThe IAM access policy that you assign to users in your account determines the actions that a user can perform within the context of the service or specific instance that you select. The allowable actions are customized and defined by Container Registry as operations that are allowed to be performed on the service. Each action is mapped to an [IAM platform or service role](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles) that you can assign to a user.\n\nPolicies enable access to be granted at different levels. Some options include the following access levels:\n\n\n\n* Access to the service in your account\n* Access to a specific resource within the service\n* Access to all IAM-enabled services in your account\n* Access to resources within a resource group\n\n\n\nIf you want to restrict user access to one or more\n\nnamespacesfor an ID that you are using for automation, use an IAM service ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-4-1879","score":21.983537674,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Managing IAM access for Container Registry \n\nAccess to IBM Cloud\u00ae Container Registry for users in your account is controlled by IBM Cloud\u00ae Identity and Access Management (IAM).\n\nEvery user that accesses the IBM Cloud Container Registry service in your account must be assigned an IAM\n\naccess policywith an IAM role. A user can also be a member of an [access group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-groups) with assigned IAM access policies that grant an IAM role. Review the following roles, actions, and more to help determine the best way to assign access to Container Registry.\n\nFor more information about IAM, see [How IBM Cloud Identity and Access Management works](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamoverviewiamoverview).\n\nTry out the tutorial [Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access).\n\n\n\n Access policies \n\nThe IAM access policy that you assign to users in your account determines the actions that a user can perform within the context of the service or specific instance that you select. The allowable actions are customized and defined by Container Registry as operations that are allowed to be performed on the service. Each action is mapped to an [IAM platform or service role](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles) that you can assign to a user.\n\nPolicies enable access to be granted at different levels. Some options include the following access levels:\n\n\n\n* Access to the service in your account\n* Access to a specific resource within the service\n* Access to all IAM-enabled services in your account\n* Access to resources within a resource group\n\n\n\nIf you want to restrict user access to one or more\n\nnamespacesfor an ID that you are using for automation, use an IAM service ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10863-1737-3164","score":16.5479030609,"text":"\nFor more information about namespaces, see [Managing namespaces](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespaces).\n\n\n\n Step 1: Create the cos-access actioncos-access action \n\nThe cos-access action is a Node.js program that simulates code to access IBM Cloud Object Storage by setting a timeout that resolves after 10 seconds.\n\n\n\n1. Go to the [Create page](https:\/\/cloud.ibm.com\/functions\/create) in the Cloud Functions console.\n2. Select Action.\n3. Create the cos-access action:\n\n\n\n1. Name your action cos-access.\n2. Click Create Package. Name your package action-tutorial and click Create.\n3. Select Node.js 10 for the runtime.\n4. Click Create.\n5. Paste in the following code example:\n\n\/\n* main() will be run when you invoke this action\n* @param Cloud Functions actions accept a single parameter, which must be a JSON object.\n* @return The output of this action, which must be a JSON object.\n\/\nfunction main(params) {\nreturn new Promise((resolve, reject) => {\n\/\/ simulate a COS access by resolving after 10s\nsetTimeout(() => {\nconsole.log('fake COS bucket access done. Resolving Promise...');\nresolve({ cos_message: 'SUCCESS'});\n}, 10000);\n});\n}\nShow more\n6. Click Save.\n7. Test your action by clicking Invoke and waiting for the following output to display.\n\nExample output\n\nResults:\n{\n\"cos_message\": \"SUCCESS\"\n}\n\nLogs:\n[\n\"2020-04-21T01:51:49.464941Z stdout: fake COS bucket access done. Resolving Promise...\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_10805-8395-9992","score":15.7883119583,"text":"\nBefore you can create entities in the namespace, you must set your CLI context to the namespace by targeting it.\n\nibmcloud fn property set --namespace <namespace_name_or_id>\n\n\n\nAfter you set a property, such as the --namespace property, it is retained until you manually unset it. If you want to switch between IAM namespaces or between Cloud Foundry and IAM namespaces, you must unset the namespace property and then reset it. For more information, see [ibmcloud fn property set](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_prop_set).\n\n\n\n\n\n Creating a namespace with the API \n\nCreate your IAM-managed namespace with the API.\n\n\n\n1. Create an IAM-enabled namespace.\n\ncurl --request POST --url 'https:\/\/jp-tok.functions.cloud.ibm.com\/api\/v1\/namespaces' --header 'accept: application\/json' --header 'authorization: <IAM_token>' --data '{\"description\":\"string\",\"name\":\"string\",\"resource_group_id\":\"string\",\"resource_plan_id\":\"string\"}'\n\n| <IAM_token> | Your IBM Cloud Identity and Access Management (IAM) token. To retrieve your IAM token, run ibmcloud iam oauth-tokens. | | -n <name> | The name of the namespace. | | -n <resource_group_id> | The ID of the resource group that you want to create the namespace in. To see resource group IDs, run ibmcloud resource groups. | | -n <resource_plan_id> | The ID of the resource plan, such as functions-base-plan | | -n <description> | Optional: Add a description to the namespace, such as which kind of actions or packages it will contain. |\n\nThe following example shows sample output from the previous command.\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespaces"},{"document_id":"ibmcld_01329-7038-8813","score":15.7867574692,"text":"\nTo set a namespace, repository, digest, or tag as the scope, enter the value in one of the following formats:\n\n\n\n* namespace\n* namespace\/repository\n* namespace\/repository:tag\n* namespace\/repository@digest\n\n\n\n\n\n\n\n Examples \n\nList all your exemptions for security issues that apply to images in the birds\/bluebird repository. The output includes exemptions that are account-wide, exemptions that are scoped to the birds namespace, and exemptions that are scoped to the birds\/bluebird repository. The output doesn't include any exemptions that are scoped to specific tags within the birds\/bluebird repository.\n\nibmcloud cr exemption-list --scope birds\/bluebird\n\nList all your exemptions for security issues that apply to images in the birds\/bluebird@sha256:101010101010 digest. The output includes exemptions that are account-wide, exemptions that are scoped to the birds namespace, and exemptions that are scoped to the birds\/bluebird repository and to the birds\/bluebird@sha256:101010101010 digest. The output doesn't include any exemptions that are scoped to specific tags within the birds\/bluebird repository.\n\nibmcloud cr exemption-list --scope birds\/bluebird@sha256:101010101010\n\n\n\n\n\n\n\n ibmcloud cr exemption-rm \n\nDelete an exemption for a security issue. To view your existing exemptions, run ibmcloud cr exemption-list.\n\nYou can identify the images in the scope by using either the [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) or the [digest](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_digest). You can reference the image by digest <dns>\/<namespace>\/<repo>@<digest>, which affects the digest and all its tags in the same repository, or by tag <dns>\/<namespace>\/<repo>:<tag>.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_05647-11842-13275","score":15.7733478546,"text":"\napiVersion: v1\nkind: ConfigMap\nmetadata:\nname: tcp-services\nnamespace: kube-system\ndata:\n9000: \"<namespace>\/<service>:8080\"\n2. Create the ConfigMap in the kube-system namespace.\n\nkubectl apply -f tcp-services.yaml -n kube-system\n3. Specify the tcp-services ConfigMap as a field in the [ibm-ingress-deploy-config ConfigMap](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-comm-ingress-annotationscomm-customize-deploy).\n\n\"tcpServicesConfig\":\"kube-system\/tcp-services\"\n4. [Modify each ALB service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-comm-ingress-annotationscomm-customize-deploy) to add the ports.\n\n\n\n\n\n\n\n Setting a maximum number of upstream keepalive requests \n\nTo set the maximum number of requests that can be served through one keepalive connection, use the following Kubernetes ibm-k8s-controller-config ConfigMap [field](https:\/\/kubernetes.github.io\/ingress-nginx\/user-guide\/nginx-configuration\/configmap\/upstream-keepalive-requests).\n\nupstream-keepalive-requests: 32\n\n\n\n\n\n Setting the maximum upstream keepalive timeout \n\nTo set the maximum time that a keepalive connection stays open between the ALB proxy server and your app's upstream server, use the following Kubernetes ibm-k8s-controller-config configmap [field](https:\/\/kubernetes.github.io\/ingress-nginx\/user-guide\/nginx-configuration\/configmap\/upstream-keepalive-timeout).\n\nupstream-keepalive-timeout: 32\n\n\n\n\n\n Customizing the ALB deployment","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-comm-ingress-annotations"},{"document_id":"ibmcld_10817-9033-10456","score":15.7515916824,"text":"\n* qName = \"mypackage\/foo\" results in namespace = default, package = mypackage, action\/trigger = \"foo\"\n* qName = \"\/mynamespace\/foo\" results in namespace = mynamespace, package = default, action\/trigger = \"foo\"\n* qName = \"\/mynamespace\/mypackage\/foo\" results in namespace = mynamespace, package = mypackage, action\/trigger = \"foo\"\n\n\n\nAll other combinations issue a WhiskError.QualifiedName error. Therefore, when you are using qualified names, you must wrap the call in a \"do\/try\/catch\" construct.\n\n\n\n\n\n Invoking actions with mobile SDK from WhiskButton \n\nFor convenience, the SDK includes a WhiskButton, which extends the UIButton to allow it to invoke actions. To use the WhiskButton, follow this example:\n\nvar whiskButton = WhiskButton(frame: CGRectMake(0,0,20,20))\nwhiskButton.setupWhiskAction(\"helloConsole\", package: \"mypackage\", namespace: \"_\", credentials: credentialsConfiguration!, hasResult: false, parameters: nil, urlSession: nil)\nlet myParams = [\"name\":\"value\"]\n\/\/ Call this when you detect a press event, e.g. in an IBAction, to invoke the action\nwhiskButton.invokeAction(parameters: myParams, callback: { reply, error in\nif let error = error {\nprint(\"Oh no, error: (error)\")\n} else {\nprint(\"Success: (reply)\")\n}\n})\n\/\/ or alternatively you can set up a \"self contained\" button that listens for press events on itself and invokes an action\nvar whiskButtonSelfContained = WhiskButton(frame: CGRectMake(0,0,20,20))","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_11870-6448-8449","score":15.5726013184,"text":"\nDefine the namespace that you want your resources to be deployed to. This must be an existing namespace.\n3. Specify the branch to deploy the resource to; for example, v1.\n4. Provide the path to deploy the resource to; for example, deployments.\n5. Select the cluster group to receive the resources that you are deploying.\n6. Provide the displayed name of the Satellite configuration.\n7. Click Continue.\n\n\n\n\n\n\n\n Step 7: Reviewing the summary \n\nReview the summary and confirm to create your toolchain.\n\n\n\n* To change any parameters you provided earlier, click Back.\n* To create the toolchain with the provided parameters, click Create toolchain.\n\n\n\n\n\n\n\n Step 8: Testing the toolchain \n\nWhen the toolchain is created, the toolchain Overview page is displayed. On this page, you can view the repositories, pipelines, and any IBM Cloud tools that are associated with this toolchain.\n\nUnder Repositories is your source repository as well as additional repositories for your Tekton catalog and pipeline tasks. If you are comfortable with using Tekton, you can go to these Tekton repositories to make changes to your toolchain.\n\nUnder Delivery pipelines, you can see the status of your pipeline runs. You can click the name of the pipeline to see details about your pipeline and set From this pipeline overview, you can set the triggers for your pipeline. Triggers define when the pipeline starts.\n\nYou can start the delivery pipeline in either of the following ways.\n\n\n\n* Trigger the delivery pipeline manually by setting a manual trigger.\n* Push a commit to the deployment source repo as defined by a Git repository trigger. To set a Git repository trigger, see [Deploying a new version of your app from a different branch](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat_toolchain_tutorialmodify_trigger).\n\n\n\nTo start a manual pipeline run, follow these steps.\n\n\n\n1. On the Overview of your toolchain under Delivery pipelines, select the delivery pipeline to view its status.\n2. Click Run pipeline.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat_toolchain_tutorial"},{"document_id":"ibmcld_04348-31498-33084","score":15.3727378845,"text":"\n--namespaceNAMESPACE\n: An IAM namespace name or ID. This flag cannot be set for Cloud Foundry namespaces. This flag is optional.\n\n\n\n\n\n Example \n\nibmcloud fn property set --namespace myNamespace\n\nOutput\n\nok: whisk namespace set to myNamespace\n\n\n\n\n\n\n\n ibmcloud fn property unset \n\nUnset a property for the wsk CLI. At least one flag is required.\n\nIf properties are retained after running the property unset command, you can delete the config.json file located at <home_dir>\/.bluemix\/plugins\/cloud-functions\/config.json to remove all properties.\n\nibmcloud fn property unset [--apihost HOST] [--apiversion VERSION] [--auth KEY] [--cert STRING] [--key STRING] [--namespace NAMESPACE]\n\n\n\n Command options \n\n--apihostHOST\n: The wsk API host. This flag is optional.\n\n--apiversionVERSION\n: The wsk API version. This flag is optional.\n\n--authKEY, -u\n: The wsk authorization KEY. This flag is optional.\n\n--certSTRING\n: The wsk client certificate. This flag is optional.\n\n--keySTRING\n: The wsk client KEY. This flag is optional.\n\n--namespaceNAMESPACE\n: An IAM namespace name or ID. This flag cannot be set for Cloud Foundry namespaces. This flag is optional.\n\n\n\n\n\n Example \n\nibmcloud fn property unset --namespace\n\n\n\n\n\n\n\n\n\n Rule commands \n\nCreate, delete, enable, disable, update, and find information about rules.\n\nTo see CLI help for the rule command, run ibmcloud fn rule.\n\n\n\n ibmcloud fn rule create \n\nCreate a rule to associate a trigger with an action. Before you can create a rule, create a trigger and an action first.\n\nibmcloud fn rule create RULE_NAME TRIGGER_NAME ACTION_NAME\n\n\n\n Example","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-functions-cli"},{"document_id":"ibmcld_10850-1823-2660","score":15.359796524,"text":"\nFor more information about namespaces, see [Managing namespaces](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespaces).\n\n\n\n1. Go to the [Create page](https:\/\/cloud.ibm.com\/functions\/create) in the Cloud Functions console.\n2. Click Create Sequence.\n3. Specify a name, package, and initial action for your sequence. You can choose existing actions that are available in your namespace or else select a public action. Click Create.\n4. Add one or more actions to your sequence and Save.\n5. You can test your code by clicking Invoke.\n\n\n\n\n\n\n\n Creating a sequence from the CLI \n\nCreate a sequence from the CLI with the [ibmcloud fn action create](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_action_create) command.\n\nibmcloud fn action create <sequence_name> --sequence <action_1>,<action_2>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sequences"},{"document_id":"ibmcld_01447-21046-23163","score":15.3382062912,"text":"\nThe namespace must be unique across all IBM Cloud accounts in the same region. Every user in your IBM Cloud account can view and work with images that are stored in your registry namespace.\n\nYou can have 100 namespaces in each region.\n\nNamespaces are created in a [resource group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgs) that you specify so that you can configure access to resources within the namespace at the resource group level. If you don't specify a resource group, and a resource group isn't targeted, the default resource group is used. If you have an older namespace that is not in a resource group, you can assign it to a resource group and then set permissions for that namespace at the resource group level. For more information about resource groups, see [Assigning existing namespaces to resource groups](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_assign).\n\nNamespaces that are assigned to a resource group show in the Resource list page of the IBM Cloud console.\n\n\n\n\n\n Repository \n\nA collection of related container images in the container registry that are distinguished by tag or digest only.\n\nRepository is often used interchangeably with container image, but a repository potentially holds multiple tagged variants of a container image.\n\nA repository stores container images, and is itself stored in a registry namespace.\n\n\n\n\n\n Tag \n\nAn identifier that is attached to container images within a repository. Tags can be reassigned or deleted from images.\n\nYou can use\n\ntagsto distinguish different versions of the same base image within a repository. When you run a Docker command and do not specify the tag of a repository image, then the image tagged latest is used by default.\n\n\n\n\n\n Untagged image \n\nAn image that has no\n\ntagis an untagged image. Images that are untagged can be referenced by using the digest reference format <repository>@<digest> as opposed to the tag reference format <repository>:<tag>. Untagged images are typically the result of an image that is pushed with a pre-existing <repository>:<tag> combination.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"},{"document_id":"ibmcld_01484-4131-5923","score":15.3218336105,"text":"\nFor more information about resource groups, see [Assigning existing namespaces to resource groups](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_assign).\n\nNamespaces that are assigned to a resource group show in the Resource list page of the IBM Cloud console.\n\nYou can set up multiple namespaces, for example, to have separate repositories for your production and staging environments. If you want to use the registry in multiple IBM Cloud regions, you must set up a namespace for each region. Namespace names are unique within regions. You can use the same namespace name for each region, unless someone else already has a namespace with that name in that region.\n\nYou can have 100 namespaces in each region.\n\nTo work with the IBM-provided public images only, you do not need to set up a namespace.\n\nIf you're unsure whether a namespace is already set for your account, run the ibmcloud cr namespace-list command with the -v option to retrieve existing namespace information.\n\nConsider the following rules when you choose a namespace:\n\n\n\n* Your namespace must be unique across all IBM Cloud accounts in the same region.\n* Your namespace must have 4 - 30 characters.\n* Your namespace must start and end with a letter or number.\n* Your namespace must contain lowercase letters, numbers, hyphens (-), and underscores (_) only.\n\n\n\nDo not put personal information in your namespace names.\n\nAfter you set your first namespace, you are assigned to the free IBM Cloud Container Registry service plan unless you [upgrade your plan](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_plan_upgrade).\n\n\n\n User permissions for working with namespaces \n\nYou can control which users can work with namespaces by using IAM roles.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespace&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1356519734}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05597-10227-11923","score":27.6754455566,"text":"\nIf the cluster master runs two or more versions behind the oldest supported version, you can no longer apply updates and must delete the cluster and create a new one.\n5. Archived: The version is unsupported with no upgrade path. IBM provides no support. IBM reserves the right to shut down the control planes for such clusters.\n\n\n\nIf you wait until your cluster is two or more minor versions behind the oldest supported version, you can't update the cluster. Instead, [create a new cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clustersclusters), [deploy your apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-appapp) to the new cluster, and [delete](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-remove) the unsupported cluster. To avoid this issue, update deprecated clusters to a supported version that is one or two behind the current version, such as 1.21 or 1.22 and then update to the latest version, 1.23. If the worker nodes run a version two or more behind the master, you might see your pods fail by entering a state such as MatchNodeSelector, CrashLoopBackOff, or ContainerCreating until you update the worker nodes to the same version as the master. After you update from a deprecated to a supported version, your cluster can resume normal operations and continue receiving support. You can find out whether your cluster is unsupported by reviewing the State field in the output of the ibmcloud ks cluster ls command or in the [IBM Cloud Kubernetes Service console](https:\/\/cloud.ibm.com\/kubernetes\/clusters).\n\n\n\n\n\n Preparing to update \n\nUpdating a cluster to a new version from the previous version is likely to have an impact on deployed apps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog"},{"document_id":"ibmcld_05728-10229-11925","score":27.6754455566,"text":"\nIf the cluster master runs two or more versions behind the oldest supported version, you can no longer apply updates and must delete the cluster and create a new one.\n5. Archived: The version is unsupported with no upgrade path. IBM provides no support. IBM reserves the right to shut down the control planes for such clusters.\n\n\n\nIf you wait until your cluster is two or more minor versions behind the oldest supported version, you can't update the cluster. Instead, [create a new cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clustersclusters), [deploy your apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-appapp) to the new cluster, and [delete](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-remove) the unsupported cluster. To avoid this issue, update deprecated clusters to a supported version that is one or two behind the current version, such as 1.21 or 1.22 and then update to the latest version, 1.23. If the worker nodes run a version two or more behind the master, you might see your pods fail by entering a state such as MatchNodeSelector, CrashLoopBackOff, or ContainerCreating until you update the worker nodes to the same version as the master. After you update from a deprecated to a supported version, your cluster can resume normal operations and continue receiving support. You can find out whether your cluster is unsupported by reviewing the State field in the output of the ibmcloud ks cluster ls command or in the [IBM Cloud Kubernetes Service console](https:\/\/cloud.ibm.com\/kubernetes\/clusters).\n\n\n\n\n\n Preparing to update \n\nUpdating a cluster to a new version from the previous version is likely to have an impact on deployed apps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions"},{"document_id":"ibmcld_05754-3185-5238","score":27.6560058594,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_master"},{"document_id":"ibmcld_10189-3187-5240","score":27.4159240723,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_master"},{"document_id":"ibmcld_06209-2829-4687","score":26.7128944397,"text":"\nIn any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) for any potential impact and choose to safely use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n![Master update process diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/\/images\/updating-master2.svg)\n\nFigure 1. Updating Kubernetes master process diagram\n\n\n\n\n\n Steps to update the cluster master \n\nBefore you begin, make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\nTo update the Kubernetes master major or minor version:\n\n\n\n1. Review the [Kubernetes changes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) and make any updates marked Update before master.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_05838-12220-14151","score":26.7114067078,"text":"\nYou can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitor"},{"document_id":"ibmcld_06209-1393-3390","score":26.6816673279,"text":"\nIf your cluster runs an unsupported Kubernetes version, follow the [version archive instructions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsk8s_version_archive). To avoid getting in an unsupported state and operational impact, keep your cluster up-to-date.\n\nCan my worker nodes run a later version than the master?\n: Your worker nodes can't run a later major.minor Kubernetes version than the master. Additionally, your worker nodes can be only up to two versions behind the master version (n-2). First, [update your master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate_master) to the latest Kubernetes version. Then, [update the worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) for any potential impact and choose to safely use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10246-15672-17685","score":26.6223659515,"text":"\nDuring the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n\n\n Disabling remote health reporting \n\nOpenShift Container Platform collects anonymized health reports about your cluster through a [telemetry component that is enabled by default](https:\/\/docs.openshift.com\/container-platform\/4.11\/support\/remote_health_monitoring\/about-remote-health-monitoring.html) in your Red Hat OpenShift on IBM Cloud cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-monitor"},{"document_id":"ibmcld_10642-1365-3347","score":26.2807312012,"text":"\nThen, [update the worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) for any potential impact and choose to safely use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_05838-13761-15409","score":26.2041244507,"text":"\nupdate_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n\n\n Setting up IBM Cloud\u00ae Monitoring alerts \n\nWhen you set up alerts, make sure to allow your cluster enough time to self-heal. Because Kubernetes has self healing capabilities, configure your alerts only for the issues that arise over time. By observing your cluster over time, you can learn which issues Kubernetes can resolve itself and which issues require alerts to avoid downtime.\n\nOn 15 June 2022, the naming convention for IBM Cloud\u00ae Monitoring alerts is changing to a Prometheus compatible format.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitor"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05608-1309-3624","score":24.2841720581,"text":"\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.\n\n\n\n What does the benchmark cover? \n\nThe benchmark covers recommendations for master components, etcd, control plane configurations, worker nodes, and policies such as for users, network, and pod security.\n\n\n\n\n\n What do the benchmark recommendations mean? \n\nThe benchmark recommendations have scoring, levels, result status, and responsibilities as follows.\n\n\n\n* Scoring\n\n\n\n* Scored: The overall benchmark score increases or decreases depending on whether the recommendation is met.\n* Not scored: The overall benchmark score is not impacted, whether the recommendation is met.\n\n\n\n* Levels\n\n\n\n* Level 1: Practical security measures that can be configured without inhibiting the service.\n* Level 2: More in-depth security measures that might reduce the performance or functionality of a service.\n\n\n\n* Result\n\n\n\n* Pass: The service complies with the benchmark recommendation.\n* Fail: The service does not comply with the benchmark recommendation by default. Refer to the remediation section for an explanation and possible actions that you can take to comply with the benchmark recommendation.\n\n\n\n* Responsibility\n\n\n\n* IBM: IBM is responsible for configuring the setting that the benchmark recommends.\n* Shared: You and IBM share responsibility for configuring the setting that the benchmark recommends.\n\n\n\n\n\n\n\n\n\n What parts of the benchmark am I responsible for? \n\nBecause IBM Cloud Kubernetes Service is a managed offering, IBM already configures many security settings for you. For example, IBM manages and automatically applies updates to your cluster master. For your worker nodes, IBM provides security and version updates, but you must apply the updates. You are also responsible for your workload applications and data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_05612-7-1934","score":23.7599925995,"text":"\nVersion 1.21 CIS Kubernetes benchmark \n\nKubernetes version 1.21 becomes unsupported on 14 September 2022. Update your cluster to at least [version 1.22](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_122) as soon as possible.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.21. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-121"},{"document_id":"ibmcld_06063-6174-8378","score":23.6793289185,"text":"\n* Konnectivity: IBM Cloud Kubernetes Service-specific component to provide secured network connectivity for all Kubernetes master to worker node communication. The Konnectivity server works with the Konnectivity agent to securely connect the master to the worker node. This connection supports apiserver proxy requests to your pods and services, and kubectl top, exec, attach, and logs requests to the kubelet. The connection from the worker nodes to the master is automatically secured with TLS certificates.\n\n\n\nContinuous monitoring by IBM Site Reliability Engineers (SREs)\n: The Kubernetes master, including all the master components, compute, networking, and storage resources are continuously monitored by IBM Site Reliability Engineers (SREs). The SREs apply the latest security standards, detect and remediate malicious activities, and work to ensure reliability and availability of IBM Cloud Kubernetes Service.\n\nCIS Kubernetes master benchmark\n: To configure IBM Cloud Kubernetes Service, IBM engineers follow relevant cybersecurity practices from the Kubernetes master benchmark that is published by the [Center of Internet Security (CIS)](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/). The cluster master and all worker nodes are deployed with images that meet the benchmark.\n\nSecure communication via TLS\n: To use IBM Cloud Kubernetes Service, you must authenticate with the service by using your credentials. When you are authenticated, IBM Cloud Kubernetes Service generates TLS certificates that encrypt the communication to and from the Kubernetes API server and etcd data store to ensure a secure end-to-end communication between the worker nodes and the Kubernetes master. These certificates are never shared across clusters or across Kubernetes master components.\n\nNeed to revoke existing certificates and create new certificates for your cluster? Check out [Rotating CA certificates in your cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitycert-rotate).\n\nConnectivity to worker nodes\n: Although Kubernetes secures the communication between the master and worker nodes by using the https protocol, no authentication is provided on the worker node by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_05653-144428-146015","score":23.0769081116,"text":"\nKubernetes benchmarks\n: Added how to [run the CIS Kubernetes benchmark tests on your own worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkcis-worker-test).\n\nRemoval of data center support\n: Updated the documentation to reflect that Melbourne (mel01) is no longer available as an option to create IBM Cloud resources in.\n\n\n\n\n\n 7 January 2021 \n\nIngress ALB change log\n: Updated the latest [Kubernetes Ingress image build to 0.35.0_869_iks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-add-ons-changelog0_35_0).\n\n\n\n\n\n 6 January 2021 \n\nMaster versions\n: Master fix pack update change log documentation is available.\n: [1.19.6_1531](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_1191196_1531), [1.18.14_1537](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-118_changelog11814_1537), [1.17.16_1550](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-117_changelog11716_1550), and [1.16.15_1556](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-116_changelog11615_1556).\n\n\n\n\n\n\n\n December 2020 \n\n\n\n 21 December 2020 \n\nGateway firewalls and Calico policies\n: For classic clusters in Tokyo, updated the IBM Cloud Kubernetes Service IP addresses that you must open in a [public gateway firewall device](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-firewallfirewall_outbound) or [Calico network isolation policies](https:\/\/github.com\/IBM-Cloud\/kube-samples\/tree\/master\/calico-policies\/public-network-isolation).\n\nWorker node versions\n: Worker node fix pack update change log documentation is available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-containers-relnotes"},{"document_id":"ibmcld_05608-3099-5358","score":22.7478027344,"text":"\n* Shared: You and IBM share responsibility for configuring the setting that the benchmark recommends.\n\n\n\n\n\n\n\n\n\n What parts of the benchmark am I responsible for? \n\nBecause IBM Cloud Kubernetes Service is a managed offering, IBM already configures many security settings for you. For example, IBM manages and automatically applies updates to your cluster master. For your worker nodes, IBM provides security and version updates, but you must apply the updates. You are also responsible for your workload applications and data. For more information, see [Your responsibilities while using IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks).\n\n\n\n\n\n What if some part of the service fails to comply with a recommendation? \n\nFirst, check the explanation of the failure for any remediation steps.\n\nThen, determine whether the failure is acceptable according to your security requirements. For example, some recommendations might be more in-depth configuration requirements than your particular processes or standards require. Also, some recommendations are not scored, and don't impact the overall benchmark score.\n\nNext, decide whether the component falls within your responsibility. If so, you might need to change how you configure that component. For example, you might configure pod security policies for all your app deployments. For components that are not directly within your responsibility, assess whether you can use another IBM Cloud service to meet the recommendation.\n\n\n\n\n\n What else can I do to increase the security and compliance of my cluster? \n\nSee [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security).\n\n\n\n\n\n\n\n Running the worker node CIS Kubernetes benchmark \n\nTo review the results of the CIS Kubernetes benchmark for Section 4: Worker node security configuration, you can run the test yourself. Because you own the worker nodes and are partially [responsible](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks) for their compliance, you might make configuration changes that you want to validate on your own.\n\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_05615-7-1945","score":22.6824455261,"text":"\nVersion 1.24 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.24. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124"},{"document_id":"ibmcld_05614-7-1955","score":22.6674022675,"text":"\nVersion 1.23 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.23. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123"},{"document_id":"ibmcld_05616-7-1945","score":22.6620540619,"text":"\nVersion 1.25 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.25. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125"},{"document_id":"ibmcld_05617-7-2046","score":22.6366615295,"text":"\nVersion 1.26 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.26. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive Not Scored 1 Pass IBM \n 1.1.10 Ensure that the Container Network Interface file ownership is set to root:root Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-126"},{"document_id":"ibmcld_05613-7-1955","score":22.6306781769,"text":"\nVersion 1.22 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.22. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-122"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06090-3328-5351","score":25.6286087036,"text":"\nYour service might not yet support private cloud service endpoints. If you have a private-only cluster, you must use service credentials that use the private cloud service endpoint, or open up the public IP address and port to connect to your service.\n\n\n\n\n\n Can I use all IBM Cloud services in my cluster? \n\nYou can use service binding only for services that support service keys so that the service credentials can automatically be created and stored in a Kubernetes secret. To find a list of services that support service keys, see [Enabling external apps to use IBM Cloud services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-externalappexternalapp).\n\nServices that don't support service keys usually provide an API that you can use in your app. The service binding method does not automatically set up API access for your app. Make sure to review the API documentation of your service and implement the API interface in your app.\n\n\n\n\n\n Can I bind multiple IBM Cloud services to multiple clusters at once? \n\nIBM Cloud service binding is on a per-cluster, per-service basis, and works by creating a Kubernetes secret that your pods can mount.\n\nFor multiple clusters and services, you can [use IAM trusted profiles instead](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-iam-identity). In IAM, you create a trusted profile with access policies for the IBM Cloud services that you want. Then, you link the trusted profile with as many clusters as you want, based on conditions such as all the prod Kubernetes namespaces in clusters in a resource group. Finally, your pods mount the Kubernetes service account projected volume to get a token that can be exchanged for an IAM token that your apps use to authenticate with the IBM Cloud services.\n\n\n\n\n\n\n\n Adding IBM Cloud services to clusters \n\nUse IBM Cloud service binding to automatically create service credentials for your IBM Cloud services and store these credentials in a Kubernetes secret.\n\nBefore you begin:\n\n\n\n* Ensure you have the following roles:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-binding"},{"document_id":"ibmcld_07578-373434-375500","score":25.583398819,"text":"\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-373408-375474","score":25.583398819,"text":"\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05777-1455-3483","score":25.5597572327,"text":"\nYour worker nodes are controlled by a highly available Kubernetes master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov).\n\n\n\n\n\n Why should I use IBM Cloud Kubernetes Service? \n\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n\n\n\n\n\n Can I get a free cluster? \n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_16727-390939-393066","score":25.1637058258,"text":"\nTo view detailed system requirements, you can run a [software product compatibility report for IBM Cloud Kubernetes Service](https:\/\/www.ibm.com\/software\/reports\/compatibility\/clarity\/softwareReqsForProduct.html). Note that compliance depends on the underlying [infrastructure provider](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers) for the cluster worker nodes, networking, and storage resources.\n\nClassic infrastructure: IBM Cloud Kubernetes Service implements controls commensurate with the following security standards:\n\n\n\n* EU-US Privacy Shield and Swiss-US Privacy Shield Framework\n* Health Insurance Portability and Accountability Act (HIPAA)\n* Service Organization Control standards (SOC 1 Type 2, SOC 2 Type 2)\n* International Standard on Assurance Engagements 3402 (ISAE 3402), Assurance Reports on Controls at a Service Organization\n* International Organization for Standardization (ISO 27001, ISO 27017, ISO 27018)\n* Payment Card Industry Data Security Standard (PCI DSS)\n\n\n\nVPC infrastructure: IBM Cloud Kubernetes Service implements controls commensurate with the following security standards:\n\n\n\n* EU-US Privacy Shield and Swiss-US Privacy Shield Framework\n* Health Insurance Portability and Accountability Act (HIPAA)\n* International Standard on Assurance Engagements 3402 (ISAE 3402), Assurance Reports on Controls at a Service Organization\n\n\n\n* Can I use IBM Cloud and other services with my cluster?\n\nYou can add IBM Cloud platform and infrastructure services as well as services from third-party vendors to your IBM Cloud Kubernetes Service cluster to enable automation, improve security, or enhance your monitoring and logging capabilities in the cluster.\n\nFor a list of supported services, see [Integrating services](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrationssupported_integrations).\n* Does IBM support third-party and open source tools that I use with my cluster?\n\nSee the [IBM Open Source and Third Party policy](https:\/\/www.ibm.com\/support\/pages\/node\/737271).\n* What am I charged for? Can I estimate and control costs in my cluster?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-390965-393092","score":25.1637058258,"text":"\nTo view detailed system requirements, you can run a [software product compatibility report for IBM Cloud Kubernetes Service](https:\/\/www.ibm.com\/software\/reports\/compatibility\/clarity\/softwareReqsForProduct.html). Note that compliance depends on the underlying [infrastructure provider](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers) for the cluster worker nodes, networking, and storage resources.\n\nClassic infrastructure: IBM Cloud Kubernetes Service implements controls commensurate with the following security standards:\n\n\n\n* EU-US Privacy Shield and Swiss-US Privacy Shield Framework\n* Health Insurance Portability and Accountability Act (HIPAA)\n* Service Organization Control standards (SOC 1 Type 2, SOC 2 Type 2)\n* International Standard on Assurance Engagements 3402 (ISAE 3402), Assurance Reports on Controls at a Service Organization\n* International Organization for Standardization (ISO 27001, ISO 27017, ISO 27018)\n* Payment Card Industry Data Security Standard (PCI DSS)\n\n\n\nVPC infrastructure: IBM Cloud Kubernetes Service implements controls commensurate with the following security standards:\n\n\n\n* EU-US Privacy Shield and Swiss-US Privacy Shield Framework\n* Health Insurance Portability and Accountability Act (HIPAA)\n* International Standard on Assurance Engagements 3402 (ISAE 3402), Assurance Reports on Controls at a Service Organization\n\n\n\n* Can I use IBM Cloud and other services with my cluster?\n\nYou can add IBM Cloud platform and infrastructure services as well as services from third-party vendors to your IBM Cloud Kubernetes Service cluster to enable automation, improve security, or enhance your monitoring and logging capabilities in the cluster.\n\nFor a list of supported services, see [Integrating services](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrationssupported_integrations).\n* Does IBM support third-party and open source tools that I use with my cluster?\n\nSee the [IBM Open Source and Third Party policy](https:\/\/www.ibm.com\/support\/pages\/node\/737271).\n* What am I charged for? Can I estimate and control costs in my cluster?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_05707-4888-6797","score":25.0796051025,"text":"\nIBM Cloud Kubernetes Service on IBM Cloud Public delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts For more information, see [IBM Cloud Kubernetes Service technology](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch).\n: You can also create your cluster in a Virtual Private Cloud (VPC), which gives you the security of a private cloud environment with isolated networking features along with the dynamic scalability of the public cloud. For more information, see [Overview of Classic and VPC infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers).\n\nIBM Cloud Private, on-premises\n: IBM Cloud Private is an application platform that can be installed locally on your own machines. You might choose to use Kubernetes in IBM Cloud Private when you need to develop and manage on-premises, containerized apps in your own controlled environment behind a firewall. For more information, see the [IBM Cloud Private product documentation](https:\/\/www.ibm.com\/docs\/en\/cloud-private\/3.2.x).\n\n\n\n\n\n Comparison of free and standard clusters \n\nReview the following table for a comparison of free and standard clusters.\n\nThe free cluster option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nFree clusters are automatically deleted after 30 days.\n\nIf you have a free cluster and want to upgrade to a standard cluster, you can [create a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusters).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov"},{"document_id":"ibmcld_05777-20604-22088","score":24.9143829346,"text":"\n* International Organization for Standardization (ISO 27001, ISO 27017, ISO 27018)\n* Payment Card Industry Data Security Standard (PCI DSS)\n\n\n\nVPC infrastructure: IBM Cloud Kubernetes Service implements controls commensurate with the following security standards:\n\n\n\n* EU-US Privacy Shield and Swiss-US Privacy Shield Framework\n* Health Insurance Portability and Accountability Act (HIPAA)\n* International Standard on Assurance Engagements 3402 (ISAE 3402), Assurance Reports on Controls at a Service Organization\n\n\n\n\n\n\n\n Can I use IBM Cloud and other services with my cluster? \n\nYou can add IBM Cloud platform and infrastructure services as well as services from third-party vendors to your IBM Cloud Kubernetes Service cluster to enable automation, improve security, or enhance your monitoring and logging capabilities in the cluster.\n\nFor a list of supported services, see [Integrating services](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrationssupported_integrations).\n\n\n\n\n\n Does IBM support third-party and open source tools that I use with my cluster? \n\nSee the [IBM Open Source and Third Party policy](https:\/\/www.ibm.com\/support\/pages\/node\/737271).\n\n\n\n\n\n What am I charged for? Can I estimate and control costs in my cluster? \n\nSee [Managing costs for your clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs).\n\n\n\n\n\n Can I downgrade my cluster to a previous version? \n\nNo, you cannot downgrade your cluster to a previous version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_05728-7028-9257","score":24.7950630188,"text":"\nIn any of these cases, you can choose to safely use the [ibmcloud ks cluster master update](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) command yourself without waiting for the update automation to apply.\n\n\n\n\n\n\n\n Release lifecycle \n\nEach supported version of IBM Cloud Kubernetes Service goes through a lifecycle of testing, development, general release, support, deprecation, and becoming unsupported. Review the descriptions of each phase of a version's lifecycle.\n\nEstimated days and versions are provided for general understanding. Actual availability and release dates are subject to change and depend on various factors, such as community updates, security patches, and technology changes between versions.\n\n\n\n1. Community release: The community releases the new version. IBM engineers begin testing and hardening the community version in preparation to release a supported IBM Cloud Kubernetes Service version.\n2. Supported version lifecycle:\n\nDevelopment release\n: Release is under development and might be available as a Beta to select customers. IBM provides best effort support for the release.\n\nGeneral availability\n: Release is generally available (GA). IBM provides full support for the release. IBM provides a tentative target date for the release to be unsupported. Release will become the default version used during cluster creation once there are minimal restrictions and a reasonable adoption rate for the release.\n\nMaintenance\n: Release has entered maintenance support as defined by the Kubernetes community. IBM provides maintenance support for Kubernetes based on community policy. IBM provides full support otherwise.\n3. Deprecated version: The version is deprecated. IBM provides an updated unsupported target date for the release. An unsupported countdown to this date will be provided at least 45 days before the release becomes unsupported. IBM provides minimal support for the release in alignment with the Kubernetes community. This support phase is generally the final phase before the release becomes unsupported and overrides the maintenance and extended support phases should there be any overlap. Security patch updates might not be provided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions"},{"document_id":"ibmcld_05597-7026-9255","score":24.7950630188,"text":"\nIn any of these cases, you can choose to safely use the [ibmcloud ks cluster master update](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) command yourself without waiting for the update automation to apply.\n\n\n\n\n\n\n\n Release lifecycle \n\nEach supported version of IBM Cloud Kubernetes Service goes through a lifecycle of testing, development, general release, support, deprecation, and becoming unsupported. Review the descriptions of each phase of a version's lifecycle.\n\nEstimated days and versions are provided for general understanding. Actual availability and release dates are subject to change and depend on various factors, such as community updates, security patches, and technology changes between versions.\n\n\n\n1. Community release: The community releases the new version. IBM engineers begin testing and hardening the community version in preparation to release a supported IBM Cloud Kubernetes Service version.\n2. Supported version lifecycle:\n\nDevelopment release\n: Release is under development and might be available as a Beta to select customers. IBM provides best effort support for the release.\n\nGeneral availability\n: Release is generally available (GA). IBM provides full support for the release. IBM provides a tentative target date for the release to be unsupported. Release will become the default version used during cluster creation once there are minimal restrictions and a reasonable adoption rate for the release.\n\nMaintenance\n: Release has entered maintenance support as defined by the Kubernetes community. IBM provides maintenance support for Kubernetes based on community policy. IBM provides full support otherwise.\n3. Deprecated version: The version is deprecated. IBM provides an updated unsupported target date for the release. An unsupported countdown to this date will be provided at least 45 days before the release becomes unsupported. IBM provides minimal support for the release in alignment with the Kubernetes community. This support phase is generally the final phase before the release becomes unsupported and overrides the maintenance and extended support phases should there be any overlap. Security patch updates might not be provided.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02573-0-2332","score":21.3785018921,"text":"\n\n\n\n\n\n\n  Introduction \n\nThis handbook is designed to serve as a set of standards, styles, and best practices for IBM Cloud APIs. It is expected to grow and evolve over time in order to best address the needs and requirements of users and developers of IBM Cloud APIs. To learn how to get involved, see [Contributing](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-contributing).\n\n\n\n  Using this handbook \n\nThis handbook is intended to be used by IBM Cloud service architects and developers as guidelines for designing any REST API exposed publicly by IBM Cloud services. Private or internal APIs SHOULD also follow these guidelines for providing the same level of consistency to internal service consumers and simplify the process if the internal APIs are subsequently exposed publicly.\n\nThere are legitimate reasons for a service to be exempted from adhering to this handbook's guidelines. For example, an exemption may be approved if a service offers an API compatible with a de facto standard, such as S3, or if a service offers an API that seamlessly extends an open source project, such as Kubernetes, following that project's API standards and conventions.\n\n\n\n\n\n  Conventions used \n\nThe key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this document are to be interpreted as described in [RFC 2119](https:\/\/datatracker.ietf.org\/doc\/html\/rfc2119).\n\n\n\n\n\n  Verifying compliance \n\nThe [OpenAPI Validator tool](https:\/\/github.com\/IBM\/openapi-validator) validates OpenAPI documents against a subset of the standards defined in this handbook and identifies areas of non-compliance with the OpenAPI specification or the guidelines in this handbook.\n\nThe output of the OpenAPI Validator is a report that identifies specific elements of the API definition that fail to comply with the OpenAPI specification or the IBM API Handbook. All errors listed by the report MUST be resolved prior to publication of the API unless the remediations would result in breaking changes for an existing API version.\n\nResolving all issues reported by the validator does not guarantee full compliance with this handbook's standards. API designers MUST perform further manual validations for the guidelines that cannot be checked automatically by the tool.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-intro"},{"document_id":"ibmcld_16729-140447-142378","score":21.2872161865,"text":"\nThis tutorial is part 4 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 4 of this tutorial series, you use the toolchain template for continuous compliance (CC) to ensure that your deployed artifacts and their source repositories are always compliant.\n\nKubernetes service Continuous Delivery\n\n+1\n\nDevSecOps\n\n\n\n* 1 hour\n* 2023-05-22\n\n\n\n[Part 3: Set up a Continuous Deployment (CD) toolchain](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cd-toolchain)Part 3: Set up a Continuous Deployment (CD) toolchain\n\nThis tutorial is part 3 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 3 of this tutorial series, you use the toolchain template for continuous deployment (CD) with security and compliance-related best practices in DevSecOps.\n\nKubernetes service Continuous Delivery\n\n+1\n\nDevSecOps\n\n\n\n* 1 hour\n* 2023-05-22\n\n\n\n[Part 2: Set up a Continuous Integration (CI) toolchain](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-ci-toolchain)Part 2: Set up a Continuous Integration (CI) toolchain\n\nThis tutorial is part 2 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 2 of this tutorial series, you use the toolchain template for continuous integration (CI) with security and compliance-related best practices in DevSecOps. It is preconfigured for continuous deployment with inventory integration, change management with Git Repos and Issue Tracking, evidence collection, and deployment to IBM Cloud Kubernetes Service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_16728-3750-5611","score":21.1998138428,"text":"\nThis tutorial shows how the IBM Log Analysis service can be used to configure and access logs of a Kubernetes application that is deployed on IBM Cloud. You will deploy a Python application to a cluster provisioned on IBM Cloud Kubernetes Service, configure a logging agent, generate different levels of application logs and access worker logs, pod logs or network logs. Then, you will search, filter and visualize those logs through Log Analysis Web UI.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Apply end to end security to a cloud application](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cloud-e2e-security)Apply end to end security to a cloud application Solution tutorial\n\nThis tutorial walks you through key security services available in the IBM Cloud\u00ae catalog and how to use them together. An application that provides file sharing will put security concepts into practice.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Architecture Framework](https:\/\/cloud.ibm.com\/docs\/architecture-framework)Architecture Framework Solution guide\n\nThe architecture framework can be used as a guide to provide a consistent approach to architect hybrid, multi-cloud end-to-end solutions based on your requirements.\n\n![solution icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/magic-wand.svg) [Best practices for organizing users, teams, applications](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-users-teams-applications)Best practices for organizing users, teams, applications Solution tutorial\n\nThis tutorial gives an overview of the concepts available in IBM Cloud for identity and access management and how they can be implemented to support the multiple development stages of an application.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"},{"document_id":"ibmcld_07578-373434-375500","score":20.4495391846,"text":"\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-373408-375474","score":20.4495391846,"text":"\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11125-7-2020","score":20.3714828491,"text":"\nService rollout policy \n\nIBM Cloud\u00ae has a resilient global network of locations to host your highly available cloud workload. To ensure that the cloud infrastructure and services are consistent and stable across our deployment locations, we created best practices for our service catalog management. These best practices help us to accomplish rollouts in the most efficient manner and minimize business impact, costs, and risks. The following information describes our guidelines on when to expect or how to request that a service is available in your region.\n\nThis policy covers all IBM Cloud public [MZRs](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locationstable-mzr), public [single-campus MZRs](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locationssingle-campus-mzr) and public [data centers](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locationsdata-centers).\n\nIBM\u00ae classifies our services deployed to our public locations as core or market-driven.\n\n\n\n Core services \n\nAll IBM\u00ae multi-zone regions contain the following core services, which are the most basic and vital services that are needed for the majority of customer workloads.\n\n\n\n* IBM Cloud platform (console, CLI, Identity and Access Management, and global catalog)\n* IBM Cloud\u00ae Virtual Private Cloud\n\n\n\n* IBM\u00ae Cloud Block Storage for Virtual Private Cloud\n* IBM Cloud\u00ae Virtual Servers for Virtual Private Cloud\n* Virtual Private Network (VPN) for VPC\n* IBM Cloud\u00ae Transit Gateway\n* Network Load Balancer for VPC\n* Application Load Balancer for VPC\n* Virtual Private Endpoint (VPE) for VPC\n* IBM Cloud\u00ae DNS Services\n\n\n\n* IBM Cloud Object Storage\n* IBM Cloud Databases for PostgreSQL\n* IBM Key Protect for IBM Cloud\n* IBM Cloud\u00ae Continuous Delivery\n* IBM Cloud Container Registry\n* IBM Cloud Kubernetes Service\n* Red Hat OpenShift on IBM Cloud\n\n\n\nThe IBM Cloud platform, including the console, CLI, Identity and Access Management, and global catalog, is a globally accessible instance that is independent of any region or zone.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-service-rollout"},{"document_id":"ibmcld_16729-141792-143568","score":20.269985199,"text":"\nThis tutorial is part 2 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 2 of this tutorial series, you use the toolchain template for continuous integration (CI) with security and compliance-related best practices in DevSecOps. It is preconfigured for continuous deployment with inventory integration, change management with Git Repos and Issue Tracking, evidence collection, and deployment to IBM Cloud Kubernetes Service.\n\nKubernetes service Continuous Delivery\n\n+1\n\nDevSecOps\n\n\n\n* 1 hour\n* 2023-06-06\n\n\n\n[Part 3: Set up a CD toolchain for Infrastructure as Code](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-tutorial-iac-cd)Part 3: Set up a CD toolchain for Infrastructure as Code\n\nThis tutorial is part 3 of a 3-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 3 of this tutorial series, you use the toolchain template for continuous deployment (CD) with security and compliance-related best practices in DevSecOps.\n\nSchematics Continuous Delivery\n\n+1\n\nDevSecOps\n\n\n\n* 1 hour\n* 2023-05-22\n\n\n\n[Part 2: Set up a CI toolchain for Infrastructure as Code (Terraform)](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-tutorial-iac-ci)Part 2: Set up a CI toolchain for Infrastructure as Code (Terraform)\n\nThis tutorial is part 2 of a 3-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud continuous delivery.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_00959-7-1866","score":20.1565551758,"text":"\nDeploy an app on Kubernetes \n\nIn this tutorial, you learn how to create an open toolchain by using different deployment strategies. You also learn how toolchains are implemented in the IBM Cloud\u00ae Continuous Delivery service and how to develop and deploy a simple web application (app) by using toolchains.\n\nThis tutorial is browser-based. You can also create a similar open toolchain in Terraform as shown in the IBM Cloud Terraform Provider example [ibm-cd-toolchain-simple-helm](https:\/\/github.com\/IBM-Cloud\/terraform-provider-ibm\/tree\/master\/examples\/ibm-cd-toolchain-simple-helm).\n\nThis tutorial uses deployment strategies that have Kubernetes as the deployment target. The toolchain that is used in this tutorial implements standard DevOps practices such as code scanning, acceptance tests, Git repos, and continuous integration and continuous delivery capabilities. After you create a Kubernetes cluster and a toolchain, you change your app's code and push the change to the Git Repos and Issue Tracking repo. When you push changes to your repo, the Tekton-based delivery pipeline automatically builds and deploys the code.\n\n[Tekton](https:\/\/www.ibm.com\/cloud\/blog\/tekton-a-modern-approach-to-continuous-delivery) is an open source, vendor-neutral, Kubernetes-native framework that you can use to build, test, and deploy apps. Tekton provides a set of shared components for building [continuous integration](https:\/\/www.ibm.com\/garage\/method\/practices\/code\/practice_continuous_integration\/) and [continuous delivery](https:\/\/www.ibm.com\/garage\/method\/practices\/deliver\/practice_continuous_delivery\/) systems. As an open source project, Tekton is managed by the [Continuous Delivery Foundation](https:\/\/cd.foundation\/). The goal is to modernize continuous delivery by providing industry specifications for pipelines, workflows, and other building blocks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-kubernetes"},{"document_id":"ibmcld_05724-5473-7562","score":20.1472148895,"text":"\n* IBM Cloud Kubernetes Service\n* IBM Cloudant\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae\n* App ID\n\n\n\nFor sensitive workloads, the clusters can be hosted in IBM Cloud Kubernetes Service for Bare Metal. By using industry-standard containers technology, apps can initially be re-hosted on IBM Cloud Kubernetes Service quickly without major architectural changes. This change provides the immediate benefit of scalability.\n\nThey can replicate and scale the apps by using defined rules and the automated Kubernetes orchestrator. IBM Cloud Kubernetes Service provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services. By using Kubernetes's deployment and runtime objects, the provider can monitor and manage upgrades to apps reliably.\n\nIBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure pipeline to on-premises databases and documents for apps that are re-hosted to run in IBM Cloud Kubernetes Service.\n\nIBM Cloudant is a modern NoSQL database suitable a range of data-driven use cases from key-value to complex document-oriented data storage and query. To minimize queries to the back-office RDBMS, IBM Cloudant is used to cache the user's session data across apps. These choices improve the front-end app usability and performance across the apps on IBM Cloud Kubernetes Service.\n\nMoving compute workloads into the IBM Cloud isn't enough though. The provider needs to go through a methods transformation as well. By adopting the practices of the IBM Garage Method, the provider can implement an agile and iterative delivery process that supports modern DevOps practices like CI\/CD.\n\nMuch of the CI\/CD process itself is automated with IBM's Continuous Delivery service in the Cloud. The provider can define workflow toolchains to prepare container images, check for vulnerabilities, and deploy them to the Kubernetes cluster.\n\n\n\n\n\n\n\n Results \n\n\n\n* Lifting the existing monolithic VMs into cloud-hosted containers was a first step that allowed the provider to save on capital costs and begin learning modern DevOps practices.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_uc_health"},{"document_id":"ibmcld_00754-3080-4555","score":20.0583667755,"text":"\nApplications can be deployed in minutes to a Kubernetes cluster on IBM Cloud, to either public or private clouds.\n\nOpen toolchain integrates more tools around Continuous Delivery such as IBM Cloud\u00ae Event Notifications, Slack, Atlassian JIRA, Sonatype Nexus, JFrog Artifactory, Sauce Labs, PagerDuty, and IBM Vulnerability Advisor. You can also substitute other tools for the Continuous Delivery capabilities, including GitHub and Jenkins. Developers can also use their favorite IDEs and editors, such as Visual Studio Code, Eclipse, and more.\n\nCode repos, issue tracking systems, build systems, and deployment systems represent a wealth of data that can be used to help you deliver apps more efficiently and effectively. IBM Cloud\u00ae DevOps Insights uses big data analysis to provide valuable insights to Executives, Managers, and Developers. DevOps Insights aggregates and analyzes data from your DevOps toolchain to advise you about the risk of deploying specific changes, and areas to improve both your codebase and team productivity. The Delivery Pipeline can automatically gate deployment to an environment based on the risk of a change.\n\nIBM Cloud DevOps provides concrete practices and architectures for cloud development. It enables Developers to get started quickly with new projects that employ the rich catalog of services on the IBM Cloud. IBM Cloud DevOps also provides Developers an open and integrated set of tools for automating delivery with speed and control.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-devops_intro"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04085-7-1799","score":18.0737533569,"text":"\nKubernetes \n\nThe IBM Blockchain Platform allows you to provision blockchain components into your Kubernetes cluster. Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\nKubernetes provides a container-centric management environment. It orchestrates computing, networking, and storage infrastructure on behalf of user workloads. This provides much of the simplicity of Platform as a Service (PaaS) with the flexibility of Infrastructure as a Service (IaaS), and enables portability across infrastructure providers.\n\nThe following diagram explains the architecture of Kubernetes. For more explanation about nodes, containers, and pod, see the [Key Kubernetes objects](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-k8s-overviewk8s-overview-key-obj) section below.\n\nZoom\n\n![Kubernetes architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/k8s-archi-diagram.svg)\n\nFigure 1. Kubernetes architecture diagram\n\n\n\n Key Kubernetes objects \n\n\n\n* Cluster\n\nA set of machines, called nodes, that run containerized applications managed by Kubernetes. A cluster has several worker nodes and at least one master node.\n* Node\n\nA node is a worker machine in Kubernetes. A node may be a VM or physical machine, depending on the cluster. Each node contains the services necessary to run pods and is managed by the master components. The services on a node include the container runtime, kubelet and kube-proxy. For more information, see the [Kubernetes Node section](https:\/\/kubernetes.io\/docs\/concepts\/architecture\/nodes\/) in the Kubernetes documentation.\n* Container\n\nA lightweight and portable executable image that contains software and all of its dependencies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-k8s-overview"},{"document_id":"ibmcld_03824-7-1809","score":18.0550117493,"text":"\nKubernetes \n\nThe IBM Blockchain Platform allows you to provision blockchain components into your Kubernetes cluster. Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\nKubernetes provides a container-centric management environment. It orchestrates computing, networking, and storage infrastructure on behalf of user workloads. This provides much of the simplicity of Platform as a Service (PaaS) with the flexibility of Infrastructure as a Service (IaaS), and enables portability across infrastructure providers.\n\nThe following diagram explains the architecture of Kubernetes. For more explanation about nodes, containers, and pod, see the [Key Kubernetes objects](https:\/\/cloud.ibm.com\/docs\/blockchain\/reference?topic=blockchain-k8s-overviewk8s-overview-key-obj) section below.\n\nZoom\n\n![Kubernetes architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/k8s-archi-diagram.svg)\n\nFigure 1. Kubernetes architecture diagram\n\n\n\n Key Kubernetes objects \n\n\n\n* Cluster\n\nA set of machines, called nodes, that run containerized applications managed by Kubernetes. A cluster has several worker nodes and at least one master node.\n* Node\n\nA node is a worker machine in Kubernetes. A node may be a VM or physical machine, depending on the cluster. Each node contains the services necessary to run pods and is managed by the master components. The services on a node include the container runtime, kubelet and kube-proxy. For more information, see the [Kubernetes Node section](https:\/\/kubernetes.io\/docs\/concepts\/architecture\/nodes\/) in the Kubernetes documentation.\n* Container\n\nA lightweight and portable executable image that contains software and all of its dependencies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain\/reference?topic=blockchain-k8s-overview"},{"document_id":"ibmcld_13180-5921-7911","score":17.6166038513,"text":"\n[Kubernetes](https:\/\/kubernetes.io\/) is a container orchestrator to manage the lifecycle of containerized apps in a cluster of worker nodes. Your apps might need many other resources to run, such as volumes, networks, and secrets which will help you connect to other cloud services, and secure keys. Kubernetes helps you to add these resources to your app. The key paradigm of Kubernetes is its declarative model. The user provides the desired state and Kubernetes attempts to conform to, and then maintains the described state.\n\nThis [self-paced workshop](https:\/\/ibm.github.io\/kube101\/) can help you to get your first hands-on experience with Kubernetes. Additionally, check out the Kubernetes [concepts](https:\/\/kubernetes.io\/docs\/concepts\/) documentation page to learn more about the concepts of Kubernetes.\n\n\n\n\n\n\n\n What IBM's doing for you \n\nBy using Kubernetes clusters with IBM Cloud Kubernetes Service, you get the following benefits:\n\n\n\n* Multiple data centers where you can deploy your clusters.\n* Support for ingress and load balancer networking options.\n* Dynamic persistent volume support.\n* Highly available, IBM-managed Kubernetes masters.\n\n\n\n\n\n\n\n\n\n Sizing clusters \n\nAs you design your cluster architecture, you want to balance costs against availability, reliability, complexity, and recovery. Kubernetes clusters in IBM Cloud Kubernetes Service provide architectural options based on the needs of your apps. With a bit of planning, you can get the most out of your cloud resources without over-architecting or over-spending. Even if you over or underestimate, you can easily scale up or down your cluster, by changing either the number or size of worker nodes.\n\nTo run a production app in the cloud by using Kubernetes, consider the following items:\n\n\n\n1. Do you expect traffic from a specific geographic location? If yes, select the location that is physically closest to you for best performance.\n2. How many replicas of your cluster do you want for higher availability?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vm-to-containers-and-kubernetes"},{"document_id":"ibmcld_01545-6013-8003","score":17.6166038513,"text":"\n[Kubernetes](https:\/\/kubernetes.io\/) is a container orchestrator to manage the lifecycle of containerized apps in a cluster of worker nodes. Your apps might need many other resources to run, such as volumes, networks, and secrets which will help you connect to other cloud services, and secure keys. Kubernetes helps you to add these resources to your app. The key paradigm of Kubernetes is its declarative model. The user provides the desired state and Kubernetes attempts to conform to, and then maintains the described state.\n\nThis [self-paced workshop](https:\/\/ibm.github.io\/kube101\/) can help you to get your first hands-on experience with Kubernetes. Additionally, check out the Kubernetes [concepts](https:\/\/kubernetes.io\/docs\/concepts\/) documentation page to learn more about the concepts of Kubernetes.\n\n\n\n\n\n\n\n What IBM's doing for you \n\nBy using Kubernetes clusters with IBM Cloud Kubernetes Service, you get the following benefits:\n\n\n\n* Multiple data centers where you can deploy your clusters.\n* Support for ingress and load balancer networking options.\n* Dynamic persistent volume support.\n* Highly available, IBM-managed Kubernetes masters.\n\n\n\n\n\n\n\n\n\n Sizing clusters \n\nAs you design your cluster architecture, you want to balance costs against availability, reliability, complexity, and recovery. Kubernetes clusters in IBM Cloud Kubernetes Service provide architectural options based on the needs of your apps. With a bit of planning, you can get the most out of your cloud resources without over-architecting or over-spending. Even if you over or underestimate, you can easily scale up or down your cluster, by changing either the number or size of worker nodes.\n\nTo run a production app in the cloud by using Kubernetes, consider the following items:\n\n\n\n1. Do you expect traffic from a specific geographic location? If yes, select the location that is physically closest to you for best performance.\n2. How many replicas of your cluster do you want for higher availability?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-vm-to-containers-and-kubernetes"},{"document_id":"ibmcld_05777-7-1924","score":17.6001777649,"text":"\nFAQs \n\nReview frequently asked questions (FAQs) for using IBM Cloud\u00ae Kubernetes Service.\n\n\n\n What is Kubernetes? \n\nKubernetes is an open source platform for managing containerized workloads and services across multiple hosts, and offers managements tools for deploying, automating, monitoring, and scaling containerized apps with minimal to no manual intervention. All containers that make up your microservice are grouped into pods, a logical unit to ensure easy management and discovery. These pods run on compute hosts that are managed in a Kubernetes cluster that is portable, extensible, and self-healing in case of failures.\n\nFor more information about Kubernetes, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/home\/?path=users&persona=app-developer<=vel=foundational).\n\n\n\n\n\n How does IBM Cloud Kubernetes Service work? \n\nWith IBM Cloud Kubernetes Service, you can create your own Kubernetes cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Kubernetes master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_05998-7-2051","score":16.6131706238,"text":"\nUnderstanding IBM Cloud Kubernetes Service \n\nLearn more about [IBM Cloud\u00ae Kubernetes Service](https:\/\/www.ibm.com\/cloud\/kubernetes-service), its capabilities, and the options that are available to you to customize the cluster to your needs.\n\nReview frequently asked questions and key technologies that IBM Cloud Kubernetes Service uses.\n\n\n\n What is IBM Cloud Kubernetes Service and how does it work? \n\nIBM Cloud Kubernetes Service is a managed offering to create your own Kubernetes cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\n\n\n\n\n What is Kubernetes? \n\nKubernetes is an open source platform for managing containerized workloads and services across multiple hosts, and offers management tools for deploying, automating, monitoring, and scaling containerized apps with minimal to no manual intervention.\n\nZoom\n\n![Kubernetes certification badge](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/certified-kubernetes-color.svg)\n\nFigure 1. This badge indicates Kubernetes certification for IBM Cloud Container Service.\n\nThe open source project, Kubernetes, combines running a containerized infrastructure with production workloads, open source contributions, and Docker container management tools. The Kubernetes infrastructure provides an isolated and secure app platform for managing containers that is portable, extensible, and self-healing in case of a failover. For more information, see [What is Kubernetes?](https:\/\/www.ibm.com\/topics\/kubernetes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overview"},{"document_id":"ibmcld_05998-1617-3497","score":16.3816490173,"text":"\nThe open source project, Kubernetes, combines running a containerized infrastructure with production workloads, open source contributions, and Docker container management tools. The Kubernetes infrastructure provides an isolated and secure app platform for managing containers that is portable, extensible, and self-healing in case of a failover. For more information, see [What is Kubernetes?](https:\/\/www.ibm.com\/topics\/kubernetes).\n\nLearn more about the key concepts of Kubernetes as illustrated in the following image.\n\nZoom\n\n![Example deployment and namespaces](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/k8-namespace.svg)\n\nFigure 2. A description of key concepts for Kubernetes\n\nAccount\n: Your account refers to your IBM Cloud account.\n\nCluster, worker pool, and worker node\n: A Kubernetes cluster consists of a master and one or more compute hosts that are called worker nodes. Worker nodes are organized into worker pools of the same flavor, or profile of CPU, memory, operating system, attached disks, and other properties. The worker nodes correspond to the Kubernetes Node resource, and are managed by a Kubernetes master that centrally controls and monitors all Kubernetes resources in the cluster. So when you deploy the resources for a containerized app, the Kubernetes master decides which worker node to deploy those resources on, accounting for the deployment requirements and available capacity in the cluster. Kubernetes resources include services, deployments, and pods. For more information, see [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch).\n\nNamespace\n: Kubernetes namespaces are a way to divide your cluster resources into separate areas that you can deploy apps and restrict access to, such as if you want to share the cluster with multiple teams.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overview"},{"document_id":"ibmcld_10495-1595-3474","score":16.3740577698,"text":"\nThe open source project, Kubernetes, combines running a containerized infrastructure with production workloads, open source contributions, and Docker container management tools. The Kubernetes infrastructure provides an isolated and secure app platform for managing containers that is portable, extensible, and self-healing in case of a failover. For more information, see [What is Kubernetes?](https:\/\/www.ibm.com\/topics\/kubernetes).\n\nLearn more about the key concepts of Kubernetes as illustrated in the following image.\n\nZoom\n\n![Example deployment and namespaces](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/openshift\/images\/k8-namespace.svg)\n\nFigure 2. A description of key concepts for Kubernetes\n\nAccount\n: Your account refers to your IBM Cloud account.\n\nCluster, worker pool, and worker node\n: A Kubernetes cluster consists of a master and one or more compute hosts that are called worker nodes. Worker nodes are organized into worker pools of the same flavor, or profile of CPU, memory, operating system, attached disks, and other properties. The worker nodes correspond to the Kubernetes Node resource, and are managed by a Kubernetes master that centrally controls and monitors all Kubernetes resources in the cluster. So when you deploy the resources for a containerized app, the Kubernetes master decides which worker node to deploy those resources on, accounting for the deployment requirements and available capacity in the cluster. Kubernetes resources include services, deployments, and pods. For more information, see [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch).\n\nNamespace\n: Kubernetes namespaces are a way to divide your cluster resources into separate areas that you can deploy apps and restrict access to, such as if you want to share the cluster with multiple teams.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview"},{"document_id":"ibmcld_05568-7-2016","score":16.1470375061,"text":"\nDeveloping Kubernetes-native apps \n\nDevelop a configuration to deploy your app workload to IBM Cloud\u00ae Kubernetes Service. Because Kubernetes is an extensible container orchestration platform that does not mandate a specific language or app, you can run various workloads such as stateless, stateful, and data-processing apps that are written in the language of your choice.\n\n\n\n Specifying your app requirements in your YAML file \n\nIn Kubernetes, you describe your app in a YAML file that declares the configuration of the Kubernetes object. The Kubernetes API server then processes the YAML file and stores the configuration and required state of the object in the etcd data store. The Kubernetes scheduler schedules your workloads onto the worker nodes within your cluster, taking into account the specification in your YAML file, any cluster policies that the admin sets, and available cluster capacity.\n\nReview a copy of the [complete YAML file](https:\/\/raw.githubusercontent.com\/IBM-Cloud\/kube-samples\/master\/deploy-apps-clusters\/deploy_wasliberty.yaml). Then, review the following sections to understand how you can enhance your app deployment.\n\nWant more information about how Kubernetes objects work together for your deployment? Check out [Understanding Kubernetes objects for apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploykube-objects).\n\n\n\n Basic deployment metadata \n\nUse the appropriate API version for the [kind of Kubernetes object](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deployobject) that you deploy. The API version determines the supported features for the Kubernetes object that are available to you. The name that you give in the metadata is the object's name, not its label. You use the name when interacting with your object, such as kubectl get deployment <name>.\n\napiVersion: apps\/v1\nkind: Deployment\nmetadata:\nname: wasliberty\n\n\n\n\n\n Replica set \n\nTo increase the availability of your app, you can specify a replica set in your deployment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-app"},{"document_id":"ibmcld_06079-7417-9399","score":15.9817724228,"text":"\n: The Kubernetes network proxy is a daemon that runs on every worker node and that forwards or load balances TCP and UDP network traffic for services that run in the cluster.\n\nkube-dashboard\n: The Kubernetes dashboard is a web-based GUI that allows users to manage and troubleshoot the cluster and applications that run in the cluster.\n\nheapster\n: Heapster is a cluster-wide aggregator of monitoring and event data. The Heapster pod discovers all nodes in the cluster and queries usage information from each node's kubelet. You can find utilization graphs in the Kubernetes dashboard.\n\nIngress ALB\n: Ingress is a Kubernetes service that you can use to balance network traffic workloads in your cluster by forwarding public or private requests to multiple apps in your cluster. To expose your apps over the public or private network, you must create an Ingress resource to register your apps with the Ingress application load balancer (ALB). Multiple apps can then be accessed by using a single URL or IP address.\n\nStorage provider\n: Every cluster is set up with a plug-in to provision file storage. You can choose to install other add-ons, such as block storage.\n\n\n\n\n\n ibm-system namespace \n\nLogging and metrics\n: You can use the IBM\u00ae Log Analysis and IBM Cloud\u00ae Monitoring services to expand your collection and retention capabilities when working with logs and metrics. Load balancer\n: A load balancer is a Kubernetes service that can be used to balance network traffic workloads in your cluster by forwarding public or private requests to an app.\n\n\n\n\n\n default namespace \n\nApp pods and services\n: In the default namespace or in namespaces that you create, you can deploy apps in pods and services to communicate with those pods.\n\n\n\n\n\n\n\n VPC cluster \n\nThe following diagram and table describe the default components that are set up in an IBM Cloud Kubernetes Service VPC cluster architecture.\n\nThe following architectural overviews are specific to the VPC infrastructure provider.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05722-7-2498","score":21.7562618256,"text":"\nFinancial services use cases for IBM Cloud \n\nThese use cases highlight how workloads on IBM Cloud\u00ae Kubernetes Service can take advantage of high availability, high-performance compute, easy spin-up of clusters for faster development, and AI from IBM Watson\u00ae.\n\n\n\n Mortgage company trims costs and accelerates regulatory compliance \n\nA Risk Management VP for a residential mortgage company processes 70 million records a day, but the on-premises system was slow and also inaccurate. IT expenses soared because hardware quickly went out of date and wasn't utilized fully. While they waited for hardware provisioning, their regulatory compliance slowed.\n\n\n\n Context \n\nTo improve risk analysis, the company looked to IBM Cloud Kubernetes Service and IBM Cloud Analytic services to reduce costs, increase worldwide availability, and ultimately accelerate regulatory compliance. With IBM Cloud Kubernetes Service in multiple regions, their analysis apps can be containerized and deployed across the globe, improving availability and addressing local regulations. Those deployments are accelerated with familiar open source tools, already part of IBM Cloud Kubernetes Service.\n\nThey started by containerizing the analysis apps and putting them in the cloud. In a flash, their hardware headaches went away. They were able to easily design Kubernetes clusters to fit their high-performance CPU, RAM, storage, and security needs. And when their analysis apps change, they can add or shrink compute without huge hardware investments. With the IBM Cloud Kubernetes Service horizontal scaling, their apps scale with the growing number of records, resulting in faster regulatory reports. IBM Cloud Kubernetes Service provides elastic compute resources around the world that are secure and capable.\n\nNow those apps receive high-volume data from a data warehouse on IBM Cloudant. Cloud-based storage in IBM Cloudant ensures higher availability than when it was locked in an on-premises system. Since availability is essential, the apps are deployed across global data centers: for DR and for latency too.\n\nThey also accelerated their risk analysis and compliance. Their predictive and risk analytics functions, such as Monte Carlo calculations, are now constantly updated through iterative agile deployments. Container orchestration is handled by a managed Kubernetes so that operations costs are reduced too. Ultimately risk analysis for mortgages is more responsive to the fast-paced changes in the market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_uc_finance"},{"document_id":"ibmcld_05724-5473-7562","score":21.4399967194,"text":"\n* IBM Cloud Kubernetes Service\n* IBM Cloudant\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae\n* App ID\n\n\n\nFor sensitive workloads, the clusters can be hosted in IBM Cloud Kubernetes Service for Bare Metal. By using industry-standard containers technology, apps can initially be re-hosted on IBM Cloud Kubernetes Service quickly without major architectural changes. This change provides the immediate benefit of scalability.\n\nThey can replicate and scale the apps by using defined rules and the automated Kubernetes orchestrator. IBM Cloud Kubernetes Service provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services. By using Kubernetes's deployment and runtime objects, the provider can monitor and manage upgrades to apps reliably.\n\nIBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure pipeline to on-premises databases and documents for apps that are re-hosted to run in IBM Cloud Kubernetes Service.\n\nIBM Cloudant is a modern NoSQL database suitable a range of data-driven use cases from key-value to complex document-oriented data storage and query. To minimize queries to the back-office RDBMS, IBM Cloudant is used to cache the user's session data across apps. These choices improve the front-end app usability and performance across the apps on IBM Cloud Kubernetes Service.\n\nMoving compute workloads into the IBM Cloud isn't enough though. The provider needs to go through a methods transformation as well. By adopting the practices of the IBM Garage Method, the provider can implement an agile and iterative delivery process that supports modern DevOps practices like CI\/CD.\n\nMuch of the CI\/CD process itself is automated with IBM's Continuous Delivery service in the Cloud. The provider can define workflow toolchains to prepare container images, check for vulnerabilities, and deploy them to the Kubernetes cluster.\n\n\n\n\n\n\n\n Results \n\n\n\n* Lifting the existing monolithic VMs into cloud-hosted containers was a first step that allowed the provider to save on capital costs and begin learning modern DevOps practices.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_uc_health"},{"document_id":"ibmcld_05723-3429-5611","score":21.3954105377,"text":"\nThus, they chose IBM Cloud Kubernetes Service because IBM simplifies infrastructure management.\n\n\n\n* Managing Kubernetes master, IaaS, and operational components, such as Ingress and storage\n* Monitoring health and recovery for worker nodes\n* Providing global compute, so Developers don\u2019t have to stand up infrastructure in worldwide regions where they need workloads and data to be located\n\n\n\nMoving compute workloads into the IBM Cloud isn't enough though. The government needs to go through a method transformation as well. By adopting the practices of the IBM Garage Method, the provider can implement an agile and iterative delivery process that supports modern DevOps practices like Continuous Integration and Delivery (CI\/CD).\n\nMuch of the CI\/CD process itself is automated with IBM Cloud\u00ae Continuous Delivery in the cloud. The provider can define workflow toolchains to prepare container images, check for vulnerabilities, and deploy them to the Kubernetes cluster.\n\nCompute, storage, and API tools run in the public cloud with secure access to and from on-premises data sources.\n\nTechnical solution:\n\n\n\n* IBM Cloud Kubernetes Service\n* IBM Cloud Object Storage and IBM Cloudant\n* IBM\u00ae API Connect\n* IBM Secure Gateway\n* IBM Cloud\u00ae Continuous Delivery\n\n\n\n\n\n Step 1: Store data in the cloud \n\n\n\n* IBM Cloud Object Storage provides historical data storage, accessible to all on the public cloud.\n* Use IBM Cloudant with developer-provided keys to cache data in the cloud.\n* Use IBM Secure Gateway to maintain secure connections to existing on-premises databases.\n\n\n\n\n\n\n\n Step 2: Provide access to data with APIs \n\n\n\n* Use IBM\u00ae API Connect for the API economy platform. APIs allow the public and private sectors to combine data into their apps.\n* Create clusters for public-private apps, which are driven by the APIs.\n* Structure apps into a set of cooperative microservices that run within IBM Cloud Kubernetes Service, which is based on functional areas of apps and their dependencies.\n* Deploy the apps to containers that run in IBM Cloud Kubernetes Service. Built-in HA tools in IBM Cloud Kubernetes Service balance the workloads, including self-healing and load balancing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_uc_gov"},{"document_id":"ibmcld_05777-7-1924","score":21.1907367706,"text":"\nFAQs \n\nReview frequently asked questions (FAQs) for using IBM Cloud\u00ae Kubernetes Service.\n\n\n\n What is Kubernetes? \n\nKubernetes is an open source platform for managing containerized workloads and services across multiple hosts, and offers managements tools for deploying, automating, monitoring, and scaling containerized apps with minimal to no manual intervention. All containers that make up your microservice are grouped into pods, a logical unit to ensure easy management and discovery. These pods run on compute hosts that are managed in a Kubernetes cluster that is portable, extensible, and self-healing in case of failures.\n\nFor more information about Kubernetes, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/home\/?path=users&persona=app-developer<=vel=foundational).\n\n\n\n\n\n How does IBM Cloud Kubernetes Service work? \n\nWith IBM Cloud Kubernetes Service, you can create your own Kubernetes cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Kubernetes master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_05998-7-2051","score":21.0602245331,"text":"\nUnderstanding IBM Cloud Kubernetes Service \n\nLearn more about [IBM Cloud\u00ae Kubernetes Service](https:\/\/www.ibm.com\/cloud\/kubernetes-service), its capabilities, and the options that are available to you to customize the cluster to your needs.\n\nReview frequently asked questions and key technologies that IBM Cloud Kubernetes Service uses.\n\n\n\n What is IBM Cloud Kubernetes Service and how does it work? \n\nIBM Cloud Kubernetes Service is a managed offering to create your own Kubernetes cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\n\n\n\n\n What is Kubernetes? \n\nKubernetes is an open source platform for managing containerized workloads and services across multiple hosts, and offers management tools for deploying, automating, monitoring, and scaling containerized apps with minimal to no manual intervention.\n\nZoom\n\n![Kubernetes certification badge](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/certified-kubernetes-color.svg)\n\nFigure 1. This badge indicates Kubernetes certification for IBM Cloud Container Service.\n\nThe open source project, Kubernetes, combines running a containerized infrastructure with production workloads, open source contributions, and Docker container management tools. The Kubernetes infrastructure provides an isolated and secure app platform for managing containers that is portable, extensible, and self-healing in case of a failover. For more information, see [What is Kubernetes?](https:\/\/www.ibm.com\/topics\/kubernetes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overview"},{"document_id":"ibmcld_05722-3930-6284","score":20.9457588196,"text":"\n* IBM Cloud Object Storage\n* IBM Cloud Data Engine (Spark)\n* IBM Cloudant\n* Secure Gateway\n\n\n\nIBM Cloud Kubernetes Service provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services as needed. Using industry-standard containers, apps can initially be re-hosted on IBM Cloud Kubernetes Service quickly without major architectural changes.\n\nThis solution provides the immediate benefit of scalability. By using Kubernetes's rich set of deployment and runtime objects, the mortgage company monitors and manages the upgrades to apps reliably. They're also able to replicate and scale the apps that use defined rules and the automated Kubernetes orchestrator.\n\nSecure Gateway is used to create a secure pipeline to on-premises databases and documents for apps that are re-hosted to run in IBM Cloud Kubernetes Service.\n\nIBM Cloud Object Storage is for all raw document and data storage as they go forward. For Monte Carlo simulations, a workflow pipeline is put in place where simulation data is in structured files that are stored in IBM Cloud Object Storage. A trigger to start the simulation scales compute services in IBM Cloud Kubernetes Service to split the data of the files into N event buckets for simulation processing. IBM Cloud Kubernetes Service automatically scales to N associated service executions and writes intermediate results to IBM Cloud Object Storage. Those results are processed by another set of the IBM Cloud Kubernetes Service compute services to produce the final results.\n\nIBM Cloudant is a modern NoSQL database that is useful for many data-driven use cases: from key-value to complex document-oriented data storage and query. To manage the growing set of regulatory and management report rules, the mortgage company uses IBM Cloudant to store documents that are associated with raw regulatory data the come into the firm. Compute processes on IBM Cloud Kubernetes Service are triggered to compile, process, and publish the data in various reporting formats. Intermediate results common across reports are stored as IBM Cloudant documents so template-driven processes can be used to produce the necessary reports.\n\n\n\n\n\n Results \n\n\n\n* Complex financial simulations are completed in 25% of the time than was previously possible with the existing on-premises systems.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_uc_finance"},{"document_id":"ibmcld_05724-7-2333","score":20.936422348,"text":"\nHealthcare use cases for IBM Cloud \n\nThese use cases highlight how workloads on IBM Cloud\u00ae Kubernetes Service benefit from the public cloud. They have secure compute on isolated bare metal, easy spin-up of clusters for faster development, migration from virtual machines, and data sharing in cloud databases.\n\n\n\n Healthcare provider migrates workloads from inefficient VMs to Ops-friendly containers for reporting and patient systems \n\nAn IT Exec for a healthcare provider has business reporting and patient systems on-premises. Those systems go through slow enhancement cycles, which leads to stagnant patient service levels.\n\nTo improve patient service, the provider looked to IBM Cloud Kubernetes Service and IBM Cloud\u00ae Continuous Delivery to reduce IT expenses and accelerate development, all on a secure platform. The provider\u2019s high-use SaaS systems, which held both patient record systems and business report apps, needed updates frequently. Yet the on-premises environment hindered agile development. The provider also wanted to counteract increasing labor costs and a decreasing budget.\n\nThey started by containerizing their SaaS systems and putting them in the cloud. From that first step, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the SaaS apps, they easily designed Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for decreased staff costs is that IBM manages Kubernetes, so the provider can focus on delivering better customer service.\n\nAccelerated development is a key win for the IT Exec. With the move to public cloud, Developers can experiment easily with Node.js SDK, pushing changes to Development and Test systems, scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. Updates to the SaaS system no longer languished in slow, error-prone build processes. The Developers can deliver incremental updates to their users, daily or even more frequently. Also, logging and monitoring for the SaaS systems, especially how the patient front-end and back-end reports interact, rapidly integrate into the system. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_uc_health"},{"document_id":"ibmcld_16676-1833-4294","score":20.8906021118,"text":"\nYou can use this service to secure your builds, detect and respond to runtime threats, and continuously manage cloud configurations, permissions, and compliance.\n\nThe IBM Cloud Security and Compliance Center Workload Protection service is a cloud workload protection tool (CWPT) that helps you monitor and protect your organization. Includes Cloud security posture management (CSPM), Kubernetes Security Posture Management (KSPM) and more. Use cloud security posture management features to secure the infrastructure where workloads are deployed. Use Kubernetes Security Posture Management features to secure Kubernetes clusters or Red Hat OpenShift clusters, and the workloads running within it.\n\nIBM Cloud Security and Compliance Center Workload Protection main goal is to provide the tools that will help you keep your organization secure and able to resist threats and attacks, while making sure that workloads are deployed successfully.\n\n\n\n Cloud security posture management (CSPM) \n\nCloud security posture management (CSPM) is a framework that includes the policies and controls, the practices, and the technologies to detect and remediate security issues, and compliance risks across multi-cloud environments in your organization. It is focused on securing cloud infrastructures where workloads are deployed. In addition, it addresses security and compliance of Infrastructure as a Service (IaaS), Software as a Service (SaaS), and Platform as a Service (PaaS).\n\nThe IBM Cloud Security and Compliance Center Workload Protection service includes CSPM functionality to continuously monitor infrastructures in your organization where workloads are deployed.\n\nThe IBM Cloud Security and Compliance Center Workload Protection service inspects cloud environments across multiple environments to continuously:\n\n\n\n* Scan, detect and alert of misconfigurations, malware, secrets, and software configuration vulnerabilities. Empower DevOps to fix them fast.\n* Provide fixes and guidance on how to remediate security findings.\n* Map misconfigurations in production to infrastructure as code (IaC) manifests.\n* Provide control over cloud infrastructure configurations and ensure consistent implementation of policies across multiple cloud providers.\n\nUse out-of-the-box compliance controls.\n\nCreate customized security policies that align with your security mandates.\n\nDuplicate an existing security policy and turn on\/off controls, or create a new ones from scratch.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-about"},{"document_id":"ibmcld_07578-373434-375500","score":20.8028316498,"text":"\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-373408-375474","score":20.8028316498,"text":"\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.4790262928}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16727-380969-382817","score":28.557674408,"text":"\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-380995-382843","score":28.557674408,"text":"\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_05777-8738-10765","score":27.3204269409,"text":"\nThis setup is called a [multizone cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.\n\nTo protect against an entire region failure, create [multiple clusters and spread them across IBM Cloud regions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmultiple-clusters-glb). By setting up a network load balancer (NLB) for your clusters, you can achieve cross-region load balancing and cross-region networking for your clusters.\n\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-haha).\n\n\n\n\n\n What options do I have to secure my cluster? \n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_10290-54697-56544","score":26.8788337708,"text":"\n: Viewer platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n--provider (classic | vpc-gen2)\n: Optional: Filter output based on infrastructure provider type.\n\n-l, --location LOCATION\n: Filter output by a specific location. To see supported locations, run ibmcloud oc locations. To specify multiple locations, use one option for each location, such as -l dal -l seo.\n\n--output json\n: Optional: Prints the command output in JSON format. Note: If you don't include the --provider option, only classic clusters are returned.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster ls command \n\nibmcloud oc cluster ls -l ams03 -l wdc -l ap\n\n\n\n\n\n\n\n ibmcloud oc cluster master pod-security get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView the pod security admission configuration for a cluster's Kubernetes API server.\n\nibmcloud oc cluster master pod-security get --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Viewer platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security get command \n\nibmcloud oc cluster master pod-security get --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud oc cluster master pod-security policy disable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nDisable the pod security policy for a cluster's Kubernetes API server.\n\nibmcloud oc cluster master pod-security policy disable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_00959-14563-16267","score":26.3486976624,"text":"\n![Kubernetes secure app secrets options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/ds_kub_setup_sm.png)\n\nFigure 6. Kubernetes Secure app secrets options\n\nFor more information about managing your secrets in IBM Key Protect or HashiCorp, see [IBM Key Protect](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-tekton-ci-compliancecd-devsecops-key-protect-ci) or [HashiCorp](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-tekton-ci-compliancecd-devsecops-vault-ci).\n\n\n\n\n\n\n\n Step 2: Configure the deployment target \n\nConfigure the target Kubernetes cluster to deploy the app to. After the app passes the build, test, and scan phase, the pipeline deploys the built app image to the target Kubernetes cluster. This deployment is now ready for acceptance testing or integration testing.\n\nIf the API key has the required access, the following fields automatically load by using the API key that is either created, retrieved from a vault, or manually specified. If the API key is valid, values for the Container registry region and namespace Cluster region, name, namespace, and Resource group are automatically populated. You can update any of these fields to match your configuration.\n\n\n\n* App name: The name of the app. The default app name is hello-containers.\n* IBM Cloud API Key: The API key that is used to interact with the ibmcloud CLI tool in several tasks. Use one of the following methods to specify the API key that you want to use:\n\n\n\n* Click the key icon to import an existing API key from a secret vault of your choice.\n* Copy and paste an existing API key.\n* Click New to create an API key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-kubernetes"},{"document_id":"ibmcld_00961-11694-13406","score":25.9602813721,"text":"\n![Kubernetes secure app secrets options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/sat_kub_secrets_manager.png)\n\nFigure 6. Kubernetes Secure app secrets options\n\nFor more information about managing your secrets in IBM Key Protect or HashiCorp, see [IBM Key Protect](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-tekton-ci-compliancecd-devsecops-key-protect-ci) or [HashiCorp](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-tekton-ci-compliancecd-devsecops-vault-ci).\n\n\n\n\n\n\n\n Step 2: Configure the deployment target \n\nConfigure the target Kubernetes cluster to deploy the app to. After the app passes the build, test, and scan phase, the pipeline deploys the built app image to the target Kubernetes cluster. This deployment is now ready for acceptance testing or integration testing.\n\nIf the API key has the required access, the following fields automatically load by using the API key that is either created, retrieved from a vault, or manually specified. If the API key is valid, values for the Container registry region and namespace Cluster region, name, namespace, and Resource group are automatically populated. You can update any of these fields to match your configuration.\n\n\n\n* App name: The name of the app. The default app name is hello-containers.\n* IBM Cloud API Key: The API key that is used to interact with the ibmcloud CLI tool in several tasks. Use one of the following methods to specify the API key that you want to use:\n\n\n\n* Click the key icon to import an existing API key from a secret vault of your choice.\n* Copy and paste an existing API key.\n* Click New to create an API key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-satellite"},{"document_id":"ibmcld_10026-14066-16194","score":25.9203071594,"text":"\nVerify that the oc commands run properly with your cluster through the private cloud service endpoint by checking the version.\n\noc version\n\nExample output\n\nClient Version: 4.5.0-0.okd-2020-09-04-180756\nServer Version: 4.5.35\nKubernetes Version: v1.18.3+cdb0358\n\n\n\n\n\n\n\n Creating an allowlist for the private cloud service endpoint \n\nControl access to your private cloud service endpoint by creating a subnet allowlist.\n\nAfter you [grant users access to your cluster through IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms), you can add a secondary layer of security by creating an allowlist for the private cloud service endpoint. Only authorized requests to your cluster master that originate from subnets in the allowlist are permitted through the cluster's private cloud service endpoint.\n\nIf you want to allow requests from a different VPC than the one your cluster is in, you must include the cloud service endpoint for that VPC in the allowlist.\n\nFor example, to access your cluster's private cloud service endpoint, you must connect to your IBM Cloud classic network or your VPC network through a VPN or IBM Cloud Direct Link. You can add the subnet for the VPN or Direct Link tunnel so that only authorized users in your organization can access the private cloud service endpoint from that subnet.\n\nA private cloud service endpoint allowlist can also help prevent users from accessing your cluster after their authorization is revoked. When a user leaves your organization, you remove their IBM Cloud IAM permissions that grant them access to the cluster. However, the user might have copied the API key that contains a functional ID's credentials, which contain the necessary IAM permissions for your cluster. That user can still use those credentials and the private cloud service endpoint address to access your cluster from a different subnet, such as from a different IBM Cloud account. If you create an allowlist that includes only the subnets for your VPN tunnel in your organization's IBM Cloud account, the user's attempted access from another IBM Cloud account is denied.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster"},{"document_id":"ibmcld_10290-53160-55098","score":25.9194316864,"text":"\nEnable [image security enforcement](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-imagesportieris-image-sec) by installing the Portieris Kubernetes admission controller and the associated default image policies in your cluster.\n\nibmcloud oc cluster image-security enable --cluster CLUSTER [-f] [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-f\n: Optional: Force the command to run with no user prompts.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster image-security enable command \n\nibmcloud oc cluster image-security enable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud oc cluster ls \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\nList all clusters in your IBM Cloud account.\n\nClusters in all locations are returned. To filter clusters by a specific location, include the --location option. For example, if you filter clusters for the dal metro, multizone clusters in that metro and single-zone clusters in data centers (zones) within that metro are returned. If you filter clusters for the dal10 data center (zone), multizone clusters that have a worker node in that zone and single-zone clusters in that zone are returned. You can pass one location or a comma-separated list of locations.\n\nibmcloud oc cluster ls [--provider (classic | vpc-gen2)] [--location LOCATION] [--output json] [-q]\n\nMinimum required permissions\n: Viewer platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n--provider (classic | vpc-gen2)\n: Optional: Filter output based on infrastructure provider type.\n\n-l, --location LOCATION\n: Filter output by a specific location. To see supported locations, run ibmcloud oc locations. To specify multiple locations, use one option for each location, such as -l dal -l seo.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_06063-7869-9744","score":25.8952236176,"text":"\nThese certificates are never shared across clusters or across Kubernetes master components.\n\nNeed to revoke existing certificates and create new certificates for your cluster? Check out [Rotating CA certificates in your cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitycert-rotate).\n\nConnectivity to worker nodes\n: Although Kubernetes secures the communication between the master and worker nodes by using the https protocol, no authentication is provided on the worker node by default. To secure this communication, IBM Cloud Kubernetes Service automatically sets up an Konnectivity connection between the Kubernetes master and the worker node when the cluster is created.\n\nFine-grained access control\n: As the account administrator you can [grant access to other users for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-usersusers) by using IBM Cloud Identity and Access Management (IAM). IBM Cloud IAM provides secure authentication with the IBM Cloud platform, IBM Cloud Kubernetes Service, and all the resources in your account. Setting up proper user roles and permissions is key to limiting who can access your resources and to limiting the damage that a user can do when legitimate permissions are misused. You can select from the following pre-defined user roles that determine the set of actions that the user can perform:\n\n\n\n* Platform access roles: Determine the cluster and worker node management-related actions that a user can perform in IBM Cloud Kubernetes Service.\n* Service access roles: Determine the [Kubernetes RBAC role](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/rbac\/) that is assigned to the user and the actions that a user can run against the Kubernetes API server. With RBAC roles, users can create Kubernetes resources, such as app deployments, namespaces, or configmaps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_10290-199554-200837","score":25.7918548584,"text":"\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n--c, --cluster CLUSTER\n: Required. The name or ID of the cluster.\n\n--name NAME\n: Required. The name of the secret to add the field to.\n\n--field CRN\n: Required. The secret CRN to add to the field. You can specify more than one field at a time. For more information, see [Managing non-TLS secret fields](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-secretsnon-tls-field).\n\n\n\n* To pull in the secret with the default field name for the secret type, use the default field option: --field <crn>. This option is available for all non-TLS secret types.\n* To specify the field name, use the named field option: --field name=<crn>. This option is available for arbitrary and IAM credential secret types.\n* To use the IBM Cloud Secrets Manager secret as the prefix, use the prefixed field option: --field prefix=<crn>. This option is available for IAM credential, username and password, and key value secret types.\n\n\n\n--namespace NAMESPACE\n: Required. The namespace that the secret is deployed to.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\nExample to add default, named, and prefixed fields to a set of IAM credentials:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11538-1139-2807","score":18.5998249054,"text":"\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case). And, if you're looking to provide feedback, see [Submitting feedback](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-feedback).\n\n\n\n Providing support case details \n\nTo ensure that the support team can start investigating your case to provide a timely resolution, you must include the architecture name, source URL, and version from your Schematics log.\n\n\n\n1. In the IBM Cloud console, go to Schematics > Workspaces > deployable architecture instance.\n2. Copy and paste into the case details the portion of the log that provides the architecture information. The following is an example of what should be copied:\n\n023\/04\/13 20:50:40 Related Workspace: name=auto-test-infra-osa21-13-04-2023, sourcerelease=(not specified), sourceurl=https:\/\/github.com\/terraform-ibm-modules\/terraform-ibm-powervs-infrastructure\/archive\/v6.2.0.tar.gz, folder=terraform-ibm-powervs-infrastructure-6.2.0\/examples\/ibm-catalog\/deployable-architectures\/full-stack\n\n\n\n\n\n\n\n Routing your support case expeditiously \n\nTo get your support case routed correctly to speed up resolution, make sure that you select the right product when you open the case.\n\nIf you're having issues getting the deployable architecture deployed, use the name of the deployable architecture as it is listed in the catalog.\n\nHowever, if you successfully deployed and are instead having an issue with a service (for example, PowerVS or VPC service) in the deployable architecture, set that service as the product name in the case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap-powervs?topic=sap-powervs-sap-powervs-automation-solution-support"},{"document_id":"ibmcld_11461-1164-2832","score":18.5998249054,"text":"\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case). And, if you're looking to provide feedback, see [Submitting feedback](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-feedback).\n\n\n\n Providing support case details \n\nTo ensure that the support team can start investigating your case to provide a timely resolution, you must include the architecture name, source URL, and version from your Schematics log.\n\n\n\n1. In the IBM Cloud console, go to Schematics > Workspaces > deployable architecture instance.\n2. Copy and paste into the case details the portion of the log that provides the architecture information. The following is an example of what should be copied:\n\n023\/04\/13 20:50:40 Related Workspace: name=auto-test-infra-osa21-13-04-2023, sourcerelease=(not specified), sourceurl=https:\/\/github.com\/terraform-ibm-modules\/terraform-ibm-powervs-infrastructure\/archive\/v6.2.0.tar.gz, folder=terraform-ibm-powervs-infrastructure-6.2.0\/examples\/ibm-catalog\/deployable-architectures\/full-stack\n\n\n\n\n\n\n\n Routing your support case expeditiously \n\nTo get your support case routed correctly to speed up resolution, make sure that you select the right product when you open the case.\n\nIf you're having issues getting the deployable architecture deployed, use the name of the deployable architecture as it is listed in the catalog.\n\nHowever, if you successfully deployed and are instead having an issue with a service (for example, PowerVS or VPC service) in the deployable architecture, set that service as the product name in the case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/powervs-vpc?topic=powervs-vpc-powervs-automation-solution-support"},{"document_id":"ibmcld_08068-0-2916","score":18.4698066711,"text":"\n\n\n\n\n\n\n  Case severity and initial response times \n\nHow quickly your support cases are addressed depends on the assigned severity. You assign the severity of the issue when you open the case. With your agreement, the support team adjusts the assigned severity if an incorrect severity level is selected. For more information about Support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n\nThe following table lists some common examples of support issues, suggested severity levels, and the initial response time objectives. The initial response time objectives are used to describe IBM goals only, and don't represent a performance guarantee.\n\nInitial response Service Level Objectives (SLO) do not apply to any billing, invoice, or sales-related inquiry or cases.\n\nSeverity Level Definition\n\nInitial Response Time Objectives\n\n\n\nTable 1. Case severity definitions\n\n Severity  Business impact  Details                                                                                                                                                                                                                                                                                                                       \n\n 4         Minimal          An inquiry or non-technical request.                                                                                                                                                                                                                                                                                          \n 3         Some             The product, service, or functions are usable, and the issue doesn't represent a significant impact on operations.                                                                                                                                                                                                            \n 2         Significant      A product, service, business feature, or function of the product or service is severely restricted in its use, or you are in jeopardy of missing business deadlines.                                                                                                                                                          \n 1         Critical         System or Service Down  <br>Business-critical functions are inoperable or a critical interface has failed. This usually applies to a production environment and indicates an inability to access products or services that results in a critical impact on operations. This condition requires an immediate solution.         \n\n\n\nWe work with you 24 hours a day and seven days a week to resolve Severity 1 problems if you have a technical resource available to work during those hours. You must reasonably assist with any problem diagnosis and resolution.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity"},{"document_id":"ibmcld_07037-4458-6495","score":16.8415546417,"text":"\n* Business impact so IBM Support understands the urgency of the issue and can prioritize it.\n* Case information for any related cases or a parent case.\n* Software versions of both the Discovery service version and IBM Cloud Pak for Data version.\n* Relevant details about configuration choices that were made during installation and deployment.\n\n\n\n\n\n\n\n Problem description \n\n\n\n* What outcome were you expecting and what happened?\n* Message text that is displayed when the error occurs, especially the document ID, if specified.\n* Steps to take to reproduce the issue.\n* Any screen captures that illustrate the problem.\n* When did the problem occur?\n* Instance ID. (From the IBM Cloud Pak for Data web client main menu, expand Services, and then click Instances. Find your instance, and open its summary page. Scroll to the Access information section of the page, and then copy the URL. The instance ID is part of the URL. You can provide the full URL to IBM Support.)\n* If you are using the API, share example API calls, including the version parameter value that was specified, and the API response body.\n\nDo not share code examples. IBM Support cannot debug custom code.\n* Relevant logs, including the Red Hat OpenShift collector logs.\n\nThe IBM Support representative can share a script with you that collects relevant logs from your cluster.\n* If the problem is related to a particular project or collection, provide the project ID and collection ID.\n\n\n\n* Project ID. (You can copy the Project ID from the API Information tab of the Integrate and deploy page in the product user interface.)\n* Collection ID, if you were able to create a collection. (To get the ID, open the Manage collections page, and then click the collection to open it. From the web browser location field, scroll to the end of the URL. Look for the collections\/ section, and then copy the ID that is displayed after it. For example, in the URL \/collections\/5a525eb7-b175-3820-0000-017d00f0fcd1\/activity, the collection ID is 5a525eb7-b175-3820-0000-017d00f0fcd1.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-get-help"},{"document_id":"ibmcld_04156-0-1820","score":16.6275672913,"text":"\n\n\n\n\n\n\n  Getting help and support for CIS \n\nIf you experience an issue or have questions when using CIS, you can use the following resources before you open a support case.\n\n\n\n*  Review [FAQs](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq) in the product documentation.\n*  Review [Troubleshooting](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-troubleshoot-your-cis-network-connection) to diagnose and resolve common issues.\n*  Check the status of the IBM Cloud platform and resources by going to the [Status page](https:\/\/cloud.ibm.com\/status).\n*  Review [Stack Overflow](https:\/\/stackoverflow.com\/search?q=cis+ibm-cloud) to see whether other users ran into the same problem. If you're using the forum to ask a question, tag your question with ibm-cloud and cis so that it is seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case).\n\n\n\n  Providing support case details for CIS \n\nTo ensure that the support team has all of the details for investigating your issue to provide a timely resolution, you must provide detailed information about your issue. Review the following tips about the type of information to include in your support case for issues with CIS.\n\nProvide the following details:\n\n\n\n1.  Provide your CRN:\n\n\n\n*  In the UI, go to the Overview page\n*  In the CLI, run ibmcloud resource service-instances --long\n\n\n\n2.  Provide your Domain name or ID.\n3.  Depending on the issue the following information might also be helpful:\n\n\n\n*  Account ID: Log into [https:\/\/cloud.ibm.com](https:\/\/cloud.ibm.com) and go to View Profile > Billing\n*  Instance ID: Run the CLI command ibmcloud resource service-instances --long\n*  Geo location\n\n\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-gettinghelp"},{"document_id":"ibmcld_10227-2655-4315","score":16.6063327789,"text":"\n* See [Getting help](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) for more details about using the forums.\n\n\n\n\n\n\n\n\n\n Contacting support \n\nBefore you open a support case, gather relevant information about your cluster environment.\n\n\n\n1. Get your cluster details.\n\nibmcloud oc cluster get -c <cluster_name_or_ID>\n2. If your issue involves worker nodes, get the worker node details.\n\n\n\n1. List all worker nodes in the cluster, and note the ID of any worker nodes with an unhealthy State or Status.\n\nibmcloud oc worker ls -c <cluster_name_or_ID>\n2. Get the details of the unhealthy worker node.\n\nibmcloud oc worker get -w <worker_ID> -c <cluster_name_or_ID>\n\n\n\n3. For issues with resources within your cluster such as pods or services, log in to the cluster and use the Kubernetes API to get more information about them.\n\nYou can also use the [IBM Cloud Kubernetes Service Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool) to gather and export pertinent information to share with IBM Support.\n4. Contact IBM Support by [opening a case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form). To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n5. For the Problem type, search for or select Red Hat OpenShift on IBM Cloud.\n6. For the Case details, provide a descriptive title and include the details that you previously gathered. From the Resources, you can also select the cluster that the issue is related to.\n\n\n\n\n\n\n\n Requesting access to allowlisted features \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help"},{"document_id":"ibmcld_02604-7-2037","score":16.5644073486,"text":"\nUsing the Support Center \n\nNeed help with your API Connect service instance? Visit the IBM Cloud [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) to file a case.\n\n\n\n1. On the Support Center page, look in the \"Contact support\" section and click Create a case.\n2. On the Create a Case page, look in the \"Services\" list and click API Connect.\n\nIt's important to create your case with the correct service so that IBM Support can track the case and assign the appropriate people to help you. The list of services depends on your IBM Cloud account. If you don't see API Connect in the \"Services\" list, you can locate it as follows:\n\n\n\n* Locate the \"What do you need help with?\" section.\n* Review the text in that section and click the view all services link.\n* In the complete list of services, locate API Connect and click it (services are listed in alphabetic order).\n\n\n\n3. Describe your problem.\n\nUse the fields on the \"Create a Case\" page to explain your problem. The following list describes important information that assists us with resolving issues that you are having in API Connect.\n\nImportant: Do not include your private key in the support request.\n\n\n\n* For all issues, include the following information:\n\n\n\n* Region and customer service instance impacted\n* Component impacted: API Manager, API calls, Portal\n* URL where error is being seen\n* For Dedicated, identify the customer environment\n* For Reserved plan, use a prefix in the Subject field to indicate the version (such as v5, v2018 or v10) and provider-org. For example: [v10 - providerOrg].\n\n\n\n* For API Manager UI-based issues, additionally include:\n\n\n\n* All error codes returned\n* Time (including time zone) that the problem occurred\n\n\n\n* For Portal-based issues, additionally include the user name of person who encountered the problem\n* For issues with invoking APIs, additionally include:\n\n\n\n* Full API URL impacted - the host name should contain apiconnect.ibmcloud.com\n* HTTP method used\n* Frequency and time (with time zone) of the issue","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-get_help"},{"document_id":"ibmcld_07395-7-1761","score":16.3902378082,"text":"\nGetting help and support for DNS Services \n\nIf you experience an issue or have questions when using IBM Cloud\u00ae DNS Services, you can use the following resources before you open a support case.\n\n\n\n* Review [FAQs](https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-frequently-asked-questions) in the product documentation.\n* Review [Troubleshooting](https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-troubleshoot-nxdomain) to diagnose and resolve common issues.\n* Check the status of the IBM Cloud platform and resources by going to the [Status page](https:\/\/cloud.ibm.com\/status).\n* Review [Stack Overflow](https:\/\/stackoverflow.com\/search?q=dns-svcs+ibm-cloud) to see whether other users ran into the same problem. If you're using the forum to ask a question, tag your question with ibm-cloud and dns-svcs so that it is seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case).\n\n\n\n Providing support case details for DNS Services \n\nTo ensure that the support team has all of the details for investigating your issue to provide a timely resolution, you must provide detailed information about your issue. Review the following tips about the type of information to include in your support case for issues with DNS Services.\n\nProvide the following details:\n\n\n\n1. The specific IDs of affected VPCs.\n2. The IDs of the DNS Services private resource records (if any).\n3. The IDs of zones that have affected private resource records (if any).\n4. The DNS queries made. If possible, give the details on DNS queries related to the issue, including DNS message ID and timestamp for each.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-gettinghelp"},{"document_id":"ibmcld_08091-5945-8032","score":16.3880271912,"text":"\nFor more information, see [Case severity and initial response times](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity).\n\nYou can change your current support plan at any time by contacting a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative.\n\n\n\n\n\n IBM beta service \n\nIBM releases services or container images that are classified as beta releases. These services are in a trial stage of development and they aren't production-ready. A beta release helps IBM development and marketing teams to assess the value of the service in the market. This assessment enables teams to make updates before the service is released as a GA service or container image.\n\nIf the root cause analysis determines the issue is a defect in the beta service or container image, IBM isn't required to provide a fix. Additionally, the case is assigned the appropriate 3 or 4 severity level.\n\n\n\n\n\n Third-party services \n\nThird-party services are provided by vendors outside of IBM. These services are provided by individual software entities, IBM Business Partners, or independent software vendors (ISV).\n\nSupport for third-party services is provided by the service provider. This includes third-party products that are deployed by using the IBM Cloud Provider Plug-in for Terraform. If the root cause analysis determines that the issue is a defect in a third-party service, IBM isn't required to provide a fix. However, IBM shares analysis with the third-party service provider, if needed, and can work through Marketplace with the third-party service to help solve the issue.\n\n\n\n\n\n Open source or community service \n\nOpen source or community services are provided by open source communities outside of IBM.\n\nIf the root cause analysis determines that the issue is a defect in an open source or community service, IBM isn't required to provide a fix. IBM closes the case and refers you to the community or forum for assistance. You can get community assistance for technical issues through [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar&interface=ui"},{"document_id":"ibmcld_07037-7-2002","score":16.320980072,"text":"\nGetting help \n\nGet help to solve issues that you encounter when you use the product.\n\nUse these resources to get answers to your questions:\n\n\n\n* Walk through a guided tour to learn about a project type or a feature. Click Guided tours from the page header to see a list of available tours.\n* For answers to frequently asked questions, see the [FAQ](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-faqs).\n* Find answers to common questions or ask questions where experts and other community members can answer. Go to the [Watson Discovery Community forum](https:\/\/community.ibm.com\/community\/user\/watsonai\/communities\/community-home?CommunityKey=80650291-2ff4-4a43-9ff8-5188fdb9552f).\n\n\n\n\n\n IBM Cloud Contacting IBM Cloud Support for managed deployments \n\nManaged deployments are deployments that are hosted on IBM Cloud, including IBM Cloud Pak for Data as a Service deployments.\n\nIf your service plan covers it, you can get help by opening a case from [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nBe ready to share the following information with IBM Support:\n\n\n\n Account information \n\n\n\n* Account name or customer name.\n* Business impact so IBM Support understands the urgency of the issue and can prioritize it.\n* Case information for any related cases or a parent case.\n* Cloud location where the service instance is hosted (Dallas, Frankfurt, and so on).\n* Your service plan (Plus, Premium and so on).\n\n\n\n\n\n\n\n Problem description \n\n\n\n* What outcome were you expecting and what happened?\n* Message text that is displayed when the error occurs, especially the document ID, if specified.\n* Steps to take to reproduce the issue.\n* Any screen captures that illustrate the problem.\n* When did the problem occur?\n* Instance ID. (The instance ID is part of the URL that is specified in the Credentials section of the service page on IBM Cloud. You can copy the full URL and provide that.)\n* Collect and share the HTTP archive (HAR) file from your browser.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-get-help"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15845-18362-19949","score":13.8016395569,"text":"\ninvalid_generation_parameter \n\nMessage: The generation query parameter is invalid.\n\nFor versions on and after 5\/31\/2019, the 'generation' query parameter must be set to 1 to allow VPC API requests for use with generation 1 compute resources and set to 2 to allow VPC API requests for use with generation 2 compute resources.\n\nHow to set the generation parameter\n\nIn the CLI: ibmcloud is target --gen 1\n\nIn the API:\n\ncurl -X GET \"$rias_endpoint\/v1\/regions?version=$version&generation=1\"\n-H \"Authorization: $iam_token\"\n\n\n\n\n\n invalid_id_format \n\nMessage: Bad ID format. Ensure format is correct.\n\nMake sure that the ID you provided does not contain any malformed data.\n\nYou may get this error message if you provide a malformed start query when making a pagination request. For example, GET \/v1\/network_acls?start=23fbba08-ceb3-4cbe-a951-84ff20a06069?version=$version&generation=1 contains two ?s. Fix the query and try again.\n\n\n\n\n\n invalid_route \n\nMessage: The requested route does not exist.\n\nThe requested route on the API URL you provided does not exist. Verify that the URL you specified to call the API endpoint is correct.\n\n\n\n\n\n invalid_request_field \n\nMessage: A field provided in the request is not valid.\n\nFor example, to update the network ACL used by a subnet use the PATCH \/v1\/subnets\/{subnet_id}?version=$version&generation=1 -d '{ \"network_acl\":{ \"id\": \u201c{network_acl_id}\u201d } }\u2019 API.\n\nThe following request would be invalid because \u201cnetworkacl\u201d is not a valid field, PATCH \/v1\/subnets\/{subnet_id}?version=$version&generation=1 -d '{ \"networkacl\":{ \"id\": \u201c{network_acl_id}\u201d } }\u2019","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-rias-error-messages"},{"document_id":"ibmcld_16321-14177-15957","score":13.1733160019,"text":"\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_07191-7-2252","score":12.9312314987,"text":"\nQuery parameters \n\nIBM Watson\u2122 Discovery offers powerful content search capabilities through queries. After your content is uploaded and enriched by Discovery, you can build queries, integrate Discovery into your own projects, or create a custom application by using the Watson Explorer Application Builder. To get started with queries, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts). For the complete list of parameters, see the [Query reference](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceparameter-descriptions).\n\nSearch parameters\n\nSearch parameters enable you to search your collection, identify a result set, and perform analysis on the result set.\n\nThe results set is the group of documents identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is performed, the results set is equal to all the documents in the collection.\n\n\n\n query \n\nA query search returns all documents in your data set with full enrichments and full text in order of relevance. A query also excludes any documents that don't mention the query content. These queries are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n\n\n filter \n\nA cacheable query that excludes any documents that don't mention the query content. Filter search results are not returned in order of relevance. These queries are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n Differences between the filter and query parameters \n\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters"},{"document_id":"ibmcld_07191-1691-3739","score":12.783788681,"text":"\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance. The reason is because the filter parameter runs first and caches results, and then the query parameter ranks them. For an example of using filters and queries together, see [Building combined queries](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsbuilding-combined-queries). Filters can also be used in aggregations.\n\nWhen you write a query that includes both a filter, and an aggregation, query, or natural_language_query parameter; the filter parameters run first, after which any aggregation, query, or natural_language_query parameters run in parallel.\n\nWith a simple query, especially on a small data set, filter and query often return the exact same (or similar) results. If a filter and query call return similar results, and getting a response in order of relevance does not matter, it is better to use filter because filter calls are faster and are cached. Caching means that the next time you make that call, you get a much quicker response, particularly in a big data set.\n\n\n\n\n\n\n\n aggregation \n\nAggregation queries return a count of documents matching a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see the [Aggregations table](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-aggregations). These aggregations are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n\n\n natural_language_query","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters"},{"document_id":"ibmcld_13446-17996-19881","score":12.4535894394,"text":"\nFor more information, see [Processing metrics](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metricsprocessing-metrics).\n\n\n\nTable 20. The processing_metrics_interval parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Not available. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Not supported \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n profanity_filter \n\nAn optional boolean that indicates whether the service censors profanity from a transcript. By default (true), profanity is filtered from the transcript. For more information, see [Profanity filtering](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-formattingprofanity-filtering).\n\n\n\nTable 21. The profanity_filter parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for US English and Japanese. \n Next-generation models Generally available for US English and Japanese. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n redaction \n\nAn optional boolean that indicates whether the service redacts numeric data with three or more consecutive digits from a transcript. By default (false), numeric data is not redacted. If you set the redaction parameter to true, the service automatically forces the smart_formatting parameter to be true, and it disables the keywords, keywords_threshold, max_alternatives, and (for the WebSocket interface) interim_results parameters. For more information, see [Numeric redaction](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-formattingnumeric-redaction).\n\n\n\nTable 22. The redaction parameter\n\n Availability and usage Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"},{"document_id":"ibmcld_09789-17320-17867","score":12.3084287643,"text":"\nOpsGenie OPSGENIE \n\n\n\n\n\n\n\n version (integer) \n\nVersion of an notification.\n\nThe version changes every time you update an notification.\n\nThe version is used for optimistic locking.\n\n\n\n\n\n\n\n Query parameters \n\n\n\n notificationId (integer) \n\nID of an notification.\n\n\n\n\n\n from (long) \n\nDefines the start timestamp, in microseconds, that is used when you request information about notifications that are defined.\n\n\n\n\n\n to (long) \n\nDefines the end timestamp, in microseconds, that is used when you request information about notifications that are defined.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-notifications_api"},{"document_id":"ibmcld_12845-3742-5554","score":12.2083454132,"text":"\n: An array of selected values that are associated with the custom parameter that you want to interact with. This parameter shows in the UI when one of those values is selected.\n\nparameters.associations.parameters.optionsRefresh\n: When this parameter is set to true, the optionsUrl is called when the associated parameter value is changed and this parameter is visible in the UI.\n\nparameters.optionsUrl\n: The API that is called by the console to get a list of options for dropdown, check box, or radio input type. The response is a JSON structure that contains two fields:\n\noptions\n: An array of JSON that will return parameters.options; for more details see the entry for parameters.options.\n\nvalue\n: The new default value of the parameter. For more details, see the entry for parameters.value.\n\nThe console passes the ace_config query parameter, which contains the current org GUID, space GUID, the current value of all custom parameters, and the current price plan ID. The bearer token is propagated in the header.\n\nparameters.invalidmessage\n: The message that appears when the content of the text box is invalid.\n\nparameters.description\n: The description of the parameter that is displayed to help users with the value of the parameter.\n\nparameters.required\n: A Boolean value that indicates whether the parameter must be entered in the IBM Cloud user interface.\n\nparameters.pattern\n: A regular expression that the value is checked against.\n\nparameters.placeholder\n: A short hint that describes the expected value.\n\nparameters.readonly\n: A Boolean value that indicates whether the value of the parameter is displayed only and cannot be changed by users. The default value is false.\n\nparameters.hidden\n: A Boolean value that indicates whether the key-value pair is hidden from users. The default value is false.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service_parameters_def_examples"},{"document_id":"ibmcld_09701-13735-14292","score":11.9728384018,"text":"\nThe value of this parameter must be a multiple of 60000000 microseconds.\n\n\n\n\n\n version (integer) \n\nVersion of an alert.\n\nThe version changes every time you update an alert.\n\nThe version is used for optimistic locking.\n\n\n\n\n\n\n\n Query parameters \n\n\n\n alertId (integer) \n\nID of an alert.\n\n\n\n\n\n from (long) \n\nDefines the start timestamp, in microseconds, that is used when you request information about alerts that are defined.\n\n\n\n\n\n to (long) \n\nDefines the end timestamp, in microseconds, that is used when you request information about alerts that are defined.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_02991-7-2062","score":11.9091415405,"text":"\nFilter query reference \n\nThe Watson Assistant service REST API offers powerful log search capabilities through filter queries. You can use the v2 \/logs API filter parameter to search your skill log for events that match a specified query.\n\nThe filter parameter is a cacheable query that limits the results to those matching the specified filter. You can filter on various objects that are part of the JSON response model (for example, the user input text, the detected intents and entities, or the confidence score).\n\nTo see examples of filter queries, see [Examples](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-referencefilter-reference-examples).\n\nThe ability to access logs was introduced with version 1.5.0.\n\nFor more information about the \/logs GET method and its response model, refer to the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v2listlogs).\n\n\n\n Filter query syntax \n\nThe following example shows the general form of a filter query:\n\n\n\n Location Query operator Term \n\n request.input.text :: \"IBM Watson\" \n\n\n\n\n\n* The location identifies the field that you want to filter on (in this example, request.input.text).\n* The query operator, which specifies the type of matching you want to use (fuzzy matching or exact matching).\n* The term specifies the expression or value you want to use to evaluate the field for matching. The term can contain literal text and operators, as described in the [next section](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-referencefilter-reference-operators).\n\n\n\nFiltering by intent or entity requires slightly different syntax from filtering on other fields. For more information, see [Filtering by intent or entity](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-referencefilter-reference-intent-entity).\n\nNote: The filter query syntax uses some characters that are not allowed in HTTP queries. Make sure that all special characters, including spaces and quotation marks, are URL encoded when sent as part of an HTTP query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-filter-reference"},{"document_id":"ibmcld_00331-49237-50377","score":11.9024629593,"text":"\nIf set to 1, query strings are removed from a URL when computing the token\u2019s HMAC algorithm. Default value is 0.\n* tokenDelimiter - Specifies a single character to separate the individual token fields.\n* aclDelimiter - Specifies a single character to separate access control list (ACL) fields.\n* hmacAlgorithm - Specifies the algorithm to use for the token\u2019s hash-based message authentication code (HMAC) field.\n* transitionKey - The token transition key, which specifies an even number of hex digits for the token transition key. An entry can be up to 64 characters in length.\n\n\n\n* Returns - An object of type SoftLayer_Container_Network_CdnMarketplace_Configuration_Behavior_TokenAuth.\n\n\n\n--------------------\n\n\n\n\n\n deleteTokenAuth \n\nDelete an existing Token Authentication behavior for an existing domain mapping and returns the updated behavior.\n\n\n\n* Parameters:\n\n\n\n* uniqueId - (Required) The unique ID of the mapping to which this origin path belongs.\n* path - (Required) Token Authentication Path to be deleted.\n\n\n\n* Return - A status message if the deletion was successful; otherwise, an exception is thrown.\n\n\n\n--------------------","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-cdn-api-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.4981892575,"ndcg_cut_10":0.4981892575}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13455-7-1568","score":18.9450244904,"text":"\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the \/v1\/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13790-7-1700","score":18.8940448761,"text":"\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its \/v1\/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST \/v1\/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_16321-14177-15957","score":18.5721607208,"text":"\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_13432-6305-8426","score":17.1569385529,"text":"\nThe WebSocket protocol is lightweight. It requires only a single connection to perform live-speech recognition.\n* Enables audio to be streamed directly from browsers (HTML5 WebSocket clients) to the service.\n* Returns results as soon as they are available when you use a next-generation model or request interim results.\n\n\n\n\n\n\n\n\n\n Using speech recognition parameters \n\nThe service's speech recognition interfaces share largely common parameters for transcribing speech to text. The parameters let you tailor aspects of your request, such as whether the data is streamed or sent all at once, and the information that the service includes in its response.\n\nThe following sections introduce the speech recognition parameters and their functionality. Some parameters are available only for some speech recognition interfaces or for some languages and models. For information about all parameters and their interface and language support, see the [Parameter summary](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary).\n\n\n\n Audio transmission and timeouts \n\n\n\n* [Audio transmission](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtransmission) describes how you can pass audio as a continuous stream of data chunks or as a one-shot delivery that passes all of the data at one time. With the WebSocket interface, audio data is always streamed to the service over the connection. With the HTTP interfaces, you can stream the audio or send it all at once.\n* [Timeouts](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtimeouts) are used by the service to ensure an active flow of data during audio streaming. When you initiate a streaming session, the service enforces inactivity and session timeouts from which your application must recover gracefully. If a timeout lapses during a streaming session, the service closes the connection.\n\n\n\n\n\n\n\n Interim results and low latency \n\n\n\n* [Interim results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-interiminterim-results) are intermediate hypotheses that the service returns as transcription progresses.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-features"},{"document_id":"ibmcld_13429-163247-165127","score":17.0458259583,"text":"\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https:\/\/github.com\/watson-developer-cloud\/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13790-1284-2889","score":16.3628501892,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13455-26115-26611","score":16.2240009308,"text":"\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13297-4312-5935","score":16.0035533905,"text":"\nTo use the WebSocket interface, you first use the \/v1\/recognize method to establish a connection with the service. You specify parameters such as the language model and any custom models that are to be used for requests that are sent over the connection. You then register event listeners to handle responses from the service. To make a request, you send a JSON text message that includes the audio format and any additional parameters. You pass the audio as a binary message (blob), and then send a text message to signal the end of the audio.\n\nThe following example provides JavaScript code that establishes a connection and sends the text and binary messages for a recognition request. The basic example does not include the code to define all of the necessary event handlers for the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token;\nvar websocket = new WebSocket(wsURI);\n\nwebsocket.onopen = function(evt) { onOpen(evt) };\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/flac'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\nwebsocket.send(JSON.stringify({action: 'stop'}));\n}\nShow more\n\n\n\n\n\n Using the synchronous HTTP interface \n\n[The synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http) provides the simplest way to make a recognition request. You use the POST \/v1\/recognize method to make a request to the service. You pass the audio and all parameters with the single request. The following curl example shows a basic HTTP recognition request:\n\nIBM Cloud","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-basic-request"},{"document_id":"ibmcld_13361-1589-2935","score":15.7362070084,"text":"\n* For the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the \/v1\/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n\nYou then specify the name of the grammar with the grammar_name parameter in the JSON start message for the active connection. Passing this value with the start message allows you to change the grammar dynamically for each request that you send over the connection.\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/l16;rate=22050',\ngrammar_name: '{grammar_name}'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n* For the [synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http), pass both parameters with the POST \/v1\/recognize method.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio\/flac\" --data-binary @audio-file.flac \"{url}\/v1\/recognize?language_customization_id={customization_id}&grammar_name={grammar_name}\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse"},{"document_id":"ibmcld_10833-0-1231","score":15.3665456772,"text":"\n\n\n\n\n\n\n  WebSocket \n\nThe preinstalled \/whisk.system\/websocket package for IBM Cloud\u00ae Functions offers a convenient way to post messages to a WebSocket.\n\nThe package includes the following actions.\n\n\n\nTable 1. WebSocket package entities\n\n Entity                          Type     Parameters        Description                                 \n\n \/whisk.system\/websocket         Package  uri               Utilities for communicating with WebSockets \n \/whisk.system\/websocket\/send    Action   uri, payload      Send the payload to the WebSocket URI.      \n\n\n\nIf you plan to send many messages to the same WebSocket URI, creating a package binding with the uri value is suggested. With binding, you don't need to specify the value each time that you use the send action.\n\n\n\n  Send a message to a WebSocket \n\nThe \/whisk.system\/websocket\/send action sends a payload to a WebSocket URI. The parameters are as follows.\n\n\n\nTable 2. WebSocket send action parameters\n\n Parameter  Description                                                                \n\n uri        The URI of the WebSocket server. For example, ws:\/\/mywebsockethost:80.     \n payload    The message to send to the WebSocket.                                      \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocket"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.8503449055,"ndcg_cut_10":0.8503449055}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16321-14177-15957","score":21.6738929749,"text":"\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_13455-7-1568","score":21.1203308105,"text":"\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the \/v1\/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13297-4312-5935","score":20.9753437042,"text":"\nTo use the WebSocket interface, you first use the \/v1\/recognize method to establish a connection with the service. You specify parameters such as the language model and any custom models that are to be used for requests that are sent over the connection. You then register event listeners to handle responses from the service. To make a request, you send a JSON text message that includes the audio format and any additional parameters. You pass the audio as a binary message (blob), and then send a text message to signal the end of the audio.\n\nThe following example provides JavaScript code that establishes a connection and sends the text and binary messages for a recognition request. The basic example does not include the code to define all of the necessary event handlers for the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token;\nvar websocket = new WebSocket(wsURI);\n\nwebsocket.onopen = function(evt) { onOpen(evt) };\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/flac'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\nwebsocket.send(JSON.stringify({action: 'stop'}));\n}\nShow more\n\n\n\n\n\n Using the synchronous HTTP interface \n\n[The synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http) provides the simplest way to make a recognition request. You use the POST \/v1\/recognize method to make a request to the service. You pass the audio and all parameters with the single request. The following curl example shows a basic HTTP recognition request:\n\nIBM Cloud","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-basic-request"},{"document_id":"ibmcld_13790-7-1700","score":20.8204250336,"text":"\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its \/v1\/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST \/v1\/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_03285-13886-15581","score":18.955537796,"text":"\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_13364-10437-12131","score":18.4467754364,"text":"\nYou pass all audio via the body of the request and specify the parameters as request headers and query parameters.\n\nThe method returns results only after it processes all of the audio for a request. The method is appropriate for batch processing but not for live speech recognition. Use the WebSocket interface to transcribe live audio.\n\nIf your data consists of multiple audio files, the recommended means of submitting the audio is by sending multiple requests, one for each audio file. You can submit the requests in a loop, optionally with parallelism to improve performance. You can also use multipart speech recognition to pass multiple audio files with a single request.\n\n\n\n Basic request example \n\nThe following example sends a recognition request for a single FLAC file named audio-file.flac. The request omits the model query parameter to use the default language model, en-US_BroadbandModel. For more information, see [Using the default model](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-usemodels-use-default).\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio\/flac\" --data-binary @{path}audio-file.flac \"{url}\/v1\/recognize\"\n\nIBM Cloud Pak for Data\n\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type: audio\/flac\" --data-binary @{path}audio-file.flac \"{url}\/v1\/recognize\"\n\nThe example returns the following transcript for the audio:\n\n{\n\"result_index\": 0,\n\"results\": [\n{\n\"alternatives\":\n{\n\"confidence\": 0.96,\n\"transcript\": \"several tornadoes touch down as a line of severe thunderstorms swept through Colorado on Sunday \"\n}\n],\n\"final\": true\n}\n]\n}\n\n\n\n\n\n\n\n Making a multipart HTTP speech recognition request","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http"},{"document_id":"ibmcld_13361-1589-2935","score":18.3648052216,"text":"\n* For the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the \/v1\/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n\nYou then specify the name of the grammar with the grammar_name parameter in the JSON start message for the active connection. Passing this value with the start message allows you to change the grammar dynamically for each request that you send over the connection.\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/l16;rate=22050',\ngrammar_name: '{grammar_name}'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n* For the [synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http), pass both parameters with the POST \/v1\/recognize method.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio\/flac\" --data-binary @audio-file.flac \"{url}\/v1\/recognize?language_customization_id={customization_id}&grammar_name={grammar_name}\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse"},{"document_id":"ibmcld_13429-109689-111379","score":18.1636734009,"text":"\n* DELETE \/v1\/customizations\/{customization_id}\/grammars\/{grammar_name} removes an existing grammar from a custom model.\n\n\n\nYou can use a grammar for speech recognition with the WebSocket and HTTP interfaces. Use the language_customization_id and grammar_name parameters to identify the custom model and the grammar that you want to use. Currently, you can use only a single grammar with a speech recognition request.\n\nFor more information about grammars, see the following documentation:\n\n\n\n* [Using grammars with custom language models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammars)\n* [Understanding grammars](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUnderstand)\n* [Adding a grammar to a custom language model](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarAdd)\n* [Using a grammar for speech recognition](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse)\n* [Managing grammars](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-manageGrammars)\n* [Example grammars](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarExamples)\n\n\n\nFor information about all methods of the interface, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nNew numeric redaction feature for US English, Japanese, and Korean now available\n: A new numeric redaction feature is now available to mask numbers that have three or more consecutive digits. Redaction is intended to remove sensitive personal information, such as credit card numbers, from transcripts. You enable the feature by setting the redaction parameter to true on a recognition request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13455-26115-26611","score":17.9553871155,"text":"\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_03285-12413-14528","score":17.8867607117,"text":"\n\"parameter name\": \"parameter value\",\n\"parameter name\": \"parameter value\"\n}\n}\n}\n]\n}\n}\nShow more\n\n\n\nEach command type along with its related parameters are described in the following sections.\n\n\n\n command_info.type : configure \n\nDynamically reconfigures the Text to Speech service by applying a set of configuration parameters, which can be based on the dialog or action flow. For example, you might want to choose a particular voice at a specific point in the conversation.\n\n\n\n parameter description required default \n\n synthesize The Text to Speech service configuration to use when synthesizing audio. The parameters defined by this object are used when connecting to the Text to Speech service for speech synthesis requests. For more information about these parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speechsynthesize-audio-websockets-). yes Current Text to Speech configuration \n update_strategy Specifies the update strategy to use when setting the speech configuration. Possible values include:<br><br><br><br> * replace: Replaces the configuration for the rest of the session. Any root-level fields in the new configuration completely overwrite the previous configuration.<br> * replace_once: Replaces the configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.75,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.60961995,"ndcg_cut_10":0.7397466333}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13386-1713-3820","score":17.344625473,"text":"\n* customization_id identifies the custom model's Globally Unique Identifier (GUID). The GUID is used to identify the model in methods of the interface.\n* created is the date and time in Coordinated Universal Time (UTC) at which the custom model was created.\n* updated is the date and time in Coordinated Universal Time (UTC) at which the custom model was last modified.\n* language is the language of the custom model.\n* owner identifies the credentials of the service instance that owns the custom model.\n* name is the name of the custom model.\n* description shows the description of the custom model, if one was provided at its creation.\n* base_model_name indicates the name of the language model for which the custom model was created.\n* versions provides a list of the available versions of the custom model. Each element of the array indicates a version of the base model with which the custom model can be used. Multiple versions exist only if the custom model is upgraded to a new version of its base model. Otherwise, only a single version is shown. For more information, see [Listing version information for a custom model](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-custom-upgrade-usecustom-upgrade-use-listing).\n\n\n\nThe methods also return a status field that indicates the state of the custom model:\n\n\n\n* pending indicates that the model was created. It is waiting either for valid training data (audio resources) to be added or for the service to finish analyzing data that was added.\n* ready indicates that the model contains valid audio data and is ready to be trained. If the model contains a mix of valid and invalid audio resources, training of the model fails unless you set the strict query parameter to false. For more information, see [Training failures](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-acousticfailedTraining-acoustic).\n* training indicates that the model is being trained on audio data.\n* available indicates that the model is trained and ready to use with recognition requests.\n* upgrading indicates that the model is being upgraded.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-manageAcousticModels"},{"document_id":"ibmcld_13396-1754-3852","score":17.170873642,"text":"\n* customization_id identifies the custom model's Globally Unique Identifier (GUID). The GUID is used to identify the model in methods of the interface.\n* created is the date and time in Coordinated Universal Time (UTC) at which the custom model was created.\n* updated is the date and time in Coordinated Universal Time (UTC) at which the custom model was last modified.\n* language is the language of the custom model. The value matches the language identifier from the name of the base model. For example, en-US for a US English language model.\n* dialect is the dialect of the language for the custom model, which does not necessarily match the language of the custom model for previous-generation Spanish models. For more information, see the description of the dialect field in [Create a custom language model](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-languageCreatecreateModel-language).\n* owner identifies the credentials of the service instance that owns the custom model.\n* name is the name of the custom model.\n* description shows the description of the custom model, if one was provided at its creation.\n* base_model indicates the name of the language model for which the custom model was created.\n* versions provides a list of the available versions of the custom model. Each element of the array indicates a version of the base model with which the custom model can be used. Multiple versions exist only if the custom model is upgraded to a new version of its base model. Otherwise, only a single version is shown. For more information, see [Listing version information for a custom model](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-custom-upgrade-usecustom-upgrade-use-listing).\n\n\n\nThe method also returns a status field that indicates the state of the custom model:\n\n\n\n* pending indicates that the model was created. It is waiting either for valid training data (corpora, words, or grammars) to be added or for the service to finish analyzing data that was added.\n* ready indicates that the model contains valid data and is ready to be trained.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-manageLanguageModels"},{"document_id":"ibmcld_13800-4975-5531","score":17.1197605133,"text":"\n\"customization_id\": \"64f4807f-a5f1-5867-924f-7bba1a84fe97\",\n\"owner\": \"297cfd08-330a-22ba-93ce-1a73f454dd98\",\n\"created\": \"2017-09-16T17:12:31.743Z\",\n\"name\": \"Customization test\",\n\"language\": \"en-US\",\n\"description\": \"Customization test\",\n\"last_modified\": \"2017-09-16T17:12:31.743Z\"\n}\n}\nShow more\n\nTo see the custom words and prompts that the model includes, use the GET \/v1\/customizations\/{customization_id} method. For more information, see [Querying a custom model](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customModelscuModelsQuery).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices-list"},{"document_id":"ibmcld_13652-8279-9663","score":17.0667858124,"text":"\n\"customization_id\": \"63f5807f-a4f2-5766-914e-7abb1a84fe97\",\n\"owner\": \"297cfd08-330a-22ba-93ce-1a73f454dd98\",\n\"created\": \"2016-07-15T18:12:31.743Z\",\n\"name\": \"Test Two\",\n\"language\": \"en-US\",\n\"description\": \"Second customization test\",\n\"last_modified\": \"2016-07-15T18:23:50.912Z\"\n}\n]\n}\nShow more\n\nThe created and last_modified times for the first model are the same because it has yet to be updated. The times for the second model are different, indicating that it has been changed since its initial creation. The information does not include the custom entries defined for the models.\n\n\n\n\n\n Updating a custom model \n\nTo update information about a custom model, use the POST \/v1\/customizations\/{customization_id} method. You specify the updates as a JSON object. In addition to modifying its name and description, you can also use this method to add or update word\/translation pairs in the model. You cannot change a model's language once it is created.\n\nThe following example updates the name and description of a custom model. An empty JSON array is sent with the words parameter to indicate that the model's entries are to remain unchanged.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data \"{\"name\":\"Test Update\", \"description\":\"Customization test update\", \"words\":[]}\" \"{url}\/v1\/customizations\/{customization_id}\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customModels"},{"document_id":"ibmcld_02753-7-2147","score":16.5528450012,"text":"\nCustomizing tokens \n\nWith App ID, tokens are used to identify users and secure your resources. You can choose to customize the information that is injected in to the tokens by the service. By injecting the information into your tokens, it's available to your application at run time without you having to configure extra network calls. For more information about tokens and how they're used in App ID, see [Understanding tokens](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-tokens).\n\nBy customizing your token configuration, you can ensure that your security and user experience needs are met. However, should a token ever become compromised, a malicious user might have more information or time that can be used to affect your application. Be sure that you understand the security implications of the customizations that you want to make before you make them.\n\n\n\n Understanding custom claims mapping \n\nA claim is a statement that an entity makes about itself or on behalf of someone else. For example, if you signed into an application by using an identity provider, the provider would send the application a group of claims or statements about you to the app so that it can group with information that it already knows about you. This way, when you sign in, the app is set up with your information, in the way that you configured it.\n\n\n\n What types of claims can I define? \n\nThe claims that are provided by App ID fall into several categories that are differentiated by their level of customization.\n\nNormalized claims\n: In each identity token, there is a set of claims that is recognized by App ID as normalized. When available, the claims are mapped directly from your identity provider to the token by default. The claims can't be explicitly omitted but they can be overwritten in your token by custom claims. The claims include name, email, picture, and locale.\n\nRestricted claims\n: Restricted claims are those that have limited customization possibilities and cannot be overwritten by custom mappings. For an access token, scope is the only restricted claim. Although it cannot be overwritten, it can be extended with your own scope.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-customizing-tokens"},{"document_id":"ibmcld_07174-18238-20370","score":16.3887214661,"text":"\n* column_header_texts_normalized: If you provide customization input, the normalized version of the column header texts according to the customization; otherwise, the same value as column_header_texts.\n* attributes: An array that identifies document attributes. Each object in the array consists of three elements:\n\n\n\n* type: The type of attribute. Possible values are Address, Currency, DateTime, Duration, Location, Number, Organization, Percentage, and Person.\n* text: The text that is associated with the attribute.\n* location: The location of the attribute as defined by its begin and end indexes.\n\n\n\n\n\n* key_value_pairs: An array that specifies any key-value pairs in tables in the input document.\n\n\n\n* key: An object that specifies a key for a key-value pair.\n\n\n\n* cell_id: The unique ID of the key in the table.\n* location: The location of the key cell in the input document as defined by its begin and end indexes.\n* text: The text content of the table cell without HTML markup.\n\n\n\n* value: An array that specifies the value or values for a key-value pair.\n\n\n\n* cell_id: The unique ID of the value in the table.\n* location: The location of the value cell in the input document as defined by its begin and end indexes.\n* text: The text content of the table cell without HTML markup.\n\n\n\n\n\n* contexts: A list of related material that precedes and follows the table, excluding its section title, which is provided in the section_title field. Related material includes related sentences; footnotes; and sentences from other parts of the document that refer to the table. The list is represented as an array. Each object in the array consists of the following elements:\n\n\n\n* text: The text contents of a related material from the input document, without HTML markup.\n* location: The location of the related material in the input document as defined by its begin and end indexes.\n\n\n\n\n\n* document_structure: An object that describes the structure of the input document.\n\n\n\n* section_titles: An array that contains one object per section or subsection that is detected in the input document. Sections and subsections are not nested.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-output_schema"},{"document_id":"ibmcld_07174-15220-17206","score":16.2385959625,"text":"\n* text_normalized: If you provide customization input, the normalized version of the cell text according to the customization; otherwise, the same value as text.\n* row_index_begin: The begin index of the cell's row location in the current table.\n* row_index_end: The end index of the cell's row location in the current table.\n* column_index_begin: The begin index of the cell's column location in the current table.\n* column_index_end: The end index of the cell's column location in the current table.\n\n\n\n* column_headers: An array of column-level cells, each applicable as a header to other cells in the same column as itself, of the current table. Each column header is defined as a collection of the following items:\n\n\n\n* cell_id: The unique ID of the cell in the current table.\n* location: The location of the cell in the input document as defined by its begin and end indexes.\n* text: The textual contents of the cell from the input document without associated markup content.\n* text_normalized: If you provide customization input, the normalized version of the cell text according to the customization; otherwise, the same value as text.\n* row_index_begin: The begin index of the cell's row location in the current table.\n* row_index_end: The end index of the cell's row location in the current table.\n* column_index_begin: The begin index of the cell's column location in the current table.\n* column_index_end: The end index of the cell's column location in the current table.\n\n\n\n* body_cells: An array of cells that are not table header or column header or row header cells, of the current table with corresponding row and column header associations. Each body cell is defined as a collection of the following items:\n\n\n\n* cell_id: The unique ID of the cell in the current table.\n* location: The location of the cell in the input document as defined by its begin and end indexes.\n* text: The textual contents of the cell from the input document without associated markup content.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-output_schema"},{"document_id":"ibmcld_13652-4903-6514","score":16.1131153107,"text":"\nIt cannot, however, be used with an en-GB voice.\n\ndescription (optional string)\n: A recommended description of the new custom model.\n\n\n\n* Use a localized description that matches the language of the custom model.\n* Include a maximum of 128 characters in the description.\n\n\n\nThe following example example creates a new US English custom model named Test. The required Content-Type header identifies the type of the input as application\/json.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data \"{\"name\":\"Test\", \"language\":\"en-US\", \"description\":\"Customization test\"}\" \"{url}\/v1\/customizations\"\n\nIBM Cloud Pak for Data\n\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type: application\/json\" --data \"{\"name\":\"Test\", \"language\":\"en-US\", \"description\":\"Customization test\"}\" \"{url}\/v1\/customizations\"\n\nThe method returns a JSON object that contains a globally unique identifier (GUID) for the new model. The GUID is used as the customization_id parameter in calls to access the model, such as those for querying, modifying, and using the model and its words.\n\n{\n\"customization_id\": \"64f4807f-a5f1-5867-924f-7bba1a84fe97\"\n}\n\n\n\n\n\n Querying a custom model \n\nTo query information about an existing custom model, use the GET \/v1\/customizations\/{customization_id} method. This is the most direct means of seeing all of the information about a model, including its metadata and the word\/translation pairs and custom prompts that it contains.\n\nIBM Cloud\n\ncurl -X GET -u \"apikey:{apikey}\" \"{url}\/v1\/customizations\/{customization_id}\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customModels"},{"document_id":"ibmcld_13645-7-1414","score":15.9121351242,"text":"\nUsing a custom model for speech synthesis \n\nOnce you create a custom model and populate it with custom entries, you use it by passing its customization ID (GUID) with the customization_id query parameter of the HTTP GET or POST \/v1\/synthesize method or the WebSocket \/v1\/synthesize method. When you include a customization ID, you must call a synthesize method with credentials for the instance of the service that owns the specified custom model.\n\n\n\n Examples of using a custom model \n\nThe first two examples generate a custom pronunciation for IEEE that is based on entries from the indicated custom model. The custom pronunciation is used instead of the default pronunciation from the service's regular pronunciation rules.\n\n\n\n* The HTTP GET \/v1\/synthesize method:\n\nIBM Cloud\n\ncurl -X GET -u \"apikey:{apikey}\" --header \"Accept: audio\/flac\" --output ieee.flac \"{url}\/v1\/synthesize?text=IEEE&customization_id={customization_id}\"\n\nIBM Cloud Pak for Data\n\ncurl -X GET --header \"Authorization: Bearer {token}\" --header \"Accept: audio\/flac\" --output ieee.flac \"{url}\/v1\/synthesize?text=IEEE&customization_id={customization_id}\"\n* The HTTP POST \/v1\/synthesize method:\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --header \"Accept: audio\/flac\" --data \"{\"text\":\"IEEE\"}\" --output ieee.flac \"{url}\/v1\/synthesize?customization_id={customization_id}\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-custom-using"},{"document_id":"ibmcld_16321-8823-10365","score":15.8367033005,"text":"\n\"smart_formatting\": true,\n\"language_customization_id\": \"81d3630-ba58-11e7-aa4b-41bcd3f6f24d\",\n\"acoustic_customization_id\": \"e4766090-ba51-11e7-be33-99bd3ac8fa93\"\n}\n}\n}\n}\n]\n}\nShow more\n\nYou can also apply an acoustic model that you might have trained to deal with background noise, accents, or other things that are associated with the quality or noise of the signal.\n\n\n\n\n\n Using a custom grammar \n\nThe Speech to Text service supports the use of grammars. A grammar allows you to configure the audio to match specific characteristics only.\n\nYou can think of it this way:\n\n\n\n* A custom language model expands the service's base vocabulary.\n* A grammar restricts the words that the service can recognize from that vocabulary.\n\n\n\nWhen you use a grammar with a custom language model for speech recognition, the service can recognize only words, phrases, and strings that are recognized by the grammar. For example, maybe you want to accept only a yes or no response. You can define a grammar that allows only those options.\n\nFor more information, see [Using grammars with custom language models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammars).\n\nThis example shows how to specify a custom grammar during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"speech_to_text\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"update_strategy\": \"merge_once\",\n\"narrowband_recognize\": {\n\"x-watson-learning-opt-out\": true,\n\"grammar_name\": \"names-abnf\",\n\"language_customization_id\": \"81d3630-ba58-11e7-aa4b-41bcd3f6f24d\"\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16291-1353-3298","score":18.4876232147,"text":"\nClick Users, and then locate and click the user account you want to use for the integration.\n4. Click the Access Keys tab.\n5. Click Generate New Access Key.\n6. Click Show Secret Key, and copy the secret key to a secure location.\n\nYou cannot retrieve the secret key again after you complete the next step and Save. You must generate a new key if the current one is lost or forgotten.\n7. Click Save.\n\n\n\n\n\n\n\n Set up the integration \n\nTo complete setup, you must have an assistant ready to deploy, your NICE CXone access keys, and phone numbers allocated for this integration.\n\nTo integrate your assistant with NICE CXone:\n\n\n\n1. In the Integrations section on the main page for your assistant under Essential Channels, you will see a tile for Phone.\n2. On the Phone tile, click Add.\n3. On the pop-up window, click Add again.\n4. Select NICE CXone on the Select contact center page.\n\nClick Next.\n5. On the Connect to contact center page, specify the following values: - the Authentication URL from NICE CXone - the API URL, which is the Admin API endpoint from NICE CXone - the Access key ID - the Access key secret\n\nClick Test connection to verify the credentials.\n\nClick Next.\n6. On the Phone number page, enter a phone number you allocated for the NICE CXone integration. You can add more phone numbers later.\n\nClick Next.\n7. On the Speech to Text page, select the instance of the Speech to Text service you want to use.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus or Enterprise instance.\n\n\n\n8. In the Choose your Speech to Text language model field, select the language you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"},{"document_id":"ibmcld_16298-1254-2469","score":17.2429237366,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/zd-products-menu.png)\n6. Click your profile, and then select Check Connection.\n\n![Screen capture of the Zendesk user interface to show where the profile is located.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/zd-profile-menu.png)\n7. Keep this open for the Connect Zendesk to your assistant step.\n\n![Screen capture of the connection dialog.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/zd-account-key.png)\n\n\n\nYou also need to decide whether to enable security for Zendesk after setup. More info at [Securing the transfer to Zendesk](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-zendeskdeploy-zendesk-secure).\n\n\n\n\n\n Setting up the Zendesk service desk connection \n\nIn your Watson Assistant install:\n\n\n\n1. Go to the Integrations page by clicking the integrations icon (![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)) in the left menu.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-zendesk"},{"document_id":"ibmcld_16291-7-1781","score":16.8766841888,"text":"\nIntegrating with phone and NICE CXone contact center ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/plus.png) \n\nIBM Cloud\n\nConnect your assistant to a NICE CXone contact center with live agents.\n\nTransfer customers from a chat with your assistant to live agents who can help them by phone. If customers ask to speak to someone, your assistant can forward them directly to customer support with the conversation history.\n\nThis integration creates a connection between your assistant and a contact center using NICE CXone.\n\nYou need a Plus or Enterprise Plan to use this feature.\n\n\n\n Before you begin \n\nYou must have a NICE CXone account and phone numbers allocated for this integration.\n\n\n\n1. Go to the [NICE website](https:\/\/www.nice.com\/).\n2. Create an account.\n3. Follow the instructions to get phone numbers or select existing phone numbers.\n\n\n\n\n\n\n\n Generate NICE CXone access keys \n\nAccess keys are used for authentication and consist of two parts: an access key ID and a secret access key.\n\nTo generate NICE CXone access keys to use with your assistant:\n\n\n\n1. Log in to the NICE CXone console.\n2. Click the app selector ![appselectoricon.png](https:\/\/help.nice-incontact.com\/content\/resources\/images\/icons\/appselectoricon.png) and select Admin.\n3. Click Users, and then locate and click the user account you want to use for the integration.\n4. Click the Access Keys tab.\n5. Click Generate New Access Key.\n6. Click Show Secret Key, and copy the secret key to a secure location.\n\nYou cannot retrieve the secret key again after you complete the next step and Save. You must generate a new key if the current one is lost or forgotten.\n7. Click Save.\n\n\n\n\n\n\n\n Set up the integration","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"},{"document_id":"ibmcld_16288-1733-3996","score":16.6500377655,"text":"\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16297-7-1893","score":16.6452102661,"text":"\nIntegrating with WhatsApp \n\nIBM Cloud\n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the Develop tab, click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\nKeep the Twilio web page open in a web browser tab so you can refer to it again later.\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1. To register, go to the [Facebook Business Manager](https:\/\/business.facebook.com\/overview) website, and click Create account. Follow the instructions to create an account.\n2. Get your Facebook Business Manager ID. In [Settings](https:\/\/business.facebook.com\/settings), click the Business info tab. The Facebook Business Manager ID is at the top of the page.\n3. Submit the Request to enable your Twilio numbers for WhatsApp form from the [Twilio API for WhatsApp](https:\/\/www.twilio.com\/whatsapp\/request-access) web page.\n\nTips for specifying the following values:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp"},{"document_id":"ibmcld_04113-7-2190","score":16.5744380951,"text":"\nBest practices for CIS setup \n\nBecause IBM Cloud\u00ae Internet Services is positioned at the edge of your network, you\u2019ll need to take a few steps to guarantee a smooth integration with your CIS services. Here are some recommended best practices for integrating CIS with your origin servers.\n\nYou can do these steps either before or after you change your DNS and activate our proxy service. These recommendations allow CIS to connect to your origin servers properly. They\u2019ll help you prevent any issues with API or HTTPS traffic, and help your logs capture the correct IP addresses of your customers, rather than the protective CIS IP addresses.\n\nHere\u2019s what you\u2019ll need to set up:\n\n\n\n* Restore the originating IPs of your customers\n* Incorporate CIS IP addresses\n* Make sure your security settings don't interfere with API traffic\n* Configure your security settings as strictly as possible\n\n\n\n\n\n Best practice 1: Know how to restore the originating IPs of your customers \n\nAs a reverse proxy, CIS provides the origination IP in these headers:\n\n\n\n* CF-Connecting-IP\n* X-Forwarded-For\n* True-Client-IP (optional)\n\n\n\nYou can restore user IP addresses using a variety of tools, for infrastructures such as Apache, Windows IIS, and NGINX.\n\n\n\n\n\n Best practice 2: Incorporate CIS IP addresses to make integration smoother \n\nHere are the two steps to take:\n\n\n\n* Remove any rate limiting of CIS IP addresses\n* Set up your ACLs to allow only CIS IP addresses and other trusted parties\n\n\n\nYou can find the updated list of IP ranges for IBM CIS [at this location](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-allowlisted-ip-addresses).\n\n\n\n\n\n Best practice 3: Review your security settings to make sure they don\u2019t interfere with API traffic \n\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup"},{"document_id":"ibmcld_16337-4251-6012","score":16.4087638855,"text":"\n* The indicated channel integrations support initiating a channel transfer (currently, the web chat integration is the only supported transfer target).\n* Initiating a channel transfer from the phone integration requires that the SMS integration also be configured.\n\n\n\n\n\n\n\n Fields \n\n\n\n Name Type Description Required? \n\n response_type string channel_transfer Y \n message_to_user string A message to display to the user before the link for initiating the transfer. Y \n transfer_info object Information used by an integration to transfer the conversation to a different channel. Y \n transfer_info.target.chat string The URL for the website hosting the web chat to which the conversation is to be transferred. Y \n\n\n\n\n\n\n\n Example \n\nThis example requests a transfer from WhatsApp to the web chat. In addition to the channel_transfer response, the output also includes a text response to be displayed by the web chat integration after the transfer. The use of the channels array ensures that the channel_transfer response is handled only by the WhatsApp integration (before the transfer), and the connect_to_agent response only by the web chat integration (after the transfer). For more information about using channels to target specific integrations, see [Targeting specific integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-referenceassistant-responses-json-target-integrations).\n\n{\n\"generic\": [\n{\n\"response_type\": \"channel_transfer\",\n\"channels\":\n{\n\"channel\": \"whatsapp\"\n}\n],\n\"message_to_user\": \"Click the link to connect with an agent using our website.\",\n\"transfer_info\": {\n\"target\": {\n\"chat\": {\n\"url\": \"https:\/\/example.com\/webchat\"\n}\n}\n}\n},\n{\n\"response_type\": \"connect_to_agent\",\n\"channels\":\n{\n\"channel\": \"chat\"\n}\n],","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference"},{"document_id":"ibmcld_16280-3111-5196","score":16.2803554535,"text":"\nExtensions are not required for an assistant, but they are recommended.\n\n\n\nWhen you add a channel to your assistant, at least two instances of the channel are created. One instance of the channel is connected to the draft environment and the other instance is connected to the live environment. If you are using [multiple environments](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-multiple-environments), instances of the channel are added to your extra environments. To connect your assistant to a new channel, go to the Integrations catalog. For more information about adding integrations to your assistant, see [Adding integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-integration-add).\n\nAlthough a channel always exists in environments, you can configure your integration separately in each environment. For example, this allows you to test integrations on your draft environment before you go live with any integration configuration. After you add an integration, you must set it up to use it with your assistant. The Finish setup icon appears on any integration that you added but didn't yet set up.\n\nYou have multiple options for deploying your assistant, depending on how you want your customers to interact with it. In most cases, an assistant is deployed by using one of the following integrations:\n\n\n\n* [Web chat integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): The web chat integration provides a secure and highly customizable widget you can add to your website. You can configure how and where the web chat widget appears, and you can use theming to align it with your branding and website design. If a customer needs help from a person, the web chat integration can transfer the conversation to an agent.\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone): The phone integration enables your assistant to converse with customers on the phone by using the IBM Watson Text to Speech and Speech to Text services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-assistant"},{"document_id":"ibmcld_03165-4477-6547","score":16.1239185333,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_03160-4262-5873","score":15.9296770096,"text":"\nIf this test did not work as expected, double check your phone number configuration to make sure its attached to your flow.\n\n\n\n\n\n\n\n Creating a Twilio function to handle incoming calls \n\nNow we need to configure the call flow to direct inbound calls to the assistant using a Twilio function. Follow these steps:\n\n\n\n1. In the navigation menu, click the All Products & Services icon.\n2. Click Services.\n3. Click Create Service. Specify a service name and then click Next.\n4. Click Add > Add Function to add a new function to your service. Name the new function \/receive-call.\n5. Replace the template in your \/receive-call function with the following code:\n\nexports.handler = function(context, event, callback) {\nconst VoiceResponse = require('twilio').twiml.VoiceResponse;\nconst response = new VoiceResponse();\nconst dial = response.dial({\nanswerOnBridge: \"true\",\nreferUrl: \"\/refer-handler\"\n});\nconst calledPhoneNumber = event.Called;\ndial.sip(sip:${calledPhoneNumber}@{sip_uri_hostname};secure=true);\nreturn callback(null, response);\n}\n\n\n\n* Replace {sip_uri_hostname} with the hostname portion of your assistant's phone integration SIP URI (everything that comes after sips:).. Note that Twilio does not support SIPS URIs, but does support secure SIP trunking by appending ;secure=true to the SIP URI.\n\n\n\n6. Click Save.\n7. Click Deploy All.\n\n\n\n\n\n\n\n Redirecting to the incoming call handler \n\nIn this section you will use a TwiML Redirect** widget in your Studio Flow editor to call out to the \/call-recieve function created in the previous section.\n\n\n\n1. Add a TwiML Redirect widget to your Studio Flow canvas.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-flex"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.4306765581,"ndcg_cut_10":0.4306765581}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16288-6287-8401","score":12.7403516769,"text":"\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have a live agent backup available. You can design your assistant to transfer a call to a human in case the phone connection fails, or if a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another. For example, if you use the web chat integration with service desk support, you cannot transfer a phone call to the service desk that is set up for the web chat.\n\nYou must provide the call center SIP URI for the call center service you use. You must specify this information in your assistant when you enable a call transfer from a dialog node or action step. For more information, see [Transferring a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\n\n\n\n\n Optimize your actions for phone interaction \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your action responses. To add formatting, use Markdown. For more information, see [Formatting responses](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-respondrespond-formatting).\n* You can use a search extension to include search results in actions that the phone integration will read. When search results are returned, the phone integration reads the introductory message (for example, I found this information that might be helpful), and then the body of only the first search result.\n\nThe entire search response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03165-4477-6547","score":12.4957637787,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_01569-7-2048","score":11.3505811691,"text":"\nInteracting with the Client \n\nThere are a few ways to interact with the client:\n\n\n\n* Through terminal command line prior to startup\n* After startup, using the client's interactive command line\n* After startup, using the client's local UI\n\n\n\n\n\n Startup Configurations \n\n\n\n Startup Arguments and Options \n\nThe following table describes all of the available options that can be provided alongside the startup command for the client. Using these will allow complete configuration of the client prior to startup rather than requiring individual setup once the client is running.\n\n\n\n Parameter and Arguments Description \n\n Connect to IBM Cloud by using the gateway ID that is provided \n -F, --aclfile Access control List file \n -g, --gateway hostname:port Used to manually select a specific gateway destination (advanced use only) \n -l, --loglevel Change the log level to ERROR, INFO, DEBUG or TRACE \n -p, --logpath Direct logging to a specific file \n -P, --port The port for the UI to run on. Defaults to port 9003 \n -r, --reconnect Reconnect attempts after drop the connection between SG client and SG server, -1 means retry forever. Defaults to 20 \n -t, --sectoken The security token to use for this gateway connection \n -w, --password The password to protect the UI with. Defaults to no password. Passwords must contain only letters. \n -x, --proxy (For SG client v182fp2 and former) The proxy for the port 9000 wss connection \n (For SG client v183 and later) The proxy for the port 9000 wss connection and port 443 gateway authentication connection \n --noUI Prevent the UI from starting up automatically \n --allow Allows all connections to the client. Is overridden by the ACL file, if provided \n --service After an initial connection, the parent will restart within 60s if all child clients are terminated \n\n\n\nNote:--service, --allow, and --noUI flags should be the last parameters in the command line arguments.\n\nThe most basic use case is to start with a single client connection with the default settings:\n\n<gateway_id> -t <security_token>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/SecureGateway?topic=SecureGateway-client-interacting"},{"document_id":"ibmcld_12997-7-2048","score":11.3505811691,"text":"\nInteracting with the Client \n\nThere are a few ways to interact with the client:\n\n\n\n* Through terminal command line prior to startup\n* After startup, using the client's interactive command line\n* After startup, using the client's local UI\n\n\n\n\n\n Startup Configurations \n\n\n\n Startup Arguments and Options \n\nThe following table describes all of the available options that can be provided alongside the startup command for the client. Using these will allow complete configuration of the client prior to startup rather than requiring individual setup once the client is running.\n\n\n\n Parameter and Arguments Description \n\n Connect to IBM Cloud by using the gateway ID that is provided \n -F, --aclfile Access control List file \n -g, --gateway hostname:port Used to manually select a specific gateway destination (advanced use only) \n -l, --loglevel Change the log level to ERROR, INFO, DEBUG or TRACE \n -p, --logpath Direct logging to a specific file \n -P, --port The port for the UI to run on. Defaults to port 9003 \n -r, --reconnect Reconnect attempts after drop the connection between SG client and SG server, -1 means retry forever. Defaults to 20 \n -t, --sectoken The security token to use for this gateway connection \n -w, --password The password to protect the UI with. Defaults to no password. Passwords must contain only letters. \n -x, --proxy (For SG client v182fp2 and former) The proxy for the port 9000 wss connection \n (For SG client v183 and later) The proxy for the port 9000 wss connection and port 443 gateway authentication connection \n --noUI Prevent the UI from starting up automatically \n --allow Allows all connections to the client. Is overridden by the ACL file, if provided \n --service After an initial connection, the parent will restart within 60s if all child clients are terminated \n\n\n\nNote:--service, --allow, and --noUI flags should be the last parameters in the command line arguments.\n\nThe most basic use case is to start with a single client connection with the default settings:\n\n<gateway_id> -t <security_token>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/SecureGateway?topic=SecureGateway-client-interacting"},{"document_id":"ibmcld_04334-44924-46898","score":10.7587575912,"text":"\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.\n* image_size_optimization: Improve image load time by optimizing images hosted on your domain.\n* ip_geolocation: Include the country code of the visitor location with all requests to your website.\n* ipv6: Enable IPv6 support and gateway.\n* max_upload: The amount of data visitors can upload to your website in a single request.\n* min_tls_version: Only allow HTTPS connections from visitors that support the selected TLS protocol version or newer.\n* minify: Reduce the file size of source code on your website.\n* mobile_redirect: Redirect visitors that are using mobile devices to a mobile-optimized website.\n* opportunistic_encryption: Opportunistic Encryption allows browsers to benefit from the improved performance of HTTP\/2 by letting them know that your site is available over an encrypted connection.\n* origin_error_page_pass_thru: When Origin Error Page is set to On, CIS will proxy the 502 and 504 error pages directly from the origin (Enterprise plan only).\n* prefetch_preload: CIS will prefetch any URLs included in the prefetch HTTP header (Enterprise plan only).\n* pseudo_ipv4: Adds an IPv4 header to requests when a client is using IPv6, but the server only supports IPv4.\n* response_buffering: Enable or disable buffering of responses from the origin server (Enterprise plan only).\n* script_load_optimization: Improve the paint time for pages that include JavaScript.\n* security_header: Enforce web security policy for your website.\n* security_level: Choose the appropriate security profile for your website.\n* server_side_exclude: Automatically hide specific content from suspicious visitors.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_16294-8240-10414","score":10.710398674,"text":"\nOnce the phone number has been enabled for SMS, you will see a webhook icon beside the number.\n\nPaste the value that you copied from the Webhook URI field into it.\n15. Click Save.\n16. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n\n\n\n\n\n\n\n\n\n SMS Advanced configuration options \n\nThe Advanced options tab is available after you set up the SMS integration. Click the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your actions for messaging \n\nFor the best customer experience, design your actions with the capabilities of the SMS integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* The SMS integration does not support chat transfers that are initiated with the connect_to_agent response type.\n* Image, Audio, Video response types allow sending a message containing media. A title and description are sent along with the attachment. Note that depending on the carrier and device of the end user these messages may not be successfully received. For a list of the supported content types for Twilio, see [Twilio: Accepted Content Types for Media](https:\/\/www.twilio.com\/docs\/sms\/accepted-mime-types).\n\nFor more information on these response types, see [Response types reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\nIf you want to use the same action for an assistant that you deploy to many different platforms, add custom responses per integration type. You can add a conditioned response that tells the assistant to show the response only when the SMS integration is being used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-sms"},{"document_id":"ibmcld_03369-22311-24192","score":10.6487054825,"text":"\nFor more information, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel).\n\n\n\n\n\n 3 December 2021 \n\nConfigure webhook timeout\n: From the Pre-message webhook and Post-message webhook configuration pages, you can configure the webhook timeout length from a minimum of 1 second to a maximum of 30 seconds. For more information, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview).\n\n\n\n\n\n 27 November 2021 \n\nNew API version\n: The current API version is now 2021-11-27. This version introduces the following changes:\n\n\n\n* The output.text object is no longer returned in message responses. All responses, including text responses, are returned only in the output.generic array.\n\n\n\n\n\n\n\n 9 November 2021 \n\nNew phone response types\n: New response types are available for controlling the configuration and behavior of the phone integration. These response types replace most of the older vgw actions, which are now deprecated. (The vgw actions will continue to work, so existing skills do not need to be changed.) For more information, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions).\n\nRich response types\n: Your assistant can now send responses that include elements such as audio, video, or embedded iframe content. For more information, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n 4 November 2021 \n\nActions enhancement: Add variables to links\n: In an actions skill, when including a link in an assistant response, you can now access and use variables. In the URL field for a link, type a dollar sign ($) character to see a list of variables to choose from.\n\n\n\n\n\n 14 October 2021 \n\nvgwHangUp message no longer sent","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03369-20825-22706","score":10.494389534,"text":"\nIf you would like to send us feedback on the new experience, please use [this form](https:\/\/form.asana.com\/?k=vvRdQAmGMFAeEGRryhTA2w&d=8612789739828).\n\n\n\n\n\n 4 February 2022 \n\nFuzzy matching updates\n: Interactions between the stemming and misspelling fuzzy matching features are not allowed. Improve fuzzy matching behavior by limiting the interactions between different fuzzy matching features. This change applies to the following languages: English, French, German, and Czech. For more information, see [How fuzzy matching works](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-fuzzy-matching).\n\n\n\n\n\n 13 January 2022 \n\nNew setting for options customer response type\n: In actions, a new List options setting allows you to enable or disable the options customer response from appearing in a list. This can be useful to prevent a phone integration from reading a long list of options to the customer. As part of this change, all customer response types now have a Settings icon. Allow skipping has moved from Edit Response and is now found in the new settings.\n\n\n\n\n\n 24 December 2021 \n\nApache Log4j security vulnerability updates\n: Watson Assistant upgraded to using Log4j version 2.17.0, which addresses all of the Critical severity and High severity Log4j CVEs, specifically CVE-2021-45105, CVE-2021-45046, and CVE-2021-44228.\n\n\n\n\n\n 10 December 2021 \n\nChannel transfer in Phone integration\n: The phone integration now supports the channel_transfer response type. For more information, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel).\n\n\n\n\n\n 3 December 2021 \n\nConfigure webhook timeout\n: From the Pre-message webhook and Post-message webhook configuration pages, you can configure the webhook timeout length from a minimum of 1 second to a maximum of 30 seconds.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_04334-40577-42576","score":10.2696008682,"text":"\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.\n* image_size_optimization: Improve image load time by optimizing images hosted on your domain.\n* ip_geolocation: Include the country code of the visitor location with all requests to your website.\n* ipv6: Enable IPv6 support and gateway.\n* max_upload: The amount of data visitors can upload to your website in a single request.\n* min_tls_version: Only allow HTTPS connections from visitors that support the selected TLS protocol version or newer.\n* minify: Reduce the file size of source code on your website.\n* mobile_redirect: Redirect visitors that are using mobile devices to a mobile-optimized website.\n* opportunistic_encryption: Opportunistic Encryption allows browsers to benefit from the improved performance of HTTP\/2 by letting them know that your site is available over an encrypted connection.\n* origin_error_page_pass_thru: When Origin Error Page is set to On, CIS will proxy the 502 and 504 error pages directly from the origin. (Enterprise plan only)\n* prefetch_preload: CIS will prefetch any URLs included in the prefetch HTTP header (Enterprise plan only).\n* pseudo_ipv4: Adds an IPv4 header to requests when a client is using IPv6, but the server only supports IPv4.\n* response_buffering: Enable or disable buffering of responses from the origin server (Enterprise plan only).\n* script_load_optimization: Improve the paint time for pages that include JavaScript.\n* security_header: Enforce web security policy for your website.\n* security_level: Choose the appropriate security profile for your website.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_12996-4488-6575","score":10.1720619202,"text":"\nThe gateway ID is defined when you create a Secure Gateway service. If the client fails to connect, you can change your selection by editing the .conf file.\n\nSecurity token If the gateway ID is enabled to check for a security token, you must provide it now. If the gateway ID does not require a security token, leave this blank.\n\nLogging level The default setting is INFO. Other valid values are TRACE, DEBUG, and ERROR.\n\nAccess Control List Enter the absolute path of the file name containing the access control list on what has access to your on-premises resources. For more information, see the README.md file in \/opt\/ibm\/securegateway or Access control list.\n\nClient UI Choose if you want to use client UI. If yes, user can change the port for the UI. Default value is 9003.\n\nNPM installation proxy Enter the proxy info if you want to install the npm module with the proxy. If NPM installation proxy is not required, leave this blank.\n\nNote: Other than the NPM installation proxy info, you do not have to answer any of the prompts, all will take the defined default or be left blank in the sgenvironment.conf file. This allows the installation process to start up Secure Gateway client without user interaction.\n\nNote: The sgenvironment.conf is read every time that you start or restart the client using the system's upstart process. You can edit the \/etc\/ibm\/sgenvironment.conf file at any time to make changes to your configuration and restart the client to pick up those changes. However, UI password in config file could only be set up during installation.\n\nNote: The language of the Secure Gateway client service logs can be changed by changing the LANGUAGE parameter in the \/etc\/ibm\/sgenvironment.conf file. The service logs will change to selected language after service restart.\n3. If you restarted the client, to make sure that the client is running properly, issue the following command:\n\ncat \/var\/log\/securegateway\/client_console.log\n4. If you want to edit the configuration file, to make sure that the configuration file is updated correctly, issue the following command:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/SecureGateway?topic=SecureGateway-client-install"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03165-4477-6547","score":13.066113472,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_01628-4-1798","score":12.5242576599,"text":"\n* CLI\n* API\n\n\n\n\n\n\n\n Increasing account limits \n\nDefault maximum limits are set on entities in your account such as access policies, service IDs, trusted profiles, identity providers (IdPs), and API keys. However, specific use cases can require an extended limit and you must request an increase for your chosen entity. You must be the account owner or administrator for all account management services to check how many policies exist in the account.\n\nTo review the default limits for your account, see [Known issues and limitations](https:\/\/cloud.ibm.com\/docs\/account?topic=account-known-issuesiam_limits).\n\n\n\n Increasing limits for IAM identity entities \n\nWhen your account approaches the maximum limit of one of the entities, you receive a warning in the Activity Tracker event for creating an entity. These events show you the current limits. See the following example:\n\nNov 26 16:46:01 iamid-6-11-12270-af4d601-cd77fd6bd-86gp7 at.log INFO IAM Identity Service: create account-serviceid 12345678-90ab-cdef-0123-456789abcdef -failure Warning: You have reached 100% of the maximum number of allowed Service IDs in account 11112222333344445555666677778888. Your current count is 3000, and the limit is 3000.\n\nA limit increase can be requested for the following types of entities:\n\n\n\n* API keys per identity\n* Service IDs\n* Identity providers (IdPs)\n* Trusted profiles\n* Dynamic rules\n\n\n\nYou can request a limit increase for the chosen entities only if the following criteria is met:\n\n\n\n* You must be the account owner or an administrator on all account management services.\n* You have taken efforts to clean up and reduce the number of entities in the account.\n* You must have a specific, reasonable use case for requesting an increase.\n\n\n\n\n\n Requesting a limit increase for different entities","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-limits"},{"document_id":"ibmcld_16471-92779-94574","score":12.4597854614,"text":"\nAssume that the PhoneNumbers view that extracts phone numbers of the pattern XXX-XXX-XXXX for United States is already defined. This select statement evaluates the regular expression for the pattern 444-888-XXXX across the input text. The view has the output columns documentText and phoneNumber. In addition, the output is limited to the first occurrence of this phone number pattern that is identified per document.\n\ncreate view PhoneNumbersPattern1 as\nselect D.documentText, D.phoneNumber\nfrom PhoneNumbers D\nwhere MatchesRegex(\/444-888-d{4}\/,D.phoneNumber)\nlimit 1;\n\nAnother example of how you can use the select statement is to find approximate mappings of people and their corresponding phone numbers. Assume that the view Person is already defined, and that it has the columns person and the view PhoneNumbers. This select statement evaluates the where clause to find text spans that contain a person mention followed by a phone number within 1 to 3 words or tokens. The input to this statement is represented by a join of the Person and PhoneNumbers views in the from list.\n\ncreate view PersonPhone as\nselect P1.documentText, P1.person, P2.phoneNumber, CombineSpans(P1.person,P2.phoneNumber) as personPhoneSpan\nfrom Person P1, PhoneNumbers P2\nwhere FollowsTok(P1.person,P2.phoneNumber,1,3);\n\nThe personPhoneSpan column will contain the matching spans that give the approximate person-phone mapping.\n\npersonPhoneSpan\nJohn : 433-999-1000\nMartha Mob 433-999-1001\n\n\n\n* The select list The select list in an AQL select or extract statement consists of a comma-delimited list of output expressions.\n* The from list The second part of a select or an extract statement in AQL is the from list. The from list is a comma-separated list that is the source of the tuples to be selected or extracted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_07116-10729-12677","score":12.2514743805,"text":"\nIn development instances, the limit is 1,000 open shards, and in production instances, the limit is two data nodes, which is equal to 2,000 open shards, or 1,000 open shards per data node. After you reach either limit, you cannot create any more projects and collections on your cluster, and if you try to create a new project and collection, you receive an error message.\n\nThis limit is due to the fact that, when you install Discovery version 2.2.0, Elasticsearch version 7.8.0 automatically runs on your clusters. Because this version of Elasticsearch runs on your clusters, a new cluster stability configuration becomes available that limits the number of open shards to 1,000 for each Elasticsearch data node.\n\nIf you are unable to create new projects and collections and you receive errors, first check the status of your Elasticsearch cluster and the number of shards on that cluster. Consider increasing the number of data nodes on your cluster to support more shards. This method is optimal for maximizing performance. However, an increased number of nodes uses more memory. If the number of shards reaches the limit, you can also increase the limit in a data node. For more information about increasing the shard limit in a node, see [Increasing the shard limit](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-troubleshootincrease-shards).\n\nThis limit of 1,000 shards does not apply to versions of Discovery that are earlier than 2.2.0.\n\n\n\n Increasing the shard limit \n\n\n\n1. Log in to your Discovery cluster.\n2. Access your data node.\n3. Enter the following command:\n\noc exec -it $(oc get pod -l app=elastic,ibm-es-data=True -o jsonpath='{.items[0].metadata.name}') -- bash\n4. Enter the following command, replacing the <> and the content inside with your port number:\n\ncurl -X POST http:\/\/localhost:<port_number>\/_cluster\/health?pretty\n\nIf you do not know what your port number is, enter the following command to find it:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-troubleshoot"},{"document_id":"ibmcld_03369-122420-124242","score":12.1771192551,"text":"\ncurl -u \"apikey:{apikey}\" \"https:\/\/{service-hostname}\/assistant\/api\/v1\/workspaces\/{workspace_id}\/dialog_nodes?version=2018-09-20&include_count=true\"\n\nwhere {service-hostname} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.\n\nSee [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors) for information about how to edit skills that you want to continue using.\n\n\n\n\n\n\n\n 27 November 2018 \n\nA new service plan, the Plus plan, is available\n: The new plan offers premium-level features at a lower price point. Unlike previous plans, the Plus plan is a user-based billing plan. It measures usage by the number of unique users that interact with your assistant over a given time period. To get the most from the plan, if you build your own client application, design your app such that it defines a unique ID for each user, and passes the user ID with each \/message API call. For the built-in integrations, the session ID is used to identify user interactions with the assistant. See [User-based plans](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-services-informationservices-information-user-based-plans) for more information.\n\n\n\nPlus plan limits\n\n Artifact Limit \n\n Assistants 100 \n Contextual entities 20 \n Contextual entity annotations 2,000 \n Dialog nodes 100,000 \n Entities 1,000 \n Entity synonyms 100,000 \n Entity values 100,000 \n Intents 2,000 \n Intent user examples 25,000 \n Integrations 100 \n Logs 30 days \n Skills 50 \n\n\n\nUser-based Premium plan\n: The Premium plan now bases its billing on the number of active unique users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_05386-2800-4412","score":12.1166305542,"text":"\nTimeout 300 seconds 600 seconds [Contact IBM support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui) \n\n\n\nFor more information about supported CPU and memory combinations, see [Supported memory and CPU combinations](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-mem-cpu-combo).\n\nCode Engine has limits for apps within a project.\n\n\n\n* You are limited to 40 apps per project.\n* You are limited to a total of 120 revisions for all apps per project.\n\n\n\nCode Engine does not support overcommitment for application resources. Therefore, if you create an application by using the API or with kubectl apply -f <yaml>, the values for Resource.Requests and Resource.Limits for CPU, Memory, and Ephemeral Storage must be specified and must be the same.\n\n\n\n\n\n Job defaults and limits \n\nThe following table lists the limits for jobs.\n\n\n\nJob limits\n\n Category Default Maximum value Need to extend the maximum? \n\n Array - Array indices 0 9999999 [Contact IBM support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui) \n Array - Number of instances 1 1000 [Contact IBM support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui) \n CPU 1.0 12.0 [Contact IBM support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui) \n Ephemeral storage 400 M 48 G <br>(limited by memory) [Contact IBM support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui) \n Memory 4 G 48 G [Contact IBM support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-limits"},{"document_id":"ibmcld_01245-4-1307","score":11.6918544769,"text":"\n* CLI\n* API\n\n\n\n\n\n\n\n Managing storage limits \n\nBy default, you can provision a combined total of 700 Block Storage for Classic and File Storage for Classic volumes globally. By following this process, you can increase the number of volumes you can provision.\n\nFor more information about increasing your storage volume capacity beyond 12 TB, see [expanding File Storage for Classic capacity](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-expandCapacityincreasecapacityover12TB).\n\nIf you're unsure how many volumes you have, you can confirm the numbers by using multiple methods.\n\n\n\n Confirming your current limit and provisioning count from the CLI \n\n\n\n SLCLI \n\nYou can list the number of your volumes by using the [volume-limits](https:\/\/softlayer-python.readthedocs.io\/en\/latest\/cli\/file\/file-volume-limits) command in slcli (version 5.8.5 or higher).\n\n slcli file volume-limits\n\nThe output looks similar to the following example.\n\n[{'datacenterName': 'global', 'maximumAvailableCount': 700, 'provisioned Count':117}]\n:............:.......................:..................:\n: Datacenter : maximumAvailableCount : ProvisionedCount :\n:............:.......................:..................:\n: global : 700 : 117 :\n:............:.......................:..................:\n\n\n\n\n\n IBM Cloud CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits"},{"document_id":"ibmcld_16727-1271119-1273166","score":11.6539735794,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1268470-1270517","score":11.6539735794,"text":"\nYou can also access the correct mount point through an API call: SoftLayer_Network_Storage::getNetworkMountAddress().\n* How many volumes can I provision?\n\nBy default, you can provision a combined total of 700 Block and File Storage for Classic volumes. To increase your limit, contact your sales representative. For more information, see [Managing storage limits](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits).\n* How many instances can share the use of a provisioned File Storage for Classic volume?\n\nThe default limit for number of authorizations per file volume is 64. To increase this limit, contact your sales representative.\n* How many File Storage for Classic volumes can be attached to a single host?\n\nThat depends on what the host operating system can handle, it\u2019s not something that IBM Cloud\u00ae limits. Refer to your OS Documentation for limits on the number of file shares that can be mounted.\n* How many files and directories are allowed for specific file volume sizes? What is the maximum number of inodes allowed per volume size?\n\nThe number of files a volume can contain is determined by how many inodes it has. An inode is a data structure that contains information about files. Volumes have both private and public inodes. Public inodes are used for files that are visible to the customer and private inodes are used for files that are used internally by the storage system. The maximum number of files setting is 2 billion. However, this maximum value can be configured only with volumes of 7.8 TB or larger. The maximum number of inodes that can be configured on a volume is calculated by taking the total allocated volume size in KB and dividing it by 4. Any volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_00249-4-1321","score":11.6151943207,"text":"\n* CLI\n* API\n\n\n\n\n\n\n\n Managing storage limits \n\nBy default, you can provision a combined total of 700 Block Storage for Classic and File Storage for Classic volumes globally. By following this process, you can increase the number of volumes that you can provision.\n\nFor more information about increasing your storage volume capacity beyond 12 TB, see [expanding Block Storage for Classic capacity](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-expandingcapacityincreasecapacityover12TB).\n\n\n\n Confirming your current limit and provisioning count from the CLI \n\nIf you're unsure how many volumes you have, you can confirm the numbers by using multiple methods.\n\n\n\n SLCLI \n\nYou can list the number of your volumes by using the [volume-limits](https:\/\/softlayer-python.readthedocs.io\/en\/latest\/cli\/block\/block-volume-limits) command in slcli (version 5.8.5 or higher).\n\n slcli block volume-limits\n\nThe output looks similar to the following example.\n\n[{'datacenterName': 'global', 'maximumAvailableCount': 700, 'provisioned Count':117}]\n:............:.......................:..................:\n: Datacenter : maximumAvailableCount : ProvisionedCount :\n:............:.......................:..................:\n: global : 700 : 117 :\n:............:.......................:..................:\n\n\n\n\n\n IBM Cloud CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingstoragelimits"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16250-5445-7809","score":15.2722530365,"text":"\nTo support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call. Using only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_16288-7-2218","score":14.1015586853,"text":"\nPhone integration configuration \n\nIBM Cloud\n\nAfter you have set up the phone integration for your assistant, you can modify the phone integration settings to customize the call behavior.\n\n\n\n Handling call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, go to the Advanced tab in the phone integration settings, and make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup call center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-transfer-service).\n* Call failure message: Add the message you want the assistant to say to a caller before it transfers the call to a human agent.\n\n\n\nIf, after you transfer the call to a human, the connection to a live agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message you want the assistant to say to a caller if transfer to a live agent fails. The message can be up to 150 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after the failure message. This option is enabled by default. If this option is disabled, when a call transfer fails, your assistant can disconnect or process a different action.\n\nIf you choose to leave a call connected despite a transfer failure, Watson Assistant will initiate a new turn to determine the next step. It's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03312-5487-7760","score":13.7291488647,"text":"\nIf a failover is automated and a regional backup is enabled, it is always best to try a different zone first and only redirect traffic to the passive backup region if a preconfigured number of failures occur within a short period of time. This prevents an unnecessary failover between regions if only a short outage occurs.\n\nNote that Watson Assistant provides a round-robin fully qualified domain name (FQDN) that includes the IPs for each zone in the region. Many SIP trunking providers automatically retry each IP in the FQDN when failures occur. To support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-failover"},{"document_id":"ibmcld_16321-19290-20983","score":13.4954967499,"text":"\n\"uri\": \"sip:12345556789\\@myhost.com\"\n\n\n\n Transferring after hangup \n\nBy default, the phone integration transfers calls by using a SIP REFER request. Depending on the IVR service provider, you might need to configure call transfer to use a SIP BYE request instead. Use the transfer_method attribute to specify how to transfer the call, using either refer or hangup. When transfer_method is set to hangup instead of refer, the behavior of the transfer action changes. Instead of sending a SIP REFER request, the phone integration plays back any associated text and then hangs up the call by sending a SIP BYE request.\n\nAfter the hangup, the phone integration passes the transfer destination that is specified in the url attribute to the call anchor in the BYE message. The header field that contains the transfer target is determined by the transfer_target_header attribute. If the transfer_target_header attribute isn't specified, the phone integration uses Transfer-Target.\n\n{\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"transfer_info\": {\n\"target\": {\n\"service_desk\": {\n\"sip\": {\n\"uri\": \"sip:user\\@domain.com\",\n\"transfer_method\": \"hangup\",\n\"transfer_target_header\": \"Transfer-Target\"\n}\n}\n}\n},\n\"agent_available\": {\n\"message\": \"Please hold on while I connect you with a live agent.\"\n},\n\"agent_unavailable\": {\n\"message\": \"Sorry, I could not find an agent.\"\n},\n\"message_to_human_agent\": \"The caller needs help resetting their password\"\n}\n]\n}\nShow more\n\n\n\n\n\n Transferring upon failure \n\nTo configure transfer on failures, go to the Advanced tab in the phone integration settings. The following selections can be configured:\n\n\n\n* Transfer failure message\n* Disconnect call on transfer failure","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03158-8929-11062","score":12.9777879715,"text":"\nFor more information, see [Configuring backup support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after sharing the failure message. This option is enabled by default. If disabled, when a call transfer fails, your assistant can disconnect or process a different dialog node.\n\n\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by selecting one or both of the following configuration options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Apply advanced SIP trunk configuration settings \n\n\n\n* SIP INVITE headers to extract: List headers that you want to use in your dialog.\n\nThe SIP request often sends INVITE headers with information about the request that is used by the SIP network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03158-7739-9484","score":12.8416128159,"text":"\n[checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/phone-checkmark-save.png) to save each number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (![Add phone number](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/phone-integ-import-number.png)), and then find the CSV file that contains the list of phone numbers.\n\nThe phone numbers you upload will replace any existing numbers in the table.\n\n\n\n\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the call behavior:\n\n\n\n Handle call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03312-7276-9469","score":12.7531747818,"text":"\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call. Using only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training. When automation is enabled it is best to start with a strategy for detecting and failing over to the passive backup region when a complete regional outage is detected. After this is in place, a strategy can be implemented to deal with partial outages, which should cover the vast majority of failure conditions that can occur with a phone integration deployment.\n\n\n\n\n\n\n\n Web chat \n\n\n\n Monitoring \n\nWeb chat provides an onError listening feature that allows the host page to detect specific types of outage errors, in particular INITIAL_CONFIG, OPEN_CONFIG, and MESSAGE_COMMUNICATION errors.\n\nYou can find the documentation for this feature here:\n\n[https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration#onerror-detail](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationonerror-detail)\n\n\n\n\n\n Failover \n\nHandling a failover for web chat is simple assuming you have set up an additional web chat integration in another region. When the failover needs to be manually triggered, make the following changes:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-failover"},{"document_id":"ibmcld_16250-7169-9454","score":12.7036943436,"text":"\nUsing only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training. When automation is enabled it is best to start with a strategy for detecting and failing over to the passive backup region when a complete regional outage is detected. After this is in place, a strategy can be implemented to deal with partial outages, which should cover the vast majority of failure conditions that can occur with a phone integration deployment.\n\n\n\n\n\n\n\n Web chat \n\n\n\n Monitoring \n\nWeb chat provides an onError listening feature that allows the host page to detect specific types of outage errors, in particular INITIAL_CONFIG, OPEN_CONFIG, and MESSAGE_COMMUNICATION errors.\n\nYou can find the documentation for this feature here:\n\n[https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration#onerror-detail](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationonerror-detail)\n\n\n\n\n\n Failover \n\nHandling a failover for web chat is simple assuming you have set up an additional web chat integration in another region. When the failover needs to be manually triggered, make the following changes:\n\n\n\n* The embed script that contains your integration ID, region, service instance ID, and subscription ID (if applicable) needs be changed or updated to use the IDs for the new integration and region.\n* If you are using Salesforce or ZenDesk integrations for connecting to human agents, update the configuration within those systems to make sure they can communicate with the correct integration. Follow the instructions on the Live agent tab in the web chat configuration for setting up those systems. This is only needed for obtaining the conversation history for the agent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_16291-8926-10529","score":11.9739551544,"text":"\nIf an error occurs during a conversation, the phone integration disconnects the call by sending a SIP BYE request.\n\nUse [Onrelease](https:\/\/help.nice-incontact.com\/content\/studio\/actions\/onrelease\/onrelease.htm) to process the BYE request and transfer a call to a live agent.\n\nIn this example, when Onrelease is triggered, the script verifies whether the call was already transferred. If not, it calls the Signal action and sets an indication that the call is being transferred to a live agent. The indication is set using the Assign action.\n\n\n\n* Variable transferred\n* Value true\n\n\n\n![Image of call disconnect on failure](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/cxone-disconnect-on-failure.png)\n\nIf the Hangup action is executed and an [Onrelease](https:\/\/help.nice-incontact.com\/content\/studio\/actions\/onrelease\/onrelease.htm) event action is present, CXone will hang up on the caller, and the script will jump to the OnRelease action. Design your script so it can distinguish whether the OnRelease event is triggered due to a transfer or hangup.\n\n\n\n\n\n\n\n\n\n Adding transfer support to your assistant \n\nConfigure your assistant to transfer calls to an agent using the Connect To Agent response_type. For instructions, see [Transferring a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\nUse the following format:\n\n{\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"transfer_info\": {\n\"target\": {\n\"nice_cxone\": {\n\"custom_data\": {\n\"p2\": \"test\"\n}\n}\n}\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"},{"document_id":"ibmcld_07839-0-1665","score":11.858836174,"text":"\n\n\n\n\n\n\n  PS-7 - Third-party Personnel Security \n\n\n\n  Control requirements \n\nThe organization:\n\nPS-7 (a)\n:   Establishes personnel security requirements including security roles and responsibilities for third-party providers;\n\nPS-7 (b)\n:   Requires third-party providers to comply with personnel security policies and procedures established by the organization;\n\nPS-7 (c)\n:   Documents personnel security requirements;\n\nPS-7 (d)\n:   Requires third-party providers to notify [Assignment: organization-defined personnel or roles] of any personnel transfers or terminations of third-party personnel who possess organizational credentials and\/or badges, or who have information system privileges within [IBM Assignment: same day]; and\n\nPS-7 (e)\n:   Monitors provider compliance.\n\n\n\n\n\n  NIST supplemental guidance \n\nThird-party providers include, for example, service bureaus, contractors, and other organizations providing information system development, information technology services, outsourced applications, and network and security management. Organizations explicitly include personnel security requirements in acquisition-related documents. Third-party providers may have personnel working at organizational facilities with credentials, badges, or information system privileges issued by organizations. Notifications of third-party personnel changes ensure appropriate termination of privileges and credentials. Organizations define the transfers and terminations deemed reportable by security-related characteristics that include, for example, functions, roles, and nature of credentials\/privileges associated with individuals transferred or terminated.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ps-7"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04621-58586-59933","score":12.1099395752,"text":"\n* The alternate Liberty runtime GA version [19.0.0.1](https:\/\/openliberty.io\/blog\/2019\/02\/01\/open-liberty-19001.html) was added.\n* The monthly Liberty beta release has been removed.\n* The IBM JRE version was updated to 8 SR5 FP27.\n* The MQ client was updated to the 9.1.0.0 release.\n* The auto-scaling agent was updated.\n\n\n\n\n\n\n\n 23 January 2019 \n\nUpdated Node.js buildpack v3.25.1\n: The SDK for Node.js buildpack v3.25.1 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.14.4, 6.16.0, 8.11.4, 8.15.0, 10.10.0 and 10.15.0. The default is latest 6.x, so it is currently 6.16.0. The versions 6.15.0, 8.14.0 and 10.14.0 that were included in the last buildpack had a regression. The regressions has been fixed in 6.16.0, 8.15.0 and 10.15.0 which are now included instead.\n\n\n\n\n\n 7 January 2019 \n\nUpdated Node.js buildpack v3.25\n: The SDK for Node.js buildpack v3.25 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.14.4, 6.15.0, 8.11.4, 8.14.0, 10.10.0 and 10.14.0. The default is latest 6.x, so it is currently 6.15.0. The buildpack also fixes a minor bug in the Dynatrace hook.\n\n\n\n\n\n 14 December 2018 \n\nUpdated Liberty buildpack v3.27-20181130-1702\n: The buildpack now includes Java Platform, Enterprise Edition 8.0. Java EE 8 no longer needs to be installed when an app is pushed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"},{"document_id":"ibmcld_00861-117621-118714","score":11.8595952988,"text":"\nGo version: go1.13.10\nGit commit: 9d988398e7\nBuilt: Fri May 15 00:22:47 2020\nOS\/Arch: linux\/amd64\nExperimental: false\n\n dc --version\ndc (GNU bc 1.07.1) 1.4.1\n\n ed --version\nGNU ed 1.14.2\nShow more\n\n\n\n\n\n Version 3.0 \n\nTo view the contents of version 3.0, from the running image, type default_versions.sh. The 3.x branch provides images with the current tool versions. The current Java\u2122 version is Java\u2122 11. Node.js no longer uses nvm to manage different node.js versions. It provides the current LTS version of Node.js at the time that it was built.\n\nThis image includes the following tools:\n\n node --version\nv14.16.1\n\n npm --version\n6.14.12\n\n jq --version\njq-1.6\n\n yq --version\nyq version 4.6.2\n\n kubectl version --client\nClient Version: version.Info{Major:\"1\", Minor:\"20\", GitVersion:\"v1.20.5\", GitCommit:\"6b1d87acf3c8253c123756b9e61dac642678305f\", GitTreeState:\"clean\", BuildDate:\"2021-03-18T01:10:43Z\", GoVersion:\"go1.15.8\", Compiler:\"gc\", Platform:\"linux\/amd64\"}\n\n buildctl --version\nbuildctl github.com\/moby\/buildkit v0.8.2 9065b18ba4633c75862befca8188de4338d9f94a\n\n helm version --client","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_00861-93522-94825","score":11.8325595856,"text":"\nTo view the contents of version 3.6, from the running image, type default_versions.sh. The 3.x branch provides images with the current tool versions. The current Java\u2122 version is Java\u2122 11. Node.js no longer uses nvm to manage different node.js versions. It provides the current LTS version of Node.js at the time that it was built.\n\nThe IBM Cloud CLI provides code risk analysis commands. You can use the IBM Cloud CLI to analyze your code for vulnerabilities and compliance with certain rules. Code Risk Analyzer is available in all IBM Cloud regions where toolchains are supported. For more information about Code Risk Analyzer, see [Code Risk Analyzer plug-in](https:\/\/cloud.ibm.com\/docs\/code-risk-analyzer-cli-plugin).\n\nThis image includes the following tools:\n\n node --version\nv16.14.0\n\n npm --version\n8.3.1\n\n jq --version\njq-1.6\n\n yq --version\nyq (https:\/\/github.com\/mikefarah\/yq\/) version 4.20.1\n\n kubectl version --client\nClient Version: version.Info{Major:\"1\", Minor:\"20\", GitVersion:\"v1.20.14\", GitCommit:\"57a3aa3f13699cf3db9c52d228c18db94fa81876\", GitTreeState:\"clean\", BuildDate:\"2021-12-15T14:52:33Z\", GoVersion:\"go1.15.15\", Compiler:\"gc\", Platform:\"linux\/amd64\"}\n\n buildctl --version\nbuildctl github.com\/moby\/buildkit v0.9.3 8d2625494a6a3d413e3d875a2ff7dd9b1ed1b1a9\n\n helm version --client","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_00861-218236-219417","score":11.3930435181,"text":"\ned --version\nGNU Ed 1.10\nShow more\n\n\n\n\n\n Version 2.15 \n\nTo view the contents of version 2.15, from the running image, type default_versions.sh.\n\nThe IBM Cloud CLI provides code risk analysis commands. You can use the IBM Cloud CLI to analyze your code for vulnerabilities and compliance with certain rules. Code Risk Analyzer is available in all IBM Cloud regions where toolchains are supported. For more information about Code Risk Analyzer, see [Code Risk Analyzer plug-in](https:\/\/cloud.ibm.com\/docs\/code-risk-analyzer-cli-plugin).\n\nThis image includes the following tools:\n\n node --version\nv14.17.6\n\n npm --version\n6.14.15\n\n jq --version\njq-1.6\n\n yq --version\nyq version 2.4.1\n\n yq3 --version\nyq version 3.4.1\n\n yq4 --version\nyq (https:\/\/github.com\/mikefarah\/yq\/) version 4.13.2\n\n kubectl version --client\nClient Version: version.Info{Major:\"1\", Minor:\"20\", GitVersion:\"v1.20.5\", GitCommit:\"6b1d87acf3c8253c123756b9e61dac642678305f\", GitTreeState:\"clean\", BuildDate:\"2021-03-18T01:10:43Z\", GoVersion:\"go1.15.8\", Compiler:\"gc\", Platform:\"linux\/amd64\"}\n\n buildctl --version\nbuildctl github.com\/moby\/buildkit v0.9.0 c8bb937807d405d92be91f06ce2629e6202ac7a9\n\n helm version --client","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_16034-28644-30202","score":11.2822685242,"text":"\nv0.6.0 \n\nVersion 0.6.0 was released on 2020-06-30.\n\n\n\n New commands \n\n\n\n* Added Creating instance from instance-template support for 'instance-create-from-template' command.\n* (Beta) Added commands to support dedicated host.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated all commands with VPC API version to '2020-05-19'.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.5.14 \n\nVersion 0.5.14 was released on 2020-04-30.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added HTTPS protocol and HTTPS health-type support for 'load-balancer-pool-create' command.\n* Added HTTPS protocol and HTTPS health-type support for 'load-balancer-pool-update' command.\n* Added floating IP data to 'instance' command JSON output.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.5.13 \n\nVersion 0.5.13 was released on 2020-04-13.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added CRN fields to various details commands output\n* Add example for the key-create and key-update commands\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.5.11 \n\nVersion 0.5.11 was released on 2020-03-05.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added resource tag fields to the ibmcloud is volumes command output\n* Updated the ibmcloud is network-acl-rule-add command example\n* Updated the ibmcloud is network-acl-create command example\n* Added more command examples to the [VPC CLI reference](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference)\n* Translation update to the command help\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Other","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_12143-11142-12571","score":11.261464119,"text":"\nVersions 0.13 through 0.15 require a stepwise upgrade, 0.13 to 0.14, 0.14 to 0.15, 0.15 to 1.0.\n\nThe process is the same for each version step. It is mandatory that a Terraform Apply is run after each version change. This updates the Terraform state file with schema changes related to that version and that version only. After successfully upgrading a single version, the next version update can be performed.\n\n\n\n1. Read the Terraform [upgrade guide](https:\/\/developer.hashicorp.com\/terraform\/language\/v1.1.x\/upgrade-guides) for the release and implement any required config changes.\n2. Follow the process outlined in [Upgrading the Terraform template version 1.x and above](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-migrating-terraform-versionterraform-version-upgrade1x-process) to upgrade a single version to the target version.\n3. Verify in the Workspace settings page the TF version is now set to the desired version.\n4. Run a Generate Plan operation against the workspace. Validate that the command runs successfully without error and no unexpected messages are logged. The Plan should result in no proposed changes to the resources.\n5. Run a Apply Plan operation against the workspace. This step is mandatory to perform a Terraform state file update. Validate that the command runs successfully without error and no unexpected messages are logged.\n6. You have now successfully upgraded a single version step.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-migrating-terraform-version"},{"document_id":"ibmcld_00861-106063-107366","score":11.1275453568,"text":"\nTo view the contents of version 3.3, from the running image, type default_versions.sh. The 3.x branch provides images with the current tool versions. The current Java\u2122 version is Java\u2122 11. Node.js no longer uses nvm to manage different node.js versions. It provides the current LTS version of Node.js at the time that it was built.\n\nThe IBM Cloud CLI provides code risk analysis commands. You can use the IBM Cloud CLI to analyze your code for vulnerabilities and compliance with certain rules. Code Risk Analyzer is available in all IBM Cloud regions where toolchains are supported. For more information about Code Risk Analyzer, see [Code Risk Analyzer plug-in](https:\/\/cloud.ibm.com\/docs\/code-risk-analyzer-cli-plugin).\n\nThis image includes the following tools:\n\n node --version\nv14.17.6\n\n npm --version\n6.14.15\n\n jq --version\njq-1.6\n\n yq --version\nyq (https:\/\/github.com\/mikefarah\/yq\/) version 4.13.2\n\n kubectl version --client\nClient Version: version.Info{Major:\"1\", Minor:\"20\", GitVersion:\"v1.20.5\", GitCommit:\"6b1d87acf3c8253c123756b9e61dac642678305f\", GitTreeState:\"clean\", BuildDate:\"2021-03-18T01:10:43Z\", GoVersion:\"go1.15.8\", Compiler:\"gc\", Platform:\"linux\/amd64\"}\n\n buildctl --version\nbuildctl github.com\/moby\/buildkit v0.9.0 c8bb937807d405d92be91f06ce2629e6202ac7a9\n\n helm version --client","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_00861-221488-222586","score":11.0206203461,"text":"\nJVM: 11.0.10 (Eclipse OpenJ9 openj9-0.24.0)\nOS: Linux 5.10.47-linuxkit amd64\n\n oc version\nClient Version: 4.8.11\n\n zip\nCopyright (c) 1990-2008 Info-ZIP - Type 'zip \"-L\"' for software license.\nThis is Zip 3.0 (July 5th 2008), by Info-ZIP.\n\n unzip\nUnZip 6.00 of 20 April 2009, by Debian. Original by Info-ZIP.\n\n git --version\ngit version 2.17.1\n\n curl\ncurl 7.58.0 (x86_64-pc-linux-gnu) libcurl\/7.58.0 OpenSSL\/1.1.1 zlib\/1.2.11 libidn2\/2.0.4 libpsl\/0.19.1 (+libidn2\/2.0.4) nghttp2\/1.30.0 librtmp\/2.3\n\n wget\nGNU Wget 1.19.4 built on linux-gnu.\n\n openssl version\nOpenSSL 1.1.1 11 Sep 2018\n\n make\nGNU Make 4.1\n\n docker\nClient: Docker Engine - Community\nVersion: 19.03.9\nAPI version: 1.40\nGo version: go1.13.10\nGit commit: 9d988398e7\nBuilt: Fri May 15 00:22:47 2020\nOS\/Arch: linux\/amd64\nExperimental: false\n\n dc --version\ndc (GNU bc 1.07.1) 1.4.1\n\n ed --version\nGNU Ed 1.10\nShow more\n\n\n\n\n\n Version 2.14 \n\nTo view the contents of version 2.14, from the running image, type default_versions.sh. This image includes the following tools:\n\n node --version\nv14.17.6\n\n npm --version\n6.14.15\n\n jq --version\njq-1.6","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_00861-209533-210870","score":10.8607120514,"text":"\ndc (GNU bc 1.07.1) 1.4.1\n\n ed --version\nGNU Ed 1.10\nShow more\n\n\n\n\n\n Version 2.17 \n\nTo view the contents of version 2.17, from the running image, type default_versions.sh.\n\nThe IBM Cloud CLI provides code risk analysis commands. You can use the IBM Cloud CLI to analyze your code for vulnerabilities and compliance with certain rules. Code Risk Analyzer is available in all IBM Cloud regions where toolchains are supported. For more information about Code Risk Analyzer, see [Code Risk Analyzer plug-in](https:\/\/cloud.ibm.com\/docs\/code-risk-analyzer-cli-plugin).\n\nThis image updated its version of node.js to the current LTS version 16.13.0. If you need to keep the previous node.js version 14.17.6, you can either continue to use the previous image or you can add nvm install v14.17.6 to the beginning of your script.\n\nThis image includes the following tools:\n\n node --version\nv16.13.0\n\n npm --version\n8.1.0\n\n jq --version\njq-1.6\n\n yq --version\nyq version 2.4.1\n\n yq3 --version\nyq version 3.4.1\n\n yq4 --version\nyq (https:\/\/github.com\/mikefarah\/yq\/) version 4.16.2\n\n kubectl version --client\nClient Version: version.Info{Major:\"1\", Minor:\"20\", GitVersion:\"v1.20.14\", GitCommit:\"57a3aa3f13699cf3db9c52d228c18db94fa81876\", GitTreeState:\"clean\", BuildDate:\"2021-12-15T14:52:33Z\", GoVersion:\"go1.15.15\", Compiler:\"gc\", Platform:\"linux\/amd64\"}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_00861-57518-58664","score":10.5166463852,"text":"\nCopyright (c) 1990-2008 Info-ZIP - Type 'zip \"-L\"' for software license.\nThis is Zip 3.0 (July 5th 2008), by Info-ZIP.\n\n unzip\nUnZip 6.00 of 20 April 2009, by Info-ZIP. Maintained by C. Spieler. Send\n\n git --version\ngit version 2.31.1\n\n curl\ncurl 7.61.1 (x86_64-redhat-linux-gnu) libcurl\/7.61.1 OpenSSL\/1.1.1k zlib\/1.2.11 brotli\/1.0.6 libidn2\/2.2.0 libpsl\/0.20.2 (+libidn2\/2.2.0) libssh\/0.9.6\/openssl\/zlib nghttp2\/1.33.0\n\n wget\nGNU Wget 1.19.5 built on linux-gnu.\n\n openssl version\nOpenSSL 1.1.1k FIPS 25 Mar 2021\n\n make\nGNU Make 4.2.1\n\n docker\nClient:\nVersion: 20.10.22\nAPI version: 1.41\nGo version: go1.18.9\nGit commit: 3a2c30b\nBuilt: Thu Dec 15 22:21:58 2022\nOS\/Arch: linux\/amd64\nContext: default\n\n dc --version\ndc (GNU bc 1.07.1) 1.4.1\n\n ed --version\nGNU ed 1.14.2\n\n skopeo --version\nskopeo version 1.9.3\n\n terraform version\nTerraform v1.3.7\non linux_amd64\nShow more\n\n\n\n\n\n Version 3.14 \n\nTo view the contents of version 3.14, from the running image, type default_versions.sh. The 3.x branch provides images with the current tool versions. The current Java\u2122 version is Java\u2122 17. Node.js no longer uses nvm to manage different node.js versions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16034-7-1778","score":15.7922296524,"text":"\nVPC CLI release notes \n\nThe following release notes are for the IBM Cloud\u00ae Virtual Private Cloud (VPC) command line interface (CLI).\n\n\n\n v6.15.0 \n\nVersion 6.15.0 was released on 2023-07-11.\n\n\n\n New commands \n\n\n\n* New commands image-obsolete and image-deprecate are introduced to support image lifecycle management.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for image lifecycle management in image-create, image-update, and images commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.14.1 \n\nVersion 6.14.1 was released on 2023-06-30.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed issue with using the SSH key generated from UI in CLI.\n\n\n\n\n\n\n\n\n\n v6.14.0 \n\nVersion 6.14.0 was released on 2023-06-23.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for more algorithms in the SSH key key-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.13.0 \n\nVersion 6.13.0 was released on 2023-06-22.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for snapshot and backup cross region copy in snaphot-create, snapshots, backup-policy-plan-create and backup-policy-plan-update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.12.0 \n\nVersion 6.12.0 was released on 2023-06-01.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for fileshare mount targets in share commands (Beta).\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces, bare-metal-server-profiles and bare-metal-servers commands to print correct response values.\n\n\n\n\n\n\n\n\n\n v6.11.1 \n\nVersion 6.11.1 was released on 2023-05-03.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-28644-30202","score":15.7554998398,"text":"\nv0.6.0 \n\nVersion 0.6.0 was released on 2020-06-30.\n\n\n\n New commands \n\n\n\n* Added Creating instance from instance-template support for 'instance-create-from-template' command.\n* (Beta) Added commands to support dedicated host.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated all commands with VPC API version to '2020-05-19'.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.5.14 \n\nVersion 0.5.14 was released on 2020-04-30.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added HTTPS protocol and HTTPS health-type support for 'load-balancer-pool-create' command.\n* Added HTTPS protocol and HTTPS health-type support for 'load-balancer-pool-update' command.\n* Added floating IP data to 'instance' command JSON output.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.5.13 \n\nVersion 0.5.13 was released on 2020-04-13.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added CRN fields to various details commands output\n* Add example for the key-create and key-update commands\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.5.11 \n\nVersion 0.5.11 was released on 2020-03-05.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added resource tag fields to the ibmcloud is volumes command output\n* Updated the ibmcloud is network-acl-rule-add command example\n* Updated the ibmcloud is network-acl-create command example\n* Added more command examples to the [VPC CLI reference](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference)\n* Translation update to the command help\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Other","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-25914-27753","score":15.2233467102,"text":"\nVersion 0.7.0 was released on 2020-10-30.\n\n\n\n New commands \n\n\n\n* Add 'create', 'update', 'list', 'get', 'delete' commands for VPC routing-table and routes (custom routes) feature\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add 'allow-ip-spoofing' flag for network-interface in instance create and network-interface create\/update commands\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.6.6 \n\nVersion 0.6.6 was released on 2020-10-23.\n\n\n\n New commands \n\n\n\n* Add load-balancer-pool-members-update command to replace the entire pool members\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Remove the DNS service from endpoint-gateway-targets command output\n* Add --members flag to load-balancer-pool-create command to support creating pool with members\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.6.4 \n\nVersion 0.6.4 was released on 2020-09-16.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update all deletion commands to support batch deletion.\n* Update vpc-routing-table-create and vpc-routing-table-update to support ingress custom routing feature.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.6.3 \n\nVersion 0.6.3 was released on 2020-08-24.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update VPC API version to 2020-08-11\n* Update network load balancer create command with '--family network' instead of the --profile option.\n* Update load-balancer-pool-update command to reset the session-persistence to null with '--session-persistence-type none'.\n* Update \u2018target\u2019 command to support only the accounts that have generation 1 access.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* Hide 'load-balancer-profiles' command and it will be removed in next major release.\n* Hide 'load-balancer-profile' command and it will be removed in next major release.\n* Hide the 'target' command for the account that doesn't have generation 1 access.\n\n\n\n\n\n\n\n\n\n v0.6.2","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-5546-7299","score":14.8371324539,"text":"\nv6.2.0 \n\nVersion 6.2.0 was released on 2022-12-14.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated volume-create command to support creation of volume from snapshot.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.1.0 \n\nVersion 6.1.0 was released on 2022-11-21.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated vpc-default-routing-table, vpc-routing-table , vpc-routing-table-create, vpc-routing-table-update commands to support Public Ingress Routing.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.0.0 \n\nVersion 6.0.0 was released on 2022-11-03.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated VPC API version to 2022-09-13.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Fixed backup-policy-job and backup-policy-jobs commands to support Backup As A Service Amendment.\n\n\n\n\n\n\n\n\n\n v5.4.0 \n\nVersion 5.4.0 was released on 2022-10-06.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated instance-create and instance-update commands to support VNF Scalability.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v5.3.0 \n\nVersion 5.3.0 was released on 2022-09-23.\n\n\n\n New commands \n\n\n\n* Added ibmcloud is catalog-image-offerings and ibmcloud is catalog-image-offering commands to support Enterprise Image Sharing.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated instance-create , instance-create-from-template , instance-template-create and instance-template-create-override-source-template commands to support Enterprise Image Sharing.\n* Updated ike-policy-create , ike-policy-update , ipsec-policy-create and ipsec-policy-update commands to support Additional Cipher Suites for VPN.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v5.2.0 \n\nVersion 5.2.0 was released on 2022-09-16.\n\n\n\n New commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-24499-26290","score":14.198266983,"text":"\nVersion 0.7.7 was released on 2021-02-08.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Remove the restriction for Generation 1 target switching.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.4 \n\nVersion 0.7.4 was released on 2020-12-10.\n\n\n\n New commands \n\n\n\n* Add instance storage disk get, list, and update commands.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add flag aliases for routing table create and update commands.\n* Updated usage for ibmcloud is vpc-address-prefix-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.3 \n\nVersion 0.7.3 was released on 2020-11-19.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add datapath logging support for load balancer create and update commands\n* Add ingress routing support for VPC routing table create and update commands\n* Add required family\/class flags for dedicated host group create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.2 \n\nVersion 0.7.2 was released on 2020-11-12.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add static, route-based mode support for creating a VPN gateway and connection.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.1 \n\nVersion 0.7.1 was released on 2020-11-05.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add proxy-protocol feature support for load balancer listener\/pool create and update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.0 \n\nVersion 0.7.0 was released on 2020-10-30.\n\n\n\n New commands \n\n\n\n* Add 'create', 'update', 'list', 'get', 'delete' commands for VPC routing-table and routes (custom routes) feature\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add 'allow-ip-spoofing' flag for network-interface in instance create and network-interface create\/update commands\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.6.6","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_05684-2632-4362","score":13.7428874969,"text":"\nVersion 1.0.480 of the CLI was released on 14 December 2022.\n: Adjusted ibmcloud ks flavor get and ibmcloud ks flavor ls commands to show secondary storage details.\n: Introduced Secondary Storage Configuration for worker-pool get.\n: Added Ignored Errors to ingress status-report.\n\n\n\n\n\n Version 1.0.471 \n\nVersion 1.0.471 of the CLI was released on 1 December 2022.\n: Adds new endpoint type vpe(Virtual Private Endpoint) for cluster config command.\n: Updates the cluster get command to show VPE url.\n: Adds infrastructureTopology field to cluster response.\n: Adds JSON output to Satellite get host command.\n\n\n\n\n\n Version 1.0.459 \n\nVersion 1.0.459 of the CLI was released on 21 October 2022.\n: Adds the --infrastructure-topology option for the ibmcloud ks cluster create satellite command.\n: Adds new ibmcloud ks flavor get and ibmcloud ks flavor ls commands.\n\n\n\n\n\n Version 1.0.454 \n\nVersion 1.0.454 of the CLI was released on 3 October 2022.\n: Adds new [Ingress status](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clialb-commands) commands.\n: Adds the --operating-system option for the cluster create commands.\n\n\n\n\n\n Version 1.0.452 \n\nVersion 1.0.452 of the CLI was released on 21 September 2022.\n: Updates the help text in various languages.\n\n\n\n\n\n Version 1.0.446 \n\nVersion 1.0.446 of the CLI was released on 12 September 2022.\n: Adds --pod-network-interface-selection option to location create flow.\n\n\n\n\n\n Version 1.0.444 \n\nVersion 1.0.444 of the CLI was released on 8 September 2022.\n: Adds Secrets Manager registration to cluster create flow.\n: Adds worker-pool OS support.\n: Removes Ingress migration command support.\n\n\n\n\n\n Version 1.0.439 \n\nVersion 1.0.439 of the CLI was released on 26 Aug 2022.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_cli_changelog"},{"document_id":"ibmcld_10140-2632-4302","score":13.7028970718,"text":"\nVersion 1.0.480 of the CLI was released on 14 December 2022.\n: Adjusted ibmcloud oc flavor get and ibmcloud oc flavor ls commands to show secondary storage details.\n: Introduced Secondary Storage Configuration for worker-pool get.\n: Added Ignored Errors to ingress status-report.\n\n\n\n\n\n Version 1.0.471 \n\nVersion 1.0.471 of the CLI was released on 1 December 2022.\n: Adds new endpoint type vpe(Virtual Private Endpoint) for cluster config command.\n: Updates the cluster get command to show VPE url.\n: Adds infrastructureTopology field to cluster response.\n: Adds JSON output to Satellite get host command.\n\n\n\n\n\n Version 1.0.459 \n\nVersion 1.0.459 of the CLI was released on 21 October 2022.\n: Adds the --infrastructure-topology option for the ibmcloud oc cluster create satellite command.\n: Adds new ibmcloud oc flavor get and ibmcloud oc flavor ls commands.\n\n\n\n\n\n Version 1.0.454 \n\nVersion 1.0.454 of the CLI was released on 3 October 2022.\n: Adds new [Ingress status](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clialb-commands) commands.\n: Adds the --operating-system option for the cluster create commands.\n\n\n\n\n\n Version 1.0.452 \n\nVersion 1.0.452 of the CLI was released on 21 September 2022.\n: Updates the help text in various languages.\n\n\n\n\n\n Version 1.0.446 \n\nVersion 1.0.446 of the CLI was released on 12 September 2022.\n: Adds --pod-network-interface-selection option to location create flow.\n\n\n\n\n\n Version 1.0.444 \n\nVersion 1.0.444 of the CLI was released on 8 September 2022.\n: Adds Secrets Manager registration to cluster create flow.\n: Adds worker-pool OS support.\n: Removes Ingress migration command support.\n\n\n\n\n\n Version 1.0.439","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog"},{"document_id":"ibmcld_16034-12689-13797","score":13.4789819717,"text":"\nVersion 3.4.0 was released on 2022-02-24.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance-create, instance-update, instance-template-create, instance-template-create-override-source-template and instance-create-from-template commands to support metadata service.\n* Update instance-create and instance-create-from-template commands to support trusted profile.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v3.3.0 \n\nVersion 3.3.0 was released on 2022-02-17.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance-create, instance-update, instance-template-create, instance-template-create-override-source-template and instance-create-from-template, commands to add support for vm-host-failure-policy.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v3.2.0 \n\nVersion 3.2.0 was released on 2022-02-11.\n\n\n\n New commands \n\n\n\n* N\/A.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance-create, instance-update and volume-update commands to support resize boot volume.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v3.1.0 \n\nVersion 3.1.0 was released on 2022-01-28.\n\n\n\n New commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-14851-15753","score":13.3618516922,"text":"\n* N\/A\n\n\n\n\n\n\n\n\n\n v3.0.0 \n\nVersion 3.0.0 was released on 2022-01-19.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update security-group-target, security-group-target-add, security-group-target-remove, and endpoint-gateway-create commands to add security group support for endpoint-gateway.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Removed the support for creation of load balancer listener with port and protocol as arguments.\n\n\n\n\n\n\n\n\n\n v2.1.0 \n\nVersion 2.1.0 was released on 2021-11-29.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update vpn-server-update command to support VPN server upgrade and downgrade.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Linux_S390x build support added.\n\n\n\n\n\n\n\n\n\n v2.0.0 \n\nVersion 2.0.0 was released on 2021-11-18.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance commands with \"by name\" support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-4138-5877","score":12.6689367294,"text":"\n* Updated instance-create, instance-create-from-template, instance-update, instance-template-create and instance-template-create-override-source-template commands to support instance metadata service.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.5.0 \n\nVersion 6.5.0 was released on 2023-02-07.\n\n\n\n New commands \n\n\n\n* Added snapshot-clone, snapshot-clone-create, snapshot-clone-delete and snapshot-clonescommands to support snapshot fast restore.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated snapshot-create, backup-policy-create, backup-policy-plan-create and backup-policy-plan-update commands to support snapshot and backup fast restore.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.4.0 \n\nVersion 6.4.0 was released on 2023-01-31.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated bare-metal-server-create, bare-metal-server-update and bare-metal-server commands to support secure boot mode and TPM.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.3.0 \n\nVersion 6.3.0 was released on 2023-01-13.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated ike-policy-create, ike-policy-update, ipsec-policy-create and ipsec-policy-update commands to remove the weak ciphers.\n* Updated vpn-server-create, vpn-server-update, load-balancer-listener-create and load-balancer-listener-update commands to remove the certificate manager support.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.2.0 \n\nVersion 6.2.0 was released on 2022-12-14.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated volume-create command to support creation of volume from snapshot.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.1.0 \n\nVersion 6.1.0 was released on 2022-11-21.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15646-26617-28366","score":20.5188999176,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-26643-28392","score":20.5188999176,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-6657-8493","score":19.2493171692,"text":"\nIf you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Changing an image from volume lifecycle status by using the API \n\nYou can change the lifecycle status of a IBM Cloud VPC image from volume by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_16092-195812-197090","score":18.6375179291,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference&interface=cli"},{"document_id":"ibmcld_15545-195860-197138","score":18.6375179291,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_16082-195756-197034","score":18.6375179291,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference"},{"document_id":"ibmcld_15558-195912-197190","score":18.6375179291,"text":"\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image\n* ibmcloud is image-update my-image-from-volume-cli --name my-image-from-volume-cli-do-not-delete --obsolete-at \"2023-03-02T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --deprecate-at \"2023-03-03T04:20:00+05:30\"\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-deprecate-at\n* ibmcloud is image-update my-image-from-volume-cli-do-not-delete --reset-obsolete-at\n\n\n\n\n\n\n\n Command options \n\n\n\n* IMAGE: ID or name of the image.\n* --name: New name of the image.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --reset-deprecate-at: Specify this flag to remove an existing deprecation date and time. If the image status is \"deprecated\", it becomes \"available\".\n* --obsolete-at: The obsolescence date and time to set for this image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"},{"document_id":"ibmcld_15646-25256-26940","score":18.5213603973,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-25269-26966","score":18.0810508728,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_16092-194819-196096","score":17.8558940887,"text":"\nIf this property is not provided, the root key from source volume is used.\n* --resource-group-id: ID of the resource group. This ID is mutually exclusive with --resource-group-name.\n* --resource-group-name: Name of the resource group. This name is mutually exclusive with --resource-group-id.\n* --deprecate-at: The deprecation date and time to set for this image. The date and time must not be in the past, and must be earlier than \"obsolete_at\". Date and time must be in the ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00\n* --obsolete-at: The obsolescence date and time to set for this image. The date and time must not be in the past, and must be later than \"deprecate_at\". Date and time must be in ISO 8601 format: 2024-03-05T15:31:50.701Z or 2024-03-05T15:31:50.701+8:00.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is image-update \n\nUpdate an image.\n\nibmcloud is image-update IMAGE --name NEW_NAME [--deprecate-at DEPRECATE_AT | --reset-deprecate-at] [--obsolete-at OBSOLETE_AT | --reset-obsolete-at] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-update 72251a2e-d6c5-42b4-97b0-b5f8e8d1f479 --name my-image","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference&interface=cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2893079283}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15646-25256-26940","score":21.5331249237,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-25269-26966","score":21.3109951019,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-5434-7003","score":21.2557430267,"text":"\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15507-8094-9618","score":20.5374526978,"text":"\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15175-10224-11754","score":20.5259132385,"text":"\necc68c2f-96a1-4862-bc86-14f47e5d9ed8 aa-1-bx-boot-1617035447000\nCreated 2021-05-20T09:43:16+08:00\nVisibility private\nFile size(GB) -\nEncryption none\nResource group f22cf48f-8836-4527-9131-1d7c73ba85e9\n\n\n\n\n\n\n\n Schedule custom image lifecycle status changes by using the CLI \n\nWhen you import a custom image by using the command-line interface (CLI), you can also schedule the lifecycle status changes of the IBM Cloud VPC custom image at the same time by using options of the ibmcloud is image-create command.\n\nSpecify the name of the custom image to be created by using the IMAGE_NAME variable and the source by using the --source-volume option to indicate that the source is an existing boot volume.\n\nTo schedule the deprecate-at or obsolete-at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates and times, the deprecate-at date must be after the obsolete-at date and time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-ifv"},{"document_id":"ibmcld_15647-27849-29558","score":20.0306243896,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15646-26617-28366","score":20.0293369293,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-26643-28392","score":20.0293369293,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-9295-10840","score":20.0157604218,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again. The previous dates and times are replaced with the new dates and times.\n\n\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the API \n\nMake a PATCH \/images request to remove any scheduled status change by updating deprecation_at or obsolescence_at to null. This property change removes the date and time from the image and the image is no longer scheduled for that status change.\n\n\n\n* To change an image from deprecated to available, change the deprecation_at property to null.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-29196-30599","score":19.9392261505,"text":"\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"}],"retriever_scores":{"recall_1":0.1428571429,"recall_3":0.2857142857,"recall_5":0.2857142857,"recall_10":0.2857142857,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.55314647,"ndcg_cut_10":0.4483039899}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":16.102809906,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_16727-1216520-1218568","score":14.2957057953,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1213887-1215935","score":14.2957057953,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12415-7-1973","score":13.9126520157,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_06881-2811-4554","score":13.709859848,"text":"\nIt runs the static scans and dynamic scans on the Application Source Code, detect secrets in Git repos, Bill Of Materials (BOM) check, CIS check, and Vulnerability Advisor scan. After scanning and running checks on artifacts and source repositories, the pipeline creates a new incident issue or updates the existing incident issues in the incident repository. Finally, using these issues and the results, the pipeline collects evidence and summarizes the evidence, so the Security and Compliance Center Center can update the compliance status of the found artifacts.\n\nThe CC pipeline uses the [async sub pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-async-stagesasync-stages-setup-triggers) that runs in parallel to the main pipeline run to optimize pipeline run time and improve pipeline resiliency.\n\nThis tutorial uses a staging environment as an example to configure and showcase the continuous compliance (CC) toolchain.\n\nThe CC toolchain implements the following best practices:\n\n\n\n* Runs a static code scanner at pre-defined intervals on the application repositories that are provided to detect secrets in the application source code and vulnerable packages that are used as application dependencies.\n* Scan the container image for security vulnerabilities.\n* Any incident issue that is found during the scan or updated is marked with a due date.\n* Generate a summary.json file and store in IBM Cloud Object Storage at the end of every run that summarizes the details of the scan.\n\n\n\nLet's get started with the creation and exploration of the CC toolchain.\n\n\n\n\n\n Step 1: Start the CC toolchain setup \n\nStart the CC toolchain configuration by using one of the following options:\n\n\n\n* Click Create toolchain.\n\n[!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cc-toolchain"},{"document_id":"ibmcld_06836-7569-8653","score":13.3785209656,"text":"\nup from the environment-properties configmap\n\n Eg. if there's a prop: my-config entry in the environment properties,\n then my-config is going to be used for $prop\nconfigmap: $prop\n\n the mechanism described works for secrets as well!\nsecret: $my-secrets\n\n the script is executed inside the checked out app repo\nscript: \n!\/bin\/sh\n...\n\n test runs after setup, but before building the docker image\ntest:\nimage: ibmcom\/pipeline-base-image:2.7\nscript: \n!\/bin\/sh\n...\n\n static-scan runs after test, but before building the docker image\nstatic-scan:\nimage: ibmcom\/pipeline-base-image:2.12\nscript: \n!\/bin\/sh\n...\n\n deploy runs after building the docker image\ndeploy:\nimage: ibmcom\/pipeline-base-image:2.7\n\n the script has access to the built docker image, which is available at \/config\/image\nscript: \n!\/bin\/sh\n\ncat \/config\/image\n\n dynamic-scan runs after deploy, but before the acceptance test run\ndynamic-scan:\nimage: ibmcom\/pipeline-base-image:2.12\nscript: \n!\/bin\/sh\n...\n\n acceptance-test runs after deploy\nacceptance-test:\nimage: ibmcom\/pipeline-base-image:2.7\nscript: \n!\/bin\/sh\n...\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-scripts"},{"document_id":"ibmcld_12717-7818-8740","score":13.3502140045,"text":"\nCheck whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether Secrets Manager arbitrary secrets are rotated at least every # days IA-5(g) Rule was added \n Check whether Secrets Manager user credentials are rotated at least every # days IA-5(g) Rule was added","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-fs-change-log"},{"document_id":"ibmcld_16729-294066-295916","score":13.2242012024,"text":"\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Getting started with Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started)Getting started with Secrets Manager\n\nThis tutorial focuses on storing and managing a username and password in IBM Cloud\u00ae Secrets Manager. With Secrets Manager, you can create, lease, and centrally manage secrets that are used in IBM Cloud services or your custom-built applications. Secrets are stored in a dedicated Secrets Manager instance, built on open source HashiCorp Vault.\n\nSecrets Manager\n\n\n\n* 10 minutes\n* 2023-03-01\n\n\n\n[Access a storage bucket by using a dynamic secret](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket)Access a storage bucket by using a dynamic secret\n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nSecrets Manager Object Storage\n\n\n\n* 1 hour\n* 2023-05-30\n\n\n\n[Secure secrets for apps that run in your Kubernetes cluster](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-kubernetes-secrets)Secure secrets for apps that run in your Kubernetes cluster\n\nThis tutorial is for the Classic flavor of Kubernetes Service clusters. External Secrets is also available as an OpenShift operator.\n\nSecrets Manager\n\n\n\n* 45 minutes\n* 2023-06-15\n\n\n\n[Part 2: Create a GitHub issue when your certificates are about to expire](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-expiring-secrets-part-2)Part 2: Create a GitHub issue when your certificates are about to expire","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_06843-4238-6198","score":13.1385030746,"text":"\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline"},{"document_id":"ibmcld_12498-9696-11699","score":12.9270610809,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.8065735964}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14389-3006-4736","score":13.5226583481,"text":"\n* Better - This offer is built on the benefits of the Good option, with the addition of BIG-IP DNS\u2122, BIG-IP Advanced Firewall Manager\u2122 (AFM), and BIG-IP Application Acceleration Manager\u2122 (AAM) modules. It delivers global traffic management services, application performance optimization, and advanced network firewall and Distributed Denial of Service (DDoS) mitigation capabilities.\n* Best - In addition to the Good and Better offers, BIG-IP Application Security Manager\u2122 (ASM) provides:\n\n\n\n* Comprehensive application protection against L7 DDoS\n* Open Web Application Security Project (OWASP) top 10 threats\n* Common application vulnerabilities\n\n\n\n\n\nBIG-IP Access Policy Manager\u2122 (APM) offers users secure, simplified access to applications located anywhere within a multicloud environment, incorporating features such as SSO (Single Sign-On) and MFA (Multifactor Authentication).\n\nYou cannot change the license model after service installation. To change the license model, you must delete the existing service and reinstall the service by choosing a different license model.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [F5 BIG-IP overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-f5_considerations)\n* [Managing F5 BIG-IP](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-managing_f5)\n* [Ordering services for vCenter Server instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservices)\n* [Contacting IBM\u00ae Support](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-trbl_support)\n* [FAQ](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-faq-vmwaresolutions)\n* [F5 Deployment Guides](https:\/\/www.f5.com\/services\/resources\/deployment-guides)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-f5_ordering"},{"document_id":"ibmcld_11573-21506-21994","score":13.4487600327,"text":"\n* [SAP Note 2588225 - SAP on IBM Cloud: Protect against speculative execution vulnerabilities](https:\/\/launchpad.support.sap.com\/\/notes\/2588225)\n* [SAP Note 1380654 - SAP support in IaaS environments](https:\/\/launchpad.support.sap.com\/\/notes\/1380654)\n* [SAP Note 2414097 - SAP Applications on IBM Cloud Classic Infrastructure environment](https:\/\/launchpad.support.sap.com\/\/notes\/2414097)\n\n\n\nThis automation is offered free of charge however, the provisioned infrastructure comes at cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-create-terraform-3tier-nw-hana-vpc-ansible"},{"document_id":"ibmcld_10510-53754-56042","score":13.1789216995,"text":"\nTo protect your app, you must protect the image and establish checks to ensure the image's integrity.\n\nShould I use a public or a private registry to store my images?\n: Public registries, such as Docker Hub, can be used to get started with Docker images and Kubernetes to create your first containerized app in a cluster. But when it comes to enterprise applications, avoid registries that you don't know or don't trust to protect your cluster from malicious images. Keep your images in a private registry, like the one provided in IBM Cloud Container Registry or the [internal registry](https:\/\/docs.openshift.com\/container-platform\/4.11\/registry\/index.html) that is automatically set up in your Red Hat OpenShift cluster, and make sure to control access to the registry and the image content that can be pushed.\n\nWhy is it important to check images against vulnerabilities?\n: Research shows that most malicious attacks leverage known software vulnerabilities and weak system configurations. When you deploy a container from an image, the container spins up with the OS and extra binaries that you described in the image. Just like you protect your virtual or physical machine, you must eliminate known vulnerabilities in the OS and binaries that you use inside the container to protect your app from being accessed by unauthorized users.\n\nTo protect your apps, consider to address the following areas:\n\n\n\n1. Automate the build process and limit permissions: Automate the process to build your container image from your source code to eliminate source code variations and defects. By integrating the build process into your CI\/CD pipeline, you can ensure that your image is scanned and built only if the image passes the security checks that you specified. To avoid that developers apply hot fixes to sensitive images, limit the number of people in your organization who have access to the build process.\n2. Scan images before they deploy into production: Make sure to scan every image before you deploy a container from it. For example, if you use IBM Cloud Container Registry, all images are automatically scanned for vulnerabilities when you push the image to your namespace. If vulnerabilities are found, consider eliminating the vulnerabilities or block deployment for those images.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_01533-4546-6910","score":12.6915283203,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_16696-7-2390","score":12.6631088257,"text":"\nKey features of IBM Cloud Security and Compliance Center Workload Protection \n\nIBM Cloud\u00ae Security and Compliance Center Workload Protection offers functionality to protect workloads, get deep cloud and container visibility, posture management (compliance, benchmarks, CIEM), vulnerability scanning, forensics, and threat detection and blocking.\n\n\n\n Provides a unified and centralized framework to manage the security and compliance of applications, workloads and infrastructure \n\n\n\n* Provides a unified and centralized framework to manage the security and compliance of applications, workloads and infrastructure and protect workloads and resources that run on IBM Cloud, in other clouds, and on-prem. Presents relevant performance and security data in one location.\n* Is built on open standards for cloud native security and control, including Falco, the open source standard for cloud threat detection, and Open Policy Agent (OPA), the open source standard for policy-as-code.\n* Offers a workload protection platform (WPP) that focuses on management and security controls for workloads.\n* Offers a compliance platform (CP) that focuses on management and compliance controls that are required to meet industry standards and laws.\n* Includes Cloud security posture management (CSPM) to help you secure the infrastructure where workloads are deployed.\n* Includes Kubernetes Security Posture Management (KSPM) to help you secure Kubernetes clusters or Openshift clusters, and the workloads running within it.\n* Offers alerting on violations, and assists with remediation tasks.\n\n\n\n\n\n\n\n Offers host and image scanning, auditing, and runtime vulnerability management capabilities \n\n\n\n* Filters and surfaces vulnerabilities in images, clusters, namespaces, or hosts.\n* Alerts on unscanned images or images when the evaluation status changes with new vulnerabilities.\n* Logs user actions, container activity, and command arguments.\n* Enforces security policies and blocks attacks.\n\n\n\n\n\n\n\n Provides posture management for a distributed environment \n\n\n\n* Schedules customized benchmark tests to run across cloud, hosts, services, or clusters.\n* Controls compliance at cloud, orchestrator, and container level.\n* Tracks and optimizes cloud users permissions and entitlements.\n* Exports results to SIEM, logging clusters, or other tools.\n\n\n\n\n\n\n\n Provides runtime detection and data enrichment","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-key-features"},{"document_id":"ibmcld_07854-0-2195","score":12.6568050385,"text":"\n\n\n\n\n\n\n  SA-12 - Supply Chain Protection \n\n\n\n  Control requirements \n\nSA-12 - 0\n:   The organization protects against supply chain threats to the information system, system component, or information system service by employing [IBM Assignment: IBM-defined personnel security requirements, approved HW\/SW vendor list\/ process, and secure SDLC procedures] as part of a comprehensive, defense-in-breadth information security strategy.\n\n\n\n\n\n  NIST supplemental guidance \n\nInformation systems (including system components that compose those systems) need to be protected throughout the system development life cycle (i.e., during design, development, manufacturing, packaging, assembly, distribution, system integration, operations, maintenance, and retirement). Protection of organizational information systems is accomplished through threat awareness, by the identification, management, and reduction of vulnerabilities at each phase of the life cycle and the use of complementary, mutually reinforcing strategies to respond to risk. Organizations consider implementing a standardized process to address supply chain risk with respect to information systems and system components, and to educate the acquisition workforce on threats, risk, and required security controls. Organizations use the acquisition\/procurement processes to require supply chain entities to implement necessary security safeguards to: (i) reduce the likelihood of unauthorized modifications at each stage in the supply chain; and (ii) protect information systems and information system components, prior to taking delivery of such systems\/components. This control also applies to information system services. Security safeguards include, for example: (i) security controls for development systems, development facilities, and external connections to development systems; (ii) vetting development personnel; and (iii) use of tamper-evident packaging during shipping\/warehousing. Methods for reviewing and protecting development plans, evidence, and documentation are commensurate with the security category or classification level of the information system. Contracts may specify documentation protection requirements.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-sa-12"},{"document_id":"ibmcld_09876-2943-4407","score":12.5515737534,"text":"\n* For more information see [What's new in MQ 9.2.1](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SSFKSJ_9.2.0\/com.ibm.mq.pro.doc\/q134930_.html)\n\n\n\n\n\n\n\n\n\n 9.2.0 r1 \n\n\n\n Available from 25th July 2020 \n\n\n\n* Updated to MQ version 9.2.0\n* For more information see [What's new in MQ 9.2.0](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SSFKSJ_9.2.0\/com.ibm.mq.pro.doc\/q134120_.html)\n\n\n\n\n\n\n\n\n\n 9.1.5 r2 \n\n\n\n Available from 9th June 2020 \n\n\n\n* Required security and vulnerability fixes\n\n\n\n\n\n\n\n\n\n 9.1.5 r1 \n\n\n\n Available from 2nd April 2020 \n\n\n\n* Updated to MQ version 9.1.5\n* For more information see [What's new in MQ 9.1.5](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SSFKSJ_9.1.0\/com.ibm.mq.pro.doc\/q128110_.htm)\n\n\n\n\n\n\n\n\n\n 9.1.4 r3 \n\n\n\n Available from 6th February 2020 \n\n\n\n* Improved REST messaging performance\n* Protection against published security vulnerabilities\n\n\n\n\n\n\n\n\n\n 9.1.4 r1 \n\n\n\n Available from 5th December 2019 \n\n\n\n* Updated to MQ version 9.1.4\n* For more information see [What's new in MQ 9.1.4](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SSFKSJ_9.1.0\/com.ibm.mq.pro.doc\/q133200_.htm)\n\n\n\n\n\n\n\n\n\n 9.1.3 r5 \n\n\n\n Available from 26th November 2019 \n\n\n\n* Fix for an issue experienced by some customers when upgrading older queue managers\n\n\n\n\n\n\n\n\n\n 9.1.3 r4 \n\n\n\n Available from 22nd November 2019 \n\n\n\n* Fix for users experiencing unexpected unauthorised errors when using the messaging REST API\n\n\n\n\n\n\n\n\n\n 9.1.3 r3 \n\n\n\n Available from 4th November 2019","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_qm_ver_and_rev_content"},{"document_id":"ibmcld_07949-17036-19108","score":12.2931480408,"text":"\nBy monitoring for risks, you can identify security vulnerabilities and quickly work to mitigate the impact and fix the issue. By using Security and Compliance Center along with [external integrations](https:\/\/cloud.ibm.com\/security-compliance\/integrations) (such as, OpenShift Compliance Operator (OSCO), Tanium, NeuVector, and so on), you can build a robust approach for monitoring for security and compliance issues.\n\n\n\n\n\n\n\n Integration \n\n\n\n IBM Event Streams for IBM Cloud (optional) \n\n[Event Streams](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-about) is a high-throughput message bus built with Apache Kafka. It is optimized for event ingestion into IBM Cloud and event stream distribution between your services and applications.\n\nYou can use Event Streams to complete the following tasks:\n\n\n\n* Offload work to back-end worker applications.\n* Connect event streams to streaming analytics to realize powerful insights.\n* Publish event data to multiple applications to react in real time.\n\n\n\nEvent Streams offers a fully managed Apache Kafka service, ensuring durability and high availability for our clients. By using Event Streams, you have support around the clock from our team of Kafka experts.\n\n\n\n\n\n\n\n Databases \n\n\n\n IBM Cloud Hyper Protect DBaaS for MongoDB (optional) \n\nMoving confidential and mission-critical data to the cloud presents data confidentiality, security, and reliability concerns. [IBM Cloud\u00ae Hyper Protect DBaaS for MongoDB](https:\/\/cloud.ibm.com\/docs\/hyper-protect-dbaas-for-mongodb?topic=hyper-protect-dbaas-for-mongodb-overview) offers highly secure database environments that have technology-enforced protection and high availability.\n\nBuilt on IBM LinuxONE technology, Hyper Protect DBaaS for MongoDB helps you to alleviate data security and compliance concerns with built-in encryption and tamper protection for data at rest and in flight. You can deploy your workloads with sensitive data and build compliant applications without having to be a security expert.\n\n\n\n\n\n IBM Cloud Hyper Protect DBaaS for PostgreSQL (optional)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-about"},{"document_id":"ibmcld_11605-7-2426","score":12.2688112259,"text":"\nIBM Security Services for SAP \n\nIBM Cloud\u00ae Security Services for SAP offer a cybersecurity solution that automates the monitoring and protection of SAP applications on IBM Cloud, and keeps workloads compliant and secure from inside and outside threats.\n\nIBM Services for SAP, developed in partnership with IBM Security Software and other business partners, implement and configure the SAP landscape to meet IT environment requirements for continuous workload visibility and protection.\n\nThrough continuous monitoring, IBM Security Services are able to deliver near real-time preventive, detective, and corrective solutions for securing SAP systems and applications with unmatched coverage and protection. This protection includes context-aware insight across SAP NetWeaver ABAP or Javas and SAP HANA platforms, with network security, security management, and associated workflows.\n\nIBM Security Services for SAP offer the following features:\n\n\n\n* Comprehensive understanding of vulnerabilities and potential attack vectors\n* Methods to implement and avoid defects in ABAP code or SAP Transports\n* Identifying configuration vulnerabilities for ABAP, JAVA, and HANA environments\n* Identifying missing or outdated SAP notes and patches\n* Identifying, monitoring and review of highly privileged SAP accounts\n* Enabling continuous monitoring of vulnerabilities with integration to existing SIEM solution\n\n\n\nKey benefits of requesting IBM Security Services for SAP to assist with your IBM Cloud\u00ae for SAP deployments:\n\n\n\n* Consultative engagement methods centered on your business objectives\n* Experienced end-to-end architectural experts that work jointly with the IBM Cloud team\n* Accelerated cloud adoption for successful implementation of SAP workloads on the cloud\n* Prescriptive best practices for solution implementation by using IBM Cloud Services products and features\n* Rapid learning and risk mitigation through access to IBM Cloud experts\n\n\n\nFor more information, see [IBM.com - IBM Security - SAP Security and GRC Strategy Services](https:\/\/www.ibm.com\/security\/services\/security-governance\/sap-grc-strategy)\n\n\n\n Procedure to request IBM Security Services for SAP \n\nTo begin with IBM Security Services for SAP, use either:\n\n\n\n* Live Chat with IBM Security Sales, by using [IBM.com - IBM Security](https:\/\/www.ibm.com\/security\/services\/security-governance\/sap-grc-strategy) and click Let's talk in the botttom-left","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-ibm-security-services"},{"document_id":"ibmcld_04227-0-2310","score":12.2405576706,"text":"\n\n\n\n\n\n\n  Web Application Firewall concepts \n\nThe Web Application Firewall (WAF) protects against OSI Layer-7 attacks, which can be some of the most tricky. This document gives some details.\n\n\n\n  What is a Web Application Firewall? \n\nA WAF helps protect web applications by filtering and monitoring HTTP traffic between a web application and the internet. A WAF is an OSI protocol Layer-7 defense in the [OSI model](https:\/\/en.wikipedia.org\/wiki\/OSI_model), and it is not designed to defend against all types of attacks.\n\nDeploying a WAF in front of a web application is like placing a shield between the web application and the internet. A proxy server protects a client machine\u2019s identity by using an intermediary (for outgoing traffic), but a WAF is a type of reverse-proxy that protects the server from exposure by having the client's traffic pass through the WAF before reaching the server (for incoming traffic).\n\n\n\n\n\n  Types of attacks WAF can prevent \n\nA WAF typically protects web applications from attacks such as cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection, among others. A WAF usually is part of a suite of tools, which together can create a holistic defense against a range of attack vectors.\n\n\n\n\n\n  How a WAF works \n\nA WAF operates through a set of rules often called policies. These policies aim to protect against vulnerabilities in the application by filtering out malicious traffic.\n\nThe value of a WAF comes from the speed and ease with which its policy modifications can be implemented, thereby allowing a faster response to varying attack vectors. For example, during a [DDoS attack](https:\/\/en.wikipedia.org\/wiki\/Denial-of-service_attack), rate limiting can be implemented by modifying WAF policies.\n\n\n\n\n\n  Key benefits of a CIS WAF \n\nThe IBM Cloud\u00ae Internet Services WAF is an easy way to set up, manage, and customize security rules to protect your web applications from common web threats. See the following list for key features:\n\n\n\n*  Easy setup - The CIS WAF is part of our overall service, which takes just a few minutes to set up. After you redirect your DNS to us, you can switch on the WAF and set up the rules you need.\n*  Detailed reporting - See greater detail in the reporting, for example, threats blocked by rule\/rule group.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-q-and-a"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":16.9927539825,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12415-7-1973","score":16.2982006073,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_12498-9696-11699","score":16.1510906219,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12493-27359-28981","score":15.8316421509,"text":"\nPrerequisites \n\nYou need the [Writer service role](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam) to rotate secrets.\n\n\n\n\n\n Command options \n\npayload\n: The new data to store for an arbitrary secret. Only text-based payloads are supported. If you need to store a binary file, be sure to base64 encode it before you save it to Secrets Manager. For more information, see [Examples](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-clivault-cli-create-static-secret-examples).\n\npassword\n: The new password to assign to a username_password secret.\n\ncertificate\n: The new certificate data to store for an imported_cert secret. Supported file type is .pem.\n\nprivate_key\n: The new private key data to store for an imported_cert secret. Supported file type is .pem.\n\nintermediate\n: The new intermediate certificate data to store for an imported_cert secret. Supported file type is .pem.\n\n-format\n: Prints the output in the format that you specify. Valid formats are table, json, and yaml. The default is table. You can also set the output format by using the VAULT_FORMAT environment variable.\n\n-force\n: Replaces the password that is stored for a username_password secret with a randomly generated, 32-character password that contains uppercase letters, lowercase letters, digits, and symbols.\n\n\n\n\n\n Examples \n\nManually rotate the secret data that is stored for an arbitrary secret.\n\nvault write -format=json ibmcloud\/arbitrary\/secrets\/fe874c2b-e8fd-bbb6-9f19-e91bbe744735\/rotate payload=\"Updated secret data.\"\n\nManually rotate the password that is stored for a username_password secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-cli"},{"document_id":"ibmcld_12717-7818-8740","score":15.6465301514,"text":"\nCheck whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether Secrets Manager arbitrary secrets are rotated at least every # days IA-5(g) Rule was added \n Check whether Secrets Manager user credentials are rotated at least every # days IA-5(g) Rule was added","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-fs-change-log"},{"document_id":"ibmcld_12467-1716-3849","score":15.0553359985,"text":"\n* When you try to modify or delete a secret while it is locked, Secrets Manager denies the request with an HTTP 412 Precondition Failed response. You see an error message similar to the following example:\n\nThe requested action can't be completed because the secret version is locked.\n\nIf you're working with\n\ndynamic secrets, such as IAM credentials, locking your secrets also means that by default, those secrets can't be read or accessed. For more information, see [Why can't I read a locked IAM credentials secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-locked-iam-credentials)\n* If a locked secret reaches its expiration date, it stays in the Active state and its data remains accessible to your applications. Secrets Manager moves the secret to the Destroyed state and permanently deletes the expired secret data only after all locks on the secret are removed.\n\nSSL\/TLS certificates still reach their defined expiration dates and move into a Destroyed state even if they are locked. For more information, see [Why did my locked certificate move to the Destroyed state?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-locked-certificates)\n* If you try to rotate a secret while its current version is locked and the previous version is unlocked (or if an automatic rotation is scheduled), the request to rotate the secret is allowed. The current secret version becomes the new previous version, retaining its existing locks. A new current version is created without any locks.\n* If you try to rotate a secret while its previous version is locked (or if an automatic rotation is scheduled), your request to rotate the secret is denied. Rotation is allowed only after all locks on the previous secret version are removed.\n\n\n\n\n\n Creating locks in the UI \n\nYou can create up to 1000 locks on a secret by using the Secrets Manager UI. Each lock can be used to represent a single application or service that uses your secret.\n\nA secret is considered locked after you attach one or more locks to it. A lock can be applied only on a secret version that contains active payload, or secret data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secret-locks"},{"document_id":"ibmcld_12422-14705-16253","score":14.972026825,"text":"\nIf reuse_api_key is false for IAM credentials, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. For example, the following command creates an IAM credential by using the service_id field.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\nYou can find the ID value of a service ID in the IAM section of the console. Go to Manage > Access (IAM) > Service IDs > name. Click Details to view the ID.\n\ncurl -X POST\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H \"Content-Type: application\/json\" -d '{\n\"name\": \"example-iam-credentials-secret\",\n\"description\": \"Description of my IAM Credentials secret\",\n\"service_id\":\"iam-ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0\",\n\"secret_type\": \"iam_credentials\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"ttl\": \"30m\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_12428-14731-16279","score":14.972026825,"text":"\nIf reuse_api_key is false for IAM credentials, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. For example, the following command creates an IAM credential by using the service_id field.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\nYou can find the ID value of a service ID in the IAM section of the console. Go to Manage > Access (IAM) > Service IDs > name. Click Details to view the ID.\n\ncurl -X POST\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H \"Content-Type: application\/json\" -d '{\n\"name\": \"example-iam-credentials-secret\",\n\"description\": \"Description of my IAM Credentials secret\",\n\"service_id\":\"iam-ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0\",\n\"secret_type\": \"iam_credentials\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"ttl\": \"30m\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"},{"document_id":"ibmcld_12960-7096-9156","score":14.9162750244,"text":"\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"},{"document_id":"ibmcld_00894-7096-9156","score":14.9162750244,"text":"\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.5294362295}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12415-7-1973","score":18.6269721985,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_12498-9696-11699","score":17.8180007935,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12422-4-1817","score":17.8115215302,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Creating IAM credentials \n\nYou can use IBM Cloud\u00ae Secrets Manager to dynamically generate IAM credentials for accessing an IBM Cloud resource that requires IAM authentication.\n\nIAM credentials are\n\ndynamic secretsthat you can use to access an IBM Cloud resource. A set of IAM credentials consists of a service ID and an API key that is generated each time that the protected resource is read or accessed. You can define a time-to-live (TTL) or a lease duration for your IAM credential at its creation so that you shorten the amount of time that the secret exists.\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\nIAM credentials require an extra configuration step before you can start to create or manage them in the service. For more information, see [Configuring the IAM credentials engine](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-configure-iam-engine).\n\nAn account administrator (or any entity with the required level of access) can externally alter IAM Credentials that are created and managed by Secrets Manager. If such a service ID or API key is deleted outside of Secrets Manager, the service might behave unexpectedly. For example, you might be unable to create, or rotate credentials.\n\n\n\n\n\n Creating IAM credentials in the UI \n\nTo create IAM credentials by using the Secrets Manager UI, complete the following steps.\n\n\n\n1. In the console, click the Menu icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_12428-4-1817","score":17.8115215302,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Creating IAM credentials \n\nYou can use IBM Cloud\u00ae Secrets Manager to dynamically generate IAM credentials for accessing an IBM Cloud resource that requires IAM authentication.\n\nIAM credentials are\n\ndynamic secretsthat you can use to access an IBM Cloud resource. A set of IAM credentials consists of a service ID and an API key that is generated each time that the protected resource is read or accessed. You can define a time-to-live (TTL) or a lease duration for your IAM credential at its creation so that you shorten the amount of time that the secret exists.\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\nIAM credentials require an extra configuration step before you can start to create or manage them in the service. For more information, see [Configuring the IAM credentials engine](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-configure-iam-engine).\n\nAn account administrator (or any entity with the required level of access) can externally alter IAM Credentials that are created and managed by Secrets Manager. If such a service ID or API key is deleted outside of Secrets Manager, the service might behave unexpectedly. For example, you might be unable to create, or rotate credentials.\n\n\n\n\n\n Creating IAM credentials in the UI \n\nTo create IAM credentials by using the Secrets Manager UI, complete the following steps.\n\n\n\n1. In the console, click the Menu icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"},{"document_id":"ibmcld_16727-1216520-1218568","score":17.4486808777,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1213887-1215935","score":17.4486808777,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12428-14731-16279","score":17.2506408691,"text":"\nIf reuse_api_key is false for IAM credentials, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. For example, the following command creates an IAM credential by using the service_id field.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\nYou can find the ID value of a service ID in the IAM section of the console. Go to Manage > Access (IAM) > Service IDs > name. Click Details to view the ID.\n\ncurl -X POST\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H \"Content-Type: application\/json\" -d '{\n\"name\": \"example-iam-credentials-secret\",\n\"description\": \"Description of my IAM Credentials secret\",\n\"service_id\":\"iam-ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0\",\n\"secret_type\": \"iam_credentials\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"ttl\": \"30m\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"},{"document_id":"ibmcld_12422-14705-16253","score":17.2506408691,"text":"\nIf reuse_api_key is false for IAM credentials, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. For example, the following command creates an IAM credential by using the service_id field.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\nYou can find the ID value of a service ID in the IAM section of the console. Go to Manage > Access (IAM) > Service IDs > name. Click Details to view the ID.\n\ncurl -X POST\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H \"Content-Type: application\/json\" -d '{\n\"name\": \"example-iam-credentials-secret\",\n\"description\": \"Description of my IAM Credentials secret\",\n\"service_id\":\"iam-ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0\",\n\"secret_type\": \"iam_credentials\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"ttl\": \"30m\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_12438-0-1298","score":16.8829154968,"text":"\n\n\n\n\n\n\n  Why can't I read a locked IAM credentials secret? \n\nYou try to read or access an IAM credentials secret that you manage in IBM Cloud\u00ae Secrets Manager, but you get a 412 Precondition Failed response.\n\n  What\u2019s happening \n\nYou have an IAM credentials secret that you want to regenerate for your application. But when you use the Secrets Manager APIs, SDKs, or CLI to get the secret, you see the following 412 Precondition Failed error:\n\nThe requested action can't be completed because the secret version is locked.\n\n  Why it\u2019s happening \n\nA lock on a secret prevents it from being modified or deleted from your instance. IAM credentials are\n\ndynamic secrets. By default, each request to read an IAM credential (for example, a GET request) generates a new service ID API key, deletes the old credentials, and returns the new credentials. Locking the secret overrides this default behavior and returns a 412 Precondition Failed error to indicate that the secret data is locked. A locked IAM credential can't be read, because doing so modifies its secret data.\n\n  How to fix it \n\nTo regenerate your IAM credentials, you can remove all the locks that are associated with your secret, and try again. To delete locks from the Secrets Manager UI, go to Secrets > secret name > Locks > Delete.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-locked-iam-credentials"},{"document_id":"ibmcld_12404-1334-3137","score":16.8691673279,"text":"\n* [Service ID creator service role](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-servicesidentity-service-account-management) on the IAM Identity Service.\n\n\n\nThe service ID creator service role is only required when you disable the creation of service IDs in your IAM settings. If the account in which you want to generate IAM credentials allows access to only specific IP addresses, you must also update the IP address settings in the account to allow incoming requests from Secrets Manager. For more information, see [Managing access with context-based restrictions](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-access-control-cbr).\n\n\n\n\n\n Setting up the IAM credentials engine in the UI \n\nYou can add an IAM credentials engine configuration by using the Secrets Manager UI. To configure your instance to start creating IAM credentials, complete the following steps.\n\n\n\n1. In the console, click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/icons\/icon_hamburger.svg)> Resource List.\n2. From the list of services, select your instance of Secrets Manager.\n3. In the Secrets engines page, click the IAM credentials tab.\n4. Click Configure.\n5. Enter an API key that has access to create and manage other API keys in your account.\n\nThe service ID that is associated with your API key must have Editor platform access on the IAM Access Groups Service, Service ID creator access, and Operator platform access on the IAM Identity Service.\n6. Click Configure.\n\nNow, your Secrets Manager instance is enabled for IAM credential secrets.\n\n\n\n\n\n\n\n Setting up the IAM credentials engine from the CLI \n\nBefore you can create dynamic IAM credentials, you must configure the IAM secrets engine for your service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-configure-iam-engine"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00589-8040-10059","score":20.0239944458,"text":"\niam_apikey_description\n: Description of IAM API key.\n\niam_apikey_name\n: ID of IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of service ID.\n\npassword\n: The IBM Cloudant legacy credential password.\n\nport\n: IBM Cloudant service port.\n\nurl\n: IBM Cloudant service URL, including embedded IBM Cloudant legacy credentials.\n\nusername\n: The IBM Cloudant legacy credential username.\n\nNote the included username and password are always equivalent to IAM's Manager credentials. Therefore, the use of Use both legacy credentials and IAM is insecure when used with Reader, Writer, Monitor, or Checkpointer IAM roles.\n\n\n\n\n\n\n\n Must I use Use only IAM or Use both legacy credentials and IAM? \n\nIf possible, Use only IAM is preferred. The major advantages for using IBM Cloud IAM are shown in the following list:\n\n\n\n* Management of access to IBM Cloudant with the standard tools of IBM Cloud rather than a combination of IBM Cloud and IBM Cloudant-specific credential management.\n* Credentials can be easily revoked and rotated when you use IBM Cloud IAM.\n\n\n\nFurther description of the advantages and disadvantages of each approach follows.\n\nWhen you use IAM roles other than Manager, such as Reader, Writer, Monitor, or Checkpointer, you must use Use only IAM to avoid supplying users with legacy credentials that include greater access permissions.\n\n\n\n Advantages and disadvantages of the two access control mechanisms \n\nOverall, IBM Cloud IAM is the recommended authentication model. However, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_05567-7-1922","score":19.3132953644,"text":"\nIAM and Activity Tracker action by API method \n\nWhen you use IBM Cloud\u00ae Kubernetes Service such as through the command line or console, the service calls application programming interface (API) methods to complete your requests. In IBM Cloud IAM, each API operation is associated with an IAM action that the user must have an access role to use the API operation. You can keep track of the requests that you make with an IBM Cloud Activity Tracker instance.\n\nReview the following list of IBM Cloud Identity and Access Management (IAM) actions and IBM Cloud Activity Tracker events that correspond to each API method in IBM Cloud Kubernetes Service.\n\nFor more information, see the following topics.\n\n\n\n* [IBM Cloud Kubernetes Service API docs](https:\/\/containers.cloud.ibm.com\/global\/swagger-global-api\/\/)\n* [User access permissions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_reference)\n* [IBM Cloud Activity Tracker events](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-at_events).\n\n\n\n\n\n Account \n\nReview the following account API methods, their corresponding actions in IBM Cloud IAM, and the events that are sent to IBM Cloud Activity Tracker for IBM Cloud Kubernetes Service.\n\n\n\nAccount API methods, IAM actions, and Activity Tracker events.\n\n API Method Description IAM action for the API Event sent to Activity Tracker \n\n DELETE\/v1\/credentials Remove IBM Cloud infrastructure account credentials from your IBM Cloud Kubernetes Service account. containers-kubernetes.cluster.create containers-kubernetes.account.delete \n GET\/v1\/addons List available add-ons that you can enable in a cluster. N\/A N\/A \n GET\/v1\/config List configuration values for your IBM Cloud account. containers-kubernetes.cluster.read N\/A \n GET\/v1\/credentials View the IBM Cloud infrastructure account credentials that are set for your IBM Cloud Kubernetes Service account. containers-kubernetes.cluster.read N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_16727-419665-421554","score":19.3075942993,"text":"\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-419683-421572","score":19.3075942993,"text":"\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_02490-7-2074","score":19.199136734,"text":"\nManaging events from log in actions in an account \n\nAs a security officer, auditor, or manager, you can use the IBM Cloud Activity Tracker service to track how users, applications, and services interact with your account. The IBM Cloud\u00ae Identity and Access Management (IAM) service in IBM Cloud generates events that you can use to monitor log in activity to your account. This tutorial explains the different log in options to IBM Cloud and what happens from an IAM and an IBM Cloud Activity Tracker perspective. You can also find out how to define views and dashboards to monitor these actions in your account.\n\nTo work in the IBM Cloud, a user, an application, or a service must log in to IBM Cloud. The user, application, or service needs valid credentials to access an account and run actions on services in that account.\n\nAs a user, you can log in to the IBM Cloud in any of the following ways:\n\n\n\n* Log in through the IBM Cloud UI\n* Log in from the command-line interface (CLI) by using an API key\n* Log in from the command-line interface (CLI) by using a one-time passcode\n* Log in from the command-line interface (CLI) by using a user ID and password\n\n\n\nAs a service, you log in to the IBM Cloud by using an API key that is associated to a service ID.\n\nIf you are a new user of the IBM Cloud, [you must request an IBMid](https:\/\/cloud.ibm.com\/login). When you register to work in the IBM Cloud, you get an IBMid, and an account is created and associated to your IBMid.\n\nOnce you have registered to IBM Cloud, you can be invited to be a member in other accounts in IBM Cloud. When you are invited to work in an account that is different from the default account that is associated with your IBMid, an event with action user-management.user.create is generated and available in the account where you are invited to work. Users in the account with permissions to monitor Activity Tracker Event Routing events can monitor these events through the IBM Cloud Activity Tracker instance in Frankfurt (eu-de).\n\nFor a user to log in successfully to your account:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-iam_manage_login"},{"document_id":"ibmcld_12574-1514-3514","score":19.1519126892,"text":"\nThey are used to identify a user, service ID, trusted profile, or resource. The IAM ID is included in the token when used in the console, CLI, or API. Access policies are defined by using IAM IDs since it is the identity that can be verified in the IAM token.\n\nTo find your IAM ID, go to Manage > Access (IAM). You can see your IAM ID in the My user details section. To view other users' IAM IDs, go to Manage > Access (IAM) > Users, then select a user's name from the list and click Details.\n\n\n\n User API keys \n\nIBM Cloud API keys are credentials that are associated with a user's identity. The access that the user is assigned can be from policies across multiple accounts that the user is a member of. User API key credentials can be used to make API and CLI calls. The user API key can be used directly or used to generate a token.\n\nFor more information about using an API key associated with your user identity, see [Managing user API keys](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userapikey).\n\n\n\n\n\n Federating users to IBM Cloud \n\nIBM Cloud offers two ways for you to federate your corporate identity provider (IdP), which simplifies login by giving your employees access to IBM Cloud with their company username and password. You can [federate with IBMid](https:\/\/ibm.box.com\/v\/IBMid-Federation-Guide), or you have the option to create an IBM Cloud App ID service instance and use that as a way to federate users into an IBM Cloud account. For more information, see [Enabling authentication from an external identity provider](https:\/\/cloud.ibm.com\/docs\/account?topic=account-idp-integration).\n\nBoth federation options require that the user is a member of the account, or has access to the account by a trusted profile to be able to complete operations. If trusted profiles are not configured, the account owner or administrator must invite individual IBMids into the IBM Cloud account. Only if the invited IBMid accepts the invitation is the user added the account as an active user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-identity-overview"},{"document_id":"ibmcld_10906-34012-35755","score":18.9026145935,"text":"\n<br><br> * Invite users to your account<br><br><br> Users are invited to an account and given access to the resources. Use IAM to invite users, cancel invitations, or resend a pending invitation. You can invite a single user or multiple users. Start [inviting users to an account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamuserinv). \n <br><br> * Set up trusted profiles<br><br><br> Trusted profiles are used to automatically grant federated users access to your account with conditions based on SAML attributes from your corporate directory. Trusted profiles can also be used to set up fine-grained authorization for applications that are running in compute resources. This way, you aren't required to create service IDs or API keys for the compute resources. Learn more about [creating trusted profiles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-trusted-profile). \n <br><br> * Create service IDs<br><br><br> A service ID identifies a service or application similar to how a user ID identifies a user. You can create a service ID and use it to enable an application outside of IBM Cloud access to resources in your account. Learn more about [creating and working with service IDs](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceids&interface=ui). <br>If you have configured a Secrets Manager instance as described in [Encrypt and protect your data](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklistsecuring), you can use that instance to dynamically generate a service ID and an API key each time a protected resource is read or accessed. For more information, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklist"},{"document_id":"ibmcld_10041-7-1932","score":18.844493866,"text":"\nIAM and Activity Tracker action by API method \n\nWhen you use Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae such as through the command line or console, the service calls application programming interface (API) methods to complete your requests. In IBM Cloud IAM, each API operation is associated with an IAM action that the user must have an access role to use the API operation. You can keep track of the requests that you make with an IBM Cloud Activity Tracker instance.\n\nReview the following list of IBM Cloud Identity and Access Management (IAM) actions and IBM Cloud Activity Tracker events that correspond to each API method in Red Hat OpenShift on IBM Cloud.\n\nFor more information, see the following topics.\n\n\n\n* [Red Hat OpenShift on IBM Cloud API docs](https:\/\/containers.cloud.ibm.com\/global\/swagger-global-api\/\/)\n* [User access permissions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_reference)\n* [IBM Cloud Activity Tracker events](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-at_events).\n\n\n\n\n\n Account \n\nReview the following account API methods, their corresponding actions in IBM Cloud IAM, and the events that are sent to IBM Cloud Activity Tracker for Red Hat OpenShift on IBM Cloud.\n\n\n\nAccount API methods, IAM actions, and Activity Tracker events.\n\n API Method Description IAM action for the API Event sent to Activity Tracker \n\n DELETE\/v1\/credentials Remove IBM Cloud infrastructure account credentials from your Red Hat OpenShift on IBM Cloud account. containers-kubernetes.cluster.create containers-kubernetes.account.delete \n GET\/v1\/addons List available add-ons that you can enable in a cluster. N\/A N\/A \n GET\/v1\/config List configuration values for your IBM Cloud account. containers-kubernetes.cluster.read N\/A \n GET\/v1\/credentials View the IBM Cloud infrastructure account credentials that are set for your Red Hat OpenShift on IBM Cloud account. containers-kubernetes.cluster.read N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_09589-2931-3858","score":18.8345985413,"text":"\nThe RabbitMQ Management plug-in UI has a tab for user creation and management available to the admin user on your deployment.\n\nUsers who are created directly in RabbitMQ do not appear in Service Credentials, but you can [add them there](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-connection-stringsadding-users-to-_service-credentials_) if you choose. These users will not be integrated with IAM controls, even if added to Service Credentials.\n\n\n\n\n\n The ibm user \n\nIf you log in to the management UI with your admin account, you might have noticed a user that is named ibm. The ibm user is the internal administrative account that manages replication, metrics, and other functions that ensure the stability of your deployment. It has the same permission levels and tags as the provided admin user. Changes to the ibm account are not advised and can disrupt the availability of your deployment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-user-management"},{"document_id":"ibmcld_03776-7-2223","score":18.6984386444,"text":"\nVideo - How can I manage billing and usage in IBM Cloud? \n\nLearn about the IBM Cloud\u00ae billing options and tools that you can use to track your usage and manage invoicing and payments.\n\n\n\n* Video transcript\n\nIBM Cloud offers multiple billing options so you can tailor how you pay based on your resource usage and your organization's procurement practices. You get the most flexibility with a Pay-As-You-Go account. You pay only for the billable services that you use each month, with no long-term contracts or commitments. If you know you have a significant amount of usage, you can purchase a subscription to get a discount. With a subscription, you commit to a certain amount of usage over a period of time. The larger the subscription, the better the discount. You can choose to pay upfront or be billed monthly, quarterly, or annually.\n\nAs an account owner, you have full access to monitoring resource usage, viewing invoices, and managing payments in the console. However, if you want to delegate billing tasks to another user, you can assign a user an Identity and Access Management (IAM) policy with the Administrator role on the Billing account management service.\n\nWhen you're ready to start tracking your resource usage and managing your billing and payment preferences, go to the Billing and usage section of the IBM Cloud console. Monitoring resource usage can help you understand what's coming in your next bill. On the Usage page, you can view current and past usage, and drill down by resource type to view the plans and instances in your account.\n\nYou can also export usage reports and choose from a high-level summary overview or a service instance view. If you use tags to organize your resources such as by team or cost center, you can sort your instance report by the tags to identify the associated usage.\n\nSetting spending limits is another helpful way to keep an eye on usage in your account. You can set notifications for total account, runtime, container, and service spending. When you reach a percentage of the spending limit that you set, you are notified immediately by email.\n\nTo view your current balance, manage your payment method, or make a one-time payment, go to the Payments page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00060-7-1693","score":24.0447673798,"text":"\nRetrieving details of a serverless instance \n\nYou can retrieve information, like the instance ID (or GUID) and the provisioning state of an IBM Analytics Engine serverless instance from the instance details. You need the instance ID to use the Spark application REST API and the Livy batch APIs.\n\nYou can retrieve the details by:\n\n\n\n* [Using the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-instance-detailsretrieve-guid-cli)\n* [Using the IBM Cloud REST API](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-instance-detailsretrieve-guid-api)\n\n\n\n\n\n Accessing instance details by using the IBM Cloud CLI \n\nTo get the details of an instance:\n\n\n\n1. List all of the created serverless instances:\n\n$ ibmcloud resource service-instances --service-name ibmanalyticsengine\n\nThis call retrieves the instances of type service_instance in all resource groups in all locations for your account.\n\nExample response:\n\nName Location State Type Resource Group ID\nserverless-instance us-south active service_instance 65xxxxxxxxxxxxxxxa3fd\n2. Enter the following command with the server instance name of your instance to view the instance details:\n\n$ ibmcloud resource service-instance \"Analytics Engine-xyz\"\n\nThis retrieves your instance from the resource groups under your account.\n\nExample response:\n\nName: Analytics Engine-xyz\nID:\ncrn:v1:staging:public:ibmanalyticsengine:us-south:a\/XXXXX:XXXXX::\nGUID: XXXXX\nLocation: us-south\nService Name: ibmanalyticsengine\nService Plan Name: standard-serverless-spark\nResource Group Name: Default\nState: active\nType: service_instance\nSub Type:\nCreated at: 2021-01-06T07:49:12Z\nCreated by: XXXXX","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-instance-details"},{"document_id":"ibmcld_00007-7-2159","score":22.8490276337,"text":"\nGetting started tutorial \n\nIBM Analytics Engine Serverless instance is allocated to compute and memory resources on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n\n\n\n* [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts)\n* [Provisioning a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n Getting started using serverless IBM Analytics Engine instances \n\nThe IBM Analytics Engine Standard Serverless plan for Apache Spark offers the ability to spin up IBM Analytics Engine serverless instances within seconds, customize them with library packages of your choice, and run your Spark workloads.\n\nCurrently, you can create IBM Analytics Engine serverless instances only in the US South region.\n\n\n\n\n\n Before you begin \n\nTo start running Spark applications in IBM Analytics Engine, you need:\n\n\n\n* An IBM Cloud\u00ae account.\n* Instance home storage in IBM Cloud Object Storage that is referenced from the IBM Analytics Engine instance. This storage is used to store Spark History events, which are created by your applications and any custom library sets, which need to be made available to your Spark applications.\n* An IBM Analytics Engine serverless instance.\n\n\n\n\n\n\n\n Provision an instance and create a cluster \n\nTo provision an IBM Analytics Engine instance:\n\n\n\n1. Get a basic understanding of the architecture and key concepts. See [Serverless instance architecture and concepts](https:\/\/cloud.ibm.com\/docs\/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine"},{"document_id":"ibmcld_00052-7-2119","score":22.6224784851,"text":"\nManaging serverless instances using the IBM Cloud console \n\nYou can manage your severless instance by:\n\n\n\n* Changing configuration settings, for example, to include library add-ons or to configure instance home after you created the instance.\n* Monitoring the status of submitted applications and kernels created in the instance.\n\n\n\n\n\n Console configuration tab \n\nYou can view and edit the current configuration settings for your IBM Analytics Engine serverless instance from the IBM Cloud\u00ae Resource list.\n\n\n\n1. Access the [IBM Cloud\u00ae Resource list](https:\/\/test.cloud.ibm.com\/resources).\n2. Click Services and software, find your IBM Analytics Engine serverless instance and click the instance to see the details.\n3. Click Manage > Configuration to view:\n\n\n\n* The runtime. Currently, you can only select the Default Spark runtime which includes the geospatial, data skipping and Parquet encryption packages.\n* The instance home volume to add an instance home or change the access credentials of an existing instance home\n\n\n\n* You can set instance home after you created your IBM Analytics Engine serverless instance. Instance home must be associated with an IBM Cloud Object Storage instance. You can choose an instance:\n\n\n\n* In your account by selecting it from the list\n* From another account. For this instance, you need to enter:\n\n\n\n* The GUID of the IBM Cloud Object Storage instance\n* The endpoint\n* The region\n* The HMAC access and secret key\n\n\n\n\n\n* You can change the access credentials of an existing instance home volume. For this instance, you need to enter:\n\n\n\n* The new HMAC access and secret key\n\n\n\n\n\nFor details on how to access Object Storage, see [Using IBM Object Storage as the instance home volume](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-cos-serverless).\n* The default Spark configuration options to override configuration settings.\n\nFor a list of the default Spark configurations set for serverless instances, see [Default Spark configurations](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-conceptsdefault-spark-config).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-manage-serverless-console"},{"document_id":"ibmcld_00060-1392-3002","score":22.6091995239,"text":"\ncrn:v1:staging:public:ibmanalyticsengine:us-south:a\/XXXXX:XXXXX::\nGUID: XXXXX\nLocation: us-south\nService Name: ibmanalyticsengine\nService Plan Name: standard-serverless-spark\nResource Group Name: Default\nState: active\nType: service_instance\nSub Type:\nCreated at: 2021-01-06T07:49:12Z\nCreated by: XXXXX\nUpdated at: 2021-01-06T07:51:01Z\nLast Operation:\nstatus create succeeded\nMessage Started create instance operation\nShow more\n\nThe response includes the GUID and the provisioning state of your instance.\n\nNote that the returned state create succeeded indicates that the provision request was successfully accepted. However, in order to run applications, the instance needs to move to active state. Track the status of the instance readiness before performing any operation on the instance. See [Tracking instance readiness](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessinstance-readiness).\n\n\n\n\n\n\n\n Accessing instance details by using the IBM Cloud REST API \n\nYou need the ID of a IBM Analytics Engine serverless instance to get the details of the instance, which include the GUID and the provisioning state of the instance for example.\n\nTo get the details of an instance:\n\n\n\n1. List all of the created serverless instances in the resource group your account:\n\nGET <resource-controller-url>\/v2\/resource_instances\n\nExample of a request:\n\ncurl -X GET https:\/\/resource-controller.cloud.ibm.com\/v2\/resource_instances? resource_plan_id=8afxxxx-xxxx-xxxx-xxxx-946d843xxxx -H \"Authorization: Bearer <>\"\n\nExample response:\n\n{\n\"rows_count\": 1,\n\"next_url\": null,\n\"resources\": [{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-instance-details"},{"document_id":"ibmcld_00093-0-742","score":22.4494590759,"text":"\n\n\n\n\n\n\n  Troubleshooting serverless instances \n\nIn this topic, you can find the answers to common questions about how to troubleshoot IBM Analytics Engine serverless instances.\n\n\n\n  Running ae-v3 CLI commands results in \"missing-required-flags-error\" \n\nWhen you run ae-v3 CLI commands, you might see a \"missing-required-flags-error\".\n\nFor example:\n\nibmcloud ae-v3 spark-app status b5e12891-c160-4674-8b94-e2cc42722be3\nFAILED\nError executing command::\nmissing-required-flags-error\n\nThe reason might be that you are using an older version of the ae-v3 CLI. Check the version that you are using and update to latest version of the plugin by running the following commands:\n\nibmcloud plugin list\nibmcloud plugin update analytics-engine-v3\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-troubleshooting-serverless"},{"document_id":"ibmcld_00064-7-2200","score":22.4008769989,"text":"\nArchitecture and concepts in serverless instances \n\nThis topic shows you the architecture of IBM Analytics Engine serverless instances and describes some key concepts and definitions.\n\n\n\n Instance architecture \n\nThe IBM Analytics Engine service is managed by using IBM Cloud\u00ae Identity and Access Management (IAM). As an IBM Cloud account owner, you are assigned the account administrator role.\n\nWith an IBM Cloud account, you can provision and manage your serverless Analytics Engine instance by using the:\n\n\n\n* IBM Cloud console\n* CLI\n* REST API\n\n\n\nThe Analytics Engine microservices in the control plane, accessed through an API gateway handle instance creation, capacity provisioning, customization and runtime management while your Spark applications run in isolated namespaces in the data plane. Each Spark application that you submit runs in its own Spark cluster, which is a combination of Spark master and executor nodes. See [Isolation and network access](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-security-model-serverlessisolation-network-access).\n\nEach Analytics Engine instance is associated with an IBM Cloud Object Storage instance for instance related data that is accessible by all applications that run in the instance. Currently, all Spark events are stored in this instance as well. Spark application logs are aggregated to a Log Analysis log server.\n\nZoom\n\n![Shows the IBM Analytics Engine serverless instance architecture.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cd4be197c8921ed12923aa899ac93a8ab643c158\/AnalyticsEngine\/images\/AE-serverless-architecture.svg)\n\nFigure 1. Architecture flow diagram of IBM Analytics Engine\n\n\n\n\n\n Key concepts \n\nWith IBM Analytics Engine serverless instances, you can spin up Apache Spark clusters as needed and customize the Spark runtime and default Spark configuration options.\n\nThe following sections describe key concepts when provisioning serverless instances.\n\n\n\n IBM Analytics Engine service instance \n\nAn IBM Cloud\u00ae service is cloud extension that provides ready-for-use functionality, such as database, messaging, and web software for running code, or application management or monitoring capabilities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts"},{"document_id":"ibmcld_00062-7-2216","score":22.3122634888,"text":"\nSecurity model \n\nIBM Analytics Engine serverless instances provide a security architecture that is designed to enable administrators and developers to create secure Spark clusters.\n\nThe following sections describe how the security model of IBM Analytics Engine serverlesss instances manages the access to and control of the secure instances.\n\n\n\n Controlling access to IBM Analytics Engine activities \n\nAccess to IBM Analytics Engine serverless instances is controlled by IAM authentication and authorization. IAM is the Identity and Access Management service of IBM Cloud\u00ae. User authentication and access control happens through IAM when you log in with your IBMId. See how to [retrieve the IAM token](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-iam-token-serverless).\n\nAs an administrator or creator of the service instance, you can grant or deny access to other users with whom you may want to share the service instance. All activities on the service instance life cycle management, like modifying the instance configuration, submitting and tracking Spark applications or customizing the instance with custom library sets are controlled through IAM authentication and authorization. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless) to understand which operations are supported and what is the level of access required for each of those operations.\n\n\n\n\n\n Encrypting at Rest \n\nIBM Cloud Object Storage is the recommended data store to store the data required for executing Spark jobs on the cluster. IBM Cloud Object Storage comes with default built-in encryption. See [Encrypting your data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-encryptionencryption).\n\nIn addition, or as an alternative to using IBM Cloud Object Storage storage encryption in analytic scenarios for large-scale data, you can use Parquet modular encryption, especially when fine-grained access control is important. See [Working with Parquet modular encryption](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-parquet-encryption-serverless).\n\n\n\n\n\n Encrypting endpoints","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-security-model-serverless"},{"document_id":"ibmcld_00055-4234-5526","score":22.0467472076,"text":"\nSee [Architecture and concepts in serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts) for a description of the provisioning parameters in the payload.\n\nNote that both Spark 3.1 and Spark 3.3 are supported. If you don't specify a default Spark runtime version when you create a service instance, Spark 3.1 is taken by default.\n\n{\n\"default_runtime\": {\n\"spark_version\": \"3.1\"\n},\n\"instance_home\": {\n\"region\": \"us-south\",\n\"endpoint\": \"https:\/\/s3.direct.us-south.cloud-object-storage.appdomain.cloud\",\n\"hmac_access_key\": \"<your-hmac-access-key\",\n\"hmac_secret_key\": \"<your-hmac-secret-key\"\n},\n\"default_config\": {\n\"key1\": \"value1\",\n\"key2\": \"value2\"\n}\n}\n\nThe IBM Cloud\u00ae response to the create instance command:\n\nCreating service instance MyServiceInstance in resource group Default of account <your account name> as <your user name>...\nOK\nService instance MyServiceInstance was created.\n\nName: MyServiceInstance\nID: crn:v1:staging:public:ibmanalyticsengine:us-south:a\/d628eae2cc7e4373bb0c9d2229f2ece5:1e32e-afd9-483a-b1-724ba5cf4::\nGUID: 1e32e-afd9-483a-b1-724ba5cf4\nLocation: us-south\nState: provisioning\nType: service_instance\nSub Type:\nService Endpoints: public\nAllow Cleanup: false\nLocked: false\nCreated at: 2021-11-29T07:20:40Z","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless"},{"document_id":"ibmcld_07578-107943-110247","score":21.9150161743,"text":"\n* Port 8443 Knox\n* Port 22 SSH\n* Port 9443 Ambari\n\n\n\n* What is IBM Analytics Engine serverless?\n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n* What are the advantages of IBM Analytics Engine serverless instances?\n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n* Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop?\n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n* Can I change the instance home storage of a serverless instance?\n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n* How is user management and access control managed in a serverless instance?\n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n* How do I define the size of the cluster to run my Spark application?\n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-107922-110226","score":21.9150161743,"text":"\n* Port 8443 Knox\n* Port 22 SSH\n* Port 9443 Ambari\n\n\n\n* What is IBM Analytics Engine serverless?\n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n* What are the advantages of IBM Analytics Engine serverless instances?\n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n* Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop?\n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n* Can I change the instance home storage of a serverless instance?\n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n* How is user management and access control managed in a serverless instance?\n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n* How do I define the size of the cluster to run my Spark application?\n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.5,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.6366824387,"ndcg_cut_10":0.7541985435}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00083-7-1689","score":14.6116285324,"text":"\nStandard Spark examples \n\nYou can use the following code samples to learn how to use Spark in different situations.\n\nTo understand how to access Object Storage, see [Understanding the Object Storage credentials](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-cos-credentials-in-iae-serverless).\n\n\n\n Reading a CSV file from Object Storage using already stated credentials \n\nThe following code samples show you how to create a Python script that reads data from a CSV file to a Python DataFrame. Both the Python script and the CSV file are located in Object Storage.\n\nYou can use the same IBM Cloud Object Storage credentials that you specified at the time you submitted the Spark application or that were set as a default configuration when you created the IBM Analytics Engine service instance to read from Object Storage within the application.\n\nExample of the application called read-employees.py. Insert the Object Storage bucket name and service name. The service name is any name given to your Object Storage instance:\n\nfrom pyspark.sql import SparkSession\n\ndef init_spark():\nspark = SparkSession.builder.appName(\"read-write-cos-test\").getOrCreate()\nsc = spark.sparkContext\nreturn spark,sc\n\ndef read_employees(spark,sc):\nprint(\"Hello 1\" , spark )\nemployeesDF = spark.read.option(\"header\",True).csv(\"cos:\/\/cosbucketname.cosservicename\/employees.csv\")\nprint(\"Hello 2\" , employeesDF)\nemployeesDF.createOrReplaceTempView(\"empTable\")\nseniors = spark.sql(\"SELECT empTable.NAME FROM empTable WHERE empTable.BAND >= 6\")\nprint(\"Hello 3\", seniors)\nseniors.show()\n\ndef main():\nspark,sc = init_spark()\nread_employees(spark,sc)\n\nif __name__ == '__main__':\nmain()\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-batch-examples"},{"document_id":"ibmcld_13481-7-1988","score":14.5285644531,"text":"\nConnecting Apache Spark with Data Engine \n\nIBM Cloud\u00ae Data Engine catalog provides an interface that is compatible with Apache Hive metastore. This unified metadata repository enables any Big Data engine, such as Apache Spark, to use Data Engine as metastore. The same definition for tables and views can be created once and used from any connected engine. Each instance of Data Engine exports its catalog as a database called default.\n\n\n\n Catalog usage within Data Engine \n\nThe Catalog can be used in Data Engine in read and write mode. Seamless access is configured without any configuration steps needed.\n\n\n\n\n\n Connecting Apache Spark with Data Engine \n\nWhen you use the Hive metastore compatible interface, access is limited to read only operations. Thus, existing tables and views can be used, but not modified.\n\nDepending from where you want to connect to your catalog, the steps may vary.\n\n\n\n Usage within Watson Studio Notebooks \n\nWatson Studio has the compatible Hive metastore client already included. It also includes a convenience library to configure the connection to the Hive metastore. Set the required variables (CRN and apikey) and call the helper function to connect to the Hive metastore:\n\n change the CRN and the APIkey according to your instance\ncrn='yourDataengineCRN'\napikey='yourAPIkey'\n\nfrom dataengine import SparkSessionWithDataengine\n\n call the helper function to create a session builder equipped with the correct config\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\nspark = session_builder.appName(\"Spark DataEngine integration test\").getOrCreate()\n\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_13481-1627-2985","score":14.1170749664,"text":"\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine. It also includes the convenience library to configure the connection to the Hive metastore. The following example shows a Spark batch job for a show tables example in Python:\n\nimport sys\nfrom dataengine import SparkSessionWithDataengine\n\nif __name__ == '__main__':\ncrn = sys.argv[1]\napikey = sys.argv[2]\n\nprint(\" Start SparkSessionWithDataengine example\")\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\n\nprint(\" Setup IBM Cloud Object Storage access\")\nspark = session_builder.appName(\"AnalyticEngine DataEngine integration\") \n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.getOrCreate()\n\nprint(\" Got a spark session, listing all tables\")\nspark.sql('show tables').show()\n\nspark.stop()\nShow more\n\nPrepare a JSON file to start that program, as in the following example (listTablesExample.json):\n\n{\n\"application_details\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_00054-3422-4901","score":13.8673610687,"text":"\n\"spark.hadoop.javax.jdo.option.ConnectionURL\": \"jdbc:postgresql:\/\/<CHANGEME>.databases.appdomain.CHANGEME\/ibmclouddb?sslmode=verify-ca&sslrootcert=\/home\/spark\/shared\/user-libs\/certificate_library_set\/custom\/postgres.cert&socketTimeout=30\",\n\"ae.spark.librarysets\":\"certificate_library_set\"\n5. Set up the Hive metastore schema in the Databases for PostgreSQL instance because there are no tables in the public schema of Databases for PostgreSQL database when you create the instance. This step executes the Hive schema related DDL so that metastore data can be stored in them. After running the following Spark application called postgres-create-schema.py, you will see the Hive metadata tables created against the \"public\" schema of the instance.\n\nfrom pyspark.sql import SparkSession\nimport time\ndef init_spark():\n\u00a0 spark = SparkSession.builder.appName(\"postgres-create-schema\").getOrCreate()\n\u00a0 sc = spark.sparkContext\n\u00a0 return spark,sc\ndef create_schema(spark,sc):\n\u00a0 tablesDF=spark.sql(\"SHOW TABLES\")\n\u00a0 tablesDF.show()\n\u00a0 time.sleep(30)\ndef main():\n\u00a0 spark,sc = init_spark()\n\u00a0 create_schema(spark,sc)\nif __name__ == '__main__':\n\u00a0 main()\n6. Now run the following script called postgres-parquet-table-create.py to create a Parquet table with metadata from IBM Cloud Object Storage in the Databases for PostgreSQL database.\n\nfrom pyspark.sql import SparkSession\nimport time\ndef init_spark():\n\u00a0 spark = SparkSession.builder.appName(\"postgres-create-parquet-table-test\").getOrCreate()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-postgresql-external-metastore"},{"document_id":"ibmcld_16661-2743-3994","score":13.7020301819,"text":"\nspark = SparkSession.builder .appName(\"lh-hms-cloud\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.endpoint\" ,\"s3.direct.us-south.cloud-object-storage.appdomain.cloud\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.access.key\" ,\"<access-key-for-source-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.secret.key\" ,\"<secret-key-for-source-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.endpoint\" ,\"s3.direct.us-south.cloud-object-storage.appdomain.cloud\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.access.key\" ,\"<access-key-for-lakehous-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.secret.key\" ,\"<secret-key-for-lakehouse-bucket>\") .enableHiveSupport() .getOrCreate()\n\nreturn spark\n\ndef main():\ntry:\nspark = init_spark()\n Create a database in lakehouse catalog\nspark.sql(\"create database if not exists lakehouse.demodb LOCATION 's3a:\/\/lakehouse-bucket\/'\")\n list the database under lakehouse catalog\nspark.sql(\"show databases from lakehouse\").show()\n\n demonstration: Create a basic Iceberg table, insert some data and then query table\nspark.sql(\"create table if not exists lakehouse.demodb.testTable(id INTEGER, name VARCHAR(10), age INTEGER, salary DECIMAL(10, 2)) using iceberg\").show()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-run_samp_file"},{"document_id":"ibmcld_00071-13290-14873","score":13.5832147598,"text":"\n[EnvironmentVariableName]\" configuration (application_details > env) also. They will, however, be accessible only to the tasks running on the executor and not the driver.\n\nExample of pyspark application that accesses the environment variables that are passed using the \"os.getenv\" call.\n\nfrom pyspark.sql.types import IntegerType\nimport os\n\ndef init_spark():\nspark = SparkSession.builder.appName(\"spark-env-test\").getOrCreate()\nsc = spark.sparkContext\nreturn spark,sc\n\ndef returnExecutorEnv(x):\n Attempt to access environment variable from a task running on executor\nreturn os.getenv(\"TESTENV1\")\n\ndef main():\nspark,sc = init_spark()\n\n dummy dataframe\ndf=spark.createDataFrame([(\"1\",\"one\")])\ndf.show()\ndf.rdd.map(lambda x: (x[0],returnExecutorEnv(x[0]))).toDF().show()\n Attempt to access environment variable on driver\nprint (os.getenv(\"TESTENV1\"))\nspark.stop()\n\nif __name__ == '__main__':\nmain()\nShow more\n\n\n\n\n\n Run a Spark application with non-default language version \n\nThe Spark runtime support Spark application written in the following languages:\n\n\n\n* Scala\n* Python\n* R\n\n\n\nA Spark runtime version comes with default runtime language version. IBM extend support for new language versions and remove the existing language version to keep the runtime free from any security vulnerabilities. The system also provides settling time to transition your workloads when ever there is a new language versions. You can test your workload with a language version by passing an environment variable that points to the language version of the application.\n\nExample:\n\n\"application_details\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-app-rest-api"},{"document_id":"ibmcld_13118-24929-26231","score":13.2845458984,"text":"\n$service'.secret.key\": \"'$secret_access_key'\"\n}'\n\nAgain verify the results in the platform log.\n\nThe final step is to submit the spark application that accesses the data in the same bucket. Create a file, solution.py, with the following contents and upload it to the bucket. Notice the COS_PARQUET environment variable that will be initialized in the next step.\n\nsolution.py:\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import SQLContext\nimport os\nimport sys\n\ndef main():\n COS_PARQUET in format: cos:\/\/<bucket>.<service>\/landing_folder\/topic=<topic>\/jobid=<jobid>\/\n like cos:\/\/ABC-log-analysis.solution\/logs-stream-landing\/topic=webserver\/jobid=48914a16-1d33-4d3e-93e3-7efb855b662e\/\nprint(\"solution v1.0\")\nif \"COS_PARQUET\" not in os.environ:\nprint(\"COS_PARQUET must be in environment\")\nreturn 1\ncos_parquet = os.environ[\"COS_PARQUET\"]\nprint(f\"cos_parquet: {cos_parquet}\")\n\nspark = SparkSession.builder.appName(\"solution\").getOrCreate()\nsc = spark.sparkContext\nsqlContext = SQLContext(sc)\n\ndf = spark.read.parquet(cos_parquet)\nsqlContext.registerDataFrameAsTable(df, \"Table\")\ndf_query = sqlContext.sql(\"SELECT * FROM Table LIMIT 10\")\ndf_query.show(10)\nreturn 0\n\nif __name__ == '__main__':\nsys.exit(main())\nShow more\n\nNow submit the spark application that accesses the data in the same bucket.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analytics"},{"document_id":"ibmcld_00029-6261-7679","score":13.2500333786,"text":"\n\"spark.hadoop.fs.cos.ALIAS NAME.endpoint\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.access.key\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.secret.key\": \"CHANGEME\"\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0},\n\u00a0 \"application\": \"cos:\/\/mybucket.ALIAS NAME\/create_table_data_engine.py\",\n\u00a0 \"arguments\": [\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\"<APIKEY-WITH-ACCESS-TO-DATA-ENGINE-INSTANCE>\"]\n\u00a0\u00a0\u00a0\u00a0}\n}\n\nParameter values:\n\nALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewendpoints).\n\nMake sure that you select the standard aliases.\n{: important}\nShow more\n\n\n\n\n\n\n\n Reading data from table by passing full list of Data Engine parameters \n\nYou can read the data from the metastore table using the SQL querry.\n\nRead the data from the table by using the Spark SQL in the following application called select_query_data_engine.py:\n\nfrom pyspark.sql import SparkSession\nimport time\n\ndef init_spark():\nspark = SparkSession.builder.appName(\"dataengine-table-select-test\").getOrCreate()\nsc = spark.sparkContext\nreturn spark,sc\n\ndef select_query_data_engine(spark,sc):\ntablesDF=spark.sql(\"SHOW TABLES\")\ntablesDF.show()\nstatesDF=spark.sql(\"SELECT * from COUNTRIESCAPITALS\");\nstatesDF.show()\n\ndef main():\nspark,sc = init_spark()\nselect_query_data_engine(spark,sc)\n\nif __name__ == '__main__':\nmain()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_00096-10596-12360","score":13.2340831757,"text":"\n\"state\": \"active\",\n\"state_change_time\": \"\"\n}\n\nOnly submit your Spark application when the state of the Analytics Engine service is active.\n\n\n\n\n\n\n\n Step 3: Upload and submit a Spark application \n\nUpload an application file to Cloud Object Storage and submit a Spark application.\n\nThis tutorial shows you how to add the Spark application to the Cloud Object Storage instance bucket that is used as instance home by the Analytics Engine instance. If you want to separate the instance related files from the files you use to run your applications, for example the applications files themselves, data files, and any results of your analysis, you can use a different bucket in the same Cloud Object Storage instance or use a different Cloud Object Storage instance.\n\n\n\n1. Upload the Spark application file:\n\nAction\n: Enter:\n\nibmcloud cos upload --bucket BUCKET_NAME --key KEY --file PATH [--concurrency VALUE] [--max-upload-parts PARTS] [--part-size SIZE] [--leave-parts-on-errors] [--cache-control CACHING_DIRECTIVES] [--content-disposition DIRECTIVES] [--content-encoding CONTENT_ENCODING] [--content-language LANGUAGE] [--content-length SIZE] [--content-md5 MD5] [--content-type MIME] [--metadata STRUCTURE] [--region REGION] [--output FORMAT] [--json]\n\nParameter values:\n\n\n\n* BUCKET_NAME: Name of bucket used when bucket was created\n* KEY: Application file name\n* PATH: file name and path to the Spark application file\n\n\n\nExample\n: Enter:\n\nibmcloud cos upload --bucket test-cos-storage-bucket --key test-math.py --file test-math.py\n\nSample application file\n: Sample of test-math.py:\n\nfrom pyspark.sql import SparkSession\nimport time\nimport random\nimport cmath\n\ndef init_spark():\nspark = SparkSession.builder.appName(\"test-math\").getOrCreate()\nsc = spark.sparkContext","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-cli"},{"document_id":"ibmcld_00083-2510-3893","score":13.1978912354,"text":"\n\"spark.hadoop.fs.cos.cosservicename.secret.key\": \"<CHANGEME>\"\n}\n}\n}\n\n\n\n\n\n Reading a CSV file from Object Storage using IAM API Key or different HMAC credentials \n\nThe following code samples show you how to create a Python script that reads data from a CSV file to a Python DataFrame. Both the Python script and the CSV file are located in Object Storage.\n\nThis example shows you how to access IBM Cloud Object Storage using the IAM API key.\n\nExample of the application called read-employees-iam-key-cos.py. Insert the Object Storage bucket name where the CSV file is located and the modify the endpoint path.\n\nfrom pyspark.sql import SparkSession\n\ndef init_spark():\nspark = SparkSession.builder.appName(\"read-write-cos-test\").getOrCreate()\nsc = spark.sparkContext\nhconf=sc._jsc.hadoopConfiguration()\nhconf.set(\"fs.cos.testcos.endpoint\", \"s3.direct.us-south.cloud-object-storage.appdomain.cloud\/CHANGEME-according-to-instance=\"\n(\"fs.cos.testcos.iam.api.key\",\"<CHANGEME>\")\nreturn spark,sc\n\ndef read_employees(spark,sc):\nprint(\"Hello1 \" , spark )\nemployeesDF = spark.read.option(\"header\",True).csv(\"cos:\/\/cosbucketname.cosservicename\/employees.csv\")\nprint(\"Hello2\" , employeesDF)\nemployeesDF.createOrReplaceTempView(\"empTable\")\njuniors = spark.sql(\"SELECT empTable.NAME FROM empTable WHERE empTable.BAND < 6\")\nprint(\"Hello3\", juniors)\njuniors.show()\n\ndef main():\nspark,sc = init_spark()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-batch-examples"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16635-0-1693","score":21.2349414825,"text":"\n\n\n\n\n\n\n  HMS Overview \n\n\n\n  Hive Metastore \n\nHive Metastore (HMS) is a service that stores metadata related to Presto and other services in a backend Relational Database Management System (RDBMS) or Hadoop Distributed File System (HDFS).\n\nWhen you create a new table, information related to the schema such as column names, data types etc is stored in the metastore relational database. A metastore enables the user to see the data files in the HDFS object storage as if they are stored in tables with HMS.\n\nMetastore acts as a bridge between the schema of the table and the data files stored in object storages. HMS holds the definitions, schema, and other metadata for each table and maps the data files and directories to the table representation which is viewed by the user. Therefore, HMS is used as a storage location for the schema and tables. HMS is a metastore server that connects to the object storage to store data and keeps its related metadata on PostgreSQL.\n\nAny database with a JDBC driver can be used as a metastore. Presto makes requests through thrift protocol to HMS. The Presto instance reads and writes data to HMS. HMS supports 5 backend databases as follows. In IBM\u00ae watsonx.data, PostgreSQL database is used.\n\n\n\n*  Derby\n*  MySQL\n*  MS SQL Server\n*  Oracle\n*  PostgreSQL\n\n\n\nCurrently HMS in watsonx.data supports Iceberg table format.\n\nFollowing three modes of deployment are supported for HMS. In watsonx.data the remote mode is used.\n\n\n\n*  Embedded Metastore - Derby with singe session.\n*  Local Metastore - MySQl with multiple session accessible locally.\n*  Remote Metastore - metastore runs on its own separate JVM and accessible via thrift network APIs.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hms_overview"},{"document_id":"ibmcld_13481-6212-7871","score":19.5197525024,"text":"\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management. For user, specify the CRN and for password a valid API key with access to your Data Engine. Find the endpoint to use in the following table.\n\n\n\nTable 1. Region endpoints\n\n Region Endpoint \n\n us-south thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083 \n eu-de thrift:\/\/catalog.eu-de.dataengine.cloud.ibm.com:9083 \n\n\n\n\n\n\n\n Convenience libraries to configure Spark \n\nWhile the Data Engine catalog is compatible with the Hive metastore and can be used as any other external Hive metastore server, an SDK is provided to minimize the steps that are needed to configure Apache Spark. The SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine-spark-integration-1.4.51.jar)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_13481-5443-6857","score":18.2598648071,"text":"\n.config(\"spark.hive.metastore.uris\", \"thrift:\/\/catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\") \n.config(\"spark.hive.metastore.client.plain.username\", '<YourDataengineCRN>') \n.config(\"spark.hive.metastore.client.plain.password\", '<YourAPIkey>') \n.config(\"spark.hive.execution.engine\", \"spark\") \n.config(\"spark.hive.stats.autogather\", \"false\") \n.config(\"spark.sql.warehouse.dir\", \"file:\/\/\/tmp\") \n only spark is allowed as the default catalog\n.config(\"metastore.catalog.default\", \"spark\") \n.enableHiveSupport() \n.getOrCreate()\nShow more\n\n\n\n\n\n Apache Hive metastore version 3.1.2 compatible client \n\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_00029-8568-9861","score":18.2083587646,"text":"\n\"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3\n\"spark.hive.metastore.truststore.path\":\"\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n for spark 3.1, spark 3.2\n\"spark.hive.metastore.truststore.path\":\"file:\/\/\/opt\/ibm\/jdk\/jre\/lib\/security\/cacerts\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.jars\":\"\/opt\/ibm\/connectors\/data-engine\/hms-client\/\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.version\":\"3.0\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.warehouse.dir\":\"file:\/\/\/tmp\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hadoop.metastore.catalog.default\":\"spark\"\n},\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"application\": \"cos:\/\/mybucket.ALIAS NAME\/select_query_data_engine.py\"\n\u00a0\u00a0\u00a0 }\n}\nShow more\n\nParameter values:\n\n\n\n* ALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewendpoints).\n* THRIFT URL: specify the region-specific thrift URL. For example, thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_13481-7-1988","score":17.9617271423,"text":"\nConnecting Apache Spark with Data Engine \n\nIBM Cloud\u00ae Data Engine catalog provides an interface that is compatible with Apache Hive metastore. This unified metadata repository enables any Big Data engine, such as Apache Spark, to use Data Engine as metastore. The same definition for tables and views can be created once and used from any connected engine. Each instance of Data Engine exports its catalog as a database called default.\n\n\n\n Catalog usage within Data Engine \n\nThe Catalog can be used in Data Engine in read and write mode. Seamless access is configured without any configuration steps needed.\n\n\n\n\n\n Connecting Apache Spark with Data Engine \n\nWhen you use the Hive metastore compatible interface, access is limited to read only operations. Thus, existing tables and views can be used, but not modified.\n\nDepending from where you want to connect to your catalog, the steps may vary.\n\n\n\n Usage within Watson Studio Notebooks \n\nWatson Studio has the compatible Hive metastore client already included. It also includes a convenience library to configure the connection to the Hive metastore. Set the required variables (CRN and apikey) and call the helper function to connect to the Hive metastore:\n\n change the CRN and the APIkey according to your instance\ncrn='yourDataengineCRN'\napikey='yourAPIkey'\n\nfrom dataengine import SparkSessionWithDataengine\n\n call the helper function to create a session builder equipped with the correct config\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\nspark = session_builder.appName(\"Spark DataEngine integration test\").getOrCreate()\n\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_00029-7452-8829","score":17.3412761688,"text":"\ntablesDF=spark.sql(\"SHOW TABLES\")\ntablesDF.show()\nstatesDF=spark.sql(\"SELECT * from COUNTRIESCAPITALS\");\nstatesDF.show()\n\ndef main():\nspark,sc = init_spark()\nselect_query_data_engine(spark,sc)\n\nif __name__ == '__main__':\nmain()\nShow more\n\nNote that for the SELECT command to work, you must pass the IBM Cloud Object Storage identifiers as one of the standard Data Engine aliases, in this example, we have used ALIAS NAME. If you do not pass the expected ones, you might see the following error: Configuration parse exception: Access KEY is empty. Please provide valid access key.\n\nselect_query_data_engine_payload.json:\n\n{\n\"application_details\": {\n\"conf\": {\n\"spark.hadoop.fs.cos.ALIAS NAME.endpoint\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.access.key\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.secret.key\": \"CHANGEME\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.truststore.password\" : \"changeit\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.execution.engine\":\"spark\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.password\":\"APIKEY-WITH-ACCESS-TO-DATA-ENGINE-INSTANCE\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.uris\":\"THRIFT URL\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_00032-0-1390","score":17.3004875183,"text":"\n\n\n\n\n\n\n  Working with Spark SQL and an external metastore \n\nSpark SQL uses Hive metastore to manage the metadata of a user's applications tables, columns, partition information.\n\nBy default, the database that powers this metastore is an embedded Derby instance that comes with the Spark cluster. You could choose to externalize this metastore database to an external data store, like to an IBM Cloud Databases for PostgreSQL or an IBM Cloud Data Engine (previously SQL Query) instance.\n\nPlacing your metadata outside of the Spark cluster will enable you to reference the tables in different applications across your IBM Analytics Engine instances. This, in combination with storing your data in IBM Cloud Object Storage, helps persisting data and metadata and allows you to work with this data seamlessly across different Spark workloads.\n\n\n\n  Enabling and testing an external metastore with IBM Analytics Engine \n\nTo enable and test an external metastore with IBM Analytics Engine, you need to perform the following steps:\n\n\n\n1.  Create a metastore to store the metadata. You can choose to provision either an IBM Cloud Databases for PostgreSQL or an IBM Cloud Data Engine (previously SQL Query) instance.\n2.  Configure IBM Analytics Engine to work with the database instance.\n3.  Create a table in one Spark application and then access this table from another Spark application.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-external-metastore"},{"document_id":"ibmcld_16636-0-1664","score":16.7517738342,"text":"\n\n\n\n\n\n\n  Integrating Presto with Apache Hudi using a Hudi connector \n\nYou can integrate Presto with Apache Hudi by using the Hudi connector. You can query Hudi tables that are synced to Hive metastore (HMS) using Presto's SQL interface. This combination offers the benefits of fast and interactive analytics on large-scale, high-velocity data stored in Hudi. Hudi connector uses the metastore to track partition locations. It uses underlying Hudi file system and input formats to list data files.\n\n\n\n  Configuring a catalog in Presto \n\nCreate a hudi.properties file inside \/opt\/presto\/etc\/catalog directory in the presto container.\n\n hudi.properties\nconnector.name=hudi\n\n HMS thrift URI\nhive.metastore.uri=thrift:\/\/<hostname>:<port>\n\n properties to enable connection to object-storage bucket\nhive.s3.ssl.enabled=true\nhive.s3.path-style-access=true\nhive.s3.endpoint=<Bucket API Endpoint>\nhive.s3.aws-access-key=<INSERT YOUR ACCESS KEY>\nhive.s3.aws-secret-key=<INSERT YOUR SECRET KEY>\n\n properties to enable TLS connection to HMS\nhive.metastore.thrift.client.tls.enabled=true\nhive.metastore.authentication.type=PLAIN\nhive.metastore.thrift.client.tls.truststore.path=<Truststore Path>\nhive.metastore.thrift.client.tls.truststore.password=<Truststore Password>\nhive.metastore.thrift.client.tls.keystore.path=<Keystore Path>\nhive.metastore.thrift.client.tls.keystore.password=<Keystore Password>\nShow more\n\n\n\n\n\n  Limitations \n\n\n\n1.  Connector does not support DDL or DML SQL statements. Presto can query data using the Hudi connector, but cannot directly perform write operations.\n2.  Data modifications must be done through Hudi-specific tools and workflows.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hudi-conn"},{"document_id":"ibmcld_16608-0-2142","score":16.5967292786,"text":"\n\n\n\n\n\n\n  Learning about watsonx.data architecture and workload isolation \n\n\n\n  Architecture \n\nIBM\u00ae watsonx.data is a new open architecture that combines the elements of the data warehouse and data lake models. The best-in-class features and optimizations available on the watsonx.data, make it an optimal choice for next generation data analytics and automation.\n\nIt is a multi-tenant system that consists of two major building blocks:\n\n\n\n1.  Control plane - One control-plane cluster is created per IBM Cloud region that runs multi-tenant components such as service web console UI and API.\n2.  Data plane - One or more data-plane clusters are connected and managed by a control-plane running single-tenant customer-dedicated components within a customer-isolated instance such as a Presto engine and Hive metastore.\n\n\n\nImportant components of watsonx.data are:\n\n\n\n1.  Web console \u2013 Web console is the UI interface for watsonx.data from where customers, can perform various functional tasks. It is a multi-tenant component, which resides in the control plane.\n2.  Presto - Presto is a distributed SQL query engine, with the capability to query vast data sets located in different data sources.\n3.  Hive Metastore - Hive metastore (HMS) is a service that stores metadata that is related to presto and other services in a backend relational database. When a new table is created, information that is related to the schema such as column names, data types, are stored in the metastore\u2019s backend database.\n\n\n\n\n\n\n\n  watsonx.data workload isolation \n\nAs mentioned in the architecture section, some components of IBM\u00ae watsonx.data are multi-tenant and shared across customers in a given IBM Cloud region and some are single-tenant where they are explicitly dedicated to customers. To separate the access to infrastructure resources and data, several levels of authentication and authorization checks are in place. IAM authentication and access policies checks are performed on a service level. Role-based access control checks are performed on a resource level to allow only authorized users to perform certain operations and access to data.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-compute_isolation"},{"document_id":"ibmcld_16641-1211-2688","score":16.2795162201,"text":"\nFor more information on getting the HMS credentials, see [Getting (Hive metastore) HMS Credentials](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hms).\n\n\n\n\n\n\n\n Configuring Analytics Engine instance by using IBM Cloud\u00ae console \n\nTo configure your Analytics Engine instance from the IBM Cloud\u00ae Resource list, complete the following steps:\n\n\n\n1. Log in to your IBM Cloud\u00ae account.\n2. Access the [IBM Cloud\u00ae Resource list](https:\/\/test.cloud.ibm.com\/resources).\n3. Search your Analytics Engine instance and click the instance to see the details.\n4. Click Manage > Configuration to view the configuration.\n5. In the Default Spark configuration section, click Edit.\n6. Add the following configuration to the Default Spark configuration section.\n\nspark.sql.catalogImplementation = hive\nspark.driver.extraClassPath = \/opt\/ibm\/connectors\/iceberg-lakehouse\/iceberg-3.3.2-1.2.1-hms-4.0.0-shaded.jar\nspark.sql.extensions = org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\nspark.sql.iceberg.vectorization.enabled = false\nspark.sql.catalog.lakehouse = org.apache.iceberg.spark.SparkCatalog\nspark.sql.catalog.lakehouse.type = hive\nspark.sql.catalog.lakehouse.uri = <hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683)\nspark.hive.metastore.client.auth.mode = PLAIN\nspark.hive.metastore.client.plain.username = <hms-user-from-watsonx.data> (for example, ibmlhapikey)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.530721274,"ndcg_cut_10":0.6719882468}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02597-4595-6892","score":13.9139261246,"text":"\nThrough the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.\n\nAs well as controlling which APIs a customer can use, different Plans can be used to implement rate limits. A rate limit can be implemented as a default rate across an entire Plan, or for specific operations of an API within that Plan, exempting them from the Plan rate limit. Different Plans can have differing rate limits, both between operations and for the overall limit. Applying rate limits to Plans makes it easy to offer different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute while a \"Full Plan\" might permit up to 1000 calls per minute.\n\nFinally, different Plans can be used to assign a billing cost. A Plan can be set as a free Plan, or as a Plan with billing. Plans with billing can be used with rate limits to set different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute for a cost of $5 per month, while a \"Full Plan\" might permit up to 1000 calls per minute for a cost of $20 per month.\n\nNote: Applying a rate limit at the Plan level, creates a default rate limit that applies to each operation within the Plan. If you need to set specific rate limits for specific operations, you must set them within the operations themselves and this setting overrides the setting at the Plan level.\n\nIBM API Connect also supports the implementation of multiple versions of Products. You can choose version numbers and use them to aid the development of your Products and Plans.\n\nNote: The version for a Product is distinct from the version of any APIs that are contained in the associated Plans. Plans cannot themselves have their own version, they use the version of their parent Product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_02597-3131-5174","score":13.7955703735,"text":"\nPlans can share APIs, but whether subscription approval is required depends upon the Plan itself. Additionally, you can enforce rate limits through Plans or through operations within a Plan's APIs that override the Plan's rate limit.\n\nPlans can also specify billing costs for customers who use your Products. For example, you can define three different Plans for a single Product. Each Plan can have a different subscription cost and a different rate limit that targets different customers.\n\n\n\n\n\n Products \n\nPlans and APIs are grouped in Products. Through Products, you can manage the availability and visibility of APIs and Plans. Use the API Designer to create, edit, and stage your Product. Use the API Manager to manage the lifecycle of your Product.\n\nThe following diagram demonstrates how Products, Plans, and APIs relate to one another. Note how Plans belong to only one Product, can possess different APIs to other Plans within the same Product, and can share APIs with Plans from any Product. Figure to show the hierarchy of Products, Plans, and APIs. ![Figure to show the hierarchy of Products, Plans, and APIs.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/images\/plan_product_hierarchy.png)\n\nYou can create Plans only within Products, and these Products are then published in a Catalog. A lifecycle manager can then control the availability and visibility of APIs and Plans through the API Manager. Through the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_16364-160126-162041","score":12.1157693863,"text":"\nSee [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors) for information about how to edit skills that you want to continue using.\n\n\n\n\n\n\n\n 27 November 2018 \n\nA new service plan, the Plus plan, is available\n: The new plan offers premium-level features at a lower price point. Unlike previous plans, the Plus plan is a user-based billing plan. It measures usage by the number of unique users that interact with your assistant over a given time period. To get the most from the plan, if you build your own client application, design your app such that it defines a unique ID for each user, and passes the user ID with each \/message API call. For the built-in integrations, the session ID is used to identify user interactions with the assistant. See [User-based plans](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-services-informationservices-information-user-based-plans) for more information.\n\n\n\nPlus plan limits\n\n Artifact Limit \n\n Assistants 100 \n Contextual entities 20 \n Contextual entity annotations 2,000 \n Dialog nodes 100,000 \n Entities 1,000 \n Entity synonyms 100,000 \n Entity values 100,000 \n Intents 2,000 \n Intent user examples 25,000 \n Integrations 100 \n Logs 30 days \n Skills 50 \n\n\n\nUser-based Premium plan\n: The Premium plan now bases its billing on the number of active unique users. If you choose to use this plan, design any custom applications that you build to properly identify the users who generate \/message API calls. See [User-based plans](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-services-informationservices-information-user-based-plans) for more information.\n\nExisting Premium plan service instances are not impacted by this change; they continue to use API-based billing methods. Only existing Premium plan users will see the API-based plan listed as the Premium (API) plan option.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_10906-20682-22396","score":11.967590332,"text":"\nLearn more about [Enterprise Savings Plan](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use) and [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions). \n <br><br> * View invoices and build your own reports<br><br><br> To manage and view your invoices, visit the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud console. See [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices). You can also build your own reports by using the API and SDK that are available.<br><br><br><br> * [Usage Reports API\/SDK](https:\/\/cloud.ibm.com\/apidocs\/metering-reporting)<br> * [Enterprise Billing Units API\/SDK](https:\/\/cloud.ibm.com\/apidocs\/enterprise-apis\/billing-unit).<br> * [Enterprise Usage Reports API\/SDK](https:\/\/cloud.ibm.com\/apidocs\/enterprise-apis\/resource-usage-reports).<br><br><br> \n\n\n\n\n\n\n\n Connect your network to IBM Cloud \n\nAs the need for global reach and 24\/7 operations of web applications increases, the need to host services in multiple cloud data centers increases too. Data centers across multiple locations provide resilience in the case of a geographic failure and bring workloads closer to globally distributed users, which reduces latency and increases perceived performance. The IBM Cloud network enables users to link workloads hosted in secure private networks across data centers and locations. Use the following checklist to review the available options and to connect your existing on-premises environments to IBM Cloud.\n\n\n\nTable 5. Getting started tasks for connecting your network to IBM Cloud\n\n Task Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklist"},{"document_id":"ibmcld_01447-3317-5285","score":11.9078540802,"text":"\nService plans are scoped to the specific registry instance (one of the regional registries or the global registry) that you're currently working with. Plan settings must all be managed separately for your account in each registry instance. For more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\nThe following table shows available IBM Cloud Container Registry service plans and their characteristics. For more information about how billing works and what happens when you exceed service plan limits, see [Quota limits and billing](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_plan_billing).\n\n\n\nTable 2. Container Registry plans\n\n Characteristics Free Standard \n\n Description. Try out Container Registry to store and share your Docker images. This plan is the default service plan when you set up your first namespace in Container Registry. Benefit from unlimited storage and pull traffic usage to manage the Docker images for all namespaces in your IBM Cloud account. \n Amount of storage for images. 500 MB Unlimited \n Pull traffic. 5 GB per month Unlimited \n Billing. If you exceed your storage or pull traffic limits, you cannot push or pull images to and from your namespace. For more information, see [Quota limits and billing](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_plan_billing). Storage. You are charged by Gigabyte-Months of usage. The first 0.5 GB-Months are free. Then, you are charged as stated in the offering details page, see [Container Registry](https:\/\/cloud.ibm.com\/registry\/catalog).<br><br>Pull traffic. You are charged by Gigabyte usage per month. The first 5 GB are free. Then, you are charged as stated in the offering details page, see [Container Registry](https:\/\/cloud.ibm.com\/registry\/catalog). If you exceed your storage or pull traffic limits, you can't push or pull images to and from your namespace.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"},{"document_id":"ibmcld_00690-17380-18259","score":11.8636417389,"text":"\n: Upgraded to [GitLab 11.9.12](https:\/\/about.gitlab.com\/releases\/2019\/06\/03\/security-release-gitlab-11-dot-11-dot-1-released\/).\n\n\n\n\n\n 24 June 2019 \n\nStricter enforcement of service plans\n: A toolchain must be linked to a CD service in order for the Delivery Pipeline run.\n: Users of the CD service are automatically added to the list of \"Authorized Users.\"\n: If you are using the Lite plan with more than five authorized users, the pipelines no longer run, pushes to Git Repos are unavailable, and DevOps Insights is unavailable.\n: If you are using the Lite plan, after 500 Delivery Pipeline jobs are run during a month, pipelines do not run, pushes to Git Repos are unavailable, and DevOps Insights is unavailable for the remainder of that billing period.\n\nRead the [announcement](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/usage-and-billing-in-ibm-cloud-continuous-delivery).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-relnotes"},{"document_id":"ibmcld_03734-7-2243","score":11.8282079697,"text":"\nEnterprise Savings Plan billing model \n\nThe IBM Cloud\u00ae Enterprise Savings Plan billing model is similar to the billing model for Subscription accounts but with a few added benefits. With this billing model, you commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nThe Commitments and subscriptions page in the console offers a view of any active or upcoming commitments. If you have an active subscription, or had subscriptions in the past, those details are also displayed on this page.\n\n\n\n Before you begin \n\nIf you haven\u2019t created an account, you can register for IBM Cloud by completing the following steps:\n\n\n\n1. Consult with an [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. IBM Cloud Sales will direct you to the [registration page](https:\/\/cloud.ibm.com\/registration\/sales).\n2. Enter the required information. After registration is complete, provide your name, email, and the account ID to the sales representative you are working with.\n3. Your account is activated upon order processing. After the account is activated, you can start leveraging the benefits of our Enterprise Savings Plan billing model.\n\n\n\n\n\n\n\n Signing up for a commitment \n\nTo use the IBM Cloud Enterprise Savings Plan billing model, you must have a Subscription account. After you have the correct account, work with [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to sign up for this billing model. The sales team creates a commitment quote based on the spending amount for a certain period of time that you want to commit to.\n\nAfter you accept the commitment quote, you receive an additional email to confirm that your payment information is processed and that the commitment is added to your account.\n\n\n\n\n\n Viewing your commitment quote \n\nAfter you contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) and sign up for a commitment, you receive a quote. The commitment quote details your contract period, duration of the commitment, billing frequency, UOM, discount, and commitment terms. The sales team will email you a copy of your quote.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use"},{"document_id":"ibmcld_01660-8584-10307","score":11.7920331955,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_00558-20425-22479","score":11.7854146957,"text":"\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-20515-22569","score":11.7854146957,"text":"\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01623-6277-8255","score":20.5539035797,"text":"\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started"},{"document_id":"ibmcld_16727-805993-808161","score":19.251663208,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-806120-808288","score":19.251663208,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03800-1779-3764","score":17.664981842,"text":"\nViewing usage details from the usage summary widget \n\nIn the usage summary widget on the billing and usage dashboard, you get view of your actual and predicted spending trends.\n\nThe predicted usage for the next month is calculated by finding the trend from the usage of the last three months, including the current month. For example, if it's August, predicted usage is calculated based on usage trends in June, July, and August to find the predicted usage for September.\n\nLet's say the usage is $950.00 USD for June, $1000.00 USD for July, and $1012.50 USD for August. The difference is calculated between the current month and the last month, and last month and the month before that. Then, the two calculations are averaged to find the trend. That trend amount of $1043.75 USD is the predicted next month's usage, with the following calculations:\n\n\n\n* Change between August and July = $1012.50 - $1000.00 = $12.50 USD\n* Change between July and June = $1000.00 - $950.00 = $50.00 USD\n* Average change (trend) = ($12.50 + $50.00) \/ 2 = $31.25 USD\n\n\n\nAugust usage ($1012.50) + Average change ($31.25) = The predicted usage for next month September ($1043.75 USD)\n\n\n\n\n\n Viewing usage details from the usage page \n\nIn the Services section, you can view a list of your services and the estimated costs that are associated with those services. To view a summary of estimated charges for all instances of a specific resource, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage.\n2. Click View plans to view all the instances of a specific type of resource.\n3. To view a detailed summary of estimated charges for each instance of a specific resource type, click View details. You can also view the detailed monthly usage metrics for the selected instance.\n\n\n\nIf you have a Pay-As-You-Go account that isn't billed in US dollars or a Subscription account, the usage for all services is finalized by the 20th of the following month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage"},{"document_id":"ibmcld_03735-7-1918","score":17.1348819733,"text":"\nEstimating your costs \n\nYou can use the cost estimator to estimate the cost of IBM Cloud\u00ae products by customizing plans that fit your business needs. Your account type doesn't affect your estimates. Explore the catalog to find available products to add to an estimate.\n\nEstimates can now be saved to an account. Make sure you're in the account that you want to save the estimate to. If you have existing estimates, they must be converted to a saved estimate that is attached to an account.\n\n\n\n Creating a new estimate \n\n\n\n1. In the IBM Cloud console, go to Cost estimator icon![Cost estimator icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/calculator.svg). From here, you are directed to Estimating your costs page.\n2. Click Create new estimate.\n3. Enter a name and description for the estimate.\n4. Click Create\n5. From here, you are directed to the estimate details page. Click Go to catalog to add products to the estimate.\n6. Select the product that you are interested in.\n\nDepending on the product, an interim informational page might be displayed. For example, if you select Bare Metal Servers, an informational page that describes various features is displayed. Click Continue.\n7. Select your pricing plan and enter other configuration details if needed. Then, click Add to estimate.\n\nSome products might require that you log in to add them to an estimate.\n8. Enter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_02665-3418-5653","score":17.0924263,"text":"\nFor server-side entities like microservices, when the state of a feature flag or property changes in the App Configuration, a websocket connection notifies the SDK in the microservice that a state change occurred. The microservice then calls back into the App Configuration to retrieve the update. This action is an API call.\n\nAn API call also occurs on startup to the retrieve the initial configuration state. For client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n\n\n\n\n\n How to view usage metrics for App Configuration? \n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n\n\n\n\n\n How to predict App Configuration cost? \n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"},{"document_id":"ibmcld_03735-1425-3233","score":16.2402839661,"text":"\nEnter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1. Click Save and select the estimate that you'd like to add the product to, and then add the calculated cost to your estimate by clicking Save.\n2. When you're done adding products to your estimate, review the product details, and click View estimate.\n\n\n\n\n\n\n\n Updating an existing estimate \n\nYou can always update the name and description of an estimate as your needs change. To edit an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to edit.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Edit.\n3. Enter the updated name and description.\n4. Click Save\n\n\n\n\n\n\n\n Saving and sharing your estimate \n\nWhen you create an estimate, you can save each estimate's unique link to share or revisit directly through your browser. To share an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to share.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Share.\n3. Click Copy link and share the link with users in your account.\n\n\n\n\n\n\n\n Creating quotes for classic infrastructure services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_07289-1587-3853","score":16.0814342499,"text":"\nFor example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n\n\n\n\n What is planned for Direct Link on Classic Exchange? \n\nThe marketplace has evolved since Direct Link Exchange was established. With data center operators now blurring the lines as network service providers, IBM will be combining the Exchange offering with Connect on the new \"next generation\" platform to reflect both this change and simplify the Direct Link portfolio. Direct Link Exchange will service only the Direct Link classic infrastructure.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-faqs"},{"document_id":"ibmcld_07578-506456-508701","score":15.9427232742,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-506398-508643","score":15.9427232742,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2371977128,"ndcg_cut_10":0.4415801104}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03729-7-2197","score":12.1515007019,"text":"\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03797-4528-6268","score":12.1234102249,"text":"\n[A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/example-invoice-console.png)\n\nFigure 3. New and one-time charges in the console for the month of March.\n\nThe remaining infrastructure charges of $322,806.71 USD from the recurring invoice in the console and the new and one-time charges should add up to the total IaaS final invoice charge of $324,245.93 USD.\n\n\n\n\n\n Granular view of the line item charges \n\nNow that we confirmed that the final invoice totals match the recurring and new and one time charges in the console, let\u2019s find out what the charges on the final invoice represent.\n\nOn the Excel version of your recurring invoice that you downloaded in step 2, click the Detailed Billing tab. The Detailed Billing tab provides a breakdown of all of your infrastructure and platform charges. They represent three major types of usage:\n\n\n\n* In Advance (for example, the month of March) infrastructure monthly usage charges. These are recurring charges that you incur until you cancel the service. The charge is the same every month.\n\n\n\nZoom\n\n![An example of an advanced infrastructure monthly usage charges on the detailed invoice tab from the downloaded Excel invoice.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_16252-6962-9118","score":10.3687391281,"text":"\nTest messages that you send from the Preview button are charged. For the preview, a random user_id is generated and stored in a cookie. The multiple interactions that a single tester has with the assistant embedded in the preview are recognized as coming from a single user and are charged accordingly. If you are doing your own test, running a scripted regression test for example, use a single user_id for all of the calls within your regression test. Other uses are flagged as abuse.\n\n\n\n\n\n Handling anonymous users \n\nIf your custom application or assistant interacts with users who are anonymous, you can generate a randomized universally unique ID to represent each anonymous user. For more information about UUIDs, see [RFC 4122](https:\/\/tools.ietf.org\/html\/rfc4122.html).\n\n\n\n* For web chat, if you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user. And you are charged only once when the same anonymous user interacts with your assistant multiple times in a single month.\n\n\n\nIf an anonymous user logs in and later is identified as being the same person who submitted a request with a known ID, you are charged twice. Each message with a unique user ID is charged as an independent active user. To avoid this situation, you can prompt users to log in before you initiate a chat or you can use the anonymous user ID to represent the user consistently.\n\n\n\n\n\n Data centers \n\nIBM Cloud has a network of global data centers that provide performance benefits to its cloud services. See [IBM Cloud global data centers](https:\/\/www.ibm.com\/cloud\/data-centers\/) for more details.\n\nYou can create Watson Assistant service instances that are hosted in the following data center locations:\n\n\n\nData center locations\n\n Location Location code API location \n\n Dallas us-south N\/A \n Frankfurt eu-de fra \n Seoul kr-seo seo \n Sydney au-syd syd \n Tokyo jp-tok tok \n London eu-gb lon","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"},{"document_id":"ibmcld_09151-1752-3025","score":10.3392190933,"text":"\nIf 200 keys are selected, for example, the charge is $200. This quota of keys can be changed later by opening a service ticket. If you attempt to exceed your key quota, you will get an error.\n\n\n\nIf you change quotas in the middle of a billing cycle (for example, going from 100 keys to 200 keys) you are charged whichever quota is larger. This charge is not prorated by the amount of time a particular quota was selected and is based on the maximum quota during a particular billing cycle.\n\nIf you navigate to the [catalog page for Key Protect on Satellite](https:\/\/cloud.ibm.com\/catalog\/services\/key-protect), click on the Satellite card under Select a location, and cannot see the specific plan information for Key Protect on Satellite, this might be because you have not been allowlisted. [Contact IBM](https:\/\/www.ibm.com\/contact\/us\/en\/) to learn more.\n\n\n\n\n\n What is a non-deleted key? \n\nRecall from [Monitoring the lifecycle of encryption keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) that keys can be either in the active, deactivated, suspended, or destroyed state. The act of deleting a key moves it to the destroyed state.\n\nIn the context of your key quota, you are charged for every key that is a state other than the destroyed state.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-pricing-plan-satellite"},{"document_id":"ibmcld_11408-13151-14243","score":10.1105861664,"text":"\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change. To calculate your pricing, use the [IBM cost estimator](https:\/\/cloud.ibm.com\/estimator) in IBM Cloud console.\n\n\n\n\n\n End of billing \n\nThe monthly billing cycle ends when you delete the LPAR. If you scale your infrastructure up and down in response to workload requirements, your billing follows the timing of the LPAR provision change. If you stop the LPAR, the billing process is not stopped. You must delete the LPAR to stop the billing cycle.\n\nYou are still charged if the VM is in a suspended state. When your VM is inactive, you can use Dynamic Logical Partitioning (DLPAR) to resize it to a minimal state. You can drastically decrease the price per hour by reducing the VM's core count and memory.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_03798-0-2240","score":9.9893188477,"text":"\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http:\/\/ibm.com\/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https:\/\/cloud.ibm.com\/billing\/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https:\/\/cloud.ibm.com\/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-understand-invoices"},{"document_id":"ibmcld_16727-784060-785333","score":9.874130249,"text":"\nNo. The CDN edge servers can only access the ICOS public endpoints, so objects in the ICOS buckets should provide public access.\n\n\n\n\n\n Will traffic sent from ICOS to CDN be charged? \n\nYes. The CDN and ICOS don't have a way of measuring each other's traffic, so both traffic from ICOS and CDN are charged.\n\n\n\n\n\n How does the CDN edge server retrieve content from the ICOS objects? \n\nThe CDN uses the S3 endpoint to access the ICOS objects, and replaces the path in the url to the bucket name. For example, if your ICOS S3 endpoint s3.us-south.cloud-object-storage.appdomain.cloud with bucket name xyz-bucket-name is added in path \/example-cos\/, when you open the CDN URL www.example.com\/example-cos\/, the CDN edge server retrieves the content from s3.us-south.cloud-object-storage.appdomain.cloud\/xyz-bucket-name\/.\n\n\n\n\n\n How do I use the ICOS default index page with CDN? \n\nThe CDN does not support the default index page for the ICOS objects because the ICOS S3 endpoint does not have the default index. You must specify the complete request path in the browser's address bar (for example, www.example.com\/index.html). If you want the CDN to automatically access the default index page of the ICOS, create a CDN with Server type of origin instead of an Object Storage type.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00360-1275-2548","score":9.874130249,"text":"\nNo. The CDN edge servers can only access the ICOS public endpoints, so objects in the ICOS buckets should provide public access.\n\n\n\n\n\n Will traffic sent from ICOS to CDN be charged? \n\nYes. The CDN and ICOS don't have a way of measuring each other's traffic, so both traffic from ICOS and CDN are charged.\n\n\n\n\n\n How does the CDN edge server retrieve content from the ICOS objects? \n\nThe CDN uses the S3 endpoint to access the ICOS objects, and replaces the path in the url to the bucket name. For example, if your ICOS S3 endpoint s3.us-south.cloud-object-storage.appdomain.cloud with bucket name xyz-bucket-name is added in path \/example-cos\/, when you open the CDN URL www.example.com\/example-cos\/, the CDN edge server retrieves the content from s3.us-south.cloud-object-storage.appdomain.cloud\/xyz-bucket-name\/.\n\n\n\n\n\n How do I use the ICOS default index page with CDN? \n\nThe CDN does not support the default index page for the ICOS objects because the ICOS S3 endpoint does not have the default index. You must specify the complete request path in the browser's address bar (for example, www.example.com\/index.html). If you want the CDN to automatically access the default index page of the ICOS, create a CDN with Server type of origin instead of an Object Storage type.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-configure-cdn-with-ibm-cloud-object-storage"},{"document_id":"ibmcld_01447-4830-6832","score":9.8567838669,"text":"\nThen, you are charged as stated in the offering details page, see [Container Registry](https:\/\/cloud.ibm.com\/registry\/catalog).<br><br>Pull traffic. You are charged by Gigabyte usage per month. The first 5 GB are free. Then, you are charged as stated in the offering details page, see [Container Registry](https:\/\/cloud.ibm.com\/registry\/catalog). If you exceed your storage or pull traffic limits, you can't push or pull images to and from your namespace. For more information about storage, pull traffic, and the cost estimator, see [Quota limits and billing](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_plan_billing). \n\n\n\n\n\n\n\n Quota limits and billing \n\nFind information and examples for how the billing process and quota limits work in Container Registry.\n\nEvery image is built from a number of layers that each represent an incremental change from the base image. When you push or pull an image, the amount of storage and pull traffic that is needed for each layer is added to your monthly usage. Identical layers are automatically shared between images in your IBM Cloud account and are reused when you create other images. The storage for each identical layer is charged only once, regardless of how many images in your account reference the layer. Layers that are only referenced by deleted images in the trash are not charged.\n\nFrom 1 February 2022, both [tagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) and [untagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images are charged for.\n\nQuota limits and billing are scoped to the specific registry instance (one of the regional registries or the global registry) that you're currently working with. Quota settings must be managed separately for your account in each registry instance. For more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"},{"document_id":"ibmcld_10116-7-2157","score":9.8488454819,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith Red Hat OpenShift on IBM Cloud clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03729-1672-3956","score":18.85987854,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03729-4932-7001","score":18.4584102631,"text":"\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03776-5228-7163","score":18.4562988281,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03729-7-2197","score":14.3726549149,"text":"\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03776-3313-5682","score":12.0178155899,"text":"\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_10116-1581-3594","score":11.8913955688,"text":"\nFor more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.\n\n\n\n* Shared versus dedicated: If you share the underlying hardware of the VM, the cost is less than dedicated hardware, but the physical resources are not dedicated to your VM.\n* Hourly billing only: Hourly billing offers more flexibility to order and cancel VMs quickly. You are charged an hourly rate that is metered for only the time that that the worker node is provisioned. The time is not rounded up or down to the nearest hour, but is metered in minutes and charged at the hourly rate. For example, if your worker node is provisioned for 90 minutes, you are charged the hourly rate for 1.5 hours, not 2 hours.\n* Tiered hours per month: The [pricing](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/aboutpricing) is billed hourly in [graduated tiered](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargesgraduated_tier). As your VM remains ordered for a tier of hours within a billing month, the hourly rate that you are charged lowers. The tiers of hours are as follows:\n\n\n\n* 0 - 150 hours\n* 151 - 290 hours\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_05666-1575-3588","score":11.8913955688,"text":"\nFor more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.\n\n\n\n* Shared versus dedicated: If you share the underlying hardware of the VM, the cost is less than dedicated hardware, but the physical resources are not dedicated to your VM.\n* Hourly billing only: Hourly billing offers more flexibility to order and cancel VMs quickly. You are charged an hourly rate that is metered for only the time that that the worker node is provisioned. The time is not rounded up or down to the nearest hour, but is metered in minutes and charged at the hourly rate. For example, if your worker node is provisioned for 90 minutes, you are charged the hourly rate for 1.5 hours, not 2 hours.\n* Tiered hours per month: The [pricing](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/aboutpricing) is billed hourly in [graduated tiered](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargesgraduated_tier). As your VM remains ordered for a tier of hours within a billing month, the hourly rate that you are charged lowers. The tiers of hours are as follows:\n\n\n\n* 0 - 150 hours\n* 151 - 290 hours\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_03578-7-2257","score":11.3645935059,"text":"\nAbout bandwidth metering \n\nTo reduce your overall bandwidth costs, it's important to consider your bandwidth metering options. You can purchase and manage bandwidth metering for classic in two ways, through metering on individual devices, or through collective-metering when you add a device to a bandwidth pool.\n\nAll inbound and outbound bandwidth inside the IBM Cloud Classic infrastructure is unlimited and cost-free for your servers' use. Public egress bandwidth is charged on a tiered basis, with a set allocation for each month of your servers' use.\n\nBandwidth usage is measured as egress traffic on a device's public interfaces.\n\nBandwidth allocations are reserved for all public egress network usage. Devices with individual bandwidth metering and pool-based metering are all measured unless the device is ordered on the private network only.\n\nBandwidth allocation is a threshold where usage below the threshold is free or included, while usage in excess of the threshold is billed as a bandwidth overage. Bandwidth overages are billed individually per server or device, unless they participate in a bandwidth pool.\n\nDevices added to a bandwidth pool contribute both their bandwidth allocation and bandwidth usage to form aggregated totals for the pool. If the pool usage exceeds the total pool allocation, the account owner is billed a consolidated pool overage fee.\n\n\n\n About device bandwidth \n\nYou can manage each device's bandwidth allocation. When you provision certain devices, you can select the amount of bandwidth that you want to allocate to that device. For each device, you pay for a fixed amount of bandwidth allocation during a billing cycle, and receive a notification when the device is at risk of overage for the billing cycle. For more information, see [Adding Bare Metal Server bandwidth](https:\/\/cloud.ibm.com\/docs\/bandwidth-services?topic=bandwidth-services-adding-bare-metal-server-bandwidth) and [Adding virtual server instance bandwidth](https:\/\/cloud.ibm.com\/docs\/bandwidth-services?topic=bandwidth-services-adding-virtual-server-insance-bandwidth).\n\nWhen the bandwidth usage on a device reaches 85% of its total allocation, the account owner receives notifications.\n\nIBM charges for some firewall bandwidth metering.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bandwidth-metering?topic=bandwidth-metering-about-bandwidth-metering"},{"document_id":"ibmcld_14546-7-1993","score":10.7789230347,"text":"\nVMware Shared pricing \n\nIBM Cloud\u00ae for VMware Solutions Shared offers two pricing plans for creating VMware\u00ae virtual data centers. Virtual data centers incur charges for the following virtual data center resource usages:\n\n\n\n* Storage allocations with tiered pricing based on storage performance\n* Virtual CPU (vCPU) usage\n* Virtual memory usage\n* Egress on public networking\n* Commercial operating system licenses used\n* Third-party VMware services\n\n\n\n\n\nTable 1. Pricing plans\n\n Plans Description \n\n VMware Shared On-demand <br><br> * The vCPU and RAM virtual data center are allocated based on the demand. Resources are not preallocated. If you have a large regional demand, delays in availability can occur.<br> <br> <br> <br> <br> * The limits that are established for the amount of vCPU and RAM are maximums.<br> * vCPU and RAM resource limits can be increased and decreased later as required.<br> * The price is calculated hourly and it is based on the resource usage in the virtual data center.<br> * The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are hourly based on GB of allocated storage.<br> * The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.<br> <br> <br> <br> <br><br><br> \n VMware Shared Reserved <br><br> * The vCPU and RAM virtual data center reservations are pre-allocated and their availability is guaranteed.<br> <br> <br> <br> <br> * vCPU and RAM resources can be increased and decreased later as required.<br> * The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are hourly based on GB of allocated storage.<br> * The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.<br> <br> <br> <br> <br><br><br> \n\n\n\n\n\n Price breakdown \n\n\n\n Usage \n\nMetering is for the full potential size of the resource for the time period that the resource is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_11328-3300-5281","score":10.6483812332,"text":"\n* The master volume is charged 2x size based on its Tier under the existing part numbers for Tier 1 and Tier 3.\n* Replication capability cost is charged $Y\/GB under a new part number \"GLOBAL_REPLICATION_STORAGE_GIGABYTE_HOURS\" that is independent of volume tier.\n\n\n\nUpon a site failure due to a catastrophe, metering is not available from the failed site. The auxiliary volumes are charged from remote site for its 2x size based on its tier. There is no replication capability cost for any replication-enabled volume.\n\n\n\n\n\n Setting up the Global replication service \n\nThe GRS involves two sites where storage replication is enabled. These two sites are fixed and mapped into one-to-one relationship mode in both directions. These two sites are fixed and are in replication partnership in both directions.\n\nYou can create a replication-enabled volume from any site, the site from where the request is initiated contains the master volume and play the role of master. The remote site is auxiliary and contain an auxiliary volume.\n\nThe following table explains how to determine the primary and secondary site based on replication-enabled volume creation:\n\n\n\nTable 2. Primary and secondary site reference based on volume creation\n\n Replication-enabled volume creation site Primary site (master volume) Secondary site (auxiliary volume) \n\n Site 1 Site 1 Site 2 \n Site 2 Site 2 Site 1 \n\n\n\n\n\n\n\n Preparation for disaster recovery \n\nWhen you have the virtual server instances with data volume running workloads, you can ensure that your data volumes are replicated and can be recovered from the remote site, in case of failure by performing [actions on primary site](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-getting-started-GRSconfigure-primary-site) and [secondary site](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-getting-started-GRSconfigure-secondary-site).\n\n\n\n Actions on the primary site \n\nTo enable DR on the primary site, complete the following steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-getting-started-GRS"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.9674679835,"ndcg_cut_10":0.9674679835}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03776-5228-7163","score":21.0910224915,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_12815-5234-7392","score":20.2474365234,"text":"\nFirst, add the Export Control Classification Number and the United Nations Standard Products and Services Code that applies to your product. Next, define your pricing plan. Currently, you can choose a free or usage-based pricing plan. If you\u2019d like, you can add multiple plans for your product. [Click Pricing then click Add ECCN to add your Export Control Classification Number. Click Add UNSPSC to add the United Nations Standard Products and Services Code for your product. Click Add plan, select the plan type, add a name, select how resource instances should be deployed, and click Save.]\n\nFor usage-based plans, you must submit your tax and EFT information to set up and receive payment disbursements for usage. You\u2019ll also want to add metrics to determine how customers are charged, and submit your updates for approval. [The Payments to me page is highlighted. Click Add metrics to add your metrics to the pricing plan. In the Metering approval section, click Request approval.]\n\nBuilding one or more service brokers is needed to manage the lifecycle of your service and metering integration. A broker must be added to complete your pricing plan. Your technical team member can get started with our sample broker. Add your broker by entering a name, a URL, a username, and a password. Or, you can import brokers from your account. After you add your broker, link it to your pricing plan. [Click Brokers. In the Onboard brokers to IBM Cloud section, click OK to open the sample reference broker. Click Add broker to add your broker. Click Pricing, click the actions icon for your pricing plan, and click Edit plan to link your broker to your pricing plan.]\n\nNow that you\u2019ve defined your pricing model, review how customers would understand and experience it. After your metering updates are approved, validate that your metered plans are correctly configured by enabling and submitting a usage test. This usage test includes creating your metering JSON, calling the Usage Metering API, and submitting metering evidence. [Click Add metrics for the pricing plan you added. Click Test estimation and metering to submit your metering evidence for review.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-started"},{"document_id":"ibmcld_01660-8584-10307","score":19.3374023438,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_12858-3912-5854","score":19.2634010315,"text":"\n8. Select the broker that you want to link to this plan. If you haven't added a broker to your account, you can't link a broker to your plan. After you add a broker, you can link it by editing the pricing plan.\n9. Click Save.\n10. Click Add metrics.\n11. In the Usage metrics section, click Add metrics.\n12. Enter 1 as the smallest unit that customers pay.\n13. Select Instance as the unit.\n14. Enter Instance as the display name for the unit.\n15. Select Per unit as the charge method.\n16. Enter 1 as the USD price.\n17. Click Done.\n18. When you are ready to submit your pricing plan and metering for review, click Request update.\n\n\n\n\n\n\n\n Step 5: Add features for your service \n\nIf you completed the steps to define your pricing plan, you can add a list of features for your service. These features uniquely identify your product's attributes and differentiate your pricing plan from others. By providing a list of features for your product, you can help customers choose the most suitable pricing plan for their use case.\n\nYou can add up to five features for your product, but you must add at least one. The first feature that you add appears more prominently. Include the most important and differentiating details as the first feature.\n\nTo add features for your service, complete the following steps:\n\n\n\n1. Click Pricing.\n2. Select a pricing plan from the table that you previously added. After you select a plan, you are redirected to the Pricing plan details page.\n3. Click Add features.\n4. Enter a description for each feature.\n\n\n\n* You can remove any feature that you add by clicking Remove feature.\n\n\n\n5. Click Save.\n\n\n\n\n\n\n\n Step 6: Review and submit the digital platform reseller agreement \n\nIf you plan to offer usage-based pricing plans, it is required to review and submit the IBM Digital Platform Reseller Agreement. This legal agreement sets the terms and conditions under which providers can onboard and sell products in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-svc-pricing"},{"document_id":"ibmcld_12407-4383-5026","score":19.0561733246,"text":"\nTo update your service plan after you create an instance, see [Updating your service plan](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-changing).\n\n\n\n\n\n Upgrading a Secrets Manager instance to the Standard plan \n\nWhen your Trial instance expires, you lose access to your secrets, and integrations. To preserve your data, and prevent any disruptions in your workflow, you must upgrade to the Standard plan before your Trial plan expires. Follow the steps to [update your pricing plan](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-changing&interface=ui). You can use the UI, API, and CLI to complete this process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-create-instance&interface=ui"},{"document_id":"ibmcld_12838-7607-9492","score":18.8106479645,"text":"\nAll plans for a product use either global or per location. By selecting per location, you can specify different regions or data centers for each plan that you add.\n8. Link a broker to the plan.\n\nIf you haven't finished adding a broker to your account, you will not see this option, and you can continue and save your pricing plan. However, you can't complete your pricing plan until the broker is added and linked to your plan.\n9. Click Save.\n\n\n\n\n\n\n\n Adding a paid pricing plan \n\nBy adding a usage-based pricing plan, you are indicating that you offer your product as a paid integrated product, and customers need to pay to use it. All information that is entered on the Add plan panel is displayed to customers in the IBM Cloud catalog to help them purchase your service.\n\nWhen you add a usage-based pricing plan, you provide your suggested retail pricing information. However, IBM reserves the right to set the final pricing for any product that is offered to customers in the IBM Cloud catalog.\n\nTo add a paid pricing plan for your service, complete the following steps:\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/icons\/icon_hamburger.svg) > Partner Center > Sell > My products.\n2. Select the product that you're onboarding, and click Pricing.\n3. Click Add plan.\n4. Select Usage-based.\n5. Enter a name for your plan.\n6. Describe the details of your plan.\n7. Choose the locations where your plan is available. All plans for a product use either global or per location. By selecting per location, you can specify different regions or data centers for each plan that you add.\n8. Select a broker to link to the plan.\n\nIf you haven't finished adding the broker to your account, you will not see this option, and you can continue and save your pricing plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-pricing-info"},{"document_id":"ibmcld_03735-1425-3233","score":18.4234333038,"text":"\nEnter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1. Click Save and select the estimate that you'd like to add the product to, and then add the calculated cost to your estimate by clicking Save.\n2. When you're done adding products to your estimate, review the product details, and click View estimate.\n\n\n\n\n\n\n\n Updating an existing estimate \n\nYou can always update the name and description of an estimate as your needs change. To edit an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to edit.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Edit.\n3. Enter the updated name and description.\n4. Click Save\n\n\n\n\n\n\n\n Saving and sharing your estimate \n\nWhen you create an estimate, you can save each estimate's unique link to share or revisit directly through your browser. To share an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to share.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Share.\n3. Click Copy link and share the link with users in your account.\n\n\n\n\n\n\n\n Creating quotes for classic infrastructure services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_03776-8303-10233","score":18.3734092712,"text":"\nIf you have a Pay-As-You-Go account that's billed in US dollars, you can view your invoice in the IBM Cloud console by going to Manage > Billing and usage, > and clicking Invoices.\n\nIf you own one of the following accounts, you can view your invoice on the [IBM Invoices](http:\/\/ibm.com\/invoices) website, which is linked from the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices) in the console.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nNew IBM Cloud Pay-As-You-Go accounts for US customers with credit card billing can now view all classic infrastructure and platform services on one invoice. In the IBM Cloud console, go to Manage > Billing and usage, and select Invoices.\n\nFor more information about invoices, see [Managing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices).\n\n\n\n\n\n Enterprise Savings Plan billing model \n\nIBM Cloud customers with a Subscription account can sign up for the Enterprise Savings Plan billing model. With this billing model, you commit to spend a certain amount on IBM Cloud and you receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount. For more information about the billing model, see [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use).\n\nPremium and advanced support options are available for Pay as you go with Committed Use. Support plan pricing falls into two tiers depending on the price level of your commitment. For more information, see [Support options for Pay as you go with Committed Use](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-planssupport-plans).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_02665-3418-5653","score":18.1912307739,"text":"\nFor server-side entities like microservices, when the state of a feature flag or property changes in the App Configuration, a websocket connection notifies the SDK in the microservice that a state change occurred. The microservice then calls back into the App Configuration to retrieve the update. This action is an API call.\n\nAn API call also occurs on startup to the retrieve the initial configuration state. For client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n\n\n\n\n\n How to view usage metrics for App Configuration? \n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n\n\n\n\n\n How to predict App Configuration cost? \n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"},{"document_id":"ibmcld_12838-1757-3539","score":18.0431480408,"text":"\nIn the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/icons\/icon_hamburger.svg) > Partner Center > Sell > Payments to me.\n2. Download the relevant EFT form, and complete it.\n\nOne of three types of bank documents is required to be submitted with the form. You can submit a scanned copy of a voided check or a bank letter that is signed and stamped by the bank. If you are outside of the United States, you can alternatively provide an online bank statement. The document that you provide must include the bank name, account number, routing number (or bank key or ABA), and the account holder's name.\n3. Download the relevant tax documentation, and complete it.\n4. Submit the completed documentation by email to apremit@us.ibm.com. You must include cloud.onboarding@ibm.com on the email.\n5. Select I confirm that I completed and emailed all of the required documents..\n\n\n\n\n\n\n\n Providing the ECCN \n\nTo start defining your pricing model, you must provide the ECCN that applies to your product. The ECCN is required for both free and usage-based pricing plans. If you don't have your ECCN, you can find it on the [Commerce Control List](https:\/\/www.bis.doc.gov\/index.php\/licensing\/commerce-control-list-classification\/export-control-classification-number-eccn). If you need to update your ECCN after you add it, you must contact IBM Cloud Support.\n\nYou must submit your tax and EFT documents and receive approval before you can provide the ECCN if you're using a usage-based pricing plan.\n\n\n\n1. Go to Partner Center > Sell > My products.\n2. Open the service that you want to edit and go to the Pricing tab.\n3. Click Enter your ECCN and provide the ECCN for your service.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-pricing-info"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08067-0-1736","score":15.9245223999,"text":"\n\n\n\n\n\n\n  Viewing your support costs \n\nIf you have Advanced or Premium support, you can keep track of your monthly support costs from the Support costs page in the IBM Cloud\u00ae console.\n\n\n\n  How you're charged for support \n\nEach [IBM Cloud support plan](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans) has a minimum monthly price for providing support for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost. For details about your purchased support plan, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n  Viewing support costs \n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\nIn the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. You can view your support plan and relevant cost details:\n\n\n\n*  If your support costs are billed monthly, you can view your costs for the current month. These costs include the starting price for the plan and any additional costs from your resource usage. After each billing cycle, these charges are added to your monthly invoice.\n*  If you have a support subscription, you can view the remaining credit in your active subscriptions and any overages for the current month. Overage is charged if you run out of credit in your active subscriptions. You can also view upcoming support subscriptions, which are subscriptions that you bought but are not yet valid.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support"},{"document_id":"ibmcld_03749-8477-10695","score":14.6632938385,"text":"\nFor more information about managing your platform and support subscriptions, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n Usage reporting \n\nEnterprises provide top-down usage reporting so that you can track the costs of resource usage from all accounts in the enterprise. Starting at the enterprise level, you can navigate within the enterprise structure to see the estimated usage costs within each account or account group. At the account level, enterprise users can view costs for each type of resource or service in the account.\n\nEnterprise administrators can provide granular access to users so that they can view usage only for certain account groups or accounts. For example, say that your enterprise has account groups for each department, and each department has account groups for each team.\n\n\n\n* You give your financial officer access to view the entire enterprise so that they can track and recover costs for each department.\n* You give each department lead access to view usage for everything in their department's account group.\n* You give each team lead access to view only the accounts in their team's account group.\n\n\n\nBecause access in the enterprise is separate from access in each account, enterprise users can't automatically manage resources within the child accounts. Similarly, users in each account can continue to view their past and current usage from the Usage page regardless of whether they have enterprise access.\n\nYou can view usage from the Usage page in the console, from the CLI, or from the Enterprise Usage Reports API. For more information, see [Viewing usage in an enterprise](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Invoicing and payments \n\nUsage in the enterprise is invoiced through the enterprise account. As with all billable accounts, usage is invoiced monthly, and the invoice is due on the billing date for your account. During each billing cycle, a single invoice with the usage costs from all accounts is made available in the enterprise account. The invoice contains costs for all platform and infrastructure usage as a single-line item in your invoice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"},{"document_id":"ibmcld_01705-10258-12247","score":14.499835968,"text":"\nSupport subscription credit is separate from any platform or service subscription credit in your account and can't be spent on resource usage. For more information, see [How subscription credit is spent](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptionssubscription-basics).\n\n\n\n\n\n Service bundle subscriptions \n\nService bundle subscriptions give you access and credit toward a set of services within a particular domain that are targeted for popular use cases. You can choose from service bundles that span AI, analytics, IBM Blockchain, Internet of Things (IoT), and cloud-native services. If your needs cross multiple domains, you can purchase multiple service bundle subscriptions.\n\nYou can add services bundles to any type of existing account, including Lite accounts. Service bundle subscriptions are subject to the [IBM Cloud Terms of Use](https:\/\/cloud.ibm.com\/docs\/overview\/terms-of-use?topic=overview-terms).\n\nService bundle subscriptions aren't available through the IBM Cloud console. To learn more and purchase a service bundle, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\nAfter you purchase a service bundle subscription, you'll receive an email with a subscription code that you apply to add the bundle to your account. For more information about how to apply subscription codes, see [Subscription credit](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptionssubscription-codes). When your service bundle expires or you use all of the credit, you can continue to use any of the services, with usage charged at the Pay-As-You Go rate.\n\n\n\n\n\n Expiring subscriptions \n\nWhen your subscription is about to expire, you are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After your subscription expires, your account is converted to a Pay-As-You-Go account, which means you pay only for billable services that you use with no contracts or commitments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_12544-8261-10509","score":14.040345192,"text":"\n* Better discounts on usage costs because subscriptions are larger\n* Fewer expiration dates to track and manage after existing subscriptions expire\n\n\n\nIn an enterprise, subscriptions are managed from the enterprise account the same way as for a stand-alone account. For more information about managing your platform and support subscriptions, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n Usage reporting \n\nEnterprises provide top-down usage reporting so that you can track the costs of resource usage from all accounts in the enterprise. Starting at the enterprise level, you can navigate within the enterprise structure to see the estimated usage costs within each account or account group. At the account level, enterprise users can view costs for each type of resource or service in the account.\n\nEnterprise administrators can provide granular access to users so that they can view usage only for certain account groups or accounts. For example, say that your enterprise has account groups for each department, and each department has account groups for each team.\n\n\n\n* You give your financial officer access to view the entire enterprise so that they can track and recover costs for each department.\n* You give each department lead access to view usage for everything in their department's account group.\n* You give each team lead access to view only the accounts in their team's account group.\n\n\n\nBecause access in the enterprise is separate from access in each account, enterprise users can't automatically manage resources within the child accounts. Similarly, users in each account can continue to view their past and current usage from the Usage page regardless of whether they have enterprise access.\n\nYou can view usage from the Usage page in the console, from the CLI, or from the Enterprise Usage Reports API. For more information, see [Viewing usage in an enterprise](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Invoicing and payments \n\nUsage in the enterprise is invoiced through the enterprise account. As with all billable accounts, usage is invoiced monthly, and the invoice is due on the billing date for your account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"},{"document_id":"ibmcld_05428-1447-3447","score":13.8974485397,"text":"\nActual costs can vary by geography. For the most up-to-date prices, see [Code Engine pricing](https:\/\/www.ibm.com\/cloud\/code-engine\/pricing).\n\n\n\n Application pricing \n\nWhen you deploy an application, charges apply for HTTP requests and for the CPU and memory resources that are consumed by running instances of the application. Incoming HTTP calls are billed by the number of HTTP calls that are received by your application. For example, if your app serves 100 calls, you are then billed for 100 HTTP calls. Internal HTTP traffic within a project between your workloads is excluded from the billable HTTP call total.\n\nFor example,\n\n\n\n* If you create a Code Engine app with 2 GB (gigabyte) memory and 1 virtual CPU, with a minimum and maximum instance scale of 1, after an hour, you are charged for 1 vCPU hour and 2 GB hours.\n* If you then set your maximum instance scale to 2 and your application receives enough requests to scale up to 2, then you are billed for the (number of instances) x (number of virtual CPUs) = 2 vCPU and 4 GB per hour.\n\n\n\nFor valid CPU and memory combinations, see [Supported memory and CPU combinations](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-mem-cpu-combo).\n\nNote that the time that it takes to pull your image or to build it from source code is included in the billable time.\n\n\n\n\n\n Job pricing \n\nWhen you run a job, charges apply for the CPU and memory resources that are consumed by the job when it runs. You are not charged for your job configuration.\n\nFor example,\n\n\n\n* If you create a job to process information from IBM Cloud Object Storage with one job instance and that runs for an hour and uses 4 GB of memory, you are billed for 1 CPU hour and 4 GB hours.\n* If you scale the same job to 4 instances and then it completes in 15 minutes, you are charged for 4 vCPU and 16 GB for .25 hours.\n\n\n\nFor valid CPU and memory combinations, see [Supported memory and CPU combinations](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-mem-cpu-combo).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-pricing"},{"document_id":"ibmcld_07578-1033424-1035350","score":13.5838184357,"text":"\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/icons\/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1033295-1035221","score":13.5838184357,"text":"\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/icons\/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12623-6811-8811","score":13.4292573929,"text":"\n* A single invoice for all usage within the enterprise, so understanding costs is easier\n* A single place to manage payment methods, so you can update once for all accounts\n\n\n\nLearn more in [Centrally manage billing and usage with enterprises](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise).\n\n\n\n\n\n Enterprise support \n\nThe level of support that is assigned to an IBM Cloud enterprise defaults to the highest support plan within the enterprise. All child accounts within the enterprise also default to the highest support plan. For more information about the support experience, see [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-planssupport_level_enterprise).\n\n\n\n\n\n Resource management \n\nResources and services within an enterprise function the same as in stand-alone accounts. Each account in an enterprise can contain resources in resource groups. Account groups can't contain resources. For more information, see [Managing resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage_resource).\n\nZoom\n\n![A diagram that shows that resources are contained in accounts in the enterprise.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d4595e5202a9a27767cf034e81b038cdf772e0d5\/secure-enterprise\/images\/enterprise-resources.svg)\n\nFigure 3. Resources in an enterprise\n\nAs with all accounts, resources are tied to the resource group and account in which they're created, so they can't be moved between accounts in the enterprise. However, the enterprise's flexible account structure means you can move resources within the enterprise by moving the accounts that contain them.\n\n\n\n\n\n Top-down usage reporting \n\nFrom the enterprise account, you can view resource usage from all accounts in the enterprise. Starting at the enterprise level, you see estimated usage costs that are broken down by account and account groups. You can navigate down within the enterprise structure to see the costs within each level.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise&interface=ui"},{"document_id":"ibmcld_03787-3261-5506","score":13.0635528564,"text":"\nFor support subscriptions that were bought before this date, credit is available on a month-to-month basis. When you buy or renew a support subscription, any existing active support subscriptions are converted to the term-based model for the remainder of their term.\n\nFor example, you might have a support subscription for $200 per month with three months remaining. When you buy a new support subscription, the existing subscription is converted to a new one with $600 of credit that can be used anytime within those three months.\n\n\n\n\n\n Viewing subscription usage \n\nYou can view the subscriptions in your account to track your credit spending. To access this information, you need an access policy with the Viewer role or higher on the Billing account management service. See [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles) for more information.\n\n\n\n Platform subscriptions \n\nTo view your platform and service subscription usage, in the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Subscriptions.\n\n\n\n* Click the tabs to view spending details and trends about your subscription usage, including any usage overages that your account incurred. For example, the credit burndown view displays how your credit balance changes over time, and the spending by month view displays your monthly spending from all subscriptions.\n* View all active and inactive subscriptions in your account in the tables. For multi-year subscriptions, each term is displayed separately. Active subscriptions are subscriptions that still have remaining credit to spend and time that's left in the subscription term. Upcoming subscriptions are subscriptions were added to the account but haven't yet reached their term period. A subscription is inactive if its term expires or all of its credit is spent.\n\n\n\nYou can use the spending and usage information on the Subscriptions page to evaluate whether your subscriptions suit your usage needs. For example, if you consistently have overages, you might increase your monthly spending commitment to save money on that usage. To buy new subscriptions or change future subscription amounts, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Support subscriptions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions"},{"document_id":"ibmcld_03363-1671-3630","score":12.8744688034,"text":"\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03765-7-1896","score":18.15102005,"text":"\nManaging payments \n\nDepending on your account type, you can easily manage your payment methods by using the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud\u00ae console or by going to [IBM\u00ae Billing](https:\/\/myibm.ibm.com\/billing\/).\n\nA valid credit card is required for all Pay-As-You-Go and Subscription accounts. Every month, the credit card is charged with the usage amount that is accumulated during that month. When updates to your payment details are approved, they are applied to your account within 24 hours. The contact that is specified in the billing address section receives an email confirming that the updates are applied.\n\nYou can contact IBM Cloud Support to get help with payment-related issues. From the console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/help.svg) > Support center, and then click Create a case to get in touch.\n\n\n\n Before you begin \n\nTo manage payments, you need to be assigned the operator role or higher on the billing account management service. See [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services) for more information.\n\n\n\n\n\n Managing payment methods for new US-based Pay-As-You-Go accounts with credit card billing \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, can you add multiple cards to the account, replace your default card with a saved one, or edit the details of a card. You manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nComplete the following steps to add a new payment method to the account:\n\n\n\n1. Click Add payment method.\n2. Enter the card details, and click Save. Updates to your card details are reflected immediately.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03776-6753-8705","score":17.4271450043,"text":"\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\nFor more information about how to manage your payments, see [Managing your payment method](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusageprereqs-payments).\n\n\n\n\n\n Tracking your usage \n\nTo view usage data for resources, you must be assigned the correct access. Access can be assigned at the account level or to individual resource groups and Cloud Foundry orgs.\n\n\n\n* To view usage for all resources in the account, you need an access policy with the Administrator role on the Billing account management service.\n* To view usage only for specific IBM Cloud Identity and Access Management (IAM) resources, you need the Viewer role or higher on the resource group.\n* To view usage for only specific Cloud Foundry services, the Billing manager role must be applied at the org level. Billing managers can see the details for only the organizations in which they are assigned the Billing manager role.\n\n\n\nYou can limit the access to view the usage for a specific resource group by assigning the viewer role or higher on all Identity and Access enabled services within that resource group.\n\n\n\n\n\n Managing your invoices \n\nIf you have a Pay-As-You-Go account that's billed in US dollars, you can view your invoice in the IBM Cloud console by going to Manage > Billing and usage, > and clicking Invoices.\n\nIf you own one of the following accounts, you can view your invoice on the [IBM Invoices](http:\/\/ibm.com\/invoices) website, which is linked from the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices) in the console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03765-5710-7263","score":16.8136558533,"text":"\nClick Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console \n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/) and log in with your IBMid and password. You are also required to enter the temporary passcode that's emailed to you.\n\nTo add a payment method, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your payment information, and click Register. A temporary passcode is emailed to you after the registration process is complete.\n\n\n\nAfter you register a payment method, when you click Manage payment method, you can view the Manage my wallet page to update or delete your payment methods by clicking the Edit icon ![Edit icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/edit-tagging.svg).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03776-7-2223","score":14.5534191132,"text":"\nVideo - How can I manage billing and usage in IBM Cloud? \n\nLearn about the IBM Cloud\u00ae billing options and tools that you can use to track your usage and manage invoicing and payments.\n\n\n\n* Video transcript\n\nIBM Cloud offers multiple billing options so you can tailor how you pay based on your resource usage and your organization's procurement practices. You get the most flexibility with a Pay-As-You-Go account. You pay only for the billable services that you use each month, with no long-term contracts or commitments. If you know you have a significant amount of usage, you can purchase a subscription to get a discount. With a subscription, you commit to a certain amount of usage over a period of time. The larger the subscription, the better the discount. You can choose to pay upfront or be billed monthly, quarterly, or annually.\n\nAs an account owner, you have full access to monitoring resource usage, viewing invoices, and managing payments in the console. However, if you want to delegate billing tasks to another user, you can assign a user an Identity and Access Management (IAM) policy with the Administrator role on the Billing account management service.\n\nWhen you're ready to start tracking your resource usage and managing your billing and payment preferences, go to the Billing and usage section of the IBM Cloud console. Monitoring resource usage can help you understand what's coming in your next bill. On the Usage page, you can view current and past usage, and drill down by resource type to view the plans and instances in your account.\n\nYou can also export usage reports and choose from a high-level summary overview or a service instance view. If you use tags to organize your resources such as by team or cost center, you can sort your instance report by the tags to identify the associated usage.\n\nSetting spending limits is another helpful way to keep an eye on usage in your account. You can set notifications for total account, runtime, container, and service spending. When you reach a percentage of the spending limit that you set, you are notified immediately by email.\n\nTo view your current balance, manage your payment method, or make a one-time payment, go to the Payments page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03765-1346-3055","score":14.4250993729,"text":"\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, can you add multiple cards to the account, replace your default card with a saved one, or edit the details of a card. You manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nComplete the following steps to add a new payment method to the account:\n\n\n\n1. Click Add payment method.\n2. Enter the card details, and click Save. Updates to your card details are reflected immediately.\n\n\n\nYou can\u2019t enter a PO Box as the billing address.\n\nWhen you add a new credit card, it becomes the default credit card. Recurring payments are charged to the default payment method.\n\nComplete the following steps to edit your active payment method:\n\n\n\n1. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Edit menu.\n2. To edit the billing address, click Edit and update the billing address.\n3. To edit the card details, click Edit and update the card number or expiration date.\n\n\n\nYou can only have one address that's associated with your payment methods. All credit cards in the account will be updated to the same address.\n\nComplete the following steps to set a new default payment method:\n\n\n\n1. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Set as default.\n2. Confirm that you want to make this payment method the default. The default payment method is charged for recurring payments\n\n\n\n\n\n\n\n Managing payment methods for all other accounts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03776-5228-7163","score":13.7760915756,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_07578-1045891-1047755","score":13.4732971191,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1045762-1047626","score":13.4732971191,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03704-4411-6289","score":13.4417848587,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n\n\n\n\n\n Can I delete my credit card? \n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_03704-3030-4892","score":13.2330303192,"text":"\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6508205186,"ndcg_cut_10":0.6508205186}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03771-7-2029","score":21.7228755951,"text":"\nViewing your invoices \n\nTo manage and view your invoices, visit the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console. If your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices.\n\nIn these situations, visit the [Invoices@IBM](http:\/\/ibm.com\/invoices) website to see your invoices.\n\n\n\n Before you begin \n\nTo view your invoices, you need to be assigned the operator role or higher on the billing account management service. For more information, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n\n\n\n\n\n Viewing invoices for new US-based Pay-As-You-Go accounts with credit card billing \n\nNew IBM Cloud Pay-As-You-Go accounts for US customers with credit card billing can now view all classic infrastructure and platform services on one invoice. In the IBM Cloud console, go to Manage > Billing and usage, and select Invoices.\n\nThe new invoice hierarchy highlights the most important details. By showcasing when the usage is measured, you can view each invoice\u2019s billing period in a clarified and comprehensive manner. The adjustments section on your invoice provides details about credits and adjustments from previous billing periods that might be included on an invoice from a different month.\n\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices):","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_16727-1068047-1069909","score":20.3612766266,"text":"\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03764-2220-3440","score":19.6329364777,"text":"\n[Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n\n\n\n\n\n Is paperless invoicing available? \n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n\n\n\n\n\n What are the adjustments that are shown on my invoice? \n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n\n\n\n\n\n How do I know if my invoice is paid? \n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-invoice-faq"},{"document_id":"ibmcld_03771-1594-3365","score":18.8262748718,"text":"\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices):\n\n\n\n* Invoiced: You received the latest invoice from IBM Cloud.\n* Paid: Your payment for the charges on your latest invoice was received.\n* Unpaid: The charges on your latest invoice have not been paid.\n* Pending: Your payment for your latest charges has not been applied due to a payment processing error. In this case, you can contact IBM Cloud Support for more details about the error.\n\n\n\nTurning a resource \"off\" doesn't cancel the resource in your account. You will receive invoices for resources in your account until you cancel them. For more information, see [Cancelling your billing items](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cancel-billing-items).\n\n\n\n\n\n Viewing and downloading your invoice \n\nView and download your invoice from the IBM console by clicking the Download icon ![Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/download.svg)> PDF invoice next to each invoice. For some accounts, invoices are available through the [Invoices@IBM](http:\/\/ibm.com\/invoices) website. See the [Viewing and downloading invoices for all other accounts](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_16727-880740-882515","score":18.2388572693,"text":"\n* How do I view my invoices?\n\nTo view your account invoices, follow these steps.\n\n\n\n1. Go to the [IBM Cloud console ![External link icon](https:\/\/cloud.ibm.com\/icons\/launch-glyph.svg)](https:\/\/%7BDomainName%7D),\n2. Then, click Manage > Billing and Usage.\n\n\n\nEach account receives a single bill. If you need separate billing for different sets of resources, then you need to create multiple accounts.\n\nFor more information about invoices, see [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices).\n* How does Block Storage for VPC prevent a single point of failure? What mechanism assures data durability?\n\n How does Block Storage for VPC prevent a single point of failure? What mechanism assures data durability? \n\nBlock Storage for VPC volume data is stored redundantly across multiple physical disks in an Availability Zone to prevent data loss due to failure of any single component.\n* How are volumes created and attached to an instance?\n\n How are volumes created and attached to an instance? \n\nWhen you create a virtual server instance, you can [create a Block Storage for VPC volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storagecreate-from-vsi) that is attached to that instance. You can also [create stand-alone volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-880863-882638","score":18.2388572693,"text":"\n* How do I view my invoices?\n\nTo view your account invoices, follow these steps.\n\n\n\n1. Go to the [IBM Cloud console ![External link icon](https:\/\/cloud.ibm.com\/icons\/launch-glyph.svg)](https:\/\/%7BDomainName%7D),\n2. Then, click Manage > Billing and Usage.\n\n\n\nEach account receives a single bill. If you need separate billing for different sets of resources, then you need to create multiple accounts.\n\nFor more information about invoices, see [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices).\n* How does Block Storage for VPC prevent a single point of failure? What mechanism assures data durability?\n\n How does Block Storage for VPC prevent a single point of failure? What mechanism assures data durability? \n\nBlock Storage for VPC volume data is stored redundantly across multiple physical disks in an Availability Zone to prevent data loss due to failure of any single component.\n* How are volumes created and attached to an instance?\n\n How are volumes created and attached to an instance? \n\nWhen you create a virtual server instance, you can [create a Block Storage for VPC volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storagecreate-from-vsi) that is attached to that instance. You can also [create stand-alone volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03795-7-1690","score":17.1500434875,"text":"\nWhy can't I view the invoices for my Pay-As-You-Go or Subscription account in the console? \n\nInvoices that are managed outside of the console can not be viewed by going to Manage > Billing and Usage > Invoices in the IBM Cloud console.\n\n What\u2019s happening \n\nAs a Pay-As-You-Go or Subscription account owner, you might not be able to view your invoices from the Invoices page in the IBM Cloud console.\n\nWhen you try to view your invoices, one of the following messages is displayed:\n\nYour invoices are managed through IBM.com.\n\nThis account is invoiced on a separate billing platform.\n\n Why it\u2019s happening \n\nIf you have a Pay-As-You-Go account that is billed in a currency other than US dollars or a Subscription account, you view your invoices on the [IBM Invoices](https:\/\/www.ibm.com\/support\/customer\/invoices\/) website, which is linked from the Invoices page in the console.\n\n How to fix it \n\nIf you're visiting the Invoices website for the first time, sign up with your IBMid and complete your profile. Then, add access to your account with your IBM customer number.\n\n\n\n1. Go to [IBM Invoices](https:\/\/www.ibm.com\/support\/customer\/invoices\/), and select your region.\n2. Log in with the same IBMid and password that you use to log in to IBM Cloud.\n3. Complete your profile on the Invoices website.\n4. From the Invoices website, go to the Accesses tab. Add access to your account and provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option or contact the [eCustomer Care team](https:\/\/www-112.ibm.com\/software\/howtobuy\/passportadvantage\/paocustomer\/docs\/en_US\/ecare.html) for help.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice"},{"document_id":"ibmcld_10906-37947-39727","score":16.9610347748,"text":"\n<br><br> * Viewing cloud status<br><br><br> The IBM Cloud Status page is the central place to find details about all incidents, planned maintenance, announcements, release notes, and security bulletins about key events that affect the IBM Cloud platform and services. Learn more about [viewing cloud status](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-viewing-cloud-status). \n <br><br> * Review available support plans<br><br><br> You can choose a Basic, Advanced, or Premium support plan to customize your IBM Cloud support experience for your business needs. The level of support that you select determines the severity that you can assign to support cases and your level of access to the tools available in the Support Center. Learn more about [support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans). \n <br><br> * Create support cases<br><br><br> If you experience problems with IBM Cloud, you can use the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) to create a support case. You can also create support cases for issues that are associated with access (IAM), billing and usage, account issues, and invoice or sales inquiries. Learn more about [creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui). In the event you\u2019re unable to access your account, please create a case [here](https:\/\/watson.service-now.com\/x_ibmwc_open_case_app.do!\/create). \n <br><br> * Check out the solution tutorials<br><br><br> Solution tutorials provide step-by-step instructions on how to use IBM Cloud Log Analysis to manage operating system logs, application logs, and platform logs in the IBM Cloud to implement common patterns based on best practices and proven technologies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklist"},{"document_id":"ibmcld_07578-1065299-1067188","score":16.6868972778,"text":"\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_07578-1064084-1065746","score":16.5580062866,"text":"\nFor more information, see [Managing migrated SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How can I download my invoice?\n\nTo download your invoice, go to Manage > Billing and usage, and select Invoices. Then, click the Download icon ![Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet. In some cases, you are redirected to the [IBM Invoices website](https:\/\/www.ibm.com\/invoices) where you can download your invoices. From the Invoices page, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n* Is paperless invoicing available?\n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.5585075863,"ndcg_cut_10":0.5585075863}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03710-0-838","score":29.7855682373,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code? \n\nTo successfully apply a subscription code, make sure the code is valid and you have the required access.\n\n  What\u2019s happening \n\nWhen you try to apply a subscription code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error if you don't have the required access in the account or the code expired.\n\n  How to fix it \n\nUse the following options:\n\n\n\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-subscription-code"},{"document_id":"ibmcld_12597-0-804","score":26.055223465,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code to my account in an enterprise? \n\nA subscription code can't be added to the account because of specific access that is required.\n\n  What\u2019s happening \n\nYou can't add a subscription code to your IBM Cloud\u00ae account because you don't have the correct access.\n\n  Why it\u2019s happening \n\nBecause your account is a child account on the enterprise, you can't apply subscription codes. Subscription codes must be applied at the enterprise level.\n\n  How to fix it \n\nContact the owner or the administrator of the enterprise to add the subscription code. When the subscription code is added, it applies to all accounts in the enterprise. For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-troubleshoot-promo-enterprise"},{"document_id":"ibmcld_03786-7-2105","score":19.7435474396,"text":"\nApplying subscription codes \n\nAfter you buy a subscription for platform or support credit, you must add the credit to your account by applying a subscription code to an existing account or a new account when you register. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nIf you set up your first subscription through the [Subscriptions page](https:\/\/cloud.ibm.com\/billing\/subscriptions), the credit for this subscription is automatically added to your account - no code required.\n\nAfter IBM Cloud Sales places the order, an email with the subscription code for each subscription and support line item is sent to the appropriate contact.\n\nOnly the account owner, enterprise account owner, or a user with the Editor or Administrator role on the Billing account management service can apply the subscription code. If you don't have access to apply subscription codes, the account owner or administrator can provide access. For more information, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services). Applying the subscription code through the IBM Cloud\u00ae console is essential to ensure that your account is migrated appropriately.\n\n\n\n1. Open the email with the subscription code.\n\nIf you bought a subscription and didn't receive your subscription code, [contact us](https:\/\/www.ibm.com\/cloud?contactmodule) or email Sales at [CloudDigitalSales@us.ibm.com](mailto:CloudDigitalSales@us.ibm.com) to request for it to be sent again.\n2. Click Add subscription to add it to an existing account.\n3. Sign in to the console with your IBMid and password.\n4. From the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_03785-7-2010","score":19.2260303497,"text":"\nFAQs for subscription accounts \n\nFAQs for subscription accounts include entries about subscription credit, subscription terms, and other subscription-related self-help information.\n\n\n\n How do I add subscription credit to my account? \n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\n\n\n\n\n What does the IN_PROGRESS status mean when I apply a subscription code? \n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n\n\n\n\n\n Can I pay the total spending commitment up-front or quarterly? \n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Can I spend more or less than my monthly commitment? \n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n\n\n\n\n\n What happens if I spend my entire subscription amount before my term ends? \n\nYou're required to continue paying your monthly charges until the end of your term.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription-account"},{"document_id":"ibmcld_03704-10459-12479","score":18.7786006927,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n How do I apply a feature code? \n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Why did my account get billed for additional services charges? \n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_16727-1051761-1053771","score":18.4367752075,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1051890-1053900","score":18.4367752075,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03732-0-1673","score":18.389793396,"text":"\n\n\n\n\n\n\n  Applying feature codes \n\nYou can apply feature codes to take advantage of extra IBM Cloud\u00ae resources or capabilities. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.\n\nAre you looking for details about adding subscription credit to your account? See [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions) for more information.\n\nYou must have the Editor role or higher for all account management services to apply a feature code. The extra resources or capabilities that are provided vary depending on the particular code but include one or more of the following items in general:\n\n\n\n*  Increase the memory quota to a number of GB that is specified by the code\n*  Add one organization with a memory quota that is specified by the code\n*  Add an unlimited number of organizations\n*  Upload an extra number of SSL certificates, as specified by the code\n*  Use premium service plans\n*  Convert a Lite account to a trial account, which provides access to more services but only within a limited trial period\n\n\n\nComplete the following steps to apply a feature code to your existing account:\n\nIf you don't have an account yet, you can add your feature code when you [register](https:\/\/cloud.ibm.com\/registration) for a new account by clicking Register with a code instead of entering your credit card information.\n\n\n\n1.  In the IBM Cloud console, go to Manage > Account, and select Account settings.\n2.  Click Apply code.\n3.  Enter the feature code, which is typically a random alphanumeric value such as a1b2c3def456.\n4.  Click Apply.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-codes"},{"document_id":"ibmcld_03786-1684-3421","score":18.3883895874,"text":"\nFrom the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date. Ensure that you add the code to the correct account because the subscription credits can't be removed after the code is applied. After you add the subscription code, you might see that the status of the subscription as IN_PROCESS. Contact IBM Cloud Sales to review the account.\n3. Enter the subscription code, and click Apply.\n\nIf you have separate codes for platform and support credit, apply the platform subscription code first, then apply the support subscription code.\n\n\n\nTo manually apply the subscription code to a new account, complete the following steps:\n\n\n\n1. Go [create an IBM Cloud account](https:\/\/cloud.ibm.com\/registration), and enter the required information.\n2. Click Register with a code instead of entering your credit card information.\n3. Click Create account.\n\n\n\nIf you don't know your seller, the codes are applied in the wrong order, or you experience issues with applying the codes, [contact IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\nFor information about other codes and credits that can be applied to different account types, see [Applying feature codes to a Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) or [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_07578-1066746-1068772","score":18.3384075165,"text":"\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?\n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n* What happens if I spend my entire subscription amount before my term ends?\n\nYou're required to continue paying your monthly charges until the end of your term. You're charged the non-discounted rate for any usage that goes over your total subscription amount. To avoid overage charges, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to sign up for a new subscription.\n* Is there a monthly minimum amount required for Subscription accounts?\n\nYes, your subscription must have a combined minimum spending and term commitment of $100.00 USD each month for 12 months.\n* Can I cancel my Subscription account before the end of my term commitment?\n\nA subscription is a contract between you and IBM that commits you to use IBM Cloud for a specific term and spending amount. You can request to cancel your subscription before the end of the term, but whether the subscription can be canceled is at the discretion of IBM. Any remaining credit on your subscription might be forfeited. For more information, contact [Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). Make sure that you provide details about why you need to cancel your subscription.\n\nTo close a Pay-As-You-Go account or a Lite account, see [Can I cancel my account?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>10","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03709-0-1479","score":24.818780899,"text":"\n\n\n\n\n\n\n  Why can't I apply a feature code? \n\nTo successfully apply a feature code, make sure the code is valid and that you have the correct account type.\n\n  What\u2019s happening \n\nWhen you try to apply a feature code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error for any of the following reasons:\n\n\n\n*  Your account doesn't meet the requirements for the feature code.\n*  You don't have the required access in the account.\n*  The code expired.\n\n\n\n  How to fix it \n\nUse the following steps to successfully apply a feature code:\n\n\n\n*  Verify that you have the correct account type. For example, some feature codes for educational promotions are only for Lite accounts. To view your account type, in the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n*  If you are unable to apply a feature code that you received from an educational provider, contact that educational provider for further assistance.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-feature-code"},{"document_id":"ibmcld_03711-0-822","score":22.1382064819,"text":"\n\n\n\n\n\n\n  Why can\u2019t I create a service after I apply a feature code? \n\nYou can recover from issues with creating service after a feature code is applied by following a few easy steps.\n\n  What\u2019s happening \n\nWhen you try to create an instance of a service from the catalog, you're prompted to upgrade with a message such as Upgrade your account to create instances of the offering.\n\n  Why it\u2019s happening \n\nYour account wasn't enabled to create resources of that type after you applied the feature code. The resources or capabilities that are provided vary for each feature code.\n\n  How to fix it \n\nContact the person who gave you the feature code to verify the capabilities that it can enable for your account. For example, contact your educational provider for feature codes that they gave you for use with coursework.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cant-create-service-feature-code"},{"document_id":"ibmcld_03732-0-1673","score":19.3334732056,"text":"\n\n\n\n\n\n\n  Applying feature codes \n\nYou can apply feature codes to take advantage of extra IBM Cloud\u00ae resources or capabilities. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.\n\nAre you looking for details about adding subscription credit to your account? See [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions) for more information.\n\nYou must have the Editor role or higher for all account management services to apply a feature code. The extra resources or capabilities that are provided vary depending on the particular code but include one or more of the following items in general:\n\n\n\n*  Increase the memory quota to a number of GB that is specified by the code\n*  Add one organization with a memory quota that is specified by the code\n*  Add an unlimited number of organizations\n*  Upload an extra number of SSL certificates, as specified by the code\n*  Use premium service plans\n*  Convert a Lite account to a trial account, which provides access to more services but only within a limited trial period\n\n\n\nComplete the following steps to apply a feature code to your existing account:\n\nIf you don't have an account yet, you can add your feature code when you [register](https:\/\/cloud.ibm.com\/registration) for a new account by clicking Register with a code instead of entering your credit card information.\n\n\n\n1.  In the IBM Cloud console, go to Manage > Account, and select Account settings.\n2.  Click Apply code.\n3.  Enter the feature code, which is typically a random alphanumeric value such as a1b2c3def456.\n4.  Click Apply.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-codes"},{"document_id":"ibmcld_03710-0-838","score":18.1013393402,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code? \n\nTo successfully apply a subscription code, make sure the code is valid and you have the required access.\n\n  What\u2019s happening \n\nWhen you try to apply a subscription code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error if you don't have the required access in the account or the code expired.\n\n  How to fix it \n\nUse the following options:\n\n\n\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-subscription-code"},{"document_id":"ibmcld_12597-0-804","score":16.5067195892,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code to my account in an enterprise? \n\nA subscription code can't be added to the account because of specific access that is required.\n\n  What\u2019s happening \n\nYou can't add a subscription code to your IBM Cloud\u00ae account because you don't have the correct access.\n\n  Why it\u2019s happening \n\nBecause your account is a child account on the enterprise, you can't apply subscription codes. Subscription codes must be applied at the enterprise level.\n\n  How to fix it \n\nContact the owner or the administrator of the enterprise to add the subscription code. When the subscription code is added, it applies to all accounts in the enterprise. For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-troubleshoot-promo-enterprise"},{"document_id":"ibmcld_03704-8977-10890","score":15.3965101242,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n\n\n\n\n\n Why did I get invoiced when I have remaining promotion credits? \n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_16727-1050284-1052192","score":15.3473711014,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1050413-1052321","score":15.3473711014,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1048818-1050647","score":14.8482379913,"text":"\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1048947-1050776","score":14.8482379913,"text":"\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>11","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-1710-3705","score":18.7861633301,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7-2194","score":16.9894046783,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03776-6753-8705","score":16.2858066559,"text":"\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\nFor more information about how to manage your payments, see [Managing your payment method](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusageprereqs-payments).\n\n\n\n\n\n Tracking your usage \n\nTo view usage data for resources, you must be assigned the correct access. Access can be assigned at the account level or to individual resource groups and Cloud Foundry orgs.\n\n\n\n* To view usage for all resources in the account, you need an access policy with the Administrator role on the Billing account management service.\n* To view usage only for specific IBM Cloud Identity and Access Management (IAM) resources, you need the Viewer role or higher on the resource group.\n* To view usage for only specific Cloud Foundry services, the Billing manager role must be applied at the org level. Billing managers can see the details for only the organizations in which they are assigned the Billing manager role.\n\n\n\nYou can limit the access to view the usage for a specific resource group by assigning the viewer role or higher on all Identity and Access enabled services within that resource group.\n\n\n\n\n\n Managing your invoices \n\nIf you have a Pay-As-You-Go account that's billed in US dollars, you can view your invoice in the IBM Cloud console by going to Manage > Billing and usage, > and clicking Invoices.\n\nIf you own one of the following accounts, you can view your invoice on the [IBM Invoices](http:\/\/ibm.com\/invoices) website, which is linked from the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices) in the console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03704-3030-4892","score":15.7582550049,"text":"\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_03799-0-731","score":15.5021619797,"text":"\n\n\n\n\n\n\n  Why can't I update my billing address? \n\nYou can't update the billing address for a credit card in the IBM Cloud console. You must contact support to update the billing address on an existing credit card.\n\n  What\u2019s happening \n\nWhen you try update your payment details, you can't update the billing address for the credit card.\n\n  Why it\u2019s happening \n\nOn the [Payment methods page](https:\/\/cloud.ibm.com\/billing\/payments), you can't edit the billing address in the IBM Cloud Console.\n\n  How to fix it \n\nTo update the billing address for a credit card, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). Depending on your level of support, you can chat with a support agent or open a case.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-update-billing-address"},{"document_id":"ibmcld_07578-1071351-1073249","score":15.401014328,"text":"\nSome countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.\n\nBased on your account type, you might manage your credit card outside of the console. To manage your credit card outside of the console, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nIf your credit card requires a MasterCard SecureCode that is sent to a mobile phone, you might see an unexpected error message after you submit the code. Refresh the manage my wallet page to verify that your new credit card information is saved.\n* How do I upgrade my account?\n\nTo upgrade your Lite account, go to your [account settings](https:\/\/cloud.ibm.com\/account\/settings). In the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) for more information.\n* If I upgrade my Lite account, can I continue to use my existing instances?\n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01660-2990-4730","score":15.2170782089,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.\n\nBased on your account type, you might manage your credit card outside of the console. To manage your credit card outside of the console, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nIf your credit card requires a MasterCard SecureCode that is sent to a mobile phone, you might see an unexpected error message after you submit the code. Refresh the manage my wallet page to verify that your new credit card information is saved.\n\n\n\n\n\n How do I upgrade my account? \n\nTo upgrade your Lite account, go to your [account settings](https:\/\/cloud.ibm.com\/account\/settings). In the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) for more information.\n\n\n\n\n\n If I upgrade my Lite account, can I continue to use my existing instances? \n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_16727-1044299-1046149","score":14.6543502808,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1044428-1046278","score":14.6543502808,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03782-0-720","score":14.5904865265,"text":"\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-section-error"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.6366824387,"ndcg_cut_10":0.6366824387}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>12","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-3269-5168","score":30.1706161499,"text":"\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-1710-3705","score":28.5611820221,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7-2194","score":24.49426651,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-4689-6647","score":21.5706863403,"text":"\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03561-0-1129","score":18.5493850708,"text":"\n\n\n\n\n\n\n  Are you getting an error due to an invalid token when you make an API request? \n\nThe API request fails if the token that you use does not have permissions to work with the Activity Tracking service.\n\n  What\u2019s happening \n\nYour request fails with an error message that indicates that you are not authorized.\n\n  Why it\u2019s happening \n\nWhen you are not authorize to complete a task, you get an error in your response:\n\n{\"trace\":\"53b41915-749c-4af2-b61f-22194d3b56ea\",\"errors\":[     !   {\"code\":\"invalid_token\",\"message\":\"You are not authorize to complete this task. Check you have IAM permissions to work with Activity Tracking in the account.\",\"recovery\":\"After you check you have permissions, run 'ibmcloud login' to log in to IBM Cloud. Then, run ibmcloud iam oauth-tokens to retrieve your access tokens. Use the IAM token for the Authorization header in your request.\"}\n  How to fix it To resolve the problem, complete the following steps:<-- <ol> -->1.  Check you have IAM permissions to work with Activity Tracking in the account.2.  Get a valid access token. Learn more about retrieving IAM access tokens]]   !  !  !  !\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-troubleshoot-02"},{"document_id":"ibmcld_03713-6236-8279","score":17.2566757202,"text":"\nFor more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_07578-1069800-1071727","score":17.0666255951,"text":"\nThis credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?\n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https:\/\/watson.service-now.com\/x_ibmwc_open_case_app.do!\/create).\n* Why is a VAT ID required when I create an account?\n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03713-7896-8949","score":16.4723167419,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03794-0-812","score":15.8468732834,"text":"\n\n\n\n\n\n\n  Why am I getting a charge limit error when I try to make a payment? \n\nYou can't make a full payment on your invoice because of a charge limit.\n\n  What\u2019s happening \n\nYou try to make a payment on an invoice that is over $1,000.00 USD, but you get the following error message:\n\n> Manual payment request cannot be processed. Payment amount is higher than the limit allowed.\n\n  Why it\u2019s happening \n\nBy default, credit card payments in US Dollars cannot exceed $1,000.00 USD, which might cause you to make multiple payments to pay your invoice.\n\n  How to fix it \n\nYou can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) to request an increase in this maximum credit card payment limit. All requests are considered based on the payment and invoice history of the account.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-charge-limit"},{"document_id":"ibmcld_03782-0-720","score":15.8035764694,"text":"\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-section-error"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
