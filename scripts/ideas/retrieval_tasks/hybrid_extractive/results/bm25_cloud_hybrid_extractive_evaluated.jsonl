{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00512-1696-3972","score":14.933185195,"text":"\nDocuments with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database. All documents are assigned to a partition, and many documents are typically given the same partition key. A partition's primary JSON data and its indexes end up colocated, meaning that the database can query data within a partition more efficiently.\n\nA partitioned database offers both partitioned and global querying. Partitioned querying takes advantage of the data layout within the database cluster to deliver improved and more scalable query performance. Partition queries are also often cheaper than global queries.\n\nAs partitioned databases offer the advantages of both global and partition querying, IBM Cloudant recommends that new applications take advantage of them.\n\n\n\n\n\n What makes a good partition key? \n\nIf you're thinking of using IBM Cloudant's new partitioned database feature, then the choice of a partition key is important. A partition key must have:\n\n\n\n* Many values - lots of small partitions are better than a few large ones. A million partitions are perfectly fine, but keep each partition under 10 GB in total size.\n* No hot spots - avoid designing a system that makes one partition handle a high proportion of the workload. If the work is evenly distributed around the partitions, the database performs more smoothly.\n* Repeating - If each partition key is unique, one document per partition exists. To get the best out of partitioned databases, multiple documents per partition must exist - documents that logically belong together.\n\n\n\nLet's look at some use cases and some good and bad choices for a partition key.\n\n\n\nTable 1. Good and bad choices for a partition key\n\n Use Case Description Partition Key Effectiveness \n\n E-commerce system - orders One document per order order_id Neutral - one document per partition is fine, but it doesn't provide the benefits of Partition Queries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00513-7-2197","score":14.5093724629,"text":"\nDatabase overview \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases contain JSON objects. These JSON objects are called [documents](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documentsdocuments).\n\nAll documents must be contained in a database. For more information, see [partitioned databases](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databasespartitioned-databases-database).\n\nThe [Grouping related documents together in IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudantgrouping-related-documents-together-in-ibm-cloudant) guide provides an example of how documents for an e-commerce application might be used within an IBM Cloudant database.\n\n\n\n Partitioned databases \n\nIBM Cloudant supports two types of databases:\n\n\n\n* Partitioned\n* Nonpartitioned\n\n\n\nA partitioned database offers significant query performance and cost advantages but requires you to specify a logical partitioning of your data. The partitioning is specified as part of each document's ID. A partitioned database provides both global and partition queries. Partition queries target queries at a single, given document partition, meaning they need to process less data to return results. Therefore, partition queries offer significant performance advantages, and also often provide cost advantages over global queries. Global queries target the entire database, which leads to extra complexity, slower performance, and increased cost, but offers results that draw from all data.\n\nAlternatively, a nonpartitioned database might be created. This type of database can be less complex to work with since no partitioning scheme needs to be defined, but you can create only global secondary indexes.\n\nIBM Cloudant strongly encourages you to use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nThe partitioning type of a database is set at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-databases"},{"document_id":"ibmcld_00512-7-2158","score":13.7881566451,"text":"\nDatabase partitioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae supports two types of databases:\n\n\n\n* Partitioned\n* Non-partitioned\n\n\n\nA partitioned database offers significant performance and cost advantages but requires you to specify a logical partitioning of your data. This process is described more in the following text.\n\nAlternatively, you can create a non-partitioned database. This type of database might be easier to work with as no partitioning scheme needs to be defined, but only global secondary indexes can be created.\n\nIBM Cloudant strongly recommends that you use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nYou can decide whether to partition at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.\n\nThe partitioning type can't be changed for an existing database.\n\n\n\n Database shards \n\nBefore you read this document, you must understand the [sharding concept](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-is-data-stored-in-ibm-cloudant-how-is-data-stored-in-ibm-cloudant-) within IBM Cloudant.\n\n\n\n\n\n Non-partitioned databases \n\nA non-partitioned database is the older type of IBM Cloudant database, and the one that is familiar if you used CouchDB or IBM Cloudant previously.\n\nWithin a non-partitioned database, documents are distributed to shards in an arbitrary manner based on a transformation of their document ID. Therefore, no real relation exists between a document's ID and the shard it ends up on. Documents with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_09521-7-2114","score":12.1730631162,"text":"\nLimitations & Exclusions \n\nMaximo Application Suite SaaS is implemented using a defined set of technologies and operates within a security profile designed to ensure our client's data is secure and the applications operate efficiently and effectively. As a result of the decisions made regarding technologies and to meet the high security standards, there are differences between what is available using the Managed Services and what a client could do if they hosted and operated the Suite themselves.\n\nThe following items are not included or allowed in the Maximo Application Suite SaaS offering:\n\n\n\n Databases \n\nThe following are database limitations of the MAS-SaaS offering:\n\n\n\n* Only IBM DB2 Warehouse is supported. Oracle and SQLServer are not supported. Conversion services are available.\n* If converting from Oracle to DB2, Oracle compatibility mode is not supported.\n* Customers are not allowed direct access to MAS-SaaS database(s). If direct database access is needed, customer should look into the [MAS-Dedicated](https:\/\/cloud.ibm.com\/docs\/mas-ms) offering.\n* DB2 Text Search is not supported.\n* Running SQL statements (update\/insert\/delete) directly on the database is not allowed and IBM SRE team will not be able to execute those statements for you. DBC scripts are not allowed. Customers should carry out these changes using the Maximo UI via [Automation Scripts](https:\/\/ibm-maximo-dev.github.io\/maximo-autoscript-documentation\/introduction\/whatisautoscript) or the [Maximo Integration Framework](https:\/\/www.ibm.com\/docs\/en\/maximo-ora-con\/8.1.0?topic=architecture-maximo-integration-framework-overview).\n\n\n\n\n\n\n\n Java Extensions \n\nJava extensions are not supported. Maximo Manage [Automation Scripting](https:\/\/ibm-maximo-dev.github.io\/maximo-autoscript-documentation\/introduction\/whatisautoscript) capability should instead be used. Existing Maximo customers who have Java extensions will need to migrate \/ convert these functions into automation scripts within the application.\n\n\n\n\n\n 3rd Party Applications \n\nMaximo Application Suite SaaS will not host or support 3rd party applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-limitations-exclusions"},{"document_id":"ibmcld_00576-7385-9302","score":12.1279889277,"text":"\nIBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether. Otherwise, separate databases, for example, users, orders, products, might be better so that secondary indexes are specific to each object type.\n\nIf you're storing arrays of objects within a document, consider whether the array items must really be their own document. For example, a product and each product review must be stored in separate documents, but a user and each of that user's orders must have their own document.\n\nIf you have an ever-growing data set, then you probably don't want to store data in a single, ever-growing database. Data is best stored in time-boxed databases that allow older data to be archived and deleted cleanly. Deleting an IBM Cloudant document leaves a tombstone document behind, so don't rely on deleting documents to recover disk space. Instead, you must rely on deleting whole databases.\n\nJSON doesn't offer a native way to store dates or timestamps. Choose your [date format](https:\/\/blog.cloudant.com\/2018\/05\/24\/Date-formats.html) carefully if you intend to query it later.\n\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00612-7-2163","score":12.1058526073,"text":"\nMigration overview \n\nThe [IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae](https:\/\/www.ibm.com\/cloud\/cloudant) database-as-a-service offering is a JSON document store that runs on multi-tenant clusters. The service is available with a choice of geographical locations with predictable costs, scalability, and a service-level agreement (SLA).\n\nYou can migrate to an IBM Cloudant Lite or Standard plan instance on IBM Cloud from one of the following plans:\n\n\n\nTable 1. IBM Cloudant migration paths\n\n Plan Description \n\n IBM Cloudant Enterprise Dedicated, single-tenant clusters \n Apache CouchDB The self-hosted, open source database on which IBM Cloudant is based. \n\n\n\n\n\n Benefits of the IBM Cloudant Lite and Standard plans \n\nWith the Standard plan, you can reserve throughput capacity for your database service, that is, to specify how much throughput your application's database is going to need to handle demand. The Standard plan also charges for the amount of storage you use. Capacity is measured with the following metrics:\n\n\n\nTable 2. Capacity metrics\n\n Metric Description \n\n Reads per second The rate when simple document fetches are performed, for example, retrieving a document by its _id, or querying against a partitioned database that uses a partition key. \n Writes per second The rate when data is written to the database. API calls dealing with document creation, update, or deletion count as \"writes\". \n Global Queries per second The rate when the database is queried by global indices, typically by accessing the _find endpoint, secondary MapReduce, or search indices. \n Storage The amount of disk space occupied by your JSON data, attachments, and secondary indices. \n\n\n\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"},{"document_id":"ibmcld_00580-20968-23077","score":12.0464433378,"text":"\nTo open an IBM Cloudant service's Dashboard, log in to IBM Cloud, find your IBM Cloudant service, and click Launch IBM Cloudant Dashboard button. A new window opens, logging you into your IBM Cloudant Dashboard.\n\nIf you leave the dashboard window unattended for a length of time, you find yourself logged out (for security purposes) and must click Launch again.\n\nThe dashboard has a number of tabs. Its default tab, Databases, lists the databases that you created in groups of 20. Each database is shown with the number of documents that it is storing and how much disk space is being used. Click a database name to examine its contents.\n\nTo create a database, click Create Database and supply the name of the database to create.\n\nWe now have a new empty database. The database's documents would be listed here in ID order. However, since this database is new, no documents exist. To add a document, click Create Document.\n\nThe IBM Cloudant Dashboard created a template document for you with a pre-generated _id. Complete the rest of the attributes yourself to complete the JSON document, and click Create Document to save.\n\nNow it's time for another practical exercise. Create a database called books, and in that database, create three or more documents with fields: title, author, date, publisher, and ISBN - each representing a book of your choice.\n\nOnce created, edit one of the documents, modifying the publication date.\n\nThen, delete one of the documents.\n\nTo summarize, the IBM Cloudant Dashboard is a web app that is built into the IBM Cloudant service and is part of the CouchDB open source offering. It is used to manage databases, documents, indexes, queries, and replication jobs. It can also be used to monitor service throughput. The Dashboard is simply an API client - anything that can be achieved with the dashboard can be scripted by you using the HTTP API.\n\nThat's the end of this part. The next part is called HTTP API Basics.\n\n\n\n\n\n\n\n HTTP API Basics video \n\nLearn how to use the command line to make HTTP requests and to add, edit, and delete documents.\n\n\n\n* HTTP API Basics video script","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_11586-7-1910","score":11.97891987,"text":"\nFast Path of IBM Cloud for VMware \n\nThis page is a collection of shortcuts to the documentation sections for each offering, excluding general information that applies to all offerings, such as SAP Sizing.\n\nUse the links in this section to quickly access relevant documents that you are already familiar with.\n\n\n\n Learn \n\nAn Infrastructure-as-a-Service (IaaS) environment consists primarily of compute, storage, and network components from a specified region (such as the US) and a designated site location (also referred to as zone, which is a data center site). For more information:\n\n\n\n* [IBM Cloud Classic Infrastructure environment introduction](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-classic-env-introduction)\n\n\n\nCertified Infrastructure-as-a-Service for SAP HANA database server is available in many variations, each with different capabilities and sizes to fit many different SAP workload scenarios. For more information:\n\n\n\n* [Infrastructure certified for SAP - VMware Software-Defined Data Center](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-iaas-offeringsiaas-vmware)\n\n\n\nThe following is an overview of the SAP-certified profiles with IBM Cloud Bare Metal servers for SAP HANA and SAP NetWeaver. For more information:\n\n\n\n* [VMware SSDC certified profiles for SAP HANA](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-hana-iaas-offerings-profiles-vmware)\n* [VMware SDDC certified profiles for SAP NetWeaver](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-nw-iaas-offerings-profiles-vmware)\n* [Compute Profiles of SAP-certified VMware on Classic Infrastructure](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-compute-os-design-considerationscompute-vmware)\n\n\n\nYour business and functional requirements determine the SAP solutions powered by the SAP HANA Database Server or SAP NetWeaver Application Server, and therefore determine how your applications are run in the available infrastructure. For more information:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-fast-path-site-map-vmware-sddc"},{"document_id":"ibmcld_06633-1299-3259","score":11.866071644,"text":"\nYou can extend high-availability further by adding [PostgreSQL members](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-horizontal-scaling) to the instance, for greater in-region redundancy, or by provisioning [read-only replicas](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-read-only-replicas) for cross-regional failover or read offloading.\n\nDatabases for PostgreSQL is designed and built to provide a robust, resilient, and performant Database as a Service offering. Review the PostgreSQL documentation on [replication techniques](https:\/\/www.postgresql.org\/docs\/current\/wal-async-commit.html) to understand the constraints and tradeoffs that are associated with the asynchronous replication strategy that is deployed by default with Databases for PostgreSQL.\n\nIn scenarios where a database becomes critically unhealthy, such as a server crash on the leader, Databases for PostgreSQL attempts a failover. This auto failover capability is capped at 16 MB of data lag from leader to follower (a few rows of data once accounting for more PostgreSQL data overhead) and is not performed if the lag threshold is exceeded. If the potential for 16 MB of data loss is intolerable for the application, horizontally scale your Databases for PostgreSQL instance to three members and configure Databases for PostgreSQL to use a synchronous replication strategy on a per user or per database basis.\n\n\n\n Synchronous replication \n\nBy default, streaming replication is asynchronous. If the primary server crashes, some transactions that were committed might not have been replicated to the standby server, causing data loss. Cloud Databases ensures that data loss is kept to a minimum substantial data loss; however, synchronous replication offers the ability to confirm that all changes were made by a transaction have been transferred to a synchronous member, ensuring consistency across a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-high-availability"},{"document_id":"ibmcld_09500-7-2159","score":11.8562202227,"text":"\nLimitations & Exclusions \n\nMaximo Application Suite Dedicated is implemented using a defined set of technologies and operates within a security profile designed to ensure our client's data is secure and the applications operate efficiently and effectively. As a result of the decisions made regarding technologies and to meet the high security standards, there are differences between what is available using the Dedicated Services and what a client could do if they hosted and operated the Suite themselves.\n\nThe following items are not included or allowed in the Maximo Application Suite Dedicated offering:\n\n\n\n Databases \n\nThe following are database limitations of the MAS-Dedicated offering:\n\n\n\n* Only DB2 is supported. Oracle and SQLServer are not supported. Conversion services are available.\n* If converting from Oracle to DB2, Oracle compatibility mode is not supported.\n* DB2 Text Search is not supported.\n* Running SQL statements (update\/insert\/delete) directly on databases is not allowed and IBM SRE team will not be able to execute those statements for you. DBC scripts are not allowed. Customers must carry out these changes using the UI via different means for example using Automation scripts or MIF. For further details on use of automation scripts, please see document below:\n\n\n\n[https:\/\/ibm-maximo-dev.github.io\/maximo-autoscript-documentation\/introduction\/whatisautoscript](https:\/\/ibm-maximo-dev.github.io\/maximo-autoscript-documentation\/introduction\/whatisautoscript)\n\n\n\n* SQL Scripts can be run on Production databases on an exception-only basis. Please see [Running SQL Scripts in Production](https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-supportrunning-sql-scripts) for details.\n\n\n\n\n\n\n\n Manage Application \n\nNo Java extensions are supported. It is assumed the Manage auomation scripting capability will be used for these types of extensions. Existing Maximo customers who have Java extensions will need to move these functions into automation scripts within the application. See link above for further details\n\n\n\n\n\n LA Fixes \n\nLA (Limited Availability) aka \"one off\" or \"hot\" fixes are the customer's responsibility to manage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-limitations-exclusions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07046-11817-13746","score":16.841797888,"text":"\nHowever, a different document ID was assigned to it and stored in the parent_document_id field. The assigned document ID is what was returned when you called the List documents method and is what had to be used as the document_id in the endpoint URL for a Delete document method request. When you used the Update document method to assign a new document_id, the original ID continued to be returned in query results. However, the assigned ID had to be used to delete the document. If you have an application that relies on the previous behavior, you can specify a version number earlier than 2023-03-31, such as 2020-08-30, in your API calls.\n\n\n\nNotes about enhancing data:\n\n\n\n* You cannot apply prebuilt or user-trained Smart Document Understanding models to JSON files.\n* When you apply an enrichment to a field from the JSON file, the field data type is converted to an array. The field is converted to an array even if it contains a single value. For example, \"field1\": \"Discovery\" becomes \"field1\": [\"Discovery\"].\n* Only the first 50,000 characters of a custom field from a JSON file are enriched.\n* In project types where the Part of Speech (POS) enrichment is applied automatically, the enrichment is applied to the field that contains the bulk of the file content in the first JSON file that is added to the collection. This field is determined by the following rules:\n\n\n\n* If a field is named text, the POS enrichment is applied to it.\n* The field with the longest string value and highest number of distinct values is chosen.\n* If more than one field meets the previous condition, one of the fields is chosen at random.\n\n\n\n* If you want to apply an enrichment to a nested field, you must create a Content Mining project, and then apply the enrichment to the field. If you want to use a project type other than Content Mining, you can reuse the collection that you created with the Content Mining project type elsewhere.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-index-overview"},{"document_id":"ibmcld_07163-5129-7116","score":16.5445680038,"text":"\nWe recommend that you apply both available ratings to your results: Relevant and Not relevant. Only rating the Relevant documents does not provide the data needed. If you plan to score your documents, using both the Discovery tooling and the API, or if you plan to begin with the API and move to the tooling, use the 0 and 10 relevancy scores.\n* A random sample of documents that are not explicitly given a relevance rating is assigned a relevance score of 0. It is not mandatory to apply a relevance score of 0 when you train your documents, but if you apply a relevance score of 0 to certain documents, relevancy training marks those documents as non-relevant examples, instead of treating them as a random sample of results from the query.\n* The training queries must include some term overlap between the query and the desired answer so it can be retrieved by the Discovery service's initial search, which is broad in scope.\n\n\n\nWatson uses training data to learn patterns and to generalize, not to memorize individual training queries. The service, therefore, might not always reproduce identical relevance results for any given training query.\n\nTraining cannot exceed the following maximum requirements:\n\n\n\n* You cannot exceed 40 trained collections per environment.\n* Within a single collection, you are limited to 10,000 training queries, with a maximum of 100 examples per query.\n\n\n\n\n\n\n\n Adding a query to the training-data set \n\nUse the POST \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data method to add a query to a collection's set of training data. The query is specified as a JSON object in the following format:\n\n{\n\"query_id\": \"string\",\n\"natural_language_query\": \"string\",\n\"filter\": \"string\",\n\"examples\": [\n{\n\"document_id\": \"string\",\n\"cross_reference\": \"string\",\n\"relevance\": 0\n}\n]\n}\n\nThe values in this object are as follows:\n\n\n\n* query_id: A unique ID for the query. If you do not specify this field, the service automatically generates an ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"},{"document_id":"ibmcld_07019-8403-10537","score":15.7390036176,"text":"\nOn the Improvement tools panel, expand Teach domain concepts, and then choose the resource that you want to add.\n\nAfter you create the resource, it becomes a new type of enrichment that you can apply to your data.\n3. Specify the collection and field in which to apply the enrichment.\n\nYou can apply enrichments to the text and html fields, and to custom fields that were added from uploaded JSON or CSV files or from the Smart Document Understanding (SDU) tool. Only the first 50,000 characters of a custom field from a JSON file are enriched.\n\nFor example, if you add a dictionary and choose to apply it to the text field of a collection, the documents in the collection are reprocessed. If the term vehicle is specified as a synonym of the car dictionary entry and occurs in the document text, vehicle is tagged as a mention of the car dictionary entry type. If a customer later searches for car, the passage that contains the vehicle mention is included in the search results.\n\nIf the field that you choose comes from a JSON file, after you apply the enrichment, the field data type is converted to an array. The field is converted to an array even if it contains a single value. For example, \"field1\": \"Discovery\" becomes \"field1\": [\"Discovery\"].\n\n\n\nYou can choose to apply resource-derived enrichments to your data later. Enrichments that you add to a project are available for use from any collection in the project. Go to the Manage collections page, choose the collection where you want to apply the enrichment, and then open the Enrichments tab. Make sure the status of the enrichment shows that it is Ready, and then apply the enrichment to a field in the collection. Enrichments that you enable are applied to the documents in random order. For more information, see [Managing enrichments](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-manage-enrichments).\n\nFrom the deployed Content Mining application, you can create a classifier or a custom annotator from a dictionary, regular expression, machine learning, or PEAR file and use it as an enrichment in collections that are stored in other project types.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domain"},{"document_id":"ibmcld_07046-13262-15106","score":15.1960062641,"text":"\n* The field with the longest string value and highest number of distinct values is chosen.\n* If more than one field meets the previous condition, one of the fields is chosen at random.\n\n\n\n* If you want to apply an enrichment to a nested field, you must create a Content Mining project, and then apply the enrichment to the field. If you want to use a project type other than Content Mining, you can reuse the collection that you created with the Content Mining project type elsewhere. For more information, see [Applying enrichments](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-database-cp4dconnector-database-cp4d-enrich-db).\n\n\n\nYou can specify the normalizations and conversions objects in the [Update a collection](https:\/\/cloud.ibm.com\/apidocs\/discovery-dataupdatecollection) method of the API to move or merge JSON fields.\n\n\n\n\n\n\n\n How passages are derived \n\nDiscovery uses sophisticated algorithms to determine the best passages of text from all of the documents that are returned by a query. Passages are returned per document by default. They are displayed as a section within each document query result and are ordered by passage relevance.\n\nDiscovery uses sentence boundary detection to pick a passage that includes a full sentence. It searches for passages that have an approximate length of 200 characters, then looks at chunks of content that are twice that length to find passages that contain full sentences. Sentence boundary detection works for all supported languages and uses language-specific logic.\n\nFor all project types except Conversational Search, you can change how the passages are displayed in the search results from the Customize display > Search results page. For example, you can configure the number of passages that are shown per document and the maximum character size per passage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-index-overview"},{"document_id":"ibmcld_00546-2347-3956","score":14.6167052099,"text":"\ndisk_size Size in bytes of the data as stored on the disk. Views indexes aren't included in the calculation. \n doc_count A count of the documents in the specified database. \n doc_del_count Number of deleted documents. \n instance_start_time Always 0. \n other JSON object that contains a data_size field. \n purge_seq The number of purge operations on the database. \n sizes A JSON object, containing file, external, and active sizes. active is the size in bytes of data that is stored internally (excluding old revisions). external is the size in bytes of decompressed user data. This value is the billable data size. The other\/data_size field is an alias for the external field. file is the size in bytes of data that is stored on the disk. Indexes aren't included in the calculation. The disk_size field is an alias for the file field. This size includes data that is waiting for compaction. \n update_seq An opaque string that describes the state of the database. Don't rely on this string for counting the number of updates. \n partitioned_indexes A JSON object that appears only if the database is partitioned. count is the number of partitioned indexes. indexes list the type of partitioned indexes, and limit shows the maximum number of allowed partitioned indexes. \n\n\n\nSee the following example (abbreviated) response that contains database details:\n\n{\n\"update_seq\": \"982...uUQ\",\n\"db_name\": \"db\",\n\"sizes\": {\n\"file\": 46114703224,\n\"external\": 193164408719,\n\"active\": 34961621142\n},\n\"purge_seq\": 0,\n\"other\": {\n\"data_size\": 193164408719\n},\n\"doc_del_count\": 5564,\n\"doc_count\": 9818541,\n\"disk_size\": 46114703224,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-database-details"},{"document_id":"ibmcld_00472-21040-23007","score":14.1830378687,"text":"\nhighlight_size Slice up field content into number of characters, so-called fragments, and highlights matches only inside the specified fragments. Yes, defaults to 100 characters Numeric Yes \n include_docs Include the full content of the documents in the response. Yes Boolean Yes \n include_fields A JSON array of field names to include in search results. Any fields that are included must be indexed with the store:true option. Yes, the default is all fields. Array of strings Yes \n limit Limit the number of the returned documents to the specified number. For a grouped search, this parameter limits the number of documents per group. Yes Numeric The limit value can be any positive integer number up to and including 200. Yes \n q Abbreviation for query. Runs a Lucene query. No String or Number Yes \n query Runs a Lucene query. No String or Number Yes \n ranges This field defines ranges for faceted, numeric search fields. The value is a JSON object where the fields names are faceted numeric search fields, and the values of the fields are JSON objects. The field names of the JSON objects are names for ranges. The values are strings that describe the range, for example \"[0 TO 10]\". Yes JSON The value must be an object with fields that have objects as their values. These objects must have strings with ranges as their field values. No \n sort Specifies the sort order of the results. In a grouped search (when group_field is used), this parameter specifies the sort order within a group. The default sort order is relevance. Yes JSON A JSON string of the form \"fieldname<type>\" or -fieldname<type> for descending order. The fieldname is the name of a String or Number field, and type is either a number, a string, or a JSON array of strings. The type part is optional, and defaults to number. Some examples are \"foo\", \"-foo\", \"bar<string>\", \"-foo<number>\", and [\"-foo<number>\",\"bar<string>\"]. String fields that are used for sorting must not be analyzed fields.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search"},{"document_id":"ibmcld_01091-1268-2866","score":14.1468507083,"text":"\nFor more information about choosing hash distribution keys, see [Choosing a hash distribution key for a table in an MPP database](https:\/\/www.ibm.com\/support\/knowledgecenter\/SS6NHC\/com.ibm.swg.im.dashdb.doc\/learn_how\/choosing_dist_key_mpp.html).\n\n\n\n\n\n Random distribution \n\nWith random distribution, data is distributed evenly across the system. Random distribution maximizes parallel processing of queries and maximizes the use of available storage space.\n\nConsider using random distribution as a simpler alternative to hash distribution, for the following reasons:\n\n\n\n1. If you don't have enough information to choose an effective hash distribution key,\n2. If you know that collocation isn't needed for the queries that are entered against the table, or\n3. If the table is small enough that performance is not affected by the distribution.\n\n\n\nYou can use random distribution by including the DISTRIBUTE BY RANDOM clause in the CREATE TABLE statement.\n\nIf you specify DISTRIBUTE BY RANDOM when creating a table with a primary or unique key, the database manager implements the random distribution by creating a hash key on the unique or primary key. In this case, when you view the table definition in the web console or the catalog tables, you'll see this hash distribution key despite the fact that you specified DISTRIBUTE BY RANDOM when you created the table.\n\nCREATE TABLE MYTABLE\n(\nCOL1 INT,\nCOL2 VARCHAR(5)\n)\nDISTRIBUTE BY RANDOM\n\n\n\n\n\n Default behavior \n\nIf you do not specify a distribution clause when creating a table in a multi-partitioned plan, a default hash distribution key is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-distribution_keys"},{"document_id":"ibmcld_03191-37711-39007","score":14.0859711834,"text":"\nSee the [java.lang.Math reference documentation](https:\/\/docs.oracle.com\/javase\/7\/docs\/api\/java\/lang\/Math.html) for information about other methods.\n\n\n\n\n\n java.util.Random() \n\nReturns a random number. You can use one of the following syntax options:\n\n\n\n* To return a random boolean value (true or false), use <?new Random().nextBoolean()?>.\n* To return a random double number between 0 (included) and 1 (excluded), use <?new Random().nextDouble()?>\n* To return a random integer between 0 (included) and a number you specify, use <?new Random().nextInt(n)?> where n is the top of the number range you want + 1. For example, if you want to return a random number between 0 and 10, specify <?new Random().nextInt(11)?>.\n* To return a random integer from the full Integer value range (-2147483648 to 2147483648), use <?new Random().nextInt()?>.\n\n\n\nFor example, you might create a dialog node that is triggered by the #random_number intent. The first response condition might look like this:\n\nCondition = @sys-number\n{\n\"context\": {\n\"answer\": \"<? new Random().nextInt(@sys-number.numeric_value + 1) ?>\"\n},\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"Here's a random number between 0 and @sys-number.literal: $answer.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methods"},{"document_id":"ibmcld_16307-10645-12182","score":14.0500315391,"text":"\nYou can use the the Class methods, including these:\n\n\n\n* max():\n\nT(Math).max(${step_297},${step_569})\n* min():\n\nT(Math).min(${step_297},${step_569})\n* pow():\n\nT(Math).pow(${step_297}.toDouble(),2.toDouble())\n\n\n\nSee the [java.lang.Math reference documentation](https:\/\/docs.oracle.com\/javase\/7\/docs\/api\/java\/lang\/Math.html) for information about other methods.\n\n\n\n\n\n java.util.Random() \n\nReturns a random number. You can use any of the following syntax options:\n\n\n\n* To return a random boolean value (true or false), use new Random().nextBoolean().\n* To return a random double number between 0 (included) and 1 (excluded), use new Random().nextDouble()\n* To return a random integer between 0 (included) and a number you specify, use new Random().nextInt(_n_), where n is 1 greater than the top of the number range you want. For example, if you want to return a random number between 0 and 10, specify new Random().nextInt(11).\n* To return a random integer from the full integer value range (-2147483648 to 2147483648), use new Random().nextInt().\n\n\n\nFor example, you might create step that is executed only for a randomly selected subset of customers. The following step condition would mean that the step has a 50% chance of executing:\n\nnew Random().nextInt(2) == 1\n\nSee the [java.util.Random reference documentation](https:\/\/docs.oracle.com\/javase\/7\/docs\/api\/java\/util\/Random.html) for information about other methods.\n\nYou can also use standard methods of the following classes:\n\n\n\n* java.lang.Byte\n* java.lang.Integer\n* java.lang.Long","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-expression-methods-actions"},{"document_id":"ibmcld_02877-35152-36525","score":14.0277069314,"text":"\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}\nShow more\n\nSee the [java.lang.Math reference documentation](https:\/\/docs.oracle.com\/javase\/7\/docs\/api\/java\/lang\/Math.html) for information about other methods.\n\n\n\n\n\n java.util.Random() \n\nReturns a random number. You can use one of the following syntax options:\n\n\n\n* To return a random boolean value (true or false), use <?new Random().nextBoolean()?>.\n* To return a random double number between 0 (included) and 1 (excluded), use <?new Random().nextDouble()?>\n* To return a random integer between 0 (included) and a number you specify, use <?new Random().nextInt(n)?> where n is the top of the number range you want + 1. For example, if you want to return a random number between 0 and 10, specify <?new Random().nextInt(11)?>.\n* To return a random integer from the full Integer value range (-2147483648 to 2147483648), use <?new Random().nextInt()?>.\n\n\n\nFor example, you might create a dialog node that is triggered by the #random_number intent. The first response condition might look like this:\n\nCondition = @sys-number\n{\n\"context\": {\n\"answer\": \"<? new Random().nextInt(@sys-number.numeric_value + 1) ?>\"\n},\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"Here's a random number between 0 and @sys-number.literal: $answer.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-methods"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06968-15099-17180","score":20.6536506766,"text":"\n[checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/icons\/checkmark-icon.svg) \n\n\n\n\n\n* PDF files that are secured with a password or certificate are not supported. Vector objects, including SVG images and vectorized text, are not supported. Only images of the supported image file types that occur in the PDF are rendered.\n* Only single-page image files are supported.\n* Files within compressed archive files (ZIP, GZIP, TAR) are extracted. Discovery ingests the supported file types within the archive; it ignores all other file types. The file names must be encoded in UTF-8. Files with names that include Japanese characters, for example, must be renamed before they are added to the ZIP file.\n* Discovery supports MacOS ZIP files only if they are generated by using a command such as: zip -r my-folder.zip my-folder -x \".DS_Store\". ZIP files that are created by right-clicking a folder and clicking Compress are not supported.\n* PDF files that you upload as part of an archive file are not displayed in the advanced view for a query result that you open from the Improve and customize page. If you want the file to be viewable from the advanced view, reimport the PDF file separately from the archive file.\n\n\n\nWhen you add files to a Document Retrieval for Contracts project type, any file types that support SDU and OCR are processed with a pretrained Smart Document Understanding model and Optical Character Recognition automatically.\n\n\n\n\n\n Document limits \n\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_07117-1664-3943","score":18.6354931564,"text":"\nIf you encounter this issue, open the file in a more recent version of Microsoft Office and convert the file to the DOCX, PPTX, or XLSX format respectively, and then upload the DOCX, PPTX, or XLSX file.\n\nLine breaks are inserted randomly\n: When some files in Microsoft Office format are added to a collection, line breaks are inserted seemingly at random to the text that is stored in the html field in the collection's index. The unexpected line breaks can impact the efficiency of enrichments, such as custom rule recognition.\n\nCause: As part of their ingestion into Discovery, such files are converted from Office format to PDF format. When the conversion happens, textual content is sometimes lost due to the nature of a PDF file. While the new lines appear to be added at random, they typically get inserted in areas where text wraps in the original document, such as in narrow text boxes or to accommodate other inline elements, such as images or diagrams.\n\nSolution: To avoid new line insertions, increase the width of text boxes in the original document. If the original document has a section where text wraps to accommodate an inline element, such as an image, move the image so that it is situated in its own section and the nearby text doesn't need to wrap around it. To test whether your fixes address the issue, you can convert the original file to a PDF file to check for unexpected carriage returns in the text.\n\nAfter applying a pretrained Smart Document Understanding model to a PPT file, table boundaries are not recognized properly\n: During the conversion process, text that is extracted from the table is confused with text that is outside the table in some PPT pages. This issue is more likely to occur in tables with a lot of text and that have footnotes displayed just outside the table border. If you encounter this issue, export the PPT file as a PDF file, and then upload the PDF file instead. Apply a user-trained Smart Document Understanding (SDU) model to the document, and then use the SDU tool to identify the tables in the document. The resulting model handles table boundaries properly and can extract text from the tables cleanly.\n\n\n\n\n\n PDF file troubleshooting tips \n\nFailed to parse document due to invalid encoding\n: Enable OCR for the file.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-troubleshoot-ingestion"},{"document_id":"ibmcld_16423-3286-5408","score":18.0344549347,"text":"\nUpload one CSV file at a time. The first column in the CSV file specifies the file name of the document. The second column in the file contains the document text. For an example of the required format, see the [documents-new.csv](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/documents-new.csv) file in the tutorial sample files.\n\n\n\n\n\n PDF files \n\nText cannot be extracted from a PDF in some cases, depending on how the PDF was created. Typically, text can't be extracted from embedded fonts that don't map to unicode characters. If you are unsure whether text from a PDF can be extracted, you can try copying the text from the PDF and then pasting it into a text editor. If you do not see the same characters that are visible in the PDF itself, then the text extraction would likely fail.\n\n\n\n\n\n Formatted documents \n\nWhen formatted documents are converted to plain text, it's possible that losing the formatting could result in poor tokenization of words. For example, if a table row in a DOCX file contains cell values that do not end with a period, the values might be converted as one sentence. As another example, if a PDF document contains a very long word that is hyphenated at the end of a line, that word might be converted as two words. In cases like these, the documents might not be suitable for machine learning unless you pre-process the files to fix formatting limitations.\n\n\n\n\n\n Documents from another Watson Knowledge Studio workspace \n\nIf you previously downloaded documents from a Knowledge Studio workspace, you can upload the ZIP file that you downloaded. An option lets you specify whether you want the ground truth annotations to be included in the imported files.\n\nAfter documents are annotated, the annotated documents are stored in JSON format. The markup language in these files, which shows how the original document text was parsed and tokenized, includes elements for all of the annotations that a human annotator added. To improve model accuracy over time, you can upload these files into another workspace, thus preserving all of the existing annotations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"},{"document_id":"ibmcld_05166-15912-16684","score":17.7574277263,"text":"\nThis allows for lower latency when accessing storage from compute resources co-located within the same data center, or for data requiring a specific geographic location. More information can be found in the [Select Regions and Endpoints](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) documentation.\n\n\n\n\n\n 8 August 2017 \n\nIntroducing IBM Cloud Object Storage\n: Object Storage is a highly available, durable, and secure platform for storing unstructured data. Unstructured data (sometimes called binary or \"blob\" data) refers to data that is not highly structured in the manner of a database. Object storage is the most efficient way to store PDFs, media files, database backups, disk images, or even large structured datasets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-updates"},{"document_id":"ibmcld_07232-1707-3805","score":17.6155187985,"text":"\nIf you crawl Box or Salesforce, a list of available resources is presented when you configure a source, using the Discovery tooling.\n* If you are using the Discovery tooling, you can configure a collection with a single data source.\n* Crawling a data source uses resources, namely API calls, of the data source. The number of API calls depends on the number of documents that need to be crawled. You must obtain an appropriate level of service license, for example Enterprise, for the data source. For information about the appropriate service level license that you need, contact the source system administrator.\n* Discovery source crawls do not delete documents that are stored in a collection, but you can manually delete them using the API. When a source is re-crawled, new documents are added, updated documents are modified to the current version, and deleted documents remain as the version last stored.\n* Discovery can only ingest the following file types, and it ignores all other document types:\n\n\n\n\n\n Lite plans Advanced plans \n\n PDF, Word, PowerPoint, Excel, JSON*, HTML* PDF, Word, PowerPoint, Excel, PNG**, TIFF**, JPG**, JSON*, HTML* \n\n\n\n* IBM Watson\u2122 Discovery supports crawling JSON and HTML documents, but you cannot edit these documents using the SDU editor. To change the configuration of HTML and JSON documents, you must use the API. For more information, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery\/).\n\n** Individual image files, such as PNG, TIFF, and JPG, are scanned, and any text is extracted. PNG, TIFF, and JPEG images embedded in PDF, Word, PowerPoint, and Excel files are also scanned, and any text is extracted.\n\nView the following table to see the objects that a data source can crawl and which data sources support crawling new and modified documents during a refresh:\n\n\n\nTable 1. Data sources that support crawling new and modified documents during refresh and objects that can be crawled\n\n Data source Crawls new and modified documents during refresh? Compatible objects that can be crawled \n\n Box (Application level access) No Files, folders","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sources"},{"document_id":"ibmcld_00576-7385-9302","score":15.5885150172,"text":"\nIBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether. Otherwise, separate databases, for example, users, orders, products, might be better so that secondary indexes are specific to each object type.\n\nIf you're storing arrays of objects within a document, consider whether the array items must really be their own document. For example, a product and each product review must be stored in separate documents, but a user and each of that user's orders must have their own document.\n\nIf you have an ever-growing data set, then you probably don't want to store data in a single, ever-growing database. Data is best stored in time-boxed databases that allow older data to be archived and deleted cleanly. Deleting an IBM Cloudant document leaves a tombstone document behind, so don't rely on deleting documents to recover disk space. Instead, you must rely on deleting whole databases.\n\nJSON doesn't offer a native way to store dates or timestamps. Choose your [date format](https:\/\/blog.cloudant.com\/2018\/05\/24\/Date-formats.html) carefully if you intend to query it later.\n\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_16358-1769-3890","score":15.4752374262,"text":"\nYou can complete this tutorial at no cost by using a Plus plan, which offers a 30-day trial at no cost. However, to create a Plus plan instance of the service, you must have a paid account (where you provide credit card details). For more information about creating a paid account, see [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account).\n2. Create a Plus plan Discovery service instance.\n\nGo to the [Discovery](https:\/\/cloud.ibm.com\/catalog\/services\/watson-discovery) resource page in the IBM Cloud catalog and create a Plus plan service instance.\n\nSpecify Dallas as the location.\n\nAs part of this tutorial, you will provision other services also. The services must be hosted in the same data location so that they can connect to one another. Because the NeuralSeek service is available only from Dallas, you will create all of the service instances in Dallas.\n\n\n\nIf you decide to stop using the Plus plan and don't want to pay for it, delete the Plus plan service instance before the 30-day trial period ends.\n\n\n\n\n\n\n\n Step 1: Get the product documentation \n\nTo use the Discovery product documentation as our knowledge base, we will download the product documentation as a PDF file.\n\n\n\n1. From a web browser, go to the product documentation site.\n\nhttps:\/\/cloud.ibm.com\/docs\/discovery-data\n2. From the table of contents panel, click the overflow menu icon in the Product guide section, and then choose View as PDF.\n3. Save the PDF file to your system by clicking the Save icon from the page header.\n4. Use a PDF file editor to split the PDF document into two separate PDF files of similar size.\n\nSplitting the PDF creates two smaller files that can be enriched faster in Discovery.\n\n\n\n\n\n\n\n Step 2: Create a Document Retrieval project \n\nNow that you have the latest copy of the product documentation, add it to a Discovery project as your data source.\n\nIn Discovery, you will create a Document Retrieval project type. Documents that you add to a project of this type are automatically enriched in the following ways:\n\n\n\n* Entities, such as proper nouns, are identified and tagged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek"},{"document_id":"ibmcld_07111-1693-3780","score":15.2261713509,"text":"\n* You can use any of the fields that are indexed by default. To see your choices, check the Fields to index list. Fields that have a Type value are stored in the index.\n* The number of segments per document is limited to 1,000. After segment number 999 is created, any remaining document content is stored within segment 1,000.\n* Metadata from PDF and Microsoft Word documents and any custom metadata is extracted and included in the index with each segment.\n\n\n\nBe careful with documents that contain repeating sections, such as a catalog that has a description and specifications section for each product entry. If you split the document at too granular a level, the subsections, such as a section with specification details, can be disassociated from the product to which it belongs.\n\nTo split the documents in a collection, complete the following steps:\n\n\n\n1. Click Manage collections from the navigation panel, and then click to open a collection.\n2. Open the Manage fields page.\n\nA list of the identified fields is displayed.\n3. From the Improve query results by splitting your documents section, click Split document.\n4. Choose the field that you want to use as your page break marker from the Select field dropdown.\n\nThe list that you can choose from includes a subset of all the identified fields.\n5. Click Apply changes and reprocess.\n\n\n\nYou can check the status of the splitting process from the Activity page.\n\nThe metadata field includes the parent document ID. Each resulting segment of the original document can contain different information. For example, if you split the document based on the subtitle field, the first segment might contain only a title field. The next segment might contain a subtitle and a text field. The third might contain a subtitle field, a text field, and a footer field.\n\n\n\n Updating documents that were split \n\nIf a document that was split changes and you want to upload the document again, work with a developer to replace the document by using the API. A developer can use the Update a document method to replace the original parent document.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-split-documents"},{"document_id":"ibmcld_07103-22905-25134","score":15.0388100556,"text":"\nFor more information about adding a document classifier by using the product user interface, see [Classifying documents](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-cm-doc-classifier).\n\n\n\n\n\n 21 March 2022 \n\nVisualize enrichments found in your documents\n: When you click to view the passage from a search result, a document preview page is displayed that shows a representation of the original document where the search result was found. For most document types, you can open a new advanced view of the document to see useful summary information, such as the number of occurrences of any enrichments that are detected in the document. You also can select one of the enrichments to highlight every occurrence of the element within the document text.\n\nCurrently, only the Entities and Keywords enrichments are listed.\n\nImproved format of search results from PDF documents\n: When you click to view a passage from a search result that is extracted from a PDF document, a document preview page is displayed that shows the returned passage in the context of the original PDF page.\n\nThe in-context view is available for PDF files to which a Smart Document Understanding model is applied. The rich preview does not work on images, meaning it doesn't work on scanned PDF documents. The in-context view is available for PDFs in all languages; however, the enrichment highlighting might be misaligned in some languages.\n\nTell us what you think\n: Share your opinions and ideas with us at any time by clicking the Share feedback button from the page header of the product user interface.\n\n\n\n\n\n 10 March 2022 \n\nManage the data in a collection from the new Manage data page\n: You can now access the Manage data page for a collection from the Manage collections navigation pane. Go there to see a list of the documents in your collection and get a quick view of information about the documents. You can also delete documents from a collection with just a few clicks. For more information, see [Excluding content from query results](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-hide-data).\n\n\n\n\n\n 15 February 2022 \n\nAn alternative authentication mechanism is available for Microsoft Sharepoint Online connectors","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_16358-7447-9162","score":14.9898623259,"text":"\nBefore we add anything to our new assistant, let's check on the status of our data.\n\n\n\n\n\n Step 5: Prepare your data for retrieval \n\nTo improve the retrievability of the information in your PDF files, you will split the PDF files into many smaller documents. To do so, you will first teach Discovery about the structure of your PDF files, so it understands how subsections are formatted and can split the document by subsection.\n\n\n\n1. Return to the web browser tab where your Discovery project is displayed.\n\nThe Improve and customize page for the last PDF file that you uploaded is displayed.\n2. From the Improvement tools panel, expand Define structure, and then click New fields.\n\nZoom\n\n![Shows the chat bot preview in a fake web page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/tut-neural-new-fields.png)\n\nFigure 5. Opening the tool for defining fields\n3. Choose the Discovery docs part 1 collection.\n\nThe Identify fields tab is displayed, where you can choose the type of Smart Document Understanding model that you want to use.\n4. Click User-trained models, and then click Submit.\n\nZoom\n\n![Shows the chat bot preview in a fake web page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/tut-neural-user-trained.png)\n\nFigure 6. Creating a user-trained model\n5. Click Apply changes and reprocess.\n\nAfter some processing occurs, a representation of the document is displayed in the Smart Document Understanding tool. The tool shows you a view of the original document along with a representation of the document, where the text is replaced by blocks. The blocks represent field types.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00546-2347-3956","score":17.301066923,"text":"\ndisk_size Size in bytes of the data as stored on the disk. Views indexes aren't included in the calculation. \n doc_count A count of the documents in the specified database. \n doc_del_count Number of deleted documents. \n instance_start_time Always 0. \n other JSON object that contains a data_size field. \n purge_seq The number of purge operations on the database. \n sizes A JSON object, containing file, external, and active sizes. active is the size in bytes of data that is stored internally (excluding old revisions). external is the size in bytes of decompressed user data. This value is the billable data size. The other\/data_size field is an alias for the external field. file is the size in bytes of data that is stored on the disk. Indexes aren't included in the calculation. The disk_size field is an alias for the file field. This size includes data that is waiting for compaction. \n update_seq An opaque string that describes the state of the database. Don't rely on this string for counting the number of updates. \n partitioned_indexes A JSON object that appears only if the database is partitioned. count is the number of partitioned indexes. indexes list the type of partitioned indexes, and limit shows the maximum number of allowed partitioned indexes. \n\n\n\nSee the following example (abbreviated) response that contains database details:\n\n{\n\"update_seq\": \"982...uUQ\",\n\"db_name\": \"db\",\n\"sizes\": {\n\"file\": 46114703224,\n\"external\": 193164408719,\n\"active\": 34961621142\n},\n\"purge_seq\": 0,\n\"other\": {\n\"data_size\": 193164408719\n},\n\"doc_del_count\": 5564,\n\"doc_count\": 9818541,\n\"disk_size\": 46114703224,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-database-details"},{"document_id":"ibmcld_06968-16615-18789","score":16.70414336,"text":"\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row\n* Each object that is defined in an array in a JSON file results in a separate document\n\n\n\n\n\nNumber of documents per service instance\n\n Plan Documents per service instance \n\n Cloud Pak for Data Unlimited \n Premium Unlimited \n Enterprise Unlimited \n Plus (includes Trial) 500,000 \n\n\n\nThe maximum allowed number can vary slightly depending on the size of the documents. Use these values as a general guideline.\n\n\n\n\n\n File size limits \n\n\n\n Crawled documents \n\nThe maximum size of each file that you can crawl by using a connector differs by deployment type.\n\nIBM Cloud\n\nManaged deployments on IBM Cloud\n\n\n\n* Premium plans only:\n\n\n\n* Box: 50 MB\n* IBM Cloud Object Store: 50 MB\n* Salesforce Files objects: 50 MB\n* All other data sources: 10 MB\n\n\n\n* All other plans: 10 MB\n\n\n\nIBM Cloud Pak for Data\n\nInstalled deployments on IBM Cloud Pak for Data\n\n\n\n* All data sources: 32 MB\n\n\n\n\n\n\n\n Uploaded documents \n\nThe size of each file that you can upload depends on your Discovery plan type. See the *Maximum document size table for details.\n\n\n\nMaximum document size\n\n Plan File size per document \n\n Cloud Pak for Data 50 MB \n Premium 50 MB \n Enterprise 10 MB \n Plus (includes Trial) 10 MB \n\n\n\n\n\n\n\n\n\n Field limits \n\nWhen a document is added to a collection, content from the document is evaluated and added to the appropriate fields in an internal index.\n\nFor structured data, such as uploaded CSV or JSON files, or data from crawled databases, each column or object is stored as a root-level field. For example, if you add a CSV file to collection, each column in the CSV file is stored as a separate field in the index.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_06968-18330-20453","score":16.5208999872,"text":"\nPlus (includes Trial) 10 MB \n\n\n\n\n\n\n\n\n\n Field limits \n\nWhen a document is added to a collection, content from the document is evaluated and added to the appropriate fields in an internal index.\n\nFor structured data, such as uploaded CSV or JSON files, or data from crawled databases, each column or object is stored as a root-level field. For example, if you add a CSV file to collection, each column in the CSV file is stored as a separate field in the index.\n\nA maximum of 1,000 fields can be added to the index.\n\nYou cannot assign the data type, such as Date or String, of a field. The data type is detected automatically and assigned to the field during document ingestion. The assignment is based on the data type that is detected from the first document that is indexed. Ingestion errors can occur in subsequent documents if a different data type is detected for the value in the same field. Therefore, if your documents have a mix of data types in a single field, first ingest the document that has a value with the most flexible data type, such as String, in the field.\n\nWhen you crawl a website or upload an HTML file, the HTML content is added to the collection and indexed in an html field.\n\nThe following table shows the maximum size limit for fields per document.\n\n\n\nMaximum field sizes\n\n Field type Maximum allowed size per document \n\n html field 5 MB \n Sum of all other fields 1 MB \n\n\n\nIf the maximum size of the fields in the document exceeds the allowed limits, they are treated as follows:\n\n\n\n* For a document with an oversized html field, all of the fields in the document are indexed except the html field.\n\nFor IBM Cloud Pak for Data version 4.0 and earlier, the entire document is not indexed.\n* For a document with oversized non-HTML fields, the document is not indexed.\n\n\n\nIf you are uploading a Microsoft Excel file and a message is displayed that indicates that the non-HTML field size limit is exceeded, consider converting the XLS file into a CSV file. When you upload a comma-separated value (CSV) file, each row is indexed as a separate document. As a result, no field size limits are exceeded.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_00510-5537-7566","score":14.6594296614,"text":"\nInstead, keep orders separate as their own document type, referencing the customer ID. Now the model is immutable. To add an order, I create a new order document in the database, which cannot generate conflicts.\n\nTo be able to retrieve all orders for a specific customer, we can employ a view, which we cover later.\n\nAvoid constructs that rely on updates to parts of existing documents, where possible. Bad data models are often hard to change after you\u2019re in production.\n\nThe previous pattern can be solved efficiently by using partitioned databases, which are covered in greater detailed later.\n\nFor more information, see the following documentation:\n\n\n\n* IBM Cloudant guide to [data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq)\n* [Database partitions](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning)\n\n\n\n\n\n\n\n Keep documents small \n\nIBM Cloudant imposes a max doc size of 1 MB. This limit does not mean that a close-to-1-MB document size is a good idea. On the contrary, if you find you are creating documents that exceed single-digit KB, you probably need to revisit your model. Several things in IBM Cloudant become less performant as documents grow. JSON decoding is costly, for example.\n\nLet's look at the following sections: Documents must group data that mostly changes together and Keep documents small. It\u2019s worth stressing that models that rely on updates have a maximum volume limit of 1 MB, the cut-off for document size. This size isn\u2019t what you want.\n\n\n\n\n\n Avoid using attachments \n\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_01234-7-2066","score":14.6126143089,"text":"\nGetting started with File Storage for Classic \n\nIBM Cloud\u00ae File Storage for Classic is persistent, fast, and flexible network-attached, NFS-based File Storage for Classic. In this network-attached storage (NAS) environment, you have total control over your file shares function and performance. File Storage for Classic shares can be connected to up to 64 authorized devices over routed TCP\/IP connections for resiliency.\n\nFor more information about using File Storage for Classic with the IBM Cloud\u00ae Kubernetes Service, see [Storing data on classic IBM Cloud File Storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-file_storage).\n\n\n\n Before you begin \n\nFile Storage for Classic volumes can be provisioned from 20 GB to 12 TB with two options:\n\n\n\n* Provision Endurance tiers that feature pre-defined performance levels and other features like snapshots and replication.\n* Build a high-powered Performance environment with allocated input\/output operations per second (IOPS).\n\n\n\nFor more information about the File Storage for Classic offering, see [What is IBM Cloud File Storage](https:\/\/www.ibm.com\/products\/file-storage).\n\n\n\n\n\n Step 1: Provisioning considerations \n\n\n\n Block size \n\nThe IOPS value for both Endurance and Performance is based on a 16-KB block size with a 50\/50 read and write, 50\/50 random and sequential workload. A 16-KB block is the equivalent of one write to the volume.\n\nThe block size that is used by your application directly impacts the storage performance. If the block size that is used by your application is smaller than 16 KB, the IOPS limit is realized before the throughput limit. Conversely, if the block size that is used by your application is larger than 16 KB, the throughput limit is realized before to the IOPS limit.\n\n\n\nTable 1 shows examples of how block size and IOPS affect the throughput. Average IO size x IOPS = Throughput in MB\/s.\n\n Block Size (KB) IOPS Throughput (MB\/s) \n\n 4 1,000 4 \n 8 1,000 8 \n 16 1,000 16 \n 32 500 16 \n 64 250 16 \n 128 128 16 \n 512 32 16 \n 1024 16 16 \n\n\n\n\n\n\n\n Authorized hosts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-getting-started"},{"document_id":"ibmcld_14361-5377-7486","score":13.5909569566,"text":"\n* Configure shares individually - Toggle this switch on to specify different configuration settings for each file share.\n* Number of shares - When you use the same configuration setting for each file share, specify the number of file shares for the NFS shared storage that you want to add.\n* Size (GB) - Select the capacity that meets your shared storage needs.\n* Performance - Select the IOPS (input\/output operations per second) per GB based on your workload requirements.\n* Add shared storage - Select to add individual file shares that use different configuration settings.\n\n\n\nChoose performance level options according to your needs.\n\n\n\nTable 3. NFS performance level options\n\n Option Details \n\n 0.25 IOPS\/GB This option is designed for workloads that are not used often. For example, vaulted data, hosting large databases with legacy data, or virtual disk images of virtual memory system as backup. \n 2 IOPS\/GB This option is designed for most general-purpose workloads. For example, hosting small databases, backing up web applications, or virtual machine disk images for a hypervisor. \n 4 IOPS\/GB This option is designed for higher-intensity workloads that have a high percentage of active data at a time. For example, transactional databases. \n 10 IOPS\/GB This option is designed for the most demanding workload types, such as analytics. For example, high-transaction databases and other performance-sensitive databases. This performance level is limited to a maximum capacity of 4 TB per file share. \n\n\n\n\n\n\n\n vSAN storage \n\nvSAN is available for the Cascade Lake bare metal configuration only.\n\n\n\n Size for vSAN capacity disks \n\nSelect an option for the capacity disks that you need.\n\n\n\n\n\n Number of vSAN capacity disks \n\nSpecify the number of capacity disks that you want to add.\n\nFor VMware vSphere 7, order up to 10 disks for Dual CPU models and order up to eight disks for Quad CPU models.\n\n\n\n\n\n Size for vSAN cache disks \n\nReview the Size for vSAN cache disks value.\n\n\n\n\n\n Number of vSAN cache disks \n\nReview the Number of vSAN cache disks value.\n\n\n\n\n\n Enable vSAN deduplication and compression","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-cr_orderinginstance-consolidwkld"},{"document_id":"ibmcld_14612-8387-10632","score":13.3425802247,"text":"\n* Number of shares - When want to use the same configuration setting for each file share, specify the number of file shares for the NFS shared storage that you want to add.\n* Size (GB) - Select the capacity that meets your shared storage needs.\n* Performance - Select the IOPS (input\/output operations per second) per GB based on your workload requirements.\n* Add shared storage - Select to add individual file shares with different configuration settings.\n\n\n\nThe following table indicates the performance level details.\n\n\n\nTable 4. NFS performance level options\n\n Option Details \n\n 0.25 IOPS\/GB This option is designed for workloads that are not used often. Example applications include vaulted data, hosting large databases with legacy data, or virtual disk images of virtual memory system as backup. \n 2 IOPS\/GB This option is designed for most general-purpose workloads. Example applications include hosting small databases, backing up web applications, or VM disk images for a hypervisor. \n 4 IOPS\/GB This option is designed for higher-intensity workloads that have a high percentage of active data at a time. Example applications include transactional databases. \n 10 IOPS\/GB This option is designed for the most demanding workload types, such as analytics. Example applications include high-transaction databases and other performance-sensitive databases. This performance level is limited to a maximum capacity of 4 TB per file share. \n\n\n\n\n\n\n\n vSAN storage \n\nSpecify the following vSAN options.\n\n\n\n Size for vSAN capacity disks \n\nSelect an option for the capacity disks that you need.\n\n\n\n\n\n Number of vSAN capacity disks \n\nSpecify the number of capacity disks that you want to add.\n\nIf you want to add more capacity disks, select the High performance with Intel Optane checkbox. This option provides two extra capacity disk bays, which are useful for workloads that require less latency and higher IOPS throughput.\n\nThe High performance with Intel Optane option is available only for vSphere 6 instances.\n\n\n\n\n\n Size for vSAN cache disks \n\nReview the Size for vSAN cache disks value. The value depends on whether you checked the High performance with Intel Optane box.\n\n\n\n\n\n Number of vSAN cache disks \n\nReview Number of vSAN cache disks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingclusters"},{"document_id":"ibmcld_07117-7-2192","score":13.3203298278,"text":"\nTroubleshooting ingestion \n\nLearn about solutions and workarounds to warnings or errors that you might encounter when you add data to a collection.\n\nThis information applies both to managed and installed instances of Discovery. For more troubleshooting tips for installed deployments only, see [Troubleshooting IBM Watson\u00ae Discovery Cartridge for IBM Cloud Pak\u00ae for Data deployments](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-troubleshoot).\n\nUnable to process one or more documents\n: This notification is displayed in the page header when a processing delay of any kind occurs in any project across the entire service instance. If the message is displayed while you are adding data to a collection, you can ignore it. If any problems occur that are related to the creation of your collection, a message is displayed in the Activity page for the collection. Check there for any pertinent messages.\n\nThis document exceeds the 1MB limit for non-HTML fields\n: The html field in the document index stores structural information about the document. If you add a single document with complex tables, images, or other objects that need to be represented in HTML, you might hit the size limit for this field. To work around this issue, consider breaking the source file up into 2 or more smaller files, and then add the files to the same collection separately so that you can apply enrichments and search them together.\n\n\n\n Microsoft document troubleshooting tips \n\nFailed to prepare document for SDU processing\n: Some DOC, PPT, and XLS files that use older features which are no longer supported by Microsoft Office can cause ingestion issues. If you encounter this issue, open the file in a more recent version of Microsoft Office and convert the file to the DOCX, PPTX, or XLSX format respectively, and then upload the DOCX, PPTX, or XLSX file.\n\nLine breaks are inserted randomly\n: When some files in Microsoft Office format are added to a collection, line breaks are inserted seemingly at random to the text that is stored in the html field in the collection's index. The unexpected line breaks can impact the efficiency of enrichments, such as custom rule recognition.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-troubleshoot-ingestion"},{"document_id":"ibmcld_06558-5483-6805","score":13.0367353478,"text":"\nSetting this value too high can exceed your database's memory limits, which can cause it to crash.\n* Default: 50\n* Minimum: 10\n* Maximum: 100\n* Restarts database? - true\n\n\n\n[innodb_flush_log_at_trx_commit](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/innodb-parameters.htmlsysvar_innodb_flush_log_at_trx_commit)\n\n\n\n* Description: Controls the balance between strict [ACID](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/glossary.htmlglos_acid) compliance for [commit](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/glossary.htmlglos_commit) operations and higher performance that is possible when commit-related I\/O operations are rearranged and done in batches. You can achieve better performance by changing the default value but then you can lose transactions in a crash.\n* Default: 2\n* Minimum: 0\n* Maximum: 2\n* Restarts database? - false\n\n\n\n[innodb_log_buffer_size](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/innodb-parameters.htmlsysvar_innodb_log_buffer_size)\n\n\n\n* Description: The size in bytes of the buffer that InnoDB uses to write to the [log files](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/glossary.htmlglos_log_file) on disk.\n* Default: 33554432\n* Minimum: 1048576\n* Maximum: 4294967295\n* Restarts database? - true\n\n\n\n[innodb_log_file_size](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/innodb-parameters.htmlsysvar_innodb_log_file_size)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-changing-configuration"},{"document_id":"ibmcld_06968-15099-17180","score":12.6684837035,"text":"\n[checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/icons\/checkmark-icon.svg) \n\n\n\n\n\n* PDF files that are secured with a password or certificate are not supported. Vector objects, including SVG images and vectorized text, are not supported. Only images of the supported image file types that occur in the PDF are rendered.\n* Only single-page image files are supported.\n* Files within compressed archive files (ZIP, GZIP, TAR) are extracted. Discovery ingests the supported file types within the archive; it ignores all other file types. The file names must be encoded in UTF-8. Files with names that include Japanese characters, for example, must be renamed before they are added to the ZIP file.\n* Discovery supports MacOS ZIP files only if they are generated by using a command such as: zip -r my-folder.zip my-folder -x \".DS_Store\". ZIP files that are created by right-clicking a folder and clicking Compress are not supported.\n* PDF files that you upload as part of an archive file are not displayed in the advanced view for a query result that you open from the Improve and customize page. If you want the file to be viewable from the advanced view, reimport the PDF file separately from the archive file.\n\n\n\nWhen you add files to a Document Retrieval for Contracts project type, any file types that support SDU and OCR are processed with a pretrained Smart Document Understanding model and Optical Character Recognition automatically.\n\n\n\n\n\n Document limits \n\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00556-7-1696","score":12.5361307725,"text":"\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image\/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) or [_users](https:\/\/cloud.ibm.com\/apidocs\/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID\/$ATTACHMENT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_00457-7630-8530","score":12.1207451743,"text":"\n\"rev\":\"1-0cde94a828df5cdc0943a10f3f36e7e5\"\n},\n{\n\"ok\":true,\n\"id\":\"d1f61e66-7708-4da6-aa05-7cbc33b44b7e\",\n\"rev\":\"1-a2b6e5dac4e0447e7049c8c540b309d6\"\n}\n]\nShow more\n\n\n\n\n\n Inserting documents in bulk \n\nTo insert documents in bulk into a database, you need to supply a JSON structure with the array of documents that you want to add to the database. You can either include a document ID for each document, or allow the document ID to be automatically generated.\n\nSee an example JSON for a bulk insert of three documents:\n\n{\n\"docs\": [\n{\n\"name\": \"Nicholas\",\n\"age\": 45,\n\"gender\": \"male\",\n\"_id\": \"96f898f0-f6ff-4a9b-aac4-503992f31b01\",\n\"_attachments\": {\n\n}\n},\n{\n\"name\": \"Taylor\",\n\"age\": 50,\n\"gender\": \"male\",\n\"_id\": \"5a049246-179f-42ad-87ac-8f080426c17c\",\n\"_attachments\": {\n\n}\n},\n{\n\"name\": \"Owen\",\n\"age\": 51,\n\"gender\": \"male\",\n\"_id\": \"d1f61e66-7708-4da6-aa05-7cbc33b44b7e\",\n\"_attachments\": {\n\n}\n}\n]\n}\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-bulk-operations"},{"document_id":"ibmcld_06115-7-2109","score":11.7799813035,"text":"\nAbout Portworx \n\nReview frequently asked questions to learn more about Portworx and how Portworx provides highly available persistent storage management for your containerized apps.\n\n\n\n What is software-defined storage (SDS)? \n\nAn SDS solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n\n\n How does Portworx work? \n\nAs a software defined storage solution, Portworx aggregates available storage that is attached to your worker nodes and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using volume replication of each container-level volume across multiple worker nodes, Portworx ensures data persistence and data accessibility across zones.\n\nPortworx also comes with additional features that you can use for your stateful apps, such as volume snapshots, volume encryption, isolation, and an integrated Storage Orchestrator for Kubernetes (Stork) to ensure optimal placement of volumes in the cluster. For more information, see the [Portworx documentation](https:\/\/docs.portworx.com\/).\n\n\n\n\n\n What are the requirements to run Portworx? \n\nReview the requirements to [install Portworx](https:\/\/docs.portworx.com\/install-portworx\/prerequisites\/).\n\nFor production environments, choose one of the [SDS worker node flavors](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodessds-table) for best performance.\n\n\n\n\n\n How can I make sure that my data is stored highly available?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_about"},{"document_id":"ibmcld_10556-7-2107","score":11.7799813035,"text":"\nAbout Portworx \n\nReview frequently asked questions to learn more about Portworx and how Portworx provides highly available persistent storage management for your containerized apps.\n\n\n\n What is software-defined storage (SDS)? \n\nAn SDS solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n\n\n How does Portworx work? \n\nAs a software defined storage solution, Portworx aggregates available storage that is attached to your worker nodes and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using volume replication of each container-level volume across multiple worker nodes, Portworx ensures data persistence and data accessibility across zones.\n\nPortworx also comes with additional features that you can use for your stateful apps, such as volume snapshots, volume encryption, isolation, and an integrated Storage Orchestrator for Kubernetes (Stork) to ensure optimal placement of volumes in the cluster. For more information, see the [Portworx documentation](https:\/\/docs.portworx.com\/).\n\n\n\n\n\n What are the requirements to run Portworx? \n\nReview the requirements to [install Portworx](https:\/\/docs.portworx.com\/install-portworx\/prerequisites\/).\n\nFor production environments, choose one of the [SDS worker node flavors](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodessds-table) for best performance.\n\n\n\n\n\n How can I make sure that my data is stored highly available?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_about"},{"document_id":"ibmcld_00589-25445-26913","score":11.4448907728,"text":"\nGET \/$DATABASE\/_design\/$DOCUMENT_ID\/_search_disk_size\/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET \/$DATABASE\/_design\/$DOCUMENT_ID\/_search_info\/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET\/HEAD \/$DATABASE\/_index\/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET \/$DATABASE\/_design_docs cloudantnosqldb.any-document.read \n GET \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.any-document.read \n GET\/HEAD \/$DATABASE\/_design\/$DOCUMENT_ID\/$ATTACHMENT cloudantnosqldb.any-document.read \n PUT \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.design-document.write \n COPY \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.design-document.write \n DELETE \/$DATABASE\/_design\/$DOCUMENT_ID cloudantnosqldb.design-document.write \n PUT \/$DATABASE\/_design\/$DOCUMENT_ID\/$ATTACHMENT cloudantnosqldb.design-document.write \n DELETE \/$DATABASE\/_design\/$DOCUMENT_ID\/$ATTACHMENT cloudantnosqldb.design-document.write \n POST\/DELETE \/$DATABASE\/_index\/$FURTHER_PATH_PARTS cloudantnosqldb.design-document.write \n GET\/HEAD \/$DATABASE\/_security cloudantnosqldb.database-security.read \n PUT \/$DATABASE\/_security cloudantnosqldb.database-security.write \n GET\/HEAD \/$DATABASE\/_shards cloudantnosqldb.database-shards.read \n COPY (Depends on write document type.) \/$DATABASE\/$DOCUMENT_ID cloudantnosqldb.any-document.read + cloudantnosqldb.design-document.write either or both cloudantnosqldb.local-document.write either or both cloudantnosqldb.data-document.write","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_00556-10831-12062","score":11.0944528147,"text":"\nThe content must be provided by using [BASE64](https:\/\/en.wikipedia.org\/wiki\/Base64) representation, as shown in the example.\n\nA full list of media types is available in the [media types](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types) article.\n\nSee the following example JSON document that includes an inline attachment of a jpeg image:\n\n{\n\"_id\":\"document_with_attachment\",\n\"_attachments\":\n{\n\"name_of_attachment\": {\n\"content_type\":\"image\/jpeg\",\n\"data\": \"iVBORw0KGgoAA... ...AASUVORK5CYII=\"\n}\n}\n}\n\n\n\n\n\n Performance considerations \n\nWhile document attachments are useful, they do have implications for application performance. In particular, having too many attachments can have an adverse performance impact during replication.\n\nFor example, if your application requires storage for multiple images as attachments or includes large images, you must use an alternative [BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object) storage mechanism to store the images. You might then use IBM Cloudant to keep the image metadata, such as URLs to the BLOB store.\n\nYou might find it helpful to do performance testing for your specific application to determine which approach works best for your circumstances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_04543-306793-308516","score":11.0659741421,"text":"\n* ibmcloud is instance-template-create --interactive Create instance template interactively.\n\n\n\n\n\n\n\n Command options \n\n\n\n* INSTANCE_TEMPLATE_NAME: Name of the instance template.\n* VPC: ID or name of the VPC.\n* ZONE_NAME: Name of the zone.\n* PROFILE_NAME: Name of the profile.\n* SUBNET: ID or name of the subnet.\n* --image: ID or name of the image.\n* --catalog-offering: The CRN for the IBM Cloud catalog offering. If specified, the latest version of that offering is used. For more information about creating a catalog offering, see [Onboarding software to your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog&interface=cli).\n* --catalog-offering-version: The CRN for the version of a IBM Cloud catalog offering. For more information about creating a version for the catalog offering, see [Onboarding software to your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog&interface=cli).\n* --total-volume-bandwidth: The amount of bandwidth (in megabits per second) that is allocated exclusively to instance storage volumes. An increase in this value results in a corresponding decrease to total network bandwidth.\n* --boot-volume: BOOT_VOLUME_JSON|@BOOT_VOLUME_JSON_FILE, boot volume attachment in JSON or JSON file. For the data schema, see the boot_volume_attachment property in the [API documentation](https:\/\/cloud.ibm.com\/apidocs\/vpccreate-instance).\n* --volume-attach: VOLUME_ATTACH_JSON|@VOLUME_ATTACH_JSON_FILE, volume attachment in JSON or JSON file, list of volumes. For the data schema, see the volume_attachments property in the [API documentation](https:\/\/cloud.ibm.com\/apidocs\/vpccreate-instance).\n* --keys: Comma-separated IDs or names of SSH keys.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-vpc-reference"},{"document_id":"ibmcld_15558-311148-312871","score":11.0659741421,"text":"\n* ibmcloud is instance-template-create --interactive Create instance template interactively.\n\n\n\n\n\n\n\n Command options \n\n\n\n* INSTANCE_TEMPLATE_NAME: Name of the instance template.\n* VPC: ID or name of the VPC.\n* ZONE_NAME: Name of the zone.\n* PROFILE_NAME: Name of the profile.\n* SUBNET: ID or name of the subnet.\n* --image: ID or name of the image.\n* --catalog-offering: The CRN for the IBM Cloud catalog offering. If specified, the latest version of that offering is used. For more information about creating a catalog offering, see [Onboarding software to your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog&interface=cli).\n* --catalog-offering-version: The CRN for the version of a IBM Cloud catalog offering. For more information about creating a version for the catalog offering, see [Onboarding software to your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog&interface=cli).\n* --total-volume-bandwidth: The amount of bandwidth (in megabits per second) that is allocated exclusively to instance storage volumes. An increase in this value results in a corresponding decrease to total network bandwidth.\n* --boot-volume: BOOT_VOLUME_JSON|@BOOT_VOLUME_JSON_FILE, boot volume attachment in JSON or JSON file. For the data schema, see the boot_volume_attachment property in the [API documentation](https:\/\/cloud.ibm.com\/apidocs\/vpccreate-instance).\n* --volume-attach: VOLUME_ATTACH_JSON|@VOLUME_ATTACH_JSON_FILE, volume attachment in JSON or JSON file, list of volumes. For the data schema, see the volume_attachments property in the [API documentation](https:\/\/cloud.ibm.com\/apidocs\/vpccreate-instance).\n* --keys: Comma-separated IDs or names of SSH keys.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"},{"document_id":"ibmcld_15545-311096-312819","score":11.0659741421,"text":"\n* ibmcloud is instance-template-create --interactive Create instance template interactively.\n\n\n\n\n\n\n\n Command options \n\n\n\n* INSTANCE_TEMPLATE_NAME: Name of the instance template.\n* VPC: ID or name of the VPC.\n* ZONE_NAME: Name of the zone.\n* PROFILE_NAME: Name of the profile.\n* SUBNET: ID or name of the subnet.\n* --image: ID or name of the image.\n* --catalog-offering: The CRN for the IBM Cloud catalog offering. If specified, the latest version of that offering is used. For more information about creating a catalog offering, see [Onboarding software to your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog&interface=cli).\n* --catalog-offering-version: The CRN for the version of a IBM Cloud catalog offering. For more information about creating a version for the catalog offering, see [Onboarding software to your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog&interface=cli).\n* --total-volume-bandwidth: The amount of bandwidth (in megabits per second) that is allocated exclusively to instance storage volumes. An increase in this value results in a corresponding decrease to total network bandwidth.\n* --boot-volume: BOOT_VOLUME_JSON|@BOOT_VOLUME_JSON_FILE, boot volume attachment in JSON or JSON file. For the data schema, see the boot_volume_attachment property in the [API documentation](https:\/\/cloud.ibm.com\/apidocs\/vpccreate-instance).\n* --volume-attach: VOLUME_ATTACH_JSON|@VOLUME_ATTACH_JSON_FILE, volume attachment in JSON or JSON file, list of volumes. For the data schema, see the volume_attachments property in the [API documentation](https:\/\/cloud.ibm.com\/apidocs\/vpccreate-instance).\n* --keys: Comma-separated IDs or names of SSH keys.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_16082-310992-312715","score":11.0659741421,"text":"\n* ibmcloud is instance-template-create --interactive Create instance template interactively.\n\n\n\n\n\n\n\n Command options \n\n\n\n* INSTANCE_TEMPLATE_NAME: Name of the instance template.\n* VPC: ID or name of the VPC.\n* ZONE_NAME: Name of the zone.\n* PROFILE_NAME: Name of the profile.\n* SUBNET: ID or name of the subnet.\n* --image: ID or name of the image.\n* --catalog-offering: The CRN for the IBM Cloud catalog offering. If specified, the latest version of that offering is used. For more information about creating a catalog offering, see [Onboarding software to your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog&interface=cli).\n* --catalog-offering-version: The CRN for the version of a IBM Cloud catalog offering. For more information about creating a version for the catalog offering, see [Onboarding software to your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog&interface=cli).\n* --total-volume-bandwidth: The amount of bandwidth (in megabits per second) that is allocated exclusively to instance storage volumes. An increase in this value results in a corresponding decrease to total network bandwidth.\n* --boot-volume: BOOT_VOLUME_JSON|@BOOT_VOLUME_JSON_FILE, boot volume attachment in JSON or JSON file. For the data schema, see the boot_volume_attachment property in the [API documentation](https:\/\/cloud.ibm.com\/apidocs\/vpccreate-instance).\n* --volume-attach: VOLUME_ATTACH_JSON|@VOLUME_ATTACH_JSON_FILE, volume attachment in JSON or JSON file, list of volumes. For the data schema, see the volume_attachments property in the [API documentation](https:\/\/cloud.ibm.com\/apidocs\/vpccreate-instance).\n* --keys: Comma-separated IDs or names of SSH keys.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00564-5557-7242","score":7.4228268293,"text":"\nThe resulting compressed data stream is then redirected and written to a file called backup.gz.\n\nIf the database requires you to supply access credentials, use $SERVICE_URL with the form https:\/\/$USERNAME:$PASSWORD@$ACCOUNT, for example, https:\/\/myusername:mypassword@myhost.cloudant.com.\n\nIt's straightforward to extend the pipeline if you want to transform the data in other ways. For example, you might want to encrypt the data before it's written to disk. You might also want to write the data directly to an object store service by using their command-line tools.\n\n\n\n\n\n Hourly or daily backups that use cron \n\nThe cron scheduling tool can be set up to take snapshots of data at regular intervals.\n\nA useful starting point is to get couchbackup to write a single backup to a file, where the file name includes the current date and time, as shown in the following example:\n\ncouchbackup --url \"https:\/\/$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com\" --db \"animaldb\" > animaldb-backup-date -u \"+%Y-%m-%dT%H:%M:%SZ\".bak\n\nAfter you check the command to ensure it works correctly, it can be entered into a 'cron job':\n\n\n\n1. Install the CouchBackup tools on the server that you want to do the backups.\n2. Create a folder to store the backups.\n3. Create a 'cron entry' that describes the frequency of the backup.\n\n\n\nYou can create a cron entry by using the crontab -e command. See your system documentation for specific details on the 'cron' options.\n\nA cron entry that runs a daily backup looks similar to the following example:\n\n0 5 * * * couchbackup --url \"https:\/\/$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com\" --db \"animaldb\" > \/path\/to\/folder\/animaldb-backup-date -u \"+%Y-%m-%dT%H:%M:%SZ\".bak","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recovery"},{"document_id":"ibmcld_10853-12023-13191","score":7.2840928694,"text":"\nActivation: 'process-change-cloudant-sequence' (68a7083b088f4be9a7083b088f0be9b4)\n[\n\"375f8e39b5c445f39f8e39b5c415f36e\",\n\"874b327c6d2841ca8b327c6d28d1ca17\"\n]\n\nActivation: 'cloudant-events-trgr' (fbf92f75057b42a9b92f75057b32a9b7)\n[ ! ! ! ! ! !\n\"{\"statusCode\":0,\"success\":true,\"activationId\":\"68a7083b088f4be9a7083b088f0be9b4\",\"rule\":\"86ee32b0-8094-4d1e-a612-83dC74cddeb9\/cloudant-events-rule-5\",\"action\":\"86ee32b0-8094-4d1e-a612-83dC74cddeb9\/cloudant-events\/process-change-cloudant-sequence\"}\"\n<-- <\/ol> --><-- <\/section \"id=\"section-cloudant-template_test_trigger\" \"> --><-- <\/section \"id=\"section-cloudant-template_test\" \"> --><-- <\/section \"id=\"section-cloudant-template\" \"> --><-- <section \"id=\"section-get-http-resource-template\" \"> --> Deploying the Get HTTP Resource template The Get HTTP Resource template creates an action, which takes as input a location parameter. The action is enabled as a web action, allowing it to be invoked with a URL, which is CORS enabled and does not need an authentication key, which is useful for building backend services for web applications.When you deploy this template, you create a single, web-enabled action called location.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-templates"},{"document_id":"ibmcld_00445-2359-3178","score":7.1694114791,"text":"\n\"checkpointed_source_seq\": \"403-g1AAAADfeJzLYWBgYMlgTmGQS0lKzi9KdUhJMjTRyyrNSS3QS87JL01JzCvRy0styQGqY0pkSLL___9_VmIymg5TXDqSHIBkUj1YUxyaJkNcmvJYgCRDA5AC6tuflZhGrPsgGg9ANAJtzMkCAPFSStc\",\n\"changes_pending\": 134,\n\"pid\": \"<0.1781.4101>\",\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"docs_written\": 0,\n\"missing_revisions_found\": 0,\n\"replication_id\": \"d0cdbfee50a80fd43e83a9f62ea650ad+continuous\",\n\"revisions_checked\": 0,\n\"source\": \"https:\/\/repl:@tsm.cloudant.com\/tsm-admin\/\",\n\"source_seq\": \"537-g1AAAADfeJzLYWBgYMlgTmGQS0lKzi9KdUhJMjTUyyrNSS3QS87JL01JzCvRy0styQGqY0pkSLL___9_VmI9mg4jXDqSHIBkUj1WTTityWMBkgwNQAqob39WYhextkE0HoBoBNo4MQsAFuVLVQ\",\n\"started_on\": 1363274083\n},\n{\n\"user\": \"acceptly\",\n\"updated_on\": 1363273779,\n\"type\": \"indexer\",\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"pid\": \"<0.20723.4070>\",\n\"changes_done\": 189,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-active-tasks"},{"document_id":"ibmcld_00445-2996-3911","score":7.1346158684,"text":"\n\"started_on\": 1363274083\n},\n{\n\"user\": \"acceptly\",\n\"updated_on\": 1363273779,\n\"type\": \"indexer\",\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"pid\": \"<0.20723.4070>\",\n\"changes_done\": 189,\n\"database\": \"shards\/00000000-3fffffff\/acceptly\/acceptly_my_chances_logs_live.1321035717\",\n\"design_document\": \"_design\/MyChancesLogCohortReport\",\n\"started_on\": 1363273094,\n\"total_changes\": 26389\n},\n{\n\"user\": \"username\",\n\"updated_on\": 1371118433,\n\"type\": \"search_indexer\",\n\"total_changes\": 5466,\n\"node\": \"dbcore@db7.meritage.cloudant.net\",\n\"pid\": \"<0.29569.7037>\",\n\"changes_done\": 4611,\n\"database\": \"shards\/40000000-7fffffff\/username\/database_name\",\n\"design_document\": \"_design\/lucene\",\n\"index\": \"search1\",\n\"started_on\": 1371118426\n},\n{\n\"view\": 1,\n\"user\": \"acceptly\",\n\"updated_on\": 1363273504,\n\"type\": \"view_compaction\",\n\"total_changes\": 26095,\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"pid\": \"<0.21218.4070>\",\n\"changes_done\": 20000,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-active-tasks"},{"document_id":"ibmcld_00614-4378-5507","score":7.102981403,"text":"\ncurl \"https:\/\/$ACCOUNT.cloudant.com\/_api\/v2\/monitoring\/disk_use?cluster=myclustername&format=json\"\n\nSee an example result after you request disk use data in JSON format:\n\n[\n{\n\"target\": \"sumSeries(net.cloudant.mycustomer001.db.df.srv.used)\",\n\"datapoints\":\n523562172416.0, 1391019360],\n524413976576.0, 1391019420],\n519036682240.0, 1391019480],\n518762102784.0, 1391019540],\n523719393280.0, 1391019600]\n]\n},\n{\n\"target\": \"sumSeries(net.cloudant.mycustomer001.db.df.srv.free)\",\n\"datapoints\":\n6488926978048.0, 1391019360],\n6487768301568.0, 1391019420],\n6493145661440.0, 1391019480],\n6493420257280.0, 1391019540],\n4330660167680.0, 1391019600]\n]\n}\n]\nShow more\n\n\n\n\n\n With format=raw \n\nThe raw format data contains a series of text strings, identifying the name of the metric and associated values.\n\nThe text string (for example sumSeries(net.cloudant.mycustomer001.db.df.srv.used)) is the name of the metric. The next two numbers are the start and end times, expressed as UTC epoch seconds. The final number is the step size in seconds.\n\nThe numbers after the | character contain the metric data that is obtained from your chosen endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitoring-an-ibm-cloudant-cluster"},{"document_id":"ibmcld_04611-7491-8427","score":7.0565993683,"text":"\nUse the config option to opt out of only the configuration update actions as in the cloudant scenario above.\n\nHere are sample opt-out specifications in a manifest.yml file for the dashDB and cloudant scenarios.\n\nenv:\nservices_autoconfig_excludes: dashDB=all\n\nenv:\nservices_autoconfig_excludes: cloudant=config\n\nenv:\nservices_autoconfig_excludes: cloudant=config dashDB=all\n\nHere are examples of how to set the services_autoconfig_excludes environment variable for the app myapp by using the command-line interface.\n\nibmcloud cf set-env myapp services_autoconfig_excludes cloudant=config\n\nibmcloud cf set-env myapp services_autoconfig_excludes \"cloudant=config dashDB=all\"\n\nTo find the label for a service in VCAP_SERVICES issue a command like the following example:\n\nibmcloud cf env myapp\n\nThe output includes text similar to the following, where you can see the label field with value elephantsql:\n\n\"elephantsql\": [ ! ! ! ! ! ! ! ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-auto_config"},{"document_id":"ibmcld_00614-5053-6507","score":6.7105758695,"text":"\nThe raw format data contains a series of text strings, identifying the name of the metric and associated values.\n\nThe text string (for example sumSeries(net.cloudant.mycustomer001.db.df.srv.used)) is the name of the metric. The next two numbers are the start and end times, expressed as UTC epoch seconds. The final number is the step size in seconds.\n\nThe numbers after the | character contain the metric data that is obtained from your chosen endpoint. For example, requesting metric data from the disk use endpoint returns the output from a df command, with the disk use expressed as bytes stored.\n\nSee an example monitoring request for disk use data returned in raw format:\n\ncurl \"https:\/\/$ACCOUNT.cloudant.com\/_api\/v2\/monitoring\/disk_use?cluster=myclustername&format=raw\"\n\nSee an example result after you request disk use data in raw format:\n\nsumSeries(net.cloudant.mycustomer001.db.df.srv.used),1391019780,1391020080,60|344708448256.0,345318227968.0,346120126464.0,346716471296.0,175483256832.0\nsumSeries(net.cloudant.mycustomer001.db.df.srv.free),1391019780,1391020080,60|6.49070326579e+12,6.4896982057e+12,6.48884414054e+12,6.48801589658e+12,4.32277107507e+12\n\n\n\n\n\n\n\n Monitoring endpoints \n\nTo list all of the currently supported monitoring endpoints, make a request to the monitoring endpoint.\n\nThe following table lists the supported monitoring endpoints that are provided by the API:\n\n\n\nTable 3. Monitoring API endpoints\n\n Endpoint Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitoring-an-ibm-cloudant-cluster"},{"document_id":"ibmcld_04611-5953-7863","score":6.4398814435,"text":"\nYou can choose to completely opt out (as in the dashDB scenario) or opt out of only the server.xml file configuration updates (as in the cloudant scenario). The value that you specify for the services_autoconfig_excludes environment variable is a string as shown below.\n\n\n\n* The string can contain opt-out specifications for one or more services.\n* The opt-out specification for a specific service is service_type=option, where:\n\n\n\n* The service_type is the label for the service as displayed in VCAP_SERVICES.\n* The option is either all or config.\n\n\n\n* If the String contains an opt-out specification for more than one service, the individual opt-out specifications must be separated by a single white-space character.\n\n\n\nSee the following example of services_autoconfig_excludes string grammar:\n\nOpt_out_string :: <service_type_specification[<delimiter>service_type_specification]\n<service_type_specification> :: <service_type>=<option>\n<service_type> :: service type (service label as it appears in VCAP_SERVICES)\n<option> :: all | config\n<delimiter> :: one white space character\n\nImportant: The service type that you specify must match the services label as it appears in the VCAP_SERVICES environment variable. White space is not allowed. Important: No white space is allowed within a <service_type_specification>. The only allowed use of white space is to separate multiple <service_type_specification> instances.\n\nUse the all option to opt out of all automatic configuration actions for a service, as in the dashDB scenario above. Use the config option to opt out of only the configuration update actions as in the cloudant scenario above.\n\nHere are sample opt-out specifications in a manifest.yml file for the dashDB and cloudant scenarios.\n\nenv:\nservices_autoconfig_excludes: dashDB=all\n\nenv:\nservices_autoconfig_excludes: cloudant=config\n\nenv:\nservices_autoconfig_excludes: cloudant=config dashDB=all","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-auto_config"},{"document_id":"ibmcld_00614-11599-12675","score":6.3562880037,"text":"\n{\n\"start\": 1436194475,\n\"end\": 1436194775,\n\"target_responses\": [\n{\n\"target\": \"myclustername Documents per second through map functions\",\n\"datapoints\":\n\n0.0,\n1436194480\n],\n\n0.5,\n1436194495\n],\n\n0.4000000000005457,\n1436194510\n],\n...\n\n0.0,\n1436194765\n]\n]\n}\n]\n}\nShow more\n\n\n\n\n\n network \n\ncurl \"https:\/\/$ACCOUNT.cloudant.com\/_api\/v2\/monitoring\/network?cluster=myclustername&node=myloadbalancername&format=json\"\n\n{\n\"end\": 1512989748,\n\"start\": 1512989450,\n\"target_responses\": [\n{\n\"datapoints\":\n\n20247725.5,\n1512989450\n]\n],\n\"target\": \"myclustername Octets tx Per Second\"\n},\n{\n\"datapoints\":\n\n17697329.3046875,\n1512989450\n]\n],\n\"target\": \"myclustername Octets rx Per Second\"\n}\n]\n}\nShow more\n\nYou must explicitly specify the load balancer in the request.\n\n\n\n\n\n rate\/status_code \n\nSee an example of a rate\/status_code monitoring request:\n\ncurl \"https:\/\/$ACCOUNT.cloudant.com\/_api\/v2\/monitoring\/rate\/status_code?cluster=myclustername&format=json\"\n\nSee example results (abbreviated) from a rate\/status_code monitoring request:\n\n{\n\"start\": 1436194902,\n\"end\": 1436195202,\n\"target_responses\": [\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitoring-an-ibm-cloudant-cluster"},{"document_id":"ibmcld_13144-27584-28518","score":6.3407949538,"text":"\nyouyou@cloudshell:$ ibmcloud resource service-keys --instance-name $YOURINITIALS-cloudant-service --output json\n[\n{\n\"guid\": \"01234560-902d-4078-9a7f-20446a639aeb\",\n\"id\": \"crn:v1:bluemix:public:cloudantnosqldb:us-south:a\/0123456789507a53135fe6793c37cc74:SECRET\",\n\"url\": \"\/v2\/resource_keys\/01234560-902d-4078-9a7f-20446a639aeb\",\n\"created_at\": \"2020-05-06T23:03:43.484872077Z\",\n\"updated_at\": \"2020-05-06T23:03:43.484872077Z\",\n\"deleted_at\": null,\n\"name\": \"cloudant-binding\",\n\"account_id\": \"0123456789507a53135fe6793c37cc74\",\n\"resource_group_id\": \"01234567836d49029966ab5be7fe50b5\",\n\"source_crn\": \"crn:v1:bluemix:public:cloudantnosqldb:us-south:a\/0123456789507a53135fe6793c37cc74:SECRET\",\n\"state\": \"active\",\n\"credentials\": {\n\"apikey\": \"SECRET\",\n\"host\": \"SECRET\",\n\"iam_apikey_description\": \"Auto-generated for key SECRET\",\n\"iam_apikey_name\": \"cloudant-binding\",\n\"iam_role_crn\": \"SECRET\",\n\"iam_serviceid_crn\": \"SECRET\",\n\"password\": \"SECRET\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-openshift-microservices"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01150-4410-6468","score":24.3237434356,"text":"\nWhat is Event Streams's maximum message size? \n\nEvent Streams's maximum message size is 1 MB, which is the Kafka default.\n\n\n\n\n\n What are Event Streams's replication settings? \n\nEvent Streams is configured to provide strong availability and durability. The following configuration settings apply to all topics and cannot be changed:\n\n\n\n* replication.factor = 3\n* min.insync.replicas = 2\n\n\n\n\n\n\n\n What are the restrictions and defaults for topics and partitions? \n\n\n\n* Topic names are restricted to a maximum of 100 characters.\n* The default number of partitions for a topic is one.\n* Each IBM Cloud space has a limit of 100 partitions. To create more partitions, you must use a new IBM Cloud space.\n\n\n\n\n\n\n\n How do I check which Event Streams plan I've provisioned? \n\nTo confirm which type of Event Streams plan you've provisioned (Lite, Standard, or Enterprise), complete the following steps:\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams that you want to check.\n2. Click the Plan tab in the navigation pane on the left. The Current plan section displays your plan type.\n\n\n\n\n\n\n\n Can I change my Event Streams plan using the IBM Cloud console? \n\nYes, but only if you are moving from the Lite plan to the Standard plan.\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams Lite plan that you want to change.\n2. Click the Plan tab in the navigation pane on the left.\n3. In the Change pricing plan section, check the Standard box. Click Upgrade.\n\nAllow a few minutes for the cached limit of 1 partition for the Lite plan to clear so that you can take advantage of the 100 partition limit for the Standard plan.\n\nHowever, this option does not currently work in the IBM Cloud console for any other combination of plans. For example, if you try a different plan combination, you'll see an error message like the the following:\n\nCould not find VCAP::CloudController::ServicePlan with guid: ibm.eventstreams.standard\n\n\n\n\n\n\n\n What are the differences between the Event Streams Standard and Event Streams Enterprise plans?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-faqs"},{"document_id":"ibmcld_07578-699255-701206","score":23.5248551365,"text":"\nClick the Plan tab in the navigation pane on the left. The Current plan section displays your plan type.\n\n\n\n* Can I change my Event Streams plan using the IBM Cloud console?\n\nYes, but only if you are moving from the Lite plan to the Standard plan.\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams Lite plan that you want to change.\n2. Click the Plan tab in the navigation pane on the left.\n3. In the Change pricing plan section, check the Standard box. Click Upgrade.\n\nAllow a few minutes for the cached limit of 1 partition for the Lite plan to clear so that you can take advantage of the 100 partition limit for the Standard plan.\n\nHowever, this option does not currently work in the IBM Cloud console for any other combination of plans. For example, if you try a different plan combination, you'll see an error message like the the following:\n\nCould not find VCAP::CloudController::ServicePlan with guid: ibm.eventstreams.standard\n\n\n\n* What are the differences between the Event Streams Standard and Event Streams Enterprise plans?\n\nTo find out more information about the different Event Streams plans, see [Choosing your plan](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose).\n* How do I handle disaster recovery?\n\nCurrently, it is the responsibility of the user to manage their own Event Streams disaster recovery. Event Streams data can be replicated between an Event Streams instance in one location (region) and another instance in a different location. However, the user is responsible for provisioning a remote Event Streams instance and managing the replication.\n\nWe suggest a tool like Kafka MirrorMaker to replicate data between clusters. For information about how to run MirrorMaker, see [Event Streams kafka-mirrormaker repository](https:\/\/github.com\/ibm-messaging\/event-streams-samples\/tree\/master\/kafka-mirrormaker).\n\nThe user is also responsible for the backup of message payload data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-699213-701164","score":23.5248551365,"text":"\nClick the Plan tab in the navigation pane on the left. The Current plan section displays your plan type.\n\n\n\n* Can I change my Event Streams plan using the IBM Cloud console?\n\nYes, but only if you are moving from the Lite plan to the Standard plan.\n\n\n\n1. In the IBM Cloud console, navigate to the instance of Event Streams Lite plan that you want to change.\n2. Click the Plan tab in the navigation pane on the left.\n3. In the Change pricing plan section, check the Standard box. Click Upgrade.\n\nAllow a few minutes for the cached limit of 1 partition for the Lite plan to clear so that you can take advantage of the 100 partition limit for the Standard plan.\n\nHowever, this option does not currently work in the IBM Cloud console for any other combination of plans. For example, if you try a different plan combination, you'll see an error message like the the following:\n\nCould not find VCAP::CloudController::ServicePlan with guid: ibm.eventstreams.standard\n\n\n\n* What are the differences between the Event Streams Standard and Event Streams Enterprise plans?\n\nTo find out more information about the different Event Streams plans, see [Choosing your plan](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose).\n* How do I handle disaster recovery?\n\nCurrently, it is the responsibility of the user to manage their own Event Streams disaster recovery. Event Streams data can be replicated between an Event Streams instance in one location (region) and another instance in a different location. However, the user is responsible for provisioning a remote Event Streams instance and managing the replication.\n\nWe suggest a tool like Kafka MirrorMaker to replicate data between clusters. For information about how to run MirrorMaker, see [Event Streams kafka-mirrormaker repository](https:\/\/github.com\/ibm-messaging\/event-streams-samples\/tree\/master\/kafka-mirrormaker).\n\nThe user is also responsible for the backup of message payload data.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16729-112397-114109","score":23.252430286,"text":"\n[Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan)Migrating an Enterprise plan to a Lite or Standard plan\n\nMigration from the Enterprise plans to IBM Cloudant Lite or Standard plans includes these tasks, which are described in the following steps.\n\nCloudant\n\n\n\n* 30 minutes\n* 2023-04-06\n\n\n\n[Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan)Migrating from a Lite plan to a Standard plan\n\nMigrating from the free Lite plan to the Standard plan by completing the following tasks.\n\nCloudant\n\n\n\n* 15 minutes\n* 2023-04-06\n\n\n\n[Finding your IBM Cloudant plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan)Finding your IBM Cloudant plan\n\nYou can subscribe to different IBM Cloudant plans, including the Lite, Standard, or Enterprise plans.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30\n\n\n\n[Combining IBM Cloudant with other IBM services](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-combine-ibm-services)Combining IBM Cloudant with other IBM services\n\nEach database technology has its own strengths and weaknesses. Some are built for high availability and data durability (at the expense of more hardware and extra cost). Others favor speed and can churn out blazingly fast queries (but might lose data in a sudden power failure).\n\nCloudant\n\n\n\n* 2023-03-30\n\n\n\n[Enhance cloud security by applying context-based restrictions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_07578-447531-449109","score":23.1952220174,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-447513-449091","score":23.1952220174,"text":"\n[Upload](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00535-0-1738","score":23.1494926837,"text":"\n\n\n\n\n\n\n  Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\n  Which plans can I migrate? \n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n*  IBM Cloudant Enterprise\n*  Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\n  Can I back up my data before I migrate? \n\nThe IBM Cloudant team advises that you use the [couchbackup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\n  Can I keep my username.cloudant.com domain and redirect it to the new service on IBM Cloudant? \n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\n  Who do I contact if I have questions? \n\nGo to the [IBM Cloud Support portal](https:\/\/www.ibm.com\/cloud\/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-migration"},{"document_id":"ibmcld_05013-2864-3381","score":22.7627598468,"text":"\nCan I create more than one Object Storage service with a Lite account? \n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n\n\n\n\n\n What happens if I exceed the maximum usage allowed for a Lite plan? \n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq-provision"},{"document_id":"ibmcld_07578-1323355-1325090","score":22.7539995097,"text":"\nSelect the \"standard\" plan and hit save.\n\nIn cases where the instance has been locked due to exceeding the maximum allowed size of a Lite instance it may be necessary to use the CLI. The plan ID for a standard Object Storage instance is 744bfc56-d12c-4866-88d5-dac9139e0e5d (if curious, this can be found by issuing the CLI command ic catalog service cloud-object-storage). You'll need to know the name of the instance you are trying to upgrade. For example, to upgrade the instance \"My Object Storage\", you can issue the command:\n\nic resource service-instance-update \"My Object Storage\" --service-plan-id 744bfc56-d12c-4866-88d5- dac9139e0e5d\n* Are bucket names case-sensitive?\n\nBucket names are required to be DNS addressable and are not case-sensitive.\n* What is the maximum number of characters that can be used in a key, or Object name?\n\nKeys have a 1024-character limit.\n* What are some tools unable to render object names?\n\nObject names that contain unicode characters that are not allowed by the XML standard will result in \"Malformed XML\" messages. For more information, see [the XML reference documentation](https:\/\/www.w3.org\/TR\/xml\/charsets).\n* Can I create more than one Object Storage service with a Lite account?\n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n* What happens if I exceed the maximum usage allowed for a Lite plan?\n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.\n* How can I find out the total size of my bucket by using the API?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1326020-1327755","score":22.7539995097,"text":"\nSelect the \"standard\" plan and hit save.\n\nIn cases where the instance has been locked due to exceeding the maximum allowed size of a Lite instance it may be necessary to use the CLI. The plan ID for a standard Object Storage instance is 744bfc56-d12c-4866-88d5-dac9139e0e5d (if curious, this can be found by issuing the CLI command ic catalog service cloud-object-storage). You'll need to know the name of the instance you are trying to upgrade. For example, to upgrade the instance \"My Object Storage\", you can issue the command:\n\nic resource service-instance-update \"My Object Storage\" --service-plan-id 744bfc56-d12c-4866-88d5- dac9139e0e5d\n* Are bucket names case-sensitive?\n\nBucket names are required to be DNS addressable and are not case-sensitive.\n* What is the maximum number of characters that can be used in a key, or Object name?\n\nKeys have a 1024-character limit.\n* What are some tools unable to render object names?\n\nObject names that contain unicode characters that are not allowed by the XML standard will result in \"Malformed XML\" messages. For more information, see [the XML reference documentation](https:\/\/www.w3.org\/TR\/xml\/charsets).\n* Can I create more than one Object Storage service with a Lite account?\n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n* What happens if I exceed the maximum usage allowed for a Lite plan?\n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.\n* How can I find out the total size of my bucket by using the API?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07103-31052-33321","score":21.6722372878,"text":"\nYou cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments\n: Relevance and confidence scores are displayed for NLU enrichments that are returned by search. For example, when you open the JSON view of the document preview from a query result, you can see confidence scores for Entities mentions and relevance scores for Keyword mentions.\n\n\n\n\n\n 9 September 2021 \n\nNew location for Plus plan\n: The Plus plan is now available from the Sydney location. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product. For more information, see [Getting the most from Discovery](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nChange to Lite and Advanced plans in most locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 26 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_07103-29564-31587","score":19.7669448726,"text":"\nPreviously, the list included fields that were not valid choices.\n\n\n\n\n\n 14 October 2021 \n\nNew Discovery home page\n: A new home page is displayed when you start Discovery and gives you quick access to a product overview video, and tours. You can collapse the home page welcome banner to see more projects.\n\nNew plan usage section\n: Stay informed about plan usage and check your usage against the limits for your plan type from the Plan limits and usage page. From the product page header, click the user icon ![User icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/user--avatar.svg). The Usage section shows a short summary. Click View all to see usage information for all of the plan limit categories.\n\nChange to spelling settings in Search\n: The spelling correction setting changed from being enabled automatically in new projects to being disabled by default. If you want to alert users when they misspell a term in their query, turn on Spelling suggestions. For more information, see [Customizing the search bar](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-bar).\n\nImproved Guided tours availability\n: The Guided tours button is now available from the product page header, which make them accessible from anywhere. Previously, it was available from the My Projects page only.\n\n\n\n\n\n 1 October 2021 \n\nChange to Lite and Advanced plans in all locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_05013-2864-3381","score":19.3919657956,"text":"\nCan I create more than one Object Storage service with a Lite account? \n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n\n\n\n\n\n What happens if I exceed the maximum usage allowed for a Lite plan? \n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq-provision"},{"document_id":"ibmcld_07238-7-1755","score":19.3680824447,"text":"\nUpgrading your plan \n\nIBM Watson\u2122 Discovery offers three plans that provide different levels of resources and capabilities to suit your needs.\n\nSee [Discovery pricing plans](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans) and [Discovery catalog](https:\/\/cloud.ibm.com\/catalog\/services\/discovery) for details.\n\nYou cannot directly upgrade your plan from Lite to XS because XS plans are not suitable for production usage. If you have the Lite plan but want the XS plan, you must create a new instance by using the XS size and then manually recreate your collections. In addition, you cannot directly downgrade from S to XS. If you have the S plan but want the XS plan, follow the same steps in the case of moving to an XS plan from a Lite plan.\n\nYou cannot upgrade from a Lite (v1) plan to a Plus (v2) plan. And you cannot upgrade from an Advanced (v1) plan to a Premium (v2) plan. To start using v2, create a new Plus or Premium plan. For more information about Premium plan instances that were created on or after 16 July 2020 or about Plus (including Plus Trial) plan instances, see [these docs](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-upgrade).\n\n\n\n Upgrading your service \n\nTo resize your plan from Lite to Advanced:\n\n\n\n1. From the [resource list](https:\/\/cloud.ibm.com\/resources\/), click on your Discovery instance to go to the Discovery dashboard page.\n2. From the Manage page of Discovery, click Upgrade to choose the Advanced plan. Follow the steps on the Plan page to complete your upgrade.\n3. Return to the Manage page and click Launch Watson Discovery to open the Discovery tooling.\n\n\n\n* If you never created an environment for your Lite plan before the upgrade to Advanced, click the !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-upgrading-your-plan"},{"document_id":"ibmcld_07103-32746-34817","score":19.250958965,"text":"\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments. Use answer finding when you want to return a concise answer to a question. For more information, see [Answer finding](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parametersanswer-finding).\n\n\n\n\n\n 16 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the Frankfurt and Tokyo locations, in addition to Dallas.\n\nChange to Lite and Advanced plans in some locations\n: Lite and Advanced plans are no longer offered. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, or Tokyo locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 27 July 2021 \n\nImproved document size limit\n: Document size limit is increased. For Premium plan collections, you can now upload files that are up to 50 MB in size instead of 32 MB. For more information, see [Document limits](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collectionscollections-doc-limits).\n\n\n\n\n\n 23 July 2021 \n\nImproved SharePoint Online connector\n: The Microsoft SharePoint Online data source connector now accepts any valid Azure Active Directory user ID syntax; the format of the user ID doesn't need to match the <admin_user>@.onmicrosoft.com syntax. For more information, see [Microsoft SharePoint Online](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-sharepoint-online-cloud).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_11142-7-1829","score":18.9522382593,"text":"\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https:\/\/cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free"},{"document_id":"ibmcld_01316-2609-4002","score":18.8240037797,"text":"\nWatson IoT Platform Standard The Standard service plan includes the free data-transfer limit that is offered in the Lite plan and then usage-based billing beyond the free quote for data exchanged, data analyzed, and edge data analyzed. \n Watson IoT Platform Advanced Security The Advanced Security service plan includes the free data-transfer limit that is offered in the Lite plan and then usage-based billing beyond the free quote for data exchanged, data analyzed, and edge data analyzed. This plan also provides advanced Risk and Security Management features. \n\n\n\n\n\n\n\n\n\n Upgrading service plans \n\nIf you are an existing customer and want to take advantage of the full [Watson IoT Platform feature set ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.ibm.com\/support\/knowledgecenter\/SSQP8H\/iot\/overview\/overview.html), you can purchase one of the Connection and Analytics Service plans and then migrate your existing environment.\n\nTo migrate plans, contact your IBM\u00ae representative or raise a support ticket.\n\nTo migrate from Watson IoT Platform Lite plan, or to migrate to other plans with only the essential configuration settings included, see the instructions in [Migrating Watson IoT Platform Lite to Watson IoT Platform Non-production or Production](https:\/\/cloud.ibm.com\/docs\/services\/IoT?topic=IoT-org_migrationorg_migration).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/IoT?topic=IoT-plans_overview"},{"document_id":"ibmcld_13336-7-1965","score":18.7450610715,"text":"\nPricing FAQs \n\nIBM Cloud\n\nThe IBM Watson\u00ae Speech to Text service is available at three pricing plans: Lite, Plus, and Premium. The following FAQs provide an overview of the pricing plans. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text).\n\nThe Standard plan is no longer available for purchase by users. The Standard plan continues to be available to its existing users indefinitely. For more information, see [Can I continue to use the Speech to Text Standard plan?](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricingfaq-pricing-standard) For new users, read about the new Plus and Premium plans below.\n\n\n\n What is the price for using the Speech to Text Lite plan? \n\nThe Lite plan lets you get started with 500 minutes per month of speech recognition at no cost. You can use any available model for speech recognition. The Lite plan does not provide access to customization. You must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n\n\n\n\n\n What is the price for using the Speech to Text Plus plan? \n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricing"},{"document_id":"ibmcld_07578-47319-49349","score":18.6748889225,"text":"\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https:\/\/cloud.ibm.com\/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-47304-49334","score":18.6748889225,"text":"\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https:\/\/cloud.ibm.com\/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02698-7-1759","score":20.0062826699,"text":"\nIntegrating SDKs \n\nThe App Configuration client SDK is available for Android, JavaScript, and React, the server SDKs for Node, Python, Go, and Java, and the admin SDK for Go, to integrate with your web and mobile applications, microservices, and distributed environments.\n\n\n\n Client-side and Server-side SDKs \n\nUnderstand the differences between the various SDKs so that you can decide between SDK types for your use case.\n\n\n\n Types of SDKs \n\nSDKs supported by App Configuration include:\n\n\n\n* Server-side SDK\n* Client-side SDK\n* Admin SDK\n\n\n\nSDKs that help evaluate feature flag and property values are broadly classified as Server-side or Client-side - based on the deployment environment. These SDKs can be integrated into your application to assess the feature or property values by considering segment targeting rules, if any.\n\nEvaluation SDKs fetch the latest configuration data from the App Configuration service and ensure that any change in the service configuration is made available to your application in real time.\n\nAdmin SDKs can be used to create and manage configurations for Environments, Collections, Feature flags, Properties, and Segments. As an option to IBM Cloud Dashboard or IBM Cloud CLI, Admin SDKs can be used to programmatically manage your service configuration from within your application.\n\nThe currently available Go language Admin SDK integrates with your Go application.\n\nDifferences between client-side and server-side SDKs:\n\n\n\nTable 1. List of App Configuration server, client, and admin SDKs\n\n SDK type Details Links to SDKs and integration docs \n\n Server side These SDKs are designed for multi-user systems and are intended to be used in a trusted environment, such as inside a corporate network or on a web server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-sdks"},{"document_id":"ibmcld_00620-14227-15704","score":19.5734223296,"text":"\nThe previous Go example requires the following import block: import (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n\"github.com\/IBM\/go-sdk-core\/core\"\nAll Go examples require the service object to be initialized. For more information, see the API documentation's Authentication section]] ! ! ! ! for examples.This option works, but you end up fetching n+1 documents when only n are required.<-- <\/section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --><-- <section \"id=\"section-option-2-the-u0000-trick\" \"> --> Option 2 - The \\u0000 trick If you're determined to fetch only n documents each time, then you need to calculate a value of startkey, which means the next ID after the last _id in the result set. For example, if the last document in the first page of results is \"example\", what must the startkey of the next call to _all_docs be? It can't be \"example\", otherwise you get the same document ID again. It turns out that you can append u0000 to the end of a key string to indicate the \"next key\" (u0000 is a Unicode null character, which can be placed in a URL as-is or with the percent code %00). ).See the following example of a first request:<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> curl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=5\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.DocsResultRow;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_12343-7-1769","score":19.2789806227,"text":"\nPython \n\nGiven its ease of use and adoption for data science applications, [Python](https:\/\/www.python.org\/) support is imperative to increase adoption of your IBM Cloud service. Supporting Python applications using [Flask](https:\/\/github.com\/pallets\/flask), [Django](https:\/\/www.djangoproject.com\/), [Jupyter](https:\/\/jupyter.org\/), and functional programming paradigms introduces special considerations that need to be observed by your SDK.\n\n\n\n Environment support \n\n\n\n* Your Python SDK should be written to support all [Python >=3.5](https:\/\/www.python.org\/downloads\/) releases.\n* Ensure your SDK is compatible with data science usecases, such as [Jupyter Notebooks](https:\/\/jupyter.org\/).\n\n\n\n\n\n\n\n Publishing \n\nAll Python SDKs should be publicly available on an [IBM GitHub organization](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributionopen-source). The releases of these SDKs should be published on [PyPI](https:\/\/pypi.org\/).\n\nYour SDK should follow the [semantic versioning best practices](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributionsemantic-versioning).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [PEP8 style guide for Python](https:\/\/www.python.org\/dev\/peps\/pep-0008\/), with a few modifications, like four spaces instead of tabs for indentation.\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-developer-tools) for Python to check style and code coverage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-python"},{"document_id":"ibmcld_12341-2467-4426","score":18.973278538,"text":"\nUse a well-defined, well-documented request library that includes browser support, like [axios](https:\/\/github.com\/axios\/axios), [superagent](https:\/\/github.com\/visionmedia\/superagent), or [node-fetch](https:\/\/github.com\/node-fetch\/node-fetch).\n\n\n\n\n\n Objects for arguments \n\nThe methods in your SDK should take a JSON object as an argument. This object will contain the options for the requests, instead of using positional parameters in the function definition.\n\n\n\n\n\n Async architecture \n\nAll network calls from your SDK should be asynchronous. All asynchronous calls should be handled using Promises, not callbacks.\n\n\n\n\n\n Standard features \n\n\n\n\n\n Authentication \n\nYou are not required to use a particular library to provide the authentication for your service.\n\nYour SDK must support all of the authentication methods for your service.\n\n\n\n\n\n Configuration \n\nIn the interests of making your SDK easy to consume and cloud native, you should provide the ability to read in environment variables. Abstracting the application logic from the environment logic allows your users to focus on using your service capabilities their applications.\n\nIf you build this capability into your SDK, you must document this mechanism clearly with examples.\n\n\n\n\n\n Using node-sdk-core \n\n[IBM node-sdk-core](https:\/\/github.com\/IBM\/node-sdk-core) provides configuration and authentication support. You can use the existing functionality provided by this dependency in your SDK.\n\n\n\n\n\n Documentation \n\nYour SDK is not useful if your audience cannot understand how to consume it in order to do the basic operations for your service. Your SDK needs to contain the following resources to help your users:\n\n\n\n* README.md\n* NPM metadata\n* [Contributor guidelines](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentationsdk-contributor-docs)\n* Code Samples\n* [Service documentation](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentation)\n\n\n\n\n\n\n\n Samples","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-node"},{"document_id":"ibmcld_12341-1239-2954","score":18.8670945648,"text":"\nThe releases of these SDKs should be published on [NPM](https:\/\/www.npmjs.com\/). Your NPM package should be [scoped](https:\/\/docs.npmjs.com\/creating-and-publishing-scoped-public-packagescreating-a-scoped-public-package) with [@ibm-cloud](https:\/\/www.npmjs.com\/search?q=%40ibm-cloud), so that NPM users can find similar packages across NPM.\n\nYour SDK should follow the [semantic versioning best practices](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributiondistribution-semver).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [Airbnb conventions](https:\/\/github.com\/airbnb\/javascript), with two spaces for indentation.\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools) for JavaScript to check style and code coverage.\n\n\n\n\n\n Streaming support \n\nIf your API takes fileType parameters, you should accept Node.js streams as an input type.\n\n\n\n\n\n Dependencies \n\nUse a well-defined, well-documented request library that includes browser support, like [axios](https:\/\/github.com\/axios\/axios), [superagent](https:\/\/github.com\/visionmedia\/superagent), or [node-fetch](https:\/\/github.com\/node-fetch\/node-fetch).\n\n\n\n\n\n Objects for arguments \n\nThe methods in your SDK should take a JSON object as an argument. This object will contain the options for the requests, instead of using positional parameters in the function definition.\n\n\n\n\n\n Async architecture","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-node"},{"document_id":"ibmcld_12271-0-1282","score":18.7703733991,"text":"\n\n\n\n\n\n\n  Schematics SDKs \n\nIBM Cloud\u00ae Schematics simplifies application development by abstracting much of the complexity of deploying application environments. Schematics SDKs are provided in multiple programming languages to assist application developers to integrate Schematics IaC operations into continuous integration and continuous delivery (CI\/CD) tools and pipelines.\n\nFollowing are the list of IBM Cloud Schematics server SDKs that are available for Node, Python, Go, and Java. For more information about installation and technical concepts, see readme file in the SDK documentation.\n\n\n\nList of Schematics SDKs\n\n Server SDKs     SDK Documentation            \n\n [Go SDK](https:\/\/github.com\/IBM\/schematics-go-sdk)      [Go SDK documentation](https:\/\/github.com\/IBM\/schematics-go-sdk\/blob\/main\/README.md)     \n [Java SDK](https:\/\/github.com\/IBM\/schematics-java-sdk)    [Java SDK documentation](https:\/\/github.com\/IBM\/schematics-java-sdk\/blob\/main\/README.md)   \n [Node SDK](https:\/\/github.com\/IBM\/schematics-node-sdk)    [Node SDK documentation](https:\/\/github.com\/IBM\/schematics-node-sdk\/blob\/main\/README.md)   \n [Python SDK](https:\/\/github.com\/IBM\/schematics-python-sdk)  [Python SDK documentation](https:\/\/github.com\/IBM\/schematics-python-sdk\/blob\/main\/README.md) \n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-schematics-sdks"},{"document_id":"ibmcld_12343-2679-4417","score":18.7403170401,"text":"\nIn the interests of making your SDK easy to consume and cloud native, you should provide the ability to read in environment variables. Abstracting the application logic from the environment logic allows your users to focus on using your service capabilities their applications.\n\nIf you build this capability into your SDK, you must document this mechanism clearly with examples.\n\n\n\n\n\n Using python-sdk-core \n\n[IBM python-sdk-core](https:\/\/github.com\/IBM\/python-sdk-core) provides configuration and authentication support. You can use the existing functionality provided by this dependency in your SDK.\n\n\n\n\n\n Documentation \n\nYour SDK is not useful if your audience cannot understand how to consume it in order to do the basic operations for your service. Your SDK needs to contain the following resources to help your users:\n\n\n\n* README.md\n* [Contributor guidelines](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentationsdk-contributor-docs)\n* Code Samples\n* [Service documentation](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentation)\n\n\n\n\n\n\n\n Samples \n\nFor your Python SDK, you will want some simple code samples and explanations of what each does. Linking out to the API reference documentation for more advanced use is strongly encouraged.\n\nAt minimum, the samples should be included in the README.md file. They should communicate how to install the library, and complete the basic operations provided by your API.\n\nThe samples should include simple installation and initialization instructions for the popular frameworks and data science tools. Additional examples should be available in an \/examples directory for more advanced operations which can be copied and pasted in to user applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-python"},{"document_id":"ibmcld_00462-1307-2903","score":18.5580744354,"text":"\nThe IBM Cloudant SDK for Python library is the official IBM Cloudant library for Python.\n\nInstall the [IBM Cloudant SDK for Python](https:\/\/pypi.org\/project\/ibmcloudant\/) library by running pip or easy_install as shown in the following examples:\n\npip install --upgrade \"ibmcloudant>=0.0.27\"\n\nor\n\neasy_install --upgrade \"ibmcloudant>=0.0.27\"\n\nFor more information, see the [python.org](https:\/\/www.python.org\/about\/) website.\n\n\n\n Library for Python \n\n\n\n* [IBM Cloudant SDK for Python](https:\/\/github.com\/IBM\/cloudant-python-sdk)\n\n\n\n\n\n\n\n\n\n Go \n\nThe IBM Cloudant SDK for Go library is the official IBM Cloudant library for Go.\n\nInstall the [IBM Cloudant SDK for Go](https:\/\/pkg.go.dev\/mod\/github.com\/IBM\/cloudant-go-sdk) library by running the following command:\n\ngo get -u github.com\/IBM\/cloudant-go-sdk\/cloudantv1\n\n\n\n Library for Go \n\n\n\n* [IBM Cloudant SDK for Go](https:\/\/github.com\/ibm\/cloudant-go-sdk)\n\n\n\n\n\n\n\n\n\n Useful tools \n\nYou can use the following tools with IBM Cloudant.\n\n\n\n Supported tools \n\nSupported tools are maintained and supported by IBM Cloudant.\n\n\n\n couchbackup \n\nA tool that you use from the command line to back up an IBM Cloudant or CouchDB database to a text file.\n\nTo install couchbackup, run the following command by using npm:\n\nnpm install -g @cloudant\/couchbackup\n\nFor more information, see [couchbackup](https:\/\/github.com\/cloudant\/couchbackup).\n\n\n\n\n\n\n\n Unsupported tools \n\nUnsupported tools are not maintained or supported by IBM Cloudant.\n\n\n\n cURL \n\nA tool that you use from the command line to transfer data.\n\nFor more information, see [curl](https:\/\/curl.haxx.se\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-client-libraries"},{"document_id":"ibmcld_00620-8515-9974","score":18.3429922669,"text":"\npanic(err)\n}\nb, _ := json.MarshalIndent(allDocsResult3, \"\", \" \")\nfmt.Println(string(b))\nThe previous Go example requires the following import block: import (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n\"github.com\/IBM\/go-sdk-core\/core\"\n)\nAll Go examples require the service object to be initialized. For more information, see the API documentation's Authentication section]] ! ! ! ! ! for examples.This practice means you define the size of the data set and the range of the _id field to return, but that isn't quite the same as pagination.The startkey\/endkey values are in double quotation marks because they're expected to be JSON-encoded and JSON.stringify('order00077') === \"order00077\".<-- <\/section \"id=\"section-the-limit-startkey-endkey-parameters\" \"> --><-- <section \"id=\"section-pagination-options\" \"> --> Pagination options For performance reasons, if you are displaying large amounts of data, you must consider using pagination. In these examples, documents are fetched in blocks of five. However, in a real application, the page size might be different and depends on document size, latency demands, memory consumption, and other tradeoffs.You can use the options that are described in the following sections.<-- <section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --> Option 1 - Fetch one document too many Instead of fetching five documents (limit=5), fetch 5+1 (limit=6), but hide the sixth document from your users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_00589-18424-20018","score":18.0655236164,"text":"\n* [cloudant-java-sdk](https:\/\/github.com\/IBM\/cloudant-java-sdk\/releases)\n\n\n\nFor an example that uses IBM Cloudant SDK for Java, see the [API and SDK documentation](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=javaauthentication).\n\n\n\n\n\n Node.js \n\nThe following link provides the latest supported version of the IBM Cloudant Node.js library:\n\n\n\n* [cloudant-node-sdk](https:\/\/github.com\/IBM\/cloudant-node-sdk\/releases)\n\n\n\nFor an example that uses IBM Cloudant SDK for Node, see the [API and SDK documentation](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=nodeauthentication).\n\n\n\n\n\n Python \n\nThe following link provides the latest supported version of the IBM Cloudant Python library:\n\n\n\n* [cloudant-python-sdk](https:\/\/github.com\/IBM\/cloudant-python-sdk\/releases)\n\n\n\nFor an example that uses IBM Cloudant SDK for Python, see the [API and SDK documentation](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=pythonauthentication).\n\n\n\n\n\n Go \n\nThe following link provides the latest supported version of the IBM Cloudant Go library:\n\n\n\n* [go-sdk](https:\/\/github.com\/IBM\/cloudant-go-sdk\/releases)\n\n\n\nFor an example that uses IBM Cloudant SDK for Go, see the [API and SDK documentation](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication).\n\n\n\n\n\n\n\n Access by using HTTP client \n\nIBM Cloud IAM requires that an IAM API key is exchanged for a time-limited access token before you make a request to a resource or service. The access token is then included in the Authorization HTTP header to the service. When the access token expires, the client must handle getting a new one from the IAM token service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1934264036}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03080-7-1901","score":34.3839110013,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16368-7-2072","score":33.9396565196,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_03421-4-1877","score":33.7410941369,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16295-7-1721","score":33.0322621006,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_03421-1518-3290","score":32.777579927,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16326-1697-3495","score":32.4829247388,"text":"\nFor more information, see [Changing background website](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"},{"document_id":"ibmcld_16365-12876-14604","score":32.2527731647,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03080-1529-3357","score":31.876645818,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16295-1365-2938","score":30.5584189503,"text":"\nThe script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5. Edit the HTML source for the web page where you want the web chat widget to appear. Paste the code snippet into the page. Paste the code as close as possible to the closing <\/body> tag to ensure that your page renders faster.\n\nDo not modify the integrationID or region property values in the generated embed script.\n\nIf you aren't ready to add the web chat to a live website, you can quickly test it using a local HTML file. Use this HTML code as the source for a test page:\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n\nJust copy this code into a file with the .html extension, and replace the script element with the embed script you copied in the previous step.\n\nThe identifiers in the embed script (such as integrationIDserviceInstanceID) are not considered secret, and are visible to anyone who has access to your website. For more information, see [Security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architectureweb-chat-architecture-security).\n6. If the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the URLs that host the web chat are accessible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16365-11574-13329","score":30.4075007709,"text":"\nAnyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website. For more information, see [Web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n Updating site security policies \n\nIf your website uses a Content Security Policy (CSP), you must update it to grant permission to the web chat.\n\nThe following table lists the values to add to your CSP.\n\n\n\nCSP properties\n\n Property Additional values \n\n default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline' \n connect-src *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watson.appdomain.cloud\" \/>\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16368-7-2072","score":37.4676855242,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16295-7-1721","score":37.4670774464,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_03080-7-1901","score":36.7909579784,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03421-4-1877","score":36.1506057553,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16365-12876-14604","score":35.8260591304,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03421-1518-3290","score":35.2660809212,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16326-1697-3495","score":34.4272346497,"text":"\nFor more information, see [Changing background website](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"},{"document_id":"ibmcld_03080-1529-3357","score":34.1498590871,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16365-11574-13329","score":34.1399808218,"text":"\nAnyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website. For more information, see [Web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n Updating site security policies \n\nIf your website uses a Content Security Policy (CSP), you must update it to grant permission to the web chat.\n\nThe following table lists the values to add to your CSP.\n\n\n\nCSP properties\n\n Property Additional values \n\n default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline' \n connect-src *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watson.appdomain.cloud\" \/>\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16295-1365-2938","score":33.9151431408,"text":"\nThe script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5. Edit the HTML source for the web page where you want the web chat widget to appear. Paste the code snippet into the page. Paste the code as close as possible to the closing <\/body> tag to ensure that your page renders faster.\n\nDo not modify the integrationID or region property values in the generated embed script.\n\nIf you aren't ready to add the web chat to a live website, you can quickly test it using a local HTML file. Use this HTML code as the source for a test page:\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n\nJust copy this code into a file with the .html extension, and replace the script element with the embed script you copied in the previous step.\n\nThe identifiers in the embed script (such as integrationIDserviceInstanceID) are not considered secret, and are visible to anyone who has access to your website. For more information, see [Security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architectureweb-chat-architecture-security).\n6. If the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the URLs that host the web chat are accessible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16368-7-2072","score":30.5763097301,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16384-1889-3334","score":29.4681731361,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16384-7-2422","score":27.9924028396,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16295-7-1721","score":27.7979467404,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_03080-7-1901","score":27.4603345763,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_02855-5574-7284","score":27.2110160597,"text":"\nFor more information, see the [Using a custom launcher tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Changing the size or position of the chat window that is displayed when users click the launcher button. For more information, see the [Render to a custom element tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n\n\n\n14. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/web-chat-window.png)\n\nThe traffic to and from the web chat is sent between the instance that is hosted by your deployed cluster environment and the web page where you embed the web chat.\n15. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere that you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n16. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03421-4-1877","score":27.1584242247,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03166-4-2012","score":26.7279122332,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https:\/\/medium.com\/ibm-watson\/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_03166-8640-10452","score":26.7100617723,"text":"\nFor more information, see [Applying advanced customizations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config).\n4. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/web-chat-window.png)\n5. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere where you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n6. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf the Connect to agent button is displayed and you don't have human agent support configured, you can hide it by changing the Suggestions configuration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nA developer can use APIs to apply more advanced customizations to the style of the web chat. For more information, see [Applying advanced customizations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config).\n\n\n\n\n\n Launcher appearance and behavior","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_03421-1518-3290","score":26.4269822212,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.530721274,"ndcg_cut_10":0.530721274}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16365-12876-14604","score":25.3882136457,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16365-11574-13329","score":24.8581340575,"text":"\nAnyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website. For more information, see [Web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n Updating site security policies \n\nIf your website uses a Content Security Policy (CSP), you must update it to grant permission to the web chat.\n\nThe following table lists the values to add to your CSP.\n\n\n\nCSP properties\n\n Property Additional values \n\n default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline' \n connect-src *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watson.appdomain.cloud\" \/>\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03422-13387-15045","score":24.8499626292,"text":"\nconnect-src *.watsonplatform.net *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watsonplatform.net .watson.appdomain.cloud\" \/>\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements, such as <script> and <style> tags, to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta http-equiv=\"Content-Security-Policy\" content=\"default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'nonce- ';connect-src *.watsonplatform.net *.watson.appdomain.cloud\"\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Security measures \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security"},{"document_id":"ibmcld_03180-5630-7213","score":24.3793046625,"text":"\nEnabling visitor authentication also enables support for cross-domain traffic and cross-browser identification. For more information, see the [Zendesk documentation](https:\/\/support.zendesk.com\/hc\/en-us\/articles\/360022185314-Enabling-authenticated-visitors-in-the-Chat-widget).\n\nBefore you can secure the Zendesk connection, complete the following required tasks:\n\n\n\n1. Secure the web chat. For more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n\/\/ Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n\/\n* Returns a signed JWT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"},{"document_id":"ibmcld_16388-7-1918","score":24.2436235865,"text":"\nEncrypting sensitive data \n\nBy using the public key that is provided by IBM, you can add another level of encryption to hide sensitive data you send from the web chat.\n\nTo use this method for encrypting data, you must first enable the web chat security feature. For more information, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nUse this method to send sensitive information in messages that come from your website, such as information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from actions. Information passed to your assistant in this way is stored in a private context variable. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for a standard customer. You do not want non-VIPs to know that they are categorized as such, but you must pass this information to your action so it can change the flow of the conversation. To do this, you can pass the customer MVP status as an encrypted variable. This private context variable is available for use by the action, but not by anything else.\n\n![development icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/development-icon.png)Tutorial: For a tutorial that shows an example of using web chat security to authenticate users and protect sensitive data, see [Tutorial: Authenticating a user in the middle of a session](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-security).\n\nTo encrypt sensitive data:\n\n\n\n1. On the Security tab of the web chat integration settings, click the Generate key button.\n2. Copy the public key that displays in the IBM-provided public key field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-encrypt"},{"document_id":"ibmcld_16326-1697-3495","score":24.1718943544,"text":"\nFor more information, see [Changing background website](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"},{"document_id":"ibmcld_16387-7-1890","score":24.0678953874,"text":"\nEnabling web chat security \n\nTo enable web chat security, you must make changes to your web application server code and the web chat embed script, as well as the web chat integration settings.\n\n\n\n Before you begin \n\nBefore you enable security, you must create an RS256 public\/private key pair. You can use a tool such as OpenSSL or PuTTYgen.\n\nFor example, to create the key pair at a command prompt using OpenSSL, you would use the command openssl genrsa -out key.pem 2048.\n\nSave the generated key pair in a secure location.\n\nMake sure these keys are accessible only by your server code. Never pass them to a client browser through your website.\n\n\n\n\n\n Generating a JWT \n\nTo use web chat security, you must configure the web chat on your website to send a JSON Web Token (JWT) with each message to the assistant. The JWT is used to verify the origin of messages sent from your website, and optionally to carry additional encrypted data. Your website will need to be able to generate a new JWT at the beginning of each session, and also whenever an existing JWT expires.\n\nDo not hardcode a JWT in your website code or share JWTs between users.\n\nOn your server, implement a function that generates and returns a JSON Web Token (JWT) that is signed with your private key. You will use this token to verify the origin of messages sent from your website, and optionally to carry additional encrypted data.\n\nMost programming languages offer JWT libraries that you can use to generate a token. To validate signed JWTs, the web chat integration uses the [jsonwebtoken](https:\/\/www.npmjs.com\/package\/jsonwebtoken) library with the RS256 algorithm.\n\nThe JWT payload must specify the following claims:\n\n\n\n* sub: A unique user ID that identifies the customer who is interacting with the web chat. This can be either a generated unique identifier (for anonymous users) or an authenticated user ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable"},{"document_id":"ibmcld_16298-4831-6878","score":23.9443281734,"text":"\nAgent status is set to Invisible unless it is explicitly changed.\n\n\n\n\n\n Turn on Agent Workspace \n\nZendesk Agent Workspace brings Zendesk Chat and Zendesk Support together, so all your customer interactions are in one place, and communication is seamless, personal, and efficient. That means more productive agents and happy customers.\n\nIn Zendesk:\n\n\n\n1. Click the Products icon and go to the Admin Center.\n2. Click Workspaces.\n3. Click the Turn on Agent Workspace button. The green On box should display.\n\n\n\nAgent Workspace should now feature on several screens in Zendesk Support, including on the Dashboard with tickets, the Visitors page, and in the top menu as Conversations where agents can accept chats from customers waiting for assistance.\n\n\n\n\n\n\n\n Securing the transfer to Zendesk \n\nYou must collect the name and email address of each user, if enabling security in Zendesk. This information must be passed to the web chat so it can be provided to Zendesk when the conversation is transferred.\n\nWhen you add security to your Zendesk integration, you ensure that the visitors you are helping are legitimate customers. Enabling visitor authentication also enables support for cross-domain traffic and cross-browser identification. For more information, see the [Enabling authenticated visitors in Zendesk](https:\/\/support.zendesk.com\/hc\/en-us\/articles\/360022185314-Enabling-authenticated-visitors-in-the-Chat-widget).\n\nBefore you can secure the Zendesk connection, complete the following required tasks:\n\n\n\n1. Secure the web chat. For more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-zendesk"},{"document_id":"ibmcld_16385-7-2272","score":23.6643054383,"text":"\nOverview: Securing the web chat \n\nIf you enable security, you can configure the web chat to authenticate users, protect private data, and restrict access to your assistant.\n\nAll messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS), which protects sensitive data as it travels through the network. However, there are still potential security exposures that you might need to protect against. By enabling the web chat security feature and updating your website code appropriately, you can add the following protections:\n\n\n\n* You can prevent unauthorized websites from sending messages to your assistant, even if they copy your web chat embed script. (The unique identifiers in the embed script, such as the integration ID and service instance ID, are visible to anyone who has access to your website.)\n* You can securely authenticate customers in order to control access to features of your assistant that require authorization.\n* You can encrypt sensistive data so that customers cannot see it, while still allowing your assistant to access it.\n\n\n\nWeb chat security uses JSON Web Tokens (JWTs), which are data objects that are sent with each message from your website to the Watson Assistant service. Because a JWT is digitally signed using a private encryption key that only you have, it ensures that each message originates with your website. The JWT payload can also be used to securely authenticate users and carry encrypted private data.\n\nFor detailed information about JSON Web Tokens, see the [JWT specification](https:\/\/tools.ietf.org\/html\/rfc7519)).\n\nEnabling web chat security involves making the following customizations:\n\n\n\n* Implementing web application server code that generates a JWT signed with your private encryption key\n* Customizing the web chat configuration to provide the generated JWT\n* Enabling security in the web chat security settings\n\nAfter you enable web chat security, any message received by the web chat integration that is not accompanied by a properly signed JWT will be rejected.\n\n\n\nFor detailed information about how to complete these steps, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security"},{"document_id":"ibmcld_16384-7-2422","score":23.5194476644,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1845756968}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03080-7-1901","score":30.4311774743,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03421-4-1877","score":30.264664253,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16368-7-2072","score":28.636169806,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16295-7-1721","score":28.2806292921,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16368-1661-3409","score":27.7937100893,"text":"\nFor more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages). By subscribing to events, you can implement custom behavior or even intercept and modify message content. For more information about the event system, see [Events](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-events) in the web chat API reference.\n\n\n\nIf you want to use the web chat API to customize your web chat implementation, you don't have to start from scratch. Tutorials are available that show examples of common web chat customizations. For more information, see [Web chat development tutorials](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-tutorials).\n\n\n\n Development tasks \n\nYou can use the web chat API to customize and extend the web chat in the following ways.\n\nWeb chat style and content\n: \n\n* [Customizing the look of the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developlook)\n* [Customizing the home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develophome-screen)\n* [Customizing strings](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developstrings)\n* [Supporting global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-developglobal-audiences)\n\n\n\nOpening, closing, and rendering the web chat window\n:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_03421-1518-3290","score":27.3043657891,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03080-1529-3357","score":27.0582428552,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03166-4-2012","score":26.8497465087,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https:\/\/medium.com\/ibm-watson\/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16375-1468-2933","score":26.4413117483,"text":"\n\/\/ A UUID like '1d7e34d5-3952-4b86-90eb-7c7232b9b540' included in the embed code provided in Watson Assistant.\nintegrationID: \"YOUR_INTEGRATION_ID\",\n\/\/ Your assistants region e.g. 'us-south', 'us-east', 'jp-tok' 'au-syd', 'eu-gb', 'eu-de', etc.\nregion: \"YOUR_REGION\",\n\/\/ A UUID like '6435434b-b3e1-4f70-8eff-7149d43d938b' included in the embed code provided in Watson Assistant.\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE_ID\",\n\/\/ The callback function that is called after the widget instance has been created.\nonLoad: function(instance) {\ninstance.render();\n},\nshowLauncher: false, \/\/ Hide the web chat launcher, you will open the WebView from your mobile application\nopenChatByDefault: true, \/\/ When the web chat WebView is opened, the web chat will already be open and ready to go.\nhideCloseButton: true \/\/ And the web chat will not show a close button, instead relying on the controls to close the WebView\n};\nsetTimeout(function(){const t=document.createElement('script');t.src=\"https:\/\/web-chat.global.assistant.watson.appdomain.cloud\/versions\/\" + (window.watsonAssistantChatOptions.clientVersion || 'latest') + \"\/WatsonAssistantChatEntry.js\";document.head.appendChild(t);});\n<\/script>\n<\/body>\n<\/html>\nShow more\n\nIn your app, make sure you include logic to hide your web chat launching mechanism when the device is offline. If the device goes offline in the middle of a conversation, appropriate error messages and retries occur.\n\n\n\n\n\n Using a JavaScript bridge","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-mobile"},{"document_id":"ibmcld_16326-1697-3495","score":26.4144400465,"text":"\nFor more information, see [Changing background website](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.636439181}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16295-7-1721","score":27.0935652684,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_03080-7-1901","score":26.3575385074,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03421-4-1877","score":26.0272515426,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16365-12876-14604","score":25.5144339511,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16368-7-2072","score":25.4945366449,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_03166-4-2012","score":25.3987363141,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https:\/\/medium.com\/ibm-watson\/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16366-7-1826","score":24.8790986878,"text":"\nWeb chat setup overview \n\nYou can modify the web chat integration settings to configure the styling and appearance of the web chat.\n\nYou can quickly deploy and test the web chat integration using the default settings. However, before you go to production with your chatbot, you will need to configure the web chat to integrate with your website and better serve the needs of your customers.\n\nAt a minimum, you should update the following basic settings for your assistant:\n\n\n\n* The [assistant name](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style) that you want to show to your customers\n* The contents of the [home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen)\n* The [suggestions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-suggestions) your assistant will offer if customers get stuck\n\n\n\nYou might also want to make additional configurations, such as changing the web chat colors to match your branding, changing the launcher greeting, or enabling encryption.\n\nIf you are a developer, you can customize the web chat by using the web chat API. With the API, you can customize the styling, change the behavior of the web chat widget and launcher, customize strings, modify message content, and more. For more information about using the web chat API, see [Web chat development overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop).\n\nTo change the web chat configuration, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click Open. The Open web chat window opens.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config"},{"document_id":"ibmcld_16326-1697-3495","score":24.7104941984,"text":"\nFor more information, see [Changing background website](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"},{"document_id":"ibmcld_16365-7-1700","score":24.4604929111,"text":"\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16384-7-2422","score":24.4338068202,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02185-4-2040","score":14.2270460942,"text":"\n* UI\n* Terraform\n\n\n\n\n\n\n\n Creating dynamic rules for access groups \n\nYou can create dynamic rules to automatically add federated users to access groups based on specific identity attributes. When your users log in with a federated ID, the data from the identity provider (IdP) dynamically maps your users to an access group based on the rules that you set.\n\nUsers already have specific identity information within your company's domain, and when they log in with a federated ID, this data can be passed through by using SAML assertions. The SAML assertions or attribute statements that are configured within the IdP provide the data that is used to create each rule. For example, you might have a true or false attribute statement that defines users as a manager. This information can be used to add all users who are managers to a specific access group for managers that you created in your IBM Cloud\u00ae account. For more information, see the tutorial about how to [Control access to cloud resources](https:\/\/developer.ibm.com\/tutorials\/use-iam-access-groups-to-effectively-manage-access-to-your-cloud-resources\/) and an [Example rule](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rulesexample).\n\nOnly users who are already invited to the account can be mapped to access groups by using dynamic rules.\n\n\n\n Setting up rules by using the console \n\nDynamic rules are created by setting conditions that must be matched by the data that is configured within the IdP and passed in with a user's federated ID during login. You can add more than one condition for a rule. All conditions set in the rule must be met for a user to be added to an access group.\n\nTo create a rule, follow these steps:\n\n\n\n1. In the IBM Cloud console, click Manage > Access (IAM), and select Access Groups.\n2. Select the name of the access group that you want to create a rule for. This action opens the group Details page.\n3. Select Dynamic rules.\n4. Click Add rule.\n5. Enter the information from your IdP that is dynamically provided for you on the Add rule page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-rules&interface=ui"},{"document_id":"ibmcld_02750-3104-4701","score":13.7607206453,"text":"\nJust as with traditional OAuth 2.0 flows, the most secure trust model creates a relationship between your identity provider and authorization server; in this case App ID) directly. Under this model, your identity provider is responsible for storing the private key and signing JWT assertions. When passed to App ID, these assertions are validated with the matching public key, which ensures that the user information from your identity provider was not maliciously altered during transport. \n\n\n\n\n\n\n\n\n\n Generating a JSON web token \n\nYou can convert your verified user data to a custom identity JWT by generating a [JSON web token](https:\/\/datatracker.ietf.org\/doc\/html\/rfc7515). The token must be signed with the private key that matches your preconfigured public key. For a list of token signing libraries, check out [https:\/\/jwt.io\/](https:\/\/jwt.io\/).\n\n\n\n Example JWT format \n\n{\n\/\/ Header\n\"alg\": \"RS256\",\n\"typ\": \"JOSE\",\n\/\/ Payload\n\/\/ Required\n\"iss\": \"String\", \/\/ Should reference your identity provider\n\"aud\": \"String\", \/\/ Must be the OAuth server URL name\n\"exp\": \"Int\", \/\/ Should be a value with a short lifespan\n\"sub\": \"String\", \/\/ Must be the unique user ID provided by your identity provider\n\n\/\/ Normalized claims (optional)\n\"name\": \"String\",\n\"email\": \"String\",\n\"locale\": \"String\",\n\"picture\": \"String\",\n\"gender\": \"String\",\n\n\/\/ Custom Scopes to add to access token (optional)\nscope=\"custom_scope1 custom_scope2\"\n\n\/\/ Other custom claims (optional)\nrole=\"admin\"\n}\n\n\n\nTable 1. JWS fields\n\n Field Description \n\n iss Should contain a reference to your identity provider. \n aud The OAuth server URL.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-custom-auth"},{"document_id":"ibmcld_03966-9450-11507","score":13.6493014924,"text":"\nBe sure that you have [set the identity](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identitiesibp-console-identities-ca-identity) to a CA admin that has the ability to register new users before you attempt this task. In general, this is your admin user. If the button is gray, you have either not set an identity, or that the identity cannot create new identities.\n\nClicking Register user opens a series of side panels:\n\n\n\n1. On the first side panel, enter the Enroll ID and Enroll Secret of the new identity. Save these values, as they are not stored by the console.\n2. Select the identity Type. The drop-down list contains the list of types that the CA supports. If you are registering an identity that will serve as an admin of a node, select type admin. If you are registering a peer identity select peer and likewise for an ordering node identity select orderer. When you need to register an identity for a client application select the type client.\n3. You can associate an affiliation with the user. Check the Use root affiliation checkbox for the user if you want them to have the root affiliation and be able to see all other users registered with this CA. When you deselect Use root affiliation, you can select a specific affiliation from the list to associate with this user. The platform includes the default affiliation ibp.\n4. Enter the Maximum Enrollments allowed for this identity. If not specified, the value defaults to unlimited enrollments.\n5. On the last side panel, add the Attributes of the identity you are creating.\n\n\n\nAfter you click Register, the new identity will be added to the list of Authenticated users that have been created by your CA. The identities are listed by their Enroll ID, along with their Type and Affiliation. Clicking on an identity in the table opens a side panel that displays the number of Maximum Enrollments and Attributes that were created during registration.\n\nDeleting a user\nIf you need to delete a registered user, click the action menu next to any user and select Delete user.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_03871-31988-33751","score":13.4462998238,"text":"\nSelect Provide a JSON identity file from the IBM Blockchain Platform and then browse to the admin identity that you exported from your console. If the identity is the administrator of multiple nodes in your network, you can associate the identity with multiple nodes.\n\n\n\nWhen you have associated an admin identity with your peers, CA, and an ordering node, you can connect to your network and use the extension to deploy smart contracts.\n\n\n\n\n\n\n\n Adding wallets and users \n\nUse the following steps to create a new wallet by using a certificate and private key:\n\n\n\n1. Hover your mouse over the Fabric Wallets pane and click +.\n2. Choose to Create a new wallet and add an identity from the options. Provide a name for your wallet and your identity.\n3. Enter the MSP ID of your organization.\n4. Choose to add a certificate and private key.\n5. If you use a certificate and private key, browse to the certificate and private key.\n\n\n\nYou can also add new users to the wallets that have already been created:\n\n\n\n1. In the Fabric Wallets pane, right-click a wallet and select Add Identity.\n2. Provide a name for the identity and an MSP ID.\n3. You can upload a JSON file, provide a certificate and private key, or provide an enrollment ID and secret.\n\n\n\n* If you are connecting to a network on the IBM Blockchain Platform, you can download an identity from your IBM Blockchain console, either by exporting an identity from your wallet or by enrolling and then exporting an identity using your Certificate Authority. You can then upload the JSON file directly to VS Code.\n* If you use a certificate and private key, browse to the certificate and private key.\n* If you use an enrollment ID and secret, choose the gateway to enroll with and enter the enrollment ID and secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-develop-vscode"},{"document_id":"ibmcld_06966-6860-8310","score":13.4119709214,"text":"\nFor more information, see [Giving users access to a Watson Discovery instance](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/svc-discovery\/discovery-admin-add-users.html).\n3. Enable document-level security for the data source when you connect to it.\n\n\n\n\n\n Creating users for document-level security \n\nYou must create users that match the users available on the source system that Discovery is connecting to so that they can query with document-level security enabled.\n\n\n\n1. Log in to Discovery as an administrator.\n2. Create users who match the users available on your source or who are connected to the identity provider that your source system uses. If you create users for document-level security, keep the following points in mind:\n\n\n\n* Optional: For each user that you want to have access to query results, you must add users. The username must match the username that the source uses. This option is only for development and testing purposes. To create users individually, see [Managing users](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/admin\/users.html).\n* To connect to an identity provider that the source is using, see [Connecting to your identity provider](https:\/\/www.ibm.com\/docs\/SSQNUZ_4.6.x\/cpd\/admin\/ldap.html).\n\n\n\n\n\nDiscovery does not synchronize changes that are made to the users in the identity provider with the user list for the service. Discovery administrators must ensure that the user list is current and remove any noncurrent users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collection-types"},{"document_id":"ibmcld_03966-11017-13066","score":13.3643376087,"text":"\nAfter you click Register, the new identity will be added to the list of Authenticated users that have been created by your CA. The identities are listed by their Enroll ID, along with their Type and Affiliation. Clicking on an identity in the table opens a side panel that displays the number of Maximum Enrollments and Attributes that were created during registration.\n\nDeleting a user\nIf you need to delete a registered user, click the action menu next to any user and select Delete user. If that option is not available, it can be enabled on your CA by overriding the CA configuration. See an example of how to enable this feature in [Modifying a CA configuration after deployment](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-ca-modify-json). Note this action does not revoke the associated certificates for the user. If you need to do that you would need to insert the associated signed certificate into the organization MSP under the \"revocation_list\": section. And then update that MSP definition everywhere that it occurs on the network.\n\n\n\n Creating new CA admins \n\nBy default, only the CA admin that is created during deployment has the ability to register new identities. You can create identities with the ability the register new users by using the Attributes panel of the registration process.\n\nOn the second side panel, click the Add Attribute button. Provide an attribute name of hf.Registrar.Roles. Enter an attribute value of . You can also use this panel to create an identity that can register only certain identity types, such as clients or peers, or within a certain affiliation. You can also create an identity that has the ability to revoke an identity and all the certificates that the identity has been issued. You can see a full list of the attributes in the [Registering a new identity](https:\/\/hyperledger-fabric-ca.readthedocs.io\/en\/release-1.4\/users-guide.htmlregistering-a-new-identity) section of the Fabric CA users guide.\n\n\n\n\n\n\n\n Enrolling an identity","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_16234-1331-2901","score":13.311894334,"text":"\nAdding users from this menu enables them to read, write, and manage all assistants in the service instance.\n4. Click Submit.\n\n\n\nAfter you click Submit, any user that you invite receives an email to access the instance. After they accept the invite, they can open the service instance and manage all assistants.\n\n\n\n\n\n Managing access with Identity and Access Management \n\nAnother way to add users to your assistants is using Identity and Access Management (IAM). If you want to add users, and you don't want them to have full Manager access, use IAM to add them. From IAM, you can also manage access roles of those users that are already added to your assistants.\n\n\n\n Opening Identity and Access Management \n\n\n\n1. Open the Manage menu. ![Manage menu](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/user--avatar.svg)\n2. Click Manage users.\n3. In Access and permissions, click Identity and Access Management in step 2.\n\nZoom\n\n![Access and permissions](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/access-control-manage-users-modal.png)\n\nAccess and permissions\n\n\n\n\n\n\n\n Adding users in Identity and Access Management \n\n\n\n1. In IAM, click Invite users.\n2. Enter the email address of the person who needs access.\n3. In How do you want to assign access?, choose Access policy.\n\nZoom\n\n![Access policy](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/access-policy.png)\n\nAccess policy\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control"},{"document_id":"ibmcld_02766-7-2005","score":13.1668791796,"text":"\nManaging authentication \n\nIdentity providers (IdP's) add a level of security for your mobile and web apps, through authentication. With IBM Cloud\u00ae App ID, you can configure one or several identity providers to create a custom sign-in experience for your users.\n\nApp ID interacts with identity providers by using various protocols such as OpenID Connect, SAML, and more. For example, OpenID Connect is the protocol that is used with many social providers such as Facebook, Google. Enterprise providers such as [Azure Active Directory](https:\/\/www.ibm.com\/cloud\/blog\/setting-ibm-cloud-app-id-azure-active-directory) or [Active Directory Federation Service](https:\/\/www.ibm.com\/cloud\/blog\/setting-ibm-cloud-app-id-active-directory-federation-service), generally use SAML as their identity protocol. For [Cloud Directory](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cloud-directory), the service uses SCIM to verify identity information.\n\nWhen you use social or enterprise identity providers, App ID reads user account information. Because the service never has write access to the information, users must go through their chosen identity provider to do actions, such as resetting their password. For example, if a user signs in to your app with Facebook, and then wanted to change their password, they must go to www.facebook.com to do so.\n\nWhen you use [Cloud Directory](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cloud-directory), App ID is the identity provider. The service uses your registry to verify your users identity. Because App ID is the identity provider, users can take advantage of advanced functionality, such as resetting their password, directly in your app.\n\nWorking with application identity? Check out [Application identity](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-app).\n\nSeveral identity providers can be configured to be used by App ID. Check out the following table to learn about your options.\n\n\n\nTable 1. Identity provider options\n\n Identity provider Type Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idp"},{"document_id":"ibmcld_02756-8679-10734","score":13.1397750674,"text":"\nVariable Description \n\n EntityID The identifier that lets the identity provider know that App ID issued the SAML request. \n Location URL The location that the identity provider sends the SAML assertions after successfully authenticating a user. \n Binding The instructions on how the identity provider must send the SAML response. \n NameID Format How the identity provider knows that which identifier format it needs to send in the subject of an assertion and how App ID identifies users. The ID must take the following form: <saml:NameID Format=\"urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress\">. \n WantAssertionsSigned The way that an identity provider checks to see whether it needs to sign the assertion. The service expects that the assertion is signed, but does not support encrypted assertions. \n KeyDescriptor The SAML signing and encryption certificates that can be used to configure your identity provider to verify the signed SAML request and encrypt the response. \n\n\n\n3. Provide the data to your identity provider. If your identity provider supports uploading the metadata file, you can do so. If it doesn't, configure the properties manually. Not every identity provider uses the same properties, so you might not use all of them.\n\nThe property names might differ between identity providers.\n4. Toggle SAML 2.0 Federation to Enabled.\n\n\n\n\n\n\n\n Providing metadata to App ID \n\nYou can obtain data from your identity provider and provide it to App ID. You can initiate login to your applications from IBM Cloud or your identity provider.\n\n\n\n Providing metadata with the UI \n\nTo log in to your applications from the IBM Cloud UI, follow these steps.\n\n\n\n1. Navigate to the SAML 2.0 tab of the App ID dashboard.\n2. Add the Provider name. The default name is SAML.\n3. Enter the following metadata that you obtained from the identity provider in the Provide Metadata from SAML IdP section.\n\n\n\nTable 2. The information that must be provided to App ID\n\n Variable Description \n\n Sign-in URL The URL that the user is redirected to for authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-enterprise"},{"document_id":"ibmcld_04000-20945-22806","score":13.1199642964,"text":"\nIt's worth clicking the Advanced button to review the endorsement policy that will be used for the smart contract. Every organization that you select from the Members drop-down list on this panel will be included in the endorsement policy (represented by the role mspId parameter in the policy). The value of the role name parameter indicates the type of identity that is required to endorse transactions and can be any of client, peer, orderer, admin, or member. If it is set to member, then any of the other four roles will satisfy the criteria.\n\nWhen a peer role is specified, you should ensure that any peers that will be submitting endorsement transactions were registered with the correct type. In the following endorsement policy example, peers who are members of org1msp can endorse transactions if their enroll id was registered with the type of client, peer, orderer, or admin. However, for peers who are members of org2msp, their enroll id must have been registered with a type of peer to be able to endorse transactions.\n\n{\n\"identities\": [\n{\n\"role\": {\n\"name\": \"member\",\n\"mspId\": \"org1msp\"\n}\n},\n{\n\"role\": {\n\"name\": \"peer\",\n\"mspId\": \"org2msp\"\n}\n}\n],\n\"policy\": {\n\"1-of-2\": [\n{\n\"signed-by\": 0\n}\n]\n}\n}\nShow more\n\nUnsure which type was selected when a peer identity was registered? From the console, you can open the CA where the peer identity was registered and view the list of registered users and their associated type.\n\n\n\n\n\n\n\n Upgrading a smart contract \n\nYou can upgrade a smart contract to change its code, endorsement policy, or private data collection while maintaining its relationship to the assets on the ledger. There are a variety of reasons why you may want to upgrade an instantiated smart contract.\n\n\n\n1. You can upgrade the smart contract to add or remove functionality from its code and iterate on the logic of your business network.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-smart-contracts-v14"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16295-7-1721","score":22.9842576531,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_03080-7-1901","score":22.7508344526,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03421-4-1877","score":22.660452661,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16368-7-2072","score":22.6531321931,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16384-1889-3334","score":22.5287058697,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16365-12876-14604","score":22.3883846946,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16384-7-2422","score":22.1361427248,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_03166-4-2012","score":22.0648355,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https:\/\/medium.com\/ibm-watson\/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16366-7-1826","score":21.9063544469,"text":"\nWeb chat setup overview \n\nYou can modify the web chat integration settings to configure the styling and appearance of the web chat.\n\nYou can quickly deploy and test the web chat integration using the default settings. However, before you go to production with your chatbot, you will need to configure the web chat to integrate with your website and better serve the needs of your customers.\n\nAt a minimum, you should update the following basic settings for your assistant:\n\n\n\n* The [assistant name](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style) that you want to show to your customers\n* The contents of the [home screen](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen)\n* The [suggestions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-suggestions) your assistant will offer if customers get stuck\n\n\n\nYou might also want to make additional configurations, such as changing the web chat colors to match your branding, changing the launcher greeting, or enabling encryption.\n\nIf you are a developer, you can customize the web chat by using the web chat API. With the API, you can customize the styling, change the behavior of the web chat widget and launcher, customize strings, modify message content, and more. For more information about using the web chat API, see [Web chat development overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop).\n\nTo change the web chat configuration, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click Open. The Open web chat window opens.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config"},{"document_id":"ibmcld_16326-1697-3495","score":21.8780875267,"text":"\nFor more information, see [Changing background website](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06160-11142-12906","score":27.0457032337,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-11475-13230","score":27.0457032337,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-5350-7330","score":22.3273326037,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-5357-7356","score":22.2055376936,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_06160-12611-14167","score":21.1400107265,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\nkubectl describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) . Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.\n\nkubectl get mutatingwebhookconfigurations\n\nkubectl get validatingwebhookconfigurations\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-12943-14509","score":20.7679412943,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\noc describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) and the [Openshift Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool). Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10227-2655-4315","score":20.6868483334,"text":"\n* See [Getting help](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) for more details about using the forums.\n\n\n\n\n\n\n\n\n\n Contacting support \n\nBefore you open a support case, gather relevant information about your cluster environment.\n\n\n\n1. Get your cluster details.\n\nibmcloud oc cluster get -c <cluster_name_or_ID>\n2. If your issue involves worker nodes, get the worker node details.\n\n\n\n1. List all worker nodes in the cluster, and note the ID of any worker nodes with an unhealthy State or Status.\n\nibmcloud oc worker ls -c <cluster_name_or_ID>\n2. Get the details of the unhealthy worker node.\n\nibmcloud oc worker get -w <worker_ID> -c <cluster_name_or_ID>\n\n\n\n3. For issues with resources within your cluster such as pods or services, log in to the cluster and use the Kubernetes API to get more information about them.\n\nYou can also use the [IBM Cloud Kubernetes Service Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool) to gather and export pertinent information to share with IBM Support.\n4. Contact IBM Support by [opening a case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form). To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n5. For the Problem type, search for or select Red Hat OpenShift on IBM Cloud.\n6. For the Case details, provide a descriptive title and include the details that you previously gathered. From the Resources, you can also select the cluster that the issue is related to.\n\n\n\n\n\n\n\n Requesting access to allowlisted features \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help"},{"document_id":"ibmcld_05818-2659-4377","score":20.5251823995,"text":"\n* See [Getting help](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) for more details about using the forums.\n\n\n\n\n\n\n\n\n\n Contacting support \n\nBefore you open a support case, gather relevant information about your cluster environment.\n\n\n\n1. Get your cluster details.\n\nibmcloud ks cluster get -c <cluster_name_or_ID>\n2. If your issue involves worker nodes, get the worker node details.\n\n\n\n1. List all worker nodes in the cluster, and note the ID of any worker nodes with an unhealthy State or Status.\n\nibmcloud ks worker ls -c <cluster_name_or_ID>\n2. Get the details of the unhealthy worker node.\n\nibmcloud ks worker get -w <worker_ID> -c <cluster_name_or_ID>\n\n\n\n3. For issues with resources within your cluster such as pods or services, log in to the cluster and use the Kubernetes API to get more information about them.\n\nYou can also use the [IBM Cloud Kubernetes Service Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) to gather and export pertinent information to share with IBM Support.\n4. Contact IBM Support by [opening a case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form). To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n5. For the Problem type, search for or select Kubernetes Service.\n6. For the Case details, provide a descriptive title and include the details that you previously gathered. From the Resources, you can also select the cluster that the issue is related to.\n\n\n\n\n\n\n\n Requesting access to allowlisted features \n\n\n\n1. [Create a ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help"},{"document_id":"ibmcld_10596-9883-11854","score":19.7121074153,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_05713-581893-583377","score":19.4407523916,"text":"\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05762-7-1980","score":19.3617836595,"text":"\nDebugging worker nodes \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nReview the options to debug your worker nodes and find the root causes for failures.\n\n\n\n Check worker node notifications and maintenance updates \n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n1.\nClassic clusters\n\nCheck the [health dashboard](https:\/\/cloud.ibm.com\/gen1\/infrastructure\/health-dashboard) for any IBM Cloud emergency maintenance notifications that might affect classic worker nodes in your account. Depending on the nature of the maintenance notification, you might need to reboot or reload your worker nodes.\n2. Check the IBM Cloud [status dashboard](https:\/\/cloud.ibm.com\/status) for any known problems that might affect your worker nodes or cluster. If any of the following components show an error status, that component might be the cause of your worker node disruptions.\n\n\n\n* For all clusters, check the Kubernetes Service and Container Registry components.\n* For VPC clusters, check the Virtual Private Cloud, Virtual Private Endpoint and Virtual Server for VPC components.\n* For Classic clusters, check the Classic Infrastructure Provisioning and Virtual Servers components.\n\n\n\n\n\n\n\n\n\n Quick steps to resolve worker node issues \n\nIf your worker node is not functioning as expected, you can follow these steps to update your cluster and command line tools or run diagnostic tests. If the issue persists, see [Debugging your worker node](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodesworker-debug-steps) for additional steps.\n\n\n\n1. [Update your cluster and worker nodes to the latest version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate).\n2. [Update your command line tools](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cli-update).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes"},{"document_id":"ibmcld_10197-7-2062","score":19.2275434415,"text":"\nDebugging worker nodes \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nReview the options to debug your worker nodes and find the root causes for failures.\n\n\n\n Check worker node notifications and maintenance updates \n\nCheck the IBM Cloud health and status dashboard for any notifications or maintenance updates that might be relevant to your worker nodes. These notifications or updates might help determine the cause of the worker node failures.\n\n\n\n1.\nClassic clusters\n\nCheck the [health dashboard](https:\/\/cloud.ibm.com\/gen1\/infrastructure\/health-dashboard) for any IBM Cloud emergency maintenance notifications that might affect classic worker nodes in your account. Depending on the nature of the maintenance notification, you might need to reboot or reload your worker nodes.\n2. Check the IBM Cloud [status dashboard](https:\/\/cloud.ibm.com\/status) for any known problems that might affect your worker nodes or cluster. If any of the following components show an error status, that component might be the cause of your worker node disruptions.\n\n\n\n* For all clusters, check the Kubernetes Service and Container Registry components.\n* For Red Hat Openshift clusters, check the Red Hat OpenShift on IBM Cloud component.\n* For VPC clusters, check the Virtual Private Cloud, Virtual Private Endpoint and Virtual Server for VPC components.\n* For Classic clusters, check the Classic Infrastructure Provisioning and Virtual Servers components.\n\n\n\n\n\n\n\n\n\n Quick steps to resolve worker node issues \n\nIf your worker node is not functioning as expected, you can follow these steps to update your cluster and command line tools or run diagnostic tests. If the issue persists, see [Debugging your worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_worker_nodesworker-debug-steps) for additional steps.\n\n\n\n1. [Update your cluster and worker nodes to the latest version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate).\n2. [Update your command line tools](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cli-update).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_worker_nodes"},{"document_id":"ibmcld_10394-7-1848","score":18.2263627059,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_16729-103029-104898","score":18.2248206361,"text":"\n* 30 minutes\n* 2023-02-21\n\n\n\n[Using Calico network policies to control traffic on Classic clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-policy_tutorial)Using Calico network policies to control traffic on Classic clusters\n\nLearn how to use Calico policies to allow network traffic from and to certain IP addresses.\n\nRed Hat OpenShift on IBM Cloud\n\n\n\n* 60 minutes\n* 2023-07-07\n\n\n\n[Updating Classic worker nodes that use OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic)Updating Classic worker nodes that use OpenShift Data Foundation\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Updating VPC worker nodes that use OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc)Updating VPC worker nodes that use OpenShift Data Foundation\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_06209-6757-8643","score":18.1304623168,"text":"\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10534-140407-141645","score":17.7937469807,"text":"\n[Updating clusters, worker nodes, and cluster components](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateupdate)\n\n\n\n* [Updating the master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemaster)\n\n\n\n* [About updating the master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemaster-about)\n* [Steps to update the cluster master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatemaster-steps)\n\n\n\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker-up-prereqs)\n* [Updating classic worker nodes in the CLI with a configmap](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker-up-configmap)\n* [Updating classic worker nodes in the console](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_up_console)\n\n\n\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_prereqs)\n* [Updating VPC worker nodes in the CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_cli)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10642-6354-8294","score":17.7790242211,"text":"\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_05713-143677-145052","score":17.66369767,"text":"\n* [About updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster-about)\n* [Steps to update the cluster master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster-steps)\n\n\n\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker-up-prereqs)\n* [Updating classic worker nodes in the CLI with a configmap](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker-up-configmap)\n* [Updating classic worker nodes in the console](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_up_console)\n\n\n\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node)\n\n\n\n* [Prerequisites](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_prereqs)\n* [Updating VPC worker nodes in the CLI](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_cli)\n* [Updating VPC worker nodes in the console](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_ui)\n\n\n\n* [Updating flavors (machine types)](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemachine_type)\n* [Updating cluster components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatecomponents)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10534-264143-265453","score":17.6298261049,"text":"\n* [Version 4.13 parameters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy-odf-classicodf-classic-params-413)\n* [Version 4.10, 4.11, and 4.12 parameters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy-odf-classicodf-classic-params-410)\n* [Version 4.9 parameters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy-odf-classicodf-classic-params-48)\n\n\n\n* [Limitations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy-odf-classicodf-limitations-classic)\n\n\n\n[Updating Classic worker nodes that use OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classicopenshift-storage-update-classic)\n\n\n\n* [Update the cluster master](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classicupdate-cluster-master-classic)\n* [Determine which worker nodes you want to update](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classicdetermine-worker-nodes-classic)\n* [Scale down OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classicscale-down-odf-classic)\n* [Cordon and drain the worker node](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classiccordon-drain-worker-node-classic)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10642-18947-20676","score":17.5925381762,"text":"\nYou notice that an update is available for your worker nodes in a [VPC infrastructure cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers). What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_updateportworx_vpc_up).\n\nIf you have OpenShift Data Foundation deployed in your cluster, follow the steps to [update VPC worker nodes with OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud oc worker replace command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.234639363,"ndcg_cut_10":0.391065605}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10394-7-1848","score":15.3893959343,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_10395-7-1827","score":15.3789688066,"text":"\nUpdating VPC worker nodes that use OpenShift Data Foundation \n\nVirtual Private Cloud\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc"},{"document_id":"ibmcld_10394-1469-2994","score":14.3715994051,"text":"\nIf you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.\n\n\n\n\n\n\n\n Step 2: Determine which worker nodes you want to update \n\nMajor\n\nMinor\n\n\n\n1. List your worker nodes by using the oc get nodes command and determining which worker nodes you want to update.\n\noc get nodes\n\nExample output\n\nNAME STATUS ROLES AGE VERSION\n10.241.0.4 Ready master,worker 106s v1.21.6+4b61f94\n10.241.128.4 Ready master,worker 22d v1.21.6+bb8d50a\n10.241.64.4 Ready master,worker 22d v1.21.6+bb8d50a\n\n\n\n\n\n\n\n Step 3: Scale down OpenShift Data Foundation \n\nMajor\n\nMinor\n\n\n\n1. For each worker node that you found in the previous step, find the rook-ceph-mon and rook-ceph-osd deployments.\n\noc get pods -n openshift-storage -o wide | grep -i <node_name>\n2. Scale down the deployments that you found in the previous step.\n\noc scale deployment rook-ceph-mon-c --replicas=0 -n openshift-storage\noc scale deployment rook-ceph-osd-2 --replicas=0 -n openshift-storage\noc scale deployment --selector=app=rook-ceph-crashcollector,node_name=NODE-NAME --replicas=0 -n openshift-storage\n\n\n\n\n\n\n\n Step 4: Cordon and drain the worker node \n\nMajor\n\nMinor\n\n\n\n1. Cordon the node. Cordoning the node prevents any pods from being scheduled on this node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_10395-1448-2944","score":14.2883755951,"text":"\nIf you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.\n\n\n\n\n\n\n\n Step 2: Determine which storage nodes you want to update \n\nMajor\n\nMinor\n\n\n\n1. List your worker nodes by using oc get nodes and determine which storage nodes you want to update.\n\noc get nodes\n\nExample output\n\nNAME STATUS ROLES AGE VERSION\n10.241.0.4 Ready master,worker 106s v1.21.6+4b61f94\n10.241.128.4 Ready master,worker 22d v1.21.6+bb8d50a\n10.241.64.4 Ready master,worker 22d v1.21.6+bb8d50a\n\n\n\n\n\n\n\n Step 3: Scale down OpenShift Data Foundation \n\nMajor\n\nMinor\n\n\n\n1. For each worker node that you found in the previous step, find the rook-ceph-mon and rook-ceph-osd deployments.\n\noc get pods -n openshift-storage -o wide | grep -i <node_name>\n2. Scale down the deployments that you found in the previous step.\n\noc scale deployment rook-ceph-mon-c --replicas=0 -n openshift-storage\ndeployment.apps\/rook-ceph-mon-c scaled\noc scale deployment rook-ceph-osd-2 --replicas=0 -n openshift-storage\ndeployment.apps\/rook-ceph-osd-2 scaled\noc scale deployment --selector=app=rook-ceph-crashcollector,node_name=NODE-NAME --replicas=0 -n openshift-storage\n\n\n\n\n\n\n\n Step 4: Cordon and drain the worker node \n\nMajor\n\nMinor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc"},{"document_id":"ibmcld_10642-6354-8294","score":13.8075827142,"text":"\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-6757-8643","score":13.789722682,"text":"\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_06209-24291-25925","score":13.5716388569,"text":"\n* If you want to apply a patch update, review the [Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) version change log.\n* Make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\n\n\n\n\n Updating VPC worker nodes in the CLI \n\nComplete the following steps to update your worker nodes by using the CLI.\n\n\n\n1. Complete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_prereqs).\n2. Optional: Add capacity to your cluster by [resizing the worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workersresize_pool). The pods on the worker node can be rescheduled and continue running on the added worker nodes during the update.\n3. List the worker nodes in your cluster and note the ID and Primary IP of the worker node that you want to update.\n\nibmcloud ks worker ls --cluster CLUSTER\n4. Replace the worker node to update either the patch version or the major.minor version that matches the master version.\n\n\n\n* To update the worker node to the same major.minor version as the master, such as from 1.25 to 1.26, include the --update option.\n\nibmcloud ks worker replace --cluster CLUSTER --worker WORKER-NODE-ID --update\n* To update the worker node to the latest patch version at the same major.minor version, such as from 1.25.8_1530 to 1.25.9_1533, don't include the --update option.\n\nibmcloud ks worker replace --cluster CLUSTER --worker WORKER-NODE-ID\n\n\n\n5. Repeat these steps for each worker node that you must update.\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_09590-3439-5305","score":13.5121118566,"text":"\nOn rare occasions, failure can result, impacting your availability. If a failure occurs, the database is disabled, and you need to restore from backup. We recommend self-migrating before the end of support date.\n\n\n\n\n\n Major versions defined \n\n\n\nTable 1. Major versions for Cloud Databases\n\n Database Versioning Schema Next Known End of Life Version and Date End of life procedure \n\n DataStax Major versions are the first number in a major.minor.patch version number. v6.8.x, March 2026 Backup taken and access removed \n Elasticsearch Major versions are the first number in a release.version.maintenance version number. v7.9, November 2023; v7.10, November 2023; v7.17, TBD Backup taken and access removed \n EnterpriseDB Major version is defined by the first number in the version number. v12, December 2024 Backup taken and access removed \n etcd Major versions are the first number in a major.minor.patch version number. v3.3, unplanned Backup taken and access removed \n MongoDB Major versions are the first two numbers in a major.x.patch version number. In cases where x is even, it is a stable release suitable for production. Even x versions are the only ones available on Cloud Databases. v4.2, July 2023; v4.4, January 2024; v5, September 2024 Automatically upgraded in place to next Major version \n PostgreSQL Major version is defined by the first number in the version number. v11, TBD Backup taken and access removed \n Redis Major versions are the first number in a major.minor.patch version number. v5.0, TBD Automatically upgraded in place to next Major version only for Redis 4 to Redis 5 \n RabbitMQ Major versions are the first two numbers in a major.x.patch version number. v3.11, TBD Backup taken and access removed \n MySQL** Major versions are the first two numbers in a major.x.patch version number. v5.7, October 2023 Backup taken and access removed","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-versioning-policy"},{"document_id":"ibmcld_06478-3439-5305","score":13.5121118566,"text":"\nOn rare occasions, failure can result, impacting your availability. If a failure occurs, the database is disabled, and you need to restore from backup. We recommend self-migrating before the end of support date.\n\n\n\n\n\n Major versions defined \n\n\n\nTable 1. Major versions for Cloud Databases\n\n Database Versioning Schema Next Known End of Life Version and Date End of life procedure \n\n DataStax Major versions are the first number in a major.minor.patch version number. v6.8.x, March 2026 Backup taken and access removed \n Elasticsearch Major versions are the first number in a release.version.maintenance version number. v7.9, November 2023; v7.10, November 2023; v7.17, TBD Backup taken and access removed \n EnterpriseDB Major version is defined by the first number in the version number. v12, December 2024 Backup taken and access removed \n etcd Major versions are the first number in a major.minor.patch version number. v3.3, unplanned Backup taken and access removed \n MongoDB Major versions are the first two numbers in a major.x.patch version number. In cases where x is even, it is a stable release suitable for production. Even x versions are the only ones available on Cloud Databases. v4.2, July 2023; v4.4, January 2024; v5, September 2024 Automatically upgraded in place to next Major version \n PostgreSQL Major version is defined by the first number in the version number. v11, TBD Backup taken and access removed \n Redis Major versions are the first number in a major.minor.patch version number. v5.0, TBD Automatically upgraded in place to next Major version only for Redis 4 to Redis 5 \n RabbitMQ Major versions are the first two numbers in a major.x.patch version number. v3.11, TBD Backup taken and access removed \n MySQL** Major versions are the first two numbers in a major.x.patch version number. v5.7, October 2023 Backup taken and access removed","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-versioning-policy"},{"document_id":"ibmcld_06733-3439-5305","score":13.5121118566,"text":"\nOn rare occasions, failure can result, impacting your availability. If a failure occurs, the database is disabled, and you need to restore from backup. We recommend self-migrating before the end of support date.\n\n\n\n\n\n Major versions defined \n\n\n\nTable 1. Major versions for Cloud Databases\n\n Database Versioning Schema Next Known End of Life Version and Date End of life procedure \n\n DataStax Major versions are the first number in a major.minor.patch version number. v6.8.x, March 2026 Backup taken and access removed \n Elasticsearch Major versions are the first number in a release.version.maintenance version number. v7.9, November 2023; v7.10, November 2023; v7.17, TBD Backup taken and access removed \n EnterpriseDB Major version is defined by the first number in the version number. v12, December 2024 Backup taken and access removed \n etcd Major versions are the first number in a major.minor.patch version number. v3.3, unplanned Backup taken and access removed \n MongoDB Major versions are the first two numbers in a major.x.patch version number. In cases where x is even, it is a stable release suitable for production. Even x versions are the only ones available on Cloud Databases. v4.2, July 2023; v4.4, January 2024; v5, September 2024 Automatically upgraded in place to next Major version \n PostgreSQL Major version is defined by the first number in the version number. v11, TBD Backup taken and access removed \n Redis Major versions are the first number in a major.minor.patch version number. v5.0, TBD Automatically upgraded in place to next Major version only for Redis 4 to Redis 5 \n RabbitMQ Major versions are the first two numbers in a major.x.patch version number. v3.11, TBD Backup taken and access removed \n MySQL** Major versions are the first two numbers in a major.x.patch version number. v5.7, October 2023 Backup taken and access removed","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-versioning-policy"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.1815417925}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16471-73103-74976","score":13.8199376241,"text":"\n* [and mapping from <mapping table name>]\n\nSpecifies the name of an AQL table that maps raw part-of-speech tags such as \"NOUN\" to combinations of high-level parts of speech and flags. While the optional mapping table can have variable names, a part-of-speech mapping table is required to have these column names:\n\n\n\n* tag\n\nThe column that holds a Multilingual tokenizer part-of-speech tag.\n* basetag\n\nThe column that holds the corresponding internal tag.\n* flagstr\n\nThe column that holds a comma-delimited list of flags that are associated with the indicated part of speech.\n\n\n\nThe mapping table must be defined by using the create table statement in the same module as the extract part_of_speech statement that uses it. It cannot be an imported table, and it cannot be an external table.\n\ncreate table POSMapping_EN(tag Text, basetag Text, flagstr Text)\nas values\n('CCONJ','CONJ','coordinating'),\n('SCONJ','CONJ','subordinating');\n* <input column>\n\nSpecifies the column of the input view from which to extract part-of-speech information.\n* <output column>\n\nSpecifies the name of the column where the spans of the tokens with the indicated parts of speech are sent.\n* <input view>\n\nSpecifies the input view from which to extract part-of-speech information.\n\n\n\n\n\n\n\n Usage notes \n\n\n\n* Part of speech extraction works only when is using the Multilingual tokenizer. If the system uses the Standard tokenizer, a part_of_speech extraction generates an error.\n\n\n\n\n\n\n\n Parts of speech tags for languages \n\nFor all supported languages, the Multilingual tokenizer uses the part-of-speech tags that are listed in the following table.\n\n\n\n Tag Descriptions \n\n ADJ adjective \n ADP adposition \n ADV adverb \n AUX auxiliary \n CCONJ coordinating conjunction \n DET determiner \n INTJ interjection \n NOUN noun \n NUM numeral \n PART particle \n PRON pronoun \n PROPN proper noun \n PUNCT punctuation","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_12583-45926-47268","score":13.5864472098,"text":"\n\"value\" : \"name of the SysDig stage service instance\",\n\"type\" : \"string\"\n} ],\n\"output\" : {\n\"name\" : \"resource_group_id\"\n}, {\n\"name\" : \"logdna_id\"\n}, {\n\"name\" : \"sysdig_id\"\n} ] ! ! !\n},\n\"project_id\" : \"db268db0-160b-4911-8f93-89659000a927\",\n\"is_draft\" : true,\n\"version\" : 2,\n\"state\" : \"ACTIVE\",\n\"pipeline_state\" : \"PIPELINE_SUCCEEDED\",\n\"update_available\" : true,\n\"created_at\" : \"2023-02-22T19:51:23.253Z\",\n\"updated_at\" : \"2023-02-22T19:51:23.253Z\"\n}\n<-- <\/section \"id=\"section-project-config-draft-get-cli-output\" \"> --><-- <\/section \"id=\"section-project-cli-config-draft-get-command\" \"> --><-- <section \"id=\"section-project-relevant-commands-other\" \"> --> Other relevant commands for IBM Cloud projects The following commands are not a part of the projects CLI plug-in, but you can use them to complete project-related tasks, such as attaching tags to a project. This list is not exhaustive of all of the relevant commands that are available to use with projects. Rather, this list is a starting point for you to explore other commands that you can use with projects.Some of the following commands might require the installation of their specific plug-ins before you can run them.Run ibmcloud resource tag-attach]ibmcloud resource tag-attach] to attach tags to a project: ibmcloud resource tag-attach --tag-names TAG --resource-id PROJECT-CRN","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-projects-cli"},{"document_id":"ibmcld_16471-71623-73502","score":13.4063862833,"text":"\non CW.word as capswords\nfrom CapitalizedWords CW;\n\nExample 2: Extract blocks of words within a token range\n\nThe following code identifies blocks of exactly two capitalized words within five tokens of each other.\n\ncreate view TwoCapitalizedWords as\nextract blocks\nwith count 2\nand separation between 0 and 5 tokens\non CW.word as capswords\nfrom CapitalizedWords CW;\n\n\n\n\n\n\n\n Part of speech \n\nUse the part-of-speech extraction specification to identify locations of different parts of speech across the input text.\n\n\n\n Syntax \n\npart_of_speech\n'<part of speech spec>'\n[and '<part of speech spec>']\n[with language '<language code>']\n[and mapping from <mapping table name>]\non <input column> as <output column>\nfrom <input view>\n\n\n\n\n\n Description \n\n\n\n* '<part of speech spec>'\n\nIdentifies the parts of speech to extract from the input text. The '<part of speech spec>' is one of the following strings:\n\n\n\n* A string that contains a comma-delimited list of part-of-speech tags that are generated by the Multilingual tokenizer\n* A combination of an internal part-of-speech name and flags, as defined by a mapping table\n\n\n\n* [and '<part of speech spec>']\n\nIdentifies the additional parts of speech tags for extraction.\n* [with language '<language code>']\n\nSpecifies the language to be used in the extraction. The <language code> is a two-letter, lowercase language code, such as 'en' or 'ja'. If this argument is omitted, the language for part-of-speech extraction is assumed to be English\n* [and mapping from <mapping table name>]\n\nSpecifies the name of an AQL table that maps raw part-of-speech tags such as \"NOUN\" to combinations of high-level parts of speech and flags. While the optional mapping table can have variable names, a part-of-speech mapping table is required to have these column names:\n\n\n\n* tag\n\nThe column that holds a Multilingual tokenizer part-of-speech tag.\n* basetag","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_07070-10644-11552","score":12.9194015091,"text":"\n\"Watson Discovery is an award-winning AI search technology.\"\n\n\n\n\n\n Response \n\nIn the JSON output:\n\n\n\n* text = The keyword text\n* mentions = The entity mentions and locations\n\n\n\n{\n\"keywords\": [\n{\n\"mentions\":\n{\n\"location\": {\n\"end\": 157,\n\"begin\": 141\n},\n\"text\": \"Watson Discovery\"\n}\n],\n\"text\": \"Watson Discovery\",\n\"relevance\": 0.503613\n},\n{\n\"mentions\":\n{\n\"location\": {\n\"end\": 177,\n\"begin\": 164\n},\n\"text\": \"award-winning\"\n}\n],\n\"text\": \"award-winning\",\n\"relevance\": 0.728722\n},\n{\n\"mentions\":\n{\n\"location\": {\n\"end\": 198,\n\"begin\": 181\n},\n\"text\": \"search technology\"\n}\n],\n\"text\": \"search technology\",\n\"relevance\": 0.779356\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n Keywords limits \n\nThe Keywords enrichment can identify up to 50 keywords, each with one or many mentions, per document.\n\n\n\n\n\n\n\n Part of speech \n\nRecognizes and tags parts of speech, including nouns, verbs, adjectives, adverbs, conjunctions, interjections, and numerals.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-nlu"},{"document_id":"ibmcld_09410-3448-5457","score":12.7621669962,"text":"\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.\n* [hash] represents the digest (manifest) of the container image. It is a unique SHA-256 hash.\n\n\n\nThe following table outlines the tagging convention adopted and the agent update behavior:\n\n\n\nTable 1. logging agent tags explained\n\n Tag Logging agent auto-update enabled More info \n\n X YES The logging agent auto-updates when a new minor version releases. <br>The logging agent does not update to a new major version, as these updates may require configuration changes. \n X.Y YES The logging agent auto-updates when a new patch version is released. \n X.Y.Z YES The logging agent auto-updates when a new vulnerability fix is released. The agent code does not change, but the included libraries have vulnerability fixes. \n X.Y.Z-<date>.[hash] NO The logging agent never updates. If you use this tag, make sure you are watching for new agent releases that have vulnerability fixes. \n\n\n\nDepending on the tag that you use, you must consider upgrading the logging agent image in your DevOps maintenance plan, to resolve vulnerabilities and apply agent enhancements and agent bug fixes. For example:\n\n\n\n* In a development environment, you can use a tag X and let auto-updates happen as new minor versions are released.\n* In a staging environment, you might consider using a tag X.Y so auto-updates happen when a new patch is released.\n* In a production environment, you can use the tag X.Y.Z so that auto-updates happen when a new vulnerability fix is released.\n* For highly regulated environments, you should use the tag X.Y.Z-<date>.[hash]. Notice that you will have to check periodically for vulnerability fixes, patches, and minor version releases to keep the agent free of issues.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_09410-1574-3779","score":12.1789114477,"text":"\n* IBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM.\n* The IBM Cloud Container Registry includes Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\n\n\nTo get details about the logging agent images, see [Getting information about logging agent images](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent_image).\n\n\n\n Resource Limits for agents deployed on Kubernetes \n\nThe agent is deployed as a Kubernetes DaemonSet, creating one pod for each node selected. The agent collects logs of all the pods in the node. The resource requirements of the agent are in direct relation to the number of pods for each node and the amount of logs produced for each pod.\n\nThe agent requires at least 128 MB and no more than 512 MB of memory. It requires at least twenty millicpu (20m).\n\nDifferent features can also increase resource utilization. When line exclusion, inclusion or redaction rules are specified, you can expect additional CPU consumption for each line and regex rule defined. When Kubernetes event logging is enabled (disabled by default), additional CPU usage will occur on the oldest agent pod.\n\nPlacing traffic shaping or CPU limits on the agent is not recommended to ensure data can be sent to the log ingestion service.\n\n\n\n\n\n Understanding image tags \n\nThe tag that is associated to a logging image indicates whether the logging agent is automatically updated.\n\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_07578-867824-869488","score":12.0848686757,"text":"\nYou add [user tags](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=uibackup-service-about-tags) to your volumes and specify the same tags in a backup policy. When the tags match, a backup is triggered based on the backup plan schedule. You can [view backup jobs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-view-policy-jobs) to see the progress of the operation. The Snapshot for VPC service is used to create the backup. The entire contents of the volume are copied and retained for the number of days or total number of backups that are specified in the backup plan. When the retention period is reached, the older backups are deleted.\n* What resources are backed up?\n\nBlock Storage for VPC data and boot volumes with user tags that match the tags in a [backup policy](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=uibackup-service-policies) are backed up.\n* How do enable my volumes to be backed up?\n\nEnabling your backups is two-part process. First, you [specify user tags](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-use-policies) on the Block Storage for VPC volumes that you want to back up. You then [create a backup policy](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-policy-create) and specify these tags, which identify the volumes that you're backing up. Within a policy, you create a [backup plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-policy-create&interface=uibackup-plan-ui) to schedule backups of these resources. You can schedule backups to be taken every daily, weekly, or monthly.\n* How many backups can I create?\n\nYou can create up to 750 backups per volume per account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-867701-869365","score":12.0848686757,"text":"\nYou add [user tags](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=uibackup-service-about-tags) to your volumes and specify the same tags in a backup policy. When the tags match, a backup is triggered based on the backup plan schedule. You can [view backup jobs](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-view-policy-jobs) to see the progress of the operation. The Snapshot for VPC service is used to create the backup. The entire contents of the volume are copied and retained for the number of days or total number of backups that are specified in the backup plan. When the retention period is reached, the older backups are deleted.\n* What resources are backed up?\n\nBlock Storage for VPC data and boot volumes with user tags that match the tags in a [backup policy](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=uibackup-service-policies) are backed up.\n* How do enable my volumes to be backed up?\n\nEnabling your backups is two-part process. First, you [specify user tags](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-use-policies) on the Block Storage for VPC volumes that you want to back up. You then [create a backup policy](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-policy-create) and specify these tags, which identify the volumes that you're backing up. Within a policy, you create a [backup plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-policy-create&interface=uibackup-plan-ui) to schedule backups of these resources. You can schedule backups to be taken every daily, weekly, or monthly.\n* How many backups can I create?\n\nYou can create up to 750 backups per volume per account.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_09275-13854-15898","score":11.7497845433,"text":"\nTags are case-sensitive, and the maximum length of a tag is 128 characters.\n\n\n\n* The characters that are permitted to name tags are A-Z, 0-9, spaces, underscore, hyphen, period, and colon.\n* Colons turn the tag into a string where you can isolate two logical parts, like a key:value pair. You can't use a colon in a tag without creating this pairing.\n* A comma separates tags and can't be used within the tag name itself.\n\n\n\nIf you add PII information in the name, you might be disclosing sensitive data to others in the same account.\n\nWhen you define your tags, do not add sensitive information in the tag name.\n\nTags are visible to all members of an account.\n\nTo control tag visibility, circulate tagging guidelines, and let users know that tags are visible account-wide.\n\n\n\n\n\n\n\n Define the log ingestion strategy \n\nFor non-IBM Cloud enabled services, you must decide the method to collect and forward logs from a log source that you want to monitor to a logging instance.\n\nIn IBM Log Analysis, you can collect and forward data to a logging instance by using any of the following methods:\n\n\n\n* logging agent: Logging agent that automatically collects and forwards logs to 1 logging instance in your account.\n* Syslog: Logging daemon that collects information across multiple devices and system-services, and forwards logs to 1 logging instance in your account.\n* REST API: API that you can use to send log data and custom metadata to 1 logging instance in your account.\n* Code libraries: Libraries that you can use to code ingestion of logs from your apps and services to 1 logging instance. logging offer libraries for Node.JS, Python, Rails, Ruby, Go, iOS, Java, and PHP.\n\n\n\nFor any method that you adopt, you have the flexibility to choose the logging instance where you want to send data per log source. Decide how many instances you might need to collect data from all your log sources based on who can see the data and the type of data that is collected. Avoid sending data to a logging instance that has the platform logs flag enabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoption"},{"document_id":"ibmcld_07043-7-2215","score":11.6643026382,"text":"\nGlossary \n\n\n\nDefinitions of Discovery terms\n\n Term Definition \n\n Classifier A resource that you can train to recognize document types and categorize them in your collection. You can create two types of classifiers, a text classifier and a document classifier. A text classifier can classify documents based on words and phrases that are extracted from the body text with their part of speech information taken into account. A document classifier can classify documents based on words and phrases that are extracted from the body text fields with information from their part of speech and the other enrichments that are applied to the body text taken into account. The information from the other nonbody fields are also used. [Learn more](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-cm-doc-classifier) \n Collection A set of documents that you can enrich and later search for meaningful information. [Learn more](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections). \n Content Intelligence A feature that you can use to enrich documents in a Document Retrieval project such that the project can recognize information that is relevant to business contracts. A Document Retrieval project with this feature enabled is referred to as a Document Retrieval for Contracts project type. [Learn more](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projectsdoc-retrieval-contracts) \n Data source An external application or service where valuable knowledge resources are stored. Connect to a service where your data is stored so you can crawl the data without having to move it. [Learn more](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections). \n Domain-specific Relates to terms and concepts that have special meaning to an industry or business. In tennis, for example, the term love has a special meaning. It represents a zero score. If you built a tennis-related application, you would teach Discovery that the term love has a meaning in the domain of tennis that is different from the generally understood meaning. \n Enrichment What you add to documents in your collection to identify or tag terms in the document that are significant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-glossary"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1510196182,"ndcg_cut_10":0.268535723}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06160-11142-12906","score":12.1577336798,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-11475-13230","score":12.1577336798,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10394-7-1848","score":10.240719415,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_10395-7-1827","score":10.1892933371,"text":"\nUpdating VPC worker nodes that use OpenShift Data Foundation \n\nVirtual Private Cloud\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc"},{"document_id":"ibmcld_10596-9883-11854","score":9.9853557397,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-12611-14167","score":9.9354224337,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\nkubectl describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) . Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.\n\nkubectl get mutatingwebhookconfigurations\n\nkubectl get validatingwebhookconfigurations\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-12943-14509","score":9.7945682972,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\noc describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) and the [Openshift Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool). Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-10037-11653","score":9.7545330777,"text":"\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_05713-581893-583377","score":9.6583971305,"text":"\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10596-5350-7330","score":9.4450939659,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10394-7-1848","score":14.43670107,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_06320-2897-4555","score":13.9310145791,"text":"\n[NodeSync](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs. Traditional repairs are unnecessary, as the automation ensures that NodeSync handles the repairs for you.\n\nWhile the automation enables NodeSync, you can also manually create tables with NodeSync enabled so that the service can repair the tables' data when necessary:\n\nCREATE TABLE myTable (...) WITH nodesync = { 'enabled': 'true'};\n\nFor more information, see [enabling the NodeSync service](https:\/\/docs.datastax.com\/en\/dse\/6.7\/dse-admin\/datastax_enterprise\/config\/enablingNodesync.html).\n\nNodetool is unsupported. Manual repairs that are issued against any table that is enabled with the NodeSync service [are ignored](https:\/\/docs.datastax.com\/en\/opscenter\/6.5\/opsc\/online_help\/services\/opscNodeSyncService.htmlNodeSyncServiceversusRepairService). See error:\n\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https:\/\/github.com\/nosqlbench\/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-getting-started"},{"document_id":"ibmcld_10395-7-1827","score":13.4161952201,"text":"\nUpdating VPC worker nodes that use OpenShift Data Foundation \n\nVirtual Private Cloud\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc"},{"document_id":"ibmcld_06209-6757-8643","score":13.3368806691,"text":"\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10642-6354-8294","score":13.1971706173,"text":"\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-8154-10055","score":13.0066546128,"text":"\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10394-1469-2994","score":12.9094589439,"text":"\nIf you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.\n\n\n\n\n\n\n\n Step 2: Determine which worker nodes you want to update \n\nMajor\n\nMinor\n\n\n\n1. List your worker nodes by using the oc get nodes command and determining which worker nodes you want to update.\n\noc get nodes\n\nExample output\n\nNAME STATUS ROLES AGE VERSION\n10.241.0.4 Ready master,worker 106s v1.21.6+4b61f94\n10.241.128.4 Ready master,worker 22d v1.21.6+bb8d50a\n10.241.64.4 Ready master,worker 22d v1.21.6+bb8d50a\n\n\n\n\n\n\n\n Step 3: Scale down OpenShift Data Foundation \n\nMajor\n\nMinor\n\n\n\n1. For each worker node that you found in the previous step, find the rook-ceph-mon and rook-ceph-osd deployments.\n\noc get pods -n openshift-storage -o wide | grep -i <node_name>\n2. Scale down the deployments that you found in the previous step.\n\noc scale deployment rook-ceph-mon-c --replicas=0 -n openshift-storage\noc scale deployment rook-ceph-osd-2 --replicas=0 -n openshift-storage\noc scale deployment --selector=app=rook-ceph-crashcollector,node_name=NODE-NAME --replicas=0 -n openshift-storage\n\n\n\n\n\n\n\n Step 4: Cordon and drain the worker node \n\nMajor\n\nMinor\n\n\n\n1. Cordon the node. Cordoning the node prevents any pods from being scheduled on this node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_06209-19911-21816","score":12.7597736045,"text":"\nAs security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_updateportworx_vpc_up).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud ks worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the VPC worker node to the same patch by using the ibmcloud ks worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10395-1448-2944","score":12.6535663212,"text":"\nIf you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.\n\n\n\n\n\n\n\n Step 2: Determine which storage nodes you want to update \n\nMajor\n\nMinor\n\n\n\n1. List your worker nodes by using oc get nodes and determine which storage nodes you want to update.\n\noc get nodes\n\nExample output\n\nNAME STATUS ROLES AGE VERSION\n10.241.0.4 Ready master,worker 106s v1.21.6+4b61f94\n10.241.128.4 Ready master,worker 22d v1.21.6+bb8d50a\n10.241.64.4 Ready master,worker 22d v1.21.6+bb8d50a\n\n\n\n\n\n\n\n Step 3: Scale down OpenShift Data Foundation \n\nMajor\n\nMinor\n\n\n\n1. For each worker node that you found in the previous step, find the rook-ceph-mon and rook-ceph-osd deployments.\n\noc get pods -n openshift-storage -o wide | grep -i <node_name>\n2. Scale down the deployments that you found in the previous step.\n\noc scale deployment rook-ceph-mon-c --replicas=0 -n openshift-storage\ndeployment.apps\/rook-ceph-mon-c scaled\noc scale deployment rook-ceph-osd-2 --replicas=0 -n openshift-storage\ndeployment.apps\/rook-ceph-osd-2 scaled\noc scale deployment --selector=app=rook-ceph-crashcollector,node_name=NODE-NAME --replicas=0 -n openshift-storage\n\n\n\n\n\n\n\n Step 4: Cordon and drain the worker node \n\nMajor\n\nMinor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc"},{"document_id":"ibmcld_10290-113594-115347","score":12.6164328886,"text":"\nibmcloud oc worker reload --cluster my_cluster -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1 -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w2\n\n\n\n\n\n\n\n ibmcloud oc worker replace \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nDelete a worker node and replace it with a new worker node in the same worker pool.\n\nThe replacement worker node is created in the same zone and has the same flavor as the old worker node, but might be assigned new public or private IP addresses. You might replace a worker node if you can't reload or update the worker node, such as if it enters a troubled state.\n\nYou can also use this command to update the Kubernetes version of the worker node to match the major and minor version of the Kubernetes master by including the --update option. If you don't include the --update option, patch version updates are applied to your worker node, but not major or minor updates. To see the changes from one major, minor, or patch version to the next, review the [Version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) documentation. Remember that your worker nodes can be only up to two versions behind the master version (n-2).\n\nWhen you replace a worker node, keep in mind the following considerations.\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Multiple worker nodes are replaced concurrently: If you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06160-11142-12906","score":14.9856637942,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-11475-13230","score":14.9856637942,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-5350-7330","score":13.5391188415,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-5357-7356","score":13.4294028625,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10394-7-1848","score":13.1263949682,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_06209-6757-8643","score":13.0908843804,"text":"\n* [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n* [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10227-2655-4315","score":13.0040067593,"text":"\n* See [Getting help](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) for more details about using the forums.\n\n\n\n\n\n\n\n\n\n Contacting support \n\nBefore you open a support case, gather relevant information about your cluster environment.\n\n\n\n1. Get your cluster details.\n\nibmcloud oc cluster get -c <cluster_name_or_ID>\n2. If your issue involves worker nodes, get the worker node details.\n\n\n\n1. List all worker nodes in the cluster, and note the ID of any worker nodes with an unhealthy State or Status.\n\nibmcloud oc worker ls -c <cluster_name_or_ID>\n2. Get the details of the unhealthy worker node.\n\nibmcloud oc worker get -w <worker_ID> -c <cluster_name_or_ID>\n\n\n\n3. For issues with resources within your cluster such as pods or services, log in to the cluster and use the Kubernetes API to get more information about them.\n\nYou can also use the [IBM Cloud Kubernetes Service Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool) to gather and export pertinent information to share with IBM Support.\n4. Contact IBM Support by [opening a case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form). To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n5. For the Problem type, search for or select Red Hat OpenShift on IBM Cloud.\n6. For the Case details, provide a descriptive title and include the details that you previously gathered. From the Resources, you can also select the cluster that the issue is related to.\n\n\n\n\n\n\n\n Requesting access to allowlisted features \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help"},{"document_id":"ibmcld_06209-8154-10055","score":12.9832858871,"text":"\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10596-9883-11854","score":12.9590196394,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10642-6354-8294","score":12.9558429176,"text":"\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.2,"recall_10":0.2,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1312050775,"ndcg_cut_10":0.1312050775}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10068-186013-187552","score":19.7848576852,"text":"\nRed Hat OpenShift 4.3.12-x86_64 4.3.18-x86_64 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.3\/release_notes\/ocp-4-3-release-notes.html). \n Red Hat OpenShift Console configuration N\/A N\/A Fixed a problem that might leave the Red Hat OpenShift Console inaccessible after a cluster master operation. \n Red Hat OpenShift Control Plane Operator 3b3ff62 bc493d4 See the [Red Hat OpenShift HyperShift toolkit repository](https:\/\/github.com\/openshift\/hypershift-toolkit\/commit\/bc493d4b51ea7d3d8e60453dee2407baf03e1c6d). Removed incorrect notifications about available cluster updates that referred to OpenShift Container Platform versions instead of Red Hat OpenShift on IBM Cloud versions. \n Red Hat OpenShift HyperShift toolkit 3b3ff62 bc493d4 See the [Red Hat OpenShift HyperShift toolkit repository](https:\/\/github.com\/openshift\/hypershift-toolkit\/commit\/bc493d4b51ea7d3d8e60453dee2407baf03e1c6d). Removed incorrect notifications about available cluster updates that referred to OpenShift Container Platform versions instead of Red Hat OpenShift on IBM Cloud versions. \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.3.14_1522_openshift, released 11 May 2020 \n\nThe following table shows the changes that are in the worker node fix pack update 4.3.13_1522_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.13_1521_openshift\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"},{"document_id":"ibmcld_10527-7-1958","score":19.5241792044,"text":"\nArchitecture and dependencies of the service \n\nReview sample architectures, components, and dependencies for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nIn Red Hat OpenShift on IBM Cloud, your clusters comprise an IBM-managed master that secures components such as the API server and etcd, and customer-managed worker nodes that you configure to run you app workloads, as well as Red Hat OpenShift-provided default components. The default components within the cluster, such as the Red Hat OpenShift web console or OperatorHub, vary with the Red Hat OpenShift version of your cluster.\n\n\n\n Classic Red Hat OpenShift version 4 architecture \n\nReview the architecture diagram and then scroll through the following tables for a description of master and worker node components in Red Hat OpenShift on IBM Cloud clusters that run version 4 on classic infrastructure. For more information about the OpenShift Container Platform architecture, see the [Red Hat OpenShift docs](https:\/\/docs.openshift.com\/container-platform\/4.11\/architecture\/architecture.html).\n\nWhen you run oc get nodes, you might notice that the ROLES of your worker nodes are marked as both master,worker. These nodes are worker nodes in IBM Cloud, and don't include the master components that are managed by IBM. Instead, these nodes are marked as master because they run OpenShift Container Platform components that are required to set up and manage default resources within the cluster, such as the OperatorHub and internal registry.\n\nZoom\n\n![Red Hat OpenShift on IBM Cloud cluster architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/openshift\/\/images\/cs_org_ov_both_ses_roks4.png)\n\nFigure 1. Red Hat OpenShift version 4 master components\n\n\n\n Red Hat OpenShift version 4 master components \n\nReview the following components in the IBM-managed master of your Red Hat OpenShift on IBM Cloud cluster.\n\nYou can't modify these components.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architecture"},{"document_id":"ibmcld_10214-15046-17052","score":19.4575345052,"text":"\nKeep in mind that some services such as Ingress might require multiple worker nodes for high availability, and you might not be able to run these services or your apps in the smallest size cluster possible.\n\nClassic clusters only: Initially, you can create a classic cluster with only 1 worker node. This operation is allowed for multizone clusters, so that you are not forced to create 2 worker nodes per zone. If you have a single zone cluster, resize the worker pool to 2. Also, note that after resizing a worker pool to 2, you can't later resize back down to 1 worker node.\n\n\n\n\n\n Which Red Hat OpenShift versions does the service support? \n\nRed Hat OpenShift on IBM Cloud concurrently supports multiple versions of Red Hat OpenShift. When a new version (n) is released, versions up to 2 behind (n-2) are supported. Versions more than 2 behind the latest (n-3) are first deprecated and then unsupported.\n\nFor more information about supported versions and update actions that you must take to move from one version to another, see [Red Hat OpenShift on IBM Cloud version information](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\n\n\n\n\n Which worker node operating systems does the service support? \n\nFor a list of supported worker node operated systems by cluster version, see [Red Hat OpenShift on IBM Cloud version information](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\n\n\n\n\n Where is the service available? \n\nRed Hat OpenShift on IBM Cloud is available worldwide. You can create clusters in every supported Red Hat OpenShift on IBM Cloud region.\n\nFor more information about supported regions, see [Locations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zonesregions-and-zones).\n\n\n\n\n\n Is the service highly available? \n\nYes. By default, Red Hat OpenShift on IBM Cloud sets up many components such as the cluster master with replicas, anti-affinity, and other options to increase the high availability (HA) of the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10397-7-2020","score":19.4412623742,"text":"\nVersion 3.11 change log \n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters that run version 3.11. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\nRed Hat OpenShift version 3.11 is unsupported as of 6 June 2022.\n\n\n\n Overview \n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features, which are subject to change, are disabled.\n\nCheck the [Security Bulletins on IBM Cloud Status](https:\/\/cloud.ibm.com\/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't also refer to an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\n\n\n\n\n Version 3.11 change log \n\nReview the change logs for Red Hat OpenShift on IBM Cloud version 3.11 patch updates.\n\n\n\n Change log for worker node fix pack 3.11.705_1634_openshift, released 7 June 2022 \n\nThe following table shows the changes that are in the worker node fix pack 3.11.705_1634_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_311"},{"document_id":"ibmcld_10401-7-1942","score":19.410417211,"text":"\nVersion 4.13 change log \n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters that run version 4.13. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\n\n\n Overview \n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features are disabled and subject to change.\n\nCheck the [Security Bulletins on IBM Cloud Status](https:\/\/cloud.ibm.com\/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't include an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\n\n\n Change log for worker node fix pack 4.13.4_1525_openshift, released 03 July 2023 \n\nThe following table shows the changes that are in the worker node fix pack 4.13.4_1525_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.13.3_1523_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift on IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_413"},{"document_id":"ibmcld_10400-7-1945","score":19.410417211,"text":"\nVersion 4.12 change log \n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters that run version 4.12. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\n\n\n Overview \n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features are disabled and subject to change.\n\nCheck the [Security Bulletins on IBM Cloud Status](https:\/\/cloud.ibm.com\/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't include an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\n\n\n Change log for worker node fix pack 4.12.22_1550_openshift, released 03 July 2023 \n\nThe following table shows the changes that are in the worker node fix pack 4.12.22_1550_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.12.21_1547_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift on IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_412"},{"document_id":"ibmcld_10154-9468-11364","score":19.3453036727,"text":"\nIn this sense, the installation is similar to IPI for you because you don't have to manage all the infrastructure and network settings. IBM also provides patch updates that you can choose to apply to your worker nodes, from the IBM Cloud interface (not the Red Hat OpenShift web console). SSH is disabled for added security. \n OCP versions and patch updates You are responsible for updating the underlying infrastructure for the master and worker nodes. You can use the Red Hat OpenShift web console to update OCP versions. IBM automatically applies updates to the master, and provides version updates and security patch updates for the worker nodes. You choose when to apply these updates to your worker nodes, from the IBM Cloud interface (not the Red Hat OpenShift web console). Supported versions might vary from standard OpenShift Container Platform. \n Autoscaling compute machines You can set up a ClusterAutoscaler resource. You can set up the [cluster autoscaler plug-in](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-scaling-classic-vpc). \n Worker node operating system CoreOS or RHEL For a list of supported operating systems by cluster version, see [Red Hat OpenShift on IBM Cloud version information](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions). \n Support Provided per the terms of your Red Hat subscription or cloud provider. You can use the oc adm must-gather tool to help gather information. Provided by [IBM Cloud Support](https:\/\/www.ibm.com\/cloud\/support). You can use the oc adm must-gather tool, or the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool) to help gather information. \n Red Hat OpenShift web console You set up and can configure or disable the Red Hat OpenShift web console. The Red Hat OpenShift web console is set up for you. You can't configure or disable the web console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10398-7-2009","score":19.3276949099,"text":"\nVersion 4.10 change log \n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters that run version 4.10. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\n\n\n Overview \n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features, which are subject to change, are disabled.\n\nCheck the [Security Bulletins on IBM Cloud Status](https:\/\/cloud.ibm.com\/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't include an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\n\n\n\n\n Change logs \n\nReview the version 4.10 change log.\n\n\n\n Change log for worker node fix pack 4.10.62_1575_openshift, released 03 July 2023 \n\nThe following table shows the changes that are in the worker node fix pack 4.10.62_1575_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.10.61_1572_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift on IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_410"},{"document_id":"ibmcld_10399-7-2013","score":19.3276949099,"text":"\nVersion 4.11 change log \n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters that run version 4.11. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\n\n\n Overview \n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features are disabled and subject to change.\n\nCheck the [Security Bulletins on IBM Cloud Status](https:\/\/cloud.ibm.com\/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't include an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n\n\n\n\n\n Change logs \n\nReview the version 4.11 change log.\n\n\n\n Change log for worker node fix pack 4.11.43_1562_openshift, released 03 July 2023 \n\nThe following table shows the changes that are in the worker node fix pack 4.11.43_1562_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.11.43_1559_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift on IBM Cloud. N\/A N\/A N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_411"},{"document_id":"ibmcld_10068-66169-67695","score":19.1877523495,"text":"\nRed Hat OpenShift on IBM Cloud Server v4.5.0-20201022 v4.5.0-20201113 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.5.0+20201113). \n Red Hat OpenShift on IBM Cloud toolkit 4.5.0+20201022 4.5.0+20201113 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.5.0+20201113). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.5.17_1519_openshift, released 9 November 2020 \n\nThe following table shows the changes that are in the worker node fix pack update 4.5.17_1519_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.5.15_1518_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift 4.5.15 4.5.17 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.5\/release_notes\/ocp-4-5-release-notes.htmlocp-4-5-17). \n RHEL 7 Packages N\/A N\/A Updated worker node image with package updates for [CVE-2020-15999](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-15999). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.5.15_1518_openshift, released 26 October 2020 \n\nThe following table shows the changes that are in the worker node fix pack update 4.5.15_1518_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07953-7-2429","score":13.8021558771,"text":"\nEnsuring isolation between Satellite management functions and workload functions \n\nA key aspect of the IBM Cloud Framework for Financial Services is to separate user workloads from system management functions and isolate security functions from nonsecurity functions. The network infrastructure of the Satellite location can be used to provide physical and logical separation between the Satellite management control plane and your workloads.\n\nNetwork flow rule design should follow the IBM Cloud Framework for Financial Services's [information flow guidelines](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-boundary-protection) by using a \"deny by default\" approach.\n\n\n\n Before you begin \n\n\n\n1. Complete the work for [account setup and management](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-account-setup).\n2. Complete [Satellite location setup](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locations).\n\n\n\n\n\n\n\n Identify network areas for control plane hosts and workload hosts \n\n\n\n1. Place control plane hosts into a separate network segment. Control plane hosts support various management and security-related components of the Satellite location. To facilitate effective network flow restrictions within the Satellite location, it is recommended to place control plane hosts into a separate network segment (whether physical or virtual) that can enable clear identification of source or destination of the network flows related to control plane functionality. The control plane hosts can be deployed to different physical locations, but the address space they are assigned to should provide an easy way to identify this group of hosts (for example, CIDR blocks).\n2. Designate a separate network segment for each group of Satellite hosts assigned to Red Hat OpenShift on IBM Cloud workload clusters. Satellite hosts that are assigned to Red Hat OpenShift on IBM Cloud workload clusters (workload hosts) should use their own network segments that would enable network flow control and monitoring between workload hosts, control plane, and other components outside of the Satellite location. It is recommended to designate a separate network segment (virtual subnet, VLAN, or a similar entity) for each group of Satellite hosts assigned to the same workload cluster.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-connectivity-management-isolation"},{"document_id":"ibmcld_14497-9718-11443","score":13.724704078,"text":"\nThis step is described in [Prerequisites for installation](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-prereq-intro).\n* Add logical switches - Two logical switches are created; OpenShift-LS the network the OpenShift VMs are deployed onto and OpenShift-DLR-Transit, the uplink between the DLR and the Edge.\n* Add an ESG - An external services gateway (ESG) is a virtual appliance that provides North-South routing, and other network functions. In this architecture, the ESG is used for; routing, NAT, firewall, and load-balancing. As the ESGs are configured as active - passive pair, DRS anti-affinity rules are used to ensure that NSX Edges do not run on the same host. Static routes are used to direct traffic to either the internet or the IBM private Network. This step is described in [Red Hat OpenShift NSX Edge configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-nsxedge-intro).\n* Add a DLR - A distributed logical router (DLR) is a virtual appliance that contains the routing control plane and it distributes the data plane in kernel modules to each hypervisor host. The DLR provides East-West distributed routing and is the default gateway for the Red Hat OpenShift VMs that will be installed on the Red Hat OpenShift logical switch. The NSX DLR virtual machines are configured as an active - passive pair, and vSphere Distributed Resource Scheduler (DRS) anti-affinity rules are created to ensure that the DLR VMs do not run on the same host. This step is described in [Red Hat OpenShift NSX DLR configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-nsxdlr-intro).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_10691-8024-10024","score":12.9986000759,"text":"\nWhen you create a VPC cluster and enable both the public and private cloud service endpoints during cluster creation, the public cloud service endpoint is used by default for access to components such as the Red Hat OpenShift web console for your cluster. In order for console pods to establish a secure, public connection over the internet through the public service endpoint, you must enable a public gateway on each VPC subnet that your worker nodes are deployed to.\n\nWhen you create a VPC cluster and enable only the private cloud service endpoint during cluster creation, the private cloud service endpoint is used by default to access Red Hat OpenShift components such as the Red Hat OpenShift web console or OperatorHub. You must be connected to the private VPC network, such as through a VPN connection, to access these components or run kubectl commands on your cluster. Also, if an IBM Cloud service does not support private cloud service endpoints, your worker nodes must be connected to a subnet that has a public gateway attached to it. The pods on those worker nodes can securely communicate with the services over the public network through the subnet's public gateway. Note that a public gateway is not required on your subnets to allow inbound network traffic from the internet to LoadBalancer services or ALBs.\n\nWithin one VPC, you can create only one public gateway per zone, but that public gateway can be attached to multiple subnets within the zone. For more information about public gateways, see the [Networking for VPC documentation](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-networking-for-vpcpublic-gateway-for-external-connectivity).\n\n\n\n\n\n Virtual private endpoints (VPE) \n\nWorker nodes can communicate with the Kubernetes master through the cluster's [virtual private endpoint (VPE)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpe).\n\nA VPE is a virtual IP address that is bound to an endpoint gateway. One VPE gateway resource is created per cluster in your VPC.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-subnets"},{"document_id":"ibmcld_14870-7-1912","score":12.9059712515,"text":"\nDeployment Journey Overview \n\nIBM Cloud\u00ae Virtual Private Cloud(VPC) allows you to establish your own virtual private cloud by defining a virtual network that is logically isolated from all other public cloud tenants. The underlying software defined networking (SDN) and virtual network functions allows you to quickly establish the network constructs and on-prem connectivity needed to run your workload. The information contained within this document is meant to serve as a technical guide for beginning with a new IBM Cloud Account and leading towards a fully configured VPC network environment.\n\nWelcome to the Deployment Journey for VPC on IBM Cloud! Use the sidebar on the left to navigate between the journey points.\n\n\n\n Journey Map \n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d50364af907081c3c38f99c11f35dd9cab4b2510\/vpc-journey\/images\/overview\/journey-map.png)\n\n\n\n\n\n Assumptions \n\nThis deployment guide will be assuming the following points. Please note that while your circumstance may not be exactly identical, you will still benefit from the overall journey steps and concepts covered in this guide.\n\n\n\n* You are already familar with the concepts introduced in the \"Tour IBM Cloud\" videos available on the [Getting Started with IBM Cloud](https:\/\/cloud.ibm.com\/cloud\/get-started) page.\n* Access groups will need to be defined so only certain users have the ability to create and manage the VPC network settings (i.e. CIDR ranges, Subnet ACL rules, etc.,).\n* You have a networking background and familar with concepts such as IP Addressing, subnets, routing, etc.,\n* Focus will be on establishing the underlying network connectivity to support VPC based workloads.\n\n\n\n* Note: A separate deployment guide will cover the compute resources which runs within the VPC like IBM Kubernetes Services (IKS), Red Hat OpenShift, IBM Code Engine, and VPC Virtual Server Instances (VSIs).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc-journey?topic=vpc-journey-vpc-overview"},{"document_id":"ibmcld_16729-24189-26236","score":12.8956746226,"text":"\nYou will create a Code Engine project, select the project and deploy Code Engine entities - applications and jobs - to the project. You will learn how to bind IBM Cloud services to your Code Engine entities. You will also understand the auto-scaling capability of Code Engine where instances are scaled up or down (to zero) based on incoming workload.\n\nCode Engine Kubernetes service\n\n+2\n\nObject Storage,Natural Language Understanding\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Tutorial: Using Secure Build Server with a digital wallet](https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-tutorial_secure_build_server)Tutorial: Using Secure Build Server with a digital wallet\n\nIn this tutorial, you use the IBM Cloud\u00ae Hyper Protect Virtual Servers Secure Build Server to build a digital wallet application, then you use Hyper Protect Virtual Servers to deploy the resulting application in the public cloud.\n\nHyper Protect Virtual Servers\n\n\n\n* 1 hour\n* 2022-02-14\n\n\n\n[Tutorial: Setting up the secure network](https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-tutorial_network)Tutorial: Setting up the secure network\n\nThis tutorial describes how you can set up the secure network which provides an end to end encrypted network communication for IBM Cloud\u00ae Hyper Protect Virtual Servers services. This tutorial is intended for IBM Cloud Hyper Protect Virtual Servers customers. Contact your IBM representative for access to the GitHub repository.\n\nHyper Protect Virtual Servers\n\n\n\n* 1 hour\n* 2022-07-20\n\n\n\n[Setting up a Red Hat OpenShift for HPC cluster](https:\/\/cloud.ibm.com\/docs\/hpc-openshift?topic=hpc-openshift-setting-up-red-hat-openshift-hpc-cluster)Setting up a Red Hat OpenShift for HPC cluster\n\nWhile IBM values the use of inclusive language, terms that are outside of IBM's direct influence are sometimes required for the sake of maintaining user understanding. As other industry leaders join IBM in embracing the use of inclusive language, IBM will continue to update the documentation to reflect those changes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_14913-0-1238","score":12.8821559456,"text":"\n\n\n\n\n\n\n  About virtual network functions over VPC \n\nNetwork Function Virtualization (NFV) is the network infrastructure behind virtualizing network services (such as routers, firewalls, and load balancers) that were traditionally run on proprietary hardware. These services, called Virtual Network Functions (VNFs), are packaged as virtual machines (VMs) on commodity hardware, which allows service providers to run their networks on standard servers instead of proprietary ones. This third-party software interacts with the IBM Software-Defined Networking (SDN) controller to offer easy configuration, centralized management, and lower operational costs.\n\nWorking along with IBM Cloud\u00ae Schematics (Infrastructure as Code) and the IBM Content catalog, customers are able to instantiate best-in-network solutions to manage their workload.\n\nBenefits include:\n\n\n\n*  Instantiating virtual network services and modifying configurations without the need to deploy new network hardware.\n*  Rapid service delivery with the agility to scale well above physical hardware.\n*  Centralized policy control.\n*  Using the same routers, firewalls, load balancers, and VPNs in IBM Cloud that were used in physical hardware or other cloud providers.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vnf"},{"document_id":"ibmcld_07953-6858-8619","score":12.8562090207,"text":"\nEnsure that workload hosts have outbound access to IBM Cloud public endpoints. For more information, see [Accessing external resources](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-connectivity-to-external).\n\n\n\n\n\n\n\n (Optional) Configure virtual network flow rules within Red Hat OpenShift on IBM Cloud \n\n\n\n1. Configure virtual network flow rules within Red Hat OpenShift on IBM Cloud. In addition to the network flow controls implemented within the IaaS layer of the Satellite location, you can use virtual networking features of Red Hat OpenShift on IBM Cloud to control network flows within and into your cluster. You can use [Kubernetes network policies](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-kube-policies) or [Calico network policies](https:\/\/projectcalico.docs.tigera.io\/security\/protect-hosts) to define network flow restrictions for each workload deployed on your Red Hat OpenShift on IBM Cloud cluster.\n\n\n\n\n\n\n\n Related controls in IBM Cloud Framework for Financial Services \n\nThe following IBM Cloud Framework for Financial Services controls below are most related to this guidance. However, in addition to following the guidance here, do your own due diligence to ensure you meet the requirements.\n\n\n\nTable 1. Related controls in IBM Cloud Framework for Financial Services\n\n Family Control \n\n Access Control (AC) [AC-20 Use of External Information Systems](https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ac-20) \n Security Assessment and Authorization (CA) [CA-3 System Interconnections](https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ca-3)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-connectivity-management-isolation"},{"document_id":"ibmcld_07953-5165-7311","score":12.7181338174,"text":"\nFor more information, see [Accessing external resources from the Satellite location](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-connectivity-to-external).\n\n\n\n\n\n\n\n Configure network flow rules for workload hosts \n\nThe following rules for workload hosts must be implemented within the networking infrastructure (virtual or physical) provided by the operator of the Satellite location.\n\n\n\n1. Allow inbound network flows to workload hosts from management resources within your environment, such as a bastion host in your management plane. It is recommended to use networking components capable of controlling Level 7 traffic to limit access to services such as Red Hat OpenShift on IBM Cloud web console based on the FQDN of the request. A combination of network rules and an HTTP proxy can be used as well.\n2. Allow bidirectional network flows between workload hosts and control plane hosts of the same Satellite location.\n3. Identify and allow network flows to other application resources within the environment that is required by the deployed workloads. For example, databases that are not deployed on the same workload service.\n4. Identify and allow network flows to other services deployed in the Satellite location (for example, another Red Hat OpenShift on IBM Cloud cluster) if required by the workload application architecture.\n5. Identify and allow the ingress network flows from the edge plane that is used to expose the workload services to application consumers (for example, load balancers).\n6. Allow outbound network flows to service endpoints in management plane that is needed for logging and monitoring.\n7. Ensure that workload hosts have outbound access to IBM Cloud public endpoints. For more information, see [Accessing external resources](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-connectivity-to-external).\n\n\n\n\n\n\n\n (Optional) Configure virtual network flow rules within Red Hat OpenShift on IBM Cloud \n\n\n\n1. Configure virtual network flow rules within Red Hat OpenShift on IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-satellite-architecture-connectivity-management-isolation"},{"document_id":"ibmcld_16729-204313-206171","score":12.6622657014,"text":"\nIBM Cloud Load Balancer,High availability and resiliency for infrastructure\n\n\n\n* 45 minutes\n* 2021-09-03\n\n\n\n[Setting up a Red Hat OpenShift for HPC cluster](https:\/\/cloud.ibm.com\/docs\/hpc-openshift?topic=hpc-openshift-setting-up-red-hat-openshift-hpc-cluster)Setting up a Red Hat OpenShift for HPC cluster\n\nWhile IBM values the use of inclusive language, terms that are outside of IBM's direct influence are sometimes required for the sake of maintaining user understanding. As other industry leaders join IBM in embracing the use of inclusive language, IBM will continue to update the documentation to reflect those changes.\n\nVirtual Private Cloud (VPC) IBM Cloud Load Balancer\n\n+3\n\nMonitoring,Log Analysis,Red Hat OpenShift for HPC\n\n\n\n* 60 minutes\n* 2022-04-14\n\n\n\n[Setting up an HPC cluster](https:\/\/cloud.ibm.com\/docs\/ibm-spectrum-lsf?topic=ibm-spectrum-lsf-using-hpc-cluster)Setting up an HPC cluster\n\nThe HPC cluster consists of a login node, a storage node where the block storage volume is attached, 1 - 3 LSF management nodes, and a number of LSF worker nodes.\n\nVirtual Servers for Classic Virtual Private Cloud (VPC)\n\n+2\n\nIBM Cloud Load Balancer,IBM Spectrum LSF\n\n\n\n* 60 minutes\n* 2023-03-24\n\n\n\n[Hosting web applications from a secure private network](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-web-app-private-network)Hosting web applications from a secure private network\n\nThis tutorial takes you through the creation of a scalable and secure Internet facing web application hosted in private network secured using a virtual router appliance (VRA), VLANs, NAT and firewalls. The application comprises a load balancer, two web application servers and a MySQL database server. It combines three tutorials to illustrate how web applications can be securely deployed on the IBM Cloud IaaS platform using classic networking.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_07986-13268-15188","score":12.6577957862,"text":"\nThe policies that you define determine when virtual server instances are added or removed from your instance group.\n\n\n\n\n\n\n\n Containers \n\n\n\n Red Hat OpenShift on IBM Cloud \n\nIn addition to Virtual Servers for VPC, you can use [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview) if you want to run containers. {{site.data.content.openshift-service-description}}\n\nIn practice, when you choose Red Hat OpenShift on IBM Cloud for your primary compute, you might also need one or more instances of Virtual Servers for VPC for other parts of the reference architecture.\n\n\n\n\n\n IBM Cloud Container Registry \n\nUse [Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview) to store and access private container images. Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. This service is required if using Red Hat OpenShift on IBM Cloud.\n\n\n\n\n\n\n\n Networking - VPC infrastructure \n\n\n\n IBM Cloud Application Load Balancer for VPC \n\nUse [Application Load Balancer for VPC (ALB)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-load-balancers) to distribute traffic among multiple server instances within the same region of your VPC. You can create a public or private ALB.\n\n[IBM Cloud\u00ae Network Load Balancer for VPC (NLB)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-network-load-balancers) is also IBM Cloud for Financial Services Validated, but does not span zones. So, NLBs are not typically used in applications where high availability is needed.\n\n\n\n\n\n IBM Cloud Virtual Private Network (VPN) for VPC \n\nYou can use the [VPN for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-using-vpn) service to securely connect your VPC to another private network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-about"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.167160455}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16666-10416-12326","score":11.5942240075,"text":"\n* Add the metadata catalogs to manage your table schemas.\n* Select the query engine to work with your data.\n\n\n\nComplete the following steps:\n\n\n\n1. In the Bucket configuration page, select Provision new IBM-managed bucket.\n2. Click Next. This displays the Catalogs configuration page.\n3. In the Catalogs configuration page, select a catalog.\n4. Click Next. This displays the Engine configuration page.\n5. In the Engine configuration page, select the Presto engine and smallest starter (1 coordinator node 1 worker node memory optimized).\n6. Click Next. This displays the Summary page.\n7. In the Summary page, review the configurations before you finish setting up your data infrastructure.\n\nWhen the setup is complete, the watsonx.data home page is displayed. You are all set to use the watsonx.data or you can configure it further.\n8. Click Finish and go. This displays the Infrastructure manager page.\n\n\n\nAlthough you can add more engines, catalogs, buckets, and databases in the Infrastructure manager page if you want to, this would change the consumption rate of your promo code. When you add items in the Infrastructure manager, you can see the resource unit consumption per hour.\n\nThe promotion credits consumption begins immediately after you configure and the support services are created for your metadata. Ensure that you pause the Presto engine when it is not used. This helps in optimizing the usage credit.\n\n\n\n\n\n Step 6: Ingesting data \n\nThe data files are ingested into watsonx.data using CLI. For the steps to perform ingestion, see the [Ingesting data through the command-line interface (CLI)](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-ingest_data_cli)\n\n\n\n\n\n Step 7: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_hp_intro"},{"document_id":"ibmcld_13498-18143-19979","score":11.475985942,"text":"\n* LIMIT: Restrict the number of rows that are returned from the result set of the fullselect. The number of rows can be defined by an expression or by using the keyword ALL that causes all rows to be returned.\n\n\n\nDISTRIBUTE BY, SORT BY, and CLUSTER BY have an effect only during your SQL query execution and do not influence the query result that is written back to Cloud Object Storage. Use these clauses only in execution of subqueries to optimize the outer query execution that works on the intermediate result sets produced by the sub queries. To define the persistent target of the overall query that is written back to Cloud Object Storage, you need to use the dedicated [resultClause](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceresultClause) instead.\n\n\n\n\n\n Examples - values clause \n\nThe set operator examples use values clauses to define result sets for the set operations. For more information about the values clause, see [valuesClause](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencevaluesClause).\n\n-- set union eliminating duplicate rows\nSELECT * FROM VALUES 1, 2 ,3 UNION VALUES 1, 2, 3\n\n-- set union eliminating duplicate rows\nSELECT * FROM VALUES 1, 2 ,3 UNION DISTINCT VALUES 1, 2, 3\n\nThe result of the example queries is shown in the following table.\n\n\n\nTable 3. Query result for the example set\n\n COL1 \n\n 1 \n 3 \n 2 \n\n\n\n-- set union with duplicate rows\nSELECT * FROM VALUES 1, 2 ,3 UNION ALL VALUES 1, 2, 3\n\nThe result of the example query is shown in the following table.\n\n\n\nTable 4. Query result for the example set\n\n COL1 \n\n 1 \n 2 \n 3 \n 1 \n 2 \n 3 \n\n\n\n-- intersecting set eliminating duplicate rows\nSELECT * FROM VALUES 1, 2 ,3 INTERSECT VALUES 2, 2, 3, 3, 3\n\n-- intersecting set eliminating duplicate rows\nSELECT * FROM VALUES 1, 2 ,3 INTERSECT DISTINCT VALUES 2, 2, 3, 3, 3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_00580-37889-39953","score":11.4654310802,"text":"\nIf you need to access objects within documents, you can use standard dot notation for example, address.zipcode to access a postal code string inside an address object.\n\nWe can also add the following parameters:\n\nFields\n: Specifies the document attributes that we want returned (the default is the entire document).\n\nSort\n: Defines how the data is to be sorted. Sort is an array, allowing the sort to be calculated on multiple attributes.\n\nLimit\n: The number of documents to return.\n\nIf you are from a relational database background, this query is the equivalent SQL query to that last IBM Cloudant query example.\n\nThe WHERE clause is the equivalent of SELECTOR in IBM Cloudant Query. ORDER and LIMIT are exactly equivalent, and the IBM Cloudant Query FIELDS list is equivalent to the comma-separated list of attributes after the SELECT keyword.\n\nThe JSON syntax might take a bit of getting used to, but MongoDB users might find it familiar.\n\nIBM Cloudant queries can be executed in the IBM Cloudant Dashboard. Select the database that you are working with, for example, books then choose the Query tab.\n\nEnter your IBM Cloudant Query JSON in the box that is provided, and click Run Query when you're ready. The result set appears on the page.\n\nThe Explain button is used to provide an explanation on how the database interprets the supplied query. This explanation becomes more important when we get to Indexing in the next part.\n\nQueries can be triggered from curl too. The Query JSON, in this case, is stored in a file and we POST to the _find endpoint by using the -d@ command-line syntax.\n\nThe Node.js code is similar. The Query is a standard JavaScript object, which is passed to the db.find function which it POSTs to the _find endpoint on your behalf.\n\nNow, time for a practical exercise. Devise your own IBM Cloudant Query that finds the titles of books that are written in the 20th Century. The IBM Cloudant Query documentation is at the on-screen URL if you need it.\n\nPause the presentation here if you don't want to know the answer...\n\nSee one solution:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_15712-17534-19586","score":11.2609976371,"text":"\nBy default, the dashboard begins with the name \"blank dashboard\". You can change the name by selecting Dashboards from the sidebar, then clicking the Pencil icon next to the name.\n\n\n\nTo return to the default dashboard at any time, select Dashboards > Default Dashboards > IBM > Load Balancer Monitoring Metrics.\n\n\n\n\n\n Working with IBM Cloud Monitoring using the APIs \n\nYou can also work with the monitoring instance by using the metric query APIs. You might want to do this if you need raw data points or want to consume your metrics from a command-line interface rather than using the IBM Cloud Monitoring dashboard.\n\nAfter creating your monitoring instance, you must collect the following two pieces of information.\n\n\n\n* The Monitor API token\n* The endpoint of your IBM Cloud Monitoring instance\n\n\n\nTo collect this information and work with your monitoring instance using metric query API, follow these steps:\n\n\n\n1. Access the [Monitoring home page](https:\/\/cloud.ibm.com\/observe\/monitoring), and click Open Dashboard next to the instance you want to work with. After the dashboard displays, select your Account Profile icon on the left sidebar, then select Settings. Your account settings display.\n2. Your Monitor API token is an alphanumeric string that is located in the Monitor API Token field. Click the Copy button to the right of the key to transfer it to your clipboard.\n\nDo not share this API token. Anyone who has this API token has full access to your metrics.\n3. To get the endpoint of your IBM Cloud Monitoring instance, navigate to your main dashboard in your browser. Then, select the URL to the dashboard, which appears similar to:\n\nhttps:\/\/us-south.monitoring.cloud.ibm.com\/\/default-dashboard\/ibm_is_load_balancer?last=3600\n\nThe first part of the URL (in this case, us-south.monitoring.cloud.ibm.com) is your endpoint. Make note of it.\n4. After you have both the API token and the endpoint, you can format your POST request. The following POST request is an example, with all the parameters that you can modify. These parameters are:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-monitoring-metrics-alb"},{"document_id":"ibmcld_13482-13691-15267","score":11.2319183372,"text":"\n* Data skipping sometimes does not work if type casting is used in the WHERE clause. For example, given a MinMax index on a column with a short data type, the following query does not benefit from data skipping:\n\nselect * from table where shortType > 1\n\nApache Spark evaluates the query as (cast(shortType3 as int) > 1) because the constant 1 is of type integer.\n\nIn some cases, Apache Spark automatically casts the literal to the right type. For example, the previous query works for all other numerical types, except for the byte type, as it requires casting, as well. To benefit from data skipping in such cases, ensure that the literal has the same type as the column type, as in the following example:\n\nselect * from table where shortType > cast(1 as short)\n* Concurrent CREATE\/REFRESH operations are not supported.\n* Indexing nested geospatial field is not supported.\n* With the Lite plan, data skipping features, such as CREATE METAINDEX, are not allowed.\n\n\n\n\n\n\n\n References \n\n\n\n* [Data skipping for Data Engine](https:\/\/www.ibm.com\/cloud\/blog\/data-skipping-for-ibm-cloud-sql-query).\n* [Data skipping demo at Think 2019](https:\/\/www.ibm.com\/cloud\/blog\/ibm-cloud-sql-query-at-think-2019) for the [Danaos use case](https:\/\/www.danaos.com\/home\/default.aspx) of [BigDataStack](https:\/\/bigdatastack.eu\/?utm_source=IBM-Ta-Shma).\n* [How to lay out Big Data in IBM Cloud Object Storage for Spark SQL](https:\/\/www.ibm.com\/cloud\/blog\/big-data-layout).\n* [Querying Geospatial Data by using Data Engine](https:\/\/www.ibm.com\/cloud\/blog\/querying-geospatial-data-using-ibm-sql-query).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-index_management"},{"document_id":"ibmcld_15746-9884-11961","score":11.2200583823,"text":"\nYou can change the name by selecting Dashboards from the sidebar, then clicking the Pencil icon next to the name.\n\n\n\nTo return to the default dashboard at any time, select Dashboards > Default Dashboards > IBM > Load Balancer Monitoring Metrics.\n\n\n\n\n\n Working with IBM Cloud Monitoring using the APIs \n\nYou can also work with the monitoring instance by using the metric query APIs. You might want to do this if you need raw data points or want to consume your metrics from a command-line interface rather than using the dashboard.\n\nAfter creating your IBM Cloud Monitoring instance, you must collect the following two pieces of information.\n\n\n\n* The Monitor API token\n* The endpoint of your IBM Cloud Monitoring instance\n\n\n\nTo collect this information and start working with your monitoring instance using metric query API, follow these steps:\n\n\n\n1. Access the [Monitoring home page](https:\/\/cloud.ibm.com\/observe\/monitoring), and click Open Dashboard next to the instance you want to work with. After the IBM Cloud Monitoring dashboard displays, select your Account Profile icon on the left sidebar, then select Settings. Your account settings display.\n2. Your Monitor API token is an alphanumeric string that is located in the Monitor API Token field. Click the Copy button to the right of the key to transfer it to your clipboard.\n\nDo not share this API token. Anyone who has this API token has full access to your metrics.\n3. To get the endpoint of your IBM Cloud Monitoring instance, navigate to your main dashboard in your browser. Then, select the URL to the dashboard, which appears similar to:\n\nhttps:\/\/us-south.monitoring.cloud.ibm.com\/\/default-dashboard\/ibm_is_load_balancer?last=3600\n\nThe first part of the URL (in this case, us-south.monitoring.cloud.ibm.com) is your endpoint. Make note of it.\n4. After you have both the API token and the endpoint, you can format your POST request. The following POST request is an example, with all the parameters that you can modify. These parameters are:\n\n\n\n* The Monitor API token.\n* The endpoint of your monitoring instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-nlb_monitoring-metrics"},{"document_id":"ibmcld_16666-11924-13606","score":11.1885180522,"text":"\nFor the steps to perform ingestion, see the [Ingesting data through the command-line interface (CLI)](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-ingest_data_cli)\n\n\n\n\n\n Step 7: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Select a catalog, for example, default schema, and a table, for example, order_detail, to run the query.\n4. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to view the details from the table:\n\nExample:\n\n!\/bin\/bash\nSELECT * FROM \"iceberg-beta\".\"default\".\"order_detail\" LIMIT 10;\n5. Click Run on to run the query.\n6. Select Result set or Details tab to view the results. If required, you can save the query.\n7. Click Saved queries to view the saved queries.\n8. Click [Explain](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n Step 8: Keep exploring \n\n\n\n1. Explore the other tutorials in the documentation.\n2. Monitor the promo code consumption to decide whether to buy, build on (default), decline or manually delete your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_hp_intro"},{"document_id":"ibmcld_16670-5968-7639","score":11.1752934812,"text":"\nYou must link the Db2 and Netezza databases to the Presto engine that is used to process the data.\n\nTo associate Db2 with the Presto engine, do the following steps:\n\n\n\n1. From the Infrastructure manager, select Db2 database. Click the overflow menu icon at the end of the row and click Associate.\n2. In the Associate with engine form, select the Presto engine that you want to use to process the data.\n3. Click Associate and restart engine. The Db2 database is associated with the Presto engine.\n\n\n\nSimilarly, select the Netezza database and link it to the Presto engine.\n\n\n\n\n\n Step 6: Combine data \n\nYou can also navigate to the Query workspace to create SQL queries to query your data.\n\nTo run the SQL query to join two tables, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to join the details from Db2 and Netezza:\n\nExample:\n\n!\/bin\/bash\nSELECT * FROM \"Db2\".\"default\".\"order_detail\" AS details\nLEFT JOIN \"Netezza\".\"gosales\".\"order_detail\" AS header\nON details.order_number=header.order_number\nLIMIT 10;\n4. Click the Run on button to run the query.\n5. Select Result set or Details tab to view the combined result. If required, you can save the query.\n6. Click Saved queries to view the saved queries.\n7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_join_data"},{"document_id":"ibmcld_16662-0-1981","score":11.0951166785,"text":"\n\n\n\n\n\n\n  Running SQL queries \n\nSQL is a standardized language for defining and manipulating data in a relational database. You can use the Query workspace interface in IBM\u00ae watsonx.data to run SQL queries and scripts against your data.\n\nThe Query workspace has the following components:\n\n\n\n*  Data objects: To view the engines, catalogs, schemas, tables, and columns.\n*  Engine: To select an engine and view the associated catalogs.\n*  Saved queries: To view the saved queries.\n*  Worksheet: To write SQL queries.\n\n\n\nThe Query workspace page provides basic options to undo, redo, cut, copy, paste, save, clear, and delete.\n\nFormat selection option is enabled only when an SQL statement in a query worksheet is selected. The Format worksheet option formats all the content in the worksheet. Comment selection is used to explain sections of SQL statements.\n\nThe Delete option is enabled only after an SQL query is saved.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select SQL. The Query workspace page opens.\n3.  Select an engine from the Engine drop-down.\n4.  Select the catalog, schema, table, or column in which you want to run the query.\n5.  Click the overflow menu and select the required query.\n\n\n\n*  For a catalog and schema, you can run the Generate Path query.\n*  For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n*  For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\n6.  Click the Save icon to save the query. A Save query confirmation dialog appears.\n7.  Click Save.\n8.  Click the Run button to run the query.\n9.  Select Result set or Details tab to view the results.\n10. Click Saved queries to view the saved queries.\n11. Click [Explain](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-run_sql"},{"document_id":"ibmcld_13498-82327-83275","score":11.0312822537,"text":"\n(8, 'C03'),\n(9,'D01') AS emp\nWHERE emp.col2 IN ('D01','D02')\n\nThe result of the example query is shown in the following table.\n\n\n\nTable 40. Query result for the example all\n\n EMP_ID EMP_DEPT \n\n 0 D01 \n 4 D01 \n 5 D02 \n 7 D01 \n 9 D01 \n\n\n\n-- all employees that are managing a department\nSELECT\nemp.col1 AS emp_id,\nemp.col2 AS emp_dept\nFROM VALUES\n(0, 'D01'),\n(2, 'C01'),\n(3, 'C02'),\n(4, 'D01'),\n(5, 'D02'),\n(6, 'C01'),\n(7, 'D01'),\n(8, 'C03'),\n(9,'D01') AS emp\nWHERE (emp.col1,emp.col2) IN (\nSELECT\nmgr.col1,\nmgr.col2\nFROM VALUES\n(2, 'C01'),\n(4, 'D01'),\n(5, 'D02') AS mgr\n)\nShow more\n\nThe result of the example query is shown in the following table.\n\n\n\nTable 41. Query result for the example all\n\n EMP_ID EMP_DEPT \n\n 2 C01 \n 4 D01 \n 5 D02 \n\n\n\n\n\n\n\n LIKE examples \n\n-- all employees that work in a department that starts with letter C\nSELECT\nemp.col1 AS emp_id,\nemp.col2 AS emp_dept\nFROM VALUES\n(0, 'D01'),\n(2, 'C01'),\n(3, 'C02'),\n(4, 'D01'),\n(5, 'D02'),","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09994-7-1823","score":14.1412454416,"text":"\nTime travel query syntax and timestamps \n\n\n\n Query syntax \n\nA SELECT query with one or more temporal clauses is a time travel query. Time travel queries might appear as sub-SELECTs in the INSERT, UPDATE, DELETE, MERGE, or CREATE TABLE AS SELECT (CTAS) statements.\n\nAlso, time travel queries might appear in a view definition (CREATE VIEW, with or without OR REPLACE) or a stored procedure definition (CREATE PROCEDURE, with or without OR REPLACE). In either case, timestamp expressions in the syntax (for example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019) are not evaluated at view or procedure definition time, but at the time a user or application queries the view or calls the procedure.\n\nAny base table reference (the table name, with or without database and schema name, and with or without an alias) in a SELECT or sub-SELECT might have an optional temporal clause, which consists of the keywords FOR SYSTEM_TIME followed by one of the following values:\n\n\n\n* AS OF <TIMESTAMP EXPRESSION>\n* BEFORE <TIMESTAMP EXPRESSION>\n* BETWEEN <TIMESTAMP EXPRESSION 1> AND <TIMESTAMP EXPRESSION 2>\n* FROM <TIMESTAMP EXPRESSION 1> TO <TIMESTAMP EXPRESSION 2>\n\n\n\nEach TIMESTAMP EXPRESSION must be one of the following:\n\n\n\n* A literal timestamp value. For example, \u20182022-10-31 20:00:00\u2019.\n* A query parameter or host variable whose value is a timestamp.\n* A built-in function that returns or implicitly converts to a timestamp. For example, CURRENT_DATE, CURRENT_TIMESTAMP or (equivalently) NOW(), or CURRENT_TIMESTAMP(subsecond-digits) or (equivalently) NOW(subsecond-digits).\n* An expression that evaluates to a single timestamp for all rows in the table. For example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019. The expression cannot refer to table columns or to a non-deterministic function (for example, RANDOM()) or be a sub-SELECT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-runningqueries_tt"},{"document_id":"ibmcld_00522-2652-4218","score":13.5665767856,"text":"\nOpen the service instance that you created in the prerequisite section.\n3. Open the database that you created.\n4. Go to the Query tab.\n5. Paste the query JSON from the previous section into the Cloudant Query window.\n6. Click Run Query. See the results in the following screen capture:\n\nZoom\n\n![Run the query, and the results show the _id, author, pages, publisher, and year.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/indexingdashboard1.png)\n\nFigure 1. Window for running queries\n\n\n\nIBM Cloudant matches the documents that meet your criteria and it seems to do it quickly, but there's a catch. IBM Cloudant isn't using an index to service this query, meaning that the database has to scan every document in the database to get your answer. This scan is fine for small data sets. But if you're running a production application where the data set is expanding all the time, you definitely don't want to rely on unindexed queries.\n\n\n\n\n\n Creating an index \n\nTo create an index, we can tell IBM Cloudant to create an index on the publisher and year fields that we are using in our query.\n\n\n\n1. From the IBM Cloudant Dashboard, select the books database.\n2. Select the Design Documents tab.\n3. Select New Indexes from the Design Documents menu.\n4. Copy and paste the following index definition:\n\n{\n\"index\": {\n\"fields\": [\n\"publisher\", \"year\"\n]\n},\n\"name\": \"publisher-year-index\",indexingdashboard5\n\"type\": \"json\"\n}\n\nSee an example in the following screen capture:\n\nZoom\n\n![Click Create index to create an index.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-dig-deeper-dashboard"},{"document_id":"ibmcld_13480-7-2163","score":13.0054954547,"text":"\nGetting started with the catalog \n\nEach instance of IBM Cloud\u00ae Data Engine includes a database catalog that you can use to register and manage table definitions for your data on IBM Cloud\u00ae Object Storage. Catalog syntax is compatible with Hive metastore syntax. See how to [work with the catalog](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalogusage) and refer to the [Catalog management](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencechapterHiveCatalog) section of the SQL reference.\n\n\n\n Benefits \n\nYou can explore, change, or discover structured data on [Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/getting-started.htmlgetting-started-console) with Data Engine by using SQL syntax. To query data on Object Storage without a table in the catalog, you need to specify the data location (the corresponding Object Storage URI) and the data format in your SELECT statement. During query execution, data and schema are dynamically discovered as part of the SQL compilation process. This process, called inference, derives column names, data types, the list of partitions, and individual objects on Object Storage that together make up the table data.\n\nInferring all this information and doing it repetitively with every query imposes latency to your queries. The inference process can take up a significant amount of time, especially for text formats (for example, CSV and JSON), or when thousands of objects exist in different table partitions. In some cases, the inference process even accounts for the largest part of the overall query execution time. So, if you are either familiar with the schema, or want to repetitively use the data for queries, create a table in the catalog. Such a table improves performance for repeated query executions.\n\nAnother advantage of creating a table in the catalog is that the table name serves as an alias and is decoupled from the data location. Hence, you can separate the tasks of data engineers and SQL authors. Data engineers deal with the data location and publish registered tables in the catalog by using descriptive table names.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_13480-7832-9910","score":12.4969695288,"text":"\nSELECT * FROM cos:\/\/us-geo\/sql\/customers.csv\nINTO cos:\/\/us-geo\/mybucket\/customers_partitioned.csv\nPARTITIONED BY (country)\n\n\n\n\n\n Step 2: Attach table partitions \n\nAfter you defined a partitioned table, it is initially empty and you must attach the partitions to it explicitly. A convenient way to add all partitions that exist on Object Storage, is to use the following RECOVER PARTITIONS clause.\n\nALTER TABLE customers RECOVER PARTITIONS\n\nThis clause overwrites the current partition definitions for the table with the structure that is detected from Object Storage data by using the location prefix that is specified for the table. You can also update partition definitions selectively with the ADD PARTITION and DROP PARTITION clauses of the ALTER TABLE statement, for example, to attach more data to a table that was uploaded recently.\n\nWhen you added all partitions, the partitioned table is set up to be queried. You get all the German customers, if you submit the following query:\n\nSELECT customerID FROM customers WHERE country = 'Germany'\n\nThe query execution reads the objects only under the cos:\/\/us-geo\/sql\/customers_partitioned.csv\/country=Germany\/ prefix because the partition definitions are used by the query optimizer to minimize the necessary data transfer.\n\n\n\n\n\n\n\n Limitations \n\n\n\n* With the Standard plan, you can create up to 100 tables with up to 20,000 partitions per table.\n* If you use the Lite plan, the catalog management features, such as CREATE TABLE, are not allowed.\n* The ADD PARTITION option of the ALTER TABLE statement may not correctly locate partitions if the value for a partition column contains special characters, such as the colon : that can appear as a timestamp separator.\n\nWhen the location is inferred from one or more partition values, some special characters in the values are URL escaped when you construct the Object Storage location. For example, the statement ALTER TABLE mytable ADD PARTITION ( startTime = '2020-01-01 12:00:00' ) constructs a partition with an Object Storage location ...\/startTime=2020-01-01 12%3A00%3A00\/.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_09991-7-1416","score":12.2800407457,"text":"\nQuerying historical data \n\nYou can run the queries by using the command-line or the [query editor inside the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-query-editor).\n\nThe following table definition is used for the example queries.\n\nCREATE TABLE PRODUCT (PRODUCTID INTEGER, DESC VARCHAR (100), PRICE DECIMAL) DATA_VERSION_RETENTION_TIME 30;\n\nThe following rows are inserted at different times. The commit times of the inserts (the insert timestamps or _SYS_START values) are indicated in SQL comments.\n\nINSERT INTO PRODUCT VALUES(1001, 'Jacket', 102.00); -- 2020-10-23 16:00:00\nINSERT INTO PRODUCT VALUES(1002, 'Gloves', 20.50); -- 2020-10-23 16:05:00\nINSERT INTO PRODUCT VALUES(1003, 'Hat', 18.99); -- 2020-10-23 16:10:00\nINSERT INTO PRODUCT VALUES(1004, 'Shoes', 125.25); -- 2020-10-23 16:15:00\n\n\n\n Showing data with the insert and delete timestamps \n\nThis SELECT command shows the table data with the associated insert and delete timestamp values at that instant when the query was issued. The _SYS_START and _SYS_END timestamps are available only in time travel queries, hence the use of AS OF NOW().\n\nSELECT , _SYS_START, _SYS_END FROM <table_name> FOR SYSTEM_TIME AS OF NOW();\n\nExample:\n\nSELECT , _SYS_START, _SYS_END FROM PRODUCT FOR SYSTEM_TIME AS OF NOW();\nPRODUCTID | DESCRIPTION | PRICE | _SYS_START | _SYS_END\n----------+-------------+---------+---------------------+-----------","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-queryingdata_tt"},{"document_id":"ibmcld_00580-42802-44973","score":12.1725260325,"text":"\nThis practice saves IBM Cloudant from having to choose which index to use from the available ones, and it makes it easy for you to remember which index is which.\n\nLet's create an index on our books database from the dashboard. Select the database, then choose the Design Documents tab and Query Indexes from the menu.\n\nAny existing indexes are listed on the side: A special index must exist that represents the primary index, based on the document's _id.\n\nComplete the index definition with the JSON:\n\nClick Create Index when you're done.\n\nClicking the button sends a POST request to the _index endpoint (other API calls are available to update and delete existing indexes).\n\nIndexes are built asynchronously by IBM Cloudant in the background. For large databases, it can take IBM Cloudant some time to construct the index for the first time. The index cannot use the database until that initial build is ready.\n\nWe can repeat our query for books in the 20th century. This time we specify the index name with the use_index field. The answer returns - this time powered by our index. You might not notice a speed improvement for a small database, but the benefit is definitely felt as your data size and query volume grows. Indexing helps your queries remain performant as your application scales.\n\nWhen you tell IBM Cloudant to create a secondary index, it starts a background task that looks at all the documents in turn and creates a new data structure on disk: the index. The index is a balanced tree which pairs the keys (the attribute or attributes that you need indexed) with the document _id they came from.\n\nThe index can be used to efficiently lookup known keys and ranges of keys without having to rescan the entire database.\n\nAnother trick that you can employ at index time is the partial filter. You can optionally supply a partial filter in your index definition. This IBM Cloudant Query selector is executed at index time to decide which documents' data makes it to the index and which are ignored.\n\nIn this example, a selector is employed that allows only dates that fall on a weekend to make it to the index. Smaller indexes are faster and more efficient.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00644-7-2122","score":12.138770671,"text":"\nUsing Views \n\nUse views to search for content within a database that matches specific criteria. The criteria are specified within the view definition.\n\nCriteria can also be supplied as arguments when you use the view.\n\n\n\n Querying a view \n\nTo query a view, submit a GET request with the following format:\n\nMethod\n: Issue a partition query by using the following command, GET $SERVICE_URL\/$DATABASE\/_partition\/$PARTITION_KEY\/_design\/$DDOC\/_view\/$VIEW_NAME. Or issue a global query by using the following command, GET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME.\n\nRequest\n: None\n\nResponse\n: JSON of the documents that are returned by the view.\n\nRoles permitted\n: _reader\n\nThe request runs either:\n\n\n\n* The specified $VIEW_NAME from the specified $DDOC design document within the $DATABASE database, which is constrained to results within the specified $PARTITION_KEY data partition.\n* The specified $VIEW_NAME from the specified $DDOC design document within the $DATABASE database.\n\n\n\nThe examples in this document vary between partition and global queries for illustrative purposes. Unless otherwise noted, modifying the path to embed or remove the partition name works for any view query type.\n\n\n\n Query and JSON Body Arguments \n\nGlobal queries can use all query and JSON body arguments. Partition queries can use only the subset that is indicated in the table.\n\n\n\nTable 1. Subset of query and JSON body arguments available for partitioned queries\n\n Argument Description Optional Type Default Supported values Partition query \n\n conflicts Specify whether to include a list of conflicted revisions in the _conflicts property of the returned document. Ignored if include_docs isn't set to true. Yes Boolean False Yes \n descending Return the documents in descending by key order. Yes Boolean False Yes \n end_key Stop returning records when the specified key is reached. Yes String or JSON array Yes \n end_key_docid Stop returning records when the specified document ID is reached. Yes String Yes \n group Specify whether to group reduced results by key. Valid only if a reduce function is defined in the view.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_15456-10582-12184","score":12.0537714289,"text":"\n\"bytes_from_initiator\": 12000,\n\"packets_from_initiator\": 2212,\n\"bytes_from_target\": 323232,\n\"packets_from_target\": 3232\n\"cumulative_packets_from_initiator\": 2212,\n\"cumulative_packets_from_target\": 3232,\n\"cumulative_bytes_from_target\": 323232,\n\"cumulative_bytes_from_initiator\": 12000,\n}\n],\n}\n\n\n\n\n\n Analyzing flow logs by using IBM Cloud SQL Query \n\nYou can analyze flow logs with SQL that uses IBM Cloud\u00ae Data Engine by using the path to the objects on Object Storage in the FROM clause of your SQL query. (For an example, see Step 3 in [Viewing flow log objects](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-fl-analyze). However, for a more convenient way of querying, it is recommended that you create table and view definitions that give you a flattened view on your flows. For more information about table catalog functions and benefits, see [Getting started with the catalog](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog).\n\nThe view flattens the flow log data structure; thus, making it easier to analyze your flows.\n\nFor more elaborate and repeatable analysis, such as when you want to collaborate and share your log analysis, it is recommended that you use IBM Cloud\u00ae Data Engine through Jupyter Notebooks (for example, through IBM Watson Studio). For a generic starter and demo notebook for IBM Cloud\u00ae Data Engine that you can use as basis for your work, see [Using IBM Cloud SQL Query](https:\/\/dataplatform.cloud.ibm.com\/analytics\/notebooks\/v2\/656c7d43-7ccd-4e50-a3c0-bbc37c001132\/view?access_token=baaa77ad715e17a8f823615d45431329fde0fe92fecb85abb9fc55a877939fe8).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-fl-analyze"},{"document_id":"ibmcld_00500-3010-4557","score":12.0435881213,"text":"\nSee an example response from running the simple view query:\n\n{\n\"total_rows\": 2,\n\"offset\": 0,\n\"rows\": [\n{\n\"id\": \"abc125\",\n\"key\": \"amelie.smith@aol.com\",\n\"value\": {\n\"name\": \"Amelie Smith\",\n\"email_verified\": true,\n\"joined\": \"2020-04-24T10:42:59.000Z\"\n}\n},\n{\n\"id\": \"abc123\",\n\"key\": \"bob.smith@aol.com\",\n\"value\": {\n\"name\": \"Bob Smith\",\n\"email_verified\": true,\n\"joined\": \"2019-01-24T10:42:59.000Z\"\n}\n}\n]\n}\nShow more\n\n\n\n\n\n Map function examples \n\nThe definition of a view within a design document also creates an index based on the key information. The production and use of the index significantly increases the speed of access and searching or selecting documents from the view.\n\nThe following sections describe indexing with simple and complex keys, and reduce functions.\n\nYour indexing functions work in a memory-constrained environment where the document forms part of the memory used in the environment. Your code's stack and document must fit within the memory. We limit documents to a maximum size of 64 MB.\n\n\n\n Indexing a field \n\nThe following map function checks whether the object has a name field, and if so emits the value of this field. With this check, you can query against the value of the name field.\n\nSee an example of indexing a field:\n\nfunction(doc) {\nif (doc.name) {\nemit(\"name\", doc.name);\n}\n}\n\n\n\n\n\n An index for a one-to-many relationship \n\nIf the object passed to emit has an _id field, a view query with include_docs set to true contains the document with the specific ID.\n\nSee an example of indexing a one-to-many relationship:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreduce"},{"document_id":"ibmcld_13498-100465-102250","score":11.8995521338,"text":"\nCAST(2018-10-31 23:55:00 AS TIMESTAMP) CAST(2018-2-28 23:55:00 AS DATE) CAST(HELLO AS TIMESTAMP) \n\n 2018-10-31 23:55:00.0 2018-02-28 null \n\n\n\n\n\n\n\n Boolean type \n\nThe BOOLEAN type represents a domain with two values, true or false. Any numeric value that represents zero, for example, 0, 0.0, or 0.0E10, can be cast to false. Numeric values that represent a nonzero value, for example, 1, 1.0, 1.0E10, or 21474.83648 can be cast to true. The string value '0' can be cast to false and '1' can be cast to true. Any other string value is cast to false.\n\n\n\n\n\n Binary type \n\nA BINARY type represents an array of byte values. Thus, string values can be cast to type BINARY.\n\n\n\n\n\n Related references - dataType \n\nA dataType is referenced by the following clauses:\n\n\n\n* [castExpression](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencecastExpression)\n* [createTable](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencecreateTable)\n\n\n\n\n\n\n\n\n\n Catalog management \n\nThe following commands allow users to store table metadata catalog in the Data Engine catalog. By defining the tables, columns, and partitions in the catalog, you can use short table names in the SQL SELECT statements. Each instance of Data Engine has its own catalog, and table definitions are not visible from other instances. For more information, see [catalog management](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog).\n\n\n\n Create table \n\n\n\n createTable \n\n\n\n\n\n columnDefinition \n\nCreate a table definition in the catalog based on the objects in the specified Object Storage location. The LOCATION option is mandatory. If a table or view with the same name exists in the same Data Engine instance, you receive an error, unless the IF NOT EXISTS clause is specified.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07045-7-2118","score":16.1312402919,"text":"\nImproving your query results \n\nLearn about actions you can take to improve the quality of your query results.\n\nYou can use the tools that are built in to Discovery to make improvements.\n\n\n\n Results include more than exact matches \n\nUnlike some other search applications, adding quotation marks to a phrase that you submit does not return only exact matches. Queries that are submitted from the product user interface are natural language queries. When quoted text is submitted in a natural language query, the phrase is used to boost result scores. However, results are not limited to documents that contain the entire phrase.\n\nIf you want more control over how queries are handled, you must use the query API. For more information about the phrase operator of the query API, see [Query operators](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsphrase).\n\n\n\n\n\n A short query returns irrelevant results \n\nIt might be that your query contains too many stop words and not enough distinct terms to trigger a meaningful search. When you submit a query, the query text is analyzed and optimized before it is submitted to the project. One of the changes that occurs is the removal of any stop words from the text. A stop word is a word that is considered to be not useful in distinguishing the semantic meaning of the content. Examples of stop words include terms such as and, the, and about. Discovery defines a list of stop words that it ignores automatically both when the data is indexed and when it is searched. When you submit a query that contains mostly or only stop words, such as About us, it is equivalent to submitting an empty query.\n\nAlthough us is not included in the stop words list, it is lemmatized to we, which is listed as a stop word.\n\nYou can edit the stop words that are used by your collection. However, you can only augment the stop words list; you cannot remove stop words. And the stop words that you define are used only at query time. They do not affect the stop word list that is used by Discovery when data is added to a collection and the index is created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-improvements"},{"document_id":"ibmcld_13075-7-2200","score":16.0609142132,"text":"\nImproving result relevance with the tooling \n\nThe relevance of natural language query results can be improved in IBM Watson\u2122 Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. See [Improving the relevance of your query results with the API](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api) if you would prefer to use the APIs.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nTo train Watson, you must provide the following:\n\n\n\n* Example queries that are representative of the queries your users enter\n* Ratings that indicate which results for each query are relevant and not relevant\n\n\n\nAfter Watson has enough training input, the information that you provide about which results are good and bad for each query is used to learn about your collection. Watson does not just memorize, but it also learns from the specific information about individual queries and applies the patterns it detects to all new queries. It does so, using machine-learning Watson techniques that find signals in your content and questions. After training, Discovery then reorders the query results to display the most relevant results at the top. As you add more and more training data, Discovery becomes more accurate in the ordering of query results.\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"},{"document_id":"ibmcld_07163-7-1995","score":15.9592452006,"text":"\nImproving result relevance with the API \n\nYou can train Discovery to improve the relevance of query results for your particular organization or subject area. When you provide a Discovery instance with training data, the service uses machine-learning Watson techniques to find signals in your content and questions. The service then reorders query results to display the most relevant results at the top. As you add more training data, the service instance becomes more accurate and sophisticated in the ordering of results it returns.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nFor comprehensive information about the training APIs, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery).\n\nIf you would prefer to use the Discovery tooling to train Discovery, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nTrained collections return a confidence score in the result of a natural language query. See [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"},{"document_id":"ibmcld_07175-7-2035","score":15.941619919,"text":"\nViewing metrics and improving query results with the Performance dashboard \n\nThe Performance dashboard in the Discovery tooling can be used to view query metrics, as well as improve query results, including query relevance.\n\nYou can access the Performance dashboard by clicking the View data metrics icon. The dashboard is not available in Premium or Dedicated environments.\n\nThere are two options to improve natural language query results:\n\n\n\n* [Fix queries with no results by adding more data](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboardaddmore)\n* [Bring relevant results to the top by training your data](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboardtraindata)\n\n\n\nYou can view the data metrics in the [query overview](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboardoverview).\n\n\n\n Fix queries with no results by adding more data \n\nIn this section of the dashboard, you can review queries that returned zero results and add more data so that the query returns results in the future. Click the View all and add data button to get started.\n\n\n\n\n\n Bring relevant results to the top by training your data \n\nIn this section, you can train your collections to improve the relevance of natural language query results. Click the View all and perform relevancy training button to get started. Then see [Adding queries and rating the relevancy of results](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingresults) for instructions.\n\nFor more about training requirements and options, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n Query overview \n\nThe Query overview section displays:\n\n\n\n* The total number of queries made by users\n* The percentage of queries with one or more results clicked\n* The percentage of queries with no results clicked\n* The percentage of queries with no results returned","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboard"},{"document_id":"ibmcld_13075-1823-3835","score":15.6905288872,"text":"\nFor more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.\n\nSee [Training data requirements](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-apireqs) for the minimum requirements for training, as well as the training limits.\n\nSee [Usage monitoring](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-usage) for details on tracking usage and using this data to help you understand and improve your applications.\n\n\n\n Adding queries and rating the relevancy of results \n\nTraining consists of three parts: a natural language query, the results of the query, and the ratings you apply to those results.\n\n\n\n1. There are two ways to access the training page in the Discovery tooling:\n\n\n\n* For an individual collection, on the Build queries screen, click Train Watson to improve results on the upper right. You don't need to enter a query on the Build queries screen to start training.\n* From the Performance dashboard. Click on the View data metrics icon on the left to open the dashboard. You are prompted to choose a collection to train.\n\n\n\n2. On the Train Watson screen, click Add a natural language query, for example: \"IBM Watson in healthcare\", and add it. Make sure your queries are written the way your users would ask them. Also, it is recommended that training queries be written with some term overlap between the query and the desired answer. This overlap improves initial results, when the natural language query is run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"},{"document_id":"ibmcld_07108-2897-3942","score":15.5038226166,"text":"\nYou can use the [expansions.json](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/discovery\/expansions.json) file as a starting point when you build a query expansion list.\n2. From the navigation pane, open the Improve and customize page.\n3. Expand Improve relevance from the Improvement tools pane.\n4. Click Synonyms, and then click Upload synonyms for the collection.\n\nDo not upload a synonyms file while documents are being added to your collection. The ingestion processing that occurs when documents are added can cause the index to be unavailable.\n\nOnly one synonyms list can be uploaded per collection. If a second expansion list is uploaded, the second list replaces the first.\n5. Run a test query to verify that the query expansion is working as expected.\n\nQuery expansions are applied at query time, not during indexing, so you can add synonyms without reprocessing your collection.\n\n\n\nTo disable query expansion, delete the synonyms file. However, do not delete a synonyms file while new documents are being processed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-settings"},{"document_id":"ibmcld_13075-3392-5440","score":15.5012246248,"text":"\nYou are prompted to choose a collection to train.\n\n\n\n2. On the Train Watson screen, click Add a natural language query, for example: \"IBM Watson in healthcare\", and add it. Make sure your queries are written the way your users would ask them. Also, it is recommended that training queries be written with some term overlap between the query and the desired answer. This overlap improves initial results, when the natural language query is run. Relevance training only uses natural language queries, so do not enter queries written in the Discovery Query Language.\n3. To view the results of your query, click the Rate Results button next to it. If you don't think there are enough results, you could try rewriting the query, or adding more documents to this collection via the Manage data screen.\n4. Begin rating results as either Relevant or Not relevant. When you are done, click Back to queries. In the Discovery tooling, Relevant has a score of 10 and Not relevanthas a score of 0. If you already started rating results for this collection, using the API, and used a different scoring scale, a warning is displayed, with options to fix the issue. At the top of the screen, Watson tracks the training status and provides tips about what you can do to improve results. \"Add more variety to your ratings\" means that you might want to use both the Relevant and Not relevant ratings. After you meet the requirements, training starts updating periodically. Most training takes less than 30 minutes to complete, but you can continue working while training is underway.\n5. Continue adding queries and rating results.\n\n\n\nTo return to the main Build queries screen at any time, click Build queries on the upper left. To return to the Manage data screen, click the name of the collection on the upper right.\n\nIf you would like to delete all of the training data in your collection at one time, you must do so via the API. See [Delete all training data for a collection](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-all-training-data) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"},{"document_id":"ibmcld_07175-1564-2340","score":15.4575991653,"text":"\nFor more about training requirements and options, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n Query overview \n\nThe Query overview section displays:\n\n\n\n* The total number of queries made by users\n* The percentage of queries with one or more results clicked\n* The percentage of queries with no results clicked\n* The percentage of queries with no results returned\n* A graph that displays these results over time, so that you can track how adding more data and relevancy training are improving performance\n\n\n\nThese results are gathered using the Events and Feedback API. See the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discoverycreate-event) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboard"},{"document_id":"ibmcld_07214-57536-59639","score":15.3400467265,"text":"\nImproved query and add functions at top level : id, score, and highlight at the top level (You can continue to add documents to your collection using document IDs with the add a document function. See the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/discoveryadd-a-document) for details. : _ prefixed field names at the top level (as a result, when querying for a document by ID, you can query for id instead of _id.) : and , in the field name : + and - prefixed field names : \"\" empty values for a field name : If your JSON documents include these characters in the field names, or id, score, and highlight at the top level, you need to remove them before adding the documents to your collection, or those fields are empty. You can create a custom configuration and normalize your JSON before adding documents to your collection to avoid this issue. See the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discoveryadd-configuration) for details. In addition, documents that include the punctuation characters ?, :, or in the file name cause errors during ingestion. Before ingesting them, rename any documents that include these characters.\n\nImproved 'natural_language_query' retrieval methods : The retrieval methods for natural_language_query are updated to improve the relevance of results by matching words with related semantics. This update only affects collections that did not undergo relevance training. If you are using natural_language_query and did not conduct relevance training, you might see improvement in the order of results returned.\n\nImproved query builder navigation : Changes to the query builder to make it easier to toggle between the Discovery Query Language and Natural Language query options, as well as among query, filter, and aggregation.\n\n\n\n\n\n 25 August 2017 \n\nImproved 'passages' array : The passages array now includes field, start_offset, and end _offset. field is the name of the field the passage was extracted from. start_offset is the starting character of the passage text within the field. end_offset is the ending character of the passage text within the field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07080-11640-13015","score":15.3310544901,"text":"\nIf analyzing contracts is your goal, complete the steps that are listed in the following table.\n\n\n\nChecklist for analyzing contracts\n\n Step Task Related information \n\n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Create a Document Retrieval for Contracts project. [Creating projects](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects) \n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Add up to 5 collections that connect to external data sources or contain uploaded files. [Creating collections](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections) \n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Run test queries to assess the quality of the initial results. [Previewing the default query results](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-results) \n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Take actions to improve your results. [Improving your query results](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-improvements) \n !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-product-overview"}],"retriever_scores":{"recall_1":0.2,"recall_3":0.4,"recall_5":0.4,"recall_10":0.4,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.55314647,"ndcg_cut_10":0.55314647}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07213-3538-5222","score":11.705665596,"text":"\nTo extract the training data, use the API to download the queries and the ratings from Discovery.\n\n\n\n1. [List the training data](https:\/\/cloud.ibm.com\/apidocs\/discoverylist-training-data)\n2. [List the examples](https:\/\/cloud.ibm.com\/apidocs\/discoverylist-examples-for-a-training-data-query) for each query.\n3. [Get the details](https:\/\/cloud.ibm.com\/apidocs\/discoveryget-details-for-training-data-example) for a training data examples.\n\n\n\nThe document IDs that you use in your training data point to the documents in your current collection. Use the same IDs in your new collections to ensure that the correct documents are referenced. If the IDs do not match, your restored relevancy training will not work.\n\n\n\n\n\n Queries \n\nBy default, Discovery stores the queries that you send to it, unless you opt out.\n\nIf you want to be able to restore your queries for [statistical purposes](https:\/\/cloud.ibm.com\/apidocs\/discoverynumber-of-queries-over-time), it is recommended that you store those queries separately.\n\nYou can [extract queries](https:\/\/cloud.ibm.com\/apidocs\/discoverysearch-the-query-and-event-log) from Discovery, however a maximum of 10,000 queries are stored. There is no paging API. Restoring queries is not recommended; we recommend starting from scratch.\n\n\n\n\n\n Feedback\/clicks \n\nIf you are storing clicks in the form of feedback events, there is currently no easy way to back up and restore this information. The recommendation is to start from scratch with the [clicks\/feedback data](https:\/\/cloud.ibm.com\/apidocs\/discoverycreate-event) API.\n\n\n\n\n\n Expansion lists \n\nIf you are using expansions for query modification, back up your expansion list, and store it locally.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-recovery"},{"document_id":"ibmcld_07214-74576-76512","score":11.676525439,"text":"\nNew support for 'sort' parameter in the query API : The query API (GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query) now supports the sort parameter, which enables you to specify a comma-separated list of fields in the document to sort on. See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information.\n\nImproved handling by 'timeslice' parameter : The timeslice parameter for query aggregations now correctly handles dates in UNIX epoch format. See [Query reference](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceaggregations) for information about aggregations and the timeslice parameter.\n\nUpdate to JavaSDK : The Discovery Java SDK has been updated. See the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/discovery?language=java) for details.\n\nFixed known issues with wildcard limitations in queries : Only one wildcard worked in any given query. For example, query-month:ctober worked, but query-month:ctobe generated a parsing error. This is resolved. : Wildcards did not work with queries that contained capital letters. For example, given the key\/field pair {\"borrower\": \"GOVERNMENT OF INDIA\"}, query-borrower:ndia returned results but query-borrower:NDIA did not. This is resolved. : Wildcards are not necessary within phrases in queries. For example, given the key\/field pair {\"borrower\": \"GOVERNMENT OF TIMOR\"}, query-borrower:\"GOVERNMENT OF TIMOR\" returns results, but query-borrower:\"GOVERNMENT OF TIOR\" does not. Using a wildcard is not applicable within phrases because all of the characters within the quotation marks (\") of a phrase are escaped.\n\n\n\n\n\n 24 March 2017 \n\nNew feature for My data insights : Added filtering to the \"My data insights\" screen in the Discovery tooling.\n\n\n\n\n\n 15 March 2017 \n\nKnown issues : All fields that are ingested from HTML, PDF, and Word documents are typed as string.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07068-17278-19223","score":11.2683361809,"text":"\ndeduplicate N\/A Not supported in v2. \n similar similar The format changed in v2. The similar:true parameter changed to similar.enable:true. The document_ids and fields parameters changed from strings to string arrays. The document_ids parameter now is required if enabled is true. \n bias N\/A Not supported in v2. \n\n\n\n\n\n\n\n\n\n\n\n Training data \n\nYou can use the v1 training data API to work with two related objects:\n\n\n\n* trained queries\n* examples that are used to train the queries\n\n\n\nThese two objects have separate API endpoints in v1. In v2, the examples that are used to train each query are provided together with the query and only one endpoint is used to work with the training data.\n\nFor example, to add a trained query and its training example documents in v2, you use the request POST \/v2\/projects\/{project_id}\/training_data\/queries and pass the query and all examples in the payload of one call. Similarly, if you want to update one example in the training set in v2, you must pass the query and the modified example (along with all of the other examples) to the v2 update endpoint. In v1, to update the example information, you use the update example endpoint to modify one example only.\n\nAnother important difference between v1 and v2 is that in v1, the trained model is associated with a particular collection. In v2, the trained model is associated with a project. You can use the data from multiple collections within a project to train a relevancy model. When you create or update training examples in v2, the API requires the collection_id for the collection where the document is stored.\n\n\n\nTraining data API support details\n\n Action v1 API v2 API \n\n List training data [GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data](https:\/\/cloud.ibm.com\/apidocs\/discoverylisttrainingdata) [GET \/v2\/projects\/{project_id}\/training_data \/queries](https:\/\/cloud.ibm.com\/apidocs\/discovery-datalisttrainingqueries)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api"},{"document_id":"ibmcld_07178-14849-16999","score":11.045885774,"text":"\n* The Discovery News is part of the system environment and cannot be included in multiple collection queries.\n* Individual collection relevancy training does not affect ranking of results when querying multiple collections. To rerank results returned when querying multiple collections implement [Continuous Relevancy Training](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-crt).\n* Reranking is not performed on any part of a multiple collection query, even if all collections in the query are trained.\n\n\n\nSee the [multiple collection query API reference](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-documents-in-multiple-collections) for more information.\n\nYou can view notices across multiple collections in the same environment by using the environments\/{environment_id}\/notices API method.\n\n\n\n* The collection_ids parameter must be specified when using this method. collection_ids is a comma-separated list of collections in the environment to query.\n* passages are supported when querying multiple collections.\n\n\n\nSee the [multiple collection notices API reference](https:\/\/cloud.ibm.com\/apidocs\/discoveryget-collection-details) for more information.\n\nYou can view the fields available across collections in the same environment by using the environments\/{environment_id}\/fields API method. See the [multiple collection field query API reference](https:\/\/cloud.ibm.com\/apidocs\/discoverylist-fields-across-collections) for more information.\n\n\n\n\n\n Query expansion \n\nYou can expand the scope of a query beyond exact matches - for example, you can expand a query for \"ibm\" to include \"international business machines\" and \"big blue\" - by uploading a list of query expansion terms. Query expansion terms are usually synonyms, antonyms, or typical misspellings for common terms.\n\nYou can define two types of expansions:\n\n\n\n* bidirectional - each expanded_term expands to include all expanded terms. For example, a query for ibm expands to ibm OR international business machines OR big blue).\n* unidirectional - the input_terms in the query are replaced by the expanded_terms. For example, a query for banana could expand to plantain and fruit.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts"},{"document_id":"ibmcld_07242-7-2087","score":10.9264933462,"text":"\nUsage monitoring \n\nYou can monitor and track usage of your Discovery instance and use this data to help you understand and improve your applications. The [Events API](https:\/\/cloud.ibm.com\/apidocs\/discoverycreate-event) can be used to create log entries that are associated with specific natural language queries and actions. For example, you can record which documents in a results set were \"clicked\" by a user, and when that click occurred.\n\nLogs and events are monitored only for natural language queries on private data collections. No logs are gathered on IBM Watson\u2122 Discovery News.\n\nDiscovery can log the following information:\n\n\n\n* Queries - Natural language queries run against collections in your environment\n* Impressions (or Results) - The results returned for a particular query, usually documents or passages\n* Events - Interactions a user performs on a result or set of results in Discovery (for example, a click on a document result)\n\n\n\nQueries and Impressions are logged automatically; Events logging can be integrated into your application via the API.\n\n\n\n Viewing the logs \n\nYou can search the query and event log to find query sessions that match the specified criteria. Searching the logs endpoint uses the standard Discovery query syntax for the parameters that are supported. The endpoint provides basic query functionality for viewing and searching through the recorded data.\n\nThe \/api\/v1\/logs endpoint supports the following Discovery query parameters.\n\n\n\n* query\n* filter\n* sort\n* count\n* offset\n* version\n\n\n\nFor additional details on the function and syntax for the parameters see [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters).\n\nExample of searching logs for a natural language query that contains the term \u201ctrain\u201d:\n\n{url}\/v1\/logs?version=2019-04-30&query=train\n\nReplace {url} with your URL.\n\nThe response of a logs query includes results that appear similar to Discovery document results. Each result is either a query or event, specified in the document type field.\n\nExample query log:\n\n{\n\"customer_id\": \"\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-usage"},{"document_id":"ibmcld_07214-41790-43719","score":10.8889600924,"text":"\nImproved query limits for Advanced and Premium plans : [Query expansion](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsquery-expansion) limits are increased for Advanced and Premium plans to 5,000 query expansions and 25,000 total terms. See [Discovery pricing plans](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans) for details.\n\n\n\n\n\n 28 February 2018 \n\nDeprecated AlchemyLanguage enrichments : AlchemyLanguage enrichments are deprecated, effective 1 March 2018.\n\n\n\n\n\n 23 February 2018 \n\nNew document similarity query feature : Added the ability to query by document similarity. You can query for similar documents by document ids, and optionally further refine the similarity by specifying fields. See [Document similarity](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsdoc-similarity) for more information.\n\nImproved highlight parameter : The [highlight parameter](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametershighlight) in query results is enhanced. Query results return complete sentences, ordered by their score.\n\n\n\n\n\n 21 February 2018 \n\nFixed PDF file type : Previously, when ingesting PDF documents, the file_type returned when ingestion notices were queried, in the extracted_metadata object, and from the document details API was html. This is no longer the case. The file_type returned is now pdf.\n\n\n\n\n\n 26 January 2018 \n\nNew Korean and Spanish accessibility in Discovery News : Added the ability to access Korean and Spanish collections to the [IBM Watson\u2122 Discovery News](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-watson-discovery-news) tile in the tooling. Previously, these collections could only be queried via the API.\n\n\n\n\n\n 23 January 2018 \n\nNew query expansion : Added the ability to expand the scope of a query - for example, you can expand a query for \"car\" to include \"automobile\" and \"motor vehicle\".","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_16653-0-871","score":10.87170656,"text":"\n\n\n\n\n\n\n  Query history \n\nA query history audits all the current and past queries across the existing engines in IBM\u00ae watsonx.data.\n\nThe query history page in watsonx.data provides the following details that are related to the queries that are run:\n\n\n\n*  Query ID\n*  Query\n*  State\n*  Engine\n*  User\n*  Created\n\n\n\nIn the Query history page, you can search, refresh, filter, and customize the queries. You can select a Query from the page, view or copy the details of query statement, logical execution plan, and distributed execution plan. You can open the queries directly in a workspace, and also get the explain details of a query from the overflow menu of each query listed.\n\nFor more information about exporting and importing query history, see [Exporting and importing the query history](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-eximp-q-hist).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-query_history"},{"document_id":"ibmcld_16671-5931-7034","score":10.8254293928,"text":"\nFrom the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Select the catalog. In this scenario, consider the Apache Iceberg catalog, default schema, order_detail table, to run the query.\n4. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to view the details from iceberg-beta:\n\nExample:\n\n!\/bin\/bash\nSELECT * FROM \"iceberg-beta\".\"default\".\"order_detail\" LIMIT 10;\n5. Click the Run on button to run the query.\n6. Select Result set or Details tab to view the results. If required, you can save the query.\n7. Click Saved queries to view the saved queries.\n8. Click [Explain](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_prov_custbckt"},{"document_id":"ibmcld_07214-23189-25155","score":10.8102439135,"text":"\nThese words are now extracted from the highlights, rather than simply displaying the first 50 words of the article. See [highlight](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametershighlight) for an explanation of highlights. Highlights do not need to be explicitly included in your query to enable this behavior.\n\n\n\n\n\n 25 September 2018 \n\nNew Continuous Relevancy Training feature : Released Continuous Relevancy Training, which uses interactions from users to learn how to surface the most relevant results. It can learn from user behavior automatically, significantly reducing the effort required to improve the relevancy ranking of results. See [Continuous Relevancy Training](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-crt) for details.\n\nNew API support for longer queries : Added API support for performing longer queries. This increases the character limit to 10,000 characters, and makes it possible to increase the number of filters in your queries and perform more complex aggregations. See the POST Query at [API reference](https:\/\/cloud.ibm.com\/apidocs\/discoverylong-collection-queries) and [API reference](https:\/\/cloud.ibm.com\/apidocs\/discoverylong-environment-queries) for details.\n\nImproved ability to upgrade to Advanced plan : You can now upgrade your Advanced plan using the API. See [Upgrading your plan](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-upgrading-your-planswitchadvanced) for details.\n\nNew Element Classification objects : The Element Classification enrichment now has updated classified elements, contract elements, and parties and tables identified. For the updates, see [Element Classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\nNew full support for Brazilian Portuguese : Added full support for the Brazilian Portuguese language. For more information, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-language-support).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_07163-7-1995","score":10.7904221307,"text":"\nImproving result relevance with the API \n\nYou can train Discovery to improve the relevance of query results for your particular organization or subject area. When you provide a Discovery instance with training data, the service uses machine-learning Watson techniques to find signals in your content and questions. The service then reorders query results to display the most relevant results at the top. As you add more training data, the service instance becomes more accurate and sophisticated in the ordering of results it returns.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nFor comprehensive information about the training APIs, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery).\n\nIf you would prefer to use the Discovery tooling to train Discovery, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nTrained collections return a confidence score in the result of a natural language query. See [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16551-0-1579","score":15.8658151477,"text":"\n\n\n\n\n\n\n  How can I address storage space limits? \n\nDepending on your subscription plan, you might reach the storage limit that is specified for your plan and be prevented from completing tasks.\n\n  What\u2019s happening \n\nYou might see a message about exceeding the allowed storage space when you attempt to perform one of these tasks:\n\n\n\n*  Upload documents or dictionaries\n*  Deploy a model or version a model\n*  Run a pre-annotator on documents\n\n\n\n  Why it\u2019s happening \n\nThe storage limit is met or exceeded if the action proceeds.\n\n  How to fix it \n\nThe largest consumers of storage space are machine learning and rule-based models. To free up space, you can take the following actions:\n\n\n\n*  Delete snapshot versions of any models that you do not expect to need to revert to.\n*  Delete any models that you do not need.\n*  If your models are too important to delete, consider upgrading your plan to one that provides a larger allotment of storage space.\n\n\n\nAfter you remove models or model versions, wait an hour before you retry the action that resulted in the error message. It can take up to an hour for the storage space that you freed up to be available for use.\n\nTo manage your monthly bill, if the Admin role is assigned to you and you have a Premium or Standard account, you can set a storage limit on the Service Details page in Knowledge Studio. To see the Service Details page and set the storage limit, from the top navigation bar in Knowledge Studio, click the Settings icon, click the View\/modify service details link, and then click the Set storage limit link.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_ts_storage"},{"document_id":"ibmcld_01241-13660-15370","score":13.8261850007,"text":"\n-h, --help Show this message and exit.\n\nIf you're using the replication feature, be sure that the schedule that you're deleting isn't the schedule that is used by replication. For more information about deleting a replication schedule, see [here](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-replication).\n\n\n\n\n\n Deleting a snapshot in the UI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. Deletion is done through Storage > File Storage for Classic.\n\n\n\n1. Click your storage volume and click Snapshot to see the list of existing snapshots.\n2. Click Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/04e9937a86546143babfc65ea21fdd4ea2d12d13\/icons\/action-menu-icon.svg) next to a particular snapshot and click Delete to delete the snapshot. This deletion doesn't affect any future or past snapshots on the same schedule as snapshots don't depend on each other.\n\n\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Deleting a snapshot from the SLCLI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. You can delete a snapshot from the SLCLI by using the following command.\n\n slcli file snapshot-delete --help\nUsage: slcli file snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managingSnapshots"},{"document_id":"ibmcld_00241-13788-15540","score":13.7453197322,"text":"\n-h, --help Show this message and exit.\n\nIf you're using the replication feature, be sure that the schedule you're deleting isn't the schedule that is used by replication. For more information about deleting a replication schedule, see [Replicating Data](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-replication).\n\n\n\n\n\n Deleting a snapshot in the UI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. Deletion is done through Storage > Block Storage for Classic.\n\n\n\n1. Click your storage volume and click Snapshot to see the list of existing snapshots.\n2. Click Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/14cf2f2f32b430cf4ed67ad14b3cecc010f91c45\/icons\/action-menu-icon.svg) next to a particular snapshot and click Delete. Click the confirmation box that warns about possible data loss, then click Delete. This deletion doesn't affect any future or past snapshots on the same schedule as snapshots don't depend on each other.\n\n\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations (oldest first).\n\n\n\n\n\n Deleting a snapshot from the SLCLI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. You can delete a snapshot from the SLCLI by using the following command.\n\n slcli block snapshot-delete\nUsage: slcli block snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingSnapshots"},{"document_id":"ibmcld_04693-5720-7686","score":13.1919716961,"text":"\nFor example, you might scale from 256 - 1256 MB by changing the memory quota on the app details page. However, because the disk quota remained the same, you didn't get more disk space.\n\n Why it\u2019s happening \n\nThe default disk quota that is allocated for an app is 1 GB. If you need more disk space, you must manually specify the disk quota.\n\n How to fix it \n\nUse one of the following methods to specify your disk quota. The maximum disk quota that you can specify is 2 GB. If 2 GB is still not enough, try an external service such as [Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage).\n\n\n\n* In the manifest.yml file, add the following item:\n\ndisk_quota: <disk_quota>\n* Use the -k option with the ibmcloud cf push command when you push your app to IBM Cloud:\n\nibmcloud cf push appname -p app_path -k <disk_quota>\n\n\n\n\n\n\n\n Org's services limit is exceeded \n\nIf you are a Lite account user, you might be unable to create an app in IBM Cloud if you exceeded your organization's services limit.\n\n What\u2019s happening \n\nWhen you try to create an app in IBM Cloud, the following error message is displayed:\n\nBXNUI2032E: The <service_instances> resource wasn't created. While Cloud Foundry was being contacted to create the resource, an error occurred. Cloud Foundry message: \"You have exceeded your organization's services limit.\"\n\n Why it\u2019s happening \n\nThis error occurs when you exceed the limit on the number of service instances that you can have for your account.\n\n How to fix it \n\nDelete any services instances that aren't needed, or remove the limit on the number of service instances that you can have.\n\n\n\n* To delete a services instance, you can use the IBM Cloud console or the command line interface.\n\nTo use the IBM Cloud console to delete a service instance, complete the following steps: 1. In the resource list, click the Actions menu for the service that you want to delete. 2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-ts-cf-apps"},{"document_id":"ibmcld_16452-7020-8905","score":12.4901007779,"text":"\nFor help using the ground truth editor, see [Annotating documents](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide).\n\n\n\n\n\n\n\n Experimental services and features: What does experimental mean? \n\nIBM releases experimental services and features for you to try out. These services might be unstable, change frequently in ways that are not compatible with earlier versions, and might be discontinued with short notice. These services and features are not recommended for use in production environments.\n\nFor more information about experimental services, see the [IBM Cloud documentation ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/cloud.ibm.com\/docs\/get-support\/servicessupport.htmls-services-exporcont). For the full details of experimental services, see the latest version of the [IBM Cloud Service Description ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.ibm.com\/software\/sla\/sladb.nsf\/sla\/bm?OpenDocument).\n\n\n\n\n\n Storage space issues \n\n\n\n Symptoms \n\nYou might see a message about having exceeded the allowed storage space when you attempt to perform one of these tasks:\n\n\n\n* Upload documents or dictionaries\n* Deploy a model or version a model\n* Run a pre-annotator on documents\n\n\n\n\n\n\n\n Causes \n\nThe storage limit has been met or would be exceeded if the action were to proceed.\n\n\n\n\n\n Resolving the problem \n\nThe largest consumers of storage space are machine learning and rule-based models. To free up space, you can take the following actions:\n\n\n\n* Delete snapshot versions of any models that you do not expect to need to revert to.\n* Delete any models that you do not need.\n* If your models are too important to delete, consider increasing the amount of storage in your deployment.\n\n\n\n\n\n\n\n\n\n Contacting IBM Support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-troubleshooting"},{"document_id":"ibmcld_09568-3117-4891","score":12.0859663845,"text":"\nRabbitMQ Disk Alarms \n\nBy default, when the RabbitMQ server detects that free disk space has dropped below a certain threshold, it raises a disk alarm. The threshold for Messages for RabbitMQ is 80% of your deployment's disk size. The alarm blocks incoming messages from publishers and prevents messages in memory from being written to disk. The alarm is cluster-wide so if disk space on one node gets too low, the alarm blocks on all nodes. To clear the alarm, either messages that have been written to disk need to be consumed and that space is reclaimed, or scale your deployment to a larger disk size.\n\nMore information about memory alarms can be found in the [RabbitMQ documentation](https:\/\/www.rabbitmq.com\/disk-alarms.html).\n\n\n\n\n\n Disk IOPS \n\nThe number of input\/output operations per second (IOPS) is limited by the type of storage volume that is being used. Storage volumes for Messages for RabbitMQ deployments are provisioned on [Block Storage Endurance Volumes in the 10 IOPS per GB tier](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-orderingthroughConsoleorderingthroughConsoleEndurance). IOPS limits can affect RabbitMQ message throughput and storage operations. Reaching these limits can cause disk to fall behind on reclaiming space after messages are consumed, leading to disk alarms and publisher throttling until activity slows down. You can increase the number IOPS available to your deployment by increasing disk space.\n\n\n\n\n\n Quorum Queues \n\nHigh-availability can be managed with [quorum queues](https:\/\/www.rabbitmq.com\/quorum-queues.html). Using quorum queues impacts performance; it needs more memory and disk space for the WAL that it uses to maintain state for operations. It also needs more disk I\/O as it persists all data on disk.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-performance"},{"document_id":"ibmcld_09575-4-2169","score":11.8582065088,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Scaling Disk, Memory, and CPU \n\nYou can manually adjust the amount of resources available to your IBM Cloud\u00ae Messages for RabbitMQ deployment to suit your workload and the size of your data.\n\n\n\n Resource Breakdown \n\nMessages for RabbitMQ deployments have three data members in a cluster, and resources are allocated to all three members equally. For example, the minimum storage of a RabbitMQ deployment is 3072 MB, which equates to an initial size of 1024 MB per member. The minimum RAM for a RabbitMQ deployment is 3072 MB, which equates to an initial allocation of 1024 MB per member.\n\nBilling is based on the total amount of resources that are allocated to the service.\n\n\n\n Disk Usage \n\nStorage shows the amount of disk space that is allocated to your service. Each member gets an equal share of the allocated space. Your data is replicated across three data members in the RabbitMQ cluster, so the total amount of storage you use is approximately three times the size of your data set.\n\nDisk allocation affects the performance of the disk, with larger disks having higher performance. Baseline input\/output operations per second (IOPS) performance for disk is 10 IOPS for each GB. Reaching IOPS limits consistently causes throughput and message processing delays, which can be alleviated by scaling up disk space.\n\nYou cannot scale down storage. If your data set size has decreased, you can recover space by backing up and restoring to a new deployment.\n\n\n\n\n\n RAM \n\nRabbitMQ throttles publishing when it detects it is using 40% of available memory to keep memory usage from growing uncontrollably during spike of activity. If you find that you regularly reach the limit, you can allocate more memory to your deployment. Adding memory to the total allocation adds memory to the members equally.\n\n\n\n\n\n Queue Rebalancing \n\nIf you notice that one RabbitMQ node is occupying significantly more resources than another, it is likely that the queues are not evenly distributed between the nodes. This can happen for the following possible reasons:\n\n\n\n* You are connected to only one of the VIPs and all the queues are created on a single node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-resources-scaling&interface=ui"},{"document_id":"ibmcld_07578-1234045-1235864","score":11.7196473593,"text":"\nYou can obtain more information about the volume, such as how much disk space is taken and how much is available, from your Compute host's operating system.\n\nYou can use the following commands.\n\n\n\n* Linux\u00ae:\n\ndf -h\n\nThe command provides an output that shows how much space is available space and the percentage used.\n\n$ df -hT \/dev\/sda1\nFilesystem Type Size Used Avail Use% Mounted on\n\/dev\/sda1 disk 6.0G 1.2G 4.9G 20% \/\n* Windows\u00ae: you have two options.\n\nfsutil volume diskfree C:\n\ndir C:\n\nThe last line of the output shows how much space is unused.\n\nYou can also view the free disk space in the File Explorer by clicking This PC.\n\n\n\n* Does the volume need to be pre-warmed to achieve expected throughput?\n\nPre-warming is not needed. You can observe specified throughput immediately upon provisioning the volume.\n* Can more throughput be achieved by using a faster Ethernet connection?\n\nThroughput limits are set at the LUN level and a faster Ethernet connection doesn't increase that limit. However, with a slower Ethernet connection, your bandwidth can be a potential bottleneck.\n* Do firewalls and security groups impact performance?\n\nIt's best to run storage traffic on a VLAN, which bypasses the firewall. Running storage traffic through software firewalls increases latency and adversely affects storage performance.\n* How do I route Block Storage for Classic traffic to its own VLAN interface and bypass a firewall?\n\nTo enact this best practice, complete the following steps.\n\n\n\n1. Provision a VLAN in the same data center as the host and the Block Storage for Classic device. For more information, see [Getting started with VLANs](https:\/\/cloud.ibm.com\/docs\/vlans?topic=vlans-getting-started).\n2. Provision a secondary private subnet to the new VLAN.3\n3. Trunk the new VLAN to the private interface of the host.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1236678-1238497","score":11.7196473593,"text":"\nYou can obtain more information about the volume, such as how much disk space is taken and how much is available, from your Compute host's operating system.\n\nYou can use the following commands.\n\n\n\n* Linux\u00ae:\n\ndf -h\n\nThe command provides an output that shows how much space is available space and the percentage used.\n\n$ df -hT \/dev\/sda1\nFilesystem Type Size Used Avail Use% Mounted on\n\/dev\/sda1 disk 6.0G 1.2G 4.9G 20% \/\n* Windows\u00ae: you have two options.\n\nfsutil volume diskfree C:\n\ndir C:\n\nThe last line of the output shows how much space is unused.\n\nYou can also view the free disk space in the File Explorer by clicking This PC.\n\n\n\n* Does the volume need to be pre-warmed to achieve expected throughput?\n\nPre-warming is not needed. You can observe specified throughput immediately upon provisioning the volume.\n* Can more throughput be achieved by using a faster Ethernet connection?\n\nThroughput limits are set at the LUN level and a faster Ethernet connection doesn't increase that limit. However, with a slower Ethernet connection, your bandwidth can be a potential bottleneck.\n* Do firewalls and security groups impact performance?\n\nIt's best to run storage traffic on a VLAN, which bypasses the firewall. Running storage traffic through software firewalls increases latency and adversely affects storage performance.\n* How do I route Block Storage for Classic traffic to its own VLAN interface and bypass a firewall?\n\nTo enact this best practice, complete the following steps.\n\n\n\n1. Provision a VLAN in the same data center as the host and the Block Storage for Classic device. For more information, see [Getting started with VLANs](https:\/\/cloud.ibm.com\/docs\/vlans?topic=vlans-getting-started).\n2. Provision a secondary private subnet to the new VLAN.3\n3. Trunk the new VLAN to the private interface of the host.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_06463-4-2086","score":11.6872835014,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Scaling Disk, Memory, and CPU \n\nYou can manually adjust the amount of resources available to your IBM Cloud\u00ae Databases for etcd deployment to suit your workload and the size of your data.\n\n\n\n Resource Breakdown \n\nDatabases for etcd deployment has three data members in a cluster, and resources are allocated to all three members equally. For example, the minimum storage of an etcd deployment is 61440 MB, which equates to an initial size of 20480 MB per member. The minimum RAM for an etcd deployment is 3072 MB, which equates to an initial allocation of 1028 MB per member.\n\nBilling is based on the total amount of resources that are allocated to the service.\n\n\n\n Disk Usage \n\nStorage shows the amount of disk space that is allocated to your service. Each member gets an equal share of the allocated space. Disk allocation affects the performance of the disk, with larger disks having higher performance. Baseline input\/output operations per second (IOPS) performance for disk is 10 IOPS for each GB. Due to the etcd [8 GB storage limit](https:\/\/etcd.io\/docs\/v3.4.0\/dev-guide\/limit\/), scaling disk space increases only the IOPS your deployment can handle.\n\nYou cannot scale down storage. You can recover space by backing up and restoring to a new deployment.\n\n\n\n\n\n RAM \n\nIf you find that your deployment suffers from performance issues due to a lack of memory, you can scale the amount of RAM allocated to your service. The amount of memory you allocate to the deployment is split between the 3 members. Adding memory to the total allocation adds memory to the members equally.\n\n\n\n\n\n Dedicated Cores \n\nYou can enable or increase the CPU allocation to the deployment. With dedicated cores, your resource group is given a single-tenant host with a reserve of CPU shares. Your deployment is then guaranteed the minimum number of CPUs you specify. The default of 0 dedicated cores uses compute resources on shared hosts. Going from a 0 to a >0 CPU count provisions and moves your deployment to new hosts, and your databases are restarted as part of that move.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-resources-scaling&interface=ui"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16729-11586-13439","score":22.1156737415,"text":"\n* 15 minutes\n* 2023-01-31\n\n\n\n[Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\nBlockchain[Setting up multiregion High Availability (HA) deployments for the ordering service](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-hadr-mr-os)Setting up multiregion High Availability (HA) deployments for the ordering service\n\nIn this tutorial, you learn how to set up a Raft ordering service with five ordering nodes that span multiple regions for maximum high availability.\n\nIBM Blockchain Platform\n\n\n\n* 2023-02-17\n\n\n\n[Using certificates from an external Certificate Authority](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-tutorial-extca)Using certificates from an external Certificate Authority\n\nIn this tutorial, you learn how to use certificates that were generated by an external Certificate Authority (CA) with your IBM\u00ae Blockchain Platform network. After you gather the required certificates for a peer or ordering node, you build a Membership Service Provider (MSP) definition that is used by your blockchain components.\n\nIBM Blockchain Platform\n\n\n\n* 30 minutes\n* 2023-02-17","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_16728-5097-7108","score":22.011480989,"text":"\n[solution icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/magic-wand.svg) [Best practices for organizing users, teams, applications](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-users-teams-applications)Best practices for organizing users, teams, applications Solution tutorial\n\nThis tutorial gives an overview of the concepts available in IBM Cloud for identity and access management and how they can be implemented to support the multiple development stages of an application.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Bring Your Own IP Address](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-byoip)Bring Your Own IP Address Solution tutorial\n\nThis tutorial presents a brief overview of BYOIP implementation patterns that can be used with IBM Cloud and a decision tree for identifying the appropriate pattern when realizing the secure enclosure as described in the Isolate workloads with a secure private network tutorial. Setup may require additional input from your onsite network team, IBM Cloud technical support or IBM Services.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage Solution tutorial\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"},{"document_id":"ibmcld_16729-326786-328759","score":21.6750675141,"text":"\nVirtual Private Cloud (VPC) Log Analysis\n\n+6\n\nActivity Tracker hosted event search,Secrets Manager,App ID,Key Protect,Hyper Protect Crypto Services,Object Storage\n\n\n\n* 1 hour\n* 2023-05-05\n\n\n\n[Serverless web application and API with Code Engine](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-serverless-webapp)Serverless web application and API with Code Engine\n\nIn this tutorial, you will create a serverless web application using a bucket in Object Storage and implementing the application backend using IBM Cloud Code Engine and IBM Cloudant as JSON document database.\n\nCode Engine Cloudant\n\n+1\n\nObject Storage\n\n\n\n* 1 hour\n* 2023-06-16\n\n\n\n[Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\n[Accelerate delivery of static files using a CDN](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-static-files-cdn)Accelerate delivery of static files using a CDN\n\nThis tutorial walks you through how to host and serve website assets (images, videos, documents) and user generated content in a IBM Cloud Object Storage, and how to use a IBM\u00ae Content Delivery Network (CDN) for fast and secure delivery to users around the world.\n\nContent Delivery Network (CDN) Object Storage\n\n\n\n* 2 hours","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_13162-7-1878","score":21.4779740332,"text":"\nBuild a data lake using object storage \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n\n\n Objectives \n\n\n\n* Use Object Storage to store raw data files\n* Query data directly from Object Storage using Data Engine (previously SQL Query)\n* Refine and analyze data in IBM Watson\u00ae Studio\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/Smart-Data-Lake-Architecture.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. Raw data is stored on Object Storage.\n2. Data is reduced, enhanced or refined with Data Engine.\n3. Data analysis occurs in Watson Studio.\n4. Non-technical users access data through application(s).\n5. Refined data is pulled from Object Storage.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI.\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools you can use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_13162-12751-14416","score":21.2148894115,"text":"\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)\n* Build a web app with a dashboard for line of business users utilizing [IBM Cognos Dashboard Embedded](https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial).\n\n\n\n\n\n\n\n Step 8: Remove resources \n\nRun the following commands to remove services, applications and keys you created and used.\n\nibmcloud resource service-instance-delete data-lake-sql\n\nibmcloud resource service-instance-delete data-lake-studio\n\nibmcloud iam api-key-delete data-lake-cos-key\n\nibmcloud resource service-instance-delete data-lake-cos\n\nIf the deletion of data-lake-cos is not successful delete it from the storage section of the [Resource List](https:\/\/cloud.ibm.com\/resources).\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-resource-reclamation).\n\n\n\n\n\n Related content \n\n\n\n* [ibmcloudsql](https:\/\/github.com\/IBM-Cloud\/sql-query-clients\/tree\/master\/Python)\n* [Jupyter Notebooks](https:\/\/jupyter.org\/)\n* [Folium](https:\/\/python-visualization.github.io\/folium\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_13162-2830-4436","score":20.5538810826,"text":"\nCreate an instance of [Object Storage](https:\/\/cloud.ibm.com\/catalog\/services\/cloud-object-storage). If you already have Object Storage instance with a lite plan, use standard instead of lite.\n\nibmcloud resource service-instance-create data-lake-cos cloud-object-storage lite global\n4. Create an instance of [Data Engine](https:\/\/cloud.ibm.com\/catalog\/services\/sql-query). Replace us-south by your region, if needed. If you already have Data Engine instance with a lite plan, use standard instead of lite.\n\nibmcloud resource service-instance-create data-lake-sql sql-query lite us-south\n5. Create an instance of [Watson Studio](https:\/\/cloud.ibm.com\/catalog\/services\/watson-studio).\n\nibmcloud resource service-instance-create data-lake-studio data-science-experience free-v1 us-south\n6. Create an API key for service access. Copy the output to a secure, permanent location for later use.\n\nibmcloud iam api-key-create data-lake-cos-key --output json\n\n\n\n\n\n\n\n Step 2: Uploading data \n\nIn this section, you will upload data to an Object Storage bucket. You can do this using regular http upload or by utilising the built-in Cloud High-Speed Transfer Service. Cloud High-Speed Transfer Service protects data as it is uploaded to the bucket and [can greatly reduce transfer time](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/ibm-cloud-object-storage-simplifies-accelerates-data-to-the-cloud).\n\n\n\n1. Download the [City of Los Angeles \/ Traffic Collision Data from 2010](https:\/\/data.lacity.org\/api\/views\/d5tf-ez2w\/rows.csv?accessType=DOWNLOAD) CSV file. The file is 81MB and may take a few minutes to download.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_14654-7-1943","score":20.2503967313,"text":"\nPlanning for vCenter Server instances \n\nPlan your instance based on the IBM Cloud\u00ae data center location, your workload capacity requirements, and add-on services requirements. Review the following requirements before you order your VMware vCenter Server\u00ae instance.\n\n\n\n* New deployments of vCenter Server instances with VMware vSphere\u00ae 6.5 or 6.7 are not supported.\n* New deployments of vCenter Server multizone instances are not supported.\n* New deployments of vCenter Server with NSX-V instances are not supported.\n\n\n\n\n\n Account requirements \n\nThe account that you are using must meet certain requirements. For more information, see [Signing up for required accounts](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-signing_required_accounts).\n\n\n\n\n\n IBM Cloud data center availability \n\nThe vCenter Server deployment has strict requirements on the physical infrastructure. Therefore, you can deploy instances only in IBM Cloud data centers that meet the requirements. The following IBM Cloud data centers are available for vCenter Server deployment.\n\nAsia-Pacific\n\nEurope\n\nNA East\n\n\n\nTable 1. Available IBM Cloud data centers for vCenter Server instances\n\n Geography Data center Pod Server options for NSX-T<br><br>[1] Server options for NSX-V<br><br>[2] \n\n Asia-Pacific CHE01 01 Skylake, Cascade Lake Skylake, Cascade Lake, SAP-certified Cascade Lake<br><br>[3] \n Asia-Pacific OSA21 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA22 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA23 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SNG01 02 Skylake, Cascade Lake, SAP-certified Cascade Lake Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SYD01 01-02 Skylake, Cascade Lake, SAP-certified Skylake, Cascade Lake, SAP-certified Cascade Lake","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_planning"},{"document_id":"ibmcld_09984-0-1283","score":20.1295655334,"text":"\n\n\n\n\n\n\n  Overview \n\nData lakes are an essential tool for storing structured and unstructured data on the cloud. With IBM\u00ae Netezza\u00ae Performance Server for IBM Cloud Pak\u00ae for Data as a Service, you can use external tables to access parquet files that are stored outside of your database in data lakes (on AWS S3). Also, you can analyze this data by using the robust and massively parallel Netezza Performance Server execution engine.\n\nExternal data sources use connection strings to specify how you can access an external system. Each connection string describes where your data is placed and how to authenticate to your data source. Each external data source has a definition (schema), but the actual data exists external to the Netezza Performance Server database.\n\nYou cannot backup (nzbackup) and restore (nzrestore) external data source objects.\n\nUse cases for external data source include:\n\n\n\n*  [Running queries against parquet data that is stored in a data lake](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-querying_singularity).\n*  [Ingesting data into Netezza Performance Server](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-ingest_singularity).\n*  [Querying both local and remote data](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-merging_singularity).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-overview_singularity"},{"document_id":"ibmcld_13497-1510-3518","score":19.5949132775,"text":"\nExisting instances still work but will be fully deprecated on 31 October.\n\n\n\n\n\n May 2022 \n\nRebranding\n: IBM Cloud SQL Query was rebranded to IBM Cloud Data Engine.\n\nHive\n: Data Engine provides an external [Hive metastore (HMS) service](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore).\n\n\n\n\n\n November 2021 \n\nAdd columns to Catalog tables\n: You can add columns to existing Catalog tables with the newly supported ALTER TABLE ... ADD COLUMNS statement.\n\n\n\n\n\n July 2021 \n\nStream landing tutorial\n: A detailed [getting started tutorial](https:\/\/www.ibm.com\/cloud\/blog\/stream-landing-from-event-streams-kafka-service-to-ibm-cloud-data-lake-on-object-storage) for stream landing with Data Engine is now available.\n\nNew region for stream landing\n: The stream landing capability is now also available in Frankfurt, in addition to Dallas.\n\n\n\n\n\n June 2021 \n\nStream landing support\n: Data Engine now supports stream landing that enables you to stream your data in real time from a topic to a bucket of your choice. This capability enables efficient analytics on the new objects created.\n\nConnect to data lakes with Cloud Pak for Data\n: IBM Cloud Pak\u00ae for Data now comes with an integrated connector to Data Engine that allows to connect to cloud data lakes and import data assets into projects and catalogs in Cloud Pak for Data. For more information, see [Connecting to a Cloud Data Lake with IBM Cloud Pak for Data](https:\/\/www.ibm.com\/cloud\/blog\/connecting-to-a-cloud-data-lake-with-ibm-cloud-pak-for-data).\n\n\n\n\n\n December 2020 \n\nSupported regions\n: Data Engine is available in Chennai, India. When you provision new instances, you can select whether it is being provisioned in Dallas, Frankfurt, or Chennai.\n\nIBM Cloud Object Storage\n: IBM Cloud Object Storage web console discovers SQL-queryable objects and folders and directly starts the Data Engine web console with a prefilled SQL statement for seamless interactive data exploration.\n\n\n\n\n\n November 2020 \n\nModify location of Hive partitions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-query-relnotes"},{"document_id":"ibmcld_14823-7-1880","score":19.4609897702,"text":"\nPlanning for VMware vSphere \n\nReview the following requirements before you order a VMware vSphere\u00ae instance. Plan your VMware vSphere based on the IBM Cloud\u00ae data center location and your workload capacity requirements.\n\nYou are responsible for setting up the environment, installing, and configuring various VMware\u00ae components after the VMware ESXi\u2122 servers are deployed. The following examples are VMware components: VMware vCenter Server\u00ae, VMware NSX\u00ae, and VMware vSAN\u2122.\n\n\n\n Account requirements \n\nThe account that you are using must meet certain requirements. For more information, see [Signing up for required accounts](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-signing_required_accounts).\n\n\n\n\n\n IBM Cloud data center availability \n\nThe vSphere deployment has strict requirements on the physical infrastructure. Therefore, you can deploy clusters only in IBM Cloud data centers that meet the requirements. The following IBM Cloud data centers are available for vSphere deployment.\n\nCascade Lake bare metal servers are available in\n\nmultizone regionIBM Cloud data centers. For more information, see [Multizone region (MZR) overview](https:\/\/cloud.ibm.com\/docs\/loadbalancer-service?topic=loadbalancer-service-multi-zone-region-mzr-overview).\n\nIf you select a vSAN component, the location list is filtered by SSD (Solid-State Disk) availability.\n\nAsia-Pacific\n\nEurope\n\nNA East\n\n\n\nTable 1. Available IBM Cloud data centers for VMware vSphere instances\n\n Geography Data center Pod Server options<br><br>[1] \n\n Asia-Pacific CHE01 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA21 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA22 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA23 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SNG01 02 Skylake, Cascade Lake, SAP-certified Cascade Lake","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_planning"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1934264036}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16627-0-1141","score":19.1452834247,"text":"\n\n\n\n\n\n\n  About Data manager \n\nThe Data manager page in IBM\u00ae watsonx.data is the entry point to browse the schemas and tables by engine. You can select an engine to view the associated catalogs, schemas, and tables.\n\nFrom the Data manager page, you can create schemas and tables by using the Create option that is provided in the left window. You can also select a catalog or schema, click the overflow menu, and use the corresponding Create option to create a schema or table. Create table from file option in the overflow menu of schema is also used to ingest a data file into watsonx.data. Similarly, schemas and tables can be dropped from the catalogs.\n\nWait for a few minutes to view the changes after a schema or table is dropped.\n\nAdding, renaming, or dropping a column are the other tasks that can be performed in the Data manager page.\n\nYou can browse the Table schema and upto 25 rows of Data sample for some tables. You can view the Time travel snapshots and use the Rollback feature to rollback to a given snapshot for Iceberg tables.\n\nPresto cannot roll back to the snapshots that are not ancestors of the current snapshot.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-exp_objects"},{"document_id":"ibmcld_16640-7-2035","score":18.2488913565,"text":"\nKnown issues (Limitations) \n\nThe following limitations and known issues, apply to IBM\u00ae watsonx.data.\n\n\n\n Issue: Unable to view created schema \n\nWhen a user with the User role and the Create access (the user only has the Create access) is added to an external database, they cannot see the schemas that they created. Though the user can create schemas, they cannot view them. Following is the system response:\n\npresto:default> show schemas;\nSchema\n--------\n(0 rows)\n\nWorkaround: Provide select privilege for the schema the user created.\n\n\n\n\n\n Issue: Access denied message occurs when querying an external database \n\nWhen a user with the User role and Create access (the user only has Create access), is added to an external database, they cannot run the select query from the table they have created. Though the user can connect to the Presto engine and create tables and schemas, they cannot query from the table. The system displays an Access Denied message.\n\nQuery 20230608_132213_00042_wpmk2 failed: Access Denied: Cannot select from columns [id] in table or view tab_appiduser_01\n\nWorkaround: Provide select privilege for the table the user created.\n\n\n\n\n\n Issue: Schema created under different catalog \n\nSchemas are available across Iceberg and Hive catalogs. When a schema is created under Iceberg catalog, it is listed under Hive catalog and vice versa.\n\n\n\n\n\n Issue: Presto does not support deletion of Iceberg tables \n\n\n\n\n\n Issue: DROP SCHEMA in Db2 \n\nIn Db2, the schema can be dropped only if it is empty. Initiating DROP SCHEMA statement against a non-empty schema may result in Db2 SQL Error SQLCODE=-478 and SQLSTATE=42893.\n\n\n\n\n\n Issue: CREATE VIEW statement that is partially supported by Db2 \n\nDb2 connector partially supports CREATE VIEW statement. The Presto supported SQL syntax does not include creating views with custom column names (different than the table column names).\n\n\n\n\n\n Issue: CREATE VIEW statement that is partially supported by Netezza \n\nNetezza connector partially supports CREATE VIEW statement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-known_issues"},{"document_id":"ibmcld_16664-1011-1647","score":18.1674927674,"text":"\nHudi X X X \u2713 -- X X X X X \u2713 X X X X X X X X \n\n\n\n\n\n Limitations \n\n\n\n1. For CREATE TABLE, MySQL connector supports only CREATE TABLE AS.\n2. For ALTER TABLE, MongoDB connector supports only table rename.\n3. Db2 connector partially supports ALTER TABLE, CREATE VIEW, and DROP SCHEMA.\n4. Netezza connector partially supports ALTER TABLE and CREATE VIEW.\n5. MySQL, PostgreSQL, MongoDB, Db2, and Netezza connectors support DROP TABLE only when enabled in catalog.\n6. The CREATE SCHEMA, CREATE TABLE, DROP SCHEMA, DROP TABLE, DELETE, DROP VIEW, ALTER TABLE, and ALTER SCHEMA are not available for database based catalogs in the Data Manager UI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-supported_sql_statements"},{"document_id":"ibmcld_16567-9760-11240","score":18.1276961392,"text":"\n--source-table-def-file ([VirtualizeTableSourceTableDefFile](https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugincli-virtualize-table-parameter-source-table-def-item-example-schema))\n: Required.\n\n--sources ([]string)\n: The name of data source. Required.\n\n--virtualized-table-name (string)\n: The name of the table that will be virtualized. Required.\n\n--virtualized-schema (string)\n: The schema of the table that will be virtualized. Required.\n\n--virtualized-table-def-file ([VirtualizeTableVirtualTableDefFile](https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugincli-virtualize-table-parameter-virtual-table-def-item-example-schema))\n: Required.\n\n--is-included-columns (string)\n: The columns that are included in the source table.\n\n--replace (bool)\n: Determines whether to replace columns in the virtualized table.\n\n\n\n\n\n Examples \n\nVirtualize table\n\nibmcloud watson-query virtualized-table-create --source-table-name table1 --source-table-def-file source_tabel_def.json --virtualized-schema DV_IBMID_270001PD8Q --sources CONN1:TABLE1 --virtualized-table-name TABLE1 --virtualized-table-def-file virtualized_table_def.json. The json file content example: \"[{\"column_name\":\"COL1\",\"column_type\":\"VARCHAR\"}]\"\n\n\n\n\n\n\n\n ibmcloud watson-query virtualized-table-delete \n\nRemove specified virtualized table. You must specify the schema and table name.\n\nibmcloud watson-query virtualized-table-delete --virtualized-schema VIRTUALIZED-SCHEMA --virtualized-name VIRTUALIZED-NAME\n\n\n\n Command options","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin"},{"document_id":"ibmcld_04326-9759-11237","score":18.1072845471,"text":"\n--source-table-def-file ([VirtualizeTableSourceTableDefFile](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-namecli-virtualize-table-parameter-source-table-def-item-example-schema))\n: Required.\n\n--sources ([]string)\n: The name of data source. Required.\n\n--virtualized-table-name (string)\n: The name of the table that will be virtualized. Required.\n\n--virtualized-schema (string)\n: The schema of the table that will be virtualized. Required.\n\n--virtualized-table-def-file ([VirtualizeTableVirtualTableDefFile](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-namecli-virtualize-table-parameter-virtual-table-def-item-example-schema))\n: Required.\n\n--is-included-columns (string)\n: The columns that are included in the source table.\n\n--replace (bool)\n: Determines whether to replace columns in the virtualized table.\n\n\n\n\n\n Examples \n\nVirtualize table\n\nibmcloud watson-query virtualized-table-create --source-table-name table1 --source-table-def-file source_tabel_def.json --virtualized-schema DV_IBMID_270001PD8Q --sources CONN1:TABLE1 --virtualized-table-name TABLE1 --virtualized-table-def-file virtualized_table_def.json. The json file content example: \"[{\"column_name\":\"COL1\",\"column_type\":\"VARCHAR\"}]\"\n\n\n\n\n\n\n\n ibmcloud watson-query virtualized-table-delete \n\nRemove specified virtualized table. You must specify the schema and table name.\n\nibmcloud watson-query virtualized-table-delete --virtualized-schema VIRTUALIZED-SCHEMA --virtualized-name VIRTUALIZED-NAME\n\n\n\n Command options","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-name"},{"document_id":"ibmcld_16669-1692-3354","score":17.865532325,"text":"\nAlternatively, you can also register and attach an object storage bucket with pre-existing data to HMS.\n\nORC, Parquet, Avro, RCFile, SequenceFile, JSON, Text (CSV) are the Hive supported file formats.\n\n\n\n\n\n\n\n Step 2: Load data files into Presto \n\nAfter attaching the object storage bucket to HMS, you need to load data files into Presto by creating schema and external tables through the Hive connector.\n\n\n\n1. Run the following command to create schema for the data you want to access.\n\nCREATE SCHEMA <SCHEMA_NAME> WITH ( location = '<SCHEMA_LOCATION>' );\n\nFor example:\n\nCREATE SCHEMA hive.gosales WITH ( location = 's3a:\/\/lhbeta\/gosales' );\n2. Run the following command to create table by using an external location by pointing to an existing table.\n\nCREATE TABLE IF NOT EXISTS <TABLE_NAME> (\"<COLUMN_NAMES>\" <DATA_TYPE>) WITH ( format = '<DATA_FORMAT>', external_location = '<TABLE_LOCATION>' );\n\nFor example:\n\nCREATE TABLE IF NOT EXISTS hive.gosales.branch (\"BRANCH_CODE\" int, \"ADDRESS1\" varchar, \"ADDRESS1_MB\" varchar, \"ADDRESS2\" varchar, \"ADDRESS2_MB\" varchar, \"CITY\" varchar, \"CITY_MB\" varchar, \"PROV_STATE\" varchar, \"PROV_STATE_MB\" varchar, \"POSTAL_ZONE\" varchar, \"COUNTRY_CODE\" int, \"ORGANIZATION_CODE\" varchar, \"WAREHOUSE_BRANCH_CODE\" int) WITH ( format = 'CSV', external_location = 's3a:\/\/lhbeta\/gosales\/branch' );\n\n\n\n\n\n\n\n Step 3: Generate statistics with analyze table \n\nIf you want to use the data without creating a new copy for a different table format or more table optimizations, you can generate statistics alone with analyze table.\n\n\n\n1. To generate statistics with analyze table, run the following command:\n\nanalyze <TABLE_NAME>;\n\nFor example:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_ingest_osbckt"},{"document_id":"ibmcld_16582-13180-14642","score":17.8360567017,"text":"\n--assets ([CatalogPublishParametersAssetsItem[]](https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin?topic=watson-query-cli-plugin-CLI-namecli-catalog-publish-parameters-assets-item-example-schema))\n: Asset description. Example: \"[{\"schema\": \"db2inst1\",\"table\": \"employee\"}]\". Required.\n\n\n\n\n\n Examples \n\nPublish virtualized tables to WKC\n\nibmcloud watson-query virtualized-table-publish --catalog-id 12c60f7e-c366-4cda-ba3a-bfbb577a5f56 --allow-duplicates true --virtualized-schema DV_IBMID_6610020D12 --virtualized-table EMPLOYEE\n\n\n\n\n\n\n\n\n\n Schema examples \n\nThe following schema examples represent the data that you need to specify for a command option. These examples model the data structure and include placeholder values for the expected value type. When you run a command, replace these values with the values that apply to your environment as appropriate.\n\n\n\n CatalogPublishParametersAssetsItem[] \n\nThe following example shows the format of the CatalogPublishParametersAssetsItem[] object.\n\n[ {\n\"schema\" : \"db2inst1\",\n\"table\" : \"EMPLOYEE\"\n} ]\n\n\n\n\n\n PostDatasourceConnectionParametersProperties \n\nThe following example shows the format of the PostDatasourceConnectionParametersProperties object.\n\n{\n\"access_token\" : \"exampleString\",\n\"account_name\" : \"exampleString\",\n\"api_key\" : \"exampleString\",\n\"auth_type\" : \"exampleString\",\n\"client_id\" : \"exampleString\",\n\"client_secret\" : \"exampleString\",\n\"collection\" : \"exampleString\",\n\"credentials\" : \"exampleString\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin?topic=watson-query-cli-plugin-CLI-name"},{"document_id":"ibmcld_09958-4322-5978","score":17.783452308,"text":"\nTo create a temporal table, set DATA_VERSION_RETENTION_TIME to a nonzero value.\n\nFor detailed syntax and privileges, see [the CREATE TABLE command](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=npsscr-create-table-2).\n\nCREATE TABLE <tablename> ( <col>[, <col>\u2026 ] ) DATA_VERSION_RETENTION_TIME <number-of-days>;\n\nExample:\n\nCREATE TABLE PRODUCT (prodid int, proddesc char(100)) DATA_VERSION_RETENTION_TIME 30;\n\nWhen you insert a row into the table, the row receives a virtual insert timestamp that is equal to the commit time of the inserting transaction.\n\nWhen you delete a row from the table, the row receives a virtual delete timestamp that is equal to the commit time of the deleting (or truncating) transaction.\n\n\n\n\n\n Creating temporal schemas with the command-line \n\nTo create a temporal schema, set DATA_VERSION_RETENTION_TIME to a nonzero value.\n\nFor detailed syntax and privileges, see [the CREATE SCHEMA](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=npsscr-create-schema-2) command.\n\nCREATE SCHEMA <schema_name> DATA_VERSION_RETENTION_TIME <number-of-days>;\n\nExample:\n\nCREATE SCHEMA SCHEMA1 DATA_VERSION_RETENTION_TIME 30;\n\n\n\n\n\n Creating temporal databases with the command-line \n\nTo create a temporal database, set DATA_VERSION_RETENTION_TIME to a nonzero value.\n\nFor detailed syntax and privileges, see [the CREATE DATABASE command](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=npsscr-create-database-2).\n\nCREATE DATABASE <db_name> DATA_VERSION_RETENTION_TIME <number-of-days>;\n\nExample:\n\nCREATE DATABASE DB1 DATA_VERSION_RETENTION_TIME 30;\n\n\n\n\n\n\n\n Creating time travel objects with the web console \n\n\n\n Creating temporal tables with the web console \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-enablingdisabling_tt"},{"document_id":"ibmcld_16471-188589-190073","score":17.7547587237,"text":"\n+ arg1Schema.size (), returnSchema.getFieldTypeByIx (i + arg1Schema.size ()), arg2Schema.getFieldTypeByIx (i)); }\n}\n}\n\n}\nShow more\n\n\n\n\n\n\n\n Declaring user-defined functions \n\nYou can make the user-defined scalar functions and machine learning models from PMML files available to AQL by using the create function statement.\n\n\n\n Syntax \n\nThe general syntax of the create function statement is as follows:\n\ncreate function <function-name>(<input-schema-definition>)\nreturn <return-type> [like <column-name>] | table ( <output-schema-definition)\nexternal_name <ext-name>\nlanguage [java | pmml]\n[deterministic | not deterministic]\n[return null on null input | called on null input];\n\n<input-schema-definition>\n<column-name> <data-type> | table (<output-schema-definition>) as locator [,<column-name> <data-type> | table (<output-schema-definition>) as locator ]\n\n<output-schema-definition>\n<column-name> <data-type> [,<column-name> <data-type>]\n\n\n\n\n\n Description \n\n\n\n* <function-name>\n\nThe <function-name> declares the AQL name of the UDF. The UDF is referred to in the AQL code with this name\n* <input-schema-definition>\n\nSpecifies the input parameters of the UDF. An input parameter has a name, which is specified as <column-name>, and can be either a scalar type or a table locator. When the language is PMML, the function must take a single table that is called params as the argument.\n* <column-name>\n\nSpecifies the name of a column in the input or the output of the UDF.\n* <data-type>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_13498-108109-110305","score":17.7500756676,"text":"\nnew partitions can add data for that column\nALTER TABLE customers_addcol ADD COLUMNS (priority INTEGER)\n\nDo not use the ADD COLUMNS option with CSV tables. The CSV data format identifies columns by order (not by name), so any schema change leads to a schema mismatch with existing data.\n\nAlternatively, you can perform schema changes by dropping and re-creating catalog tables. It does not affect the stored data in Object Storage. This allows you to reexecute the automatic schema detection when the underlying data is extended with new objects containing more columns. You can also use this method to remove columns from the schema that you do not want to appear in the catalog.\n\n\n\n\n\n\n\n Describe table \n\n\n\n describeTable \n\nReturn the schema (column names and data types) of a table or view definition. If the table or view does not exist, you receive an error.\n\n-- returns detailed information about the customer table\nDESCRIBE TABLE customers_partitioned\n\n\n\n\n\n\n\n Show tables \n\n\n\n showTables \n\nReturns the list of the defined tables and views in the catalog. The LIKE option allows to filter for an indicated pattern. Use * as wildcard character.\n\n-- returns all defined tables in the catalog for this instance\nSHOW TABLES\n\n\n\n\n\n\n\n Show Partitions \n\n\n\n showPartitions \n\nList the defined partitions of a table when a table was created as partitioned. You can filter the returned partitions by using the partitionSpec option.\n\n-- returns all partitions for the table customers_partitioned\nSHOW PARTITIONS customers_partitioned\n\n\n\n\n\n\n\n\n\n Index management \n\nWith the following commands, you can create indexes for data skipping during SQL execution to improve performance and lower the costs of your SQL queries. The indexes store summary metadata for each partition of your table to avoid scanning data that is not needed for the query execution. For more information, see [index management](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-index_management).\n\n\n\n Create index \n\n\n\n createIndex \n\nCreate an index on the objects in the specified Object Storage location or on the specified table. Define the required index type for each column that you want to calculate the summary metadata for.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00579-2977-4822","score":17.4643356525,"text":"\n* IBM Cloudant guide to using [views](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsusing-views)\n* Performance implications of using [include_docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsmulti-document-fetching)\n\n\n\n\n\n\n\n Never rely on the default behavior of IBM Cloudant Query\u2019s no-indexing \n\nIt\u2019s tempting to rely on IBM Cloudant Query's ability to query without creating explicit indexes. This practice is costly in terms of performance, as every lookup is a full scan of the database rather than an indexed lookup. If your data is small, this full-scan lookup doesn\u2019t matter, but as the data set grows, performance becomes a problem for you, and for the cluster as a whole. It is likely that we will limit this facility soon. The IBM Cloudant Dashboard provides a method for creating indexes in an easy way.\n\nCreating indexes and crafting IBM Cloudant Queries that take advantage of them requires some flair. To identify which index is being used by a particular query, send a POST to the _explain endpoint for the database, with the query as data.\n\nFor more information, see [IBM Cloudant Query docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query).\n\n\n\n\n\n In IBM Cloudant Search (or IBM Cloudant Query indexes of type text), limit the number of fields \n\nIBM Cloudant Search and IBM Cloudant Query indexes of type text (both of which are Apache Lucene under the hood) provide you with a way to index any number of fields into the index. Some examples exist where this type of indexing is abused either deliberately, or mostly by mistake. Plan your indexing to comprise only the fields required by your actual queries. Indexes take up space and can be costly to rebuild if the number of indexed fields are large.\n\nWe also have the issue of which fields that you store in an IBM Cloudant Search.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00539-7-1755","score":16.8203360082,"text":"\nUsing IBM Cloudant Query FAQ \n\n[IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query) is an API for querying slices of data based on the values of a database's document attributes. It is a flexible API that must be used carefully to ensure that database performance can be maintained as the data size grows over time.\n\n\n\n How do I use IBM Cloudant Query? \n\nIBM Cloudant Query is accessed through the [POST \/{db}\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) API endpoint where the JSON specification of the query is passed in the HTTP POST body. For example, this query finds up to 10 documents where the firstname is \"Charles\" and the surname is \"Dickens\":\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"limit\": 10\n}\n\nFor more information, see [Selector Syntax](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-queryselector-syntax).\n\n\n\n\n\n How do I create an index to support an IBM Cloudant Query? \n\nWithout a suitable secondary index, IBM Cloudant Query scans each document in the database in turn until it has enough matches to satisfy the query. The larger the data set and the more documents it has to scan to find matching documents, the slower the response time. For faster performance, an IBM Cloudant Query _find must be backed by a suitable secondary index. A secondary index is a pre-calculated data structure that allows IBM Cloudant to quickly jump to the slice of data it needs without scanning irrelevant documents. For the surname fields, we call the [POST \/{db}\/_index](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostindex) endpoint to pass the JSON index definition as the HTTP POST body:\n\n{\n\"index\": {\n\"fields\": [\"firstname\", \"surname\"]\n},\n\"ddoc\": \"jsonindexes\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_00579-1483-3406","score":16.6079265062,"text":"\nSince the index does not store the document, you can access any field without thinking ahead about what to store in the index.\n* The disadvantage is that getting the document back is more costly than the alternative of emitting data into the index itself. First, the database has to look up the requested key in the index and then read the associated document. Also, if you\u2019re reading the whole document, but need only a single field, you\u2019re making the database read and transmit data that you don\u2019t need.\n\n\n\nThis example also means that a potential race condition exists here. The document might change, or be deleted, between the index and document read (although unlikely in practice).\n\nEmitting data into the index (a so-called \u201cprojection\u201d in relational algebra terms) means that you can fine-tune the exact subset of the document that you need. In other words, you don\u2019t need to emit the whole document. Emit a value that represents only the data you need in the app that is a cut-down object with minimal details, for example:\n\nemit(doc.indexed_field, {name: doc.name, dob: doc.dob});\n\nIf you change your mind on what fields you want to emit, the index needs rebuilding.\n\nIBM Cloudant Query\u2019s JSON indexes use views this way under the hood. IBM Cloudant Query can be a convenient replacement for some types of view queries, but not all. Do take the time to understand when to use one or the other.\n\n\n\n* IBM Cloudant Query [docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query)\n* IBM Cloudant guide to using [views](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsusing-views)\n* Performance implications of using [include_docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsmulti-document-fetching)\n\n\n\n\n\n\n\n Never rely on the default behavior of IBM Cloudant Query\u2019s no-indexing \n\nIt\u2019s tempting to rely on IBM Cloudant Query's ability to query without creating explicit indexes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00640-7-1376","score":16.3812585409,"text":"\nSending multiple queries to a database \n\nNow, the following instructions describe how to send multiple queries to a database by using _all_docs and _view endpoints.\n\n\n\n Sending multiple queries to a database by using _all_docs \n\nTo send multiple queries to a specific database, send a POST request to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/_all_docs\/queries.\n\nSee the following example that uses HTTP to send multiple queries to a database:\n\nPOST \/$DATABASE\/_all_docs\/queries HTTP\/1.1\n\nSee the following example to multi-query the list of all documents in a database:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" -X POST \"$SERVICE_URL\/products\/_all_docs\/queries\" -H \"Content-Type: application\/json\" --data '{\n\"queries\": [\n{\n\"keys\":\n\"small-appliances:1000042\",\n\"small-appliances:1000043\"\n]\n},\n{\n\"limit\": 3,\n\"skip\": 2\n}\n]\n}'\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsQuery;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsQueriesResult;\nimport com.ibm.cloud.cloudant.v1.model.PostAllDocsQueriesOptions;\n\nimport java.util.Arrays;\n\nCloudant service = Cloudant.newInstance();\n\nAllDocsQuery query1 = new AllDocsQuery.Builder()\n.keys(Arrays.asList(\"small-appliances:1000042\",\n\"small-appliances:1000043\"))\n.build();\n\nAllDocsQuery query2 = new AllDocsQuery.Builder()\n.limit(3)\n.skip(2)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-send-multiple-queries-to-a-database"},{"document_id":"ibmcld_00580-37889-39953","score":16.3534027429,"text":"\nIf you need to access objects within documents, you can use standard dot notation for example, address.zipcode to access a postal code string inside an address object.\n\nWe can also add the following parameters:\n\nFields\n: Specifies the document attributes that we want returned (the default is the entire document).\n\nSort\n: Defines how the data is to be sorted. Sort is an array, allowing the sort to be calculated on multiple attributes.\n\nLimit\n: The number of documents to return.\n\nIf you are from a relational database background, this query is the equivalent SQL query to that last IBM Cloudant query example.\n\nThe WHERE clause is the equivalent of SELECTOR in IBM Cloudant Query. ORDER and LIMIT are exactly equivalent, and the IBM Cloudant Query FIELDS list is equivalent to the comma-separated list of attributes after the SELECT keyword.\n\nThe JSON syntax might take a bit of getting used to, but MongoDB users might find it familiar.\n\nIBM Cloudant queries can be executed in the IBM Cloudant Dashboard. Select the database that you are working with, for example, books then choose the Query tab.\n\nEnter your IBM Cloudant Query JSON in the box that is provided, and click Run Query when you're ready. The result set appears on the page.\n\nThe Explain button is used to provide an explanation on how the database interprets the supplied query. This explanation becomes more important when we get to Indexing in the next part.\n\nQueries can be triggered from curl too. The Query JSON, in this case, is stored in a file and we POST to the _find endpoint by using the -d@ command-line syntax.\n\nThe Node.js code is similar. The Query is a standard JavaScript object, which is passed to the db.find function which it POSTs to the _find endpoint on your behalf.\n\nNow, time for a practical exercise. Devise your own IBM Cloudant Query that finds the titles of books that are written in the 20th Century. The IBM Cloudant Query documentation is at the on-screen URL if you need it.\n\nPause the presentation here if you don't want to know the answer...\n\nSee one solution:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00522-3956-5681","score":16.205228804,"text":"\nCopy and paste the following index definition:\n\n{\n\"index\": {\n\"fields\": [\n\"publisher\", \"year\"\n]\n},\n\"name\": \"publisher-year-index\",indexingdashboard5\n\"type\": \"json\"\n}\n\nSee an example in the following screen capture:\n\nZoom\n\n![Click Create index to create an index.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/images\/indexingdashboard2.png)\n\nFigure 2. Window for creating indexes\n\n\n\nThe fields array contains a list of fields that we want IBM Cloudant to index.\n\nIf we repeat our query, it is faster and remains quick even as the database size reaches millions of documents.\n\nIndexing instructs IBM Cloudant to create a secondary data structure that allows it to find the slice of data you need much faster than looking over every document in turn. IBM Cloudant Query is best for fixed queries based on the same fields in the same order.\n\nFor more information, see the following details in IBM Cloudant documentation:\n\n\n\n* [Optimizing IBM Cloudant Queries](https:\/\/blog.cloudant.com\/2020\/04\/24\/Optimising-Cloudant-Queries.html)\n* [IBM Cloudant Query documentation](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query)\n\n\n\nThis index is useful for queries that involve both the publisher and the year, but if we introduce another field or make the query more complex (for example, by using the $or operator), then the index doesn't get used. We are back to a full database scan.\n\nFor a general-purpose search facility, we need IBM Cloudant Search, which is described in the next section.\n\n\n\n\n\n\n\n Step 3. Creating a search engine - IBM Cloudant Search \n\nIBM Cloudant Search is based on Apache Lucene and has its own query language that allows rich queries to be constructed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-dig-deeper-dashboard"},{"document_id":"ibmcld_04339-5327-6381","score":16.1545405526,"text":"\nRequired.\n\nAllowable list items are: management, data. The minimum length is 1 item.\n\n\n\n\n\n Example \n\nExample request\n\nibmcloud cloudant events-config-update --types management,data\n\n\n\n\n\n Example output \n\nExample Ok response.\n\n{\n\"ok\" : true\n}\n\n\n\n\n\n\n\n ibmcloud cloudant throughput \n\nView the current consumption of provisioned throughput capacity for an IBM Cloudant instance. The current consumption shows the quantities of reads, writes, and global queries conducted against the instance for a given second.\n\nibmcloud cloudant throughput\n\n\n\n Example \n\nExample request\n\nibmcloud cloudant throughput\n\n\n\n\n\n Example default output \n\nExample CurrentThroughputInformation response.\n\nquery\t13\nread\t133\nwrite\t42\n\n\n\n\n\n Example full output \n\nExample CurrentThroughputInformation response.\n\n{\n\"throughput\" : {\n\"query\" : 13,\n\"read\" : 133,\n\"write\" : 42\n}\n}\n\n\n\n\n\n Default JMESPath \n\nA JMESPath query is applied to the output of this command by default. The default JMESPath is:\n\nthroughput\n\nIf a custom JMESPath query is provided, it will replace the default JMESPath.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cloudant-cli"},{"document_id":"ibmcld_00512-5160-7348","score":15.9971300714,"text":"\nSee also a brief overview of the underlying querying mechanism that you use to select the query mechanism that is best for each query your application needs to make.\n\n\n\n Global querying \n\nYou can make global queries to the following index types:\n\n\n\n* IBM Cloudant Query\n* Views\n* Search\n\n\n\nWhen you make a global query, the database must perform a scatter-gather operation across all data in the database. This action means making requests of many individual database servers. The API coordination node receives the responses from all these servers and combines them to form a single response to the client. This response might involve buffering data and delaying the response to the client if, for example, data requires sorting.\n\n\n\n\n\n Partition querying \n\nYou can make partition queries to the following index types:\n\n\n\n* IBM Cloudant Query\n* Views\n* Search\n\n\n\nWhen you make a partition query, the database can query just the data within a single partition. A partition's data resides in just one shard (with three replicas). The API coordination node can make a request directly to servers that host that data rather than needing to combine responses from many servers. The API coordination node is also free from buffering the response since it has no combination step to carry out. As a result, the data arrives at the client more quickly.\n\nAs the size of a database increases, the number of shards must also increase. The increase in shards directly increases the number of queries that the API coordination node needs to make to servers that host data when you use global queries. However, when you use partition queries, the number of shards has no effect on the number of servers the API coordination node needs to contact. As this number stays small, increasing data size has no effect on query latency, unlike global queries.\n\n\n\n\n\n\n\n Partitioned databases tutorials \n\nYou can see two examples of using partitioned databases:\n\n\n\n1. Read about [partitioned databases and Node.js](https:\/\/blog.cloudant.com\/2019\/05\/24\/Partitioned-Databases-with-Cloudant-Libraries.html) in this blog article that includes how to create a partitioned database, search, views, and a global index.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00620-25943-27384","score":15.954547197,"text":"\n* IBM Cloudant provides an array of 10 IBM Cloudant documents and a bookmark, an opaque key that represents a pointer to the next documents in the result set. * When the next set of results is required, the search is repeated. However, the query is sent, with the bookmark from the first response, to IBM Cloudant in the request. * IBM Cloudant replies with the second set of documents and another bookmark, which can be used to get a third page of results. * Repeat<-- <\/ul> -->Now you can see how to do that with code.<-- <\/section \"id=\"section-how-do-cloudant-bookmarks-work\" \"> --><-- <section \"id=\"section-use-cloudant-query-search\" \"> --> How can I use IBM Cloudant Query to search? First, you search for all the cities in the US. You're using IBM Cloudant Query]IBM Cloudant Query 1] , so the operation is specified as a block of JSON: {\n\"selector\": {\n\"$eq\": {\n\"country\": \"US\"\n}\n},\n\"limit\": 5\n}\nBy using the \/db\/_find]IBM Cloudant Query] ! ! API endpoint, the results are passed to IBM Cloudant.<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> curl -X POST -H \"Authorization: Bearer $API_BEARER_TOKEN\" -H 'Content-type: application\/json' -d '{\"selector\":{\"country\":{\"$eq\": \"US\"}},\"limit\":5}' \"$SERVICE_URL\/cities\/_find\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.FindResult;\nimport com.ibm.cloud.cloudant.v1.model.PostFindOptions;\n\nimport java.util.Collections;\nimport java.util.Map;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_00579-4284-6271","score":15.9412987467,"text":"\nIBM Cloudant Search and IBM Cloudant Query indexes of type text (both of which are Apache Lucene under the hood) provide you with a way to index any number of fields into the index. Some examples exist where this type of indexing is abused either deliberately, or mostly by mistake. Plan your indexing to comprise only the fields required by your actual queries. Indexes take up space and can be costly to rebuild if the number of indexed fields are large.\n\nWe also have the issue of which fields that you store in an IBM Cloudant Search. Stored fields are retrieved in the query without doing include_docs=true so the tradeoff is similar to the [Understand the tradeoffs in emitting data or not into a view](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-queryingtradeoffs-emit-data-or-not-in-view) section. For more information, see IBM Cloudant Search [docs](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search).\n\n\n\n\n\n Design document management requires some flair \n\nAs your data set grows, and your number of views goes up, sooner or later you want to ponder how you organize your views across design documents. A single design document can be used to form a so-called view group: a set of views that belong together by some metric that makes sense for your use case. If your views are static, that makes your view query URLs semantically similar for related queries. It\u2019s also more performant at index time because the index loads the document once and generates multiple indexes from it.\n\nDesign documents themselves are read and written by using the same read\/write endpoints as any other document. With these endpoints, you can create, inspect, modify, and delete design documents from within your application. However, even small changes to design documents can have significant effects on your database. When you update a design document, all views in it become unavailable until indexing is complete. This lag can be problematic in production.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.2463023887,"ndcg_cut_10":0.2463023887}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03162-10976-13038","score":14.58767108,"text":"\nThe routing rules identify the queue of agents to which messages from the assistant are transferred by default.\n\nThe code that you add to the setup page when you configure the service desk integration shares the following required information with Watson Assistant:\n\n\n\n* organization_id: Unique ID of the organization. A company can have more than one organization set up in Salesforce.\n* chat_api_endpoint: Salesforce API endpoint that is used by the integration to communicate with Salesforce.\n* deployment_id: Unique ID of the deployment. An organization can have multiple deployments.\n* button_id: Unique ID of a button, which defines the specific routing rules for incoming messages. Each deployment can have multiple buttons associated with it.\n\n\n\nTo override the default routing rules, you must specify a new value for the button_id. Before you perform this procedure, find out the ID of the Salesforce button implementation with the alternative routing rules that you want to use.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific group of Salesforce agents which is distinct from the default group.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Salesforce from the Service desk routing field.\n4. In the Button ID field, add the button_id value for the alternate routing destination that you want the assistant to use for conversations about only this topic. For example, 5733i0000008yGz.\n\nBe sure to specify the exact right syntax for the button_id value. The value is not validated by the service as you add it to your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-salesforce"},{"document_id":"ibmcld_03180-11118-12801","score":14.4955382305,"text":"\nIf the customer is on the Returns page, you might want to route the chat transfer to agents who know how to help customers return merchandise.\n\nFor more information, see [Web chat: Accessing browser information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrationsdialog-integrations-chat-browser-info).\n\n\n\n\n\n Routing by topic \n\nYou can specify a routing preference for specific topics of conversation in your dialog. When specified, the chat is transferred to the department that you designate. You can choose a department that you know has agents who are best able to address the topic.\n\nBefore you perform this procedure, determine which department you want users to be routed to.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific Zendesk department.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Zendesk from the Service desk routing field.\n4. In the Department field, add the department to which you want the assistant to transfer customers who want to discuss this topic. For example, sales.\n\nBe sure to specify the exact right syntax for the department name. The value is not validated by the service as you add it to your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"},{"document_id":"ibmcld_06926-3212-5298","score":14.1358540404,"text":"\n* The customer VRF is a connectivity service that provides isolation among tenants. Any additional controls that are needed within a tenancy must be provisioned separately by using a gateway, security groups, or host-based controls.\n\n\n\n\n\n\n\n Benefits of moving to VRF \n\nMoving to VRF includes the following primary benefits:\n\n\n\n* Industry-proven and widely accepted multiple isolation separation technologies. Many cloud customers find the Level-3 VPN approach more palatable than ACLs to their auditors and compliance officers.\n* IBM Cloud customers can extend or migrate the reach of their network significantly, due to addition of new sites or applications throughout the IBM network.\n* Tenant-specific routing tables narrow the aperture for IP address overlap, without the risk of overlap with other tenants' subnets or other parts of the network that are not applicable.\n\n\n\nCompared to the older ACL model, there are a few minor tradeoffs to take into account:\n\n\n\n* Converting to a customer VRF requires a maintenance window, which causes a brief disruption of backbone traffic flows.\n* Remote access by using the managed VPN services (SSL, IPsec) is limited to just SSL VPN into a data center; however, the shared ACL over the backbone allows global access from any entry point from either service.\n* VLAN spanning is a feature of the shared tenancy model and is not available in a VRF; this will be disabled upon conversion to the Customer VRF.\n* IPsec VPN managed service on IBM Cloud classic infrastructure remote access is not available.\n\n\n\nMany IBM Cloud customers currently operate with a shared tenancy model on the IBM Cloud network. During conversion, your shared tenancy is converted to use a customer VRF, most commonly with a new Direct Link subscription.\n\nFor specific information about how to initiate a VRF conversion for your account, refer to the conversion instructions for your IBM Cloud offering. For example:\n\n\n\n* [Direct Link conversion instructions](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-what-happens-during-the-account-conversion-process)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"},{"document_id":"ibmcld_16338-2788-4628","score":13.8037940874,"text":"\n* [Confidence scores](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-reviewreview-debug-confidence)\n* [Step locator](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-reviewreview-debug-step-locator)\n* [Follow along](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-reviewreview-debug-follow-along)\n\n\n\n\n\n Start and end of an action \n\nThe assistant marks the spots in the conversation when a customer enters an input that fits within an action. The assistant also marks when an action completes, and how it completes.\n\nCompletion options include ending:\n\n\n\n* With an end step\n* Without an end step\n* With a human agent escalation\n* With a search to a knowledge base\n\n\n\n\n\n\n\n Action confidence score \n\nEvery input that you enter that can start a new topic shows a confidence score icon. Hover over this icon to see a list of actions with different confidence scores.\n\nThese scores represent the assistant\u2019s confidence that the sentence or phrase that you entered can be solved by the steps that are built into a specific action.\n\nZoom\n\n![Debug mode](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/rn-debug-confidence.png)\n\nDebug mode\n\nThe top score in green represents the action with the highest confidence and the one the assistant used.\n\nThe remaining two are actions that were considered because of their confidence score, but weren't used because thee confidence scores were lower.\n\nIf no action scores higher than 20% confidence, you see the built-in action No action matches.\n\n\n\n\n\n Step locator \n\nSometimes you might find an error in the middle of a test conversation, and need to find which step and action is involved. A locator icon next to each assistant response lets you find the associated steps in the editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-review"},{"document_id":"ibmcld_10143-7-2020","score":13.5942485776,"text":"\nWhy can't I view or work with my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n What\u2019s happening \n\nYou are not able to find a cluster. When you run ibmcloud oc cluster ls, the cluster is not listed in the output.\n\nOr, you are not able to work with a cluster. When you run ibmcloud oc cluster config or other cluster-specific commands, the cluster is not found.\n\n Why it\u2019s happening \n\nIn IBM Cloud, each resource must be in a resource group. For example, cluster mycluster might exist in the default resource group.\n\nWhen the account owner gives you access to resources by assigning you an IBM Cloud IAM platform access role, the access can be to a specific resource or to the resource group. When you are given access to a specific resource, you don't have access to the resource group. In this case, you don't need to target a resource group to work with the clusters you have access to. If you target a different resource group than the group that the cluster is in, actions against that cluster can fail. Conversely, when you are given access to a resource as part of your access to a resource group, you must target a resource group to work with a cluster in that group. If you don't target your CLI session to the resource group that the cluster is in, actions against that cluster can fail.\n\nIf you can't find or work with a cluster, you might be experiencing one of the following issues:\n\n\n\n* You have access to the cluster and the resource group that the cluster is in, but your CLI session is not targeted to the resource group that the cluster is in.\n* You have access to the cluster, but not as part of the resource group that the cluster is in. Your CLI session is targeted to this or another resource group.\n* You don't have access to the cluster.\n\n\n\n How to fix it \n\nTo check your user access permissions:\n\n\n\n1. List all your user permissions.\n\nibmcloud iam user-policies <your_user_name>\n2. Check if you have access to the cluster and to the resource group that the cluster is in.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cluster_access"},{"document_id":"ibmcld_05690-7-2020","score":13.5942485776,"text":"\nWhy can't I view or work with my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n What\u2019s happening \n\nYou are not able to find a cluster. When you run ibmcloud ks cluster ls, the cluster is not listed in the output.\n\nOr, you are not able to work with a cluster. When you run ibmcloud ks cluster config or other cluster-specific commands, the cluster is not found.\n\n Why it\u2019s happening \n\nIn IBM Cloud, each resource must be in a resource group. For example, cluster mycluster might exist in the default resource group.\n\nWhen the account owner gives you access to resources by assigning you an IBM Cloud IAM platform access role, the access can be to a specific resource or to the resource group. When you are given access to a specific resource, you don't have access to the resource group. In this case, you don't need to target a resource group to work with the clusters you have access to. If you target a different resource group than the group that the cluster is in, actions against that cluster can fail. Conversely, when you are given access to a resource as part of your access to a resource group, you must target a resource group to work with a cluster in that group. If you don't target your CLI session to the resource group that the cluster is in, actions against that cluster can fail.\n\nIf you can't find or work with a cluster, you might be experiencing one of the following issues:\n\n\n\n* You have access to the cluster and the resource group that the cluster is in, but your CLI session is not targeted to the resource group that the cluster is in.\n* You have access to the cluster, but not as part of the resource group that the cluster is in. Your CLI session is targeted to this or another resource group.\n* You don't have access to the cluster.\n\n\n\n How to fix it \n\nTo check your user access permissions:\n\n\n\n1. List all your user permissions.\n\nibmcloud iam user-policies <your_user_name>\n2. Check if you have access to the cluster and to the resource group that the cluster is in.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_cluster_access"},{"document_id":"ibmcld_16258-1324-3123","score":12.7050978531,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-7-1952","score":12.5939024,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_02844-1555-3643","score":12.332551279,"text":"\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"},{"document_id":"ibmcld_03043-1537-3553","score":12.2405647785,"text":"\nTo train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.\n* [Dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build): A dialog is a branching conversation flow that defines how your application responds when it recognizes the defined intents and entities. You use the dialog editor in the tool to create conversations with users, providing responses based on the intents and entities that you recognize in their input.\n\n![Diagram of a basic implementation that uses intent and dialog only.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/basic-impl.png)\n\n\n\nTo enable your dialog skill to handle more nuanced questions, define entities and reference them from your dialog.\n\n\n\n* [Entities](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entities); An entity represents a term or object that is relevant to your intents and that provides a specific context for an intent. For example, an entity might represent a city where the user wants to find a business location, or the amount of a bill payment. In the tool, the name of an entity is always prefixed with the @ character.\n\nYou can train the skill to recognize your entities by providing entity term values and synonyms, entity patterns, or by identifying the context in which an entity is typically used in a sentence. To fine tune your dialog, go back and add nodes that check for entity mentions in user input in addition to intents.\n\n\n\n![Diagram of a more complex implementation that uses intent, entity, and dialog.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16258-1324-3123","score":24.1518267672,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-7-1952","score":24.0729001389,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_02844-1555-3643","score":23.4862583247,"text":"\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"},{"document_id":"ibmcld_16258-2570-3569","score":21.9802199821,"text":"\n[Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps. A panel opens showing the full back and forth between your customer and the assistant, including step interactions. The panel also provides a summary of how many requests there were, how many were recognized, whether search was initiated, and the duration of the conversation.\n\n![Conversation detail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-side.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_06926-3212-5298","score":21.2682952273,"text":"\n* The customer VRF is a connectivity service that provides isolation among tenants. Any additional controls that are needed within a tenancy must be provisioned separately by using a gateway, security groups, or host-based controls.\n\n\n\n\n\n\n\n Benefits of moving to VRF \n\nMoving to VRF includes the following primary benefits:\n\n\n\n* Industry-proven and widely accepted multiple isolation separation technologies. Many cloud customers find the Level-3 VPN approach more palatable than ACLs to their auditors and compliance officers.\n* IBM Cloud customers can extend or migrate the reach of their network significantly, due to addition of new sites or applications throughout the IBM network.\n* Tenant-specific routing tables narrow the aperture for IP address overlap, without the risk of overlap with other tenants' subnets or other parts of the network that are not applicable.\n\n\n\nCompared to the older ACL model, there are a few minor tradeoffs to take into account:\n\n\n\n* Converting to a customer VRF requires a maintenance window, which causes a brief disruption of backbone traffic flows.\n* Remote access by using the managed VPN services (SSL, IPsec) is limited to just SSL VPN into a data center; however, the shared ACL over the backbone allows global access from any entry point from either service.\n* VLAN spanning is a feature of the shared tenancy model and is not available in a VRF; this will be disabled upon conversion to the Customer VRF.\n* IPsec VPN managed service on IBM Cloud classic infrastructure remote access is not available.\n\n\n\nMany IBM Cloud customers currently operate with a shared tenancy model on the IBM Cloud network. During conversion, your shared tenancy is converted to use a customer VRF, most commonly with a new Direct Link subscription.\n\nFor specific information about how to initiate a VRF conversion for your account, refer to the conversion instructions for your IBM Cloud offering. For example:\n\n\n\n* [Direct Link conversion instructions](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-what-happens-during-the-account-conversion-process)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"},{"document_id":"ibmcld_06926-4859-5591","score":20.8998346687,"text":"\nDuring conversion, your shared tenancy is converted to use a customer VRF, most commonly with a new Direct Link subscription.\n\nFor specific information about how to initiate a VRF conversion for your account, refer to the conversion instructions for your IBM Cloud offering. For example:\n\n\n\n* [Direct Link conversion instructions](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-what-happens-during-the-account-conversion-process)\n* [VPC conversion instructions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-setting-up-access-to-classic-infrastructure&interface=uihow-you-can-initiate-the-conversion)\n* [IBM Cloud service endpoints conversion instructions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-vrf-service-endpoint)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"},{"document_id":"ibmcld_16259-1485-3642","score":20.4530776752,"text":"\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery\/takeout, Small\/Medium\/Large, Cheese\/Pepperoni\/Mushrooms\/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview"},{"document_id":"ibmcld_07325-4878-5917","score":20.4320462392,"text":"\n* VLAN spanning is a feature of the shared tenancy model and is not available in a VRF; this will be disabled upon conversion to the Customer VRF.\n* IPsec VPN managed service on IBM Cloud classic infrastructure remote access is not available.\n\n\n\nMany IBM Cloud customers currently operate with a shared tenancy model on the IBM Cloud network. During conversion, your shared tenancy is converted to use a customer VRF, most commonly with a new Direct Link subscription.\n\nFor specific information about how to initiate a VRF conversion for your account, see the conversion instructions for your IBM Cloud offering.\n\n\n\n* [Direct Link conversion instructions](https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-what-happens-during-the-account-conversion-process)\n* [VPC conversion instructions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-setting-up-access-to-classic-infrastructure&interface=uihow-you-can-initiate-the-conversion)\n* [IBM Cloud service endpoints conversion instructions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-vrf-service-endpoint)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"},{"document_id":"ibmcld_03162-10976-13038","score":20.2016199857,"text":"\nThe routing rules identify the queue of agents to which messages from the assistant are transferred by default.\n\nThe code that you add to the setup page when you configure the service desk integration shares the following required information with Watson Assistant:\n\n\n\n* organization_id: Unique ID of the organization. A company can have more than one organization set up in Salesforce.\n* chat_api_endpoint: Salesforce API endpoint that is used by the integration to communicate with Salesforce.\n* deployment_id: Unique ID of the deployment. An organization can have multiple deployments.\n* button_id: Unique ID of a button, which defines the specific routing rules for incoming messages. Each deployment can have multiple buttons associated with it.\n\n\n\nTo override the default routing rules, you must specify a new value for the button_id. Before you perform this procedure, find out the ID of the Salesforce button implementation with the alternative routing rules that you want to use.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific group of Salesforce agents which is distinct from the default group.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Salesforce from the Service desk routing field.\n4. In the Button ID field, add the button_id value for the alternate routing destination that you want the assistant to use for conversations about only this topic. For example, 5733i0000008yGz.\n\nBe sure to specify the exact right syntax for the button_id value. The value is not validated by the service as you add it to your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-salesforce"},{"document_id":"ibmcld_03180-9400-11633","score":20.1601897167,"text":"\nAfter writing a function that ensures that name and email values are always provided, set the Authenticate anonymous user chat transfers switch to On.\n\n\n\n\n\n\n\n Adding transfer support to your dialog \n\nUpdate your dialog to make sure it understands when users request to speak to a person, and can transfer the conversation properly. For more information, see [Adding chat transfer support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-transfers).\n\n\n\n\n\n Adding routing logic for transfers \n\nWhen you enable transfers to the Zendesk service desk, no routing preferences are specified. The conversation is sent to any available agent. However, there might be times when you want to route a customer to a specific Zendesk department. For example, your dialog might have a root dialog node that conditions on a close_account intent. For that branch of the conversation only, you want to transfer customers to agents in the Sales department who are authorized to offer incentives as a way to retain customers. You can direct transfers to specific departments by adding routing logic to your dialog.\n\nYou can specify alternate routing preferences based on:\n\n\n\n* browser information\n* the current topic of conversation\n\n\n\n\n\n Routing based on browser information \n\nWhen a customer interacts with the web chat, information about the current web browser session is collected. For example, the URL of the current page is collected. You can use this information to add custom routing rules to your dialog. For example, if the customer is on the Products page when a transfer to a human is requested, you might want to route the chat transfer to agents who are experts in your product portfolio. If the customer is on the Returns page, you might want to route the chat transfer to agents who know how to help customers return merchandise.\n\nFor more information, see [Web chat: Accessing browser information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrationsdialog-integrations-chat-browser-info).\n\n\n\n\n\n Routing by topic \n\nYou can specify a routing preference for specific topics of conversation in your dialog. When specified, the chat is transferred to the department that you designate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16252-3899-5971","score":7.5913395446,"text":"\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2messagestateless)\n* [v2 stateful \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"},{"document_id":"ibmcld_03107-5127-7134","score":7.5579442472,"text":"\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For Facebook integrations, the user_id property is set to the sender ID that Facebook provides in its payload.\n* For Slack integrations, the user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n* For web chat, you can set the value of the user_id property.\n\n\n\nBilling is managed per monthly active user per service instance. If a single user interacts with assistants that are hosted by different service instances that belong to the same plan, each interaction is treated as a separate use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_03107-3801-5605","score":7.4671308355,"text":"\nThe user_id property is specified at the root of the request body, as in this example:\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"I want to cancel my order\"\n},\n\"user_id\": \"my_user_id\"\n}\n\nIn some older SDK versions, the user_id property is not supported as a top-level method parameter. As an alternative, you can specify user_id within the nested context.global.system object.\n\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2messagestateless)\n* [v2 stateful \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_03042-2711-4616","score":7.4618486042,"text":"\n{: note}\n\n1. conversation_id (v1 only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\nShow more\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For web chat, you can set the value of the user_id property. For more information, see [Adding user identity information](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid).\n\n\n\n\n\n Handling anonymous users \n\nIf your custom application or assistant interacts with users who are anonymous, you can generate a randomized universally unique ID to represent each anonymous user. For more information about UUIDs, see [RFC 4122](https:\/\/tools.ietf.org\/html\/rfc4122.html).\n\n\n\n* For web chat, if you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user.\n\n\n\n\n\n\n\n\n\n Service API versioning","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-services-information"},{"document_id":"ibmcld_03037-1358-3485","score":7.4092485588,"text":"\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing. A skill is effectively a wrapper for a V1 workspace.\n\n\n\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each \/message API call.\n\n\n\n\n\n Enabling user metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_03042-1241-3131","score":7.4073744924,"text":"\n* [Skills](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-addskill-add-limits)\n* [Versions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-versionsversions-limits)\n\n\n\n\n\n\n\n User information \n\nA unique user is recognized by the user ID that is associated with the person that interacts with your assistant. It is your responsibility to pass the user ID information to the service. Watson Assistant checks for the following information from API requests in this order:\n\n1. user_id: A property defined in the API that is sent in the context object of a \/message API call. Using this property is the best way to ensure that you accurately attribute \/message API calls to unique users. For more information about the user ID property, see the API reference documentation:\n\n- context.global.system.user_id: [v2 API](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v2message)\n- context.metadata.user_id: [v1 API](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1message)\n\n1. session_id (v2 only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes integration or after the inactivity time limit is reached.\n\nIf you use the stateless v2 \/message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n{: note}\n\n1. conversation_id (v1 only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-services-information"},{"document_id":"ibmcld_03037-2895-4808","score":7.1123787396,"text":"\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each \/message API call.\n\n\n\n\n\n Enabling user metrics \n\nUser metrics allow you to see, for example, the number of unique users who have engaged with your assistant, or the average number of conversations per user over a given time interval on the [Overview page](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview). User metrics are enabled by using a unique User ID parameter.\n\nTo specify the User ID for a message sent using the \/message API, include the user_id property in your global [context](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v2message), as in this example:\n\n\"context\": {\n\"global\": {\n\"system\": {\n\"user_id\": \"{UserID}\"\n}\n}\n}\n\nIf your application is still using the older [v1 runtime API](https:\/\/cloud.ibm.com\/apidocs\/assistant-data-v1?curl=message), the context format is different:\n\n\"context\" : {\n\"metadata\" : {\n\"user_id\": \"{UserID}\"\n}\n}\n\n\n\n\n\n Associating message data with a user for deletion \n\nThere might come a time when you want to completely remove a set of your user's data from a Watson Assistant instance. When the delete feature is used, then the Overview metrics will no longer reflect those deleted messages; for example, they will have fewer Total Conversations.\n\n\n\n Before you begin \n\nTo delete messages for one or more individuals, you first need to associate a message with a unique Customer ID for each individual.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_03364-6793-8946","score":7.0337370041,"text":"\nSee [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-limits) for details.\n\nFor a Python script you can run to export logs and convert them to CSV format, download the export_logs_py.py file from the [Watson Assistant GitHub)](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py) repository.\n\n\n\n\n\n Understanding logs-related terminology \n\nFirst, review the definitions of terms that are associated with Watson Assistant logs:\n\n\n\n* Assistant: An application - sometimes referred to as a 'chat bot' - that implements your Watson Assistant content.\n* Assistant ID: The unique identifier of an assistant.\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resources"},{"document_id":"ibmcld_16262-6573-7996","score":7.0316695125,"text":"\n{\n\"output\": {\n\"generic\": [!\n{\n\"response_type\": \"text\",\n\"text\": \"Welcome to the Watson Assistant example\"\n}\n],\n\"intents\": [\n{\n\"intent\": \"hello\",\n\"confidence\": 1\n}\n],\n\"entities\": []\n},\n\"user_id\": \"my_user_id\",\n\"context\": {\n\"global\": {\n\"system\": {\n\"turn_count\": 1,\n\"user_id\": \"my_user_id\"\n}\n},\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"account_number\": \"123456\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n Restoring conversation state \n\nIn some situations, you might want the ability to restore a conversation to a previous state.\n\nYou can use the export option on stateful message requests to specify that you want the context object in the response to include complete session state data. If you specify true for this option, the returned skill context includes an encoded state property that represents the current conversation state.\n\nIf you are using the stateful message API, the service stores conversation state data only for the life of the session. However, if you save this context data (including state) and send it back to the service with a subsequent message request, you can restore the conversation to the same state, even if the original session expired or was deleted.\n\nIf you are using the stateless message API, the state property is always included in responses (along with the rest of context). Although stateless sessions do not expire, you can still use this state data to reset a conversation to a previous state.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context"},{"document_id":"ibmcld_03364-8502-10365","score":6.934949763,"text":"\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing. A skill is effectively a wrapper for a V1 workspace.\n\n\n\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each \/message API call.\n\n\n\n\n\n Associating message data with a user for deletion \n\nThere might come a time when you want to completely remove a set of your user's data from a Watson Assistant instance. When the delete feature is used, then the Overview metrics will no longer reflect those deleted messages; for example, they will have fewer Total Conversations.\n\n\n\n Before you begin \n\nTo delete messages for one or more individuals, you first need to associate a message with a unique Customer ID for each individual. To specify the Customer ID for any message sent using the \/message API, include the X-Watson-Metadata: customer_id property in your header. You can pass multiple Customer ID entries with semicolon separated field=value pairs, using customer_id, as in the following example:\n\ncurl -X POST -u \"apikey:3Df...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resources"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07765-0-1628","score":22.3587166159,"text":"\n\n\n\n\n\n\n  IA-5 (4) - Automated Support for Password Strength Determination \n\n\n\n  Control requirements \n\nIA-5 (4) - 0\n:   The organization employs automated tools to determine if password authenticators are sufficiently strong to satisfy [Assignment: organization-defined requirements].\n\n\n\n\n\n  IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n*  Check whether App ID advanced password policies are enabled\n*  IBMid employs automated tools to determine if password authenticators satisfy IBMid password requirements\n*  Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n*  Check whether App ID password strength regex is configured\n*  Check whether IBMid password policy policy contains spaces or any of the following characters: ;:(\"?)<>\n*  Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters\n*  Check whether IBMid password policy requires at least one uppercase letter\n*  Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nThis control enhancement focuses on the creation of strong passwords and the characteristics of such passwords (e.g., complexity) prior to use, the enforcement of which is carried out by organizational information systems in IA-5 (1).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5.4"},{"document_id":"ibmcld_02746-7-1681","score":17.4788020831,"text":"\nDefining password policies \n\nPassword policies, such as strength requirements, help you to enforce more secure applications. By defining advanced policies, you can define the rules that a user must conform to when they set their password or attempt to sign in to your app. For example, you can set the number of times that a user can try to sign in before they are locked out of their account.\n\n\n\n Policy: password strength \n\nA strong password makes it difficult, or even improbable for someone to guess the password in either a manual or automated way. To set requirements for the strength of a user's password, you can use the following steps.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. In the Define password strength box, click Edit. A screen opens.\n3. Enter a valid regex string in the Password strength box.\n\nExamples:\n\n\n\n* Must be at least 8 characters. (^.{8,}$)\n* Must have one number, one lowercase letter, and one capital letter. (^(?:(?=.d)(?=.[a-z])(?=.[A-Z]).)$)\n* Must have only English letters and numbers. (^[A-Za-z0-9]$)\n* Must have at least one unique character. (^(w)w?(?!1)w+$)\n\n\n\n4. Click Save.\n\n\n\nPassword strength can be set in the Cloud Directory settings page in the App ID dashboard, or by using [the management APIs](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Management%20API%20-%20Config\/mgmt.set_cloud_directory_password_regex).\n\n\n\n Setting a custom error message \n\nIf you set your own password regex policy and a user chooses a password that does not meet your requirements, the default message is The password doesn't meet the strength requirements.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_07787-0-1608","score":17.0545997017,"text":"\n\n\n\n\n\n\n  MA-4 - Nonlocal Maintenance \n\n\n\n  Control requirements \n\nThe organization:\n\nMA-4 (a)\n:   Approves and monitors nonlocal maintenance and diagnostic activities;\n\nMA-4 (b)\n:   Allows the use of nonlocal maintenance and diagnostic tools only as consistent with organizational policy and documented in the security plan for the information system;\n\nMA-4 (c)\n:   Employs strong authenticators in the establishment of nonlocal maintenance and diagnostic sessions;\n\nMA-4 (d)\n:   Maintains records for nonlocal maintenance and diagnostic activities; and\n\nMA-4 (e)\n:   Terminates session and network connections when nonlocal maintenance is completed.\n\n\n\n\n\n  NIST supplemental guidance \n\nNonlocal maintenance and diagnostic activities are those activities conducted by individuals communicating through a network, either an external network (e.g., the Internet) or an internal network. Local maintenance and diagnostic activities are those activities carried out by individuals physically present at the information system or information system component and not communicating across a network connection. Authentication techniques used in the establishment of nonlocal maintenance and diagnostic sessions reflect the network access requirements in IA-2. Typically, strong authentication requires authenticators that are resistant to replay attacks and employ multifactor authentication. Strong authenticators include, for example, PKI where certificates are stored on a token protected by a password, passphrase, or biometric. Enforcing requirements in MA-4 is accomplished in part by other controls.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ma-4"},{"document_id":"ibmcld_00708-54925-56282","score":16.8878621329,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"},{"document_id":"ibmcld_00684-54925-56282","score":16.8878621329,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"},{"document_id":"ibmcld_04341-54906-56263","score":16.8878621329,"text":"\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cra-cli-plugin"},{"document_id":"ibmcld_00708-32460-34303","score":16.7612108137,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"},{"document_id":"ibmcld_00684-32460-34303","score":16.7612108137,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"},{"document_id":"ibmcld_04341-32441-34284","score":16.7612108137,"text":"\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cra-cli-plugin"},{"document_id":"ibmcld_13992-7-1976","score":16.3878318191,"text":"\nConfiguring virtual servers \n\nWhen you have access to your virtual server, make sure that you change your password and consider setting up SSH for a more secure authentication solution. You have many other options for configuring your virtual server to meet the needs of your environment.\n\nBefore you configure a virtual server, review your options for connecting to the server and how to manage passwords and credentials. For more information, see [Getting started with IBM Cloud Virtual Private Networking](https:\/\/cloud.ibm.com\/docs\/iaas-vpn?topic=iaas-vpn-getting-started) and [Managing device access](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-managing-device-access).\n\n\n\n Log in \n\nLog in to the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/classic?) with the credentials that you received in an email when your account was initially created.\n\n\n\n Locate your virtual server \n\nFind your virtual server in the Device List in the IBM Cloud console. From the Device List, you can manage devices, upgrade devices, or generate bandwidth usage charts. For more information, see [Managing virtual servers](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-managing-virtual-serversmanaging-virtual-servers).\n\n\n\n\n\n Change your password \n\nChange your password using strong password guidelines. See [Viewing and managing device user names and passwords](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-view-update-user-name-password-for-deviceview-update-user-name-password-for-device).\n\n\n\n\n\n Manage SSH keys \n\nSSH provides better security solution than password authentication. See [Getting started with SSH keys](https:\/\/cloud.ibm.com\/docs\/ssh-keys?topic=ssh-keys-getting-started-tutorialgetting-started-tutorial).\n\n\n\n\n\n Record IP addresses and credentials \n\nKeep a log of IP addresses and credentials for the server in a safe location so that you can access them quickly without having to log in to the IBM Cloud console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-configuring-virtual-servers"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16258-7-1952","score":19.9695371546,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-1324-3123","score":19.4270324574,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_03354-4-1897","score":19.1476537182,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Improve your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nThe length of time for which messages are retained depends on your Watson Assistant service plan:\n\nService plan | Chat message retention\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"},{"document_id":"ibmcld_02844-1555-3643","score":18.1101010659,"text":"\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"},{"document_id":"ibmcld_16258-2570-3569","score":17.76806007,"text":"\n[Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps. A panel opens showing the full back and forth between your customer and the assistant, including step interactions. The panel also provides a summary of how many requests there were, how many were recognized, whether search was initiated, and the duration of the conversation.\n\n![Conversation detail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-side.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_03036-5624-7724","score":17.6771838496,"text":"\n[Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were covered (meaning intents in your dialog understood user requests and were able to address them), and not covered (meaning the input did not match an intent in the dialog and was processed by the Anything else node instead).\n* The trend graph shows the percentage of daily conversations that were covered. This graph helps you to see if your dialog is getting better or worse at covering conversations over time.\n\n\n\n![Shows the two coverage metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/coverage-metric.png)\n\nThe coverage metric requires that your dialog contain an Anything else node.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-4413-6535","score":17.5320527944,"text":"\nFor more information, see [Ending the conversation gracefully](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-startdialog-start-anything-else).\n\nThe containment and coverage metrics are available to Plus or Enterprise plan users.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period. This number counts exchanges in which the welcome message is displayed to a user, even if the user doesn't respond.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter to be specified with the messages. This value is typically specified by all integrations because it is used for billing purposes. For more information, see [User-based plans explained](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).\n\n\n\n\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03363-4-2165","score":17.2508979819,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03036-2789-4951","score":17.1757449174,"text":"\nIf you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-3084-5067","score":17.1674810929,"text":"\n[Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were covered (meaning intents in your dialog understood user requests and were able to address them), and not covered (meaning the input did not match an intent in the dialog and was processed by the Anything else node instead).\n* The trend graph shows the percentage of daily conversations that were covered. This graph helps you to see if your dialog is getting better or worse at covering conversations over time.\n\n\n\n![Shows the two coverage metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/coverage-metric.png)\n\nThe coverage metric requires that your dialog contain an Anything else node. For more information, see [Ending the conversation gracefully](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-startdialog-start-anything-else).\n\nThe containment and coverage metrics are available to Plus or Enterprise plan users.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period. This number counts exchanges in which the welcome message is displayed to a user, even if the user doesn't respond.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.2,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1130534018}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16417-3559-5683","score":29.0638502469,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-3559-5682","score":29.0638502469,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16464-12399-14287","score":23.8254921958,"text":"\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16417-1764-4158","score":23.4936592248,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-1764-4158","score":23.4936592248,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16563-12333-14196","score":23.3895502211,"text":"\nThe IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16417-5155-7505","score":22.8842562568,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":22.8842562568,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16563-10714-12816","score":21.8243213814,"text":"\nFrom the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16464-13891-15856","score":21.5640627524,"text":"\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16417-5155-7505","score":19.074851812,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":19.074851812,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16563-10714-12816","score":18.8166184672,"text":"\nFrom the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16425-14122-16407","score":18.6690597836,"text":"\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_16490-14092-16377","score":18.6690597836,"text":"\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"},{"document_id":"ibmcld_16468-13270-15209","score":18.575387762,"text":"\n[Modifying a type system without losing human annotations](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-improve-mlwks_projtypesysmod)\n\n\n\n\n\n\n\n\n\n Setting the IAA threshold \n\nTo help you decide whether to accept or reject an annotated document set, you can specify an inter-annotator agreement threshold. The threshold helps you compare how well or poorly inter-annotator agreement compares to the IAA score calculated by the system.\n\n\n\n About this task \n\nTo compare how different human annotators annotated the same documents, specify an evaluation threshold. If the annotations made by one human annotator differ from the annotations made by another human annotator to the point where the difference results in a low score, it means that the annotators do not agree. The disagreement needs to be investigated and resolved.\n\n\n\n\n\n Procedure \n\nTo set the inter-annotator agreement threshold:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. Select the Settings > IAA Settings tab.\n3. Specify a value between 0 and 1, such as .5 or .8, and then click Save.\n\n\n\n\n\n\n\n\n\n Connecting to annotation guidelines \n\nAfter you create annotation guidelines for your project, you can configure Knowledge Studio to connect to them. For help with choosing the correct annotation to apply, human annotators can review the guidelines while annotating documents. Administrators can also review the guidelines if they need assistance while resolving annotation conflicts in overlapping documents.\n\n\n\n Procedure \n\nTo connect the ground truth editor and adjudication tool to your annotation guidelines:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. select the Settings > Annotation Guidelines tab.\n3. Specify the URL to where your guidelines are hosted.\n4. Click Save. The system connects the ground truth editor and adjudication tool to your annotation guidelines.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_16464-10867-12930","score":18.4523496765,"text":"\n[This screen capture shows two mentions connected by the relation type, \"founderOf\".](images\/wks_tut_annotaterelation.png \"This screen capture shows two mentions connected by the relation type, \"founderOf\".\")\n\n\n\n8. From the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\n> Note: In a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16464-13891-15856","score":18.4463569025,"text":"\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16417-3559-5683","score":18.1633566213,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-3559-5682","score":18.1633566213,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16417-3559-5683","score":11.6620411471,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-3559-5682","score":11.6620411471,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_01286-13972-15675","score":11.2562737206,"text":"\nIf original IOPS\/GB for the volume is greater than or equal to 0.3, new IOPS\/GB for the volume must also be greater than or equal to 0.3.]\n\n-t, --new-tier\n: Endurance Storage Tier (IOPS per GB) [only for endurance volumes]. If no tier is specified, the original tier of the volume is used. Requirements: [If original IOPS\/GB for the volume is 0.25, new IOPS\/GB for the volume must also be 0.25. If original IOPS\/GB for the volume is greater than 0.25, new IOPS\/GB for the volume must also be greater than 0.25.]\n\n-f, --force\n: Force operation without confirmation.\n\nExamples:\n\nibmcloud sl file volume-modify 12345678 --new-size 1000 --new-iops 4000\n\nThis command modifies volume 12345678 with size of 1000 GB, and IOPS of 4000.\n\nibmcloud sl file volume-modify 12345678 --new-size 500 --new-tier 4\n\nThis command modifies volume 12345678 with size 500 GB, and tier level 4 IOPS per GB.\n\n\n\n\n\n ibmcloud sl file volume-options \n\nList all options for ordering a file storage:\n\nibmcloud sl file volume-options\n\nExamples:\n\nibmcloud sl file volume-options\n\nThis command lists all options for creating a file storage volume, including storage type, volume size, IOPS, tier level, data center, and snapshot size.\n\n\n\n\n\n ibmcloud sl file volume-refresh \n\nRefresh a dependent duplicate volume with a snapshot from its parent:\n\nibmcloud sl file volume-refresh VOLUME_ID SNAPSHOT_ID [OPTIONS]\n\nCommand options:\n\n-f, --force-refresh\n: Force the volume refresh. Ongoing transactions are canceled. --output\n: Specify output format. Only JSON is supported now.\n\nExamples:\n\nibmcloud sl file volume-refresh 123 456\n\nRefresh a dependent duplicate 123 with a snapshot from its parent 456.\n\n\n\n\n\n ibmcloud sl file volume-set-note","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-sl-file-storage-service"},{"document_id":"ibmcld_15490-7-1958","score":11.1743469655,"text":"\nSecuring your data \n\nThe data volume that you attach to your Hyper Protect Virtual Server for VPC instance is protected by a Linux Unified Key Setup (LUKS) encryption passphrase derived from seeds provided during deployment. You can add a higher level of encryption protection and control to your data at rest by using your own key from Hyper Protect Crypto Services.\n\n\n\n How your data volume is encrypted \n\nWithout your own key, the data volume that you attach to your instance is encrypted automatically with two seeds that are provided in the workload - volumes and env - volumes sections of the contract. The seeds are internally converted to UTF8 sequences and then concatenated. The hash (SHA256) of the concatenated sequence is computed as a hexdigest, which is used as the LUKS passphrase to encrypt the data volume. For more information, see [About contract](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-contract_sehpcr_contract_volumes).\n\n\n\n\n\n Protecting your sensitive data with your own key \n\nStarting from ibm-hyper-protect-container-runtime-1-0-s390x-11, Hyper Protect Virtual Servers for VPC support integration with the key management service (KMS) Hyper Protect Crypto Services. Hyper Protect Crypto Services generates a random value as the third seed and wraps it with the CRK (customer root key). The wrapped seed is stored in the metadata partition of your data volume. The LUKS passphrase is generated by using three seeds - the seed in the metadata partition (unwrapped first) and the two seeds from the contract.\n\nBackground knowledge: From the HPCR image version ibm-hyper-protect-container-runtime-1-0-s390x-9, for new Hyper Protect Virtual Servers for VPC instances, the data volume is partitioned into two parts. The first partition (100 Mib) is reserved for internal metadata only (not to be accessed by a workload); the second partition remains as the data volume for workload. Only new volumes are partitioned.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-hyper-protect-virtual-server-mng-data"},{"document_id":"ibmcld_07578-963331-965355","score":11.1043696789,"text":"\nRestoring a volume from a snapshot creates an entirely new boot or data volume. The new volume has the same properties of the original volume, including encryption. If you restore from a bootable snapshot, you create a boot volume. Similarly, you can create a data volume from a snapshot of a data volume. The volume that you create from the snapshot uses the same volume profile and contains the same data and metadata as the original volume. You can restore a volume when you provision an instance, update an existing instance, or create a stand-alone volume by using the UI, CLI, or the volumes API. For more information, see [Restoring a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).\n\nFor best performance, you can enable snapshots for fast restore. By using the fast restore feature, you can create a volume from a snapshot that is fully provisioned when the volume is created. For more information, see [Snapshots fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\n\n\n I restored a Block Storage for VPC volume from a snapshot, and it's not performing at the expected levels. Is this normal? \n\nPerformance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones do not require hydration. The data is available as soon as the volume is created.\n\n\n\n* I restored a Block Storage for VPC volume from a snapshot, and it's not performing at the expected levels. Is this normal?\n\n I restored a Block Storage for VPC volume from a snapshot, and it's not performing at the expected levels. Is this normal? \n\nPerformance of boot and data volumes is initially degraded when data is restored from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-963207-965231","score":11.1043696789,"text":"\nRestoring a volume from a snapshot creates an entirely new boot or data volume. The new volume has the same properties of the original volume, including encryption. If you restore from a bootable snapshot, you create a boot volume. Similarly, you can create a data volume from a snapshot of a data volume. The volume that you create from the snapshot uses the same volume profile and contains the same data and metadata as the original volume. You can restore a volume when you provision an instance, update an existing instance, or create a stand-alone volume by using the UI, CLI, or the volumes API. For more information, see [Restoring a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).\n\nFor best performance, you can enable snapshots for fast restore. By using the fast restore feature, you can create a volume from a snapshot that is fully provisioned when the volume is created. For more information, see [Snapshots fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\n\n\n I restored a Block Storage for VPC volume from a snapshot, and it's not performing at the expected levels. Is this normal? \n\nPerformance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones do not require hydration. The data is available as soon as the volume is created.\n\n\n\n* I restored a Block Storage for VPC volume from a snapshot, and it's not performing at the expected levels. Is this normal?\n\n I restored a Block Storage for VPC volume from a snapshot, and it's not performing at the expected levels. Is this normal? \n\nPerformance of boot and data volumes is initially degraded when data is restored from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_15078-5749-7732","score":11.0396947281,"text":"\nBlock Storage for VPC data volumes can be attached to any available instance in your region, based on your customer account and permissions, and within [certain limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-attaching-block-storagevol-attach-limits). These volumes are detached by default when the instance is deleted. Detaching by default allows your data to persist beyond the virtual server instance lifecycle. It removes only the volume's association with the instance. You can delete data volumes manually after they are detached. Also, when you create data volumes, you can specify that they be [automatically deleted](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-block-storageauto-delete) when the instance is deleted.\n\nDetached volumes can be attached to an available, running instance without reprovisioning the volume or the instance.\n\nWhen you create and attach a data volume to a virtual server instance, you can later increase the size of that volume. You indicate capacity in GB increments up to 32,000 GB capacity, depending on your volume profile. For more information, see [expanding Block Storage for VPC volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes).\n\nData volumes are encrypted by default with IBM-managed encryption. You can also encrypt data volumes by using your own root keys.\n\n\n\n\n\n Block Storage for VPC IOPS profiles \n\nWhen you create a Block Storage for VPC volume in your availability zone, you can use 3 different tiered profiles with predefined IOPS levels and a custom profile with which you can define your own IOPS level based on the volume capacity. All profiles are backed by solid-state drives (SSDs).\n\nFor more information, see [Block Storage for VPC profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles)\n\n\n\n\n\n\n\n Block Storage for VPC encryption \n\nIBM Cloud takes the need for security seriously and understands the importance of being able to encrypt data to keep it safe.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about"},{"document_id":"ibmcld_15081-5775-7758","score":11.0396947281,"text":"\nBlock Storage for VPC data volumes can be attached to any available instance in your region, based on your customer account and permissions, and within [certain limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-attaching-block-storagevol-attach-limits). These volumes are detached by default when the instance is deleted. Detaching by default allows your data to persist beyond the virtual server instance lifecycle. It removes only the volume's association with the instance. You can delete data volumes manually after they are detached. Also, when you create data volumes, you can specify that they be [automatically deleted](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-block-storageauto-delete) when the instance is deleted.\n\nDetached volumes can be attached to an available, running instance without reprovisioning the volume or the instance.\n\nWhen you create and attach a data volume to a virtual server instance, you can later increase the size of that volume. You indicate capacity in GB increments up to 32,000 GB capacity, depending on your volume profile. For more information, see [expanding Block Storage for VPC volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes).\n\nData volumes are encrypted by default with IBM-managed encryption. You can also encrypt data volumes by using your own root keys.\n\n\n\n\n\n Block Storage for VPC IOPS profiles \n\nWhen you create a Block Storage for VPC volume in your availability zone, you can use 3 different tiered profiles with predefined IOPS levels and a custom profile with which you can define your own IOPS level based on the volume capacity. All profiles are backed by solid-state drives (SSDs).\n\nFor more information, see [Block Storage for VPC profiles](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-profiles)\n\n\n\n\n\n\n\n Block Storage for VPC encryption \n\nIBM Cloud takes the need for security seriously and understands the importance of being able to encrypt data to keep it safe.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about&interface=ui"},{"document_id":"ibmcld_11659-14972-16603","score":10.9911925555,"text":"\n\/dev\/mapper\/hana_vg-hana_shared_lv \/hana\/shared xfs defaults,inode64 0 0\n\/dev\/mapper\/hana_vg-hana_data_lv \/hana\/data xfs defaults,largeio,swalloc,inode64 0 0\n\n\n\n\n\n mx2-48x384 profile \n\nFor Virtual Server created based on the mx2-48x384 profile there are:\n\n\n\n* 3x 500 GB volumes; three block storage volumes of 500 GB size, with a custom volume profile that supports up to 10,000 Max IOPS attached to the Virtual Server is required\n* 4x 100 GB volumes; four block storage volumes of 100 GB size, with a custom volume profile that supports up to 6,000 Max IOPS attached to the Virtual Server is required\n* Optional: 1x 2,000 GB volume; one block storage volume of 2,000 GB size, with a lower 4,000 IOPS (medium performance) attached to the Virtual Server for backups\n\n\n\nAfter attaching the seven data volumes, seven new virtual disks will appear in the Virtual Server, see the table that follows. In this example, those disks are vdd, vde, vdf, vdg, vdh, vdi, vdj.\n\nThese three disks must be managed under the Linux\u00ae Logical Volume Manager (LVM), and deployed as logical volumes. In order to achieve that, first put the three devices under LVM control. For example, make them physical volumes:\n\n[root@hana384-vsi ] pvcreate \/dev\/vd[d,e,f,g,h,i,j]\n\nThen, two different volume groups need to be created:\n\n[root@hana384-vsi ] vgcreate hana_vg \/dev\/vdh \/dev\/vdi \/dev\/vdj\n[root@hana384-vsi ] vgcreate hana_log_vg \/dev\/vdd \/dev\/vde \/dev\/vdf \/dev\/vdg\n\nNext, three logical volumes need to be defined on top. These logical volumes reflect the file system size requirements for SAP HANA. The following commands are for a 384 GB virtual server:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-storage-design-considerations"},{"document_id":"ibmcld_15622-7-2004","score":10.9798897232,"text":"\nManaging volume count and capacity limits \n\nBlock Storage for VPC offers block-level data storage volumes that can be attached to an instance as either a boot volume or as a data volume. Answer the following questions when you're ordering block storage volumes or requesting an increase in your volume or capacity limits.\n\n\n\n Overview \n\nWith Block Storage for VPC, you can create up to 750 boot and data block storage volumes per account in a region. You can request an increase of this quota by contacting [IBM Support](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add) and submitting a support case.\n\nCapacity for secondary volumes ranges 10 - 16,000 GB. You can also expand volume capacity within its IOPS tier profile or custom band. For more information, see [expanding block storage volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes).\n\n\n\n\n\n Volume count and storage limits checklist \n\nReview the following checklist items and record your answers. Provide this information when you create a support case.\n\n\n\n* Ticket Subject: \"Request to Increase VPC Volume Count Limit\".\n* How many extra volumes do you need? Provide your account, region, and the zone where you want more volumes. For example, \"200 volumes in US South-2\".\n* How many volumes are primary boot volumes versus secondary data volumes? For example, \"50% primary volumes, 50% secondary volumes\" or \"100 primary volumes, 100 secondary volumes\".\n* Of the secondary volumes, how many secondary volumes do you need and of what capacity? For example, \"75% of the secondary volumes are under 250 GB and 25% are up to 16,000 GB.\n* How many total volumes use customer-managed encryption? For example, \"100 volumes (or 50%) are to use customer-managed encryption\".\n* Provide an estimate of when you expect or plan to provision all of the requested volumes. For example, \"I expect to create these volumes within 90 days\".\n* Provide a 90-day forecast of expected average capacity usage of these volumes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-storage-limit"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16464-4463-6317","score":19.2630091597,"text":"\nOn the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\n> Note: In a realistic scenario, you would create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16464-8477-10131","score":18.8835395097,"text":"\nLog in to Knowledge Studio as a user who is assigned to the annotation task that you created in [Lesson 3](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introwks_tutless_ml2).\n\n> Note: If you have access only to a single administrator ID for this tutorial, you can use that ID to perform human annotation. However, remember that in a realistic scenario, human annotation is performed by different users with the Human Annotator role.\n2. Open the My workspace workspace and click Machine Learning Model > Annotations.\n3. Click the Annotation Tasks tab, then open the Test annotation task you created in [Lesson 3](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introwks_tutless_ml2).\n4. Click Annotate for one of the assigned annotation sets.\n\nDepending on how you set up the annotation tasks, you could have one or more annotation tasks assigned to the user ID you logged in with.\n5. From the list of documents, find the Technology - gmanews.tv document and open it.\n\nNotice that the term IBM was already annotated with the ORGANIZATION entity type. This annotation was added by the dictionary pre-annotator that was applied in [Lesson 2](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introwks_tutless_ml3). This pre-annotation is correct, so it does not need to be modified.\n\n![This screen capture shows an open document with an existing pre-annotation for \"IBM\".](images\/wks_tut_preannotation.png \"This screen capture shows an open document with an existing pre-annotation for \"IBM\".\")\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16444-7-2064","score":18.67917702,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16563-8147-9811","score":18.4782628696,"text":"\nLog in to Knowledge Studio as a user who is assigned to the annotation task that you created in [Lesson 3](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introwks_tutless_ml2).\n\nIf you have access only to a single administrator ID for this tutorial, you can use that ID to perform human annotation. However, remember that in a realistic scenario, human annotation is performed by different users with the Human Annotator role.\n2. Open the My workspace workspace and click Machine Learning Model > Annotations.\n3. Click the Annotation Tasks tab, then open the Test annotation task you created in [Lesson 3](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introwks_tutless_ml2).\n4. Click Annotate for one of the assigned annotation sets.\n\nDepending on how you set up the annotation tasks, you could have one or more annotation tasks assigned to the user ID you logged in with.\n5. From the list of documents, find the Technology - gmanews.tv document and open it.\n\nNotice that the term IBM was already annotated with the ORGANIZATION entity type. This annotation was added by the dictionary pre-annotator that was applied in [Lesson 2](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introwks_tutless_ml3). This pre-annotation is correct, so it does not need to be modified.\n\n![This screen capture shows an open document with an existing pre-annotation for \"IBM\".](images\/wks_tut_preannotation.png \"This screen capture shows an open document with an existing pre-annotation for \"IBM\".\")\n6. Annotate a mention:\n\n\n\n1. Click the Entity tab.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16563-4292-6145","score":18.3368563072,"text":"\nSelect the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introtut_lessml1).\n6. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\nIn a realistic scenario, you create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3. Specify the details for the task:\n\n\n\n* In the Task name field, enter Test.\n* In the Deadline field, select a date in the future.\n\n\n\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16463-4148-5042","score":18.0832437204,"text":"\nAfter the pre-annotation is complete, create a human annotation task that includes the annotation set you created.\n\nFor more information about creating an annotation task, see [Annotation setup](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents).\n7. To view the annotations that were applied by the machine learning model to the new documents, open the annotation task.\n\nBecause the new documents were pre-annotated with the machine learning model, human annotation requires less time. For more information about adding annotations by human annotators, see [Annotating documents](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide).\n\n\n\n\n\n\n\n Results \n\nBy using your machine learning model to pre-annotate new document sets, you can expedite human annotation tasks for those documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutboot_intro"},{"document_id":"ibmcld_16444-1600-3658","score":18.0444660365,"text":"\nHuman annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16516-12409-14637","score":17.9205881803,"text":"\nAnnotation tasks Assets & Tools > Documents > Tasks Machine Learning Model > Annotation Tasks \n Coreferences tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Dictionaries page (management) Assets & Tools > Pre-annotators > Manage Dictionaries Assets \n Dictionaries tab (mapping to classes for rule-based model) Document Annotation Rule-based Model > Rules \n Documents page Assets & Tools Assets \n Entity Types page Assets & Tools Assets \n Mentions tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Performance page Model Management Machine Learning Model \n Pre-annotators page Assets & Tools Machine Learning Model > Pre-annotation \n Regex tab Document Annotation Rule-based Model > Rules \n Relation Types page Assets & Tools Assets \n Relations tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Rules tab Document Annotation Rule-based Model \n Tasks tab Assets & Tools > Documents Machine Learning Model > Annotation Tasks \n Versions page (machine learning model) Model Management Machine Learning Model \n Versions page (rule-based model) Model Management Rule-based Model \n\n\n\n\n\n\n\n\n\n May 2018 \n\n\n\n New features and changes \n\nConfiguration issue fixed\n: A configuration issue was fixed that caused service instances in Sydney region to not appear in US South region.\n\nDeploy Model window support changes\n: In the Deploy Model window, if the region you're deploying to supports both IBM Cloud\u00ae Identity and Access Management resource groups and Cloud Foundry spaces, to see the list, you will need to choose the method of access management that your service instance uses.\n\nData collection setting added\n: Added the data collection setting on the Service Details page. For more information about data collection, see [Troubleshooting, support, and FAQs](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-troubleshootingcontent)\n\nSupport for Chinese (Traditional)\n: Added Chinese (traditional) language support.\n\nAdministrators can see number of workspaces\n: Users who have the Admin role can now see the number of workspaces that are used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-release-notes"},{"document_id":"ibmcld_16444-4487-6387","score":17.7901277935,"text":"\nIf a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2. Click the Move up and Move down arrow** buttons to move pre-annotation methods earlier or later in the order.\n3. Click Save.\n4. Double check the Order column on the Pre-annotation page to make sure that it matches the order that you want.\n\n\n\n\n\n\n\n Run pre-annotators \n\n\n\n1. After your pre-annotation methods are prepared and you have configured the order of your pre-annotators, click Run Pre-annotators.\n2. Select the pre-annotators that you want to use, and then click Next.\n3. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries. The human annotator can change or remove the pre-annotated entity types and assign entity types to unannotated mentions. Pre-annotation by a dictionary does not annotate relations, coreferences. Relations and coreferences must be annotated by human annotators.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16507-1455-3632","score":17.7811754164,"text":"\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.234639363,"ndcg_cut_10":0.234639363}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16491-3401-4553","score":18.9510862644,"text":"\nBefore you upload documents that include ground truth into a new workspace, you must download the type system from the old workspace and upload it into the new workspace. The type system and documents must originate from the same Knowledge Studio workspace, and the type system must exist in the new workspace before you upload the ground truth annotations.\n\nTo upload documents, open the Document Sets tab in the new workspace, click Upload Document Sets and select the corpus ZIP file that you downloaded. Specify whether you want the uploaded documents to include or exclude the ground truth annotations before you click Upload. Only annotations that were promoted to ground truth before the documents were downloaded will be uploaded.\n\nRelated concepts:\n\n[Types of artifacts](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-artifacts)\n\n[Adding documents for annotation](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation)\n\n[Adding documents for defining rules](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_rule_anno_add)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-exportimport"},{"document_id":"ibmcld_16426-3401-4583","score":18.6997180245,"text":"\nBefore you upload documents that include ground truth into a new workspace, you must download the type system from the old workspace and upload it into the new workspace. The type system and documents must originate from the same Knowledge Studio workspace, and the type system must exist in the new workspace before you upload the ground truth annotations.\n\nTo upload documents, open the Document Sets tab in the new workspace, click Upload Document Sets and select the corpus ZIP file that you downloaded. Specify whether you want the uploaded documents to include or exclude the ground truth annotations before you click Upload. Only annotations that were promoted to ground truth before the documents were downloaded will be uploaded.\n\nRelated concepts:\n\n[Types of artifacts](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-artifacts)\n\n[Adding documents for annotation](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation)\n\n[Adding documents for defining rules](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_rule_anno_add)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-exportimport"},{"document_id":"ibmcld_16533-1638-3518","score":17.076963428,"text":"\n[Overview of the process to build a machine learning model](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks-ovw-anno.svg) Figure 1. Overview of the process to build a machine learning model\n\n\n\n1. Based on a set of domain-specific source documents, the team creates a type system that defines entity types and relation types for the information of interest to the application that will use the model.\n2. A group of two or more human annotators annotates a small set of source documents to label words that represent entity types, to identify relation types where the text identifies relationships between entity mentions, and to define coreferences, which identify different mentions that refer to the same thing, that is, the same entity. Any inconsistencies in annotation are resolved, and one set of optimally annotated documents is built, which forms the ground truth.\n3. Knowledge Studio uses the ground truth to train a model.\n4. The trained model is used to find entities, relations, and coreferences in new, never-seen-before documents.\n\n\n\nSee [Creating a machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-ml_annotator) for more details.\n\n\n\n\n\n Build a rule-based model \n\nKnowledge Studio provides a rules editor that simplifies the process of finding and capturing common patterns in your documents as rules. You can then create a model that recognizes the rule patterns, and deploy it for use in other services.\n\nSee [Creating a rule-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-rule-annotator) for more details.\n\n\n\n\n\n\n\n Analyze text with advanced rules \n\nThe advanced rules feature is Beta. The feature is in a trial stage of development and is not intended for use in production environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_overview_full"},{"document_id":"ibmcld_16487-7-2224","score":16.966451941,"text":"\nAdding documents for annotation \n\nTo train a machine learning model, you must add documents that contain subject matter knowledge, such as journal articles or other industry-specific texts, to your workspace.\n\n\n\n About this task \n\nThis section describes how to add documents for annotation only. To define rules for the rule-based model, you add or upload documents from which you can draw patterns to define as rules. See [Adding documents for defining rules](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_rule_anno_add) for more information.\n\n\n\n\n\n Documents \n\nTo train a machine learning model, you need to collect documents that are representative of your domain content and of high value to your application.\n\nTry to ensure that your training documents are truly representative of content that is of interest to your domain; that is, they contain many relevant mentions that can be annotated. To choose the best documents, follow these guidelines:\n\n\n\n* Strive to provide a set of documents that have a total size of about 300,000 words. Provide more words for a complex type system, and fewer for a simpler one.\n* Limit each document to a page or two of content (fewer than 2,000 words, and closer to 1,000 words per document is best). In the early stages of model development, keeping each document down to a few paragraphs is also a good practice. A human annotator can mark mentions and relations in a long document, but attempts to mark coreferences across multiple pages might prove unwieldy.\n* Ensure that the data in the documents is distributed across all possible entity types, subtypes, and roles, and the relationships between them. A goal to aim for is to eventually have at least 50 annotations for each entity type and 50 for each relation type in the document collection.\n* Again, documents should represent the breadth of the subject matter that the application will cover, but in the case of skewed frequency-of-occurrence of entity types and relation types, try to get at least 50 exemplars of each type, more for entity types that have mentions which tend to be phrases.\n* The set that you create for training must contain at least 10 annotated documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation"},{"document_id":"ibmcld_16458-1666-3574","score":16.9208271555,"text":"\n[Overview of the process to build a machine learning model](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks-ovw-anno.svg) Figure 1. Overview of the process to build a machine learning model\n\n\n\n1. Based on a set of domain-specific source documents, the team creates a type system that defines entity types and relation types for the information of interest to the application that will use the model.\n2. A group of two or more human annotators annotates a small set of source documents to label words that represent entity types, to identify relation types where the text identifies relationships between entity mentions, and to define coreferences, which identify different mentions that refer to the same thing, that is, the same entity. Any inconsistencies in annotation are resolved, and one set of optimally annotated documents is built, which forms the ground truth.\n3. Knowledge Studio uses the ground truth to train a model.\n4. The trained model is used to find entities, relations, and coreferences in new, never-seen-before documents.\n\n\n\nSee [Creating a machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-ml_annotator) for more details.\n\n\n\n\n\n Build a rule-based model \n\nKnowledge Studio provides a rules editor that simplifies the process of finding and capturing common patterns in your documents as rules. You can then create a model that recognizes the rule patterns, and deploy it for use in other services.\n\nSee [Creating a rule-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-rule-annotator) for more details.\n\n\n\n\n\n\n\n Analyze text with advanced rules \n\nThe advanced rules feature is Beta. The feature is in a trial stage of development and is not recommended for use in production environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_overview_full"},{"document_id":"ibmcld_16423-7-2234","score":16.9063388928,"text":"\nAdding documents for annotation \n\nTo train a machine learning model, you must add documents that contain subject matter knowledge, such as journal articles or other industry-specific texts, to your workspace.\n\n\n\n About this task \n\nThis section describes how to add documents for annotation only. To define rules for the rule-based model, you add or upload documents from which you can draw patterns to define as rules. See [Adding documents for defining rules](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_rule_anno_add) for more information.\n\n\n\n\n\n Documents \n\nTo train a machine learning model, you need to collect documents that are representative of your domain content and of high value to your application.\n\nTry to ensure that your training documents are truly representative of content that is of interest to your domain; that is, they contain many relevant mentions that can be annotated. To choose the best documents, follow these guidelines:\n\n\n\n* Strive to provide a set of documents that have a total size of about 300,000 words. Provide more words for a complex type system, and fewer for a simpler one.\n* Limit each document to a page or two of content (fewer than 2,000 words, and closer to 1,000 words per document is best). In the early stages of model development, keeping each document down to a few paragraphs is also a good practice. A human annotator can mark mentions and relations in a long document, but attempts to mark coreferences across multiple pages might prove unwieldy.\n* Ensure that the data in the documents is distributed across all possible entity types, subtypes, and roles, and the relationships between them. A goal to aim for is to eventually have at least 50 annotations for each entity type and 50 for each relation type in the document collection.\n* Again, documents should represent the breadth of the subject matter that the application will cover, but in the case of skewed frequency-of-occurrence of entity types and relation types, try to get at least 50 exemplars of each type, more for entity types that have mentions which tend to be phrases.\n* The set that you create for training must contain at least 10 annotated documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"},{"document_id":"ibmcld_16507-4382-6307","score":16.1659790869,"text":"\nConfiguring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson. If a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2. Click the Move up and Move down arrow** buttons to move pre-annotation methods earlier or later in the order.\n3. Click Save.\n4. Double check the Order column on the Pre-annotation page to make sure that it matches the order that you want.\n\n\n\n\n\n\n\n Run pre-annotators \n\n\n\n1. After your pre-annotation methods are prepared and you have configured the order of your pre-annotators, click Run Pre-annotators.\n2. Select the pre-annotators that you want to use, and then click Next.\n3. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with Natural Language Understanding \n\nYou can use the Natural Language Understanding service to pre-annotate documents that you add to your corpus.\n\n\n\n Before you begin \n\nDetermine whether the Natural Language Understanding pre-annotator is likely to add value for your use case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-4487-6387","score":16.1313987708,"text":"\nIf a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2. Click the Move up and Move down arrow** buttons to move pre-annotation methods earlier or later in the order.\n3. Click Save.\n4. Double check the Order column on the Pre-annotation page to make sure that it matches the order that you want.\n\n\n\n\n\n\n\n Run pre-annotators \n\n\n\n1. After your pre-annotation methods are prepared and you have configured the order of your pre-annotators, click Run Pre-annotators.\n2. Select the pre-annotators that you want to use, and then click Next.\n3. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries. The human annotator can change or remove the pre-annotated entity types and assign entity types to unannotated mentions. Pre-annotation by a dictionary does not annotate relations, coreferences. Relations and coreferences must be annotated by human annotators.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16507-13849-15752","score":16.0084249266,"text":"\nHowever, you can use the model to pre-annotate documents to help speed up the human annotation of subsequent documents. For example, if you add documents to the corpus after you train a machine learning model, you can use the model to pre-annotate the new document sets. Never run a pre-annotator on the same documents that have been annotated by a person. Pre-annotators remove human annotation.\n\n\n\n\n\n Procedure \n\nTo use an existing machine learning model to pre-annotate documents:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Go to the Machine Learning Model > Pre-annotation page.\n3. Click Run Pre-annotators.\n4. Select Machine Learning Model, and then click Next.\n5. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n6. Select the check box for each document set that you want to pre-annotate and click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets or annotation sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with the rule-based model \n\nYou can use an existing rule-based model to pre-annotate documents that you add to your corpus.\n\n\n\n Procedure \n\nTo use the rule-based model to pre-annotate documents, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Go to the Machine Learning Model > Pre-annotation page.\n3. Click the overflow menu button in the Rule-based Model row in the page, then click Map entity types and classes to map entity types that you defined in the Knowledge Studio type system to one or more rule-based model classes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16533-7-2114","score":15.8963123806,"text":"\nAbout \n\nUse IBM Watson\u00ae Knowledge Studio to create a machine learning model that understands the linguistic nuances, meaning, and relationships specific to your industry or to create a rule-based model that finds entities in documents based on rules that you define.\n\n\n\n Identify custom entities and relations \n\nAn entities and relations workspace enables you to create your own entity type system and train a custom model that can recognize custom entities in text. With machine learning models, you can also define custom relation types and train the model to recognize when two entities are related. Consider the following example sentence.\n\nABC Motors has received great reviews for its new 2020 Lightning.\n\nA custom entities and relations model could be trained to recognize \"2020 Lightning\" as a Vehicle entity, and \"ABC Motors\" as a Manufacturer entity. The model could also be trained to recognize that the two entities are connected by a isManufacturedBy relation.\n\n\n\n Build a machine learning model \n\nKnowledge Studio provides easy-to-use tools for annotating unstructured domain literature, and uses those annotations to create a custom machine learning model that understands the language of the domain. The accuracy of the model improves through iterative testing, ultimately resulting in an algorithm that can learn from the patterns that it sees and recognize those patterns in large collections of new documents. You can deploy the finished machine learning model to other Watson cloud-based offerings and cognitive solutions to find and extract mentions of relations and entities, including entity coreferences.\n\n![Overview of the process to build a machine learning model](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks-ovw-anno.svg) Figure 1. Overview of the process to build a machine learning model\n\n\n\n1. Based on a set of domain-specific source documents, the team creates a type system that defines entity types and relation types for the information of interest to the application that will use the model.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_overview_full"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11603-6477-8007","score":12.3563101837,"text":"\n<metric category=\"config\" context=\"host\" device-id=\"\" last-refresh=\"1607451781\" refresh-interval=\"0\" type=\"string\" unit=\"none\">\n<name>Virtualization Solution<\/name>\n<value>KVM<\/value>\n<\/metric>\n.\n.\n.\n<\/metrics>\n\n\n\nYou might experience a delay before your data is available.\n\n\n\n\n\n Troubleshooting \n\nUse the following troubleshooting tips for IMCS.\n\n\n\n Uninstalling the Metrics Collector \n\n\n\n1. Run the following command to uninstall IMCS if you have any issues during the installation process. Then, reinstall it.\n\n.\/uninstall-linux.sh\n\nRemoving IBM Metric Collector for SAP...\nSuccessfully removed IBM Metric Collector for SAP.\n\n\n\n\n\n\n\n No metrics reported when you run the curl command \n\nNo reported metrics message is often due to the port not assigned to SAP Metrics Collector. It needs port 18181 available for localhost. If you have any other applications that use the port, you must close the applications.\n\n\n\n1. Use the following command to see whether the port is assigned to another application.\n\nnmap -sT -O localhost\n\nStarting Nmap 6.40 (http:\/\/nmap.org) at (date and time)\nNmap scan report for localhost (your localhost address)\nHost is up (0.0s latency).\nOther addresses for localhost (not scanned): (localhost addresses)\nrDNS record for (localhost): sap-mc-redhat\nNot shown: (number of) closed ports\nPORT STATE SERVICE\n(port)\/tcp open ssh\n(port)\/tcp open smtp\nDevice type: general purpose\nRunning: Linux 3.X\nOS CPE: cpe:\/o:linux:linux_kernel:3\nOS details: Linux 3.7 3.9\nNetwork Distance: 0 hops\n\n\n\n\n\n\n\n nmap not found","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-ibm-metrics-collector-for-sap-linux"},{"document_id":"ibmcld_11603-7711-8687","score":12.0692781707,"text":"\nrDNS record for (localhost): sap-mc-redhat\nNot shown: (number of) closed ports\nPORT STATE SERVICE\n(port)\/tcp open ssh\n(port)\/tcp open smtp\nDevice type: general purpose\nRunning: Linux 3.X\nOS CPE: cpe:\/o:linux:linux_kernel:3\nOS details: Linux 3.7 3.9\nNetwork Distance: 0 hops\n\n\n\n\n\n\n\n nmap not found \n\nYou can install nmap on your system by using the appropriate package manager like yum or apt-get.\n\n* Command for Red Hat: yum install nmap\n* Command for SUSE: zypper install nmap\n\n\n\n\n\n\n\n Additional information \n\nIf you don't have an IBM Cloud API key, the IMCS can't collect all of the metrics that are required by SAP, which include\n\n* Network Adapter Mapping - replaced with local MAC ID.\n* Network Adapter Bandwidth - Port Speed - defaults to 0.\n* Disk Volume Mapping - replaced with Volume Attachment ID.\n* Disk Guaranteed IOPS - defaults to 0.\n\nYou must provide an API key so that all metrics can be collected. Otherwise, this virtual server is not fully supported by SAP.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-ibm-metrics-collector-for-sap-linux"},{"document_id":"ibmcld_09834-1423-2910","score":11.2961543244,"text":"\ncs [Computer system metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.cs.md) \n logical_disk [Disk metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.logical_disk.md) \n os [Operating System metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.os.md) \n system [System metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.system.md) \n net [Network interface metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.net.md) \n memory [Memory metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.memory.md) \n\n\n\nComplete the following steps to configure the Prometheus Windows exporter in your Windows system:\n\n\n\n1. Login to your Windows system, for example, you can connect via remote desktop (RDP).\n2. [Download the Prometheus windows_exporter](https:\/\/github.com\/martinlindhe\/wmi_exporter\/releases) appropriate for your environment.\n3. Identify the collectors that include data for the metric data that you want to collect.\n4. Change to the directory where you downloaded the Prometheus Windows exporter.\n5. Run the windows_exporter and configure the collectors that you want to enable. For example:\n\n.windows_exporter-0.16.0-amd64.exe --collectors.enabled <COLLECTORS>\n\nWhere <COLLECTORS> indicates the list of connectors that you want to configure.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-windows"},{"document_id":"ibmcld_09834-7-1796","score":11.1159812229,"text":"\nMonitoring a Windows environment \n\nThe standard monitoring agent cannot be installed on a Windows platform. In order to monitor a Windows system with IBM Cloud Monitoring, you can leverage the [Prometheus Windows Exporter](https:\/\/promcat.io\/apps\/windows) to perform the collection of the metrics on the system.\n\nOnce the metrics are collected you have two options for publishing the metrics, remotely scraping the metrics with a Linux monitoring agent,or pushing from a local instance of Prometheus using remote write. Step 3 will cover these two options, but step 1 and 2 are the same regardless of how the metrics are sent.\n\nComplete the following steps to configure the following Windows images to send metrics to a monitoring instance:\n\n\n\n* Windows Server 2019 Standard Edition (64 bit)\n* Windows Server 2016 Standard Edition (64 bit)\n\n\n\n\n\n Step 1: Configure the Prometheus Windows exporter \n\nConfigure the [Prometheus windows_exporter](https:\/\/github.com\/prometheus-community\/windows_exporter) to collect Windows system metrics.\n\nThe Prometheus Windows exporter runs as a Windows service. You configure the metrics that you want to monitor by enabling collectors.\n\nThe following collectors are supported:\n\n\n\nTable 1. Collectors\n\n Collector name Information about metrics collected per collector \n\n cpu [CPU metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.cpu.md) \n cs [Computer system metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.cs.md) \n logical_disk [Disk metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.logical_disk.md) \n os [Operating System metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.os.md)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-windows"},{"document_id":"ibmcld_09807-6204-7430","score":10.5612207376,"text":"\n!\/usr\/bin\/env python3\n\nimport os\nimport sys\nsys.path.insert(0, os.path.join(os.path.dirname(os.path.realpath(sys.argv[0])), '..'))\n\nfrom sdcclient import IbmAuthHelper, SdMonitorClient\n\n Parse arguments.\ndef usage():\nprint('usage: %s <ENDPOINT_URL> <MONITOR_TOKEN> <INSTANCE_GUID>' % sys.argv[0])\nprint('ENDPOINT_URL: IBM Cloud endpoint URL (e.g. https:\/\/us-south.monitoring.cloud.ibm.com')\nprint('MONITOR_TOKEN: token that is associated to a team.')\nsys.exit(1)\n\nif len(sys.argv) != 3:\nusage()\n\nURL = sys.argv[1]\nMONITOR_TOKEN = sys.argv[2]\n\n Instantiate the client\nsdclient = SdMonitorClient(token=MONITOR_TOKEN,sdc_url=URL)\nShow more\n\n\n\n\n\n References \n\n\n\n* [Extracting metrics from a Monitoring instance by using the Monitoring Python client](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-metrics_python)\n* [Managing dashboards by using the Monitoring Python client](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-dashboard_python)\n* [Managing alerts by using the Python client](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_python)\n* [Python Client](https:\/\/github.com\/draios\/python-sdc-client)\n* [Monitoring Python samples](https:\/\/github.com\/draios\/python-sdc-client\/tree\/master\/examples)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-python-client"},{"document_id":"ibmcld_09801-2595-4012","score":10.06532925,"text":"\ncpu [CPU metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.cpu.md) \n cs [Computer system metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.cs.md) \n logical_disk [Disk metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.logical_disk.md) \n os [Operating System metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.os.md) \n system [System metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.system.md) \n net [Network interface metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.net.md) \n memory [Memory metrics](https:\/\/github.com\/prometheus-community\/windows_exporter\/blob\/master\/docs\/collector.memory.md) \n\n\n\nTo learn how to configure the Windows exporter, see [Monitoring a Windows environment](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-windows).\n\nThe legacy Prometheus WMI Exporter is still supported, see [Monitoring a Windows environment using the legacy WMI Exporter](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-windows_wmi) for information on the WMI Exporter.\n\n\n\n\n\n IPMI exporter \n\nIn addition to the set of metrics that are automatically collected by the monitoring agent, you might want to collect other metrics such as sensor metrics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-prometheus-exporters"},{"document_id":"ibmcld_09735-6297-7536","score":9.5672959532,"text":"\nSYSDIG_TOKEN = sys.argv[2]\n\nDASHBOARD_NAME = 'My New Dashboard from Python'\nPANEL_NAME = 'CPU Over Time'\n\nsdclient = SdMonitorClient(token=SYSDIG_TOKEN,sdc_url=URL)\n\n Create an empty dashboard\nok, res = sdclient.create_dashboard(DASHBOARD_NAME)\n\n Check the result\ndashboard_name = None\nif ok:\nprint('Dashboard %d created successfully' % res['dashboard'])\ndashboard_name = res['dashboard']\nelse:\nprint(res)\nsys.exit(1)\n\n Add a time series panel\npanel_type = 'timeSeries'\nmetrics = [\n{'id': 'proc.name'},\n{'id': 'cpu.used.percent', 'aggregations': {'time': 'avg', 'group': 'avg'}}\n]\nok, res = sdclient.add_dashboard_panel(\ndashboard_name, PANEL_NAME, panel_type, metrics)\n\n Check the result\nif ok:\nprint('Panel added successfully')\ndashboard_name = res['dashboard']\nelse:\nprint(res)\nsys.exit(1)\nShow more\n\n\n\n\n\n Copy a dashboard \n\nYou can use Python to copy dashboards.\n\n\n\n Copy a custom dashboard in the default team \n\nThe following code shows the structure of a Python script to copy a custom dashboard to the default team.\n\n!\/usr\/bin\/env python3\n\nimport os\nimport sys\nsys.path.insert(0, os.path.join(os.path.dirname(os.path.realpath(sys.argv[0])), '..'))\nfrom sdcclient import IbmAuthHelper, SdMonitorClient\n\n Parse arguments.\ndef usage():","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-dashboard_python"},{"document_id":"ibmcld_09735-5372-6589","score":9.5595010794,"text":"\n{'id': 'cpu.used.percent', 'aggregations': {'time': 'avg', 'group': 'avg'}}\n]\nok, res = sdclient.add_dashboard_panel(\ndashboard_name, PANEL_NAME, panel_type, metrics)\n\n Check the result\nif ok:\nprint('Panel added successfully')\ndashboard_name = res['dashboard']\nelse:\nprint(res)\nsys.exit(1)\nShow more\n\n\n\n\n\n Create a dashboard in a team \n\nThe following code shows the structure of a Python script to create a dashboard for a specific team.\n\n!\/usr\/bin\/env python3\n\nimport os\nimport sys\nsys.path.insert(0, os.path.join(os.path.dirname(os.path.realpath(sys.argv[0])), '..'))\n\nfrom sdcclient import SdMonitorClient\n\n Parse arguments.\ndef usage():\nprint('usage: %s <endpoint-url> <sysdig_token>' % sys.argv[0])\nprint('endpoint-url: The endpoint URL that should point to IBM Cloud')\nprint('sysdig_token: Sysdig token for the team')\nsys.exit(1)\n\nif len(sys.argv) != 3:\nusage()\n\nURL = sys.argv[1]\n\n Set to the Sysdig token of the team\nSYSDIG_TOKEN = sys.argv[2]\n\nDASHBOARD_NAME = 'My New Dashboard from Python'\nPANEL_NAME = 'CPU Over Time'\n\nsdclient = SdMonitorClient(token=SYSDIG_TOKEN,sdc_url=URL)\n\n Create an empty dashboard\nok, res = sdclient.create_dashboard(DASHBOARD_NAME)\n\n Check the result\ndashboard_name = None\nif ok:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-dashboard_python"},{"document_id":"ibmcld_11633-23849-25162","score":9.5368645843,"text":"\nSee the latest installation guides and support notes from SAP for an up-to-date list of these prerequisites. Currently, the following extra packages are required for an SAP NetWeaver installation: - compat-sap-c++-7: Achieves compatibility of the C++ runtime with the compilers that are used by SAP - uuidd: Maintains OS support for the creation of UUIDs - csh: C shell support for the OS\n\n\n\n1. Follow [SAP note 2195019](https:\/\/launchpad.support.sap.com\/\/notes\/2195019) and install package compat-sap-c++-7. Create a specific soft-link, which is required by the SAP binary files.\n\n[root@sap-app-vsi ] yum install compat-sap-c++-7\n...\n\n[root@sap-app-vsi tmp] mkdir -p \/usr\/sap\/lib\n[root@sap-app-vsi tmp] ln -s \/opt\/rh\/SAP\/lib64\/compat-sap-c++-7.so \/usr\/sap\/lib\/libstdc++.so.6\n2. Check if uuid daemon (uuidd) is installed. If it\u2019s not, install and start it.\n\n[root@sap-app-vsi ] rpm -qa | grep uuidd\n[root@sap-app-vsi ] yum install uuidd\n[root@sap-app-vsi ] systemctl enable uuidd\n[root@sap-app-vsi ] systemctl start uuidd\n3. Install the tcsh package required for C shell support\n\n[root@sap-app-vsi ] yum install tcsh\n\n\n\n\n\n\n\n Installing the IBM Cloud Metrics Collector for SAP \n\nSAP requires the installation of the IBM Cloud Metrics Collector for SAP to analyze your infrastructure if a support case is submitted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-quickstudy-vs-gen2-netweaver-rhel"},{"document_id":"ibmcld_00208-31543-33509","score":9.3625975805,"text":"\nEach storage node has multiple paths to its own Solid-State Drives and its partner node's SSDs as well. This configuration protects against path failure, and also controller failure because the node can still access its partner's disks seamlessly. For more information, see [Availability and Durability of Block Storage for Classic](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-storageavailability).\n\n\n\n\n\n How can I identify a Block Storage for Classic volume from my OS? \n\nVarious reasons exist for why you would want to look up the LUN ID of the attached storage volumes on the Compute host. For example, you might have multiple storage devices that are mounted on the same host with the same volume sizes. You want to detach and decommission one of them. However, you are not sure how to correlate what you see on your Linux\u00ae host with what you see in the console. Another example might be that you have multiple Block Storage for Classic volumes that are attached to an esxi server. You want to expand the volume size of one of the LUNs, and you need to know the correct LUN ID of the storage to do that. For OS-specific instructions, click one of the following links.\n\n\n\n* [Viewing LUN information in Linux\u00ae](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-identifyLUNidentifyLUNLin)\n* [Viewing LUN information in Windows\u00ae](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-identifyLUNidentifyLUNWin)\n* [Viewing LUN information in VMWare\u00ae](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-identifyLUNidentifyLUNVMware)\n\n\n\n\n\n\n\n Can I get storage performance metrics (IOPS or latency) from the Support teams? \n\nIBM Cloud\u00ae does not provide storage performance IOPS and latency metrics. Customers are expected to monitor their own Block Storage for Classic devices by using their choice of third-party monitoring tools.\n\nThe following examples are utilities that you might consider to use to check performance statistics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-block-storage-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09061-4-1966","score":9.3480529967,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09120-94597-96242","score":9.3397685255,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08988-95785-97389","score":9.3383511797,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_04488-93746-95375","score":9.3324969525,"text":"\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_01019-7-2103","score":9.3096269078,"text":"\nDeleting a database \n\nWhen a service instance is deleted, the database that it provides is also removed. This will delete any online data and logs as well as database backups. The data will not be recoverable after this action.\n\n\n\n How is the data deleted \n\nAll data is encrypted at rest to ensure data is protected at all times using encryption keys stored in a key management service called Key Protect. When access to those keys is removed, the data is crypto-shredded and cannot be recovered. When the service instance is deleted, the block storage that is used for the database is wiped to ensure that all of the data is erased. Any data objects in cloud object storage are also deleted and not recoverable.\n\n\n\n\n\n When is the data deleted \n\n\n\n\n\n Using your own encryption keys to delete data \n\nYou can use your own encryption keys to delete data. This is called crypto-shredding. After the key is deleted, your data is unrecoverable and unreadable by anyone.\n\nKey Protect allows you to initiate a force delete of a key that is in use by various IBM Cloud\u00ae services, including your Db2 on Cloud service instances. Deleting a key that is in use on your deployment locks the disks containing your data when the key is requested again. You can have this occur right away by contacting IBM Support or by deleting your service instance. Key deletion is sent to the Log Analysis Activity Tracker as kms.secrets.delete.\n\nIf you delete a deployment that is protected with your Key Protect key, the deployment remains registered against the key for the duration of the soft-deletion period (up to 9 days). If you need to delete the key during the soft-deletion period, you have to force delete the key. After the soft-deletion period, the key can be deleted without the force. You can check the association between the key and your deployment to determine when you can delete the key.\n\n\n\n\n\n Deleting data in your database \n\nThe Db2 database stores data in pages on block storage. When DELETE or TRUNCATE operations are performed, that data is no longer accessible unless you are using TEMPORAL tables.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-del_db"},{"document_id":"ibmcld_09055-22025-23534","score":9.2860169281,"text":"\ncorrelation_id='cbc0d18b-a816-45ab-af6a-b8e18dc3e628',\nmsg='Conflict: 1 prior authorization(s) are required for deletion: Key could not be deleted. Please see \"reasons\" for more details.',\nreasons='[AUTHORIZATIONS_NOT_MET: Number of authorizations required to delete is not met -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\n\n\n\n\n\n\n\n Required parameters \n\n-d, --disable\nor\n-e, --enable\n: Disable or enable the dual authorization policy. One option is required.\n\n\n\n\n\n\n\n kp key cancel-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-twokp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_09120-29325-30645","score":9.2683225251,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08988-30080-31503","score":9.2651047137,"text":"\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_09055-69659-70937","score":9.2625574789,"text":"\nUser 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-twokp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_08987-28071-29358","score":9.261164682,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-pluginkp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-4-1684","score":20.7937332383,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-4-1966","score":20.1936162334,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-1255-3053","score":19.9476930615,"text":"\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-2799-4588","score":19.2866093255,"text":"\n[Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.\n6. From the options menu, click Schedule key deletion and review the key's associated resources.\n7. Click the Next button, enter the key name, and click Schedule deletion.\n8. Contact another user to complete the deletion of the key.\n\n\n\nThe other user must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n\n\n Purging a key that holds dual authorization in the console \n\nFour hours after the other user with a Manager access policy has authorized the key for deletion, it can be purged by one of the users as long as they hold [the KeyPurge attribute](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grant-access-keysgrant-access-keys-specific-functions).\n\nThis can be done by clicking the \u22ef icon to open a list of options for the key that you want to purge and then clicking Purge. If you cannot delete the key, make sure it has been at least four hours since the key was authorized for deleting by another user and that you hold the KeyPurge attribute.\n\n\n\n\n\n Authorize deletion for a key with the API \n\n[After you enable dual authorization for an instance or key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\/actions\/setKeyForDeletion\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08776-2908-4519","score":19.2038801314,"text":"\nDual authorization enabled The status of a dual authorization policy on the key.<br><br><br><br> * True: Dual authorization is required to delete the key.<br> * False: No prior authorization is required to delete the key.<br><br><br> \n Set for deletion Indicates whether a delete authorization is issued for a key.<br><br><br><br> * True: An authorization to delete this key is issued by the first user. A second user with a Manager access policy can safely delete the key.<br> * False: The key is not set for deletion. No further action is needed.<br><br><br> \n Deletion expiration The date that an authorization for deletion expires for the key. If this date passes, the authorization is no longer valid. If False is the value for the Dual authorization enabled or Set for deletion column of the key, the Deletion expiration column is left empty. \n\n\n\nNot all key characteristics are displayed by default. To customize how the Keys table is to be presented, click the Settings icon![Settings icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/settings.svg) and check the columns to be displayed.\n\nNot seeing the full list of keys that are stored in your service instance? Verify with your administrator that you are assigned the correct role for the applicable service instance or individual key. For more information about roles, see [Roles and permissions](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessroles).\n\nYou can also search for a specific key by using the search bar, or filter keys based on your needs by clicking the Filter icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-keys"},{"document_id":"ibmcld_09055-48796-50259","score":19.1261541435,"text":"\n\"updatedBy\": \"user id ...<redacted>...\",\n\"rotation\": {\n\"interval_month\": 2\n}\n}\n]\n\n\n\n\n\n Required parameters \n\nKEY_ID\n: The ID of the key that you want to query. To retrieve a list of your available keys, run the [kp keys](#kp-keys) command.\n\n\n\n\n\n Optional parameters \n\n-d, --dual-auth\n: Show policies that have a dual-auth-delete policy.\n\n\n\n\n\n\n\n kp key policy-update dual-auth-delete \n\nYou can use Key Protect to safely delete encryption keys by using a dual authorization process. When you delete a key, you shred its contents and associated data. Any data that is encrypted by the key becomes inaccessible.\n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) requires an authorization from two users. With the Key Protect API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the [GUI](https:\/\/cloud.ibm.com\/login\/) or [API](https:\/\/cloud.ibm.com\/apidocs\/key-protect) to delete the key.\n\nibmcloud kp key policy-update dual-auth-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n-e, --enable\n[-o, --output OUTPUT]\n\n\n\n Example \n\nThis example enables the dual authorization delete policy.\n\n create a root key\n$ KEY_ID=$(ibmcloud kp key create my-root-key --output json | jq -r '.[\"id\"]')\n\n$ echo $KEY_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_09061-1334-3188","score":19.1243529976,"text":"\nWhen the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted. When you delete a key, it is \"soft deleted\", meaning that the key and its associated data will be restorable up to 30 days after deletion. You are able to still retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically [purged](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-key-purge), or hard deleted, and its associated data will be permanently removed from the Key Protect service.\n\n\n\n\n\n\n\n Authorize deletion for a key in the console \n\n[After you enable dual authorization for an instance or key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by using the Key Protect IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-6176-7874","score":18.9284726508,"text":"\n<br> <br>For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br>For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) by using the Key Protect GUI or API.\n\nIf you need to prevent the deletion of a key that's already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<keyID_or_alias>\/actions\/unsetKeyForDeletion.\n\n\n\n Delete the key \n\nAfter you set a key for deletion, another user with a Manager access policy can safely delete the key by using the Key Protect GUI or API.\n\nKey Protect sets a seven-day authorization period that starts after you provide the first authorization to delete the key. During this seven-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) and all key operations are allowed on the key. If no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-4752-6201","score":18.8484124016,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08987-65731-67061","score":18.8454298742,"text":"\nYou can use Key Protect to safely delete encryption keys by using a dual authorization process. When you delete a key, you shred its contents and associated data. Any data that is encrypted by the key becomes inaccessible.\n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) requires an authorization from two users. With the Key Protect API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the [GUI](https:\/\/cloud.ibm.com\/login\/) or [API](https:\/\/cloud.ibm.com\/apidocs\/key-protect) to delete the key.\n\nibmcloud kp key policy-update dual-auth-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n-e, --enable\n[--key-ring KEY_RING_ID]\n[-o, --output OUTPUT]\n\n\n\n Example \n\nThis example enables the dual authorization delete policy.\n\n create a root key\n$ KEY_ID=$(ibmcloud kp key create my-root-key --output json | jq -r '.[\"id\"]')\n\n$ echo $KEY_ID\n\nd887bfe8-5166-4dad-af32-7e3055ca1873\n\n show key details\n$ ibmcloud kp key show $KEY_ID --output json\n\n{\n\"id\": \"d887bfe8-5166-4dad-af32-7e3055ca1873\",\n\"name\": \"my-root-key\",\n\"type\": \"application\/vnd.ibm.kms.key+json\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.2,"recall_5":0.2,"recall_10":0.4,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.1695801026,"ndcg_cut_10":0.2826335044}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-6973-8664","score":22.2884630632,"text":"\nYour IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the cURL request. For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Hyper Protect Crypto Services instance. For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) by using the IBM Cloud console or key management service API.\n\nIf you need to prevent the deletion of a key that is already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion.\n\n\n\n\n\n\n\n Step 2. Delete the key \n\nAfter you set a key for deletion, a second user with a Manager access policy can safely delete the key.\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-3634-5079","score":22.2267222799,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-1255-3053","score":19.5092698177,"text":"\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-8253-9823","score":18.5106784186,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-4-1684","score":18.29881882,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-4752-6201","score":17.7805837608,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_11726-1653-3309","score":17.3687250409,"text":"\n: No, you don't need to re-create the Location. You can reconnect the existing Location and reauthenticate to continue working with your Location.\n\nHow do I reauthenticate?\n: Reconnect your Location first and then log in again with your credentials.\n\nDo I have to recover etcd backup?\n: No, you don't need to recover etcd backup. The Location recovers automatically after you reconnect it and reauthenticate.\n\nWhat happens if a location is disconnected for more than 7 days?\n: After restoring connection, you might need to replace all hosts across the location with new infrastructure.\n\nHow do I know when to reconnect a location?\n: You can make a note or set a reminder to reconnect the location before the 7-day window expires. The timer starts when you request the token.\n\n\n\n\n\n Setting the disconnected usage time \n\nSatellite Locations and Red Hat OpenShift on IBM Cloud can run disconnected from the parent managed-from region in IBM Cloud for up to 168 hours (7 days).\n\nYou can modify this setting by changing the accessTokenMaxAgeSeconds value for all your OAuth clients. The default value for accessTokenMaxAgeSeconds is 86400 seconds.\n\nThe accessTokenMaxAgeSeconds value starts counting when the user was last authenticated, not when the Location is disconnected. Note that a user must have access to IAM to authenticate.\n\n\n\n1. Get your OAuth clients by running oc get oauthclients.\n\nExample output\n\nNAME SECRET WWW-CHALLENGE TOKEN-MAX-AGE REDIRECT URIS\nconsole OBXIvSxQx2t5ANYe5-xAEylpsbdytupjyjJicScdFsE false default https:\/\/console-openshift-console.sl-disc2b-be7d0adc45c89a3b4c1f8e7bc127f800-0000.eu-de.containers.appdomain.cloud\/auth\/callback","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-disconnected-use"},{"document_id":"ibmcld_02745-2771-4521","score":16.6842849206,"text":"\n\"http:\/\/my-first-app.com\/after_logout\",\n\"http:\/\/my-second-app.com\/after_logout\"\n]\n}\n\n\n\nTable 1. SSO configuration settings\n\n Setting Definition \n\n isActive To enable SSO, set this value to true. The default setting is false. \n inactivityTimeoutSeconds The longest length of time that can pass without any user activity before the user is required to reenter their credentials. This value is specified in seconds and can be a maximum of 604800 seconds (7 days). The default setting is 86400 seconds (1 day). \n logoutRedirectUris A comma-separated list of allowed URIs that App ID can redirect your users to after they sign out. \n\n\n\n\n\n\n\n\n\n Configuring logout \n\nWith App ID, you can end a user's SSO session for their current browser. If the API endpoint is accessed by the user's browser, their session is terminated and the user is prompted to enter their credentials on their next sign-in attempt in that browser - for any of your apps.\n\nWhen one of the flows that are related to changing, resetting, or renewing a password is started, the sessions across all clients are automatically terminated for the user.\n\n\n\n By using the API \n\nTo sign out a user, redirect their browser by using your information to complete the following API call.\n\nhttps:\/\/<region>.appid.cloud.ibm.com\/oauth\/v4\/<tenantID>\/cloud_directory\/sso\/logout?redirect_uri=<redirectURI>&client_id=<clientID>\n\n\n\nTable 2. SSO sign-out API call variables\n\n Variable Value \n\n region The region in which your instance of App ID is provisioned. Learn more about the [available regions](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-regions-endpoints). \n tenantID The unique identifier for your instance of App ID. You can find this value in the Service Credentials tab of the App ID dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-sso"},{"document_id":"ibmcld_13880-15220-16805","score":15.2758886743,"text":"\nFirst display the bindings then delete them by Service Bindings Names (FIRST and SECOND below are from the get output)\n\nibmcloud ce application get --name ghstats-app\n\nibmcloud ce application unbind --name ghstats-app --binding ghstats-app-ce-service-binding-FIRST\n\nibmcloud ce application unbind --name ghstats-app --binding ghstats-app-ce-service-binding-SECOND\n2. Delete the project and its components.\n\nibmcloud ce project delete --name ghstats --hard -f\n3. Delete the services:\n\nibmcloud resource service-instance-delete -f ghstatsDB\n\nibmcloud resource service-instance-delete -f ghstatsAppID\n4. Delete the Container Registry namespace\n\nibmcloud cr namespace-rm $NAMESPACE -f\n5. Delete the [Github.com token](https:\/\/github.com\/settings\/tokens)\n\n\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-resource-reclamation).\n\n\n\n\n\n Expand the tutorial \n\nWant to add to or change this tutorial? Here are some ideas:\n\n\n\n* Expand the app for multi-tenant support.\n* Use social identity providers.\n* Add a date picker to the statistics page to filter displayed data.\n* Use a custom login page for App ID.\n\n\n\n\n\n\n\n Related Content \n\nHere are links to additional information on the topics covered in this tutorial. The app itself is available in this [GitHub repository](https:\/\/github.com\/IBM-Cloud\/github-traffic-stats).\n\nDocumentation:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-serverless-github-traffic-analytics"},{"document_id":"ibmcld_04591-3226-4632","score":15.2230056969,"text":"\nWhen I order \"Base Flex Plan\", it says each authorized user entitled for one VM, what if user needs to provision more than one VM? \n\nApplications Lab Base Flex Plan (a.k.a. per authorized user plan) allows maximum one reservation at a time. If you want to have multiple reservations at the same time, please use other plans or use mutiple accounts.\n\n\n\n\n\n What happens when I delete my service instance? \n\nThe service instance will not appear on Resource List and billing of the instance stops from next month. IBM Cloud retains the service instance for 7 days and in case you need to restore the same instance back, please raise a support ticket for \"IBM Cloud for Education\" in 7 days upon deleting instance from IBM Cloud UI. After 7 days, the service instance will be deleted permanently and can no longer be restored.\n\n\n\n\n\n Can't submit block allocation request? \n\nPlease make sure that \"First Date of Usage\" is later than the current time. The time zone by default is UTC.\n\n\n\n\n\n Which model of GPU cards are installed on the servers? \n\nNvidia V100 is used. Customers cannot access GPU directly, and can only access virtual GPU virtualized from V100.\n\n\n\n\n\n Do you support Operating Systems not shown in the image library, like Ubuntu 20 etc? \n\nYes. We are able to support the most popular Operating Systems in the market, please submit a ticket or click on the help to send us the configuration detail.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-for-education?topic=cloud-for-education-faq"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.5,"recall_10":0.75,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.414429925,"ndcg_cut_10":0.5534861045}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08211-2628-3483","score":22.8177409683,"text":"\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period. If a server is restored, the timeframe for which the server was within the resource reclamations is billed to your account.\n\nAfter the server is deleted, only metadata, which isn't considered to be personal data is kept for 6 months. Make sure you back up important data for future use because you can't recover data after the virtual server has been deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_08211-1158-3123","score":21.7939303093,"text":"\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_09087-65885-67524","score":16.5667382792,"text":"\nUsing the CLI, create an import token, allow it to expire, then attempt to retrieve it.\n\n create an import token that expires in 5 minutes (300 seconds) and allows 2 retrievals\n$ ibmcloud kp import-token create -e 300 -m 2\n\nCreated Expires Max Retrievals Remaining Retrievals\n2020-08-18 19:39:06 +0000 UTC 2020-08-18 19:44:06 +0000 UTC 2 2\n\n sleep 300 seconds, which allows the import token to expire\n$ sleep 300\n\n show the import token\n$ ibmcloud kp import-token show\n\nFAILED\nkp.Error:\ncorrelation_id='fb677c6e-9bfa-422e-a14b-0e221bbad32b',\nmsg='Conflict:\nImport Token could not be retrieved.\nPlease see reasons for more details.',\nreasons='[IMPORT_TOKEN_EXPIRED_ERR:\nThe import token has expired. -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/apidocs\/key-protect]'\nShow more\n\n\n\n\n\n\n\n\n\n 24 - The key cannot be deleted because it's... \n\n\n\n Message \n\nThe key cannot be deleted because it's protecting a cloud resource that has a retention policy: Before you delete this key, contact an account owner to remove the retention policy on each resource that is associated with the key\n\nReason code: PREV_KEY_DEL_ERR\n\n\n\n\n\n HTTP status code \n\n409 - Conflict\n\nThe HTTP 409 Conflict response status code indicates a request conflict with current state of the server.\n\nConflicts are most likely to occur in response to a PUT request. For example, you may get a 409 response when uploading a file which is older than the one already on the server resulting in a version control conflict.\n\n\n\n\n\n Context \n\nThis error occurs when a key, used for \"Registrations\", is deleted.\n\nIn most cases, a key with registrations can be deleted using the --force option.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_00324-15719-17878","score":15.6905917162,"text":"\nThat content is then cached for the TTL duration specified for the content. If a user request is received after the TTL has expired, the Edge server reaches out to the origin host to fetch the content. If the origin server cannot be reached for some reason (for instance, the origin host is down, or there is a network issue), the Edge server serves the expired (stale) content to the request. This feature is supported by Akamai and cannot be turned off.\n\n\n\n\n\n Support for multiple origins with distinct paths \n\nIn certain cases, you might want to deliver certain content from a different origin server. For example, you might want certain photos or videos that are served from different origin servers. IBM Cloud CDN provides the option to set up multiple origin servers with multiple paths. This allows flexibility with regards to how and where the data is stored.\n\nThe path that is specified for the origin server must be unique regarding the CDN. The origin server itself does not need to be unique.\n\n\n\n\n\n Time to Live (TTL) \n\nTime to Live indicates the amount of time (in seconds) the Edge server retains the cached content for that particular file or directory path. When a CDN is first created, a global TTL is created for path \/* with a default time of 3600 seconds. The minimum value for TTL is 0 seconds, and the maximum value is 2147483647 seconds. For each entry, the TTL path must be unique for the CDN. If multiple paths match a given content, the most recently configured path match applies to that content. For example, consider two TTLs, \/example\/file created first with a time to live value of 3000 seconds and \/example\/* is created later, with a value of 4000 seconds. Although \/example\/file is more specific, \/example\/ was created most recently, so the TTL for \/example\/file is 4000 seconds. After creation, TTL entries can be edited for path, time, or both. TTL entries can also be deleted.\n\n\n\n\n\n Token authentication \n\nToken authentication is the process of generating tokens, associating them with an authenticated user session, and validating the request by using these tokens to prevent unauthorized sharing of links to your content.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-about-content-delivery-networks-cdn-"},{"document_id":"ibmcld_08217-1687-3909","score":15.5467966804,"text":"\nWhen you click the 'Inactive' server in Name field, an error message is displayed to indicate that provisioning has failed.\n\n What\u2019s happening \n\nYou try to create more than five virtual servers within a short period in one data center without any existing virtual server instances.\n\n Why it\u2019s happening \n\nThe number of virtual servers per data center is limited to five. Creating more than five virtual servers almost all at the same time in one data center leads to the status 'Inactive' (provisioning failed) for the sixth and all subsequent instances.\n\n How to fix it \n\nYou can either provision more than five virtual servers in different data centers. Or you can provision more than five instances by using different IBM Cloud accounts.\n\n\n\n\n\n Generating a new virtual server fails because of exhausted resources \n\nYou can only create a limited number of virtual server instances in each data center.\n\n What\u2019s happening \n\nWhen you provision a new virtual server, you get an error message because the resources (for example, memory) are exhausted.\n\n Why it\u2019s happening \n\nThe resources for the selected data center are exhausted.\n\n How to fix it \n\nRetry the action and select a different data center.\n\n\n\n\n\n Can't connect to free virtual server anymore \n\nI can't connect to a server (for example, via SSH), which is in the free plan although it's visible in the IBM Cloud resource list.\n\n What\u2019s happening \n\nYou can't connect to a server in the free plan anymore. The server is still visible in the resource list, but the dashboard shows an error message. The message indicates that the server has expired. When a server expires, the server and all data that is stored on the server are deleted.\n\n Why it\u2019s happening \n\nAll virtual servers in free plans are deleted after 30 days.\n\n How to fix it \n\nVirtual servers in paid plans aren't deleted. You can remove the server from the resource list by deleting it from the resource list.\n\n\n\n\n\n Can't create new virtual servers because of exhausted resources or plan limitations \n\nYou can't create new virtual servers because of exhausted resources or plan limitations, although you've less than the described limits.\n\n What\u2019s happening \n\nYou try to create a new server but fail.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-troubleshooting"},{"document_id":"ibmcld_04537-3875-4793","score":14.9523128923,"text":"\nThe four files are: certificate file, certificate signing request file, intermediate certificate file, and private key file.\n\n\n\n\n\n ibmcloud sl security cert-list \n\nList SSL certificates on your account:\n\nibmcloud sl security cert-list [OPTIONS]\n\nCommand options:\n\n--status\n: Show certificates with this status, default is: all, options are: all,valid,expired.\n\n--sortby\n: Column to sort by. Options are: id,common_name,days_until_expire,note.\n\nExamples:\n\nibmcloud sl security cert-list --status valid --sortby days_until_expire\n\nThis command lists all valid certificates on current account and sort them by validity days.\n\n\n\n\n\n ibmcloud sl security cert-remove \n\nRemove SSL certificate:\n\nibmcloud sl security cert-remove IDENTIFIER [OPTIONS]\n\nCommand options:\n\n-f, --force\n: Force operation without confirmation.\n\nExamples:\n\nibmcloud sl security cert-remove 12345678\n\nThis command removes certificate with ID 12345678.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sl-manage-security-keys"},{"document_id":"ibmcld_06178-0-1673","score":14.7590522685,"text":"\n\n\n\n\n\n\n  Why does the Ingress status show an ESSEF error? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\n  What\u2019s happening \n\nWhen you check the status of your cluster's Ingress components by running the ibmcloud ks ingress status-report get command, you see an error similar to the following example.\n\nThe Opaque secret field expired or will expire soon (ESSEF).\n\n  Why it\u2019s happening \n\nYou have secrets in your cluster that have fields which are either expired or are about to expire in the next 5 days.\n\n  How to fix it \n\nReview the secrets in your cluster and update or remove them.\n\n\n\n1.  List your secrets.\n\nibmcloud ks ingress secret ls\n2.  Complete the steps depending on whether the secret fields are still needed or not. If the expiring secret field in the secret is still needed, ensure the corresponding secret in the IBM Cloud Secrets Manager instance has been updated and has a new expiry date. Then, update the secret field with the new values from IBM Cloud Secrets Manager by running the following command.\n\nTo view all the secrets in your IBM Cloud Secrets Manager instance, see [Accessing Secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-access-secrets&interface=uiget-secret-value-ui).\n\nibmcloud ks ingress secret update\n3.  If the secret in the secret field is expiring because it is no longer needed, run the ibmcloud ks ingress secret field rm command to remove it.\n4.  If the issue persists, contact support. Open a [support case](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar). In the case details, be sure to include any relevant log files, error messages, or command outputs.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-ingress-essef"},{"document_id":"ibmcld_10610-0-1673","score":14.7590522685,"text":"\n\n\n\n\n\n\n  Why does the Ingress status show an ESSEF error? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\n  What\u2019s happening \n\nWhen you check the status of your cluster's Ingress components by running the ibmcloud oc ingress status-report get command, you see an error similar to the following example.\n\nThe Opaque secret field expired or will expire soon (ESSEF).\n\n  Why it\u2019s happening \n\nYou have secrets in your cluster that have fields which are either expired or are about to expire in the next 5 days.\n\n  How to fix it \n\nReview the secrets in your cluster and update or remove them.\n\n\n\n1.  List your secrets.\n\nibmcloud oc ingress secret ls\n2.  Complete the steps depending on whether the secret fields are still needed or not. If the expiring secret field in the secret is still needed, ensure the corresponding secret in the IBM Cloud Secrets Manager instance has been updated and has a new expiry date. Then, update the secret field with the new values from IBM Cloud Secrets Manager by running the following command.\n\nTo view all the secrets in your IBM Cloud Secrets Manager instance, see [Accessing Secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-access-secrets&interface=uiget-secret-value-ui).\n\nibmcloud oc ingress secret update\n3.  If the secret in the secret field is expiring because it is no longer needed, run the ibmcloud oc ingress secret field rm command to remove it.\n4.  If the issue persists, contact support. Open a [support case](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar). In the case details, be sure to include any relevant log files, error messages, or command outputs.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-ingress-essef"},{"document_id":"ibmcld_13104-7-2031","score":14.2447911571,"text":"\nRetrieving information about a virtual server \n\nAfter you create a virtual server instance by using the Hyper Protect Virtual Servers service, you can view detailed information about your new instance.\n\nThe Ubuntu servers are preconfigured in such a way that the passwords expire after 90 days. After the user password expires, you have 30 days to change your password. If you don't change your password within the 30 days, your account becomes inactive and it is no longer possible to log in with SSH even if you are using SSH-keys. For more information, see [Protecting a virtual server](https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-protect_vs).\n\n\n\n Retrieving information in the UI \n\n\n\n1. To select the Hyper Protect Virtual Servers resource, either:\n\n\n\n* Go to the [Resource list](https:\/\/cloud.ibm.com\/resources), then look for your virtual server instance under the Services entry in the Name column.\n* From the IBM Cloud dashboard or the IBM Cloud Navigation Menu, select View all within the Resource summary area to open the Resource list. The column Location displays the data center where your instance was created. Use the filter to search for virtual server instances in certain regions or data centers. See also Figure 2 from [Provisioning a virtual server](https:\/\/cloud.ibm.com\/docs\/services\/hp-virtual-servers?topic=hp-virtual-servers-provision).\n\n\n\n2. Click your virtual server instance to open the Hyper Protect Virtual Servers dashboard.\n\n\n\nIn this dashboard:\n\n\n\n* The Locate map shows you in which region your instance was created.\n* You can find the public IP address, which you use to connect to the virtual server.\n\n\n\nYou must use the internal IP address when you connect to a virtual server from another virtual server, which is in the same virtual LAN (VLAN). VLANs span across all data centers within their region.\n\nYou must also work with the internal IP addresses, when you connect to other IBM Cloud Cloud services that are located within the same data center.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/hp-virtual-servers?topic=hp-virtual-servers-retrieve-info-vs"},{"document_id":"ibmcld_10007-1574-3749","score":13.9521817111,"text":"\nPassword expiration Specifies when a user password expires. \n Created on Specifies when the user was created. \n Authentication type Specifies the authentication type. \n\n\n\n\n\n\n\n User actions \n\nIn the users list view, there is an overflow menu that lists the actions that can be taken on the user.\n\n\n\nTable 1. The table lists user actions and their definitions.\n\n Value Description \n\n Assign owner Set the owner of the user account. \n Change password Change the password for the system user. \n Account expiration Set a date that the system user account will be valid until. \n Password expiration Set a number of days until the password for the user account expires. \n Rename Change the username of the user account. \n Admin privileges View and grant admin privileges. \n Object privileges View and grant object privileges. \n Remove Delete the user account from the system. \n\n\n\n\n\n\n\n Granting admin privileges to users \n\nUser privileges dictate what actions can be taken by a particular user account. When new users are created, they have no privileges, so in most cases privileges need to be added.\n\n\n\n1. Go to Users and groups > Users.\n2. Select the user for which you want to grant admin privileges and select Admin privileges from the overflow menu.\nIn this view, you can see different admin privileges, which are already granted or that can be granted to the selected user.\nGranting these privileges allows the user to do the actions that the privileges correspond to. Granting privileges on global database and global schema unlocks all the privileges to the user equivalent to an admin.\n3. Click Edit.\n4. Update, grant, or revoke object privileges by putting ticks in corresponding boxes.\n5. Click Save.\n\n\n\n\n\n\n\n Granting object privileges to users \n\nUser privileges dictate what actions can be taken by a particular user account. When new users are created, they have no privileges, so in most cases privileges need to be added.\n\n\n\n1. Go to Users and groups > Users.\n2. Select the user for which you want to grant object privileges and select Object privileges from the overflow menu.\n3. Select a database.\nYou can choose between the Global database and a specific database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-users-groups"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-4-1684","score":10.3055030679,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-4-1966","score":10.2018436813,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-1334-3188","score":10.1609869117,"text":"\nWhen the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted. When you delete a key, it is \"soft deleted\", meaning that the key and its associated data will be restorable up to 30 days after deletion. You are able to still retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically [purged](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-key-purge), or hard deleted, and its associated data will be permanently removed from the Key Protect service.\n\n\n\n\n\n\n\n Authorize deletion for a key in the console \n\n[After you enable dual authorization for an instance or key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by using the Key Protect IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-1255-3053","score":10.1220272796,"text":"\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08695-1371-3050","score":10.1185263166,"text":"\n* To resolve the error that is reported in error message 1, [review the resources](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy. You can verify whether a key is associated with a nonerasable resource by [checking the registration details](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-protected-resourcesview-protected-resources-api) for the key. Then, you must contact an account owner to remove the retention policy on each resource that is associated with the key before you can delete the key.\n\nIf you don't need the resources that are associated with the key any more, you can also first delete the associated resources and then delete the key.\n* To resolve the error that is reported in error message 2, you need to assign two approvers to delete a key if you enable the dual authorization policy [for your instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy).\n\nThe first approver must have a Writer or Manager role to first schedule the key deletion and the second approver must have a Manager role to complete the deletion within 7 days. For more information, see [Deleting keys by using dual authorization](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"},{"document_id":"ibmcld_08435-3634-5079","score":10.0737595069,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-6176-7874","score":10.0148743443,"text":"\n<br> <br>For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br>For more information, see [Retrieving an instance ID](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) by using the Key Protect GUI or API.\n\nIf you need to prevent the deletion of a key that's already authorized for deletion, you can remove the existing authorization by calling POST \/api\/v2\/keys\/<keyID_or_alias>\/actions\/unsetKeyForDeletion.\n\n\n\n Delete the key \n\nAfter you set a key for deletion, another user with a Manager access policy can safely delete the key by using the Key Protect GUI or API.\n\nKey Protect sets a seven-day authorization period that starts after you provide the first authorization to delete the key. During this seven-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) and all key operations are allowed on the key. If no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09149-1514-3367","score":10.0102667305,"text":"\nDeactivated and Suspended keys have not been deleted, and still count as non-deleted versions. For more information about key states, check out [Key states and transitions](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-stateskey-transitions).\n\n\n\n Pricing scenarios \n\n\n\n* Scenario: You have one non-deleted key that has been rotated 19 times, which means it has 20 total versions.\n\n\n\n* Pricing: Your charge is USD15.675 per month (the first five key versions are free).\n\n\n\n* Scenario: You have one non-deleted key that has been rotated four times, meaning the key has five total versions.\n\n\n\n* Pricing: Your charge is USD0 per month.\n\n\n\n* Scenario: You have one non-deleted key with 20 total versions, another key with three versions, and a key in the Suspended state with two versions.\n\n\n\n* Pricing: Your charge is USD20.9 per month.\n\n\n\n\n\nYou are charged for all versions of all non-deleted keys that exist in your instances during the billing period (minus the five free key versions). This includes keys you create (or import) and delete before the month is over. If for example you create and delete a key the same day, you are charged USD1.045 that month for the key (if you have more than five key versions in your instances). However, you will not be charged the following month for that key if it remains deleted. If you restore the key at any point, you will be charged for all of the versions of that key for that month. For more information about deleting keys, check out [About deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keys).\n\n\n\n\n\n How many key versions do you have? \n\nTo see how many versions you have of each key you have deployed:\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-pricing-plan"},{"document_id":"ibmcld_09055-48796-50259","score":9.9493446965,"text":"\n\"updatedBy\": \"user id ...<redacted>...\",\n\"rotation\": {\n\"interval_month\": 2\n}\n}\n]\n\n\n\n\n\n Required parameters \n\nKEY_ID\n: The ID of the key that you want to query. To retrieve a list of your available keys, run the [kp keys](#kp-keys) command.\n\n\n\n\n\n Optional parameters \n\n-d, --dual-auth\n: Show policies that have a dual-auth-delete policy.\n\n\n\n\n\n\n\n kp key policy-update dual-auth-delete \n\nYou can use Key Protect to safely delete encryption keys by using a dual authorization process. When you delete a key, you shred its contents and associated data. Any data that is encrypted by the key becomes inaccessible.\n\nDeleting a key that has a [dual authorization policy](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) requires an authorization from two users. With the Key Protect API, you can provide the first authorization by [setting the key for deletion](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the [GUI](https:\/\/cloud.ibm.com\/login\/) or [API](https:\/\/cloud.ibm.com\/apidocs\/key-protect) to delete the key.\n\nibmcloud kp key policy-update dual-auth-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n-e, --enable\n[-o, --output OUTPUT]\n\n\n\n Example \n\nThis example enables the dual authorization delete policy.\n\n create a root key\n$ KEY_ID=$(ibmcloud kp key create my-root-key --output json | jq -r '.[\"id\"]')\n\n$ echo $KEY_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_08441-4-1794","score":9.9223761587,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting internal keystores \n\nYou can delete internal keystores in Unified Key Orchestrator with the IBM Cloud\u00ae console, or programmatically with the Unified Key Orchestrator API. After you delete an internal keystore, all the managed keys are deactivated in this keystore\uff0c and associated resources are detached.\n\nTo delete an internal keystore, [delete all activated keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-managed-keys) in this keystore first. The key metadata remains in the keystore for 90 days before it gets removed automatically. You can delete the keystore only after the key metadata gets removed. If you want to delete the keystore immediately, [manually remove all key metadata using the KMS API](https:\/\/cloud.ibm.com\/apidocs\/hs-cryptopurgekey) in 4 hours after you destroy the key. Make sure that you have the KMS Key Purge role assigned. For more information about roles, see [Managing user access](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-uko-manage-access).\n\n\n\n Deleting internal keystores with the IBM Cloud console \n\nTo delete an internal keystore by using the console, complete the following steps:\n\n\n\n1. [Log in to the Hyper Protect Crypto Services instance](https:\/\/cloud.ibm.com\/login).\n2. Click Target keystores from the navigation to view all the available keystores.\n3. Click the keystore that you want to delete. The side panel is displayed.\n4. Click Delete to delete the keystore and all the metadata.\n5. Click Delete keystore to confirm the deletion.\n\n\n\nThe internal keystore has been deleted with all the managed keys deactivated in this keystore and associated resources detached.\n\n\n\n\n\n Deleting internal keystores with the API \n\nTo delete an internal keystore through the API, follow these steps:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-internal-keystores"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.195190025,"ndcg_cut_10":0.195190025}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09055-35815-37068","score":16.1857484212,"text":"\n\"creationDate\": \"2020-06-15T20:36:46Z\"\n}\n}\n]\n\n delete the authorization policy between COS AND KMS - this breaks everything\n$ ibmcloud iam authorization-policy-delete $COS_KMS_AUTHORIZATION --force\n\n delete the KP root key - this fails because the registration was not deleted\n$ ibmcloud kp key delete $MY_COS_KEY_ID\n\nDeleting key: 52a9d772-8982-4620-bfb4-b070dd812a0c, from instance: b0d84b32-09d0-4314-8049-da78e3b9ab6f...\nFAILED\nkp.Error:\ncorrelation_id='c27b7948-4a1f-4cbd-8770-cb3616888e27',\nmsg='Conflict: Key could not be deleted. Please see \"reasons\" for more details.',\nreasons='[PROTECTED_RESOURCE_ERR: Key is protecting one or more cloud resources -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshootingunable-to-delete-keys]'\n\n delete the KP root key; use --force because the registration between COS and KMS still exists\n$ ibmcloud kp key delete $MY_COS_KEY_ID --force --output json\n\n{\n\"id\": \"52a9d772-8982-4620-bfb4-b070dd812a0c\"\n}\n\n delete the KMS instance\n$ ibmcloud resource service-instance-delete $KMS_NAME --force\n\n delete the COS instance\n$ ibmcloud resource service-instance-delete $COS_NAME --force\n\n view resources (COS and KMS should no longer exist)\n$ ibmcloud resource service-instances","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_08988-50073-51234","score":16.1324720709,"text":"\n\"keyVersion\": { \"id\": \"52a9d772-8982-4620-bfb4-b070dd812a0c\", \"creationDate\": \"2020-06-15T20:36:46Z\"\n}\n}\n]\n\n delete the authorization policy between COS AND KMS - this breaks everything\n$ ibmcloud iam authorization-policy-delete $COS_KMS_AUTHORIZATION --force\n\n delete the KP root key - this fails because the registration was not deleted\n$ ibmcloud kp key delete $MY_COS_KEY_ID\n\nDeleting key: 52a9d772-8982-4620-bfb4-b070dd812a0c, from instance: b0d84b32-09d0-4314-8049-da78e3b9ab6f...\nFAILED\nkp.Error:\ncorrelation_id='c27b7948-4a1f-4cbd-8770-cb3616888e27',\nmsg='Conflict: Key could not be deleted. Please see \"reasons\" for more details.',\nreasons='[PROTECTED_RESOURCE_ERR: Key is protecting one or more cloud resources -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshootingunable-to-delete-keys]'\n\n delete the KP root key; use --force because the registration between COS and KMS still exists\n$ ibmcloud kp key delete $MY_COS_KEY_ID --force --output json\n\n{\n\"id\": \"52a9d772-8982-4620-bfb4-b070dd812a0c\"\n}\n\n delete the KMS instance\n$ ibmcloud resource service-instance-delete $KMS_NAME --force\n\n delete the COS instance","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_08695-1371-3050","score":15.8210992492,"text":"\n* To resolve the error that is reported in error message 1, [review the resources](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy. You can verify whether a key is associated with a nonerasable resource by [checking the registration details](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-protected-resourcesview-protected-resources-api) for the key. Then, you must contact an account owner to remove the retention policy on each resource that is associated with the key before you can delete the key.\n\nIf you don't need the resources that are associated with the key any more, you can also first delete the associated resources and then delete the key.\n* To resolve the error that is reported in error message 2, you need to assign two approvers to delete a key if you enable the dual authorization policy [for your instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy).\n\nThe first approver must have a Writer or Manager role to first schedule the key deletion and the second approver must have a Manager role to complete the deletion within 7 days. For more information, see [Deleting keys by using dual authorization](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"},{"document_id":"ibmcld_09120-144494-145843","score":15.456962853,"text":"\n$ ibmcloud cos put-object --bucket $COS_BUCKET --key '\/cos-file.txt' --body cos-file-upload.txt\n\n delete the authorization policy between COS AND KMS - this breaks everything\n$ ibmcloud iam authorization-policy-delete $COS_KMS_AUTHORIZATION --force\n\n get the object from COS - this fails because COS no longer has access to KMS\n$ ibmcloud cos get-object --bucket $COS_BUCKET --key '\/cos-file.txt' cos-file-download.txt\n\nFAILED\nServiceNotAuthorized: The specified COS Service Instance does not have sufficient\npermissions to access the resource provided in the ibm-sse-kp-customer-root-key-crn request header\nstatus code: 401,\nrequest id: a51e1da3-9bf7-4cc9-9eb0-0d074c7f9093,\nhost id:\n\n delete the object\n$ ibmcloud cos delete-object --bucket $COS_BUCKET --key '\/cos-file.txt' --force\n\n delete the bucket\n$ ibmcloud cos delete-bucket --bucket $COS_BUCKET --force\n\n delete the KP root key - this fails because the registration was not deleted\n$ ibmcloud kp key delete $MY_COS_KEY_ID --output json\n\nFAILED\nkp.Error:\ncorrelation_id='fffdd8a9-405a-4a91-a5a7-52c30d11424d',\nmsg='Conflict: Key could not be deleted. Please see \"reasons\" for more details.',\nreasons='[PROTECTED_RESOURCE_ERR: Key is protecting one or more cloud resources -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshootingunable-to-delete-keys]'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_04488-142426-143775","score":15.456962853,"text":"\n$ ibmcloud cos put-object --bucket $COS_BUCKET --key '\/cos-file.txt' --body cos-file-upload.txt\n\n delete the authorization policy between COS AND KMS - this breaks everything\n$ ibmcloud iam authorization-policy-delete $COS_KMS_AUTHORIZATION --force\n\n get the object from COS - this fails because COS no longer has access to KMS\n$ ibmcloud cos get-object --bucket $COS_BUCKET --key '\/cos-file.txt' cos-file-download.txt\n\nFAILED\nServiceNotAuthorized: The specified COS Service Instance does not have sufficient\npermissions to access the resource provided in the ibm-sse-kp-customer-root-key-crn request header\nstatus code: 401,\nrequest id: a51e1da3-9bf7-4cc9-9eb0-0d074c7f9093,\nhost id:\n\n delete the object\n$ ibmcloud cos delete-object --bucket $COS_BUCKET --key '\/cos-file.txt' --force\n\n delete the bucket\n$ ibmcloud cos delete-bucket --bucket $COS_BUCKET --force\n\n delete the KP root key - this fails because the registration was not deleted\n$ ibmcloud kp key delete $MY_COS_KEY_ID --output json\n\nFAILED\nkp.Error:\ncorrelation_id='fffdd8a9-405a-4a91-a5a7-52c30d11424d',\nmsg='Conflict: Key could not be deleted. Please see \"reasons\" for more details.',\nreasons='[PROTECTED_RESOURCE_ERR: Key is protecting one or more cloud resources -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshootingunable-to-delete-keys]'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_08988-145748-147097","score":15.456962853,"text":"\n$ ibmcloud cos put-object --bucket $COS_BUCKET --key '\/cos-file.txt' --body cos-file-upload.txt\n\n delete the authorization policy between COS AND KMS - this breaks everything\n$ ibmcloud iam authorization-policy-delete $COS_KMS_AUTHORIZATION --force\n\n get the object from COS - this fails because COS no longer has access to KMS\n$ ibmcloud cos get-object --bucket $COS_BUCKET --key '\/cos-file.txt' cos-file-download.txt\n\nFAILED\nServiceNotAuthorized: The specified COS Service Instance does not have sufficient\npermissions to access the resource provided in the ibm-sse-kp-customer-root-key-crn request header\nstatus code: 401,\nrequest id: a51e1da3-9bf7-4cc9-9eb0-0d074c7f9093,\nhost id:\n\n delete the object\n$ ibmcloud cos delete-object --bucket $COS_BUCKET --key '\/cos-file.txt' --force\n\n delete the bucket\n$ ibmcloud cos delete-bucket --bucket $COS_BUCKET --force\n\n delete the KP root key - this fails because the registration was not deleted\n$ ibmcloud kp key delete $MY_COS_KEY_ID --output json\n\nFAILED\nkp.Error:\ncorrelation_id='fffdd8a9-405a-4a91-a5a7-52c30d11424d',\nmsg='Conflict: Key could not be deleted. Please see \"reasons\" for more details.',\nreasons='[PROTECTED_RESOURCE_ERR: Key is protecting one or more cloud resources -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshootingunable-to-delete-keys]'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_08987-142613-143962","score":15.456962853,"text":"\n$ ibmcloud cos put-object --bucket $COS_BUCKET --key '\/cos-file.txt' --body cos-file-upload.txt\n\n delete the authorization policy between COS AND KMS - this breaks everything\n$ ibmcloud iam authorization-policy-delete $COS_KMS_AUTHORIZATION --force\n\n get the object from COS - this fails because COS no longer has access to KMS\n$ ibmcloud cos get-object --bucket $COS_BUCKET --key '\/cos-file.txt' cos-file-download.txt\n\nFAILED\nServiceNotAuthorized: The specified COS Service Instance does not have sufficient\npermissions to access the resource provided in the ibm-sse-kp-customer-root-key-crn request header\nstatus code: 401,\nrequest id: a51e1da3-9bf7-4cc9-9eb0-0d074c7f9093,\nhost id:\n\n delete the object\n$ ibmcloud cos delete-object --bucket $COS_BUCKET --key '\/cos-file.txt' --force\n\n delete the bucket\n$ ibmcloud cos delete-bucket --bucket $COS_BUCKET --force\n\n delete the KP root key - this fails because the registration was not deleted\n$ ibmcloud kp key delete $MY_COS_KEY_ID --output json\n\nFAILED\nkp.Error:\ncorrelation_id='fffdd8a9-405a-4a91-a5a7-52c30d11424d',\nmsg='Conflict: Key could not be deleted. Please see \"reasons\" for more details.',\nreasons='[PROTECTED_RESOURCE_ERR: Key is protecting one or more cloud resources -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshootingunable-to-delete-keys]'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"},{"document_id":"ibmcld_07578-1211120-1213024","score":15.3716817374,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1213753-1215657","score":15.3716817374,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_09055-106313-107675","score":15.1980197035,"text":"\nmust be done in the console user interface (UI) because\n there is no API or CLI support at this time\n\n capture the name of the COS bucket that was created\n$ COS_BUCKET=my-cos-kms-bucket\n\n upload an object to COS\n$ ibmcloud cos put-object --bucket $COS_BUCKET --key '\/cos-file.txt' --body cos-file-upload.txt\n\n delete the authorization policy between COS AND KMS - this breaks everything\n$ ibmcloud iam authorization-policy-delete $COS_KMS_AUTHORIZATION --force\n\n get the object from COS - this fails because COS no longer has access to KMS\n$ ibmcloud cos get-object --bucket $COS_BUCKET --key '\/cos-file.txt' cos-file-download.txt\n\nFAILED\nServiceNotAuthorized: The specified COS Service Instance does not have sufficient\npermissions to access the resource provided in the ibm-sse-kp-customer-root-key-crn request header\nstatus code: 401,\nrequest id: a51e1da3-9bf7-4cc9-9eb0-0d074c7f9093,\nhost id:\n\n delete the object\n$ ibmcloud cos delete-object --bucket $COS_BUCKET --key '\/cos-file.txt' --force\n\n delete the bucket\n$ ibmcloud cos delete-bucket --bucket $COS_BUCKET --force\n\n delete the KP root key - this fails because the registration was not deleted\n$ ibmcloud kp key delete $MY_COS_KEY_ID --output json\n\nFAILED\nkp.Error:\ncorrelation_id='fffdd8a9-405a-4a91-a5a7-52c30d11424d',\nmsg='Conflict: Key could not be deleted. Please see \"reasons\" for more details.',","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01034-3831-4923","score":24.1062856373,"text":"\nAfter the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-hpcs"},{"document_id":"ibmcld_06381-1376-2975","score":23.7191110955,"text":"\nDeleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"},{"document_id":"ibmcld_06341-2428-3641","score":23.6686248131,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"},{"document_id":"ibmcld_06499-2416-3629","score":23.6686248131,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"},{"document_id":"ibmcld_06443-2410-3623","score":23.6686248131,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-deprovisioning"},{"document_id":"ibmcld_06627-2422-3635","score":23.6686248131,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"},{"document_id":"ibmcld_06696-2412-3625","score":23.6686248131,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-deprovisioning"},{"document_id":"ibmcld_09551-1435-3087","score":23.5798530181,"text":"\nList of service instances on the Resource List\n\n\n\n\n\n Deleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"},{"document_id":"ibmcld_06564-1431-3083","score":23.5798530181,"text":"\nList of service instances on the Resource List\n\n\n\n\n\n Deleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https:\/\/dev.mysql.com\/doc\/refman\/5.7\/en\/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-deprovisioning"},{"document_id":"ibmcld_09559-3849-5260","score":23.3110493128,"text":"\nIf you delete a deployment that is protected with an HPCS key, the deployment remains registered against the key during the soft-deletion period (up to 9 days). If you need to delete the key in the soft-deletion period, you must [force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) the key. After the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-hpcs"}],"retriever_scores":{"recall_1":0.1666666667,"recall_3":0.1666666667,"recall_5":0.5,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6164336326,"ndcg_cut_10":0.6508562437}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06370-5041-6727","score":23.5523194763,"text":"\nRabbitMQ Major versions are the first two numbers in a major.x.patch version number. v3.11, TBD Backup taken and access removed \n MySQL** Major versions are the first two numbers in a major.x.patch version number. v5.7, TBD Backup taken and access removed \n\n\n\nIBM Cloud\u00ae Databases for DataStax is deprecated and no longer supported as of 30 June 2024. For more information, see the [deprecation details](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-deprecationdep_details).\n\n**For more information, see [MySQL 8 GA](https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-mysql8-ga).\n\nAny actions taken after a database EOL date happen over several days after the EOL date. We try, but cannot guarantee, to make these upgrades outside of business hours in the local regions. If you want more control over the upgrade process of your database instance, we recommend that you upgrade following our [backup and restore process](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups) before the EOL date of your database version.\n\n\n\n\n\n Major versioning End of Life \n\nYou receive multiple notifications when a major version reaches its End of life. You can typically expect:\n\n\n\n* A blog post, for example: [Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/messages-for-rabbitmq-38-end-of-life-in-july-2022)\n* An announcement in your service's Release Notes, for example: [IBM Cloud\u00ae Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-rabbitmq-relnotesmessages-for-rabbitmq-25jan2022)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-versioning-policy"},{"document_id":"ibmcld_06397-5041-6727","score":23.5523194763,"text":"\nRabbitMQ Major versions are the first two numbers in a major.x.patch version number. v3.11, TBD Backup taken and access removed \n MySQL** Major versions are the first two numbers in a major.x.patch version number. v5.7, TBD Backup taken and access removed \n\n\n\nIBM Cloud\u00ae Databases for DataStax is deprecated and no longer supported as of 30 June 2024. For more information, see the [deprecation details](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-deprecationdep_details).\n\n**For more information, see [MySQL 8 GA](https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-mysql8-ga).\n\nAny actions taken after a database EOL date happen over several days after the EOL date. We try, but cannot guarantee, to make these upgrades outside of business hours in the local regions. If you want more control over the upgrade process of your database instance, we recommend that you upgrade following our [backup and restore process](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups) before the EOL date of your database version.\n\n\n\n\n\n Major versioning End of Life \n\nYou receive multiple notifications when a major version reaches its End of life. You can typically expect:\n\n\n\n* A blog post, for example: [Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/messages-for-rabbitmq-38-end-of-life-in-july-2022)\n* An announcement in your service's Release Notes, for example: [IBM Cloud\u00ae Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-rabbitmq-relnotesmessages-for-rabbitmq-25jan2022)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-versioning-policy"},{"document_id":"ibmcld_06674-5041-6727","score":23.5523194763,"text":"\nRabbitMQ Major versions are the first two numbers in a major.x.patch version number. v3.11, TBD Backup taken and access removed \n MySQL** Major versions are the first two numbers in a major.x.patch version number. v5.7, TBD Backup taken and access removed \n\n\n\nIBM Cloud\u00ae Databases for DataStax is deprecated and no longer supported as of 30 June 2024. For more information, see the [deprecation details](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-deprecationdep_details).\n\n**For more information, see [MySQL 8 GA](https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-mysql8-ga).\n\nAny actions taken after a database EOL date happen over several days after the EOL date. We try, but cannot guarantee, to make these upgrades outside of business hours in the local regions. If you want more control over the upgrade process of your database instance, we recommend that you upgrade following our [backup and restore process](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups) before the EOL date of your database version.\n\n\n\n\n\n Major versioning End of Life \n\nYou receive multiple notifications when a major version reaches its End of life. You can typically expect:\n\n\n\n* A blog post, for example: [Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/messages-for-rabbitmq-38-end-of-life-in-july-2022)\n* An announcement in your service's Release Notes, for example: [IBM Cloud\u00ae Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-rabbitmq-relnotesmessages-for-rabbitmq-25jan2022)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-versioning-policy"},{"document_id":"ibmcld_06606-5041-6727","score":23.5523194763,"text":"\nRabbitMQ Major versions are the first two numbers in a major.x.patch version number. v3.11, TBD Backup taken and access removed \n MySQL** Major versions are the first two numbers in a major.x.patch version number. v5.7, TBD Backup taken and access removed \n\n\n\nIBM Cloud\u00ae Databases for DataStax is deprecated and no longer supported as of 30 June 2024. For more information, see the [deprecation details](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-deprecationdep_details).\n\n**For more information, see [MySQL 8 GA](https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-mysql8-ga).\n\nAny actions taken after a database EOL date happen over several days after the EOL date. We try, but cannot guarantee, to make these upgrades outside of business hours in the local regions. If you want more control over the upgrade process of your database instance, we recommend that you upgrade following our [backup and restore process](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups) before the EOL date of your database version.\n\n\n\n\n\n Major versioning End of Life \n\nYou receive multiple notifications when a major version reaches its End of life. You can typically expect:\n\n\n\n* A blog post, for example: [Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/messages-for-rabbitmq-38-end-of-life-in-july-2022)\n* An announcement in your service's Release Notes, for example: [IBM Cloud\u00ae Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-rabbitmq-relnotesmessages-for-rabbitmq-25jan2022)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-versioning-policy"},{"document_id":"ibmcld_06539-5041-6727","score":23.5523194763,"text":"\nRabbitMQ Major versions are the first two numbers in a major.x.patch version number. v3.11, TBD Backup taken and access removed \n MySQL** Major versions are the first two numbers in a major.x.patch version number. v5.7, TBD Backup taken and access removed \n\n\n\nIBM Cloud\u00ae Databases for DataStax is deprecated and no longer supported as of 30 June 2024. For more information, see the [deprecation details](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-deprecationdep_details).\n\n**For more information, see [MySQL 8 GA](https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-mysql8-ga).\n\nAny actions taken after a database EOL date happen over several days after the EOL date. We try, but cannot guarantee, to make these upgrades outside of business hours in the local regions. If you want more control over the upgrade process of your database instance, we recommend that you upgrade following our [backup and restore process](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups) before the EOL date of your database version.\n\n\n\n\n\n Major versioning End of Life \n\nYou receive multiple notifications when a major version reaches its End of life. You can typically expect:\n\n\n\n* A blog post, for example: [Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/messages-for-rabbitmq-38-end-of-life-in-july-2022)\n* An announcement in your service's Release Notes, for example: [IBM Cloud\u00ae Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-rabbitmq-relnotesmessages-for-rabbitmq-25jan2022)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-versioning-policy"},{"document_id":"ibmcld_04584-5041-6727","score":23.5523194763,"text":"\nRabbitMQ Major versions are the first two numbers in a major.x.patch version number. v3.11, TBD Backup taken and access removed \n MySQL** Major versions are the first two numbers in a major.x.patch version number. v5.7, TBD Backup taken and access removed \n\n\n\nIBM Cloud\u00ae Databases for DataStax is deprecated and no longer supported as of 30 June 2024. For more information, see the [deprecation details](https:\/\/cloud.ibm.com\/docs\/databases-for-cassandra?topic=databases-for-cassandra-deprecationdep_details).\n\n**For more information, see [MySQL 8 GA](https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-mysql8-ga).\n\nAny actions taken after a database EOL date happen over several days after the EOL date. We try, but cannot guarantee, to make these upgrades outside of business hours in the local regions. If you want more control over the upgrade process of your database instance, we recommend that you upgrade following our [backup and restore process](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups) before the EOL date of your database version.\n\n\n\n\n\n Major versioning End of Life \n\nYou receive multiple notifications when a major version reaches its End of life. You can typically expect:\n\n\n\n* A blog post, for example: [Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/messages-for-rabbitmq-38-end-of-life-in-july-2022)\n* An announcement in your service's Release Notes, for example: [IBM Cloud\u00ae Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-rabbitmq-relnotesmessages-for-rabbitmq-25jan2022)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-versioning-policy"},{"document_id":"ibmcld_09590-4947-6640","score":23.4023092191,"text":"\nv5.0, TBD Automatically upgraded in place to next Major version only for Redis 4 to Redis 5 \n RabbitMQ Major versions are the first two numbers in a major.x.patch version number. v3.11, TBD Backup taken and access removed \n MySQL** Major versions are the first two numbers in a major.x.patch version number. v5.7, October 2023 Backup taken and access removed \n\n\n\n**For more information, see [MySQL 8 GA](https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-mysql8-ga).\n\nAny actions taken after a database EOL date happen over several days after the EOL date. We try, but cannot guarantee, to make these upgrades outside of business hours in the local regions. If you want more control over the upgrade process of your database instance, we recommend that you upgrade following our [backup and restore process](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups) before the EOL date of your database version.\n\n\n\n\n\n Major versioning End of Life \n\nYou receive multiple notifications when a major version reaches its End of life. You can typically expect:\n\n\n\n* A blog post, for example: [Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/messages-for-rabbitmq-38-end-of-life-in-july-2022)\n* An announcement in your service's Release Notes, for example: [IBM Cloud\u00ae Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-rabbitmq-relnotesmessages-for-rabbitmq-25jan2022)\n* A notification by email through the IBM Cloud Databases API. This email contains a Notifications link that takes you to a Notifications Management page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-versioning-policy"},{"document_id":"ibmcld_06478-4947-6640","score":23.4023092191,"text":"\nv5.0, TBD Automatically upgraded in place to next Major version only for Redis 4 to Redis 5 \n RabbitMQ Major versions are the first two numbers in a major.x.patch version number. v3.11, TBD Backup taken and access removed \n MySQL** Major versions are the first two numbers in a major.x.patch version number. v5.7, October 2023 Backup taken and access removed \n\n\n\n**For more information, see [MySQL 8 GA](https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-mysql8-ga).\n\nAny actions taken after a database EOL date happen over several days after the EOL date. We try, but cannot guarantee, to make these upgrades outside of business hours in the local regions. If you want more control over the upgrade process of your database instance, we recommend that you upgrade following our [backup and restore process](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups) before the EOL date of your database version.\n\n\n\n\n\n Major versioning End of Life \n\nYou receive multiple notifications when a major version reaches its End of life. You can typically expect:\n\n\n\n* A blog post, for example: [Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/messages-for-rabbitmq-38-end-of-life-in-july-2022)\n* An announcement in your service's Release Notes, for example: [IBM Cloud\u00ae Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-rabbitmq-relnotesmessages-for-rabbitmq-25jan2022)\n* A notification by email through the IBM Cloud Databases API. This email contains a Notifications link that takes you to a Notifications Management page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-versioning-policy"},{"document_id":"ibmcld_06733-4947-6640","score":23.4023092191,"text":"\nv5.0, TBD Automatically upgraded in place to next Major version only for Redis 4 to Redis 5 \n RabbitMQ Major versions are the first two numbers in a major.x.patch version number. v3.11, TBD Backup taken and access removed \n MySQL** Major versions are the first two numbers in a major.x.patch version number. v5.7, October 2023 Backup taken and access removed \n\n\n\n**For more information, see [MySQL 8 GA](https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-mysql8-ga).\n\nAny actions taken after a database EOL date happen over several days after the EOL date. We try, but cannot guarantee, to make these upgrades outside of business hours in the local regions. If you want more control over the upgrade process of your database instance, we recommend that you upgrade following our [backup and restore process](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups) before the EOL date of your database version.\n\n\n\n\n\n Major versioning End of Life \n\nYou receive multiple notifications when a major version reaches its End of life. You can typically expect:\n\n\n\n* A blog post, for example: [Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/messages-for-rabbitmq-38-end-of-life-in-july-2022)\n* An announcement in your service's Release Notes, for example: [IBM Cloud\u00ae Messages for RabbitMQ 3.8 End of Life in July 2022](https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-rabbitmq-relnotesmessages-for-rabbitmq-25jan2022)\n* A notification by email through the IBM Cloud Databases API. This email contains a Notifications link that takes you to a Notifications Management page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-versioning-policy"},{"document_id":"ibmcld_09549-4-1855","score":22.5261418382,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Managing Cloud Databases backups \n\nBackups for Cloud Databases deployments are accessible from the Backups tab of your deployment's dashboard. Here is some additional general information about backups:\n\n\n\n* One backup is taken every day.\n* Backups are available for 30 days.\n* Backups cannot be deleted.\n* If you delete your deployment, its backups are deleted automatically.\n* Daily backup scheduling is not configurable.\n* Backups are restorable to other regions, except for eu-de and par-01, which can restore backups only between each other. For example, par-01 backups can be restored to eu-de, and vice versa.\n* Backup storage is encrypted. To manage the encryption keys, see [Key Protect integration](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-key-protectbyok-for-backups). Otherwise, backups are encrypted with a key that is automatically generated for your deployment.\n* Backups are restorable across accounts, but only through the API and only if the user that is running the restore has access to both the source and destination accounts.\n* Cloud Databases backups are not downloadable. If you need a local backup, use the appropriate software. For example, [pg_dump](https:\/\/www.postgresql.org\/docs\/9.6\/static\/backup-dump.html) is an effective tool for managing PostgreSQL backups.\n* IBM Cloud\u00ae Databases for DataStax does not support reenablement. After a deployment is disabled, that deployment must be restored from a backup.\n\n\n\nFor information on taking an on-demand backup, see [Taking an on-demand backup](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups&interface=cliondemand-backup).\n\n\n\n Backups in the UI \n\nThe backup types have their respective tabs, either On-demand or Automatic. Each backup is listed with its type and when the backup was taken.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-dashboard-backups"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12584-10119-11773","score":25.976097925,"text":"\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Meet disaster recovery objectives IBM follows best practices for disaster recovery. All IBM applications automatically recover and restart after any disaster event. For more information about disaster recovery, see the [IBM Disaster Recovery Plan](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimedisaster-recovery). Customers can help meet disaster recovery objectives by deploying their project in a development or test environment before they deploy to production. <br>\\nThe customer does not have to take other actions to prepare for an event of a catastrophic failure in a region. \n Meet high availability objectives IBM Cloud is available globally and load balanced from a single URL. It is highly available and continues to run even if your resources are unavailable. For more information about high availability, see the [IBM service level objectives](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slo) and the [sample application architecture](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-bcdr-app-recovery). N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-responsibilities-deployable-architectures"},{"document_id":"ibmcld_14598-9419-11893","score":25.8502102369,"text":"\nResponsibilities for security and regulation compliance for VMware Solutions offerings (other than VMware Shared)\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Encryption Provide integration with Key Protect and Hyper Protect Crypto Services through KMIP service as an option for implementing data at-rest encryption. Configure and manage encryption for both data at rest and in transit, as needed. \n\n\n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as:\n\n\n\n* Providing dependencies on disaster recovery sites\n* Provision disaster recovery environments\n* Data and configuration backup\n* Replicating data and configuration to the disaster recovery environment\n* Fail over on disaster events\n\n\n\n\n\n Disaster recovery for VMware Shared \n\nThe following table describes the responsibilities that are related to disaster recovery for VMware Shared.\n\n\n\nTable 8. Responsibilities for disaster recovery for VMware Shared\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Backup of configuration data Backups are conducted of the shared management components to include customer environment configurations. Offsite backup copies are enabled and they run daily. \n Backup of workload Backup services are enabled for customer workload. Configure individual backup jobs to include critical systems. Offsite copies can be enabled per request. \n Recovery of configuration Recovery will be conducted in the original data center after the infrastructure is available. If long-term outage occurs, offsite recovery is conducted. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, customer restore services will be provided after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover. Restore systems from the configured backup jobs. \n\n\n\n\n\n\n\n Disaster recovery for VMware Solutions offerings (other than VMware Shared)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-understand-responsib"},{"document_id":"ibmcld_14738-7598-10031","score":25.3064503676,"text":"\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Encryption Provide secure SSL connections to administration portals and replication endpoints. Workload can be deployed by using AES 256-bit encrypted data stores with unique key per customer instance. Backups are encrypted uniquely per customer. Choose encrypted data stores when you are deploying workloads into the environment where appropriate. Use encrypted networking for workload to workload and workload to IBM Cloud Service connections. Use the IBM Cloud private network where appropriate. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Backup of management configuration data Conduct backups of the management component configurations. These backups include single-tenant vCenter Server, VMware NSX-T, VMware Cloud Director\u2122, and service configurations. Offsite immutable backup copies are enabled in an independent backup account and they run daily. \n Backup of workloads Enable backup services for customer workload. Choose and implement a backup provider for critical workloads. For more information, see [Understanding business continuity and disaster recovery](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-bc-dr). \n Recovery of configuration Conduct recovery in the original data center after the infrastructure is available. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, provide customer restore services after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vmaas-understand-responsib"},{"document_id":"ibmcld_12738-3824-6006","score":24.871829954,"text":"\nSecurity and regulation compliance includes tasks such as security controls implementation and compliance certification.\n\n\n\nTable 4. Responsibilites for security and regulation compliance\nThe rows are read from left to right. The first column describes the task that the customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n IBM Responsibilities Your Responsibilities \n\n Meet security and compliance objectives Provide a secure service that complies with key standards. For more information about data security, see [How do I know that my data is safe](https:\/\/cloud.ibm.com\/docs\/overview\/terms-of-use?topic=overview-security)? Ensure that you are properly securing your workloads and data so that you are meeting the regulatory standards for your organization. For more information about bucket requirements for results storage, see [Storing and processing data](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-storage). \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilites for disaster recovery\nThe rows are read from left to right. The first column describes the task that the customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n IBM responsibilities Your responsibilities \n\n Back up of management and configuration data Conduct backups of configurations such as attachments and scan settings. \n Back up of scan results Conduct backups of your Cloud Object Storage data according to best practices. \n Recovery of configuration Conduct recovery in the original region when availability is returned. \n Recovery of scan results Conduct recovery of your Cloud Object Storage data according to best practices.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-responsibilities"},{"document_id":"ibmcld_12585-5718-7900","score":24.4416532623,"text":"\n(https:\/\/cloud.ibm.com\/docs\/overview\/terms-of-use?topic=overview-security). Secure your workloads and data. Integrate tools into your toolchains that satisfy your security and compliance requirements. To learn more about securing your cloud apps, see [Security to safeguard and monitor your cloud apps](https:\/\/www.ibm.com\/cloud\/architecture\/architecture\/practices\/securing-cloud-native-apps-risks-mitigation\/). To learn more about securing your data while you are using the Projects service, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd_data_security&interface=ui). To learn more about regulatory compliance with the Projects service, see [Understanding tool integrations with IBM for Financial Services](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-integrations&interface=ui). \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilites for disaster recovery\nThe first column describes the task that the customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Meet disaster recovery objectives IBM follows best practices for disaster recovery. All IBM applications automatically recover and restart after any disaster event. For more information about disaster recovery see the [IBM Disaster Recovery Plan](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimedisaster-recovery). Customer can help meet DR objectives by deploying their project in a development or test environment before deploying to production.<br><br>There are no other actions the customer needs to take to prepare for an event of a catastrophic failure in a region. \n Meet high availability objectives IBM is available globally and load balanced from a single URL.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-responsibilities-projects"},{"document_id":"ibmcld_01092-7-2034","score":24.3963699856,"text":"\nDisaster recovery \n\nDisaster recovery (DR) backups for IBM\u00ae Db2\u00ae Warehouse on Cloud are enabled by default and supplement daily snapshot backups. DR backups are used exclusively for system recovery purposes by IBM service operators if there is a disaster or system loss.\n\nIf a disaster event occurs at the data center where your Db2 Warehouse on Cloud instance is deployed, IBM service operators will work with you to stand up a new data warehouse in a different data center, by using the most recent disaster recovery backup. There is no additional charge for these backups.\n\nThe RPO (Recovery Point Objective) and RTO (Recovery Time Objective) for DR backups for each cloud provider are described in the following sections. On IBM Cloud, DR backups are geo-replicated by default. You can open a support ticket to not have your DR backups replicated to certain regions to comply with your data retention policies. On AWS, DR backups are stored in another Availability Zone in the same region and can also be geo-replicated at an additional cost.\n\nFor more information about DR and replication on Db2 Warehouse on Cloud, see [Replication](https:\/\/www.ibm.com\/support\/knowledgecenter\/SS6NHC\/com.ibm.swg.im.dashdb.idrca.doc\/overview\/ovu-db2woc.html).\n\n\n\n IBM Cloud \n\nWhen deployed on IBM Cloud, a full backup of the database is taken once a week for disaster recovery. This DR backup is encrypted and stored in IBM Cloud Object Storage (COS).\n\nIBM COS replicates each DR backup across multiple IBM Cloud regions to ensure availability if a single zone fails.\n\nDR backups of the last 2 weeks are retained by default. The RPO for DR backups on IBM Cloud is 1 week. The RTO if a disaster occurs is dependent upon the size of the database \u2013 1.5 hours per terabyte of data.\n\n\n\n\n\n Amazon Web Services \n\nWhen deployed on Amazon Web Services, a full backup of the database is taken once a day for disaster recovery. This DR backup is encrypted and stored in Amazon Web Services S3.\n\nDR backups of the last 7 days are retained by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-dr"},{"document_id":"ibmcld_00057-5736-7021","score":24.1374657775,"text":"\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a the customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n General <br><br> * Restore or rebuild the provisioning environments in the affected regions.<br> * Restore existing Spark clusters, where possible.<br><br><br> <br><br> * Track instance state.<br> * Provision new Spark instances in alternatively available regions.<br> * Ensure that the Spark instance is stateless by making sure that all data, metadata and applications reside outside of the cluster. This activity must be completed before disaster recovery can be initiated.<br> * Provision a new service instance in an alternatively available region if the current instances can't be accessed.<br> * Track instance state.<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-responsibilities-serverless"},{"document_id":"ibmcld_01473-3605-5979","score":24.0018169158,"text":"\nProcess access policies It is the responsibility of IBM to ensure that the policies are processed. \n Set up access policies It is your responsibility to set up access policies. For more information, see [Creating policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-usercreate). \n Access to back-end resources It is the responsibility of IBM to access to back-end resources. \n Access to namespaces It is your responsibility to set up access to namespaces. For more information, see [Automating access to IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_access). \n\n\n\n\n\n\n\n Security and regulation compliance \n\nSecurity and regulation compliance includes tasks such as security controls implementation and compliance certification.\n\n\n\nTable 4. Responsibilities for security and regulation compliance\nThe first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Secure confidential information. It is your responsibility to make sure that no confidential information is put into your images. \n Ensure that the service instance is secure. It is the responsibility of IBM to ensure the security of the service instance. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and fail over on disaster events. For more information, see [High availability for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-ha-dr) and [Business continuity and disaster recovery for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-bc-dr).\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Copy your data to another region. It is your responsibility to copy the data to another region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_responsibilities"},{"document_id":"ibmcld_12584-8474-10890","score":23.8018451463,"text":"\nIt\u2019s recommended to use a trusted profile, but you can use an API key or an existing secret to [authorize a project to deploy](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-authorize-project) in an account. \n\n\n\n\n\n\n\n Security and regulation compliance \n\nSecurity and regulation compliance includes tasks such as security controls implementation and compliance certification.\n\n\n\nTable 4. Responsibilities for security and regulation compliance\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Apply patches and security updates to operating system in customer instances IBM notifies you of updates. Customer must apply all updates. \n Install software and OS patches into customer-managed virtual machines N\/A Customer must apply all patches. \n Meet security and compliance objectives Provide a secure deployable architecture that complies with declared standards. For more information about data security, see [How do I know that my data is safe?](https:\/\/cloud.ibm.com\/docs\/overview\/terms-of-use?topic=overview-security). Secure your workloads and data. Integrate tools into your toolchains that satisfy your security and compliance requirements. To learn more about securing your cloud apps, see [Security to safeguard and monitor your cloud apps](https:\/\/www.ibm.com\/cloud\/architecture\/architecture\/practices\/securing-cloud-native-apps-risks-mitigation\/). \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Meet disaster recovery objectives IBM follows best practices for disaster recovery. All IBM applications automatically recover and restart after any disaster event.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-responsibilities-deployable-architectures"},{"document_id":"ibmcld_00057-4367-6381","score":23.4289624093,"text":"\nAccess control of the service instance through IAM <br><br> * Verify the user's permissions on the service instance before allowing access.<br><br><br> <br><br> * Maintain responsibility for any service roles that you create for your instances.<br><br><br> \n\n\n\n\n\n\n\n Security and regulation compliance \n\nSecurity and regulation compliance includes tasks such as security controls implementation and compliance certification.\n\n\n\nTable 4. Responsibilities for security and regulation compliance\nThe rows are read from left to right. The first column describes the task that a the customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n General <br><br> * Maintain controls commensurate to various industry compliance standards.<br> * Monitor, isolate, and recover instances.<br> * Monitor and report the health of instances in the various interfaces.<br> * Secure cluster access through TLS\/SSH (data plane in the IBM Services account).<br> * Integrate IBM Analytics Engine with IBM Cloud Identity and Access Management (IAM).<br><br><br> <br><br> * Set up and maintain security and regulation compliance for the IBM Analytics Engine instances.<br><br><br> \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a the customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-responsibilities-serverless"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16729-104404-106143","score":24.7493761706,"text":"\nIf you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster\n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-05-09\n\n\n\n[Creating Red Hat OpenShift on IBM Cloud clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial)Creating Red Hat OpenShift on IBM Cloud clusters\n\nCreate a cluster with worker nodes that come installed with Red Hat OpenShift container orchestration platform.\n\nRed Hat OpenShift on IBM Cloud\n\n\n\n* 45 minutes\n* 2023-07-13\n\n\n\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07\n\n\n\n[Setting capacity quotas for apps that use IBM Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-cos-tutorial-quota)Setting capacity quotas for apps that use IBM Cloud Object Storage","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_10702-7-1940","score":24.704350505,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"},{"document_id":"ibmcld_14497-11060-12784","score":24.2258248396,"text":"\nThe NSX DLR virtual machines are configured as an active - passive pair, and vSphere Distributed Resource Scheduler (DRS) anti-affinity rules are created to ensure that the DLR VMs do not run on the same host. This step is described in [Red Hat OpenShift NSX DLR configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-nsxdlr-intro).\n* Update DNS - The infrastructure DNS, provisioned with the vCenter Server instance is updated with the names and IP addresses for the Red Hat OpenShift components by using a PowerShell script. This step is described in [VMware Solutions DNS configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-dns-intro).\n\n\n\n* Phase 2 - Red Hat OpenShift installation. These steps are described in [Red Hat OpenShift 4.7 user provider infrastructure installation](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-install-intro).\n\n\n\n* A Red Hat virtual machine, the bastion node, is provisioned to run the Red Hat OpenShift installer and to host an HTTP Server. It is registered with Red Hat by using your subscription, and the Red Hat OpenShift installer is downloaded.\n* On the bastion node, the install-config.yaml file is populated with the required Red Hat OpenShift parameters and Red Hat OpenShift ignition is used to generate a number of files used for the installation of the bootstrap, control plane, and worker machines.\n* Terraform, on the bastion node, uses the files that are created by Ignition to create the Red Hat OpenShift VMs.\n\n\n\n* Phase 3 - Post deployment activities. Configure a persistent volume for use by the Red Hat OpenShift cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_10154-17039-18368","score":24.1757313223,"text":"\nContainer-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https:\/\/www.redhat.com\/en\/topics\/microservices\/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https:\/\/docs.openshift.com\/container-platform\/4.11\/service_mesh\/v1x\/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https:\/\/gist.githubusercontent.com\/kitch\/39c504a2ed9e381c2aadea436d5b52e4\/raw\/d8efa69f41d41425b16bb363a881a98d40d3708c\/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_14497-7-1724","score":24.0795110737,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_08259-0-511","score":24.0514143864,"text":"\n\n\n\n\n\n\n  Release notes for Red Hat OpenShift for HPC \n\nUse these release notes to learn about the latest updates to Red Hat\u00ae OpenShift\u00ae for HPC that are grouped by date.\n\n\n\n  March 2022 \n\n\n\n  24 March 2022 \n\nIntroducing Red Hat OpenShift for HPC solutions\n:   You can now take advantage of automated deployment of a Red Hat OpenShift cluster along with a deployer virtual server instance, which allows you to easily assemble, compile, and deploy your HPC applications to the Red Hat OpenShift cluster.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-openshift?topic=hpc-openshift-release-notes"},{"document_id":"ibmcld_08006-7-1967","score":23.9131357255,"text":"\nSingle-region IBM Cloud for Financial Services reference architecture for VPC with Red Hat OpenShift on IBM Cloud \n\nIf you want to use containers, you can add [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview) to your VPC. Except for the addition of Red Hat OpenShift on IBM Cloud, you use the same architectural patterns and components that were described for the [Single-region IBM Cloud for Financial Services reference architecture for VPC with Virtual Servers for VPC](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-vsi).\n\nThe following diagram shows a more detailed view of both the management and workload VPCs when Red Hat OpenShift on IBM Cloud is introduced.\n\n\n\n Architecture diagram \n\nZoom\n\n![Single region IBM Cloud for Financial Services reference architecture for VPC with Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9ac5c38b41e0aa1cb4ccc6cc7f547751ec805221\/framework-financial-services\/vpc\/images\/roks-single-region\/roks-single-region-consumer-intranet.svg)\n\nFigure 1. Single region IBM Cloud for Financial Services reference architecture for VPC with Red Hat OpenShift on IBM Cloud\n\nYou can choose to use Red Hat OpenShift on IBM Cloud alongside (or instead of) virtual servers in either or both VPCs. Even though it is shown in the diagram as an option, it is not required to put Red Hat OpenShift on IBM Cloud in your management VPC.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud concepts \n\nRed Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift on IBM Cloud cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-openshift"},{"document_id":"ibmcld_16729-218252-220002","score":23.9049402743,"text":"\nA VPC allows you to create your own space in IBM Cloud so that you can run an isolated environment in the public cloud with custom network policies.\n\nVirtual Private Cloud (VPC) Terraform on IBM Cloud\n\n\n\n* 2 hours\n* 2023-04-21\n\n\n\n[Updating VPC worker nodes that use OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc)Updating VPC worker nodes that use OpenShift Data Foundation\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster\n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-05-09\n\n\n\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_14492-7-1792","score":23.6518268991,"text":"\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_10228-4-1670","score":23.5337607635,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Getting started with Red Hat OpenShift on IBM Cloud \n\nWith Red Hat OpenShift on IBM Cloud, you can deploy apps on highly available Red Hat OpenShift clusters that run the [Red Hat OpenShift on IBM Cloud Container Platform](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) software on Red Hat Enterprise Linux machines.\n\nFirst, create a classic Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster or a cluster on the second generation of compute infrastructure in a Virtual Private Cloud (VPC). Then, deploy and expose a sample app in your cluster.\n\nTo complete the getting started tutorial, use a [Pay-As-You-Go or Subscription IBM Cloud\u00ae Kubernetes Service account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) where you are the owner or have [full Administrator access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\n\n\n Creating a classic Red Hat OpenShift cluster in the console \n\nCreate a Red Hat OpenShift on IBM Cloud cluster on classic IBM Cloud infrastructure in the IBM Cloud console. To get started, create a cluster that runs OpenShift Container Platform version 4.11. The operating system is Red Hat Enterprise Linux 7.\n\nWant to learn more about customizing your cluster setup with the CLI? Check out [Creating a Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clusters).\n\n\n\n1. Log in to your [IBM Cloud account](https:\/\/cloud.ibm.com\/).\n2. From the Catalog, click [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about?platformType=openshift).\n3. Review the platform version details, Red Hat OpenShift 4.11.42.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-started"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10534-1033-2260","score":21.7152810591,"text":"\n[Understanding Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewoverview)\n\n\n\n* [What is Red Hat OpenShift on IBM Cloud and how does it work?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-overview)\n* [What is Kubernetes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-kube-overview)\n* [What are containers?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-are-containers-overview)\n* [What is Red Hat OpenShift?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-openshift-overview)\n* [What compute host infrastructure does the service offer?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-compute-infra-is-offered)\n* [Related resources](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewkubernetes-resources)\n\n\n\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_07578-394005-396150","score":20.9575275275,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-393979-396124","score":20.9575275275,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10214-7-1980","score":20.6290864036,"text":"\nFAQs \n\nReview frequently asked questions (FAQs) for using Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\n\n\n How does Red Hat OpenShift on IBM Cloud work? \n\nWith Red Hat OpenShift on IBM Cloud, you can create your own Red Hat OpenShift cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n\n\n\n\n\n Why should I use Red Hat OpenShift on IBM Cloud? \n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10154-7-1896","score":20.5781627508,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_05707-7-2073","score":18.2440996498,"text":"\nBenefits and service offerings \n\n[IBM Cloud\u00ae Kubernetes Service](https:\/\/www.ibm.com\/cloud\/kubernetes-service) delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts. For more information about certification, see [Compliance on the IBM Cloud](https:\/\/www.ibm.com\/cloud\/compliance).\n\n\n\n Benefits of using the service \n\nClusters are deployed on compute hosts that provide native Kubernetes and IBM-specific capabilities.\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud. For more information, see Comparison between [Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovopenshift_kubernetes) and community Kubernetes clusters.\n\nSingle-tenant Kubernetes clusters with compute, network, and storage infrastructure isolation\n: Create your own customized infrastructure that meets the requirements of your organization.\n: Choose between [IBM Cloud Classic or VPC infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers).\n: Provision a dedicated and secured Kubernetes master, worker nodes, virtual networks, and storage by using the resources provided by IBM Cloud infrastructure.\n: Fully managed Kubernetes master that is continuously monitored and updated by IBM to keep your cluster available.\n: Option to provision worker nodes as bare metal servers for compute-intensive workloads such as data, GPU, and AI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov"},{"document_id":"ibmcld_10214-1438-3413","score":18.0927892011,"text":"\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n\n\n\n\n\n What container platforms are available for my cluster? \n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform. If you want to use multiple container platforms, create a separate cluster for each.\n\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https:\/\/kubernetes.io\/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10534-1903-3343","score":17.9107410004,"text":"\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes)\n* [Comparison between clusters that run in IBM Cloud and standard OCP](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcompare_ocp)\n\n\n\n[Supported infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers)\n\n\n\n* [Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersvpc-gen2-infra-overview)\n* [Satellite](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providerssatellite-infra-overview)\n* [Classic](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersclassic-infra-overview)\n* [Troubleshooting and support](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfra-troubleshoot)\n\n\n\n[Your responsibilities with using Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iksresponsibilities_iks)\n\n\n\n* [Overview of shared responsibilities](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iksoverview-by-resource)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_05713-1178-2700","score":17.8826490812,"text":"\nAbout \n\n[Understanding IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewoverview)\n\n\n\n* [What is IBM Cloud Kubernetes Service and how does it work?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewwhat-is-overview)\n* [What is Kubernetes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewwhat-is-kube-overview)\n* [What are containers?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewwhat-are-containers-overview)\n* [What compute host infrastructure does the service offer?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewwhat-compute-infra-is-offered)\n* [Related resources](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overviewkubernetes-resources)\n\n\n\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits)\n* [Comparison of offerings and their combinations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovdifferentiation)\n* [Comparison of free and standard clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovopenshift_kubernetes)\n\n\n\n[Supported infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providersinfrastructure_providers)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10214-12307-14229","score":17.591385839,"text":"\nRed Hat OpenShift security bulletins that affect Red Hat OpenShift on IBM Cloud users or the IBM Cloud platform are published in the [IBM Cloud security bulletin](https:\/\/cloud.ibm.com\/status?component=containers-kubernetes&selected=security).\n\nSome CVEs require the latest patch update for a version that you can install as part of the regular [cluster update process](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) in Red Hat OpenShift on IBM Cloud. Make sure to apply security patches in time to protect your cluster from malicious attacks. For more information about what is included in a security patch, refer to the [version change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionscs_versions_available).\n\n\n\n\n\n Does the service offer support for bare metal and GPU? \n\nCertain VPC worker node flavors offer GPU support. For more information, see the [VPC flavors](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-flavors).\n\nYes, you can provision your worker node as a single-tenant physical bare metal server. Bare metal servers come with high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have to worry about \"noisy neighbors\".\n\nFor more information about available bare metal flavors and how bare metal is different from virtual machines, see [Physical machines (bare metal)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesbm).\n\n\n\n\n\n What is the smallest size cluster that I can make? \n\nYour cluster must have at least 2 worker nodes to run default Kubernetes and OpenShift Container Platform components. You can't have a cluster with 0 worker nodes, and you can't power off or suspend billing for your worker nodes. Additionally, the type of cluster and the number of worker pools that you have can impact the size of your cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16729-104404-106143","score":15.4921430474,"text":"\nIf you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster\n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-05-09\n\n\n\n[Creating Red Hat OpenShift on IBM Cloud clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial)Creating Red Hat OpenShift on IBM Cloud clusters\n\nCreate a cluster with worker nodes that come installed with Red Hat OpenShift container orchestration platform.\n\nRed Hat OpenShift on IBM Cloud\n\n\n\n* 45 minutes\n* 2023-07-13\n\n\n\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07\n\n\n\n[Setting capacity quotas for apps that use IBM Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-cos-tutorial-quota)Setting capacity quotas for apps that use IBM Cloud Object Storage","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_16729-218252-220002","score":15.1747520888,"text":"\nA VPC allows you to create your own space in IBM Cloud so that you can run an isolated environment in the public cloud with custom network policies.\n\nVirtual Private Cloud (VPC) Terraform on IBM Cloud\n\n\n\n* 2 hours\n* 2023-04-21\n\n\n\n[Updating VPC worker nodes that use OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc)Updating VPC worker nodes that use OpenShift Data Foundation\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster\n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-05-09\n\n\n\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_10702-7-1940","score":15.1683739577,"text":"\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https:\/\/docs.openshift.com\/container-platform\/4.11\/welcome\/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"},{"document_id":"ibmcld_10154-17039-18368","score":15.1607563127,"text":"\nContainer-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https:\/\/www.redhat.com\/en\/topics\/microservices\/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https:\/\/docs.openshift.com\/container-platform\/4.11\/service_mesh\/v1x\/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https:\/\/gist.githubusercontent.com\/kitch\/39c504a2ed9e381c2aadea436d5b52e4\/raw\/d8efa69f41d41425b16bb363a881a98d40d3708c\/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_14497-7-1724","score":14.7532501077,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_16729-219607-221413","score":14.5753879137,"text":"\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07\n\n\n\n[Deploying OpenShift Data Foundation on Satellite clusters with Azure worker nodes](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-odf-tutorial)Deploying OpenShift Data Foundation on Satellite clusters with Azure worker nodes\n\nIn this tutorial, you complete the following tasks to set up OpenShift Data Foundation.\n\nSatellite Kubernetes service\n\n+1\n\nVirtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-06-02\n\n\n\n[Onboarding a virtual server image with Terraform to a private catalog](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-vsimage-onboard)Onboarding a virtual server image with Terraform to a private catalog\n\nThis tutorial walks you through how to onboard a virtual server image with Terraform to a private catalog. By completing this tutorial, you learn how to import the virtual server image from a GitHub repository, configure the deployment and other details, and validate that you can deploy the image to a target IBM Cloud\u00ae Virtual Private Cloud (VPC).\n\nObject Storage Virtual Private Cloud (VPC)\n\n+1\n\nSelling on IBM Cloud\n\n\n\n* 45 minutes\n* 2022-08-02\n\n\n\n[Onboarding a virtual server image for Power Systems to a private catalog](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-vsipower-onboard)Onboarding a virtual server image for Power Systems to a private catalog\n\nThis tutorial walks you through how to onboard a public virtual server image for Power Systems Virtual Server to a private catalog.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_10407-7-1954","score":14.5620439988,"text":"\nService limitations \n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae and the Red Hat OpenShift open source project come with default service settings and limitations to ensure security, convenience, and basic functionality. Some limitations you might be able to change where noted.\n\nIf you anticipate reaching any of the following Red Hat OpenShift on IBM Cloud limitations, [contact IBM Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) and provide the cluster ID, the new quota limit, and the region in your support ticket.\n\n\n\n Service and quota limitations \n\nRed Hat OpenShift on IBM Cloud comes with the following service limitations and quotas that apply to all clusters, independent of what infrastructure provider you plan to use. Keep in mind that the [classic](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitationsclassic_limits) and [VPC](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitationsks_vpc_gen2_limits) cluster limitations also apply.\n\nTo view quota limits on cluster-related resources in your IBM Cloud account, use the ibmcloud oc quota ls command.\n\n\n\nRed Hat OpenShift on IBM Cloud limitations\n\n Category Description \n\n API rate limits 200 requests per 10 seconds to the Red Hat OpenShift on IBM Cloud API from each unique source IP address. \n App deployment The apps that you deploy to and services that you integrate with your cluster must be able to run on the operating system of the worker nodes. \n Container-native virtualization The Red Hat OpenShift [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) to run VM workloads alongside container workloads is not supported by IBM. If you choose to install the add-on yourself, you must use bare metal machines, not virtual machines. You are responsible for resolving any issues and impact to your workloads from using container-native virtualization.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitations"},{"document_id":"ibmcld_14682-7-2113","score":14.4894167498,"text":"\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"},{"document_id":"ibmcld_08259-0-511","score":14.4159093416,"text":"\n\n\n\n\n\n\n  Release notes for Red Hat OpenShift for HPC \n\nUse these release notes to learn about the latest updates to Red Hat\u00ae OpenShift\u00ae for HPC that are grouped by date.\n\n\n\n  March 2022 \n\n\n\n  24 March 2022 \n\nIntroducing Red Hat OpenShift for HPC solutions\n:   You can now take advantage of automated deployment of a Red Hat OpenShift cluster along with a deployer virtual server instance, which allows you to easily assemble, compile, and deploy your HPC applications to the Red Hat OpenShift cluster.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-openshift?topic=hpc-openshift-release-notes"},{"document_id":"ibmcld_11950-7-2002","score":14.4103388644,"text":"\nSetting up virtualization on a Satellite location \n\nYou can set up your Bare Metal Servers to use Red Hat OpenShift virtualization in your Satellite location. By using virtualization, you can provision Windows or other virtual machines on your Bare Metal Servers in a managed Red Hat OpenShift space.\n\nSupported host operating systems\n: Red Hat CoreOS (RHCOS)\n\n\n\n Prerequisites \n\n\n\n* Create a RHCOS-enabled location. To check whether your location is RHCOS-enabled, see [Is my location enabled for Red Hat CoreOS?](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locationsverify-coreos-location). If your location is not enabled, [create a new one with RHCOS](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locations).\n* Attach hosts to your location and set up your [location control plane](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-control-plane).\n* Find and record your bare metal host name.\n* Find your bare metal server network information. Record the CIDR and gateway information for the public and private interfaces for your system.\n* If you want to use IBM Cloud Object Storage to store your ignition file, create or identify a bucket.\n* Create or identify a cluster within the Satellite location that runs a supported operating system; for example, this tutorial uses a Red Hat OpenShift cluster that is running 4.11.\n* If you want to use OpenShift Data Foundation as your storage solution, add 2 storage disks to each of your Bare Metal Servers when you provision them.\n\n\n\n\n\n\n\n Bare Metal Server requirements for Satellite \n\nTo set up virtualization, your Bare Metal Server must meet the following requirements.\n\n\n\n* Must support virtualization technology.\n\n\n\n* For Intel CPUs, support for virtualization is referred to as Intel VT or VT-x.\n* For AMD CPUs, support for virtualization is referred to as AMD Virtualization or AMD-V.\n\n\n\n* Must have a minimum of minimum of 8 cores and 32 GB RAM, plus any additional cores that you need for your vCPU overhead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-location"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14682-7-2113","score":30.1719264817,"text":"\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"},{"document_id":"ibmcld_14497-7-1724","score":29.4834272585,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_14492-7-1792","score":28.6643964773,"text":"\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_10214-7-1980","score":27.7614763496,"text":"\nFAQs \n\nReview frequently asked questions (FAQs) for using Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\n\n\n How does Red Hat OpenShift on IBM Cloud work? \n\nWith Red Hat OpenShift on IBM Cloud, you can create your own Red Hat OpenShift cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n\n\n\n\n\n Why should I use Red Hat OpenShift on IBM Cloud? \n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10534-1033-2260","score":27.5567056189,"text":"\n[Understanding Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewoverview)\n\n\n\n* [What is Red Hat OpenShift on IBM Cloud and how does it work?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-overview)\n* [What is Kubernetes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-kube-overview)\n* [What are containers?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-are-containers-overview)\n* [What is Red Hat OpenShift?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-is-openshift-overview)\n* [What compute host infrastructure does the service offer?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewwhat-compute-infra-is-offered)\n* [Related resources](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-overviewkubernetes-resources)\n\n\n\n[Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_10154-7-1896","score":27.4879938428,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10170-10609-12793","score":27.4135167576,"text":"\nThus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* Red Hat OpenShift on IBM Cloud\n* IBM Cloud\u00ae Continuous Delivery\n* IBM Logging and Monitoring\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae\n* IBM Cloud App ID\n\n\n\nAccelerated development is a key win for the HR Exec. The team gets started by containerizing their apps and putting them in the cloud. With the use of modern containers, Developers can experiment easily with Node.js SDK and push changes to Development and Test systems, which are scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. No longer were updates to the HR site languishing in slow, error-prone build processes. They can deliver incremental updates to their site, daily or even more frequently. Moreover, logging and monitoring for the HR site is rapidly integrated, especially for how the site pulls personalized data from back-end benefit systems. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems. Developers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_07578-394005-396150","score":27.3894412712,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-393979-396124","score":27.3894412712,"text":"\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_10531-7-2246","score":27.3116769722,"text":"\nRed Hat OpenShift on IBM Cloud partners \n\nTo provide you with all the capabilities that you need to run production workloads in the cloud, Red Hat OpenShift on IBM Cloud partners with other third-party service providers to enhance your cluster with logging, monitoring, and storage tools.\n\nReview the list of partners and the benefits of each solution that they provide. To find other proprietary IBM Cloud and third-party open source services that you can use in your cluster, see [Understanding IBM Cloud and 3rd party integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations).\n\n\n\n Portworx \n\n[Portworx](https:\/\/portworx.com\/products\/portworx-enterprise\/\/) is a highly available software-defined storage solution that you can use to manage local persistent storage for your containerized databases and other stateful apps, or to share data between pods across multiple zones.\n\nAn software defined storage (SDS), such as Portworx, solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n Benefits \n\nReview the following table to find a list of key benefits that you can get by using Portworx.\n\n\n\nBenefits of using Portworx\n\n Benefit Description \n\n Cloud native storage and data management for stateful apps Portworx aggregates available local storage that is attached to your worker nodes and that can vary in size or type, and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using Kubernetes persistent volume claims (PVC), you can add local persistent storage to your apps to store your data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.296081911,"ndcg_cut_10":0.296081911}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10154-7-1896","score":12.653676264,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10116-3182-5089","score":12.0461893435,"text":"\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.\n* Longer ordering process: After you order or cancel a bare metal server, the process is completed manually in your IBM Cloud infrastructure account. Therefore, it can take more than one business day to complete.\n\nVPC Generation 2 only: Prices vary by region where the underlying worker node infrastructure resides, and you can get sustained usage discounts. For more information, see [What are the regional uplift charges and sustained usage discounts for VPC worker nodes?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costscharges_vpc_gen2).\n\n\n\nFor more information about worker node specifications, see [Available hardware for worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes).\n\n\n\n\n\n Compute licenses \n\nIn Red Hat OpenShift on IBM Cloud, worker nodes require OpenShift Container Platform licenses to cover the use of Red Hat OpenShift Container Platform and Red Hat Enterprise Linux. OpenShift Container Platform licenses can be supplied by an [existing IBM Cloud Pak entitlement](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costslicenses-cloud-pak) or [by Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costslicenses-on-demand).\n\n\n\n OCP licenses from Red Hat OpenShift on IBM Cloud \n\nWhen you create worker nodes by adding a worker pool or cluster, Red Hat OpenShift on IBM Cloud helps you include the purchase of OpenShift Container Platform licenses for the worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_10154-9468-11364","score":11.9898731794,"text":"\nIn this sense, the installation is similar to IPI for you because you don't have to manage all the infrastructure and network settings. IBM also provides patch updates that you can choose to apply to your worker nodes, from the IBM Cloud interface (not the Red Hat OpenShift web console). SSH is disabled for added security. \n OCP versions and patch updates You are responsible for updating the underlying infrastructure for the master and worker nodes. You can use the Red Hat OpenShift web console to update OCP versions. IBM automatically applies updates to the master, and provides version updates and security patch updates for the worker nodes. You choose when to apply these updates to your worker nodes, from the IBM Cloud interface (not the Red Hat OpenShift web console). Supported versions might vary from standard OpenShift Container Platform. \n Autoscaling compute machines You can set up a ClusterAutoscaler resource. You can set up the [cluster autoscaler plug-in](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-scaling-classic-vpc). \n Worker node operating system CoreOS or RHEL For a list of supported operating systems by cluster version, see [Red Hat OpenShift on IBM Cloud version information](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions). \n Support Provided per the terms of your Red Hat subscription or cloud provider. You can use the oc adm must-gather tool to help gather information. Provided by [IBM Cloud Support](https:\/\/www.ibm.com\/cloud\/support). You can use the oc adm must-gather tool, or the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool) to help gather information. \n Red Hat OpenShift web console You set up and can configure or disable the Red Hat OpenShift web console. The Red Hat OpenShift web console is set up for you. You can't configure or disable the web console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10462-7-2030","score":11.8873796474,"text":"\nSetting pod priority \n\nWith pod priority and preemption, you can configure priority classes to indicate the relative priority of the pods that make up your Red Hat OpenShift cluster's workload. The Red Hat OpenShift controller takes into consideration the priority of a pod and can even preempt (remove) pods with lower priority to make room on a worker node for higher priority pods. For more information, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/nodes\/pods\/nodes-pods-priority.html).\n\nWhy do I set pod priority?\n: As a cluster administrator, you want to control which pods are more critical to your cluster workload. Priority classes can help you control the Red Hat OpenShift controller decisions to favor higher priority pods over lower priority pods. The Red Hat OpenShift controller can even preempt (remove) lower priority pods that are running so that pending higher priority pods can be scheduled.\n\nBy setting pod priority, you can help prevent lower priority workloads from impacting critical workloads in your cluster, especially in cases where the cluster starts to reach its resource capacity.\n\nMake sure that you have [set up proper user access](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-usersusers) to your cluster, and if applicable, [security context constraints (SCCs)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_sccoc_sccs). Access policies and SCCs can help prevent untrusted users from deploying high priority pods that prevent other pods from scheduling.\n\nHow does priority scheduling and preemption work?\n\nIn general, pending pods that have a higher priority are scheduled before lower prioritized pods. If you don't have enough resources remaining in your worker nodes, the Red Hat OpenShift controller can preempt (remove) pods to free up enough resources for the higher prioritized pods to be scheduled. Preemption is also affected by graceful termination periods, pod disruption budgets, and worker node affinity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-pod_priority"},{"document_id":"ibmcld_10203-7-1859","score":11.7332584777,"text":"\nDeploying apps in Red Hat OpenShift clusters \n\nWith Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters, you can deploy apps from a remote file or repository such as GitHub with a single command. Also, your clusters come with various built-in services that you can use to help operate your cluster.\n\n\n\n Moving your apps to Red Hat OpenShift \n\nTo create an app in your Red Hat OpenShift on IBM Cloud cluster, you can use the Red Hat OpenShift console or CLI.\n\nSeeing errors when you deploy your app? Red Hat OpenShift has different default settings than community Kubernetes, such as stricter security context constraints. Review the [common scenarios where you might need to modify your apps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_deployopenshift_move_apps_scenarios) so that you can deploy them on Red Hat OpenShift clusters.\n\n\n\n Deploying apps through the console \n\nYou can create apps through various methods in the Red Hat OpenShift console by using the Developer perspective. For more information, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/applications\/creating_applications\/odc-creating-applications-using-developer-perspective.html).\n\n\n\n1. From the [Red Hat OpenShift clusters console](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift), select your cluster.\n2. Click Red Hat OpenShift web console.\n3. From the perspective switcher, select Developer. The Red Hat OpenShift web console switches to the Developer perspective, and the menu now offers items such as +Add, Topology, and Builds.\n4. Click +Add.\n5. In the Add pane menu bar, select the Project that you want to create your app in from the drop-down list.\n6. Click the method that you want to use to add your app, and follow the instructions. For example, click From Git.\n\n\n\n\n\n\n\n Deploying apps through the CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"},{"document_id":"ibmcld_10116-4552-6190","score":11.7191820722,"text":"\nOpenShift Container Platform licenses can be supplied by an [existing IBM Cloud Pak entitlement](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costslicenses-cloud-pak) or [by Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costslicenses-on-demand).\n\n\n\n OCP licenses from Red Hat OpenShift on IBM Cloud \n\nWhen you create worker nodes by adding a worker pool or cluster, Red Hat OpenShift on IBM Cloud helps you include the purchase of OpenShift Container Platform licenses for the worker nodes. The way that these OpenShift Container Platform licenses are billed varies by the type of OpenShift Container Platform licenses that the worker nodes have.\n\n\n\n* [New OCP licenses](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costslicenses-on-demand-new) with reduced pricing, available 9 November 2020. Create a cluster or worker pool with the latest flavors to use the new OCP licenses.\n* Deprecated: [Old OCP licenses](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costslicenses-on-demand-old) for existing worker nodes before 9 November 2020 or deprecated bare metal flavors. [Migrate](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costslicenses-on-demand-migrate) your existing worker nodes to take advantage of the new OCP licenses.\n\n\n\n\n\n New OCP licenses with reduced pricing, available 9 November 2020 \n\nNew OCP licenses include reduced pricing from Red Hat. a Red Hat OpenShift license is billed for every two virtual cores (or one physical cores) of the worker node flavor. Charges vary by the type of worker node that you have, for as long as you have the worker node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_10248-1412-3302","score":11.7148577355,"text":"\n* ibm-charts: Helm charts that are approved for Red Hat OpenShift on IBM Cloud and IBM Cloud Private clusters.\n* ibm-community: Helm charts that originated outside IBM, such as from [Red Hat OpenShift on IBM Cloud partners](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners). These charts are supported and maintained by the community partners.\n* kubernetes: Helm charts that are provided by the Kubernetes community and considered stable by the community governance. These charts are not verified to work in Red Hat OpenShift on IBM Cloud or IBM Cloud Private clusters.\n* kubernetes-incubator: Helm charts that are provided by the Kubernetes community and considered incubator by the community governance. These charts are not verified to work in Red Hat OpenShift on IBM Cloud or IBM Cloud Private clusters.\n* entitled: Helm charts of licensed software that you must purchase and for which you must set up cluster access with an entitlement key. For more information, see [Setting up a cluster to pull entitled software](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registrysecret_entitled_software).\n\n\n\nHelm charts from the iks-charts, ibm-charts, and, if licensed, entitled repositories are fully integrated into the IBM Cloud support organization. If you have a question or an issue with using these Helm charts, you can use one of the Red Hat OpenShift on IBM Cloud support channels. For more information, see [Getting help and support](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help). [Install the latest release of Helm v3](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helminstall_v3).\n\n\n\n\n\n\n\n Installing Helm v3 in your cluster \n\nSet up Helm v3 and the IBM Cloud Helm repositories in your cluster.\n\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-helm"},{"document_id":"ibmcld_14682-7-2113","score":11.6365723862,"text":"\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"},{"document_id":"ibmcld_10214-7-1980","score":11.6049969408,"text":"\nFAQs \n\nReview frequently asked questions (FAQs) for using Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\n\n\n How does Red Hat OpenShift on IBM Cloud work? \n\nWith Red Hat OpenShift on IBM Cloud, you can create your own Red Hat OpenShift cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov).\n\n\n\n\n\n Why should I use Red Hat OpenShift on IBM Cloud? \n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqs"},{"document_id":"ibmcld_10392-218624-220182","score":11.560596748,"text":"\n4 December 2019 \n\nExposing apps with load balancers or Ingress ALBs\n: Added quick start pages to help you get up and running with [load balancers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-loadbalancer-qs) and [Ingress ALBs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-managed-ingress-about).\n\nRed Hat OpenShift charges\n: Now when you create Red Hat OpenShift clusters, you are not charged for the Red Hat Enterprise Linux operating system that is installed on the worker nodes. For more information, see [What am I charged for when I use Red Hat OpenShift clusters?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-faqscharges).\n\nRed Hat OpenShift routes\n: Added steps for [bringing your own hostname](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_routesroutes-setup) for public routes and steps for [setting up private routes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_routesprivate-routes-setup-43).\n\nUse the internal KVDB in Portworx\n: Automatically set up a key-value database (KVDB) during the Portworx installation to store your Portworx metadata. For more information, see [Using the Portworx KVDB](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_kv_store).\n\n\n\n\n\n\n\n November 2019 \n\n\n\n 26 November 2019 \n\nCLI change log\n: Updated the IBM Cloud Kubernetes Service CLI plug-in change log page for the [release of version 0.4.61](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog).\n\nDiagnostics and Debug Tool add-on for Red Hat OpenShift clusters","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-relnotes"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14497-4136-6209","score":21.7873260475,"text":"\n* Load-balancer - An NSX ESG load-balancer service is used to front end the Red Hat OpenShift APIs, both internal and external, and the Red Hat OpenShift router. The load balancer is configured so that Port 6443 and 22623 point to the bootstrap and control plane nodes, while ports 80 and 443 are configured to point to the worker nodes.\n* Webserver - A web server is needed to hold the ignition configurations and installation images for the installation of RHEL CoreOS. NGINX is installed on the bastion node to provide this function.\n* Persistent Storage - To support the persistent storage requirements, the vSphere cloud provider is used to provide storage volumes up to the Red Hat OpenShift platform backed by any supported vSphere datastore that is, VMware\u00ae vSAN\u2122, NFS, or iSCSI. Red Hat OpenShift can deliver storage through static or dynamic provisioning. The preferred method is to use dynamic provisioning. Dynamic provisioning automatically triggers the creation of the persistent volume and its backend VMDK file. For dynamic provisioning, a default StorageClass for the Red Hat OpenShift cluster is defined and a PersistentVolumeClaim in Kubernetes is created.\n\n\n\nAccess to the environment for this build process is done through a \"jump-server\" or remote device:\n\n\n\n* You can have a Microsoft Windows\u00ae or Linux Virtual Server Instance (VSI) installed alongside your vCenter Server instance to provide administrative access to the environment. This VSI has internet access for the remote connection to the server and for downloading files. It also has private network access for connecting to vCenter and to the bastion node.\n* You can have a remote device (laptop or desktop) connected through the IBM Cloud SSL VPN to the IBM Cloud Private network. This remote device has access to the internet to download the required files and can connect to vCenter and the bastion node through the SSL VPN.\n\n\n\n\n\n\n\n Scripts overview \n\nThis build process uses the following scripting tools and scripts:\n\n\n\n* govc is a vSphere CLI pre-compiled for Linux, OSX, and Windows.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_16729-86110-87974","score":21.676389474,"text":"\nIn this tutorial, you learn how to create and deploy a scalable Node.js Express application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Deploy a Java Spring app by using IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-spring-webapp)Deploy a Java Spring app by using IBM Cloud Schematics\n\nIn this tutorial, you learn how to create and deploy a scalable Java Spring application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Creating an IBM Cloud Satellite environment on AWS by using scripts](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-trysat)Creating an IBM Cloud Satellite environment on AWS by using scripts\n\nThis tutorial and set of scripts provide a mostly automated way to set up an IBM Cloud Satellite location and Red Hat OpenShift cluster on Amazon Web Services (AWS). This is not a production-ready solution, but it provides a useful tool for proof-of-concepts, learning, and experimenting.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_16729-246841-248669","score":21.6585644672,"text":"\nIn this tutorial, you learn how to create and deploy a scalable Java Spring application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Creating an IBM Cloud Satellite environment on AWS by using scripts](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-trysat)Creating an IBM Cloud Satellite environment on AWS by using scripts\n\nThis tutorial and set of scripts provide a mostly automated way to set up an IBM Cloud Satellite location and Red Hat OpenShift cluster on Amazon Web Services (AWS). This is not a production-ready solution, but it provides a useful tool for proof-of-concepts, learning, and experimenting.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 1.5 hours\n* 2022-02-23\n\n\n\n[Reconciling usage for nonsubscription multi-year account invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice)Reconciling usage for nonsubscription multi-year account invoices\n\nAs an IBM Cloud\u00ae customer with a nonsubscription multi-year account, understanding the different invoices that are available to you can help you understand your monthly cost breakdown.\n\nManaging billing and usage\n\n\n\n* 15 minutes\n* 2022-08-30\n\n\n\n[Getting started with the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started)Getting started with the IBM Cloud CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_14490-7-2135","score":21.5117616226,"text":"\nManaging Red Hat OpenShift for VMware \n\nReview the following information to manage your Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service after deployment.\n\n\n\n Rotating the Red Hat OpenShift certificates (required) \n\nRed Hat OpenShift for VMware uses kubelet client certificates that must be rotated periodically for security purposes. Red Hat OpenShift mainly automates the rotation process, but requires manual approval of certificate signing requests (CSRs). Therefore, it is important that you understand the Red Hat OpenShift certificate rotation schedule to avoid expired certificates.\n\nThe initial certificates that are created during installation expire 24 hours after they are created. IBM's automation process, which installs Red Hat OpenShift, handles the approval of the CSRs for this initial rotation, which is done by running a script on the bastion for the first 30 hours. The script is named \/root\/approve-csr.sh and its log file is named \/root\/approve-csr.log.\n\nFor the script to run successfully, the initial kubeadmin credentials must be the same until the initial certificate rotation is complete. Do not change the kubeadmin credentials for the first 24 hours. If the credentials are changed, you must monitor and approve the CSRs for the initial certificate rotation. For more information, see [Approving the CSRs for your machines](https:\/\/docs.openshift.com\/container-platform\/4.7\/installing\/installing_vsphere\/installing-vsphere.htmlinstallation-approve-csrs_installing-vsphere).\n\nDo not restart any of the Red Hat OpenShift cluster virtual machines (VMs) or the bastion VM until the first certificate rotation is done.\n\nAfter the initial certificate rotation, certificates are renewed every 30 days. You must establish a process to approve the CSRs for every certificate rotation. According to Red Hat\u00ae, you can approve CSRs when they reach 80% of their expiration period, which is approximately 25 days into the lifespan of the CSRs.\n\nIf you do not approve CSRs in time and the certificates expire, you can recover from expired control plane certificates and get the Red Hat OpenShift cluster operational again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_managing"},{"document_id":"ibmcld_06835-3900-5573","score":21.3471526584,"text":"\n* This toolchain uses [Satellite Config](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-cluster-config) to deploy an application to a group of clusters.\n* This toolchain assumes that you have a [Satellite cluster group](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig) with the required clusters.\n* This toolchain supports a Satellite cluster group that contains only one type of cluster (Red Hat\u00ae OpenShift\u00ae).\n\n\n\n\n\n\n\n Deployment \n\nDevSecOps provides out of the box scripts to deploy your application on the group of clusters. You might need to customize these scripts according to your application and cluster group requirements.\n\nThese scripts are located in the deployment repository and are specified in the pipeline-config.yml file.\n\ndeploy:\nimage: icr.io\/continuous-delivery\/pipeline\/pipeline-base-image:2.12@sha256:ff4053b0bca784d6d105fee1d008cfb20db206011453071e86b69ca3fde706a4\nscript: \n!\/usr\/bin\/env bash\n\nif [ \"$PIPELINE_DEBUG\" == 1 ]]; then\ntrap env EXIT\nenv\nset -x\nfi\n\nsource scripts\/deploy_setup.sh\nsource scripts\/deploy.sh\nexport DEPLOY_EXIT=$?\nsource scripts\/doi-publish-deploy.sh\nShow more\n\n\n\n\n\n\n\n Deploying to a custom target \n\nDeploy to a custom target if you want to:\n\n\n\n* Deploy your application on your own choice of infrastructure, such as Virtual Server Instances (VSI).\n* Perform custom tasks, such as updating some configurations in a Red Hat\u00ae OpenShift\u00ae cluster.\n\n\n\nIn these cases, select \"custom\" as a deployment target.\n\n\n\n Performing a custom deployment \n\n\n\n* DevSecOps templates are fully customizable. You can provide your own stages and steps in the pipeline-config.yml file of the deployment repository.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-deployment-target"},{"document_id":"ibmcld_16729-139037-140928","score":20.6583624584,"text":"\nIn this tutorial, you learn how to create and deploy a scalable Java Spring application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Creating an IBM Cloud Satellite environment on AWS by using scripts](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-trysat)Creating an IBM Cloud Satellite environment on AWS by using scripts\n\nThis tutorial and set of scripts provide a mostly automated way to set up an IBM Cloud Satellite location and Red Hat OpenShift cluster on Amazon Web Services (AWS). This is not a production-ready solution, but it provides a useful tool for proof-of-concepts, learning, and experimenting.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 1.5 hours\n* 2022-02-23\n\n\n\n[Part 4: Set up a Continuous Compliance (CC) toolchain](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cc-toolchain)Part 4: Set up a Continuous Compliance (CC) toolchain\n\nThis tutorial is part 4 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 4 of this tutorial series, you use the toolchain template for continuous compliance (CC) to ensure that your deployed artifacts and their source repositories are always compliant.\n\nKubernetes service Continuous Delivery\n\n+1\n\nDevSecOps\n\n\n\n* 1 hour","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_05174-7319-9347","score":20.5936149843,"text":"\nSpecify where you want to install IBM Cloud Pak for Data:\n\n\n\n1. Select the Red Hat OpenShift on IBM Cloud cluster where you want to deploy IBM Cloud Pak for Data.\n2. Enter or select the Red Hat OpenShift on IBM Cloud project where you want to deploy IBM Cloud Pak for Data.\n\n\n\n\n\n\n\n Step 3. Configure your workspace \n\nSpecify how you will track and manage your installation:\n\n\n\n1. Enter or select a name for the installation.\n2. Consider changing the default resource group.\n3. Specify any tags that you want to use for the installation. Specify multiple tags as a comma-separated list.\n\n\n\n\n\n\n\n Step 4. Complete the preinstallation task \n\nA Red Hat OpenShift on IBM Cloud cluster administrator must complete this step. Specifically, the administrator must have an [access](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-users) policy in IBM Cloud Identity and Access Management that has an Operator role or higher.\n\n\n\n* If you are not an administrator, use the Share link to share the script with your cluster administrator.\n* If you are a cluster administrator, click Run script to run the preinstallation set up on your cluster.\n\n\n\nThe preinstallation script makes the following changes to your Red Hat OpenShift on IBM Cloud cluster:\n\n\n\n* Increases the size of the Docker registry to 200 GB. This change increases the cost of your Red Hat OpenShift on IBM Cloud cluster.\n* Creates the security context constraints that are required for IBM Cloud Pak\u00ae for Data.\n* Grants access to the security context constraints to the service accounts that are required for IBM Cloud Pak\u00ae for Data.\n\n\n\nConfirm that the script completes successfully before you proceed.\n\nIf the cluster administrator is not allowed to modify the storage, or the infrastructure account is not the same as the current account, a storage administrator can manually execute the script that is provided in [Complete the preinstallation section](https:\/\/cloud.ibm.com\/catalog\/content\/ibm-cp-datacore-6825cc5d-dbf8-4ba2-ad98-690e6f221701-global).\n\n\n\n\n\n Step 5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-data?topic=cloud-pak-data-getting-started"},{"document_id":"ibmcld_05173-7408-9438","score":20.0847672748,"text":"\n2. Enter or select the Red Hat OpenShift on IBM Cloud project where you want to deploy IBM Cloud Pak for Data.\n\n\n\n\n\n\n\n Step 3. Configure your workspace \n\nSpecify how you will track and manage your installation:\n\n\n\n1. Enter or select a name for the installation.\n2. Consider changing the default resource group.\n3. Specify any tags that you want to use for the installation. Specify multiple tags as a comma-separated list.\n\n\n\n\n\n\n\n Step 4. Complete the preinstallation task \n\nA Red Hat OpenShift on IBM Cloud cluster administrator must complete this step. Specifically, the administrator must have an [access](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-users) policy in IBM Cloud Identity and Access Management that has an Operator role or higher.\n\n\n\n* If you are not an administrator, use the Share link to share the script with your cluster administrator.\n* If you are a cluster administrator, click Run script to run the preinstallation set up on your cluster.\n\n\n\nThe preinstallation script makes the following changes to your Red Hat OpenShift on IBM Cloud cluster:\n\n\n\n* Increases the size of the Docker registry to 200 GB. This change increases the cost of your Red Hat OpenShift on IBM Cloud cluster.\n* Creates the security context constraints that are required for IBM Cloud Pak\u00ae for Data.\n* Grants access to the security context constraints to the service accounts that are required for IBM Cloud Pak\u00ae for Data.\n\n\n\nConfirm that the script completes successfully before you proceed.\n\nIf the cluster administrator is not allowed to modify the storage, or the infrastructure account is not the same as the current account, a storage administrator can manually execute the script that is provided in [Complete the preinstallation section](https:\/\/cloud.ibm.com\/catalog\/content\/ibm-cp-datacore-6825cc5d-dbf8-4ba2-ad98-690e6f221701-global).\n\n\n\n\n\n Step 5. Set the deployment values \n\nChoose a storage class:\n\n\n\n* EnduranceFileStorage - This option uses the storage class ibmc-file-gold-gid to install Cloud Pak for Data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-pak-data"},{"document_id":"ibmcld_07058-6931-8719","score":20.0167111456,"text":"\nwhere {built_connector_zip_file} is the name of the file you packaged in [Compiling and packaging the example connector](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-assemblecompile-package-connector).\n\nIf your Discovery instance is running on Red Hat OpenShift, specify the -o or --openshift parameter with the script.\n\nFor example:\n\nbash scripts\/manage_custom_crawler.sh deploy -z myCrawler.zip -o true\n\n\n\n\n\n\n\n Uninstalling a connector in 4.0.5 and earlier releases \n\nTo uninstall a custom connector from a Discovery instance, run the following command at the root of the unzipped custom-crawler-docs.zip directory:\n\nbash scripts\/manage_custom_crawler.sh undeploy -n {built_connector_name}\n\nwhere {build_connector_name} is the name, not the zip file, of the installed connector.\n\nIf your IBM Watson\u00ae Discovery instance is running on Red Hat OpenShift, specify the -o or --openshift parameter with the script.\n\nbash scripts\/manage_custom_crawler.sh undeploy -n {built_connector_name} -o true\n\n\n\n\n\n Understanding the manage_custom_crawler.sh script in 4.0.5 and earlier releases \n\nThe manage_custom_crawler.sh script has the following internal documentation:\n\nUsage: ${BASH_SOURCE[0]} [--pathToZip PATH] [--properties PROPERTIES] [--xml XML]\n\nWatson Discovery Custom Crawler Manager\n\nThis script will help you deploy, manage, and undeploy your custom crawler for\nWatson Discovery.\n\nSubcommands:\ndeploy Add a new Custom Crawler to your Watson Discovery instance.\nproperties Generate the properties file for your crawler.\nundeploy Undeploy your Custom Crawler by name.\nlist List all Custom Crawlers for your Watson Discovery instance.\n\nOptions:\n-d --discovery The name of the Watson Discovery instance\n-z --zipfile The path to the zip file to be uploaded.\nFor deploy only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-install-connector"},{"document_id":"ibmcld_06726-8970-10659","score":19.841965389,"text":"\n[The Truck Tracker Zoom View](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c1b02d6157702384a9668d8c58bb951e69117793\/databases-for-redis\/includes\/cloud-databases\/includes\/cloud-databases\/images\/trucktrackerzoom.png)\n\nFigure 4. Single-Truck View\n\n\n\n\n\n\n\n What you just did \n\n\n\n The build.sh script \n\nThe build.sh script does a number of things:\n\n\n\n1. It builds a docker image for each of the services you need. The producer, consumers and web application are all in different folders. Each folder has its own simple Dockerfile file that is used by the script to create a container image, which is then uploaded to the IBM Container Registry.\n2. It creates a bunch of kubernetes secrets with all the credentials that are going to be needed to access the different IBM services (IBM Cloudant, Redis and Event Streams).\n3. It deploys the application code (and the secretes) to the Red Hat OpenShift on IBM Cloud cluster using the instructions contained in the deployment.yml script.\n\n\n\n\n\n\n\n The deployment.yml script \n\nThis script tells Openshift what to deploy to the machines in the Openshift cluster. In our case this is:\n\n\n\n1. Data producers (trucktrackerproducer).\n2. Data consumers (trucktrackerredisconsumer and trucktrackercloudantconsumer)\n3. Web application (trucktrackerweb)\n\n\n\nIn all cases, they pull an image from the container registry and get fed some environment variables with the credentials they require to access external services.\n\n\n\n\n\n The Truck Tracker system \n\nThe Truck Tracker system is a set of simple Node.js scripts that use four main packages:\n\n\n\n1. [@ibm-cloud\/cloudant](https:\/\/github.com\/IBM\/cloudant-node-sdk) to connect to IBM Cloudant and read\/write data.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-truck-tracker-ibmcloud"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14492-7-1792","score":23.0272218778,"text":"\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_10154-7-1896","score":22.362386533,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_14497-11060-12784","score":21.6496986084,"text":"\nThe NSX DLR virtual machines are configured as an active - passive pair, and vSphere Distributed Resource Scheduler (DRS) anti-affinity rules are created to ensure that the DLR VMs do not run on the same host. This step is described in [Red Hat OpenShift NSX DLR configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-nsxdlr-intro).\n* Update DNS - The infrastructure DNS, provisioned with the vCenter Server instance is updated with the names and IP addresses for the Red Hat OpenShift components by using a PowerShell script. This step is described in [VMware Solutions DNS configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-dns-intro).\n\n\n\n* Phase 2 - Red Hat OpenShift installation. These steps are described in [Red Hat OpenShift 4.7 user provider infrastructure installation](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-install-intro).\n\n\n\n* A Red Hat virtual machine, the bastion node, is provisioned to run the Red Hat OpenShift installer and to host an HTTP Server. It is registered with Red Hat by using your subscription, and the Red Hat OpenShift installer is downloaded.\n* On the bastion node, the install-config.yaml file is populated with the required Red Hat OpenShift parameters and Red Hat OpenShift ignition is used to generate a number of files used for the installation of the bootstrap, control plane, and worker machines.\n* Terraform, on the bastion node, uses the files that are created by Ignition to create the Red Hat OpenShift VMs.\n\n\n\n* Phase 3 - Post deployment activities. Configure a persistent volume for use by the Red Hat OpenShift cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_14747-73981-75972","score":21.5514531059,"text":"\n* Red Hat OpenShift for VMware v4.4.13\n\n\n\nPromotions for VMware Solutions add-on services\n: IBM Cloud for VMware Solutions offers promotions for some VMware services. Promotional pricing offers a number of months free of charge for a service\u2019s licenses, if the service has license charges.\n\nYou can use one promotion (promo) code for one or more of the following services.\n\n\n\n* Ordering a new VMware vCenter Server\n* Adding a service to an existing vCenter Server\n* Ordering a stand-alone service (license), such as Caveonix or Veeam\n\n\n\nResource requirements for add-on services\n: Capacity checks are performed to ensure that resource requirements are met for services installation. Capacity checks are performed for the following services during instance deployment.\n\n\n\n* Caveonix RiskForesight\n* F5 BIG-IP\n* FortiGate Virtual Appliance\n* HyTrust CloudControl\n* Zerto\n\n\n\nSelecting the target cluster for Red Hat OpenShift for VMware\n: The target cluster for installing Red Hat OpenShift varies with the following scenarios.\n\n\n\n* During deployment, you aren't prompted for the cluster. The service is automatically installed to the management cluster.\n* During Day 2 operations, you are prompted for the cluster. You can install the service to a management cluster or a workload cluster.\n\n\n\nDeleting services from a cluster before deleting the cluster\n: If you remove a nonmanagement cluster that has services installed on it, the services are also deleted as part of the process.\n\nPreviously, when you removed a nonmanagement cluster, for example, an edge services cluster, any services installed on that cluster were not removed. You had to first delete the services from the cluster and then delete the cluster itself.\n\nThis change affects the Juniper vSRX and Red Hat OpenShift for VMware services.\n\nREST APIs\n: APIs are now available for the Red Hat OpenShift for VMware service.\n\nNew and updated documentation\n: A new topic, Resource requirements for add-on services, is now available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vmwaresolutions-relnotes"},{"document_id":"ibmcld_13150-2578-4333","score":21.334726025,"text":"\n* (optional) IBM Cloud GitLab configured with your SSH key.Check the instructions under the Generate an SSH key pair and Add an SSH key to your GitLab account sections of the [documentation here](https:\/\/us-south.git.cloud.ibm.com\/help\/user\/ssh.md)\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools, you can use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console. Use oc version to ensure the version of the Red Hat OpenShift on IBM Cloud CLI matches your cluster version (4.12.x). If they do not match, install the matching version by following [these instructions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorialsgetting-started-cloud-shell).\n\nIn addition, make sure you [set up a registry namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_setup).\n\n\n\n\n\n Step 1: Create an Red Hat OpenShift on IBM Cloud cluster \n\nWith Red Hat OpenShift on IBM Cloud, you have a fast and secure way to containerize and deploy enterprise workloads in Red Hat OpenShift on IBM Cloud clusters. Red Hat OpenShift on IBM Cloud clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nIn this section, you will provision a Red Hat OpenShift on IBM Cloud cluster in one (1) zone with two (2) worker nodes:\n\n\n\n1. Create an Red Hat OpenShift on IBM Cloud cluster from the [IBM Cloud\u00ae catalog](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/create?platformType=openshift).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-scalable-webapp-openshift"},{"document_id":"ibmcld_14497-7-1724","score":20.80712444,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_13145-2436-4270","score":20.6464384718,"text":"\n5. The user securely(HTTPS) accesses the application via browser.\n6. The admin monitors the health and performance of the microservices using the metrics, traces, logs.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI,\n\n\n\n* IBM Cloud Kubernetes Service plugin (kubernetes-service),\n\n\n\n* oc to interact with OpenShift.\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools, you can use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console. Use oc version to ensure the version of the Red Hat OpenShift on IBM Cloud CLI matches your cluster version (4.12.x). If they do not match, install the matching version by following [these instructions](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorialsgetting-started-cloud-shell).\n\n\n\n\n\n Step 1: Create a Red Hat OpenShift on IBM Cloud cluster \n\nWith Red Hat OpenShift on IBM Cloud, you have a fast and secure way to containerize and deploy enterprise workloads in clusters. Red Hat OpenShift on IBM Cloud clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nIn this section, you will provision a Red Hat OpenShift on IBM Cloud cluster in one (1) zone with two (2) worker nodes:\n\n\n\n1. Log into your IBM Cloud account and create a Red Hat OpenShift on IBM Cloud cluster from the [Red Hat OpenShift on IBM Cloud cluster create page](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/create?platformType=openshift).\n2. Set the Orchestration service to 4.12.x version of Red Hat OpenShift on IBM Cloud.\n3. Select your OCP entitlement.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-openshift-service-mesh"},{"document_id":"ibmcld_10258-4105-6088","score":20.6090772907,"text":"\nTo connect to a different VPC or to an on-prem data center, use the [VPN for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpn-onprem-example) service.\n\n\n\n\n\n\n\n Kubernetes community and open source integrations \n\nBecause you own the standard clusters that you create in Red Hat OpenShift on IBM Cloud, you can choose to install third-party solutions to add extra capabilities to your cluster.\n\nSome open source technologies, such as Portworx are tested by IBM and provided as managed add-ons, Helm charts, or IBM Cloud services that are operated by the service provider in partnership with IBM. These open source tools are fully integrated into the IBM Cloud billing and support system.\n\nYou can install other open source tools in your cluster, but these tools might not be managed, supported, or verified to work in Red Hat OpenShift on IBM Cloud.\n\nSupported integrations depend on the container platform, the infrastructure provider, and the cluster type that you choose. For more information, see [Supported IBM Cloud and third-party integrations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrations).\n\n\n\n Integrations operated in partnership \n\nFor more information about Red Hat OpenShift on IBM Cloud partners and the benefit of each solution that they provide, see [Red Hat OpenShift on IBM Cloud partners](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners).\n\n\n\n\n\n Managed add-ons \n\nRed Hat OpenShift on IBM Cloud integrates popular open source integrations by using [managed add-ons](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-managed-addons). Managed add-ons are an easy way to install an open source tool in your cluster that is tested by IBM and approved to be used in Red Hat OpenShift on IBM Cloud.\n\nManaged add-ons are fully integrated into the IBM Cloud support organization. If you have a question or an issue with using the managed add-ons, you can use one of the Red Hat OpenShift on IBM Cloud support channels.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations"},{"document_id":"ibmcld_16729-104404-106143","score":20.5748996959,"text":"\nIf you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster\n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-05-09\n\n\n\n[Creating Red Hat OpenShift on IBM Cloud clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial)Creating Red Hat OpenShift on IBM Cloud clusters\n\nCreate a cluster with worker nodes that come installed with Red Hat OpenShift container orchestration platform.\n\nRed Hat OpenShift on IBM Cloud\n\n\n\n* 45 minutes\n* 2023-07-13\n\n\n\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07\n\n\n\n[Setting capacity quotas for apps that use IBM Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-cos-tutorial-quota)Setting capacity quotas for apps that use IBM Cloud Object Storage","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_14501-7-1869","score":20.4618668675,"text":"\nPrerequisites for installation \n\nBefore you can start the build process to install the Red Hat\u00ae OpenShift\u00ae cluster, the following steps are required.\n\n\n\n* Order new subnets for the Red Hat OpenShift environment.\n\n\n\n* A private portable subnet for the Red Hat OpenShift cluster NSX ESG.\n* A public portable subnet for the Red Hat OpenShift cluster NSX ESG.\n\n\n\n* Download Red Hat OpenShift 4.7 - Access to a Red Hat\u00ae subscription to download the installer, pull secret and Red Hat Enterprise CoreOS OVA.\n* Download RHEL 8.0 ISO - Access to a Red Hat subscription to download the Red Hat Enterprise Linux\u00ae 8.x ISO for the bastion host.\n* IBM Cloud\u00ae environment details - Collect the following details for IBM Cloud for VMware\u00ae Solutions environment.\n\n\n\n* VMware vCenter Server\u00ae instance details and passwords\n* The additional private portable subnet information\n* The additional public portable subnet information\n\n\n\n* Download and install govc - govc is a VMware vSphere\u00ae CLI, an alternative to the GUI, and suited for automation tasks.\n\n\n\n\n\n Ordering new subnets for the Red Hat OpenShift environment \n\n\n\n1. Log in to the [IBM Cloud for VMware Solutions console](https:\/\/cloud.ibm.com\/vmware).\n2. Select Classic Infrastructure>Network>IP management>Subnets.\n3. Click Order IP Subnets.\n\n\n\nReview the following requirements.\n\n\n\n* 8 Public portable addresses assigned to the Public VLAN collected in the previous step.\n* 64 Private portable addresses assigned to the Private VLAN collected in the previous step.\n\n\n\n\n\n\n\n Downloading Red Hat OpenShift 4.7 \n\nAccess the [Red Hat OpenShift Infrastructure Providers page](https:\/\/cloud.redhat.com\/openshift\/install\/vsphere\/user-provisioned).\n\n\n\n1. Download the installer.\n2. Download the Pull Secret.\n3. Download the Red Hat Enterprise Linux CoreOS (RHEL CoreOS) OVA image or download the OVA by using the following code.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-prereq-intro"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14497-7-1724","score":28.0845251294,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_16729-104404-106143","score":27.2508276799,"text":"\nIf you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster\n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-05-09\n\n\n\n[Creating Red Hat OpenShift on IBM Cloud clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial)Creating Red Hat OpenShift on IBM Cloud clusters\n\nCreate a cluster with worker nodes that come installed with Red Hat OpenShift container orchestration platform.\n\nRed Hat OpenShift on IBM Cloud\n\n\n\n* 45 minutes\n* 2023-07-13\n\n\n\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07\n\n\n\n[Setting capacity quotas for apps that use IBM Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-cos-tutorial-quota)Setting capacity quotas for apps that use IBM Cloud Object Storage","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_08259-0-511","score":27.1355941519,"text":"\n\n\n\n\n\n\n  Release notes for Red Hat OpenShift for HPC \n\nUse these release notes to learn about the latest updates to Red Hat\u00ae OpenShift\u00ae for HPC that are grouped by date.\n\n\n\n  March 2022 \n\n\n\n  24 March 2022 \n\nIntroducing Red Hat OpenShift for HPC solutions\n:   You can now take advantage of automated deployment of a Red Hat OpenShift cluster along with a deployer virtual server instance, which allows you to easily assemble, compile, and deploy your HPC applications to the Red Hat OpenShift cluster.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-openshift?topic=hpc-openshift-release-notes"},{"document_id":"ibmcld_16729-218252-220002","score":26.8775897852,"text":"\nA VPC allows you to create your own space in IBM Cloud so that you can run an isolated environment in the public cloud with custom network policies.\n\nVirtual Private Cloud (VPC) Terraform on IBM Cloud\n\n\n\n* 2 hours\n* 2023-04-21\n\n\n\n[Updating VPC worker nodes that use OpenShift Data Foundation](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc)Updating VPC worker nodes that use OpenShift Data Foundation\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster\n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-05-09\n\n\n\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_14497-11060-12784","score":26.7905622353,"text":"\nThe NSX DLR virtual machines are configured as an active - passive pair, and vSphere Distributed Resource Scheduler (DRS) anti-affinity rules are created to ensure that the DLR VMs do not run on the same host. This step is described in [Red Hat OpenShift NSX DLR configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-nsxdlr-intro).\n* Update DNS - The infrastructure DNS, provisioned with the vCenter Server instance is updated with the names and IP addresses for the Red Hat OpenShift components by using a PowerShell script. This step is described in [VMware Solutions DNS configuration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-dns-intro).\n\n\n\n* Phase 2 - Red Hat OpenShift installation. These steps are described in [Red Hat OpenShift 4.7 user provider infrastructure installation](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-install-intro).\n\n\n\n* A Red Hat virtual machine, the bastion node, is provisioned to run the Red Hat OpenShift installer and to host an HTTP Server. It is registered with Red Hat by using your subscription, and the Red Hat OpenShift installer is downloaded.\n* On the bastion node, the install-config.yaml file is populated with the required Red Hat OpenShift parameters and Red Hat OpenShift ignition is used to generate a number of files used for the installation of the bootstrap, control plane, and worker machines.\n* Terraform, on the bastion node, uses the files that are created by Ignition to create the Red Hat OpenShift VMs.\n\n\n\n* Phase 3 - Post deployment activities. Configure a persistent volume for use by the Red Hat OpenShift cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_08014-3143-5139","score":26.6305386719,"text":"\nThe Red Hat OpenShift on IBM Cloud pods that are running the Elasticsearch, Kibana, and Fluentd components are assigned to a worker pool that is dedicated to logging. A dedicated worker pool prevents logging operations from stealing resources from pods that are running other applications. Worker pools are not shown in the diagram.\n\nInstances of the Elasticsearch server are configured to run in all three of the region's zones. The Elasticsearch cluster is configured to replicate data, which is stored in shards, to a second server in the cluster.\n\nThe logging stack that is running in each VPC can also be used to collect application logs from virtual server instances that are using Fluentd. You can collect logs from virtual server instances by using [Fluentd's Elasticsearch plug-in](https:\/\/docs.fluentd.org\/output\/elasticsearch) to forward logs to the logging stack that is running in the Red Hat OpenShift on IBM Cloud cluster.\n\nWhen you configure Red Hat OpenShift on IBM Cloud for both operational logging and operational monitoring, the worker nodes can be shared. You can use the same worker pool for both logging and monitoring. You can use the same taint tag to steer monitoring and logging pods to the shared worker pool.\n\nTo implement your operational logging solution, you need to complete the following high-level steps:\n\n\n\n1. Provision an instance of Red Hat OpenShift on IBM Cloud\n2. Configure the worker pool in your Red Hat OpenShift on IBM Cloud cluster.\n3. Install the Elasticsearch Operator within your Red Hat OpenShift on IBM Cloud cluster.\n4. Install the Cluster Logging Operator within your Red Hat OpenShift on IBM Cloud cluster.\n5. Create a cluster logging instance.\n6. Set up virtual server instance logging with Fluentd.\n\n\n\n\n\n\n\n Before you begin \n\n\n\n* You have a [VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started) provisioned.\n* Subnets are provisioned across three zones within a region.\n\n\n\n\n\n\n\n Step 1: Provision Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-logging-operational-tutorial"},{"document_id":"ibmcld_14682-7-2113","score":26.2974140313,"text":"\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"},{"document_id":"ibmcld_14492-8686-10586","score":26.2160841865,"text":"\n* Before the service is installed in your environment, a check is completed against the available capacity of the target cluster in the environment to ensure that the service components can fit. The storage capacity check applies only to vSAN storage. For NFS clusters, a new NFS datastore, dedicated to Red Hat OpenShift, is added.\n* The cluster is associated with the Red Hat account from the pull secret that is provided.\n* The Latency Sensitivity setting of the Red Hat OpenShift cluster VMs can affect Kubernetes scheduling performance. By default, the setting is set to Normal, but it can be set to High if you encounter Kubernetes performance issues.\n\n\n\n\n\n\n\n Considerations when you delete Red Hat OpenShift for VMware \n\n\n\n* Before you delete Red Hat OpenShift for VMware, you must remove any additional VMs that you created in the ocp directory on VMware. The VMware Solutions automation removes only the items that were deployed during the initial installation of Red Hat OpenShift (VMs, storage, and NSX). Any node that is deployed after the installation is not cleaned up.\n* The VXLAN, DLR, and the Edge Gateway that were created during the initial deployment of Red Hat OpenShift for VMware is deleted. The VMs that you deployed on VXLAN will lose connectivity after the removal of Red Hat OpenShift for VMware starts.\n* If your cluster uses NFS storage, deleting Red Hat OpenShift deletes the NFS datastore that was added during installation.\n* If you are using a vSAN datastore, delete any persistent volumes that you no longer need before you uninstall Red Hat OpenShift. Any volumes that are not deleted will remain in the vSAN storage after the Red Hat OpenShift uninstallation.\n* Before you delete the service, you must remove any personal VMs that were deployed with this service, from the storage. Red Hat OpenShift only orders personal VMs if it\u2019s not vSAN.\n\n\n\n\n\n\n\n Related links","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_14492-7-1792","score":26.068178714,"text":"\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_14492-1397-3188","score":26.0579250136,"text":"\nFor more information, see [Promotions for VMware Solutions services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS\n\n\n\nFor more information about the architecture, see [Red Hat OpenShift architecture](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-redhat-arch).\n\n\n\n Technical specifications for Red Hat OpenShift for VMware \n\nThe following capacity requirements apply only if your vCenter Server instance is using vSAN\u2122 storage. If you are using NFS, a new 2-TB NFS datastore, which is dedicated to Red Hat OpenShift, is ordered.\n\nThe solution topology has the following requirements:\n\n\n\n* 9 CPUs\n* 120 GB RAM\n* 1,170 GB storage\n\n\n\nFor more information about resource requirements and capacity checking, see [Resource requirements for services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-resource-requirements).\n\nTo successfully deploy Red Hat OpenShift for VMware on vCenter Server, you must have a Red Hat account and the pull secret key from your account. All Red Hat accounts have an associated pull secret, which you can retrieve by [logging in to your Red Hat account](https:\/\/cloud.redhat.com\/openshift\/install\/vsphere\/user-provisioned). You must purchase Red Hat support entitlements through Red Hat and, if needed, send information for all Red Hat OpenShift support issues to Red Hat.\n\n\n\n Selection of the target cluster for installation \n\nDuring deployment and Day 2 operations, you are prompted for the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04334-199697-200931","score":16.1077714887,"text":"\n<-- <\/section \"id=\"section-create-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-create-cis-service-instance\" \"> --><-- <section \"id=\"section-delete-cis-service-instance\" \"> --> ibmcloud cis instance-delete Delete a CIS service instance. ibmcloud cis instance-delete INSTANCE -f, --force] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance. Required.-f, --force: Delete instance without prompting for confirmation.<-- <\/section \"id=\"section-delete-cis-service-instance-options\" \"> --><-- <section \"id=\"section-delete-cis-service-instance-examples\" \"> --> Examples Delete cis instance cis-demo ibmcloud cis instance-delete cis-demo -f\n<-- <\/section \"id=\"section-delete-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-delete-cis-service-instance\" \"> --><-- <section \"id=\"section-update-cis-service-instance\" \"> --> ibmcloud cis instance-update Update a CIS service instance. ibmcloud cis instance-update INSTANCE --name NAME] --plan PLAN] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-update-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04183-0-2205","score":15.8092577656,"text":"\n\n\n\n\n\n\n  Securing your data in CIS \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Internet Services, it is important to know exactly what data is stored and encrypted and how to delete any stored personal data.\n\n\n\n  How your data is stored and encrypted in CIS \n\nCIS interacts with Cloudflare services using a channel that is fully encrypted end-to-end using Transport Layer Security (TLS) 1.2. CIS does not store any customer data. Configuration data about your specific CIS configuration is encrypted in transit and at rest. CIS configuration data is deleted on your request through the UI, CLI, or API.\n\n\n\n\n\n  Protecting your sensitive data in CIS \n\nAll data related to CIS configuration is not considered sensitive data. The configuration data is encrypted at rest. No customer-managed keys are managed by the CIS offering. Therefore, neither Key Protect nor Hyper Protect Crypto Services are used.\n\n\n\n  Working with customer-managed keys for CIS \n\nNo customer-managed keys are managed by the CIS offering.\n\n\n\n\n\n\n\n  Deleting your data in CIS \n\nThe CIS configuration data is deleted on request through the UI, CLI or API.\n\n\n\n  Deleting CIS instances \n\nThe CIS data retention policy describes how long your data is stored after you delete the service. The data retention policy is included in the CIS service description, which you can find in [IBM Cloud Terms](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms). When a CIS instance is deleted by the UI, CLI, or API, the instance data is retained for seven days from deletion.\n\nBefore deleting an instance, all the domains in the instance must be removed.\n\nDeleting the CIS instance removes all data.\n\n\n\n\n\n  Restoring deleted data for CIS \n\nCIS can currently restore the deleted instance. After you delete an instance of CIS, you can restore the deleted service instance within the data retention period of seven days. After the seven-day period expires, the service instance is permanently deleted.\n\nTo view which service instances are available for restoration, use the ibmcloud resource reclamations command. To restore a deleted service instance, use the ibmcloud resource reclamation-restore command.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data"},{"document_id":"ibmcld_04334-198873-200152","score":15.4941125899,"text":"\n<-- <\/section \"id=\"section-set-context-cis-service-examples\" \"> --><-- <\/section \"id=\"section-set-context-cis-service-instance\" \"> --><-- <section \"id=\"section-create-cis-service-instance\" \"> --> ibmcloud cis instance-create Create a CIS service instance. ibmcloud cis instance-create INSTANCE_NAME PLAN --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-create-cis-service-instance-options\" \"> --> Command options INSTANCE_NAME: The name of CIS service instance. Required.PLAN: The name or ID of a service plan. Required.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-create-cis-service-instance-options\" \"> --><-- <section \"id=\"section-create-cis-service-instance-examples\" \"> --> Examples Create a standard plan cis instance cis-demo ibmcloud cis instance-create cis-demo standard\n<-- <\/section \"id=\"section-create-cis-service-instance-examples\" \"> --><-- <\/section \"id=\"section-create-cis-service-instance\" \"> --><-- <section \"id=\"section-delete-cis-service-instance\" \"> --> ibmcloud cis instance-delete Delete a CIS service instance. ibmcloud cis instance-delete INSTANCE -f, --force] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04149-3050-4970","score":15.4568954754,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04334-196613-197723","score":15.325662975,"text":"\n! ! ! ! ! ! !\n<-- <section \"id=\"section-delete-ratelimit-rule-options\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.RATELIMIT_RULE_ID: The ID of rate limit rule. Required.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.<-- <\/section \"id=\"section-delete-ratelimit-rule-options\" \"> --><-- <section \"id=\"section-delete-ratelimit-rule-examples\" \"> --> Examples Delete rate limiting rule 372e67954025e0ba6aaa6d586b9e0b60. ibmcloud cis ratelimit-rule-delete 31984fea73a15b45779fa0df4ef62f9b 372e67954025e0ba6aaa6d586b9e0b60 -i \"cis-demo\"\n<-- <\/section \"id=\"section-delete-ratelimit-rule-examples\" \"> --><-- <\/section \"id=\"section-delete-ratelimit-rule\" \"> --><-- <\/section \"id=\"section-ratelimit\" \"> --><-- <section \"id=\"section-resource-instance\" \"> --> Resource instance Manipulate CIS Service instances by using the following instance commands.<-- <section \"id=\"section-list-cis-service-instances\" \"> --> ibmcloud cis instances List all CIS service instances. ibmcloud cis instances --output FORMAT] ! ! ! ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-74160-75348","score":15.3181730493,"text":"\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nDelete a firewall rule.\n\nibmcloud cis firewall-delete dc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -i \"cis-demo\"\nibmcloud cis firewall-delete bc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall-delete 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall-delete e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n Firewall rules \n\nManipulate how firewall rules perform using the following firewall-rules commands:\n\n\n\n ibmcloud cis firewall-rules \n\nRetrieve a list of currently existing firewall-rules for a given DNS domain.\n\nibmcloud cis firewall-rules DNS_DOMAIN_ID [--page PAGE] [--per-page PER_PAGE] [-i, --instance INSTANCE] [ ! ! ! ! ! ! --output FORMAT","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-109828-111095","score":15.2361353993,"text":"\nIf not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-show-glb-monitor-options\" \"> --><-- <section \"id=\"section-show-glb-monitor-examples\" \"> --> Examples Show the details of GLB monitor f1aba936b94213e5b8dca0c0dbf1f9cc. ibmcloud cis glb-monitor f1aba936b94213e5b8dca0c0dbf1f9cc -i \"cis-demo\"\n<-- <\/section \"id=\"section-show-glb-monitor-examples\" \"> --><-- <\/section \"id=\"section-show-glb-monitor\" \"> --><-- <section \"id=\"section-delete-glb-monitor\" \"> --> ibmcloud cis glb-monitor-delete Delete the GLB monitor for a given service instance. ibmcloud cis glb-monitor-delete GLB_MON_ID -i, --instance INSTANCE] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-glb-monitor-options\" \"> --> Command options GLB_MON_ID: The ID of global load balancer monitor. Required.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.<-- <\/section \"id=\"section-delete-glb-monitor-options\" \"> --><-- <section \"id=\"section-delete-glb-monitor-examples\" \"> --> Examples Delete GLB monitor f1aba936b94213e5b8dca0c0dbf1f9cc. ibmcloud cis glb-monitor-delete f1aba936b94213e5b8dca0c0dbf1f9cc -i \"cis-demo\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-31256-32402","score":15.2208487827,"text":"\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet a dns record details in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record-delete \n\nDelete a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-delete DNS_DOMAIN_ID DNS_RECORD_ID [-i, --instance INSTANCE]\n\n\n\n Command options \n\n`DNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE will be used.\n\n\n\n\n\n Examples \n\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-8152-9618","score":15.1833200043,"text":"\nUpdate access certificate a5836c2a7ea72d2e225890caea70ae32.\n\nibmcloud cis access-certificate-update 31984fea73a15b45779fa0df4ef62f9b a5836c2a7ea72d2e225890caea70ae32 --name example --associated-hostnames example.com -i cis-demo\n\n\n\n\n\n\n\n ibmcloud cis access-certificate-delete \n\nDelete an access certificate (Enterprise plan only).\n\nibmcloud cis access-certificate-delete DNS_DOMAIN_ID ACCESS_CERTIFICATE_ID [-i, --instance INSTANCE]\n\nMust clear the associated hostnames before deleting the certificate.\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nACCESS_CERTIFICATE_ID\n: The ID of access certificate. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nDelete access certificate a5836c2a7ea72d2e225890caea70ae32.\n\nibmcloud cis access-certificate-delete 31984fea73a15b45779fa0df4ef62f9b a5836c2a7ea72d2e225890caea70ae32 -i cis-demo\n\n\n\n\n\n\n\n ibmcloud cis access-certificates-settings \n\nGet access certificates settings for a given DNS domain (Enterprise plan only).\n\nibmcloud cis access-certificates-settings DNS_DOMAIN_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-285086-286222","score":15.1368788905,"text":"\nibmcloud cis alert-policy glb-healthcheck-alert-update a2633e68-1a64-2512-a321-b64a17c7db7a --name test1 --emails test1@cn.ibm.com --enabled true --pools all --include-future-pools true -i \"cis-demo\"\n<-- <\/section \"id=\"section-update-glb-healthcheck-alert-examples\" \"> --><-- <\/section \"id=\"section-update-glb-healthcheck-alert\" \"> --><-- <section \"id=\"section-delete-alert-policy\" \"> --> ibmcloud cis alert-policy delete Delete an alert policy. cis alert-policy delete POLICY_ID -i, --instance INSTANCE] -f, --force] ! ! ! ! ! ! ! !\n<-- <section \"id=\"section-delete-alert-policy-options\" \"> --> Command options POLICY_ID: The ID of alert policy. Required.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.-f, --force: Attempt to delete policy without prompting for confirmation.<-- <\/section \"id=\"section-delete-alert-policy-options\" \"> --><-- <section \"id=\"section-delete-alert-policy-examples\" \"> --> Examples delete an alert policy a2633e68-1a64-2512-a321-b64a17c7db7a. ibmcloud cis alert-policy delete a2633e68-1a64-2512-a321-b64a17c7db7a -f -i \"cis-demo\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":33.500211448,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04334-33215-34565","score":28.1036098876,"text":"\nValid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-import \n\nImport your BIND config.\n\nibmcloud cis dns-records-import DNS_DOMAIN_ID --file FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: BIND config to import. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nImport BIND config in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-import 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-export \n\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-31256-32402","score":26.6763342338,"text":"\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet a dns record details in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record-delete \n\nDelete a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-delete DNS_DOMAIN_ID DNS_RECORD_ID [-i, --instance INSTANCE]\n\n\n\n Command options \n\n`DNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE will be used.\n\n\n\n\n\n Examples \n\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04195-6086-8151","score":26.0716330631,"text":"\nBecause CIS doesn't support email traffic by default, you must set the PTR record to the location of your email server. Contact your email provider for assistance.\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, you can click the Edit record option from the menu, which opens a dialog box that you can use to update the record.\n\nAfter you are finished making your changes, select Update record to save them, or Cancel to abort the changes.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, you can select the Delete record option from the menu, which opens a dialog box to confirm the delete process.\n\nYou can select the Delete button to confirm your delete action. Select Cancel if you don't want to delete.\n\n\n\n\n\n Importing and exporting DNS records \n\nDNS records can be imported into and exported from CIS. All files are imported and exported as .txt files in BIND format. Learn more about [BIND format](https:\/\/en.wikipedia.org\/wiki\/Zone_file). Click the overflow menu and select to import or export records.\n\nImport records - By default, a total of 3500 DNS records are allowed (imported and created on CIS). You can import multiple files, one at a time, as long as the total number of records is under the max limit. After importing, you are shown a summary with the number of records successfully added and the number that failed, along with the reason why each record failed.\n\nExport records - Use Export records to create a backup of your zone file, or export it to use with another DNS provider. When this menu option is clicked, the records are downloaded to the location specified by your browser settings (typically the Downloads folder). To select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cis"},{"document_id":"ibmcld_04334-25771-26954","score":25.4835740387,"text":"\nCreate a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-create 31984fea73a15b45779fa0df4ef62f9b --json '{\"name\": \"testCNAME\", \"type\": \"CNAME\", \"content\": \"example.com\"}' -i \"cis-demo\"\nibmcloud cis dns-record-create 31984fea73a15b45779fa0df4ef62f9b --type A --name testA --content \"127.0.0.1\" -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record-update \n\nUpdate a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID (--json @JSON_FILE | JSON_STRING) [-i, --instance INSTANCE] [--output FORMAT]\nibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID [--type TYPE] [--name NAME] [--content CONTENT] [--proxied PROXIED] [--ttl TTL] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID --json-str JSON_STR [-i, --instance INSTANCE] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID --json-file JSON_FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n--name\n: DNS record name.\n\n--type\n: DNS record type.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-20830-22207","score":25.1698140209,"text":"\nibmcloud cis custom-pages [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n`-d, --domain\n: DNS Domain ID.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList existing custom pages for domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis custom-pages -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n DNS record \n\nManipulate how the DNS Record performs using the following dns-record commands:\n\n\n\n ibmcloud cis dns-record-create \n\nCreate a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-create DNS_DOMAIN_ID (--json @JSON_FILE | JSON_STRING) [-i, --instance INSTANCE] [--output FORMAT]\nibmcloud cis dns-record-create DNS_DOMAIN_ID --type TYPE --name NAME --content CONTENT [--ttl TTL] [-i, --instance INSTANCE] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-create DNS_DOMAIN_ID --json-str JSON_STR [-i, --instance INSTANCE] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-create DNS_DOMAIN_ID --json-file JSON_FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--name\n: DNS record name.\n\n--type\n: DNS record type.\n\n--content\n: DNS record content.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-30336-31563","score":25.1202741656,"text":"\nA file contains input JSON data.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nUpdate a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-update 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 --json '{\"name\": \"testCNAME\", \"type\": \"CNAME\", \"content\": \"example.com\"}' -i \"cis-demo\"\nibmcloud cis dns-record-update 31984fea73a15b45779fa0df4ef62f9b 417e8605a72d3e085020b82c93cd7f82 --type A --name testA --content \"127.0.0.1\" -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record \n\nGet a DNS record details for a given domain under a service instance.\n\nibmcloud cis dns-record DNS_DOMAIN_ID DNS_RECORD_ID [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet a dns record details in domain 31984fea73a15b45779fa0df4ef62f9b.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-32129-33511","score":25.0347453565,"text":"\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.\n\nibmcloud cis dns-records DNS_DOMAIN_ID [--type TYPE] [--name NAME] [--content CONTENT] [--page PAGE] [--per-page PER_PAGE] [--order ORDER] [--direction DIRECTION] [--match MATCH] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--type\n: Type of DNS records to display.\n\n--name\n: Value of name field to filter by.\n\n--content\n: Value of content field to filter by.\n\n--page\n: Page number of paginated results.\n\n--per_page\n: Maximum number of DNS records per page.\n\n--order\n: Field by which to order list of DNS records. Valid values are type, name, content, ttl, proxied\n\n--direction\n: Direction in which to order results [ascending or descending order]. Valid values are asc, desc\n\n--match\n: Whether to match all or at least one search parameter. Valid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04148-0-1895","score":24.7122358396,"text":"\n\n\n\n\n\n\n  Getting CIS running with a new subdomain \n\nFollow these steps to practice using CIS with a subdomain or CNAME. This example uses the GoDaddy domain registrar. Your case might be different, depending on which registrar you use.\n\n\n\n1.  Deploy a CIS instance by using the IBM Cloud console or API.\n\nIt is recommended that you mirror the name of your CIS instance with the domain or subdomain.\n2.  Click Let\u2019s get started.\n3.  Enter the subdomain in the Domain name field and click Connect and continue.\n4.  For new subdomains click Next Step, for existing subdomains click Import records.\n5.  Make note the New NS records for entry into the GoDaddy DNS Management system.\n6.  Log in to GoDaddy domain Registrar.\n7.  Navigate to the DNS Management page for the candidate CIS domain. IBM Cloud\u00ae must be updated through the API.\n8.  Click ADD to create an NS Host record for each name server entry provided from CIS.\n9.  Set up a DNS record with the supplied CIS NS Records\n\n\n\n*  Type Nameserver\n*  Host subdomain (the name of the subdomain, for example, subdomain.example.com)\n*  Points to ns004.name.cloud.ibm.com\n*  TTL \u00bd hour\n\n\n\n10. The DNS Management page now reflects the two new NS records for the subdomain.\n11. Go back to the IBM Cloud Internet Services instance.\n12. After the NS Records are DNS propagated, it is reflected in the DNS tools, and you are ready to proceed.\n13. With completed NS propagation, click Check name servers.\n14. CIS starts checking NS configuration for the subdomain and might be in a Pending State.\n\nAny typographical errors in can produce a \"silent\" failure. If your subdomain is in the pending state for more than 30 minutes, you might have an error.\n\n\n\nUpon successful subdomain name server and NS record confirmation, the CIS instance reports Active. Customers are now ready to start configuring the service and routing traffic to their services.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-get-started-new-subdomain"},{"document_id":"ibmcld_04334-26644-27941","score":24.1692625129,"text":"\n[Deprecated] ibmcloud cis dns-record-update DNS_DOMAIN_ID DNS_RECORD_ID --json-file JSON_FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n--name\n: DNS record name.\n\n--type\n: DNS record type.\n\n--content\n: DNS record content.\n\n--ttl\n: Time to live for DNS record. Value of 1 is automatic. The default value is 1.\n\n--proxied\n: Control whether or not traffic should flow through the security and performance functions on CIS. CIS only proxies traffic for A, AAAA, and CNAME records. Valid values: true, false.\n\n--json\n: The JSON file or JSON string used to describe a DNS Record. Supported DNS Record types are: A, AAAA, CNAME, NS, TXT, MX, LOC, SRV, CAA,PTR.\n\n\n\n* For type A, AAAA, CNAME, NS, TXT:\n\n\n\n* The required fields in JSON data are name, type, content.\n* The optional fields are ttl, proxied:\n\n\n\n* proxied Control whether or not traffic should flow through the security and performance functions on CIS. CIS only proxies traffic for A, AAAA, and CNAME records.\n\n\n\n\n\n\n\nSample JSON data:\n\n{\n\"name\": \"testA\",\n\"type\": \"A\",\n\"content\": \"127.0.0.1\",\n\"proxied\": true\n}\n\n{\n\"name\": \"testAAAA\",\n\"type\": \"AAAA\",\n\"content\": \"2001:0db8:0012:0001:3c5e:7354:0000:5db1\",\n\"proxied\": false\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.8772153153,"ndcg_cut_10":0.8772153153}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":18.6270709687,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_05353-20027-21778","score":17.7540629347,"text":"\nIf you use the CIS TLS mode of End-to-End-flexible, you can switch to use the CIS TLS End-to-End CA signed mode, and obtain a CA signed certificate that is created outside of Cloud Internet Services (CIS).\n\n\n\n1. Create the TLS\/SSL certificate outside of CIS. See [How can I obtain a certificate for my custom domain?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingsprepare-custom-domain-cert)\n2. [Create the custom domain mapping](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingscustom-domain) in Code Engine with the certificate chain and the private key.\n3. [Obtain the CNAME record for the custom domain mapping](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingscompleting-custom-domain-cname).\n4. In CIS, update the DNS records to point to your Code Engine project. In CIS, go to the DNS records page (Reliability>DNS) and Add the CNAME record.\n5. Change the CIS mode. Go to the TLS security page (Security>TLS). Select End-to-end CA signed as the TLS mode.\n\n\n\nIf you need to register multiple domains and subdomains, such as example.com and www.example.com, you must repeat the previous steps 2 and 3 for each subdomain. You can consider creating a single certificate that covers more than one domain. However, you can use that single certificate only one time in a region. If you plan to use your custom domains in more than one project in a single region, keep them separate.\n\n\n\n\n\n\n\n Testing your custom domain \n\nAfter the CNAME record updates are published, you can test the application with the custom domain mapping.\n\nWith a browser, call the application by targeting the custom domain by using curl.\n\ncurl -v -X GET https:\/\/www.example.com\n\nExample output\n\nHello World from:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings"},{"document_id":"ibmcld_04334-20830-22207","score":17.0351885434,"text":"\nibmcloud cis custom-pages [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n`-d, --domain\n: DNS Domain ID.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList existing custom pages for domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis custom-pages -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n DNS record \n\nManipulate how the DNS Record performs using the following dns-record commands:\n\n\n\n ibmcloud cis dns-record-create \n\nCreate a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-create DNS_DOMAIN_ID (--json @JSON_FILE | JSON_STRING) [-i, --instance INSTANCE] [--output FORMAT]\nibmcloud cis dns-record-create DNS_DOMAIN_ID --type TYPE --name NAME --content CONTENT [--ttl TTL] [-i, --instance INSTANCE] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-create DNS_DOMAIN_ID --json-str JSON_STR [-i, --instance INSTANCE] [--output FORMAT]\n[Deprecated] ibmcloud cis dns-record-create DNS_DOMAIN_ID --json-file JSON_FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--name\n: DNS record name.\n\n--type\n: DNS record type.\n\n--content\n: DNS record content.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-19715-21120","score":17.0255894082,"text":"\nUpdate basic_challenge page for domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis custom-page-update \"basic_challenge\" \"http:\/\/www.example.com\/example.html\" -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis custom-page \n\nRetrieve a specific custom page.\n\nibmcloud cis custom-page PAGE_ID [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nPAGE_ID\n: The name of the Custom Page type. Valid values: basic_challenge, country_challenge, ip_block, ratelimit_block, serve_stale_content, under_attack, waf_block, waf_challenge, 1000_errors, 500_errors. Required.\n\n-d, --domain\n: DNS Domain ID.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet basic_challenge page for domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis custom-page \"basic_challenge\" -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis custom-pages \n\nRetrieve a list of currently existing custom pages.\n\nibmcloud cis custom-pages [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n`-d, --domain\n: DNS Domain ID.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_05980-10127-11813","score":16.7236891839,"text":"\nTo register your custom domain, work with your Domain Name Service (DNS) provider or [IBM Cloud DNS](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-getting-started). If the apps that you want Ingress to expose are in different namespaces in one cluster, register the custom domain as a wildcard domain, such as .custom_domain.net. Note that domains are limited to 130 characters or fewer in Kubernetes version 1.20 or later.\n2. Define an alias for your custom domain by specifying the IBM-provided subdomain as a Canonical Name record (CNAME). To find the IBM-provided Ingress domain, run ibmcloud ks cluster get --cluster <cluster_name> and look for the Ingress subdomain field.\n\nSpecifying the IBM-provided subdomain as a CNAME is required for automatic health checks to remove any failing IPs from the DNS response, and to ensure that your custom domain updates when you add or remove ALBs.\n\n\n\n\n\n\n\n Creating custom domains for private ALBs \n\nFollow the steps to create a custom domain for private ALBs. Note that custom domains are required to use Ingress with private ALBs.\n\nIf you have a classic cluster with only a private VLAN, you must first configure your own [DNS service that is available on your private network](https:\/\/kubernetes.io\/docs\/tasks\/administer-cluster\/dns-custom-nameservers\/).\n\n\n\n1. Create a custom domain through your DNS service provider. Note that Ingress URLs must be 130 characters or fewer.\n2. Map your custom domain to the private ALBs by adding their IP addresses as A records (classic clusters) or their VPC hostname as a CNAME (VPC clusters). To find the ALB IP addresses (classic) or hostname (VPC), run ibmcloud ks ingress alb ls -c <cluster_name_or_ID>.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-managed-ingress-setup"},{"document_id":"ibmcld_05353-18865-20445","score":16.655116827,"text":"\nTo obtain the CNAME record with the CLI, use the [ibmcloud ce domainmapping get](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-domainmapping-get) command. For example,\n\nibmcloud ce domainmapping get --domain-name www.example.com\n\nExample output\n\nGetting domain mapping 'www.example.com'...\nOK\n\nDomain Name: www.example.com\nCNAME: custom.abcdabcdabc.us-south.codeengine.appdomain.cloud\nTarget Name: myapp\nTarget Type: app\nTLS Secret: mytlssecret\nStatus: ready\n\nAfter you have the CNAME target, you are ready to add the CNAME record entry to the DNS settings of your custom domain. Note that publishing of the CNAME record with the domain registrar can take some time to populate the DNS changes in the internet.\n\n\n\n\n\n How can I use Cloud Internet Services (CIS) with custom domain mapping? \n\nYou cannot use the CIS TLS encryption mode of End-to-End flexible with Code Engine custom domain mappings because this mode uses self-signed certificates that are not allowed. Instead, you can use the default TLS encryption mode of [End-to-End CA signed](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-ca-signed). If you use the CIS TLS mode of End-to-End-flexible, you can switch to use the CIS TLS End-to-End CA signed mode, and obtain a CA signed certificate that is created outside of Cloud Internet Services (CIS).\n\n\n\n1. Create the TLS\/SSL certificate outside of CIS. See [How can I obtain a certificate for my custom domain?](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappingsprepare-custom-domain-cert)\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings"},{"document_id":"ibmcld_04625-7-1865","score":16.5695229138,"text":"\nAdding and using a custom domain \n\nIBM\u00ae Cloud Foundry is deprecated and no longer supported as of 1 June 2023. For more information, see the [deprecation details](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-deprecationdep_details).\n\nDomains provide the URL route that is allocated to your organization in IBM Cloud\u00ae. Custom domains direct requests for your apps to a URL that you own. A custom domain can be a shared domain, a shared subdomain, or a shared domain and host. Unless a custom domain is specified, IBM Cloud uses a default shared domain in the route to your app. You can create and use a custom domain by using either the IBM Cloud console or the command-line interface.\n\nThe default shared domain is mybluemix.net, but appdomain.cloud is another domain option that you can use. For more information about migrating to appdomain.cloud, see [Updating your domain](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-update-domain).\n\nTo use a custom domain, you must register the custom domain on a public DNS server, and then configure the custom domain in IBM Cloud. Next, you must map the custom domain to the IBM Cloud system domain on the public DNS server. After your custom domain is mapped to the system domain, requests for your custom domain are routed to your app in IBM Cloud.\n\n\n\n Adding a custom domain from the IBM Cloud console \n\nComplete these steps to add a custom domain for your org by using the console:\n\n\n\n1. Go to Manage > Account, and select Cloud Foundry orgs.\n2. Click the name of the org for which you're creating a custom domain.\n3. Click the Domains tab to view a list of available domains.\n4. Click Add a domain, enter your domain name, and select the region.\n5. Confirm your updates, and click Add.\n\n\n\n\n\n\n\n Adding the route with the custom domain to an app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-custom-domains"},{"document_id":"ibmcld_04186-9163-11063","score":16.465569911,"text":"\n* [Configure the Ingress for the DNS subdomain](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cismulti-region-k8s-cis-ingress)\n\n\n\n\n\n\n\n Step 3: Configure multi-location load-balancing \n\nYour application is now running in two clusters but it is missing one component for the users to access either clusters transparently from a single entry point.\n\nIn this section, you will configure IBM Cloud Internet Services (CIS) to distribute the load between the two clusters. CIS is a one stop-shop service providing Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your Cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the Ingress Subdomain of the Kubernetes clusters,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the clusters.\n\n\n\n\n\n Register a custom domain with IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. After you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cis"},{"document_id":"ibmcld_04625-2824-4330","score":16.4285192245,"text":"\n* US-SOUTH - api.us-south.cf.cloud.ibm.com\n* US-EAST - api.us-east.cf.cloud.ibm.com\n* EU-DE - api.eu-de.cf.cloud.ibm.com\n* EU-GB - api.eu-gb.cf.cloud.ibm.com\n* AU-SYD - api.au-syd.cf.cloud.ibm.com\n\n\n\n2. Create a custom domain for your organization by typing the following command:\n\nibmcloud app domain-create <MY_ORGNAME> <MY_DOMAIN>\n3. Add the route with the custom domain to an app.\n\nFor Cloud Foundry apps, run the following command:\n\nibmcloud app route-map <MY_APPNAME> <MY_DOMAIN> -n <MY_HOSTNAME>\n\n\n\n\n\n\n\n Mapping the custom domain to the system domain \n\nAfter you configure the custom domain in IBM Cloud, map the custom domain to the IBM Cloud system domain on your registered DNS server:\n\n\n\n1. Set up a 'CNAME' record for the custom domain name on your DNS server. Steps for setting up the CNAME record vary depending on your DNS provider. For example, if you use GoDaddy, you follow the [Domains Help](https:\/\/www.godaddy.com\/help\/add-a-cname-record-19236) guidance from GoDaddy.\n2. Map the custom domain name to the secure endpoint for the IBM Cloud region where your app is running. Use the following region endpoints to provide the URL route that is allocated to your organization in IBM Cloud. For example, point your CNAME to custom-domain.us-east.cf.cloud.ibm.com.\n\nCloud Foundry endpoints:\n\n\n\n* US-SOUTH - custom-domain.us-south.cf.cloud.ibm.com\n* US-EAST - custom-domain.us-east.cf.cloud.ibm.com\n* EU-DE - custom-domain.eu-de.cf.cloud.ibm.com\n* EU-GB - custom-domain.eu-gb.cf.cloud.ibm.com","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-custom-domains"},{"document_id":"ibmcld_01391-9188-11098","score":16.3793794596,"text":"\n* [Configure the Ingress for the DNS subdomain](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cismulti-region-k8s-cis-ingress)\n\n\n\n\n\n\n\n Step 3: Configure multi-location load-balancing \n\nYour application is now running in two clusters but it is missing one component for the users to access either clusters transparently from a single entry point.\n\nIn this section, you will configure IBM Cloud Internet Services (CIS) to distribute the load between the two clusters. CIS is a one stop-shop service providing Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your Cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the Ingress Subdomain of the Kubernetes clusters,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the clusters.\n\n\n\n\n\n Register a custom domain with IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. After you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2371977128,"ndcg_cut_10":0.2371977128}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14311-3835-5367","score":22.7266842806,"text":"\n[Layer 2 bridge setup with a new bridge edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.\n* If you have a larger deployment, deploying a dedicated edge cluster or several edge clusters offers better performance and generally scales better.\n* If you use new edge nodes for bridging, they do not have to be in the same network or POD as the workload edge. Edge nodes are transport nodes and they communicate with the other NSX-T transport nodes (edges or hosts) through Geneve tunnels over layer 3 routed connections by using the IBM Cloud classic network as a transport network.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [VMware vSphere overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview)\n* [Getting started with IBM Cloud Gateway Appliance](https:\/\/cloud.ibm.com\/docs\/gateway-appliance?topic=gateway-appliance-getting-started)\n* [Installing NSX-T edge transport nodes](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.2\/installation\/GUID-5EF2998C-4867-4DA6-B1C6-8A6F8EBCC411.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_14311-2669-4435","score":21.6355299562,"text":"\nIf you use the existing workload edge cluster, you must create the edge bridge profile by using that cluster and change the existing-distributed port group to allow Promiscuous mode and Forged transmits. This setup shares the capacity of the private uplinks from the edge nodes for both private routed and bridged traffic. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-edge-private.\n\nZoom\n\n![Layer 2 bridge setup with workload edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-workload-edge.svg)\n\nFigure 2. Layer 2 bridge setup with workload edge cluster\n\nAlternatively, you can deploy a new edge cluster for bridging. In this case, you must create new edge nodes and create a new edge cluster by using these nodes. When you configure the edge bridge profile, you can then use this edge cluster for bridging only. This alternative scales better, and provides a better dedicated bridging performance. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-bridge.\n\nZoom\n\n![Layer 2 bridge setup with a new bridge edge cluster](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_04107-7548-9466","score":20.8907781071,"text":"\nThese attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address. This allows CIS to ingest, single-pass inspect, and re-encrypt data before sending it to the origin server destination. CIS can also act in DNS-only mode, returning the actual DNS record without obfuscating the IP, which disables DDoS and the other functions of CIS. To enable CIS protections, switch the \"proxy\" slider next to each DNS record to on; to disable protections, switch to off.\n\n\n\n\n\n Unlimited DDoS mitigation \n\nDDoS mitigation is typically an expensive service that can grow in cost when under attack. Unlimited DDoS mitigation is included with CIS at no additional cost.\n\n\n\n\n\n Mitigate Layer 7 attacks (configuration) \n\nThough DDoS is enabled by default in CIS, you can further configure Layer 7 security by:\n\n\n\n* Configuring WAF ruleset sensitivity and response behavior\n* Adding rate limiting\n* Adding firewall rules\n\n\n\nUse these features to customize Layer 7 mitigation of both volumetric and non-volumetric attacks.\n\n\n\n\n\n Mitigate non volumetric attacks \n\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04107-6095-8145","score":19.8912895127,"text":"\nThis tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.\n* Always use HTTPS - Redirects all visitors to the HTTPS version.\n* Email obfuscation - Prevents spam from harvesters and bots that try to access email addresses on your pages.\n* Automatic HTTPS rewrites - Helps fix mixed content by changing http to https for all resources (or links) on your website that can be served with HTTPS.\n* Opportunistic encryption - Allows browsers to benefit from the improved performance of HTTP\/2 by informing them that your site is available over an encrypted connection.\n* Universal SSL - Activates universal SSL certificates from your zone to the edge.\n* True client IP header - Sends the user's IP address in the True-Client-IP header.\n\n\n\n\n\n\n\n Security standards and platform \n\n\n\n* TLS (SHA2 and SHA1)\n* IPv4 and IPv6\n* HTTP\/2\n\n\n\n\n\n\n\n Network attacks and mitigation \n\nGenerally, attacks fall into two categories:\n\n\n\nTable 1. Types of network attacks\n\n Layer-3 or Layer-4 attacks Layer-7 attacks \n\n These attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_14311-7-1811","score":19.8410517852,"text":"\nArchitecture pattern for using layer 2 (L2) bridging with NSX-T \n\nWith layer 2 bridging, you can have a L2 connection to a VLAN-backed port group or a device that is outside of your NSX-T data center deployment. An L2 bridge is also useful in a migration scenario, in which you need to split a subnet across physical and virtual workloads. Or when you run a database cluster on IBM Cloud bare metal servers.\n\nYou can use layer 2 bridging in IBM Cloud by following the principles that are presented in this pattern. You can adapt the pattern based on your needs by following VMware\u00ae best practices and IBM Cloud Classic network capabilities.\n\n\n\n Layer 2 bridging with NSX-T \n\nThe following diagram presents an overview for an architecture pattern for using layer 2 bridging with NSX-T edges in IBM Cloud classic infrastructure.\n\nZoom\n\n![Layer 2 bridging with NSX-T](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/arch-pattern-l2-bridge.svg)\n\nFigure 1. Layer 2 bridging with NSX-T\n\nThe following list is a summary of the architecture pattern deployment:\n\n\n\n1. An L2 bridge requires an Edge cluster and an Edge Bridge profile to be deployed. An Edge Bridge profile specifies which Edge cluster to use for bridging and which Edge transport node acts as the primary and backup bridge.\n2. You need to have a new VLAN for the bridged devices. After the VLAN is provisioned, you can request to trunk the hosts. VLAN must be trunked to all hosts in your cluster through IBM Cloud Classic portal (Classic Infrastructure > Network > Gateway appliances). Then, add the ESX hosts to a wanted NSX-T VLAN transport zone, for example tz-bridge.\n3. On the edge cluster uplink distributed port group, enable Promiscuous mode and Forged transmits for bridging.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"},{"document_id":"ibmcld_15141-6204-8279","score":19.2102370039,"text":"\nThe VPN server receives the username and passcode from the VPN client and makes an IAM call to verify the passcode and permission with IAM policy.\n\n\n\n* The passcode is an one-time password. The user MUST re-generate the passcode for re-connection, even if the re-connection is initiated by the VPN server.\n* The SoftLayer MFA is not supported because SoftLayer MFA enforcement is not done via the browser.\n\n\n\nIf you use user ID\/passcode authentication, maintenance activities force users to re-authenticate by fetching and re-entering the code. The connection is restored only after the new code is entered. This is applicable using stand-alone or HA mode.\n\n\n\n\n\n Client certificate revocation lists \n\nOptionally, you can import a certificate revocation list (CRL), which is a time-stamped list of certificates that have been revoked by a certificate authority (CA). A certificate in a certificate revocation list (CRL) might not be expired, but is no longer trusted by the certificate authority that issued the certificate. The VPN client uses this list to validate digital certificates.\n\nAfter you import a CRL, the VPN client uses this list to validate digital certificates. The CRL is saved as a string (not a file) in the system. If you need to download the CRL in the future, it is renamed as <vpn_server_name>.pem.\n\nFor more information, see [Setting up client-to-server authentication](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-authentication).\n\n\n\n\n\n Transport protocol \n\nThe transport layer oversees the delivery of data from a process on one device to a process on another device. Transport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-vpn-planning"},{"document_id":"ibmcld_05440-3062-4677","score":18.940508487,"text":"\nUse secrets to store sensitive information You can store information, such as passwords and SSH keys in a secret. For more information, see [Working with secrets](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret). \n\n\n\n\n\n Supported TLS versions and cipher suites \n\nThe Code Engine API and application endpoints support transport layer security (TLS) 1.2 (or higher) and the following cipher suites.\n\n\n\n TLS cipher suites \n\n\n\n* ECDHE-ECDSA-AES128-GCM-SHA256\n* ECDHE-ECDSA-AES256-GCM-SHA384\n* ECDHE-RSA-AES128-GCM-SHA256\n* ECDHE-RSA-AES256-GCM-SHA384\n* ECDHE-ECDSA-CHACHA20-POLY1305\n* ECDHE-RSA-CHACHA20-POLY1305\n\n\n\n\n\n\n\n\n\n DDoS protection \n\nCode Engine provides out-of-the-box DDoS protection for your application. Code Engine's DDoS protection is provided by Cloud Internet Services (CIS) at no additional cost to you.\n\nDDoS protection covers System Interconnection (OSI) Layer 3 and Layer 4 (TCP\/IP) protocol attacks, but not Layer 7 (HTTP) attacks.\n\nTo address Layer 7 attacks, you can take the following steps so that your traffic runs through a secure route using your custom domain and is no longer available to the public internet through the Code Engine provided domain.\n\n\n\n1. Obtain your custom domain.\n2. In Code Engine, [create a custom domain mapping](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings) for your app.\n3. Set up an instance of [Cloud Internet Services (CIS)](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) to manage your custom domain.\n4. [Add the custom domain to the CIS instance](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-domain-support).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secure"},{"document_id":"ibmcld_16000-0-2579","score":18.4561851274,"text":"\n\n\n\n\n\n\n  Understanding Internet Communication Protocols \n\nGenerally speaking, a communication protocol is a system of rules that allow two or more entities of a communications system to transmit information. The internet has a large suite of protocols to cover many situations. In creating web-based applications and programming interfaces, software developers commonly use three of these communication protocols to describe the state of the network and the ways that data packets are moved across the network:\n\n\n\n*  ICMP, Internet Control Message Protocol, part of the internet protocol suite defined in RFC 792.\n*  TCP, Transmission Control Protocol\n*  UDP, User Datagram Protocol\n\n\n\nThe protocols that are used for a particular implementation of, say, an API call, can influence the overall behavior of your network. So it is worthwhile to understand the basic differences between them. If you need more information, many good articles are available on the internet with detailed descriptions of the protocols.\n\n\n\n  ICMP \n\nICMP is a control protocol, meaning that it is designed to carry information about the status of the network itself. It is essentially a network layer (OSI layer 3) error-reporting and error-control protocol for the network. The best-known examples of ICMP in practice are the ping and traceroute utilities. The ping utility uses ICMP to probe remote hosts for responsiveness and overall round-trip time of the probe messages. The traceroute utility uses ICMP to discover and trace network routes that the ICMP packets take when they travel to their destination.\n\nWhat developers need to know is that ICMP packets have no TCP or UDP port numbers that are associated with them because port numbers are a layer 4 (transport layer) construct.\n\n\n\n\n\n  TCP and UDP \n\nBoth Transmission Control Protocol (TCP) and User Datagram Protocol (UDP) are OSI layer 4 transport protocols. These protocols are used to pass the actual data. The main difference between TCP and UDP, from a developer's perspective, is how they handle packet order.\n\nTCP is a connection-oriented protocol, it guarantees that all sent packets reach the destination in the correct order.\n\nAlternatively, UDP is a connection-less protocol. Communication is datagram-oriented, so the integrity is guaranteed only on the single datagram. Datagrams reach a destination and can arrive out of order, or possibly they don't arrive at all.\n\nTypically, UDP is used for real-time communication, where a little percentage of the packet loss rate is preferable to the overhead of a TCP connection.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-understanding-icp"},{"document_id":"ibmcld_04122-7-1660","score":18.4345480318,"text":"\nSetting Transport Layer Security (TLS) options \n\nThe Transport Layer Security (TLS) options let you control whether visitors can browse your website over a secure connection, and when they do, how IBM Cloud\u00ae Internet Services connects to your origin server.\n\nUse the latest version of the TLS protocol (TLS 1.3) for improved security and performance by switching from Off to On.\n\n\n\n TLS encryption modes \n\nSet the TLS mode by selecting one of the following options from the Mode list.\n\nThese options are listed in the order from the least secure (Off) to the most secure (End-to-End CA signed).\n\n\n\n* [Off](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-off) (not recommended)\n* [Client-to-Edge](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-client-to-edge) (edge to origin not encrypted, self-signed certificates are not supported)\n* [End-to-End flexible](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-flexible) (edge to origin certificates can be self-signed)\n* [End-to-End CA signed](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-ca-signed) (default and recommended)\n* [HTTPS only origin pull](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-origin-only-pull) (Enterprise only)\n\n\n\n\n\n Off \n\nNo secure connection between your visitor and CIS, and no secure connection between CIS and your web server. Visitors can only view your website over HTTP, and any visitor attempting to connect using HTTPS receives an HTTP 301 Redirect to the plain HTTP version of your website.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-options"},{"document_id":"ibmcld_15141-7808-9997","score":17.7695305169,"text":"\nTransport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP. Sending a message by using UDP takes much less time than using TCP. It performs little error checking and does not add any advantages to IP services except to provide process-to-process communication instead of host-to-host communication.\n* Transmission Control Protocol (TCP)\n\nTransmission Control Protocol (TCP) is a reliable but complex transport-layer protocol. TCP adds connection-oriented features and reliability to IP services.\n\nTCP is a stream delivery service that guarantees delivery of data streams sent from one host to another without duplication or lost data. Since packet transfer is not reliable, a technique known as positive acknowledgment with retransmission is used to guarantee reliability of packet transfers. This fundamental technique requires the receiver to respond with an acknowledgment message as it receives the data.\n\nThe sender keeps a record of each packet it sends, and waits for acknowledgment before sending the next packet. The sender also keeps a timer from when the packet was sent, and retransmits a packet if the timer expires. This timer is needed in case a packet becomes lost or corrupted.\n\n\n\n\n\n\n\n Full versus split-tunnel mode \n\nWhen a VPN connection is set up, an encrypted tunnel is created over the internet to the VPN server. The VPN connection appears as a virtual network interface to the computer in addition to the existing LAN interface. You can now use both interfaces simultaneously by sending the private traffic destined to the VPC inside the VPN tunnel and the public traffic (internet traffic) over the other interface (outside the VPN tunnel). When the traffic is split between the VPN interface and other interfaces, split tunneling is said to be in use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-vpn-planning"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1845756968}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02776-3988-5695","score":16.9720140965,"text":"\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.\n\nThese Service Providers have access to Personal Data only to perform these tasks on Developer\u2019s behalf and are obligated not to disclose or use it for any other purpose.\n\n\n\n\n\n Children's Privacy \n\nThe Permitted Use of the Service does not address anyone under the age of 18 (\"Children\").\n\nDeveloper does not knowingly collect Personal Data from anyone under the age of 18. If Developer becomes aware of the collection or processing of Personal Data from Children without verification of parental consent, Developer will take steps to remove that information from the default settings of App ID.\n\n\n\n\n\n Changes To This Privacy Policy \n\nThis Privacy Policy may be updated from time to time and any changes will be reflected by posting the new Privacy Policy on this page. Before the change becomes effective and updated, notification is made via prominent notice on our Service.\n\nThis Privacy Policy should be reviewed periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\n\n\n\n\n\n Contact Us \n\nFor any questions about this Privacy Policy, please contact the Developer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-privacy-policy"},{"document_id":"ibmcld_08766-9493-11228","score":16.1177166865,"text":"\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.\n\nIn the context of web servers, the TLS\/SSL protocol allows a website to establish the identity. Users of the website can be sure that no one else is masquerading as the website. It is done through a public-private key pair.\n\nHyper Protect Crypto Services provides a way to offload the cryptographic operations that are done during the TLS handshake to establish a secure connection to the web server, while it keeps the TLS\/SSL private key securely stored in the dedicated HSM. In this way, you have control over your TLS\/SSL keys and processing. As a result, security is improved and reputational risk is decreased.\n\nTLS\/SSL offloading to the Hyper Protect Crypto Services HSM enables data in transit protection for web, API, and mobile transactions by using the standard PKCS #11 API. With Hyper Protect Crypto Services, you can integrate TLS\/SSL offloading with other cloud proxies.\n\nFor a tutorial on how to offload the SSL workload to a load balancer such as NGINX while managing keys by using Hyper Protect Crypto Services, see [Using IBM Cloud Hyper Protect Crypto Services to offload NGINX TLS](https:\/\/developer.ibm.com\/components\/ibmz\/tutorials\/use-hyper-protect-crypto-services-to-offload-nginx-tls\/).\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-use-cases"},{"document_id":"ibmcld_08739-11193-12939","score":16.0930626333,"text":"\n* For a tutorial on how to use TDE with Hyper Protect Crypto Services, see\n\n[Tutorial: Using Oracle Transparent Database Encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-tde-pkcs11).\n* For a tutorial on how to use Db2 default encryption with Hyper Protect Crypto Services, see\n\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.\n\nIn the context of web servers, the TLS\/SSL protocol allows a website to establish the identity. Users of the website can be sure that no one else is masquerading as the website. It is done through a public-private key pair.\n\nHyper Protect Crypto Services provides a way to offload the cryptographic operations that are done during the TLS handshake to establish a secure connection to the web server, while it keeps the TLS\/SSL private key securely stored in the dedicated HSM. In this way, you have control over your TLS\/SSL keys and processing. As a result, security is improved and reputational risk is decreased.\n\nTLS\/SSL offloading to the Hyper Protect Crypto Services HSM enables data in transit protection for web, API, and mobile transactions by using the standard PKCS #11 API. With Hyper Protect Crypto Services, you can integrate TLS\/SSL offloading with other cloud proxies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-uko-use-cases"},{"document_id":"ibmcld_13616-13587-15670","score":15.937408345,"text":"\n[https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html)\n\n\n\n\n\n Data Privacy and Subject Rights \n\n\n\n* IBM Privacy Statement\n\n\n\nIBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\n\n\n* Right to Lodge a Complaint\n\n\n\nIn the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\n\n\n* IBM TRIRIGA Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\n\n\n* IBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the TRIRIGA Application Suite applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n* IBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n\n\n DDoS Protection \n\n\n\n* IBM Cloud provides DDoS (Distributed Denial of Service) protection for its environment, designed to protect the entire network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tas-ms?topic=tas-ms-security"},{"document_id":"ibmcld_09852-23029-24933","score":15.7371386358,"text":"\n* Message Integrity: Enables authentication of inbound traffic on a per-message basis, as well as strict restrictions on which queues those messages can be sent to and which recipients can receive them.\n* Message Privacy: Based on the protection policy set on the target queue, AMS encrypts the message even before it is placed on the queue, thus ensuring that its contents are never exposed.\n\n\n\nDemonstration of end to end message security involves demonstrating message integrity and message privacy. We start by demonstrating message integrity, where we can see that non-authorized users are not allowed to access the protected queue. We then check if the authorized users, from our example, alice and bob can send and receive messages on protected queue. We conclude by demonstrating that messages while at rest in the protected queue are encrypted and not readable.\n\n\n\n Message Integrity Check \n\nTo demonstrate that message integrity is protected, any attempt to access the protected queue without complying to the signing or encryption policy shall fail. To test this, we run the sender program without setting the environment variable MQS_KEYSTORE_CONF. By doing so, AMS will fail to find the keystore and certificate to use for signing.\nYou can observe that alice is able to establish connection with the queue manager, but an attempt to open the protected queue will fail as this is the point where the AMS interceptor would check the identity for user alice.\n\n\n\n1. Create the following environment variables in alice's command shell.\n\nOn Mac:\nexport MQSAMP_USER_ID=alice\nexport MQSERVER=\"CLOUD.ADMIN.SVRCONN\/TCP\/<HOSTNAME>(<PORT>)\"\n\nOn Linux:\nexport MQSAMP_USER_ID=alice\nexport MQSERVER=\"CLOUD.ADMIN.SVRCONN\/TCP\/<HOSTNAME>(<PORT>)\"\n\nOn Windows:\nset MQSAMP_USER_ID=alice\nset MQSERVER=CLOUD.ADMIN.SVRCONN\/TCP\/<HOSTNAME>(<PORT>)\n\n\n\n* <HOSTNAME> - this is 'hostname' in the file connection_info.txt","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_app_ams"},{"document_id":"ibmcld_12297-14875-16224","score":15.6568090525,"text":"\n* [Creating network zones by using the CBR UI](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-zone-ui)\n\n\n\n* [Understanding network rules](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-network-rules)\n\n\n\n* [Create network rules by using the CBR API](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-rules-api)\n* [Creating network rules by using the CBR UI](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-rules-ui)\n\n\n\n* [Next steps](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-next-steps)\n\n\n\n[Data privacy and governance](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-data-privacy-and-governancedata-privacy-and-governance)\n\n[General Data Protection Regulation (GDPR)](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprgeneral-data-protection-regulation-gdpr)\n\n\n\n* [How do you audit access to Schematics?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprhow-do-i-audit-access-to-ibm-schematics)\n* [Supporting classifications of personal data](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprsupported-classifications-of-personal-data)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"},{"document_id":"ibmcld_08766-8126-10005","score":15.607816918,"text":"\n[IBM Db2 default encryption by using the standard PKCS #11 API](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/hs-crypto\/\/images\/pkcs-db2.svg)\n\nFigure 5. IBM Db2 default encryption by using the standard PKCS #11 API\n\n\n\nWith the PKCS #11 library integration, Hyper Protect Crypto Services supports the industry-standard PKCS #11 API. The Hyper Protect Crypto Services PKCS #11 library connects your database to Hyper Protect Crypto Services to perform cryptographic operations. The database system can invoke operations to manage the TDE master encryption keys or the master keys in the Hyper Protect Crypto Services PKCS #11 library. The Hyper Protect Crypto Services PKCS #11 library then interacts with your Hyper Protect Crypto Services instance to provide the highest level of security for storing and managing your TDE master encryption keys or your master keys in the cloud. It, in turn, provides the highest level of security to your data encryption keys and your data.\n\n\n\n* For a tutorial on how to use TDE with Hyper Protect Crypto Services, see\n\n[Tutorial: Using Oracle Transparent Database Encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-tde-pkcs11).\n* For a tutorial on how to use Db2 default encryption with Hyper Protect Crypto Services, see\n\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-use-cases"},{"document_id":"ibmcld_09060-4951-6938","score":15.3199763544,"text":"\nThe unique identifier of the target key ring that you would like the newly create key to be a part of. If unspecified, the header is automatically set to 'default' and the key will sit in the default key ring in the specified Key Protect service instance. For more information, see [Grouping keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys). \n correlation_ID Optional.The unique identifier that is used to track and correlate transactions. \n return_preference A header that alters server behavior for POST and DELETE operations. When you set the return_preference variable to return=minimal, the service returns only the key metadata, such as the key name and ID value, in the response entity-body. When you set the variable to return=representation, the service returns both the key material and the key metadata. \n key_name Required. A human-readable name for convenient identification of your key. To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional.One or more unique, human-readable aliases assigned to your key. Important: To protect your privacy, do not store your personal data as metadata for your key. Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be between 2 - 90 characters (inclusive). \n key_description Optional.An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-standard-keys"},{"document_id":"ibmcld_12035-7-1995","score":15.2429611162,"text":"\nCompliance \n\nIBM Cloud\u00ae Schematics actively participates in several industry compliance programs. As compliance focal, you can use the Schematics goals to check that your organization is adhering to the external and internal standards for your industry. For more information about monitoring compliance, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nTo monitor your resources with Schematics, see [Managing security and compliance with Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-monitoring-instances).\n\n\n\n General Data Protection Regulation (GDPR) readiness \n\nAbout GDPR and how Schematics adheres to it, see [General Data Protection Regulation](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdpr). View [IBM's commitment to GDPR readiness](https:\/\/www.ibm.com\/data-responsibility\/gdpr\/) to learn about IBM's GDPR readiness journey and the GDPR capabilities and offerings to support your compliance journey.\n\n\n\n\n\n Privacy shield \n\nSchematics is privacy shield that is certified. For more information, see the [IBM Privacy Shield Privacy Policy for Certified IBM Cloud Services](https:\/\/www.ibm.com\/us-en\/privacy\/privacy-shield).\n\n\n\n\n\n International Organization for Standardization (ISO) \n\nSchematics is audited by a Third-party security firm and meet ISO 27001, ISO 27017, ISO 27018, and ISO 27701 requirements. For more information, see the [Schematics Compliance page](https:\/\/www.ibm.com\/cloud\/compliance) for links to the certificates. The following descriptions on the Schematics compliance page cover the Schematics service and respective certifications:\n\n\n\n* IBM Cloud Services (PaaS and SaaS) certified cloud product listing\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27001\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27017\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27018","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-compliance"},{"document_id":"ibmcld_04997-3175-3972","score":15.0973169185,"text":"\nSee [IBM Cloud Docs: Enabling the HIPAA Supported setting](https:\/\/cloud.ibm.com\/docs\/account?topic=account-eu-hipaa-supportedenabling-hipaa) for additional information.\n\n\n\n\n\n General Data Protection Regulation (GDPR) readiness \n\nPlease visit [IBM's commitment to GDPR readiness](https:\/\/www.ibm.com\/data-responsibility\/gdpr\/) page to learn about IBM\u2019s GDPR readiness journey and our GDPR capabilities and offerings to support your compliance journey.\n\n\n\n* [IBM Data Processing Addendum (DPA)](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=dpa)\n\n\n\n\n\n\n\n Privacy shield \n\nIBM Cloud Object Storage is privacy shield certified. For more information please visit [IBM Privacy Shield Privacy Policy for Certified IBM Cloud Services](https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-compliance"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04107-7548-9466","score":14.351477754,"text":"\nThese attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address. This allows CIS to ingest, single-pass inspect, and re-encrypt data before sending it to the origin server destination. CIS can also act in DNS-only mode, returning the actual DNS record without obfuscating the IP, which disables DDoS and the other functions of CIS. To enable CIS protections, switch the \"proxy\" slider next to each DNS record to on; to disable protections, switch to off.\n\n\n\n\n\n Unlimited DDoS mitigation \n\nDDoS mitigation is typically an expensive service that can grow in cost when under attack. Unlimited DDoS mitigation is included with CIS at no additional cost.\n\n\n\n\n\n Mitigate Layer 7 attacks (configuration) \n\nThough DDoS is enabled by default in CIS, you can further configure Layer 7 security by:\n\n\n\n* Configuring WAF ruleset sensitivity and response behavior\n* Adding rate limiting\n* Adding firewall rules\n\n\n\nUse these features to customize Layer 7 mitigation of both volumetric and non-volumetric attacks.\n\n\n\n\n\n Mitigate non volumetric attacks \n\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04107-7-1956","score":13.6238817275,"text":"\nAbout IBM Cloud Internet Services \n\nIBM Cloud\u00ae Internet Services, powered by Cloudflare, provides a fast, highly performant, reliable, and secure internet service for customers running their business on IBM Cloud.\n\nIBM CIS gets you started quickly by establishing defaults for you, which you can change easily by using the UI or API.\n\n\n\n Clock synchronization \n\nISO 27001 requires that clocks of all relevant information processing systems within an organization or security domain must be synchronized with a single reference time source. CIS synchronizes the systems with a Network Time Protocol (NTP) server to ensure that all time-based activities occur synchronously everywhere on the network.\n\nIBM CIS uses the following internal NTP servers:\n\n\n\n* time.adn.networklayer.com\/\n* time.service.networklayer.com\n\n\n\n\n\n\n\n Security features \n\nProxy your [DNS records](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-dns-conceptsdns-concepts-proxying-dns-records) or a [global load balancer](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-global-load-balancer-glb-concepts) to use the security features. The proxy allows traffic to flow through our servers and you can monitor the data.\n\nZoom\n\n![security graphic](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/images\/security-graphic.png)\n\nFigure 1. Security features\n\n\n\n TLS \n\nProtect your site and control your Transport Layer Security (TLS) settings. Manage the certificates used to secure traffic to your site.\n\n\n\n\n\n Origin \n\nManage the TLS certificates that encrypt traffic between your origin server and your users.\n\n\n\n\n\n Rate limiting \n\nUse rate limiting rules to protect your site or API from malicious traffic by blocking client IP addresses that match a URL pattern or exceed a defined threshold.\n\n\n\n\n\n Traffic scrubbing \n\nCIS offers 192 Tbps of global network edge capacity and can mitigate DDoS attacks that have extremely high packet and HTTP request rates.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_05440-3062-4677","score":12.6079450574,"text":"\nUse secrets to store sensitive information You can store information, such as passwords and SSH keys in a secret. For more information, see [Working with secrets](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret). \n\n\n\n\n\n Supported TLS versions and cipher suites \n\nThe Code Engine API and application endpoints support transport layer security (TLS) 1.2 (or higher) and the following cipher suites.\n\n\n\n TLS cipher suites \n\n\n\n* ECDHE-ECDSA-AES128-GCM-SHA256\n* ECDHE-ECDSA-AES256-GCM-SHA384\n* ECDHE-RSA-AES128-GCM-SHA256\n* ECDHE-RSA-AES256-GCM-SHA384\n* ECDHE-ECDSA-CHACHA20-POLY1305\n* ECDHE-RSA-CHACHA20-POLY1305\n\n\n\n\n\n\n\n\n\n DDoS protection \n\nCode Engine provides out-of-the-box DDoS protection for your application. Code Engine's DDoS protection is provided by Cloud Internet Services (CIS) at no additional cost to you.\n\nDDoS protection covers System Interconnection (OSI) Layer 3 and Layer 4 (TCP\/IP) protocol attacks, but not Layer 7 (HTTP) attacks.\n\nTo address Layer 7 attacks, you can take the following steps so that your traffic runs through a secure route using your custom domain and is no longer available to the public internet through the Code Engine provided domain.\n\n\n\n1. Obtain your custom domain.\n2. In Code Engine, [create a custom domain mapping](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings) for your app.\n3. Set up an instance of [Cloud Internet Services (CIS)](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) to manage your custom domain.\n4. [Add the custom domain to the CIS instance](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-domain-support).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secure"},{"document_id":"ibmcld_04122-7-1660","score":12.263651719,"text":"\nSetting Transport Layer Security (TLS) options \n\nThe Transport Layer Security (TLS) options let you control whether visitors can browse your website over a secure connection, and when they do, how IBM Cloud\u00ae Internet Services connects to your origin server.\n\nUse the latest version of the TLS protocol (TLS 1.3) for improved security and performance by switching from Off to On.\n\n\n\n TLS encryption modes \n\nSet the TLS mode by selecting one of the following options from the Mode list.\n\nThese options are listed in the order from the least secure (Off) to the most secure (End-to-End CA signed).\n\n\n\n* [Off](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-off) (not recommended)\n* [Client-to-Edge](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-client-to-edge) (edge to origin not encrypted, self-signed certificates are not supported)\n* [End-to-End flexible](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-flexible) (edge to origin certificates can be self-signed)\n* [End-to-End CA signed](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-ca-signed) (default and recommended)\n* [HTTPS only origin pull](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-origin-only-pull) (Enterprise only)\n\n\n\n\n\n Off \n\nNo secure connection between your visitor and CIS, and no secure connection between CIS and your web server. Visitors can only view your website over HTTP, and any visitor attempting to connect using HTTPS receives an HTTP 301 Redirect to the plain HTTP version of your website.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-options"},{"document_id":"ibmcld_04107-6095-8145","score":12.2324120148,"text":"\nThis tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.\n* Always use HTTPS - Redirects all visitors to the HTTPS version.\n* Email obfuscation - Prevents spam from harvesters and bots that try to access email addresses on your pages.\n* Automatic HTTPS rewrites - Helps fix mixed content by changing http to https for all resources (or links) on your website that can be served with HTTPS.\n* Opportunistic encryption - Allows browsers to benefit from the improved performance of HTTP\/2 by informing them that your site is available over an encrypted connection.\n* Universal SSL - Activates universal SSL certificates from your zone to the edge.\n* True client IP header - Sends the user's IP address in the True-Client-IP header.\n\n\n\n\n\n\n\n Security standards and platform \n\n\n\n* TLS (SHA2 and SHA1)\n* IPv4 and IPv6\n* HTTP\/2\n\n\n\n\n\n\n\n Network attacks and mitigation \n\nGenerally, attacks fall into two categories:\n\n\n\nTable 1. Types of network attacks\n\n Layer-3 or Layer-4 attacks Layer-7 attacks \n\n These attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_08766-9493-11228","score":12.1395527212,"text":"\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.\n\nIn the context of web servers, the TLS\/SSL protocol allows a website to establish the identity. Users of the website can be sure that no one else is masquerading as the website. It is done through a public-private key pair.\n\nHyper Protect Crypto Services provides a way to offload the cryptographic operations that are done during the TLS handshake to establish a secure connection to the web server, while it keeps the TLS\/SSL private key securely stored in the dedicated HSM. In this way, you have control over your TLS\/SSL keys and processing. As a result, security is improved and reputational risk is decreased.\n\nTLS\/SSL offloading to the Hyper Protect Crypto Services HSM enables data in transit protection for web, API, and mobile transactions by using the standard PKCS #11 API. With Hyper Protect Crypto Services, you can integrate TLS\/SSL offloading with other cloud proxies.\n\nFor a tutorial on how to offload the SSL workload to a load balancer such as NGINX while managing keys by using Hyper Protect Crypto Services, see [Using IBM Cloud Hyper Protect Crypto Services to offload NGINX TLS](https:\/\/developer.ibm.com\/components\/ibmz\/tutorials\/use-hyper-protect-crypto-services-to-offload-nginx-tls\/).\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-use-cases"},{"document_id":"ibmcld_08739-11193-12939","score":12.1225320483,"text":"\n* For a tutorial on how to use TDE with Hyper Protect Crypto Services, see\n\n[Tutorial: Using Oracle Transparent Database Encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-tde-pkcs11).\n* For a tutorial on how to use Db2 default encryption with Hyper Protect Crypto Services, see\n\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.\n\nIn the context of web servers, the TLS\/SSL protocol allows a website to establish the identity. Users of the website can be sure that no one else is masquerading as the website. It is done through a public-private key pair.\n\nHyper Protect Crypto Services provides a way to offload the cryptographic operations that are done during the TLS handshake to establish a secure connection to the web server, while it keeps the TLS\/SSL private key securely stored in the dedicated HSM. In this way, you have control over your TLS\/SSL keys and processing. As a result, security is improved and reputational risk is decreased.\n\nTLS\/SSL offloading to the Hyper Protect Crypto Services HSM enables data in transit protection for web, API, and mobile transactions by using the standard PKCS #11 API. With Hyper Protect Crypto Services, you can integrate TLS\/SSL offloading with other cloud proxies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-uko-use-cases"},{"document_id":"ibmcld_05275-6041-7982","score":11.9950310621,"text":"\nApplications follow the scale-to-zero model, where no instances are created in the absence of traffic, leading to cost optimization. When there is an incoming request, an app automatically scales up from zero to accommodate the workload.\n\nWith Code Engine, you can control autoscaling by setting the minimum and maximum number of instances. You can also specify the concurrency of the application by specifying the number of requests to run in parallel for a specific application instance, to help determine when a new instance is provisioned.\n\nFor more information about scaling your app, see [Configuring application scaling](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-app-scale).\n\n\n\n\n\n Security \n\nCode Engine provides out-of-the-box DDOS protection for your application. Code Engine's DDOS protection is provided by Cloud Internet Services (CIS) at no additional cost to you. DDoS protection covers System Interconnection (OSI) Layer 3 and Layer 4 (TCP\/IP) protocol attacks, but not Layer 7 (HTTP) attacks. See [DDoS protection](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-securesecure-ddos).\n\nCode Engine also provides a service mesh to use its networking layer, which enables mutual Transport Layer Security (TLS) traffic on applications, thus securing service-to-service and user-to-service communication.\n\nFor more information about security, see [Code Engine and security](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secure).\n\n\n\n\n\n Triggering applications with events \n\nYou can subscribe Code Engine applications to receive cron events, IBM Cloud Object Storage events or Kafka topics. When you subscribe to an event producer, you must specify the name of your destination application to receive the events.\n\nFor more information about working with event producers, see [Getting started with subscriptions](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-subscribing-events).\n\n\n\n\n\n Visibility","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-ceapplications"},{"document_id":"ibmcld_05277-6235-8105","score":11.9651158011,"text":"\nFor more information about creating and invoking Functions, see [Working with Functions in Code Engine](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-work).\n\n\n\n\n\n Security \n\nCode Engine provides out-of-the-box DDOS protection for your Function. Code Engine's DDOS protection is provided by Cloud Internet Services (CIS) at no additional cost to you. DDoS protection covers System Interconnection (OSI) Layer 3 and Layer 4 (TCP\/IP) protocol attacks, but not Layer 7 (HTTP) attacks. See [DDoS protection](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-securesecure-ddos).\n\nCode Engine also provides a service mesh to use its networking layer, which enables mutual Transport Layer Security (TLS) traffic for Functions, thus securing service-to-service and user-to-service communication.\n\nFor more information about security, see [Code Engine and security](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secure).\n\n\n\n\n\n Invocation concurrency and scaling of Function instances \n\nWhen multiple Functions are being invoked at the same time, Code Engine initializes new Function instances for each invocation, but at the same time, tries to maximize the reuse. Only one Function invocation is handled by a Function instance at a single point in time. For Node.js, the Function can be configured with concurrency > 0 to allow multiple invocations to be handled in a single Function instance.\n\n\n\n\n\n Packaging your source code for a Function \n\nFunctions can be packaged in three different ways.\n\n\n\n* as a single file\n* as multiple files (with a folder structure and dependent modules)\n* as a container image\n\n\n\n\n\n\n\n\n\n How can I get started with Functions? \n\nTo deploy a simple Code Engine application with a hello-world sample image, see [Running IBM Code Engine Functions](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-tutorial) tutorial.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cefunctions"},{"document_id":"ibmcld_04195-7739-8817","score":11.9107336008,"text":"\nTo select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).\n\nDNSSec adds a layer of authentication to the internet's DNS infrastructure, which otherwise is not secure. Secure DNS guarantees that visitors are directed to your web server when they type your domain name into a web browser. All you need to do is enable DNSSec in your DNS page from your IBM CIS account and add the DS record to your registrar.\n\nYou can select View DS records to display the information needed to add the DS record to your registrar. You must copy parts of the DS record and paste them into your registrar\u2019s dashboard. Every registrar is different, and your registrar might only require you to enter information for some of the available fields.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cis"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.2021073465}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04334-84318-85504","score":21.1166977348,"text":"\nibmcloud cis firewall-rule-update 31984fea73a15b45779fa0df4ef62f9b 372e67954025e0ba6aaa6d586b9e0b60 --json '{\"expression\": \"ip.src eq 93.184.216.1 and http.request.uri.path \"^.\/wp-login.php$\"\", \"action\": \"allow\", \"priority\": 100, \"paused\": false, \"description\": \"do not challenge login from office\"}' -i \"cis-demo\"\n<-- <\/section \"id=\"section-update-a-firewall-rule-examples\" \"> --><-- <\/section \"id=\"section-update-a-firewall-rule\" \"> --><-- <section \"id=\"section-delete-a-Firewall-rule\" \"> --> ibmcloud cis firewall-rule-delete Delete a specific firewall-rule for a given DNS domain. ibmcloud cis firewall-rule-delete DNS_DOMAIN_ID FIREWALL_RULE_ID -i, --instance INSTANCE] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-a-firewall-rule-options\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.FIREWALL_RULE_ID: The ID of firewall-rule. Required.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.<-- <\/section \"id=\"section-delete-a-firewall-rule-options\" \"> --><-- <section \"id=\"section-delete-a-firewall-rule-examples\" \"> --> Examples Delete firewall-rule 372e67954025e0ba6aaa6d586b9e0b60.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-80476-81744","score":21.0997899757,"text":"\nibmcloud cis firewall-rule-create 31984fea73a15b45779fa0df4ef62f9b --json '{\"expression\": \"ip.src eq 93.184.216.1 and http.request.uri.path \"^.\/wp-login.php$\"\", \"action\": \"allow\", \"priority\": 100, \"paused\": false, \"description\": \"do not challenge login from office\"}' -i \"cis-demo\"\n<-- <\/section \"id=\"section-create-a-firewall-rule-examples\" \"> --><-- <\/section \"id=\"section-create-a-firewall-rule\" \"> --><-- <section \"id=\"section-update-a-firewall-rule\" \"> --> ibmcloud cis firewall-rule-update Update a specific firewall-rule for a given DNS domain. ibmcloud cis firewall-rule-update DNS_DOMAIN_ID FIREWALL_RULE_ID --expression EXPRESSION] --action ACTION] --priority PRIORITY] --paused on|off] --description DESCRIPTION] -i, --instance INSTANCE] --output FORMAT]\nibmcloud cis firewall-rule-update DNS_DOMAIN_ID FIREWALL_RULE_ID (--json @JSON_FILE | JSON_STRING) -i, --instance INSTANCE] --output FORMAT]\nDeprecated] ibmcloud cis firewall-rule-update DNS_DOMAIN_ID FIREWALL_RULE_ID (-s, --json-str JSON_STR | -j, --json-file JSON_FILE) -i, --instance INSTANCE] --output FORMAT] ! !!!!!! ! ! ! ! !\n<-- <section \"id=\"section-update-a-firewall-rule-options\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.FIREWALL_RULE_ID: The ID of firewall-rule.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-73111-74523","score":20.569941638,"text":"\nibmcloud cis firewall 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis firewall-delete \n\nDelete a firewall rule by ID.\n\nibmcloud cis firewall-delete FIREWALL_RULE_ID (-t, --type Type) [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nFIREWALL_RULE_ID\n: The ID of firewall rule. Required.\n\n-t, --type\n: Type of firewall rule to create. Valid values: access-rules, ua-rules, lockdowns. Required.\n\n\n\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nDelete a firewall rule.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-70962-72477","score":20.4835100912,"text":"\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n--page\n: Page number of paginated results. The default value is 0.\n\n--per-page\n: Maximum number of access rules per page. The minimum value is 5. The default value is 20.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList firewall rules.\n\nibmcloud cis firewalls -t access-rules -i \"cis-demo\"\nibmcloud cis firewalls -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewalls -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis firewall \n\nGet details of a firewall rule.\n\nibmcloud cis firewall FIREWALL_RULE_ID (-t, --type Type) [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nFIREWALL_RULE_ID\n: The ID of firewall rule. Required.\n\n-t, --type\n: Type of firewall rule to create. Valid values: access-rules, ua-rules, lockdowns.\n\n\n\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-72037-73413","score":20.0454116811,"text":"\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet firewall rule details.\n\nibmcloud cis firewall dc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -i \"cis-demo\"\nibmcloud cis firewall bc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis firewall-delete \n\nDelete a firewall rule by ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-76051-77163","score":20.0234258397,"text":"\nibmcloud cis firewall-rules 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n<-- <\/section \"id=\"section-list-firewall-rules-examples\" \"> --><-- <\/section \"id=\"section-list-firewall-rules\" \"> --><-- <section \"id=\"section-show-a-firewall-rule\" \"> --> ibmcloud cis firewall-rule Retrieve a specific firewall-rule for a given DNS domain. ibmcloud cis firewall-rule DNS_DOMAIN_ID FIREWALL_RULE_ID -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-show-a-firewall-rule-options\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.FIREWALL_RULE_ID: The ID of firewall-rule. Required.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-show-a-firewall-rule-options\" \"> --><-- <section \"id=\"section-show-a-firewall-rule-examples\" \"> --> Examples Get the details of firewall-rule 372e67954025e0ba6aaa6d586b9e0b60. ibmcloud cis firewall-rule 31984fea73a15b45779fa0df4ef62f9b 372e67954025e0ba6aaa6d586b9e0b60 -i \"cis-demo\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04109-1462-2676","score":19.9663447871,"text":"\nExempts matching requests from evaluation, based on a user-defined list that contains one or more of the following features: Browser Integrity Check, Domain Lockdown, Hotlink Protection, Rate Limiting, Security Level, User Agent Block, WAF Managed Rules. Matching requests are still subject to evaluation within Firewall Rules, based on order of execution. 2 \n Allow <br><br> * Firewall rules<br> * IP firewall<br><br><br> Allows matching requests to access the site, on condition that no other CIS firewall features block the request, such as IP firewall or access rules. 3 \n Challenge (Captcha) <br><br> * Firewall rules<br> * IP firewall<br> * User agent rules<br><br><br> Requires a user to pass a Google reCaptcha Challenge before proceeding. If successful, CIS accepts the matched request; otherwise, it is blocked. 4 \n JS Challenge <br><br> * Firewall rules<br> * IP firewall<br> * User agent rules<br><br><br> JS Challenge Requires a user to pass a CIS JavaScript Challenge before proceeding. If successful, CIS accepts the matched request; otherwise, it is blocked. \n Block <br><br> * Firewall rules<br> * IP firewall<br> * User agent rules<br><br><br> Blocks a matching request from accessing the site. 6","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-actions"},{"document_id":"ibmcld_04109-7-2036","score":19.9662717097,"text":"\nAssigning firewall rule actions \n\nFirewall rule actions tell CIS how to respond to requests that match the criteria you define.\n\nFor lightweight firewall rules, navigate to Security > IP firewall, which contains IP rules, User Agent rules, and Domain Lockdown rules. Firewall rules are based on IP address, IP address range, Autonomous System Number (ASN), or country\/region.\n\nDomain lockdown rules specify a list of IP addresses, CIDR ranges, or networks that can access a domain, subdomain, or URL. Anything not on the list is blocked.\n\nFor more robust firewall rules, navigate to Security > Firewall rules, where you can create rules that examine incoming HTTP traffic against a set of filters to block, challenge, log, or allow matching requests.\n\nThe following table describes the actions that you can assign to your rules. The priority column shows what precedence the action receives. If a request matches two different rules that have the same priority, precedence determines the action to take.\n\n\n\nTable 1. Firewall rule actions and priority\n\n Action Available in Description Priority \n\n Log <br><br> * Firewall rules<br><br><br> Logs matching requests on the CIS edge for access with Enterprise Logpush and Logpull. Recommended for testing rule effectiveness you commit to a more severe action. Available to Enterprise customers only. 1 \n Bypass <br><br> * Firewall rules<br><br><br> Allows dynamic disabling of security features for a request. Exempts matching requests from evaluation, based on a user-defined list that contains one or more of the following features: Browser Integrity Check, Domain Lockdown, Hotlink Protection, Rate Limiting, Security Level, User Agent Block, WAF Managed Rules. Matching requests are still subject to evaluation within Firewall Rules, based on order of execution. 2 \n Allow <br><br> * Firewall rules<br> * IP firewall<br><br><br> Allows matching requests to access the site, on condition that no other CIS firewall features block the request, such as IP firewall or access rules. 3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-actions"},{"document_id":"ibmcld_04334-75020-76382","score":19.8201120788,"text":"\nManipulate how firewall rules perform using the following firewall-rules commands:\n\n\n\n ibmcloud cis firewall-rules \n\nRetrieve a list of currently existing firewall-rules for a given DNS domain.\n\nibmcloud cis firewall-rules DNS_DOMAIN_ID [--page PAGE] [--per-page PER_PAGE] [-i, --instance INSTANCE] [ ! ! ! ! ! ! --output FORMAT\n<-- <section \"id=\"section-list-firewall-rules-options\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.--page: Page number of paginated results. The default value is 1.--per-page: Number of firewall rules per page. The minimum value is 5 and the maximum value is 100. The default value is 25.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-list-firewall-rules-options\" \"> --><-- <section \"id=\"section-list-firewall-rules-examples\" \"> --> Examples List existing firewall-rules in domain 31984fea73a15b45779fa0df4ef62f9b. ibmcloud cis firewall-rules 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n<-- <\/section \"id=\"section-list-firewall-rules-examples\" \"> --><-- <\/section \"id=\"section-list-firewall-rules\" \"> --><-- <section \"id=\"section-show-a-firewall-rule\" \"> --> ibmcloud cis firewall-rule Retrieve a specific firewall-rule for a given DNS domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-74160-75348","score":19.8108031142,"text":"\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nDelete a firewall rule.\n\nibmcloud cis firewall-delete dc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -i \"cis-demo\"\nibmcloud cis firewall-delete bc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall-delete 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall-delete e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n Firewall rules \n\nManipulate how firewall rules perform using the following firewall-rules commands:\n\n\n\n ibmcloud cis firewall-rules \n\nRetrieve a list of currently existing firewall-rules for a given DNS domain.\n\nibmcloud cis firewall-rules DNS_DOMAIN_ID [--page PAGE] [--per-page PER_PAGE] [-i, --instance INSTANCE] [ ! ! ! ! ! ! --output FORMAT","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10852-44214-45420","score":28.521246299,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-7-1802","score":28.2395733199,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-43319-44485","score":27.6919336132,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-2884-4620","score":24.5278650476,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_13724-72779-74671","score":24.4234064549,"text":"\nThe customization interface includes a collection of new HTTP methods that have the names POST \/v1\/customizations, POST \/v1\/customizations\/{customization_id}, POST \/v1\/customizations\/{customization_id}\/words, and PUT \/v1\/customizations\/{customization_id}\/words\/{word}. The service also provides a new GET \/v1\/pronunciation method that returns the pronunciation for any word and a new GET \/v1\/voices\/{voice} method that returns detailed information about a specific voice. In addition, existing methods of the service's interface now accept custom model parameters as needed.\n\nFor more information about customization and its interface, see [Understanding customization](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customIntro) and the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\nThe customization interface is a beta release that currently supports US English only. All customization methods and the GET \/v1\/pronunciation method can currently be used to create and manipulate custom models and word translations only in US English.\n\nNew Brazilian Portuguese voice: pt-BR_IsabelaVoice\n: The service supports a new voice, pt-BR_IsabelaVoice, to synthesize audio in Brazilian Portuguese with a female voice. For more information, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile Software Development Kits (SDKs) are available for the speech services. The SDKs enable mobile applications to interact with both the Text to Speech and Speech to Text services. You can use the SDKs to send text to the Text to Speech service and receive an audio response.\n\n\n\n* The Watson Swift SDK is available from the [swift-sdk repository](https:\/\/github.com\/watson-developer-cloud\/swift-sdk) in the watson-developer-cloud namespace on GitHub.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"},{"document_id":"ibmcld_02772-1628-3402","score":23.6414619312,"text":"\nFollowing registration, your users authenticate by using either the OAuth2 authorization code or resource owner password[authorization grant](https:\/\/datatracker.ietf.org\/doc\/html\/rfc6749section-1.3) flows to authenticate users.\n\n\n\n\n\n Dynamic client registration \n\n\n\n1. A user triggers a request by the client application to the App ID SDK.\n2. If your app is not registered as a mobile client yet, the SDK initiates a dynamic registration flow.\n3. On a successful registration, App ID returns your installation-specific client ID.\n\n\n\n\n\n\n\n Authorization flow \n\nZoom\n\n![App ID mobile request flow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/mobile-flow.svg)\n\nFigure 1. App ID mobile request flow\n\n\n\n1. The App ID SDK starts the authorization process by using the App ID \/authorization endpoint.\n2. The login widget is displayed to the user.\n3. The user authenticates by using one of the configured identity providers.\n4. App ID returns an authorization grant.\n5. The authorization grant is exchanged for access, identity, and refresh tokens from the App ID \/token endpoint.\n\n\n\n\n\n\n\n\n\n Configuring your mobile app with the App ID SDKs \n\nGet started with the App ID SDKs.\n\n\n\n Before you begin \n\nYou need the following information:\n\n\n\n* An App ID instance\n* Your instance's tenant ID. This can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10852-45155-46272","score":23.1347871889,"text":"\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)\n* [Invoking actions with mobile SDK from WhiskButton](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-actions-whiskbutton)\n\n\n\n\n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage)\n\n\n\n* [Packages for Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorageobstorage_packages)\n* [Setting up the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev)\n\n\n\n* [Prerequisites for working with the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragecos_changes_pre)\n* [1. Assigning the Notifications Manager role to your Cloud Functions namespace](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_auth)\n* [2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02674-7-1766","score":23.0637532988,"text":"\nApp Configuration server SDK for Go \n\nApp Configuration service provides SDK to integrate with your Golang web and mobile applications, microservices, and distributed environments.\n\n\n\n Prerequisites \n\nFollowing is the prerequisite for using App Configuration service SDK for Go:\n\n\n\n* Go version 1.16 or later\n\n\n\n\n\n\n\n Integrating server SDK for Go \n\nThe v1.x.x versions of the App Configuration Go SDK have been retracted.\n\nApp Configuration service provides SDK to integrate with your Golang web and mobile applications, microservices, and distributed environments. You can evaluate the values of your property and feature flag by integrating the App Configuration SDK.\n\n\n\n1. Install the SDK by using the following code from the git repository.\n\ngo get -u github.com\/IBM\/appconfiguration-go-sdk@latest\n2. In your Golang microservice or application, include the SDK module with:\n\nimport (\nAppConfiguration \"github.com\/IBM\/appconfiguration-go-sdk\/lib\"\n)\n\nRun go mod tidy to download and install the new dependency and update your Go application's go.mod file.\n3. Initialize the SDK to connect with your App Configuration service instance.\n\ncollectionId := \"airlines-webapp\"\nenvironmentId := \"dev\"\n\nappConfiguration = AppConfiguration.GetInstance()\nappConfiguration.Init(\"region\", \"guid\", \"apikey\")\nappConfiguration.SetContext(\"collectionId\", \"environmentId\")\n\nWhere,\n\n\n\n* region: Region name where the service instance is created. Use AppConfiguration.REGION_US_SOUTH for Dallas, AppConfiguration.REGION_US_EAST for Washington DC, AppConfiguration.REGION_EU_GB for London, and AppConfiguration.REGION_AU_SYD for Sydney.\n* guid: Instance ID of the App Configuration service. Get it from the service credentials section of the App Configuration service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-golang"},{"document_id":"ibmcld_10817-6582-8092","score":22.9770005379,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-4213-5899","score":22.6985371222,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.6509209298,"ndcg_cut_10":0.6509209298}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":29.4232381923,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":28.6215460312,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_02772-4213-5899","score":26.3899543922,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10852-43319-44485","score":23.9303369319,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_04518-1426-3052","score":23.3135146866,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-1342-3184","score":22.6932467827,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12332-1034-2510","score":20.3983315861,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_07551-14062-16080","score":16.8936899056,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_05088-31320-33239","score":10.5380442216,"text":"\nDirectory download in progress: 5632 bytes transferred\nDirectory download in progress: 1047552 bytes transferred\n...\nDirectory download in progress: 53295130 bytes transferred\nDirectory download in progress: 62106855 bytes transferred\nDownload complete!\n\n\n\n\n\n Pause\/Resume\/Cancel \n\nThe SDK provides the ability to manage the progress of file\/directory transfers through the following methods of the AsperaTransferFuture object:\n\n\n\n* pause()\n* resume()\n* cancel()\n\n\n\nThere are no side-effects from calling either of the methods outlined above. Proper clean up and housekeeping is handled by the SDK.\n\n Create Transfer manager\nbucket_name = \"<bucket-name>\"\nlocal_download_directory = \"<absolute-path-to-directory>\"\nremote_directory = \"<object prefix>\"\n\nwith AsperaTransferManager(client) as transfer_manager:\n\n download a directory with Aspera\nfuture = transfer_manager.download_directory(bucket_name, remote_directory, local_download_directory, None, None)\n\n pause the transfer\nfuture.pause()\n\n resume the transfer\nfuture.resume()\n\n cancel the transfer\nfuture.cancel()\nShow more\n\n\n\n\n\n Troubleshooting Aspera Issues \n\nIssue: Developers using any version of Python besides 3.6 may experience failures when installing or using Aspera SDK.\n\nCause: If there are different versions of Python installed on your environment, then you might encounter installation failures when you try to install the Aspera SDK. This can be caused by a missing DLL files or wrong DLL in path.\n\nSolution: The first step to resolving this issue would be to reinstall the Aspera libraries. There might have been a failure during the installation. As a result this might have affected the DLL files. If that does not resolve the issues, then you will be required to update your version of Python. If you are unable to do this, then you can use installation [Intel\u00ae Distribution for Python*](https:\/\/software.intel.com\/en-us\/distribution-for-python).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_06160-8533-10577","score":9.8347844601,"text":"\n* Check any Calico or Kubernetes network policies that are applied to the cluster and make sure that they do not block traffic from the worker node to the cluster apiservice, container registry, or other critical services.\n\n\n\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see if the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. Check the status of your worker nodes. If they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n6. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.932521092}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":31.8036681652,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":27.5841665811,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_02772-4213-5899","score":26.3539824727,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10852-43319-44485","score":25.9115432922,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-1342-3184","score":25.2151695739,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-1426-3052","score":22.8947392566,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_12332-1034-2510","score":17.1171307049,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_07551-14062-16080","score":16.5066213076,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10852-44214-45420","score":11.0022420182,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-2884-4620","score":10.7298836868,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.9469024295,"ndcg_cut_10":0.9469024295}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-7-1802","score":29.5290400494,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":27.3432056788,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_02772-4213-5899","score":24.8426450751,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10817-1342-3184","score":22.9509912327,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-1426-3052","score":22.5701102595,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-43319-44485","score":22.3978330888,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_12332-1034-2510","score":19.7381977646,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_07551-14062-16080","score":15.4750230031,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_14098-24347-26246","score":7.8965173086,"text":"\nBe sure to use the fully qualified domain name (FQDN) of the server rather than the IP address so that DNS is used when each host is added.\n\nAfter you add the ESXi hosts to vCenter, you might notice a couple of warnings messages about the enablement of the shell and SSH on each ESXi host. To suppress these warnings, click Suppress Warning > Yes on the pop-up window. If the Suppress Warnings link is not present, follow these steps:\n\n\n\n1. Go to the ESXi host Manage tab.\n2. Select the Settings and click Advanced System Settings.\n3. Find the UserVars.SupressShellWarning key and change the value to 1.\n4. Click OK.\n\n\n\nAfter the management and capacity hosts are added to their respective clusters, go to each host and setup DNS and NTP. To set up DNS, follow these steps:\n\n\n\n1. Click a host and select Manage > Networking.\n2. Select the default system stack (TCP\/IP configuration) and click the pencil icon.\n3. Enter the IP address of the DNS server that you previously created and the host and domain name.\n\n\n\nFor NTP settings:\n\n\n\n1. Go to Manage, Settings, Time Configuration.\n\n\n\n\n\n* Enter servertime.service.softlayer.com as the NTP server.\n* Set the NTP Service Startup Policy to Start and stop with host.\n\n\n\n\n\n\n\n Creating a distributed virtual switch for the capacity hosts \n\n\n\n1. Use the vSphere Web Client to go to Networking and right-click on the data center name.\n2. Select New Distributed Switch.\n3. Name the distributed switch and click Next.\n4. Select the appropriate distributed switch version and click Next.\n5. On the Edit Settings screen, enter 2 as the number of uplinks and clear the Create a default port group selection.\n6. Click Next > Finish and create the distributed virtual switch.\n\n\n\n\n\n\n\n Creating port groups for distributed virtual switch \n\nNow that the distributed virtual switch is present, you must create port groups for vMotion, fault tolerance, VMs, and storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-advanced-single-site-vmware-reference-architecture"},{"document_id":"ibmcld_14512-23446-24871","score":7.3529683066,"text":"\nFor more information, see [Preparing the installation environment](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-hcxclient-planning-prep-install). \n Initial NSX configuration As part of the deployment of your vCenter Server instance, a sample customer network is available that consists of a private subnet, a public subnet, an NSX logical switch, a distributed logical router, and an NSX edge appliance that is deployed and configured to perform network address translation. For steps to configure this sample customer network for your VMs, see [Configuring your network to use the customer-managed NSX ESG with your VMs](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_esg_configvc_esg_config). \n Add a logical switch Logical switches are similar to VLANs, in that they provide network connections to which you can attach your VMs. The VMs can then communicate with each other over VXLAN if the VMs are connected to the same logical switch. When you are adding logical switches, it is important to have in mind a particular topology that you are building. For more information, see [Add a logical switch](https:\/\/docs.vmware.com\/en\/VMware-NSX-Data-Center-for-vSphere\/6.4\/com.vmware.nsx.install.doc\/GUID-DD31D6BC-2E56-4E91-B45F-FCA3E80FF786.html). \n Add a DLR A Distributed Logical Router (DLR) is a virtual appliance that routes between connected logical switches (East-West traffic).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsprocs-configure"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.8529278651,"ndcg_cut_10":0.8529278651}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04518-1426-3052","score":33.2793822946,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-1342-3184","score":30.4629301683,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":28.9698461614,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_12332-1034-2510","score":26.6318522054,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_07551-14062-16080","score":24.5767386154,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10852-43319-44485","score":24.4400311087,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_07551-15747-17355","score":23.6031662842,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10852-44214-45420","score":20.6695669859,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-7-1802","score":20.1926095528,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_00944-3804-5592","score":8.6405525356,"text":"\nIBM Cloud Event Notifications is the preferred method for distributing notifications to PagerDuty and other communication channels such as Slack, email, SMS, push notifications, webhook, Microsoft\u00ae Teams, ServiceNow, and IBM Cloud Functions. For more information about using Event Notifications, see [Enabling event notifications for toolchains](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-event-notifications-cd).\n\n\n\n\n\n\n\n Creating a toolchain from a template with Git Repos and Issue Tracking or GitHub with the API \n\nYou can create a toolchain from a template only by using the console. To view the steps for using the console, switch to the UI instructions.\n\nFor more information about how to create a toolchain with the API instead of by using a template, see [Adding the Git tool integration to an existing toolchain with the API](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-toolchains_gitadding_to_toolchain_api).\n\n\n\n\n\n Creating a toolchain from a template with Git Repos and Issue Tracking or GitHub with Terraform \n\nYou can create a toolchain from a template only by using the console. To view the steps for using the console, switch to the UI instructions.\n\nFor more information about how to create a toolchain with Terraform instead of by using a template, see [Adding the Git tool integration to an existing toolchain with Terraform](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-toolchains_gitadding_to_toolchain_terraform).\n\n\n\n\n\n Adding the Git tool integration to an existing toolchain by using the console \n\nYou can add a Git tool integration to any existing toolchain by using the console.\n\n\n\n1. Log in to [IBM Cloud](http:\/\/cloud.ibm.com).\n2. From the IBM Cloud console, click the menu icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-toolchains_git"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.9066276098}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11192-0-1195","score":20.6464005913,"text":"\n\n\n\n\n\n\n  Exploring scorecards \n\nYou can use different approaches to add data to your metrics cube.\n\nScorecards reflect the strategic goals of an organization. Using scorecards, you can identify how well objectives are being met by comparing targets to actual results. Visual status indicators such as traffic lights, trend icons, and colors are used to help you to quickly evaluate performance.\n\nIn Planning Analytics with Watson, you can add existing scorecards to your books, and analyze data by selecting different time periods, metrics, and dimensions. You can also create visualizations from scorecards, such as impact diagrams and strategy maps.\n\nYou can explore scorecards in Planning Analytics with Watson with the GO_Scorecards sample.\n\n\n\n*  [Scorecards](https:\/\/www.ibm.com\/docs\/planning-analytics\/2.0.0?topic=es-scorecards)\n\n\n\nA scorecard is a collection of performance metrics that are designed to reflect the strategic goals of your business unit or organization.\n\n\n\n*  [Metrics cubes](https:\/\/www.ibm.com\/docs\/planning-analytics\/2.0.0?topic=es-metrics-cubes)\n\n\n\nA metrics cube is a special type of cube that provides the basis for scorecard solutions and scorecard diagrams.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/planning-analytics?topic=planning-analytics-exploring-scorecards"},{"document_id":"ibmcld_09615-10623-12269","score":20.5678395351,"text":"\n\"containers-kubernetes\"\n]\n},\n{\n\"operand\": \"location\",\n\"operator\": \"in\",\n\"values\":\n\"us-south\",\n\"eu-de\"\n]\n}\n]\n}]\nShow more\n\nWhere:\n\naction\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09615-4729-6393","score":20.516017798,"text":"\n{\n\"operand\": \"location\",\n\"operator\": \"in\",\n\"values\":\n\"us-south\",\n\"eu-de\"\n]\n}\n]\n}]\nShow more\n\nWhere:\n\naction\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09615-2350-4116","score":20.4202071512,"text":"\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\n--rules RULES","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09615-8271-10037","score":20.4202071512,"text":"\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\n--rules RULES","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli"},{"document_id":"ibmcld_09628-1427-3147","score":20.385852615,"text":"\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\n\n\n\n\n Inclusion filters \n\nInclusion filters define the conditions that are used to determine which metrics are routed to the targets specified in the rule.\n\nTo route all metrics, exclude the inclusion_filters definition when you configure a route.\n\nInclusion filters are composed of an operand, operator, and value:\n\noperand\n: Operand is the name of the property in the target that is used to filter data. The following operands are supported: location, service_name, service_instance, resource_type, and resource. The value is extracted from the target CRN.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route_rules_definitions"},{"document_id":"ibmcld_09623-1182-2897","score":20.3355606212,"text":"\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nFor example, to define an inclusion filter that defines the condition where only metrics that are generated in the us-south region are routed, looks as follows:\n\n{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}\n\n\n\n\n\n Configure the route \n\nRun the following command to exclude all metrics received by IBM Cloud Metrics Routing from the us-south region.\n\nibmcloud metrics-router route create --name drop-route --rules '[{\"action\": \"drop\", \"inclusion_filters\":{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}]}]'\n\nWhere inclusion_filters specifies the filters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route-drop"},{"document_id":"ibmcld_09623-4-1600","score":20.214724481,"text":"\n* CLI\n\n\n\n\n\n\n\n Excluding metrics by using the drop action \n\nYou can configure IBM Cloud\u00ae Metrics Routing to exclude (drop) metrics based on a configured rule. Dropped metrics are not sent on to a target.\n\n\n\n Prereqs \n\n\n\n1. [Install the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli).\n2. [Install the IBM Cloud Metrics Routing CLI](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli-config).\n3. Ensure you have the [correct IAM permissions to configure IBM Cloud Metrics Routing routes.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-iam)\n4. Log in to IBM Cloud. Run the following command: [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliibmcloud_login).\n\n\n\n\n\n\n\n Define the inclusion filter \n\nInclusion filters determine which metrics are routed to the targets.\n\nInclusion filters are comprised of an operand, operator, and values:\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location, service_name, service_instance, resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route-drop"},{"document_id":"ibmcld_09625-1179-2989","score":20.1298599566,"text":"\nStep 2: Define the inclusion filter \n\nInclusion filters determine which metrics are routed to the targets.\n\nInclusion filters are comprised of an operand, operator, and values:\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-cloud-services-mr)\n\nFor example, to define an inclusion filter that defines the condition where only metrics that are generated in the us-south region are routed, looks as follows:\n\n{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}\n\n\n\n\n\n Step 3: Configure the route","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route-from-1-location"},{"document_id":"ibmcld_13115-18852-20356","score":16.6933279223,"text":"\nIn the New Panel:\n\n\n\n1. Set the Metric to sysdig_container_net_http_request_time.\n2. Set Group by to container_id.\n\n\n\n3. Edit the Dashboard scope, set the filter to container_image, is and icr.io\/solution-tutorials\/tutorial-application-log-analysis:latest.\n4. Save the dashboard.\n\n\n\nZoom\n\n![New Dashboard](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution12\/new_dashboard.png)\n\nFigure 3. New dashboard\n\nTo add another panel:\n\n\n\n1. Use the Add Panel button in the dashboard.\n2. Change the panel type from Timechart to Number\n3. Set the Metric to sysdig_container_net_request_count.\n4. Set the Time Aggregation to Rate.\n5. Set the Group by to Sum.\n6. Enable Compare To and set the value to 1 Hour ago.\n7. Save the dashboard.\n\n\n\n\n\n\n\n\n\n Step 7: Remove resources \n\n\n\n* If you created them as part of this tutorial, remove the logging and monitoring instances from [Observability](https:\/\/cloud.ibm.com\/observe) page.\n* Delete the cluster including worker node, app and containers. This action cannot be undone.\n\nibmcloud ks cluster rm --cluster $MYCLUSTER -f --force-delete-storage\n\n\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-resource-reclamation).\n\n\n\n\n\n Expand the tutorial","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-application-log-analysis"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09701-12088-14157","score":17.2404480371,"text":"\nSeverity Severity status \n\n 0 HIGH \n 1 HIGH \n 2 MEDIUM \n 3 MEDIUM \n 4 LOW \n 5 LOW \n 6 INFO \n 7 INFO \n\n\n\n\n\n\n\n segmentBy (array of strings) \n\nDefines additional segmentation criteria.\n\nFor example, you can segment a CPU alert by ['host.mac', 'proc.name'] so the alert can report on any process in any machine for which you get data in the monitoring instance.\n\n\n\n\n\n segmentCondition (string) \n\nDefines when the alert is triggered for each monitored entity that is specified in the segmentBy parameter. This parameter is required for MANUAL alerts only.\n\nValid values are the following:\n\n\n\n* ANY: The alert is triggered when at least one of the monitored entities satisfies the condition.\n* ALL: The alert is triggered when all of the monitored entities satisfy the condition.\n\n\n\n\n\n\n\n teamId (string) \n\nDefines the GUID of the team that owns the alert.\n\n\n\n\n\n type (string) \n\nDefines the type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\nSet to MANUAL for alerts that you want to control when a notification is sent. You must define the threshold that determines when the alert is triggered.\n\nSet to BASELINE for alerts that you want to notify when unexpected metric values are detected. New metric data is compared with metric values that are collected over time.\n\nSet to HOST_COMPARISON for alerts that you want to notify when 1 host in a group reports metrics values that are different from the other hosts in the group.\n\n\n\n\n\n timespan (integer) \n\nMinimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered.\n\nThe minimum value is 60000000 microseconds, that is, 1 minute.\n\nThe value of this parameter must be a multiple of 60000000 microseconds.\n\n\n\n\n\n version (integer) \n\nVersion of an alert.\n\nThe version changes every time you update an alert.\n\nThe version is used for optimistic locking.\n\n\n\n\n\n\n\n Query parameters \n\n\n\n alertId (integer) \n\nID of an alert.\n\n\n\n\n\n from (long) \n\nDefines the start timestamp, in microseconds, that is used when you request information about alerts that are defined.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_08592-8007-9409","score":16.4307804854,"text":"\nYou can scope down your metrics by using the following scope filters.\n\n\n\nTable 4. Describes the scope filters for Hyper Protect Crypto Services metrics.\n\n Attribute Name Description \n\n ibmResourceGroupName The name of the resource group associated with the Hyper Protect Crypto Services service instance. \n ibmScope The account, organization, or space GUID associated with the metric. \n ibmServiceInstanceName The service instance associated with the metric. \n ibmHpcsApi The Hyper Protect Crypto Services API calls associated with the metric. \n\n\n\nBecause of Monitoring limitations, you are able to see the values in the filters for up to 6 hours at a time. You can manually type in value into scope variables to use scope filters for given time periods.\n\n\n\n\n\n\n\n Setting Alerts \n\nYou can set alerts on your Monitoring dashboard to notify you of certain metrics. To set up alerts, complete the following steps:\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert and select Metric as the alert type.\n3. Select the aggregation and the metric that you would like to be performed on.\n4. Select the scope if applicable.\n5. Set the metric and time requirements for the alert to trigger.\n6. Configure and set up the notification channel and notification interval.\n7. Click CREATE.\n\n\n\nFor more information about configuring metric alerts, see [Metric Alerts](https:\/\/docs.sysdig.com\/en\/metric-alerts.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-operational-metrics"},{"document_id":"ibmcld_09703-1640-3664","score":15.9319519389,"text":"\n* Alerts are executed in 1 minute or less from receipt, with the option to configure the trigger wait time by hour or day.\n* For PromQL alerts only, you can optionally configure a 0 minute wait time.\n\n\n\nYou can enable predefined alerts, modify alerts, and create custom alerts in the web UI and by using the IBM Cloud Monitoring API.\n\nYou manage alerts in the Alerts view of the web UI. You can configure the table columns that are displayed in the Alerts view. Valid column options are Name, Scope, Alert When, Segment By, Notifications, Enabled, Modified, Captures, Channels, Created, Description, Email recipients, For at least, OpsGenie, PagerDuty, Severity, Slack, WebHook, Type, and VictorOps.\n\n\n\n Types of alerts \n\nThe IBM Cloud Monitoring service includes pre-defined alerts that you can enable. In addition, you can configure custom alerts from panels in a dashboard, by using the REST API, or in the Alerts section of the web UI.\n\nIn the IBM Cloud Monitoring service, you can define any of the following types of alerts:\n\n\n\n* Downtime: Use this type of alert to monitor sources and alert when they are down, for example, a bare metal.\n* Metric: Use this type of alert to monitor time-series metrics and alert when they reach the thresholds defined.\n* PromQL: Use this type of metric to monitor metrics by using a PromQL query.\n* Event: Use this type of alert to monitor occurrences of specific events and alert when they reach the thresholds defined. For example, you can use this alert to monitor when a number of unauthorize access requests are reported.\n* Anomaly Detection: Use this type of alert to monitor hosts based on historical behaviors and alert when they deviate from the expected pattern.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n* Group Outlier: Use this type of alert to monitor hosts and be notified when 1 acts differently from the rest.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n\n\n\n\n\n\n\n Notification channels","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alerts"},{"document_id":"ibmcld_09148-8939-9806","score":15.6814151105,"text":"\nTo setup a metric, complete the follow steps.\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert at the top of the page.\n3. Select Metric as the alert type.\n4. Select the aggregation and the metric that you would like to be performed on.\n5. Select the scope if applicable.\n6. Set the metric and time requirements for the alert to trigger.\n7. Configure and set up the notification channel and notification interval.\n8. Click the CREATE button.\n\n\n\nThe figure as shown provides an example of how to configure an alert when your service instance receives multiple 401 and 403 errors within a 10 minute time span.\n\nZoom\n\n![An example of a 401 and 403 configuration.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc\/key-protect\/images\/monitor-401-alert.png)\n\nFigure 5. The configuration for a 401 alert in a Monitoring dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-operational-metrics"},{"document_id":"ibmcld_09700-7-1797","score":15.5314797538,"text":"\nConfiguring an alert by using the legacy alert editor \n\nIn the IBM Cloud Monitoring service, you can configure single alerts and multi-condition alerts to notify about problems that may require attention. When an alert is triggered, you can be notified through 1 or more notification channels. An alert definition can generate multi-channel notifications.\n\nAn alert is a notification event that you can use to warn about situations that require attention. Each alert has a severity status. This status informs you about the criticality of the information it reports on. [Learn more](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alerts).\n\nComplete the following steps to configure an alert:\n\n\n\n Step 1. Select the alert type \n\nFrom the Alert section of the UI, select Add Alert. Then, choose the alert type.\n\n\n\n\n\n Step 2. Name the alert \n\nEnter a name for the alert.\n\nYou can also add a description for the alert and the name of an alert group if you want to group you alerts. If an alert group is not specified, the alert will be created in the default group.\n\n\n\n\n\n Step 3. Define the severity \n\nAdd a severity level. Valid severity values are info, low, medium, and high.\n\n\n\n\n\n Step 4. Define the metric section \n\n\n\n1. Select a metric (entity) that you want to monitor.\n2. Define the alert condition. Choose any of the following options:\n\nOption 1: Choose a metric and a single condition such as average, sum, minimum or maximum.\n\nOption 2: Choose Create multi-condition alerts. Enter the condition, for example, min(min(cpu.used.percent)) < = 50 OR max(max(cpu.used.percent)) >= 80.\n\nZoom\n\n![Multi-condition alert](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/monitor\/images\/multi-condition-alerts.png)\n\nMulti-condition alert","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert-config"},{"document_id":"ibmcld_02436-1294-2980","score":15.5047144806,"text":"\nA graph will help you determine the number of log entries for the timezone and time range.\n\n\n\n6. Specify 1 or more email addresses.\n7. Optional: You can click Test to test that your alert configuration is correct.\n8. Click Save Alert.\n\n\n\n\n\n\n\n Muting an alert \n\nThis section only applies to email alerts.\n\nAfter you configure an alert on a view and receive a notification email, complete the following steps to mute the alert a period of time:\n\n\n\n1. Go to the email account where you receive email notifications.\n2. Open a notification email for a view that you want to mute.\n\nLook for emails that are sent by IBM Cloud Activity Tracker. The subject includes the name of the view.\n\nIn the email, there is a section that includes the following text:\n\nMute these alerts for [1 Hour] [6 Hours] [12 Hours] [1 Day]\n3. Choose a period of time.\n\nA window opens. The information provided indicates the view, the notification that is muted, and the time period that is muted for.\n\nFor example, you can get a message that indicates the following:\n\nEmail alerting for MyView has been muted for an hour.\n\nUnmute\n\nAlerting is scheduled to resume at Jun 14, 11:59am.\n\nManage Alerts\n\nFrom this page, you can select Unmute to enable notifications on the view. You can also select Manage to go to the ALERTS dashboard in the web UI.\n\n\n\n\n\n\n\n Unmuting a muted alert \n\nYou can manage alerts through the ALERTS dashboard.\n\n\n\n1. Launch the ALERTS dashboard.\n\nIn the web UI, select the Settings icon ![Settings icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/alerts\/images\/admin.png).\n\nSelect ALERTS.\n\nYou can see the list of alerts that are muted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-email"},{"document_id":"ibmcld_09344-1263-2917","score":15.4743025358,"text":"\nA graph will help you determine the number of log entries for the timezone and time range.\n\n\n\n6. Specify 1 or more email addresses.\n7. Optional: You can click Test to test that your alert configuration is correct.\n8. Click Save Alert.\n\n\n\n\n\n\n\n Muting an alert \n\nThis section only applies to email alerts.\n\nAfter you configure an alert on a view and receive a notification email, complete the following steps to mute the alert a period of time:\n\n\n\n1. Go to the email account where you receive email notifications.\n2. Open a notification email for a view that you want to mute.\n\nLook for emails that are sent by IBM Cloud Activity Tracker. The subject includes the name of the view.\n\nIn the email, there is a section that includes the following text:\n\nMute these alerts for [1 Hour] [6 Hours] [12 Hours] [1 Day]\n3. Choose a period of time.\n\nA window opens. The information provided indicates the view, the notification that is muted, and the time period that is muted for.\n\nFor example, you can get a message that indicates the following:\n\nEmail alerting for MyView has been muted for an hour.\n\nUnmute\n\nAlerting is scheduled to resume at Jun 14, 11:59am.\n\nManage Alerts\n\nFrom this page, you can select Unmute to enable notifications on the view. You can also select Manage to go to the ALERTS dashboard in the web UI.\n\n\n\n\n\n\n\n Unmuting a muted alert \n\nYou can manage alerts through the ALERTS dashboard.\n\n\n\n1. In the web UI, select the Settings icon ![Settings icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/alerts\/images\/admin.png).\n2. Select ALERTS.\n\nYou can see the list of alerts that are muted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-email"},{"document_id":"ibmcld_09794-9435-11301","score":15.1644397296,"text":"\n[Panel options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/platform\/images\/sysdig-platform-15.png)\n\nPanel options\n\nIf you have multiple queries defined in a panel, you are prompted to select the metric for which you want to create an alert.\n7. Configure the alert. Set the following fields:\n\nName: Enter a name for the alert.\n\nDescription: Add a description that other users can read to get more context. This field is optional.\n\nGroup: The alert group this alert will be part of. If not specified, the alert will be part of the default group.\n\nSeverity: Set the level of criticality of the alert. Valid values are High, Medium, Low, and Info.\n\nMetric: This field is set to the metric that you have selected from the panel. Check that the metric and aggregation are the ones that you need.\n\nScope: This field is set to the scope that you have defined for the metric in the panel. Check that the scope is the one that you need.\n\nTrigger: Define the condition and threshold value that must be evaluated. It also defines whether the alert sends a single alert or multiple alerts. Valid time scales are minute, hour, or day. A single alert fires an alert for the entire scope. Multiple Alerts are sent if 1 or more segments breach the threshold at once. An alert is sent for each segment that you specify.\n\nNotification Channel: Enable 1 or more notification channels.\n\n\n\n\n\n\n\n\n\n Configuring an alert from the Alerts section \n\nYou can define a metric alert directly from the Alerts section.\n\nComplete the following steps to define an alert on a metric:\n\n\n\n1. [Launch the monitoring UI](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-launch).\n2. Verify that you have a notification channel that defines how you want to be notified.\n\nYou can enabled 1 or more notification channels when you configure an alert.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-platform_metrics_working"},{"document_id":"ibmcld_02436-7-1736","score":15.1533210788,"text":"\nIntegrating with email \n\nYou can send alerts to 1 or more email addresses.\n\n\n\n Configuring email \n\nWhen you [configure an alert](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-alertsconfigure-an-alert), you can have that alert sent to 1 or more email addresses.\n\n\n\n1. When configuring your alert, click ![email icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/alerts\/images\/email.png).\n2. Select if you want the alert to be sent when the condition exists (Presence) or does not exist (Absence).\n3. Indicate the logging criteria when an alert should be sent. For example, when 100 lines matching in the view are logged in an hour. A graph will help you determine the number of log lines matching your specified criteria.\n4. Select if the alert should be sent at the end of the selected period or immediately when the number of lines are logged.\n5. Optionally you can specify a Custom schedule with alerting limited to a specified timezone, days of the week, or timeframe. To configure a Custom schedule:\n\n\n\n1. Select on for Custom schedule.\n2. Select the Timezone for the log entries.\n3. Select the days of the week when alerts should be generated.\n4. Optionally specify a time range for the selected days. A graph will help you determine the number of log entries for the timezone and time range.\n\n\n\n6. Specify 1 or more email addresses.\n7. Optional: You can click Test to test that your alert configuration is correct.\n8. Click Save Alert.\n\n\n\n\n\n\n\n Muting an alert \n\nThis section only applies to email alerts.\n\nAfter you configure an alert on a view and receive a notification email, complete the following steps to mute the alert a period of time:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-email"},{"document_id":"ibmcld_09344-7-1711","score":15.1533210788,"text":"\nIntegrating with email \n\nYou can send alerts to 1 or more email addresses.\n\n\n\n Configuring email \n\nWhen you [configure an alert](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-alerts) you can have that alert sent to 1 or more email addresses.\n\n\n\n1. When configuring your alert, click ![email icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/alerts\/images\/email.png).\n2. Select if you want the alert to be sent when the condition exists (Presence) or does not exist (Absence).\n3. Indicate the logging criteria when an alert should be sent. For example, when 100 lines matching in the view are logged in an hour. A graph will help you determine the number of log lines matching your specified criteria.\n4. Select if the alert should be sent at the end of the selected period or immediately when the number of lines are logged.\n5. Optionally you can specify a Custom schedule with alerting limited to a specified timezone, days of the week, or timeframe. To configure a Custom schedule:\n\n\n\n1. Select on for Custom schedule.\n2. Select the Timezone for the log entries.\n3. Select the days of the week when alerts should be generated.\n4. Optionally specify a time range for the selected days. A graph will help you determine the number of log entries for the timezone and time range.\n\n\n\n6. Specify 1 or more email addresses.\n7. Optional: You can click Test to test that your alert configuration is correct.\n8. Click Save Alert.\n\n\n\n\n\n\n\n Muting an alert \n\nThis section only applies to email alerts.\n\nAfter you configure an alert on a view and receive a notification email, complete the following steps to mute the alert a period of time:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-email"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03363-4-2165","score":21.3504064499,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03036-4322-6185","score":19.4183351144,"text":"\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-1671-3630","score":19.2401263671,"text":"\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03036-2789-4951","score":18.697093458,"text":"\nIf you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_09592-3-1444","score":13.5920257397,"text":"\nIBM Cloud Metrics Routing \n\nUse IBM Cloud Metrics Routing to configure how to route platform metrics in your IBM Cloud account.\n\n Developer tools \n\n[API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/metrics-router\/metrics-router-v3)[CLI reference](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli)\n\n Recommended content \n\n[Understanding IBM Cloud Metrics Routing Learn about how to manage metrics by using IBM Cloud Metrics Routing](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-about)[Getting started with IBM Cloud Metrics Routing Use the IBM Cloud Metrics Routing CLI to configure your account to manage metrics.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-getting-started)[Planning your environment Plan how to configure the account to manage metrics.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-planning)[See what's new Read about the latest changes to IBM Cloud Metrics Routing. ](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-release-notes)\n\n Learn more \n\n[IBM Developer<br><br>Visit IBM Developer for technical articles, code patterns, tutorials, and more.<br><br>![112-Developer-tools.svg](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/112-Developer-tools.svg)](https:\/\/developer.ibm.com\/depmodels\/cloud\/)[Architecture Center<br><br>Discover the architecture references available for this product.<br><br>!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router"},{"document_id":"ibmcld_09628-4-1912","score":13.4587638708,"text":"\n* CLI\n* API\n\n\n\n\n\n\n\n Defining routing rules \n\nTo define a routing rule, you must specify 1 or more targets as the destinations for metrics. You can also define 1 or more inclusion filters that define the conditions of how those metrics are routed to those destinations.\n\nFor each route that you define in the account, you can configure up to 4 rules. The rules specify what metrics are routed in a region and where to route them. For more information, see [Understanding how routes work in your account](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-routes&interface=cliroute_behaviour).\n\nA rule consists of 1 action, 1 or more targets, and 0 or more inclusion filters.\n\n\n\n Targets \n\nTargets define the list of target IDs where the metrics are routed.\n\n\n\n* You can specify up to three target IDs per rule.\n* You can define target IDs for resources that are available in the same region where you are configuring the route, in a different region, and in a different account.\n\n\n\nFor example, you can define a list of targets as follows:\n\n\"targets\": [{\"id\":\"11111111-1111-1111-1111-111111111111\"},{\"id\":\"22222222-2222-2222-2222-222222222222\"}]\n\nTargets must be IBM Cloud Monitoring instances.\n\n\n\n\n\n Action \n\nAction defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\n\n\n\n\n Inclusion filters \n\nInclusion filters define the conditions that are used to determine which metrics are routed to the targets specified in the rule.\n\nTo route all metrics, exclude the inclusion_filters definition when you configure a route.\n\nInclusion filters are composed of an operand, operator, and value:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route_rules_definitions"},{"document_id":"ibmcld_09630-0-1462","score":13.4541145817,"text":"\n\n\n\n\n\n\n  Understanding routing precedence \n\nYou can configure exactly where IBM Cloud\u00ae Metrics Routing routes platform metrics in your account. Route rule inclusion filters provides elevated control over how your metrics are routed. You can also configure default targets by using IBM Cloud\u00ae Metrics Routing settings. How the configuration is processed determines the final destination where metrics are sent; each data point is processed individually.\n\n\n\n1.  If a route rule's inclusion filters match the data point, the data point is sent to the configured targets. Route rules are processed sequentially, the first match is used. If there are multiple routes, all route rules will be processed to find a match.\n\nIf a matched route rule uses the drop action, the data point will be dropped and no destinations will receive it.\n2.  If the data point does not match any route rules, the [default targets setting](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-target-default) is used to route the data point to the default targets.\n3.  If the data point does not match any route rules, and no default target is defined, the metric is routed to the IBM Cloud Monitoring instance defined in the region as the receiver of platform metrics. [A IBM Cloud Monitoring instance enabled to receive platform metrics must exist in the region to receive the metrics.](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-platform_metrics_enabling)\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-routes_precedence"},{"document_id":"ibmcld_09627-4-1579","score":13.4133260104,"text":"\n* CLI\n\n\n\n\n\n\n\n Routing all metrics \n\nRoute all metrics that are generated in all of the IBM Cloud\u00ae Metrics Routing supported locations to multiple destination targets.\n\nA rule consists of 1 or more targets, and 1 or more inclusion filters. For more information on how routes work, see [Understanding how routes work in your account](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-routes&interface=cliroute_behaviour).\n\nInclusion filters determine which metrics are routed to the targets.\n\nTo route all metrics, you must exclude the inclusion_filters definition when you configure the route.\n\n\n\n Prereqs \n\n\n\n1. [Install the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-install-ibmcloud-cli).\n2. [Install the IBM Cloud Metrics Routing CLI](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-metrics-router-cli-config).\n3. Ensure you have the [correct IAM permissions to configure IBM Cloud Metrics Routing routes.](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-iam)\n4. Log in to IBM Cloud. Run the following command: [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliibmcloud_login).\n\n\n\n\n\n\n\n Step 1: Get the target details \n\nComplete the following steps:\n\n\n\n1. Run the following command to list all targets. Copy the target ID of the one where you want to route the metrics.\n\nibmcloud metrics-router target ls\n2. Run the following command to get the details of the targets where you want to route the metrics:\n\nibmcloud metrics-router target get --target <TARGET_ID>\n\n\n\n\n\n\n\n Step 2: Configure the route","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-route-rule-all-metrics"},{"document_id":"ibmcld_09635-4-1907","score":13.391772298,"text":"\n* CLI\n* API\n\n\n\n\n\n\n\n About targets \n\nYou can manage IBM Cloud\u00ae Metrics Routing targets in your account by using the IBM Cloud Metrics Routing CLI, the IBM Cloud Metrics Routing REST API, and Terraform scripts. A target is a resource where you can collect metrics data. The resource can be located in the same IBM Cloud account where metrics are generated or in a different account.\n\n\n\n Understanding how targets work in your account \n\nNote the following information about targets:\n\n\n\n* Targets are regional under an account and can be accessed from any regional IBM Cloud Metrics Routing API endpoint.\n* You can define a target in any of the supported locations where IBM Cloud Metrics Routing is available. For more information, see [Locations](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions).\n* You can configure up to 16 targets in each account.\n* You can configure up to two default targets for each IBM Cloud account.\n\nDefault targets collect metrics from locations where you do not specify in the account where to route the metrics that are generated in that location.\n* Information about targets is stored as metadata in the primary and backup locations that you set for the IBM Cloud account. The information that is stored include details about the destinatiion resource and credentials to send metrics.\n\nThe primary metadata location must be set prior to configuring a target.\n\nIf you do not configure a primary metadata location, the location is set to the location where you define your first target in the account. For more information, see [Configuring account settings](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-settings).\n* You can use private and public endpoints to manage targets. For more information about the list of endpoints that are available, see [Endpoints](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-endpoints).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-target"},{"document_id":"ibmcld_09605-2432-4324","score":13.3312297023,"text":"\nWhen you configure IBM Cloud Metrics Routing in your account, you can configure account settings such as metadata locations, type of endpoints that are allowed to manage the configuration, locations where targets can be defined, and default targets for collecting metrics in regions that you have not explicitly configured how to route metrics. For more information, see [Configuring IBM Cloud Metrics Routing account settings](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-settings).\n\nBefore you can configure targets and routes in the account, you must configure the primary metadata location that defines the region where all your IBM Cloud Metrics Routing resource definitions are stored.\n\nRun the following command to configure the primary metadata location:\n\nibmcloud metrics-router setting update --primary-metadata-region <REGION>\n\nWhere <REGION> is set to a supported region where IBM Cloud Metrics Routing is available. For more information, see [Locations](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-regions).\n\nBefore setting the metadata location, check any compliance or industry regulations that apply to the data location.\n\n\n\n\n\n Step 2. Configure 1 target \n\nA target defines where metrics are collected. For more information about targets, see [Understanding how targets work in your account](https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-target&interface=clitarget_behavior).\n\nWhen you configure a target, you are defining the destination where you plan to send platform metrics that are collected in a region in your account.\n\nComplete the following steps to configure a target:\n\n\n\n1. Define a target where to route metrics.\n\nibmcloud metrics-router target create --name TARGET_NAME --destination-crn DESTINATION_TARGET_CRN [--region REGION]\n\nWhere\n\n--name\n: Defines the name to be given to the target.\n\n--destination-crn","title":"","source":"https:\/\/cloud.ibm.com\/docs\/metrics-router?topic=metrics-router-getting-started"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2640681226,"ndcg_cut_10":0.2640681226}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03363-4-2165","score":18.9709319252,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03036-4322-6185","score":18.2144397775,"text":"\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-1671-3630","score":18.1897432713,"text":"\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03036-2789-4951","score":18.0273599057,"text":"\nIf you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_14503-4971-7126","score":15.2074152642,"text":"\nThe client can also configure their compute VMs to uses these forwarders, if required.\n* VMware Update Manager (VUM) provides updating of vSphere hosts and VM hardware and tools. VUM uses the Proxy to gain access to the internet repositories.\n\n\n\nVMware Aria Operations collects data from objects in the environment. Each piece of data that is collected is called a metric observation or value. VMware Aria Operations uses the vCenter adapter to collect raw metrics from vCenter. In addition to the metrics it collects, VMware Aria Operations calculates capacity metrics, badge metrics, and metrics to monitor the health of your system. Alert definitions are a combination of symptoms and recommendations that identify problem areas and generate alerts on which you act for those areas.\n\n\n\n\n\n Monitored components \n\n\n\n Monitoring of vCenter \n\nThe monitoring of vCenter is accomplished with VMware Aria Operations and the VMware SDDC Health Management Pack. VMware Aria Operations for Logs collects the log data from vCenter and the Content Pack for vSphere adds specific understanding to the logs and in turn sends alerts to VMware Aria Operations.\n\nThe VMware SDDC Health Management Pack monitors the SDDC Management stack and provides badges for health and alerts related to configuration and compliance of SDDC product components that include vCenter.\n\n\n\n\n\n Monitoring of vSphere hosts \n\nMonitoring of the vSphere hosts is accomplished with VMware Aria Operations through vCenter and the collection of logs through VMware Aria Operations for Logs.\n\n\n\n\n\n Monitoring of vSAN \n\nTo monitor vSAN, VMware Aria Operations, and VMware Aria Operations for Logs are used. In vCenter, you can use an extra set of vSAN Health Checks. Installation of the Management Pack for vSAN provides more dashboards to aid with the monitoring of vSAN.\n\nVMware Aria Operations generates an alert if a problem occurs in the SDDC product components in the storage area network that the VMware vSAN adapter is monitoring. An alert that is related to configuration compliance and health is passed through VMware SDDC Health Solution management pack from VMware vSAN Management Pack.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsmgmt-arch"},{"document_id":"ibmcld_09701-6981-8407","score":14.979077436,"text":"\ncurl -X GET <REST_API_ENDPOINT>\/api\/alerts?from=<START_TIMESTAMP>&to=<END_TIMESTAMP> -H \"Authorization: Bearer $AUTH_TOKEN\" -H \"IBMInstanceID: $GUID\"\n\nWhere\n\n\n\n* <REST_API_ENDPOINT> indicates the endpoint targetted by the REST API call. For more information, see [Monitoring REST API endpoints](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-endpointsendpoints_rest_api). For example, the public endpoint for an instance that is available in us-south is the following: https:\/\/us-south.monitoring.cloud.ibm.com\/api\n* You can pass multiple headers by using -H.\n\nAuthorization and IBMInstanceID are headers that are required for authentication. To get an AUTH_TOKEN and the GUID see, [Headers for IAM Tokens](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-mon-curlmon-curl-headers-iam).\n* to and from are query parameters that you must define to configure the period of time for which you want information on the alerts.\n\n\n\nFor more information about the response format, see [Alert schema](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_apialert-api-schema-res).\n\n\n\n\n\n Alerts schema: Request body \n\n{\n\"alerts\": [\n{\n\"alert\": {\n\"version\": null,\n\"name\": \"\",\n\"description\": null,\n\"teamId\": null,\n\"enabled\": false,\n\"filter\": null,\n\"type\": \"\",\n\"condition\": \"\",\n\"timespan\": 600000000,\n\"notificationChannelIds\": ],\n\"reNotify\": false,\n\"reNotifyMinutes\": 30,\n\"segmentBy\": ],\n\"segmentCondition\": {\n\"type\": \"\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_02501-7-1681","score":14.842682065,"text":"\nIntegrating with the Monitoring service \n\nYou can send alerts to the Monitoring service and manage them through the Events view section.\n\n\n\n Configuring a Monitoring alert \n\nWhen you [configure an alert](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-alertsconfigure-an-alert) you can have that alert sent to Monitoring.\n\n\n\n1. When configuring your alert, click ![Sysdig icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/6f3c07c34058f637b1c86044ca4f9b24214330a7\/activity-tracker\/images\/sysdig.png).\n2. Select if you want the alert to be sent when the condition exists (Presence) or does not exist (Absence).\n3. Indicate the logging criteria when an alert should be sent. For example, when 100 lines matching in the view are logged in an hour. A graph will help you determine the number of log lines matching your specified criteria.\n4. Select if the alert should be sent at the end of the selected period or immediately when the number of lines are logged.\n5. Optionally you can specify a Custom schedule with alerting limited to a specified timezone, days of the week, or timeframe. To configure a Custom schedule:\n\n\n\n1. Select on for Custom schedule.\n2. Select the Timezone for the log entries.\n3. Select the days of the week when alerts should be generated.\n4. Optionally specify a time range for the selected days. A graph will help you determine the number of log entries for the timezone and time range.\n\n\n\n6. Configure the Monitoring instance details.\n\nSpecify the API key. Set this field to the API token. For more information on how to get the token, see [Working with tokens](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-api_token).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-monitoring"},{"document_id":"ibmcld_09415-7-1658","score":14.8092558441,"text":"\nIntegrating with IBM Cloud Monitoring \n\nYou can send alerts to IBM Cloud Monitoring and manage them through the Events view section.\n\n\n\n Configuring an alert \n\nWhen you [configure an alert](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-alerts) you can have that alert sent to IBM Cloud Monitoring.\n\n\n\n1. When configuring your alert, click ![Sysdig icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/images\/sysdig.png).\n2. Select if you want the alert to be sent when the condition exists (Presence) or does not exist (Absence).\n3. Indicate the logging criteria when an alert should be sent. For example, when 100 lines matching in the view are logged in an hour. A graph will help you determine the number of log lines matching your specified criteria.\n4. Select if the alert should be sent at the end of the selected period or immediately when the number of lines are logged.\n5. Optionally you can specify a Custom schedule with alerting limited to a specified timezone, days of the week, or timeframe. To configure a Custom schedule:\n\n\n\n1. Select on for Custom schedule.\n2. Select the Timezone for the log entries.\n3. Select the days of the week when alerts should be generated.\n4. Optionally specify a time range for the selected days. A graph will help you determine the number of log entries for the timezone and time range.\n\n\n\n6. Configure the Monitoring instance details.\n\nSpecify the API key. Set this field to the API token. For more information on how to get the token, see [Working with tokens](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-api_monitoring_token).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-monitoring"},{"document_id":"ibmcld_09701-12088-14157","score":14.5631207565,"text":"\nSeverity Severity status \n\n 0 HIGH \n 1 HIGH \n 2 MEDIUM \n 3 MEDIUM \n 4 LOW \n 5 LOW \n 6 INFO \n 7 INFO \n\n\n\n\n\n\n\n segmentBy (array of strings) \n\nDefines additional segmentation criteria.\n\nFor example, you can segment a CPU alert by ['host.mac', 'proc.name'] so the alert can report on any process in any machine for which you get data in the monitoring instance.\n\n\n\n\n\n segmentCondition (string) \n\nDefines when the alert is triggered for each monitored entity that is specified in the segmentBy parameter. This parameter is required for MANUAL alerts only.\n\nValid values are the following:\n\n\n\n* ANY: The alert is triggered when at least one of the monitored entities satisfies the condition.\n* ALL: The alert is triggered when all of the monitored entities satisfy the condition.\n\n\n\n\n\n\n\n teamId (string) \n\nDefines the GUID of the team that owns the alert.\n\n\n\n\n\n type (string) \n\nDefines the type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\nSet to MANUAL for alerts that you want to control when a notification is sent. You must define the threshold that determines when the alert is triggered.\n\nSet to BASELINE for alerts that you want to notify when unexpected metric values are detected. New metric data is compared with metric values that are collected over time.\n\nSet to HOST_COMPARISON for alerts that you want to notify when 1 host in a group reports metrics values that are different from the other hosts in the group.\n\n\n\n\n\n timespan (integer) \n\nMinimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered.\n\nThe minimum value is 60000000 microseconds, that is, 1 minute.\n\nThe value of this parameter must be a multiple of 60000000 microseconds.\n\n\n\n\n\n version (integer) \n\nVersion of an alert.\n\nThe version changes every time you update an alert.\n\nThe version is used for optimistic locking.\n\n\n\n\n\n\n\n Query parameters \n\n\n\n alertId (integer) \n\nID of an alert.\n\n\n\n\n\n from (long) \n\nDefines the start timestamp, in microseconds, that is used when you request information about alerts that are defined.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_10852-50127-51451","score":14.3076749642,"text":"\n* [Implementing feeds with polling](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_customfeeds_polling)\n* [Implementing feeds by using connections](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-feeds_customfeeds_connections)\n\n\n\n[IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-alerts-notifyalerts-notify)\n\n\n\n Watson packages \n\n[Watson Assistant](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_watson_assistantpkg_watson_assistant)\n\n\n\n* [Creating a Watson Assistant service instance](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_watson_assistantservice_instance_conversation)\n* [Installing the Watson Assistant package](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_watson_assistantinstall_conversation)\n\n\n\n* [Installing from the Cloud Functions CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_watson_assistantconversation_cli)\n* [Installing from the Cloud Functions console](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_watson_assistantconversation_ui)\n\n\n\n* [Using the Watson Assistant package](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_watson_assistantusage_conversation)\n\n\n\n[Natural Language Classifier](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_natlang_classifierpkg_natlang_classifier)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16261-10613-12744","score":24.6166441081,"text":"\nBecause we need a way to end the conversation, the client app is also watching for the literal command quit to indicate that the program should exit.\n\nBut something still isn't right:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nI'm afraid I don't understand. Please rephrase your question.\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Thursday\nI'm afraid I don't understand. Please rephrase your question.\n>>\n\nThe assistant is starting out with the correct greeting, but it doesn't understand when you tell it your name. And if you tell it you want to make an appointment, the correct action is triggered; but once again, it doesn't understand when you answer the follow-up question.\n\nThis is happening because we are using the stateless message method, which means that it is the responsibility of our client application to maintain state information for the conversation. Because we are not yet doing anything to maintain state, the assistant sees every round of user input as the first turn of a new conversation. Because it has no memory of asking a question, it tries to interpret your answer as a new question or request.\n\n\n\n\n\n Maintaining state \n\nState information for your conversation is maintained using the context. The context is an object that is passed back and forth between your application and the assistant, storing information that can be preserved and updated as the conversation goes on. Because we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_16306-8539-10329","score":23.8973656678,"text":"\nIf no utterance is received before the timeout occurs, the phone integration sends a message to the assistant that includes the post_response_timeout_occurred property set to true. \n cdr_custom_data Object A JSON object containing key\/value pairs to be stored in the CDR record for the call. Each time this object is sent, its contents are merged with data sent previously during the call. \n turn_settings.timeout_count Integer The time (in milliseconds) to wait for Watson Assistant to finish processing each conversation turn. \n\n\n\n\n\n\n\n Example request JSON \n\n\"voice_telephony\" : {\n\"post_response_timeout_count\":10000,\n\"final_utterance_timeout_count\":30000,\n\"turn_settings\": {\n\"timeout_count\": 5000\n},\n\"cdr_custom_data\" : {\n\"custom_data_1\": \"data 1\",\n\"custom_data_2\": \"data 2\"\n}\n}\n\n\n\n\n\n\n\n text_messaging \n\nIncluded only if the SMS with Twilio integration is in use.\n\n\n\n Properties \n\nProperties contained in the private object are treated as private variables, which are not included in logs.\n\n\n\nProperties of the text_messaging object\n\n Name Type Description \n\n assistant_phone_number String The phone number associated with with the Watson Assistant end of the conversation. \n private.user_phone_number String The phone number from which the customer's SMS message originated. \n\n\n\n\n\n\n\n Example JSON \n\n\"text_messaging\": {\n\"private\":{\n\"user_phone_number\":\"+18595553456\"\n},\n\"assistant_phone_number\":\"+18885556789\"\n}\n\n\n\n\n\n\n\n whatsapp \n\nIncluded only if the WhatsApp integration is in use.\n\n\n\n Properties \n\nProperties contained in the private object are treated as private variables, which are not included in logs.\n\n\n\nProperties of the whatsapp object\n\n Name Type Description \n\n assistant_phone_number String The phone number associated with with the Watson Assistant end of the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-expression-integration-variables"},{"document_id":"ibmcld_16261-12076-14011","score":22.9754449389,"text":"\nBecause we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.\n\nIn addition to maintaining our place in the conversation, the context can also contain action variables that store any other data you want to pass back and forth between your application and the assistant. This can include persistent data you want to maintain throughout the conversation (such as a customer's name or account number), or any other data you want to track (such as the contents of a shopping cart or user preferences).\n\n\n\n* Python\n* Node\n\n\n\n Example 3: Preserves context to maintain state.\n\nfrom ibm_watson import AssistantV2\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n\n Create Assistant service object.\nauthenticator = IAMAuthenticator('{apikey}') replace with API key\nassistant = AssistantV2(\nversion = '2021-11-27',\nauthenticator = authenticator\n)\nassistant.set_service_url('{url}') replace with service instance URL\nassistant_id = '{environment_id}' replace with environment ID\n\n Initialize with empty message to start the conversation.\nmessage_input = {\n'message_type:': 'text',\n'text': ''\n}\ncontext = {}\n\n Initialize with empty message to start the conversation.\nmessage_input = {\n'message_type:': 'text',\n'text': ''\n}\ncontext = {}\n\n Main input\/output loop\nwhile message_input['text'] != 'quit':\n\n Send message to assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_16322-7-2220","score":21.8154808434,"text":"\nPhone integration context variables \n\nYou can use context variables to manage the flow of conversations with customers who interact with your assistant over the telephone.\n\nThe following tables describe the context variables that have special meaning in the context of the phone integration. They should not be used for any purpose other than the documented use.\n\n\n\n Context variables that are set by the phone channel \n\n\n\nContext variables set by the phone channel\n\n Name Type Description \n\n sip_call_id string The SIP call ID associated with the Watson Assistant session. \n sip_custom_invite_headers object A JSON object containing key\/value pairs defining SIP headers that are pulled from the initial SIP INVITE request and passed to the Watson Assistant service (for example, {\"Custom-Header1\": \"123\"}). \n private.sip_from_uri string The SIP From URI associated with the Watson Assistant service. \n private.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.\n\n\n\nInput parameters set by the phone channel\n\n Name Type Description \n\n post_response_timeout_occurred boolean Whether the post response timeout expired. \n barge_in_occurred boolean Whether barge-in occurred. \n final_utterance_timeout_occurred true or false Whether the final utterance timeout expired. \n dtmf_collection_succeeded boolean Whether the DTMF collection succeeded or failed. When true, a DTMF collection succeeded, and returns the expected number of digits. When false, a DTMF collection failed to collect the specified number of digits. Even when dtmf_collection_succeeded is false, all collected digits are passed to the dialog in the input string of the turn request. \n is_dtmf boolean Whether the input to Watson Assistant is dual-tone multi-frequency signaling (DTMF).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-context"},{"document_id":"ibmcld_03367-1712-3458","score":21.7427922246,"text":"\nIf this time is exceeded, the phone integration tries again to contact Watson Assistant. If the service still can't be reached, the call fails. N\/A \n cdr_custom_data object Any JSON key\/value pairs to collect and store with the CDR record at the end of the phone call. Each time this object is received, it is merged with any previously received cdr_custom_data context. N\/A \n\n\n\n\n\n Example \n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text\",\n\"text\": \"Hello\"\n}\n]\n},\n\"context\": {\n\"integrations\": {\n\"voice_telephony\": {\n\"post_response_timeout_count\": 10000,\n\"turn_settings\": {\n\"timeout_count\": 5000\n},\n\"cdr_custom_data\": {\n\"key1\": \"value1\",\n\"key2\": \"value2\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n\n\n Context variables that are set by the phone channel \n\n\n\nContext variables set by the phone channel\n\n Name Type Description \n\n sip_call_id string The SIP call ID associated with the Watson Assistant session. \n sip_custom_invite_headers object A JSON object containing key\/value pairs defining SIP headers that are pulled from the initial SIP INVITE request and passed to the Watson Assistant service (for example, {\"Custom-Header1\": \"123\"}). \n private.sip_from_uri string The SIP From URI associated with the Watson Assistant service. \n private.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context"},{"document_id":"ibmcld_03367-2935-4844","score":21.734319532,"text":"\nprivate.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.\n\n\n\nInput parameters set by the phone channel\n\n Name Type Description \n\n post_response_timeout_occurred boolean Whether the post response timeout expired. \n barge_in_occurred boolean Whether barge-in occurred. \n final_utterance_timeout_occurred true or false Whether the final utterance timeout expired. \n dtmf_collection_succeeded boolean Whether the DTMF collection succeeded or failed. When true, a DTMF collection succeeded, and returns the expected number of digits. When false, a DTMF collection failed to collect the specified number of digits. Even when dtmf_collection_succeeded is false, all collected digits are passed to the dialog in the input string of the turn request. \n is_dtmf boolean Whether the input to Watson Assistant is dual-tone multi-frequency signaling (DTMF). \n speech_to_text_result object The final response from the Speech to Text service in JSON format, including the transcript and confidence score for the top hypothesis and any alternatives. The format matches exactly the format that is received from the Speech to Text service. (For more information, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-textrecognize).) \n\n\n\n\n\n Example \n\n{\n\"input\": {\n\"text\": \"agent \",\n\"integrations\": {\n\"voice_telephony\": {\n\"speech_to_text_result\": {\n\"result_index\": 0,\n\"stopTimestamp\": \"2021-09-29T17:43:31.036Z\",\n\"transaction_ids\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context"},{"document_id":"ibmcld_16262-6573-7996","score":21.3057395414,"text":"\n{\n\"output\": {\n\"generic\": [!\n{\n\"response_type\": \"text\",\n\"text\": \"Welcome to the Watson Assistant example\"\n}\n],\n\"intents\": [\n{\n\"intent\": \"hello\",\n\"confidence\": 1\n}\n],\n\"entities\": []\n},\n\"user_id\": \"my_user_id\",\n\"context\": {\n\"global\": {\n\"system\": {\n\"turn_count\": 1,\n\"user_id\": \"my_user_id\"\n}\n},\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"account_number\": \"123456\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n Restoring conversation state \n\nIn some situations, you might want the ability to restore a conversation to a previous state.\n\nYou can use the export option on stateful message requests to specify that you want the context object in the response to include complete session state data. If you specify true for this option, the returned skill context includes an encoded state property that represents the current conversation state.\n\nIf you are using the stateful message API, the service stores conversation state data only for the life of the session. However, if you save this context data (including state) and send it back to the service with a subsequent message request, you can restore the conversation to the same state, even if the original session expired or was deleted.\n\nIf you are using the stateless message API, the state property is always included in responses (along with the rest of context). Although stateless sessions do not expire, you can still use this state data to reset a conversation to a previous state.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context"},{"document_id":"ibmcld_03363-4-2165","score":21.2095308526,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03423-14168-15303","score":20.7687473363,"text":"\nThe assistant_interaction_summaries object contains the following keys:\n\n\n\nKeys for the assistant_interaction_summaries object\n\n Key Type Description \n\n assistant_id string The unique identifier of the assistant. \n session_id string The unique identifier of the session. \n turns JSON array An array of the Watson Assistant transactions that took place during the conversation. \n\n\n\nThe turn object contains the following keys:\n\n\n\nKeys for the turn object\n\n Key Type Description \n\n assistant.log_id string A unique identifier for the logged transaction. Can be used to correlate between message logs and CDR events. \n assistant.start_timestamp string. Time in the ISO format yyyy-MM-ddTHH:mm:ss.SSSZ Time when the request was sent to Watson Assistant. \n assistant.response_milliseconds number Time between when the request was sent and when the response was received from Watson Assistant. \n request JSON object A request sent to Watson Assistant. \n response JSON array An array of the response objects associated with the request. \n\n\n\nThe request object contains the following keys:\n\n\n\nKeys for the request object\n\n Key Type Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-log"},{"document_id":"ibmcld_16274-4164-6148","score":20.6576363733,"text":"\nheaders.from_uri String The SIP URI from the initial SIP INVITE From header. \n headers.to_uri String The SIP URI from the initial SIP INVITE To header. \n\n\n\n\n\n\n\n assistant_interaction_summaries \n\nThe assistant_interaction_summaries object contains the following properties:\n\n\n\nProperties of the assistant_interaction_summaries object\n\n Property Type Description \n\n assistant_id String The unique identifier of the assistant. \n session_id String The unique identifier of the session. \n turns Array An array of objects describing the Watson Assistant interactions that took place during the conversation. See [assistant_interaction_summaries.turns]](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-cdr-log-referencecdr-log-reference-turns). \n\n\n\n\n\n assistant_interaction_summaries.turns[] \n\nThe objects in the assistant_interaction_summaries.turns array contain the following properties:\n\n\n\nProperties of the objects in the assistant_interaction_summaries.turns[] array\n\n Property Type Description \n\n assistant.log_id String A unique identifier for the logged event. This can be used to correlate between message logs and CDR events. \n assistant.start_timestamp String The time when the request was sent to the assistant, in ISO format (yyyy-MM-ddTHH:mm:ss.SSSZ). \n assistant.response_milliseconds Number The time (in milliseconds) between when the request was sent and when the response was received from the assistant. \n request Object A request sent to the assistant. See [assistant_interaction_summaries.turns].request](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-cdr-log-referencecdr-log-reference-request). \n response Array An array of the response objects associated with the request. \n\n\n\n\n\n assistant_interaction_summaries.turns[].request \n\nThe assistant_interaction_summaries.turns[].request object contains the following properties:\n\n\n\nProperties of the assistant_interaction_summaries.turns[].request object\n\n Property Type Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-cdr-log-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03036-2789-4951","score":23.5019648604,"text":"\nIf you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-4-2165","score":21.0454991021,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03363-1671-3630","score":19.287058846,"text":"\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_05479-871-1495","score":16.2228285107,"text":"\n{\"level\":\"info\",\"ts\":1625217529.370393,\"logger\":\"git\",\"msg\":\"ssh\",\"path\":\"\/usr\/bin\/ssh\",\"version\":\"OpenSSH_8.0p1, OpenSSL 1.1.1g FIPS 21 Apr 2020\"}\n{\"level\":\"info\",\"ts\":1625217529.3847454,\"logger\":\"git\",\"msg\":\"git\",\"path\":\"\/usr\/bin\/git\",\"version\":\"git version 2.27.0\"}\n{\"level\":\"info\",\"ts\":1625217529.3940003,\"logger\":\"git\",\"msg\":\"git-lfs\",\"path\":\"\/usr\/bin\/git-lfs\",\"version\":\"git-lfs\/2.11.0 (GitHub; linux amd64; go 1.14.4)\"}\n{\"level\":\"debug\",\"ts\":1625217529.3940916,\"logger\":\"git\",\"msg\":\"\/usr\/bin\/git clone --quiet --no-tags --branch main --depth 1 --single-branch -- https:\/\/github.com\/IBM\/CodeEngineX \/workspace\/source\"}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-ts-build-gitsource-stepfail"},{"document_id":"ibmcld_12430-2025-3161","score":16.1215054364,"text":"\nmsg: \"{{ lookup('community.hashi_vault.hashi_vault', 'secret=ibmcloud\/kv\/data\/mykvsecret:key1 token={{ vault_token }} url={{ hostname_vault }}') }}\"\n\n- name: Lookup User Credentials secret with token - full\nvars:\nsecret_id: \"dc1d3b5a-176f-aea4-8124-7073f53dcf82\"\nansible.builtin.debug:\nmsg: \"{{ lookup('community.hashi_vault.hashi_vault', 'secret=ibmcloud\/username_password\/secrets\/{{ secret_id }} token={{ vault_token }} url={{ hostname_vault }}') }}\"\n\n- name: Parsing username_password\nvars:\nsecret_id: \"dc1d3b5a-176f-aea4-8124-7073f53dcf82\"\nsecret_data: \"{{ lookup('community.hashi_vault.hashi_vault', 'secret=ibmcloud\/username_password\/secrets\/{{ secret_id }}:secret_data token={{ vault_token }} url={{ hostname_vault }}') | to_json }} \"\nansible.builtin.debug:\nmsg: \"user is {{ secret_data.username }} and password is {{ secret_data.password }}\"\n\nwhen: login.status == 200\nShow more\n\nA successful request returns the following response.\n\nTASK [Lookup KV secret with token] \nok: [localhost] => {\n\"msg\": \"secret1\"\n}\n\nTASK [Lookup User Credentials secret with token - full] \nok: [localhost] => {\n\"msg\": {\n\"created_by\": \"xxxxxxxxxxxxx\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-integration-ansible"},{"document_id":"ibmcld_05367-2825-4556","score":16.054656954,"text":"\nAfter you create and run your Function, you can also update your Function by using any of the preceding ways, independent of how you created or previously updated your Function.\n\n\n\n\n\n Requests and responses \n\nFunctions are invoked with the HTTP protocol. When you invoke your Function, you can specify the custom request parameters, custom request body and headers, as well as the HTTP method. The request parameters are made available to the Function code as input parameters. The Function code can set the response body, response headers, and response code, which are returned to the caller from the Functions endpoint.\n\n\n\n Example 1: Generating an HTML response from a Function \n\nThe following example illustrates how to generate an HTML response from a Function.\n\nfunction main(params) {\nvar msg = 'You did not tell me who you are.';\nif (params.name) {\nmsg = Hello, ${params.name}!\n} else {\nmsg = Hello, FaaS on CodeEngine!\n}\nreturn {\nheaders: { 'Content-Type': 'text\/html; charset=utf-8' },\nbody: <html><body><h3>${msg}<\/h3><\/body><\/html>\n}\n}\n\nmodule.exports.main = main;\n\n\n\n\n\n Example 2: Setting a response code and response header \n\nYour Function can set a specific response code and header flags. The following example illustrates how you can set a response code and response header to add a redirect to a different URL.\n\nfunction main(params) {\nreturn {\nheaders: { location: 'https:\/\/cloud.ibm.com\/docs\/codeengine' },\nstatusCode: 302\n}\n}\n\n\n\n\n\n Example 3: Generating a plain text response from a Function \n\nThe following example illustrates how to generate a plain text response from a Function.\n\nfunction main(params) {\nvar msg = 'You did not tell me who you are.';\nif (params.name !== \"\") {\nmsg = Hello, ${params.name}!\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-work"},{"document_id":"ibmcld_11852-5893-6717","score":15.8048229182,"text":"\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.133Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agentOps\",\"msgid\":\"A02\",\"msg\":\"Load SATELLITE_CONNECTOR_ID value from SATELLITE_CONNECTOR_ID environment variable.\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.138Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agentOps\",\"msgid\":\"A01\",\"msg\":\"Load SATELLITE_CONNECTOR_IAM_APIKEY value from file \/agent-env-files\/apikey.\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.140Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agentOps\",\"msgid\":\"A02\",\"msg\":\"Load SATELLITE_CONNECTOR_TAGS value from SATELLITE_CONNECTOR_TAGS environment variable.\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.141Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agentOps\",\"msgid\":\"A02\",\"msg\":\"Load SATELLITE_CONNECTOR_REGION value from SATELLITE_CONNECTOR_REGION environment variable.\"}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-run-agent-locally"},{"document_id":"ibmcld_11852-7002-7827","score":15.7694903398,"text":"\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.392Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"tunneldns\",\"msgid\":\"D04\",\"msg\":\"DoTunnelDNSLookup DNS resolve c-01-ws.us-south.link.satellite.cloud.ibm.com to 169.61.31.178\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:21.560Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"utilities\",\"msg\":\"MakeLinkAPICall GET \/v1\/connectors\/U2F0ZWxsaXRlQ29ubmVjdG9yOiJjaThzdWd1ZDFwZ2RrZmUxa3UxZyI status code 200\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:21.563Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agent_tunnel\",\"msgid\":\"LAT03\",\"msg\":\"Got configuration\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:21.565Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agent_tunnel\",\"msgid\":\"LAT04-wss:\/\/c-01-ws.us-south.link.satellite.cloud.ibm.com\/ws\",\"msg\":\"Connecting to wss:\/\/c-01-ws.us-south.link.satellite.cloud.ibm.com\/ws\"}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-run-agent-locally"},{"document_id":"ibmcld_11755-0-1532","score":15.6047847154,"text":"\n\n\n\n\n\n\n  Why does host assign fail with a CRI-O error? \n\n  What\u2019s happening \n\nWhen you try to assign a host to a cluster, you see a message similar to the following error.\n\nDec 01 11:45:31 satellite.host crio[12190]: time=\"2021-12-01 11:45:31.818616215-06:00\" level=info msg=\"Node configuration value for pid cgroup is true\"\nDec 01 11:45:31 satellite.host crio[12190]: time=\"2021-12-01 11:45:31.818820217-06:00\" level=info msg=\"Node configuration value for memoryswap cgroup is true\"\nDec 01 11:45:31 satellite.host crio[12190]: time=\"2021-12-01 11:45:31.830378308-06:00\" level=info msg=\"Node configuration value for systemd CollectMode is true\"\nDec 01 11:45:31 satellite.host crio[12190]: time=\"2021-12-01 11:45:31.834555839-06:00\" level=error msg=\"Node configuration validation for systemd AllowedCPUs failed: check systemd AllowedCPUs: exit status 1\"\nDec 01 11:45:31 satellite.host crio[12190]: time=\"2021-12-01 11:45:31.834638109-06:00\" level=info msg=\"Node configuration value for systemd AllowedCPUs is false\"\nDec 01 11:45:31 satellite.host crio[12190]: time=\"2021-12-01 11:45:31.837060028-06:00\" level=fatal msg=\"Validating root config: failed to get store to set defaults: kernel does not support overlay fs: 'overlay' is not supported over xfs at \"\/var\/data\/criorootstorage\/overlay\": backing file system is unsupported for this graph driver\n\n  Why it\u2019s happening \n\nThe host file system is a type other than ext4.\n\n  How to fix it \n\nConvert the host file system to ext4 or provision a new host with an ext4 file system.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-assign-file-system"},{"document_id":"ibmcld_11852-6505-7216","score":15.4829410149,"text":"\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.141Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"agentOps\",\"msgid\":\"A02\",\"msg\":\"Load SATELLITE_CONNECTOR_REGION value from SATELLITE_CONNECTOR_REGION environment variable.\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.142Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"connector-agent\",\"msgid\":\"LA2\",\"msg\":\"Connector id: U2F0ZWxsaXRlQ29ubmVjdG9yOiJjaThzdWd1ZDFwZ2RrZmUxa3UxZyI, region: us-south, release info: 20230610-dd48822928d35a84b31029a996fa9abc9d29fc93_A.\"}\n{\"level\":30,\"time\":\"2023-06-20T16:12:20.392Z\",\"pid\":8,\"hostname\":\"6b793f671c79\",\"name\":\"tunneldns\",\"msgid\":\"D04\",\"msg\":\"DoTunnelDNSLookup DNS resolve c-01-ws.us-south.link.satellite.cloud.ibm.com to 169.61.31.178\"}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-run-agent-locally"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03329-1102-2607","score":31.6543149321,"text":"\n[Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-gs-dialog"},{"document_id":"ibmcld_02998-1325-2715","score":31.1613610428,"text":"\nName the assistant My first assistant.\n3. Click Create assistant.\n\n![Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-create-assistant-done.png)\n\n\n\n\n\n\n\n Step 3: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click the My first assistant tile to open the assistant.\n2. Click Add dialog skill.\n\n![Shows the Add skill button from the home page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-dialog-skill.png)\n3. Click the Create skill tab.\n4. Give your skill the name My first skill.\n5. Optional: If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-skill-done.png)\n6. Click Create skill.\n\n![Shows the My first assistant with the My first skill added to it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-my-first-skill.png)\n7. Click the skill you just created to open it.\n\n\n\n\n\n\n\n Step 4: Add intents from a content catalog","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03049-1355-3132","score":30.7657967077,"text":"\nClick Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-data-v1?curl=createworkspace).)\n* The JSON cannot contain tabs, newlines, or carriage returns.\n\n\n\nSpecify the data you want to include:\n\n\n\n* Select Everything (Intents, Entities, and Dialog) if you want to import a complete copy of the exported skill, including the dialog.\n* Select Intents and Entities if you want to use the intents and entities from the exported skill, but you plan to build a new dialog.\n\n\n\nClick Import.\n\nIf you have trouble importing a skill, see [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-addskill-dialog-add-import-errors).\n\n\n\n5. Specify the details for the skill:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03369-66296-68553","score":30.6886673391,"text":"\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-103662-105841","score":30.4113243557,"text":"\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nThe actions skill is available as a beta feature. For more information, see [Adding an actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add).\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance. For more information, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\nText messaging integration was renamed\n: The Twilio messaging integration was renamed to SMS with Twilio.\n\n\n\n\n\n 9 October 2020 \n\nSearch skill update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03369-36856-39124","score":29.6025100937,"text":"\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests.\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-146046-148039","score":29.1667316534,"text":"\n: For some first-time users, a new introductory product tour is shown that the user can choose to follow to perform the initial steps of creating an assistant.\n\n\n\n\n\n 1 August 2019 \n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. The new Webhook support simplifies the callout implementation process. (No more action JSON objects required.) For more information, see [Making a programmatic call from a dialog node](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-webhooks).\n\nImproved dialog page responsiveness\n: In all service instances, the user interface of the Dialog page was updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\n\n\n\n\n 31 July 2019 \n\nSearch skill and autocorrection are generally available\n: The search skill and spelling autocorrection features, which were previously available as beta features, are now generally available.\n\n\n\n* Search skills can be created by users of Plus or Premium plans only.\n* You can enable autocorrection for English-language dialog skills only. It is enabled automatically for new English-language dialog skills.\n\n\n\n\n\n\n\n 26 July 2019 \n\nMissing skills issue is resolved\n: In some cases, workspaces that were created through the API only were not being displayed when you opened the Watson Assistant user interface. This issue has been addressed. All workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03369-108318-110450","score":28.7751294628,"text":"\nYou can use this method to extract a specific occurrence of a regular expression pattern that recurs in user input. For more details, see the [dialog methods](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methodsdialog-methods-strings-getMatch) topic.\n\n\n\n\n\n 9 August 2019 \n\nIntroductory product tour\n: For some first-time users, a new introductory product tour is shown that the user can choose to follow to perform the initial steps of creating an assistant.\n\n\n\n\n\n 6 August 2019 \n\n\n\n* Webhook callouts and Dialog page improvements are available in Dallas.\n\n\n\n\n\n\n\n 1 August 2019 \n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. The new Webhook support simplifies the callout implementation process. (No more action JSON objects required.) For more information, see [Making a programmatic call from a dialog node](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-webhooks).\n\nImproved dialog page responsiveness\n: In all service instances, the user interface of the Dialog page was updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\n\n\n\n\n 31 July 2019 \n\nSearch skill and autocorrection are generally available\n: The search skill and spelling autocorrection features, which were previously available as beta features, are now generally available.\n\n\n\n* Search skills can be created by users of Plus or Premium plans only.\n* You can enable autocorrection for English-language dialog skills only. It is enabled automatically for new English-language dialog skills.\n\n\n\n\n\n\n\n 26 July 2019 \n\nMissing skills issue is resolved\n: In some cases, workspaces that were created through the API only were not being displayed when you opened the Watson Assistant user interface. This issue has been addressed. All workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-101992-104197","score":28.7465999749,"text":"\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03381-1467-3226","score":28.3993308239,"text":"\nThe uploaded JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10 MB. If you need to upload a larger skill, consider using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1?curl=createworkspace).\n\nClick Upload.\n\nIf you have trouble uploading a skill, see [Troubleshooting skill upload issues](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors).\n* If you have created a dialog skill already, the Add existing skill tab is displayed, and you can click to add an existing skill.\n\n\n\n3. Specify the details for the skill:\n\n\n\n* Name: A name no more than 64 characters in length. A name is required.\n* Description: An optional description no more than 128 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n4. For Skill type, choose Dialog.\n5. Click Create skill.\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog).\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Troubleshooting skill upload issues","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1412669729}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03353-5263-7331","score":29.0053216952,"text":"\nItalian (it) GA Deprecated \n Japanese (ja) GA Deprecated \n Korean (ko) GA Deprecated \n Portuguese (Brazilian) (pt-br) GA Deprecated \n Spanish (es) GA Deprecated \n Universal (xx) GA NA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the tool interface itself (descriptions, labels, etc.) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee has mandated that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing a skill language \n\nOnce a skill has been created, its language cannot be modified. If it is necessary to change the supported language of a skill, you can do so by editing the skill's underlying JSON.\n\nTo change the skill language, take the following steps:\n\n\n\n1. Download the skill that you want to edit.\n2. Open the downloaded skill JSON file in a text editor.\n3. Search for the property named language.\n\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_03027-4976-6968","score":28.3729945791,"text":"\nEnglish (en) GA Deprecated \n Arabic (ar) GA Deprecated \n Chinese (Simplified) (zh-cn) GA Deprecated \n Chinese (Traditional) (zh-tw) GA Deprecated \n Czech (cs) GA Deprecated \n Dutch (nl) GA Deprecated \n French (fr) GA Deprecated \n German (de) GA Deprecated \n Italian (it) GA Deprecated \n Japanese (ja) GA Deprecated \n Korean (ko) GA Deprecated \n Portuguese (Brazilian) (pt-br) GA Deprecated \n Spanish (es) GA Deprecated \n Universal (xx) GA NA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the tool interface itself (descriptions, labels, etc.) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee has mandated that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing a skill language \n\nOnce a skill has been created, its language cannot be modified. If it is necessary to change the supported language of a skill, you can do so by editing the skill's underlying JSON.\n\nTo change the skill language, take the following steps:\n\n\n\n1. Download the skill that you want to edit.\n2. Open the downloaded skill JSON file in a text editor.\n3. Search for the property named language.\n\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_03353-4-2000","score":28.1113028125,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Supported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a Beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add) [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add) \n\n English (en) GA GA GA \n Arabic (ar) GA GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_02839-1790-3940","score":27.4787008156,"text":"\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03027-7-1946","score":27.4370422406,"text":"\nSupported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add) \n\n English (en) GA GA \n Arabic (ar) GA GA \n Chinese (Simplified) (zh-cn) GA GA \n Chinese (Traditional) (zh-tw) GA GA \n Czech (cs) GA GA \n Dutch (nl) GA GA \n French (fr) GA GA \n German (de) GA GA \n Italian (it) GA GA \n Japanese (ja) GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_03120-3469-5331","score":27.1985851168,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_02855-19323-21142","score":27.0173716275,"text":"\nintegrationID: 'YOUR_INTEGRATION_ID',\nregion: 'YOUR_REGION',\nserviceInstanceID: 'YOUR_SERVICE_INSTANCE',\nonLoad: function(instance) {\ninstance.updateUserID(L12345);\ninstance.render();\n}\n};\nsetTimeout(function(){\nconst t=document.createElement('script');\nt.src=\"https:\/\/web-chat.global.assistant.watson.appdomain.cloud\/loadWatsonAssistantChat.js\";\ndocument.head.appendChild(t);\n});\n<\/script>\nShow more\n\n\n\n\n\n\n\n Global audience support \n\nThe underlying skills understand customer messages that are written in any of the languages that are supported by the service. For more information, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support). The responses from your assistant are defined by you in the underlying skill and can be written in any language you want.\n\nEven if your skill includes responses in a language other than English, some of the phrases that are displayed in the web chat widget are added by the web chat itself and do not come from the underlying skill. These hardcoded phrases are specified in English unless you choose to apply a different language.\n\nThere are language files that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1. To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03418-1763-3833","score":27.0010760086,"text":"\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Global audience support \n\nThe underlying skills understand customer messages that are written in any of the languages that are supported by the service. For more information, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support). The responses from your assistant are defined by you in the underlying skill and can be written in any language you want.\n\nEven if your skill includes responses in a language other than English, some of the phrases that are displayed in the web chat widget are added by the web chat itself and do not come from the underlying skill. These hardcoded phrases are specified in English unless you choose to apply a different language.\n\nThere are language files that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1. To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basics"},{"document_id":"ibmcld_02839-7-2335","score":26.9745501277,"text":"\nAdding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03120-1659-3917","score":26.8766270181,"text":"\nThe precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website. Deploy your German-speaking assistant to the German page of your website. Maybe you have a support phone number for French customers. You can configure your French-speaking assistant to answer those calls, and configure another phone number that German customers can use.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03329-1102-2607","score":20.5981154486,"text":"\n[Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-gs-dialog"},{"document_id":"ibmcld_02998-1325-2715","score":20.5103359128,"text":"\nName the assistant My first assistant.\n3. Click Create assistant.\n\n![Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-create-assistant-done.png)\n\n\n\n\n\n\n\n Step 3: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click the My first assistant tile to open the assistant.\n2. Click Add dialog skill.\n\n![Shows the Add skill button from the home page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-dialog-skill.png)\n3. Click the Create skill tab.\n4. Give your skill the name My first skill.\n5. Optional: If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-skill-done.png)\n6. Click Create skill.\n\n![Shows the My first assistant with the My first skill added to it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-my-first-skill.png)\n7. Click the skill you just created to open it.\n\n\n\n\n\n\n\n Step 4: Add intents from a content catalog","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03049-1355-3132","score":20.1406957618,"text":"\nClick Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-data-v1?curl=createworkspace).)\n* The JSON cannot contain tabs, newlines, or carriage returns.\n\n\n\nSpecify the data you want to include:\n\n\n\n* Select Everything (Intents, Entities, and Dialog) if you want to import a complete copy of the exported skill, including the dialog.\n* Select Intents and Entities if you want to use the intents and entities from the exported skill, but you plan to build a new dialog.\n\n\n\nClick Import.\n\nIf you have trouble importing a skill, see [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-addskill-dialog-add-import-errors).\n\n\n\n5. Specify the details for the skill:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_07578-18457-20516","score":20.058491102,"text":"\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-18457-20516","score":20.058491102,"text":"\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16364-103662-105841","score":19.9632301769,"text":"\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nThe actions skill is available as a beta feature. For more information, see [Adding an actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add).\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance. For more information, see [Integrating the web chat with your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat).\n\nText messaging integration was renamed\n: The Twilio messaging integration was renamed to SMS with Twilio.\n\n\n\n\n\n 9 October 2020 \n\nSearch skill update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_07578-78252-80149","score":19.9557619238,"text":"\nWith the V2 API and an Enterprise plan, you can use the Segment extension to see what browser was used to send the message. For more information, see [Sending events to Segment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-segment-add).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nWatson Assistant for IBM Cloud Pak for Data (Installed)\n\n\n\n* What's a...\n\n\n\n Term Definition \n\n Assistant Container for your skills. You add skills to an assistant, and then deploy the assistant when you are ready to start helping your customers. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistants). \n Condition Logic that is defined in the If assistant recognizes section of a dialog node that determines whether the node is processed. The dialog node conditions is equivalent to an If statement in If-Then-Else programming logic. \n Content catalog A set of prebuilt intents that are categorized by subject, such as customer care. You can add these intents to your skill and start using them immediately. Or you can edit them to complement other intents that you create. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog). \n Context variable A variable that you can use to collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables). \n Dialog The component where you build the conversation that your assistant has with your customers. For each defined intent, you can author the response your assistant should return.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-78227-80124","score":19.9557619238,"text":"\nWith the V2 API and an Enterprise plan, you can use the Segment extension to see what browser was used to send the message. For more information, see [Sending events to Segment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-segment-add).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nWatson Assistant for IBM Cloud Pak for Data (Installed)\n\n\n\n* What's a...\n\n\n\n Term Definition \n\n Assistant Container for your skills. You add skills to an assistant, and then deploy the assistant when you are ready to start helping your customers. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistants). \n Condition Logic that is defined in the If assistant recognizes section of a dialog node that determines whether the node is processed. The dialog node conditions is equivalent to an If statement in If-Then-Else programming logic. \n Content catalog A set of prebuilt intents that are categorized by subject, such as customer care. You can add these intents to your skill and start using them immediately. Or you can edit them to complement other intents that you create. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog). \n Context variable A variable that you can use to collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables). \n Dialog The component where you build the conversation that your assistant has with your customers. For each defined intent, you can author the response your assistant should return.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03369-66296-68553","score":19.8289960671,"text":"\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03381-1467-3226","score":19.5813656271,"text":"\nThe uploaded JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10 MB. If you need to upload a larger skill, consider using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1?curl=createworkspace).\n\nClick Upload.\n\nIf you have trouble uploading a skill, see [Troubleshooting skill upload issues](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors).\n* If you have created a dialog skill already, the Add existing skill tab is displayed, and you can click to add an existing skill.\n\n\n\n3. Specify the details for the skill:\n\n\n\n* Name: A name no more than 64 characters in length. A name is required.\n* Description: An optional description no more than 128 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n4. For Skill type, choose Dialog.\n5. Click Create skill.\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-catalog).\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Troubleshooting skill upload issues","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09226-18248-20249","score":26.8646878444,"text":"\n* English to and from Slovenian (en-sl and sl-en)\n\n\n\nNew identifiable languages\n: The following languages can now be identified by the service:\n\n\n\n* Catalan (ca)\n* Croatian (hr)\n* Irish (ga)\n* Malay (ms)\n* Maltese (mt)\n* Serbian (sr)\n* Slovenian (sl)\n* Thai (th)\n\n\n\n\n\n\n\n 14 June 2019 \n\nNew translation models\n: New translation models are now available for English and Greek:\n\n\n\n* English to Greek (en-el)\n* Greek to English (el-en)\n\n\n\n\n\n\n\n 13 June 2019 \n\nNew translation models\n: New translation models are now available for English and Hebrew:\n\n\n\n* English to Hebrew (en-he)\n* Hebrew to English (he-en)\n\n\n\n\n\n\n\n 21 March 2019 \n\nChanges to service credential information\n: From March 21 2019, you will see only service credential information associated with the role that has been assigned to your IBM Cloud account. For example, if you have assigned a reader role, any writer or higher levels of service credentials will not be visible.\n\nThis change does not affect API access for users or applications with existing service key credentials. Only the viewing of credentials within IBM Cloud is affected.\n\nFor more information about service keys and user roles, see [Authenticating to Watson services](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iam).\n\n\n\n\n\n 14 December 2018 \n\nNew London location\n: You can now create Language Translator service instances in the IBM Cloud London location.\n\n\n\n\n\n 16 November 2018 \n\nNew beta support for document translation\n: [Translating documents](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorial) is now available through new API endpoints. Submit a Microsoft Office document, PDF, or other document with a supported file format, and Language Translator will provide a translated copy that preserves the original formatting. [Supported file formats](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorialsupported-file-formats) include .doc, .ppt, .pdf, and more.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-release-notes"},{"document_id":"ibmcld_02839-3583-5403","score":23.4293744186,"text":"\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03120-3469-5331","score":23.2877735778,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_02839-1790-3940","score":22.1660750803,"text":"\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_09226-4688-6719","score":21.4879193695,"text":"\nFor more information about all file formats, their file extensions and content types, and how and when to specify the file extension or content type, see [Supported file formats](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorialsupported-file-formats).\n\nDocumentation updates for bidirectional translation\n: The documentation now states that the service correctly translates from and to bidirectional languages that are written left-to-right and right-to-left (for example, Arabic, Hebrew, and Urdu). This is not new functionality, but the documentation had failed to emphasize the information.\n\n\n\n\n\n 5 August 2022 \n\nThe following changes were made available on 1 August 2021. They are now documented.\n\nMost document formats for translation are now generally available\n: Most supported file formats for document translation are now generally available (GA). In addition, subtitle formats for documentation translation are also GA. The PDF format remains experimental. For more information, see [Supported file formats](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorialsupported-file-formats).\n\n\n\n\n\n 15 June 2022 \n\nThe following changes were made available on 1 November 2021. They are now documented.\n\nNew customizable translation models\n: Added new customizable translation models for the following languages:\n\n\n\n* English to Kannada (en-kn)\n* English to Marathi (en-mr)\n* English to Punjabi (Indian) (en-pa)\n* English to Punjabi (Pakistani) (en-pa-PK)\n* Kannada to English (kn-en)\n* Marathi to English (mr-en)\n* Punjabi (Indian) to English (pa-en)\n* Punjabi (Pakistani) to English (pa-PK-en)\n\n\n\nThe Kannada language is new; it is not identifiable. All of the languages except for Kannada already existed and are identifiable. For more information, see [Supported languages for translation](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-models).\n\nImproved customizable translation models","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-release-notes"},{"document_id":"ibmcld_09913-7-1696","score":21.4773081971,"text":"\nLanguage support \n\nNatural Language Understanding supports a variety of languages depending on which features you analyze. Currently, English is the only language that is supported across all features. The rest of the languages have limited support. To jump to the list of features that are compatible with a language, click the language in the following list.\n\n\n\n* [Arabic](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportarabic)\n* [Chinese (Simplified)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportchinese-simplified)\n* [Czech](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportczech)\n* [Danish](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportdanish)\n* [Dutch](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportdutch)\n* [English](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportenglish)\n* [Finnish](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportfinnish)\n* [French](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportfrench)\n* [German](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportgerman)\n* [Hebrew](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supporthebrew)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_09229-1545-3258","score":21.3164280526,"text":"\n\"supported_as_target\": false,\n\"identifiable\": true\n},\n{\n\"language\": \"ar\",\n\"language_name\": \"Arabic\",\n\"native_language_name\": \"\u0627\u0644\u0639\u0631\u0628\u064a\u0629\",\n\"country_code\": \"AR\",\n\"words_separated\": true,\n\"direction\": \"right_to_left\",\n\"supported_as_source\": true,\n\"supported_as_target\": true,\n\"identifiable\": true\n},\n. . .\n]\nShow more\n\nThe list of support languages is long, reporting more than 75 languages.\n\n\n\n\n\n List of supported languages \n\nThe following table list the translatable languages. The service can translate from the following languages to any other language in the list (with the exception of Basque and Catalan). The service correctly translates from and to bidirectional languages that are written left-to-right and right-to-left (for example, Arabic, Hebrew, and Urdu).\n\nThe service use ISO two-character codes for most languages. It uses an ISO three-character code (cnr) for Montenegrin. In some cases, it uses a two-character language code and a two-character country code separated by a hyphen, such as fr-CA for French Canadian, pa-PK for Punjabi spoken in Pakistan, and zh-TW for traditional (Mandarin) Chinese spoken in Taiwan.\n\nNot all language combinations that are supported for translation are also customizable. Usually, only the combinations with English as source or target language are customizable. Click the name of a language to see the customizable translation models for that language.\n\n\n\nTable 1. Translatable languages\n\n Language Language code Language Language code \n\n [Arabic](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-modelsarabic) ar [Latvian](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-modelslatvian) lv","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-models"},{"document_id":"ibmcld_09218-1677-3252","score":20.9962744421,"text":"\n* The source and target languages must be among the [List of supported languages](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-modelslist-languages-supported).\n* The service correctly translates from and to bidirectional languages that are written left-to-right and right-to-left (for example, Arabic, Hebrew, and Urdu).\n\n\n\nThis tutorial walks you through translating documents from the command line with curl. You can also use the Watson SDKs to translate documents with a number of programming languages. For more information, see the methods in the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/language-translator).\n\n\n\n\n\n Step 1: Submit a document to translate \n\nThe following example request submits the file curriculum.html to the service and translates it from English to French. Replace {apikey} and {url} with your service credentials, and replace curriculum.html with a relative path to your file. The source and target parameters specify the languages for the translation.\n\ncurl -X POST --user \"apikey:{apikey}\" --form \"file=@curriculum.html\" --form \"source=en\" --form \"target=fr\" \"{url}\/v3\/documents?version=2018-05-01\"\n\nTo translate a document with a [custom model](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-customizing), use the model_id parameter. The following request translates the document with the custom model identified by the model ID 96221b69-8e46-42e4-a3c1-808e17c787ca. The custom model is defined for en-fr translation, so the source and target parameters are not needed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-document-translator-tutorial"},{"document_id":"ibmcld_09229-16048-18016","score":20.2656858626,"text":"\nen-th English (en) Thai (th) general \n en-tr English (en) Turkish (tr) general \n en-uk English (en) Ukrainian (uk) general \n en-ur English (en) Urdu (ur) general \n en-vi English (en) Vietnamese (vi) general \n en-zh English (en) Simplified Chinese (zh) general \n en-zh-TW English (en) Traditional Chinese (zh-TW) general \n\n\n\n\n\n\n\n Estonian \n\nThe following Estonian translation model can be customized.\n\n\n\nTable 15. Estonian translation model\n\n Model ID Source Target Domain \n\n et-en Estonian (et) English (en) general \n\n\n\n\n\n\n\n Finnish \n\nThe following Finnish translation model can be customized.\n\n\n\nTable 16. Finnish translation model\n\n Model ID Source Target Domain \n\n fi-en Finnish (fi) English (en) general \n\n\n\n\n\n\n\n French \n\nThe following French translation model can be customized.\n\n\n\nTable 17. French translation model\n\n Model ID Source Target Domain \n\n fr-en French (fr) English (en) general \n\n\n\n\n\n\n\n French (Canadian) \n\nThe following French (Canadian) translation model can be customized.\n\n\n\nTable 18. Canadian French translation model\n\n Model ID Source Target Domain \n\n fr-CA-en Canadian French (fr-CA) English (en) general \n\n\n\n\n\n\n\n German \n\nThe following German translation models can be customized.\n\n\n\nTable 19. German translation models\n\n Model ID Source Target Domain \n\n de-en German (de) English (en) general \n de-fr German (de) French (fr) general \n de-it German (de) Italian (it) general \n\n\n\n\n\n\n\n Greek \n\nThe following Greek translation model can be customized.\n\n\n\nTable 20. Greek translation model\n\n Model ID Source Target Domain \n\n el-en Greek (el) English (en) general \n\n\n\n\n\n\n\n Gujarati \n\nThe following Gujarati translation model can be customized.\n\n\n\nTable 21. Gujarati translation model\n\n Model ID Source Target Domain \n\n gu-en Gujarati (gu) English (en) general \n\n\n\n\n\n\n\n Hebrew \n\nThe following Hebrew translation model can be customized.\n\n\n\nTable 22. Hebrew translation model\n\n Model ID Source Target Domain \n\n he-en Hebrew (he) English (en) general","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-models"},{"document_id":"ibmcld_09919-4253-6578","score":20.1781964904,"text":"\nBy using the more generic v2 Entities type system together with other features, such as Concepts and Categories, you can achieve similar outcomes with more flexibility. For more information about v2 entity types, see [Entity types (Version 2)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-types-version-2).\n\n\n\n\n\n 9 June 2023 \n\nRetired Custom Sentiment Feature\n: The Custom Sentiment feature is retired. Custom sentiment models can no longer be created nor can they be used with Analyze API calls. To ensure we continue providing our clients with robust and powerful text classification capabilities, IBM recently announced the general availability of a new [single-label text classification capability](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-classifications). This new feature includes extended language support and training data customizations suited for building a custom sentiment classifier.\n\n\n\n\n\n 16 February 2023 \n\nUpdated training process for Custom Classifications\n: Updates were made to the Custom Classifications training process including improvements in the preprocessing stage, updating underlying libraries, and fixing minor bugs.\n\n\n\n\n\n 2 February 2023 \n\nSentiment support for additional languages\n: Support for sentiment is now available, for all public service instances, for the following languages: Czech, Danish, Finnish, Hebrew, Hindi, Norwegian Bokm\u00e5l, Norwegian Nynorsk, Polish, Romanian, Slovak, Swedish, Turkish. For details, see [Language support](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support).\n\n\n\n\n\n 11 January 2023 \n\nImproved English and Korean Entities Model\n: Fixed a bug for English and Korean models using Version 2 Entity type system where not all entities are returned properly.\n\n\n\n\n\n 3 November 2022 \n\nImproved Error Handling and Validation for Sentiment and Custom Sentiment\n: If a request contains both an error in the sentiment feature and a valid feature request for another feature, the response returns a 200 with a warning for the sentiment feature.\n\nRequests for Custom Sentiment that include at least one target found in the document will now return a 200 with sentiment analysis for the found targets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.2,"recall_10":0.2,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1460683498,"ndcg_cut_10":0.1460683498}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00644-14024-16089","score":19.6175066736,"text":"\nWhile IBM Cloudant strives to keep indexes updated in the background, no guarantee exists about how out-of-date the view is when queried with update=false or update=lazy.\n\nThe stable option indicates whether you would prefer to get results from a single, consistent set of shards. The false value means that all available shard replicas are queried and IBM Cloudant uses the fastest response. By contrast, setting stable=true forces the database to use just one replica of the index.\n\nUsing stable=true can cause high latency as it consults only one of the copies of the index, even if the other copies would respond faster.\n\n\n\n\n\n Combining parameters \n\nIf you specify stable=false and update=false, you see greater inconsistency between results, even for the same query and without making database changes. We recommend against this combination unless you are sure that your system can tolerate this behavior.\n\n\n\n\n\n\n\n Sorting returned rows \n\nThe data that is returned by a view query is in the form of an array. Each element within the array is sorted by using standard [UTF-8](https:\/\/en.wikipedia.org\/wiki\/UTF-8) sorting. The sort is applied to the key defined in the view function.\n\nThe basic order of the output is shown in the following table:\n\n\n\nTable 2. Order of returned rows\n\n Value Order \n\n null First \n false \n true \n Numbers \n Text (lowercase) \n Text (uppercase) \n Arrays (according to the values of each element, by using the order given in this table) \n Objects (according to the values of keys, in key order by using the order given in this table) Last \n\n\n\nYou can reverse the order of the returned view information by setting the descending query value true.\n\nWhen you issue a view request that specifies the keys parameter, the results are returned in the same order as the supplied keys array.\n\nSee the example of using HTTP to request the records in reversed sort order:\n\nGET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME?descending=true HTTP\/1.1\nAccept: application\/json\n\nSee the example of requesting the records in reverse sort order.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_00644-20617-22169","score":17.1244299356,"text":"\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration) for examples.\n\nFor example, if you have a database that returns one result when you use a start_key of alpha and an end_key of beta, you would get a 400 (Bad request) error with a reversed order. The reason is that the entries in the view are reversed before the key filter is applied.\n\nSee the example that uses HTTP to illustrate why reversing the order of start_key and end_key might return a query parse error:\n\nGET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME?descending=true&start_key=\"alpha\"&end_key=\"beta\" HTTP\/1.1\n\nSee the example illustrating why reversing the order of start_key and end_key might cause a 400 error.\n\nClient libraries use POST method instead of GET because they have the same behavior.\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X GET \"$SERVICE_URL\/users\/_design\/allusers\/_view\/getVerifiedEmails?descending=true&start_key=\"alpha\"&end_key=\"beta\"\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostViewOptions;\nimport com.ibm.cloud.cloudant.v1.model.ViewResult;\n\nCloudant service = Cloudant.newInstance();\n\nPostViewOptions viewOptions = new PostViewOptions.Builder()\n.db(\"users\")\n.ddoc(\"allusers\")\n.view(\"getVerifiedEmails\")\n.descending(true)\n.startKey(\"alpha\")\n.endKey(\"beta\")\n.build();\n\nViewResult response =\nservice.postView(viewOptions).execute()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_11295-5607-7284","score":16.2374751566,"text":"\nConnect the VPC to a [Transit Gateway](https:\/\/cloud.ibm.com\/docs\/transit-gateway?topic=transit-gateway-ordering-transit-gateway&interface=uitg-ui-creating-transit-gateway).\n4. [Create a cloud connection](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-cloud-connectionscreate-cloud-connections) to connect the non-PER Power Systems Virtual Server workspace to the same transit gateway.\n\n\n\nThe Power Systems Virtual Server would then use the VPE's IP address to connect to COS. If the VPE has multiple IP addresses, you can set up custom DNS and a custom hostname to connect to COS.\n3. Deploy a Nginx reverse proxy server in either the classic or VPC infrastructure.\n\nNginx is a mature, compact, and fast open source web server that excels at specialized tasks, including the reverse proxy server role. For information on setting up a Nginx reverse proxy server, see [Installing your Nginx reverse proxy](https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-using-ibm-cloud-direct-link-to-connect-to-ibm-cloud-object-storagedirect-link-installing-your-nginx-reverse-proxy).\n\n\n\n\n\n Cloud Object Storage on AIX \n\nIBM Power Systems that are running AIX 7.2 TL3, or later, have a script that is located in the path, \/usr\/samples\/nim\/cloud_setup. The cloud_setup command installs the command-line environment for cloud storage services.\n\ncloud_setup [-I | G | C] [-v]\n\n-I: Install the necessary RPMs for universal CLI (supports COS).\n-G: Install the necessary RPMs for gsutil CLI (Google Cloud Storage).\n-C: Install the necessary RPMs for cloud-init.\n-v: Enable debug output.\n\n\n\n1. To begin, copy the file to the system that requires AWS and give it execute permission.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-backup-strategies"},{"document_id":"ibmcld_00644-22813-24283","score":16.0238418604,"text":"\n\"allusers\",\n\"getVerifiedEmails\",\n)\n\npostViewOptions.SetDescending(true)\npostViewOptions.StartKey = \"alpha\"\npostViewOptions.EndKey = \"beta\"\n\nviewResult, response, err := service.PostView(postViewOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(viewResult, \"\", \" \")\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n)\n\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration) for examples.\n\nThe end_key of beta is seen before the start_key of alpha, resulting in a query parse error.\n\nThe solution is to reverse not just the sort order, but also the start_key and end_key parameter values.\n\nThe following example shows correct filtering and reversing the order of output, by using the descending query argument, and reversing the start_key and end_key query arguments.\n\nSee the example that uses HTTP to apply correct filtering and sorting to a global query:\n\nGET $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME?descending=true&start_key=\"beta\"&end_key=\"alpha\" HTTP\/1.1\n\nSee the example to apply correct filtering and sorting to a global query.\n\nClient libraries use POST method instead of GET because they have the same behavior.\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_04126-7-1694","score":15.7259606097,"text":"\nCompression and optimization concepts \n\nIBM Cloud\u00ae Internet Services applies gzip and brotli compression to some types of content. CIS also compresses items based on the browser's UserAgent to speed up page loading time.\n\nIf you're already using gzip, CIS honors your gzip settings as long as you're passing the details in a header from your web server for the files.\n\nCIS only supports the content type gzip towards your origin server and can also only deliver content either gzip-compressed, brotli-compressed, or not compressed.\n\nCIS's reverse proxy is also able to convert between compressed formats and uncompressed formats, meaning that it can pull content from a customer's origin server through gzip and serve it to clients uncompressed (or reversed). This is done independently of caching.\n\nThe Accept-Encoding header is not respected and is removed.\n\n\n\n What gets compressed \n\nIn addition to CIS's serving stale content and minification of CSS, JS, and HTML to speed up your site, CIS also provides gzip and brotli compression to help site owners.\n\nCIS returns gzip or brotli encoded responses to compatible clients and browsers for the following content-types:\n\ntext\/html\ntext\/richtext\ntext\/plain\ntext\/css\ntext\/x-script\ntext\/x-component\ntext\/x-java-source\ntext\/x-markdown\napplication\/javascript\napplication\/x-javascript\ntext\/javascript\ntext\/js\nimage\/x-icon\nimage\/vnd.microsoft.icon\napplication\/x-perl\napplication\/x-httpd-cgi\ntext\/xml\napplication\/xml\napplication\/xml+rss\napplication\/vnd.api+json\napplication\/x-protobuf\napplication\/json\nmultipart\/bag\nmultipart\/mixed\napplication\/xhtml+xml\nfont\/ttf\nfont\/otf\nfont\/x-woff\nimage\/svg+xml\napplication\/vnd.ms-fontobject\napplication\/ttf","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compression-concepts"},{"document_id":"ibmcld_00539-2548-4016","score":15.5995171496,"text":"\n\"type\": \"json\"\n}\n\n\n\n\n\n Can I sort in reverse order? \n\nYes! IBM Cloudant Query supports sorting the result set in ascending or descending order, but not a combination of the two. For example, a query that sorts some fields in ascending order, and a query where descending is not allowed.\n\nThis query returns documents that match firstname and surname and sorts by surname\/firstname\/date descending:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\n{ \"firstname\": \"desc\" },\n{ \"surname\": \"desc\" },\n{ \"date\": \"desc\" }\n],\n\"limit\": 10\n}\n\nA suitable index must be present that contains the selector fields and the sort fields. Otherwise, IBM Cloudant refuses to execute the query. A suitable index definition for the previous query is shown next:\n\n{\n\"index\": {\n\"fields\": [\n\"firstname\",\n\"surname\",\n\"date\"\n]\n},\n\"ddoc\": \"jsonindexes\",\n\"name\": \"byNameAndDate\",\n\"type\": \"json\"\n}\n\nThe previous index is suitable for both ascending and descending sort order.\n\n\n\n\n\n How can I tell if an index is backing a query? \n\nThe [POST \/{db}\/_explain](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=javapostexplain) API endpoint when passed a JSON object that is usually sent to the [POST \/{db}\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) endpoint, explains how such a query is handled and which indexes, if any, might be used.\n\nIf the index object in the response indicates that \"all_docs\" is being used, a full database scan is required to service the query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"},{"document_id":"ibmcld_06932-3767-5600","score":15.4600558596,"text":"\nBasic premise: Remote clients pass requests, including secure credentials, through a private server to COS.\n\nZoom\n\n![reverse=proxy](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d7287ec7418d843dbd7caf286d842c439df6979e\/direct-link\/images\/reverse-proxy.png)\n\nFigure 1. Reverse proxy\n\nHTTPS (secure HTTP) COS requests are initiated from a client at a remote site. They're transmitted securely through IBM Cloud Direct Link, targeting one of a cluster of reverse proxy servers deployed in a customer\u2019s IBM Cloud account. From there, requests are passed to a COS private endpoint, processed, and then the results returned to the remote calling client.\n\nAny sample client code that works with COS should also work through a reverse proxy server. The only change that is required is that, instead of targeting a COS private endpoint URL published by IBM, the client targets the IP address or URL of the reverse proxy server.\n\n\n\n Installing your Nginx reverse proxy \n\nNginX is a mature, compact, and fast open source web server that excels at specialized tasks, including the reverse proxy server role.\n\nThe instructions and configuration information that follows (for setting up an NginX reverse proxy server) can work after you adapt it to your environment. If you get stuck or need additional information, see the reverse proxy portion of the [Nginx documentation](https:\/\/docs.nginx.com\/nginx\/admin-guide\/web-server\/reverse-proxy\/) or search [stackoverflow](https:\/\/stackoverflow.com) for examples.\n\n\n\n1. Provision your VSI or bare metal servers with minimal RHEL or CentOS Linux build (recommended).\n2. For each VSI, enable the following security group rules on the public interface: allow_http, allow_https, allow_outbound, allow_ssh\n3. For each VSI, enable allow_all and allow_outbound rules on the private interface; select Save.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/direct-link?topic=direct-link-using-ibm-cloud-direct-link-to-connect-to-ibm-cloud-object-storage"},{"document_id":"ibmcld_08775-3653-3948","score":15.4340512092,"text":"\n\"id\": \"02fd6835-6001-4482-a892-13bd2085f75d\",\n\"creationDate\": \"2020-03-05T16:39:25Z\"\n},\n{\n\"id\": \"12e8c9c2-a162-472d-b7d6-8b9a86b815a6\",\n\"creationDate\": \"2020-03-02T16:28:38Z\"\n}\n]\n}\n\nThe resources object lists each key version, along with the ID and creation date, in reverse chronological order.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-versions"},{"document_id":"ibmcld_02114-4183-5917","score":15.2868223697,"text":"\nibmcloud catalog search <QUERY> [--catalog CATALOG] [--type TYPE] [-r, --region REGION] [-k, --kind KIND] [--fields FIELDS] [-p, --price PRICE] [-t, --tag TAG] [--sort-by PROPERTY] [--col COLUMNS] [--reverse] [--output TYPE] [--global]\n\n\n\n Command options \n\n--type TYPE (optional)\n: Optional. Default is services. Valid options are services and software.\n\n--catalog CATALOG (optional)\n: Search for the software published by your account. Specify the catalog name or ID to search by.\n\n--output FORMAT (optional)\n: Specifies output format. Default is terminal compatible and the only alternative options are json and csv.\n\n--kind KIND (optional)\n: Flag is only valid for services search. Provide a comma-separated list of types of products.\n\n--region REGION (optional)\n: Flag is only valid for services search. Provide a comma-separated list of regions. Run ibmcloud cs regions to return a valid list.\n\n--price PRICE (optional)\n: Flag is only valid for services search. Provide a comma-separated list of pricing types.\n\n--tag TAG (optional)\n: Flag is only valid for services search. Provide a comma-separated list of tags.\n\n--global (optional)\n: Flag is only valid for services search. Use it to operate in global scope.\n\n--sort-by TYPE (optional)\n: Flag is only valid for services search and used to order the search result. Available options are name, displayname, kind, provider, created, and updated.\n\n--reverse (optional)\n: Flag is only valid for services search. Use it to reverse the sorting order.\n\n--fields FIELDS (optional)\n: Flag is only valid for services search. Customize the table, for example, --fields name,kind,metadata.service.iam_compatible.\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nName ID Category","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-plugin"},{"document_id":"ibmcld_04491-4183-5917","score":15.2868223697,"text":"\nibmcloud catalog search <QUERY> [--catalog CATALOG] [--type TYPE] [-r, --region REGION] [-k, --kind KIND] [--fields FIELDS] [-p, --price PRICE] [-t, --tag TAG] [--sort-by PROPERTY] [--col COLUMNS] [--reverse] [--output TYPE] [--global]\n\n\n\n Command options \n\n--type TYPE (optional)\n: Optional. Default is services. Valid options are services and software.\n\n--catalog CATALOG (optional)\n: Search for the software published by your account. Specify the catalog name or ID to search by.\n\n--output FORMAT (optional)\n: Specifies output format. Default is terminal compatible and the only alternative options are json and csv.\n\n--kind KIND (optional)\n: Flag is only valid for services search. Provide a comma-separated list of types of products.\n\n--region REGION (optional)\n: Flag is only valid for services search. Provide a comma-separated list of regions. Run ibmcloud cs regions to return a valid list.\n\n--price PRICE (optional)\n: Flag is only valid for services search. Provide a comma-separated list of pricing types.\n\n--tag TAG (optional)\n: Flag is only valid for services search. Provide a comma-separated list of tags.\n\n--global (optional)\n: Flag is only valid for services search. Use it to operate in global scope.\n\n--sort-by TYPE (optional)\n: Flag is only valid for services search and used to order the search result. Available options are name, displayname, kind, provider, created, and updated.\n\n--reverse (optional)\n: Flag is only valid for services search. Use it to reverse the sorting order.\n\n--fields FIELDS (optional)\n: Flag is only valid for services search. Customize the table, for example, --fields name,kind,metadata.service.iam_compatible.\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nName ID Category","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-plugin"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03935-8186-10253","score":9.8123038891,"text":"\nIf an ordering service organization was added as an administrator of the system channel after this application channel was created, it must be added to the channel before any nodes belonging to it can be added as application channel consenters. Note: if your console is at a build before 2.1.3-104, you will not see this option. To see the version of your build, click on the support icon in the upper right corner (it resembles a question mark). The version will be listed below IBM Blockchain Platform version on the upper left.\n* Ordering cluster without a system channel - Ordering organizations that are administrators were added to the application channel at channel creation. If an ordering service organization was created and intended to be an administrator after the application channel was created, it must be added to the channel before any nodes belonging to it can be added as application channel consenters.\n\n\n\n* Consenter set. The ordering service nodes on a particular channel are known in a Raft consensus mechanism as a \"consenter set\". For this reason, the ordering nodes in a consenter set are sometimes referred to as \"consenters\". The orderer's system channel (when applicable) will always contain all of the possible consenters available in a network (its consenter set is \"all consenters\"), while application channels might have all consenters or some subset of consenters. It is possible to add or remove particular nodes from this consenter set during both the creation of an application channel and through a channel update. For example to add newly created orderers, if a system channel is being used they are first added to the system channel, then to the consenter set of an application channel. To add a node to the consenter set, first ensure that the organization that owns the consenter is an admin of the ordering service of the application channel through the Ordering service administrator panel. You can then add the consenter through this Consenter set panel by opening the drop-down list, clicking on a node, and clicking Add.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-govern"},{"document_id":"ibmcld_07214-65893-68177","score":8.3408092853,"text":"\n: The new version string enables enrichments in German (de) or Spanish (es) if the language of a collection is set to one of those languages. Previously, all enrichments were performed in English regardless of a collection's language setting. : If you do not use enrichments in non-English languages, you can continue to use the 2016-12-01 version string. However, to avoid potential future conflicts, it is recommended that you update the version string as soon as possible.\n\nNew anomaly detection availability : Anomaly detection is now available as part of timeslice aggregations as a GA capability.\n\nNew beta improvement to relevancy tooling : Added the beta ability to improve the relevancy of query results using the Discovery tooling (relevancy tooling). See [Improving the relevance of your query results with the Discovery tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n 19 June 2017 \n\nNew select language of documents : Added option to specify the language of the documents in a new collection as English, Spanish, or German. To use it, choose Select the language of your documents on the Name your new collection dialog.\n\nAdded a Summary tab to the Build queries screen : The Summary tab displays an overview of the full query results provided in the existing JSON tab. The Summary display varies, based on your query and enrichments. Information that might be displayed includes: document name or ID, aggregation statistics, document passages in order of relevance, and results by enrichment.\n\nAdded a Natural Language Query option to the Build queries screen : To use it, click Ask a question in plain language in the Search for documents section, and a field displays where you can enter your question. You can now access the original query field, formerly titled Enter a query or keyword, by clicking the Use the Discovery Query Language button.\n\nThe Build queries screen was redesigned, but all fields and options remain. : Following are the old and new names for the fields.\n\n Old field name New field or section name \n\n Write and run a query Search for documents \n Narrow your query results (Filter) Limit which documents you query \n Group query results (Aggregation) Include analysis of your results","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_01499-0-939","score":8.1994482374,"text":"\n\n\n\n\n\n\n  Why can't I pull the newest image by using the latest tag? \n\nYou're unable to pull the most recent image by using the latest\n\ntagin IBM Cloud\u00ae Container Registry.\n\n  What\u2019s happening \n\nYou're trying to run the command docker pull, but it returned a version of your image that isn't the most recent version built.\n\n  Why it\u2019s happening \n\nThe latest tag is applied by default to reference an image when you run Docker commands without specifying the tag value. The latest tag is applied to the most recent docker build or docker tag command that was run without a tag value explicitly set. Therefore, it's possible to run docker commands out of order or to explicitly set tags on some images. Both scenarios cause the latest tag to refer to a build that isn't the most recent.\n\n  How to fix it \n\nIt is generally better to explicitly define a different sequential tag for your images every time, and not rely on the latest tag.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-docker-latest"},{"document_id":"ibmcld_07214-64178-66368","score":8.1715680075,"text":"\n: If you integrate with Watson Knowledge Studio, you must still use the AlchemyLanguage enrichment configuration. For details, see [Integrating with IBM Watson\u2122 Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-integrating-with-wks).\n\nUpdate to version string : The version string for all API calls changed to 2017-07-19 from 2017-06-25. This version enables an NLU default config on collection creation. You should still be able to enrich with AlchemyLanguage in previous versions. : The default configuration is updated to use Natural Language Understanding. To avoid conflicts and possible errors, it is recommended that you update the version string as soon as possible.\n\nKnown issue for Insight Cards : The Insight Cards for collections with AlchemyLanguage enrichments do not update automatically any longer. You must migrate your collection to Natural Language Understanding Enrichments for the insight cards to update. : If you created a collection prior to 18 July, 2017 and applied the Default Configuration, that collection was enriched with the AlchemyLanguage enrichments. If you apply the Default Configuration to a collection after this date, the Natural Language Understanding enrichments are used. The configuration name switches to Default Configuration with NLU in the tooling. Because AlchemyLanguage enrichments are being deprecated, it is recommended that they not be used with new collections.\n\n\n\n\n\n 30 June 2017 \n\nUpdate to entity normalization : The entity normalization capability introduced as a beta feature on 5 May 2017 moved to GA status.\n\n\n\n\n\n 23 June 2017 \n\nUpdate to version string : The version string for all API calls changed to 2017-06-25 from 2016-12-01. : The new version string enables enrichments in German (de) or Spanish (es) if the language of a collection is set to one of those languages. Previously, all enrichments were performed in English regardless of a collection's language setting. : If you do not use enrichments in non-English languages, you can continue to use the 2016-12-01 version string. However, to avoid potential future conflicts, it is recommended that you update the version string as soon as possible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_16359-5458-7439","score":8.1638146564,"text":"\n[Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/download-icon.png).\n\nYour example phrases are downloaded to a CSV file.\n\n\n\n\n\n\n\n\n\n Asking clarifying questions \n\nWhen your assistant finds that more than one action might fulfill a customer's request, it can automatically ask for clarification. Instead of guessing which action to take, your assistant shows a list of the possible actions to the customer, and asks the customer to pick the right one.\n\nZoom\n\n![Shows a sample conversation between a user and the assistant, where the assistant asks for clarification from the user.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/disambig-demo.png)\n\nSample conversation\n\nAny Created by you action that might match the customer's input can be included in the choices that are listed by a clarifying question. The Set by assistant actions are never included.\n\nIn the assistant output, the possible actions are listed by name. The default name for an action is the text of the first example message that you add to it (such as I want to open an account), but you can change this name to something more descriptive.\n\nThe order in which the actions are listed might change. In fact, the actions themselves that are included in the list might change. This behavior is intended. As part of development that is in progress to help the assistant learn automatically from user choices, the actions that are included and their order in the list is randomized on purpose. Randomizing the order helps to prevent bias that can be introduced by a percentage of people who always pick the first option without carefully reviewing all of their choices beforehand.\n\n\n\n Customizing clarifying questions \n\nTo customize clarification, you can:\n\n\n\n* Change settings like the wording your assistant uses to introduce the clarification list or when no action matches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questions"},{"document_id":"ibmcld_03891-21933-24093","score":7.9298656681,"text":"\nTo see the version of your build, click on the support icon in the upper right hand corner (it resembles a question mark). The version will be listed below IBM Blockchain Platform version on the upper left.\n\nAfter the organization has been added, we can add the consenter.\n\nIt is possible to add a node to the consenter and add the MSP of the organization that owns the node as part of the same channel configuration update.\n\n\n\n\n\n Add the node to the application channel \n\nAfter adding the organization, click on the Consenter set tab, select the Ordering Service_2 node from the drop down list, and click Add. Note that you will only be able to add one node to a channel at a time.\n\nAfter the Ordering Service MSP has signed the channel configuration update, the organization that initiated the channel update will get a notification that it must sign and submit the channel configuration update. This notification, like all notifications, will be located in the upper right of the screen behind the Notifications icon, which resembles a bell. For more information about how signature collections work, see [Signature collection flow](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-governibp-console-govern-update-channel-signature-collection).\n\nIt will take a few minutes for the new node to sync with the consenter set of the application channel. The time involved depends on a number of factors, including the number of blocks in a channel. During this time, the ordering service may be down. After the node has been successfully added to the application channel, you will see it in the Ordering nodes tab.\n\n\n\n\n\n Join the node to the application channel \n\nClusters that do not use a system channel can join and unjoin ordering nodes to an application channel. You can verify if a cluster does or does not use a system channel by clicking the cluster's tile and looking near the Orderer Type text.\n\nJoining an orderer to an application channel will make it either a follower or a consenter. It will be a consenter if the node is found in the the channel's config block in the consenters section. Otherwise the orderer will be a follower.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-add-remove-orderer"},{"document_id":"ibmcld_03935-33555-35918","score":7.8131094769,"text":"\nBecause the peers will be unable to progress beyond this configuration block, it will not be possible to reverse this configuration block and submit another one to \"fix\" the problem. A channel in this state is unrepairable.\n\n\n\n\n\n\n\n\n\n Tuning your ordering service \n\nPerformance of a blockchain platform can be affected by many variables such as transaction size, block size, network size, as well as limits of the hardware. The orderer node includes a set of tuning parameters that together can be used to control orderer throughput and performance. You can use these parameters to customize how your orderer processes transactions depending on whether you have many small frequent transactions, or fewer but large transactions that arrive less frequently. Essentially, you have the control to decide when the blocks are cut based on your transaction size, quantity, and arrival rate.\n\nThe following parameters are available in the console by clicking the orderer node in the Nodes tab and then clicking its Settings icon. Click the Advanced button to open the Advanced channel configuration for the orderer.\n\n\n\n Block cutting parameters \n\nThe following three parameters work together to control when a block is cut, based on a combination of setting the maximum number of transactions in a block as well as the block size itself.\n\n\n\n* Absolute max bytes Set this value to the largest block size in bytes that can be cut by the orderer. No transaction may be larger than the value of Absolute max bytes. Usually, this setting can safely be two to ten times larger than your Preferred max bytes. Note: The maximum size permitted is 99MB.\n* Max message count Set this value to the maximum number of transactions that can be included in a single block.\n* Preferred max bytes Set this value to the ideal block size in bytes, but it must be less than Absolute max bytes. A minimum transaction size, one that contains no endorsements, is around 1KB. If you add 1KB per required endorsement, a typical transaction size is approximately 3-4KB. Therefore, it is recommended to set the value of Preferred max bytes to be around Max message count * expected averaged tx size. At run time, whenever possible, blocks will not exceed this size. If a transaction arrives that causes the block to exceed this size, the block is cut and a new block is created for that transaction.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-govern"},{"document_id":"ibmcld_07103-9826-12106","score":7.7876197983,"text":"\nThe problems were related to a new version of the optical character recognition (OCR v2) feature that was enabled automatically for English, German, French, Spanish, Dutch, Brazilian Portuguese, and Hebrew collections during that timeframe. The new version changes sentence boundaries in ways that can negatively impact other functions, including element identification in contracts and the document labeling view in the entity extractor tool.\n\nIf you experience any of these issues with documents that were added or processed during this period, revert the version of OCR that is applied to the documents. Starting on 12 November 2022, OCR v1 is applied to all collections where OCR is enabled. To go back to using OCR v1, make a change that will reprocess the affected documents. For example, you can re-add documents that were added during the timeframe to reprocess them. Or you can reprocess an entire collection.\n\nTo reprocess a collection, from the Manage collections page, open the collection, and then go to the Processing settings tab. Expand the More processing settings section, set the OCR switch to Off, and then set it back to On. Click Apply changes and reprocess to reprocess your collection.\n\n\n\n\n\n 2 November 2022 \n\nA new and improved optical character recognition technology is available\n: A new version of optical character recognition technology is now available. This latest version (OCR v2) is used automatically when you enable OCR for English, German, French, Spanish, Dutch, Brazilian Portuguese, and Hebrew collections in all IBM Cloud service plans. The new optical character recognition model was developed by IBM Research to be better at extracting text from scanned documents and other images that have the following limitations:\n\n\n\n* Low quality images due to incorrect scanner settings, insufficient resolution, bad lighting (such as with mobile capture), loss of focus, unaligned pages, and badly printed documents\n* Documents with irregular fonts or a variety of colors, font sizes, and backgrounds\n\n\n\n\n\n\n\n 1 November 2022 \n\nEntity extractor loads the first 40,000 characters from training data documents\n: Even extra long documents from the collection that you use to define custom entity examples are loaded into the document view of the tool.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_03114-8624-9860","score":7.7451380534,"text":"\nFor an example of implementing option responses in a simple client application, see [Example: Implementing option responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-responsesapi-dialog-option-example).\n\n\n\n\n\n Suggestion \n\nThis feature is available only to users with a paid plan.\n\nThe suggestion response type is used by the disambiguation feature to suggest possible matches when it isn't clear what the user wants to do. A suggestion response includes an array of suggestions, each one corresponding to a possible matching dialog node:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"suggestion\",\n\"title\": \"Did you mean:\",\n\"suggestions\":\n{\n\"label\": \"I'd like to order a drink.\",\n\"value\": {\n\"intents\":\n{\n\"intent\": \"order_drink\",\n\"confidence\": 0.7330395221710206\n}\n],\n\"entities\": ],\n\"input\": {\n\"suggestion_id\": \"576aba3c-85b9-411a-8032-28af2ba95b13\",\n\"text\": \"I want to place an order\"\n}\n},\n\"output\": {\n\"text\":\n\"I'll get you a drink.\"\n],\n\"generic\":\n{\n\"response_type\": \"text\",\n\"text\": \"I'll get you a drink.\"\n}\n],\n\"nodes_visited_details\":\n{\n\"dialog_node\": \"node_1_1547675028546\",\n\"title\": \"order drink\",\n\"user_label\": \"I'd like to order a drink.\",\n\"conditions\": \"order_drink\"\n}\n]\n},\n\"source_dialog_node\": \"root\"\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-responses"},{"document_id":"ibmcld_02900-9312-11284","score":7.7450559004,"text":"\n3. Click Apply.\n4. Use the Try it out pane to test the digression behavior.\n\nAgain, you cannot define the start and end of a digression. The user controls where and when digressions happen. You can only apply settings that determine how a single node participates in one. Because digressions are so unpredictable, it is hard to know how your configuration decisions will impact the overall conversation. To truly see the impact of the choices you made, you must test the dialog.\n\n\n\nThe #reservation and #cuisine nodes represent two dialog branches that can participate in a single user-directed digression. The digression settings that are configured for each individual node are what make this type of digression possible at run time.\n\n![Shows two dialogs, one that sets the digressions away from the reservation slots node and one that sets the digression into the cuisine node.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/digression-settings.png)\n\n\n\n\n\n Digression usage tips \n\nThis section describes solutions to situations that you might encounter when using digressions.\n\n\n\n* Custom return message: For any nodes where you enable returns from digressions away, consider adding wording that lets users know they are returning to where they were in a previous dialog flow. In your text response, use a special syntax that lets you add two versions of the response.\n\nIf you do not take action, the same text response is displayed a second time to let users know they have returned to the node they digressed away from. You can make it clearer to users that they have returned to the original conversation thread by specifying a unique message to be displayed when they return.\n\nFor example, if the original text response for the node is, What's the order number?, then you might want to display a message like, Now let's get back to where we were. What is the order number? when users return to the node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16034-8170-9974","score":11.2201045333,"text":"\n* Updated security-group-target, security-group-target-add and security-group-target-remove commands to support a VPN server target.\n* Updated vpn-server-create, and vpn-server-update commands to support the secrets manager.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* Removed VPC route commands vpc-routes,vpc-route, vpc-route-create, vpc-route-update and vpc-route-delete.\n\n\n\n\n\n\n\n Note \n\n\n\n* VPN server commands are available.\n\n\n\n\n\n\n\n\n\n v4.2.0 \n\nVersion 4.2.0 was released on 2022-06-17.\n\n\n\n New commands \n\n\n\n* Added backup-policies, backup-policy-create, backup-policy, backup-policy-update, backup-policy-delete, backup-policy-plan, backup-policy-plans, backup-policy-plan-create, backup-policy-plan-update, backup-policy-plan-delete, backup-policy-jobs and backup-policy-job commands to support Backup As a Service.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated volume-create, volume-update, snapshot-create and snapshot-update commands to support user tags.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Added plugin support for Linux and Mac ARM64 architecture.\n\n\n\n\n\n\n\n\n\n v4.1.0 \n\nVersion 4.1.0 was released on 2022-05-27.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated load-balancer-listener-create and load-balancer-listener-update commands to support secrets manager.\n* Updated security-group-rule-update command to support ICMP type and ICMP code reset options.\n* Updated instance-update command to support placement target patch.\n* Updated vpn-server-update command to support client DNS reset option.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v4.0.3 \n\nVersion 4.0.3 was released on 2022-04-25.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated instance-create command to support more data volumes in interactive mode.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16197-3137-5275","score":11.2103820959,"text":"\nMembers 50 per pool \n Policies N\/A \n Rules N\/A \n Security Groups N\/A \n Subnets 1 per load balancer \n\n\n\n\n\n\n\n Routing tables and routes \n\n\n\nTable 9. Quotas for routing tables and routes\n\n Resource Quota \n\n Routing tables per VPC 50 \n Routes per routing table 200 \n\n\n\nEach route has a destination property, which includes a prefix length (\/24 in 10.2.0.0\/24). The number of unique prefix lengths that are supported per custom routing table is 14. Multiple routes with the same prefix count as only one unique prefix.\n\n\n\n\n\n Reserved IP addresses \n\n\n\nTable 10. Quotas for reserved IP addresses\n\n Resource Quota \n\n Reserved IP addresses 20,000 per region \n\n\n\n\n\n\n\n Block storage volumes and snapshots \n\n\n\nTable 11. Quotas for block storage volumes and snapshots\n\n Resource Quota \n\n Boot and secondary volumes 300 total VPC volumes per account in a region \n Snapshots and backup snapshots Up to 750 per volume in a region \n\n\n\n\n\n\n\n File shares \n\n\n\nTable 12. Quotas for file shares\n\n Resource Quota \n\n File shares 300 total file shares per account in a region \n\n\n\n\n\n\n\n Placement groups \n\n\n\nTable 13. Quotas for placement groups\n\n Resource Quota \n\n Placement groups 100 placement groups per account in a region \n Instances 12 instances per placement group per region with host_spread placement group strategy. \n Instances 4 instances per placement group per region with power_spread placement group strategy. \n\n\n\nThe quotas for placement groups are set and can't be adjusted.\n\n\n\n\n\n\n\n Service limits \n\nThe following table displays current VPC service limits. Unlike quotas, these limits can't be adjusted.\n\n\n\nTable 14. Limits for VPC resources\n\n Resource Limit \n\n VPCs with classic access 1 per region \n Network interfaces 5 per instance \n PCI network interfaces for bare metal servers 8 per bare metal server \n Public Gateways 1 per zone per VPC \n Security groups 5 per network interface (NIC) on a virtual server instance \n Remote rules for security groups 5 per security group \n Secondary volumes per instance Up to 12 secondary volumes \n Instance groups for auto scale and more 200 per account \n Instance group memberships 1000 per instance group","title":"","source":"https:\/\/cloud.ibm.com\/docs\/wanclouds-vpc-plus?topic=vpc-quotas"},{"document_id":"ibmcld_15926-2839-5137","score":11.0811280169,"text":"\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore"},{"document_id":"ibmcld_15934-2839-5137","score":11.0811280169,"text":"\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=api"},{"document_id":"ibmcld_15937-2839-5137","score":11.0811280169,"text":"\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=cli"},{"document_id":"ibmcld_15938-2839-5137","score":11.0811280169,"text":"\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=terraform"},{"document_id":"ibmcld_15939-2839-5137","score":11.0811280169,"text":"\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=ui"},{"document_id":"ibmcld_15926-22629-23750","score":10.6511093364,"text":"\n\"name\": \"my-server-name\",\n\"zone\": {\n\"name\": \"us-south-1\"\n},\n\"vpc\": {\n\"id\": \"4d27c489-8ad7-3c18-cbf4-2103d9f8da93\"\n},\n\"profile\": {\n\"name\": \"cx2-2x4\"\n},\n\"primary_network_interface\": {\n\"name\": \"region1example-net1\",\n\"subnet\": {\n\"id\": \"\"\n}\n},\n\"volume_attachments\": [\n{\n\"name\": \"restore-data-vol1\",\n\"delete_volume_on_instance_delete\": true,\n\"volume\": {\n\"profile\": {\n\"name\": \"general-purpose\"\n},\n\"source_snapshot\": {\n\"id\": \"bdcdc984-ba4e-4aef-84fb-e8448c3116b1\"\n}\n}\n}\n]\n\"resource_group\": {\n\"id\": \"2fab2c7f-c09d-4c64-baf7-1453b7461493\"\n}\n}'\n\n\n\n\n\n Creating a stand-alone data volume from a snapshot with the API \n\nYou can use the API to create a stand-alone volume from a snapshot. Use this option when you're not sure which virtual server instance you want to attach the volume to. Or, if you want to restore data from an unattached volume that was detached from an instance.\n\nTo restore a stand-alone data volume from a snapshot, make a POST \/volumes request and specify the ID, CRN, or URL of the snapshot in the source_snapshot property. The restored volume capacity (in GBs) must be at least the snapshot's minimum_capacity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore"},{"document_id":"ibmcld_15937-22643-23764","score":10.6511093364,"text":"\n\"name\": \"my-server-name\",\n\"zone\": {\n\"name\": \"us-south-1\"\n},\n\"vpc\": {\n\"id\": \"4d27c489-8ad7-3c18-cbf4-2103d9f8da93\"\n},\n\"profile\": {\n\"name\": \"cx2-2x4\"\n},\n\"primary_network_interface\": {\n\"name\": \"region1example-net1\",\n\"subnet\": {\n\"id\": \"\"\n}\n},\n\"volume_attachments\": [\n{\n\"name\": \"restore-data-vol1\",\n\"delete_volume_on_instance_delete\": true,\n\"volume\": {\n\"profile\": {\n\"name\": \"general-purpose\"\n},\n\"source_snapshot\": {\n\"id\": \"bdcdc984-ba4e-4aef-84fb-e8448c3116b1\"\n}\n}\n}\n]\n\"resource_group\": {\n\"id\": \"2fab2c7f-c09d-4c64-baf7-1453b7461493\"\n}\n}'\n\n\n\n\n\n Creating a stand-alone data volume from a snapshot with the API \n\nYou can use the API to create a stand-alone volume from a snapshot. Use this option when you're not sure which virtual server instance you want to attach the volume to. Or, if you want to restore data from an unattached volume that was detached from an instance.\n\nTo restore a stand-alone data volume from a snapshot, make a POST \/volumes request and specify the ID, CRN, or URL of the snapshot in the source_snapshot property. The restored volume capacity (in GBs) must be at least the snapshot's minimum_capacity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=cli"},{"document_id":"ibmcld_15938-22649-23770","score":10.6511093364,"text":"\n\"name\": \"my-server-name\",\n\"zone\": {\n\"name\": \"us-south-1\"\n},\n\"vpc\": {\n\"id\": \"4d27c489-8ad7-3c18-cbf4-2103d9f8da93\"\n},\n\"profile\": {\n\"name\": \"cx2-2x4\"\n},\n\"primary_network_interface\": {\n\"name\": \"region1example-net1\",\n\"subnet\": {\n\"id\": \"\"\n}\n},\n\"volume_attachments\": [\n{\n\"name\": \"restore-data-vol1\",\n\"delete_volume_on_instance_delete\": true,\n\"volume\": {\n\"profile\": {\n\"name\": \"general-purpose\"\n},\n\"source_snapshot\": {\n\"id\": \"bdcdc984-ba4e-4aef-84fb-e8448c3116b1\"\n}\n}\n}\n]\n\"resource_group\": {\n\"id\": \"2fab2c7f-c09d-4c64-baf7-1453b7461493\"\n}\n}'\n\n\n\n\n\n Creating a stand-alone data volume from a snapshot with the API \n\nYou can use the API to create a stand-alone volume from a snapshot. Use this option when you're not sure which virtual server instance you want to attach the volume to. Or, if you want to restore data from an unattached volume that was detached from an instance.\n\nTo restore a stand-alone data volume from a snapshot, make a POST \/volumes request and specify the ID, CRN, or URL of the snapshot in the source_snapshot property. The restored volume capacity (in GBs) must be at least the snapshot's minimum_capacity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=terraform"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11788-8466-10910","score":11.9030228284,"text":"\nFor any other connections into your location that your applications require, you can use Satellite Link to create layer 4 communications by setting up an endpoint for each destination resource in your location. All connections through your endpoints are always under your control, including completely disabling endpoints.\n\n\n\n\n\n How do I make my data secure in transit? \n\nLink endpoints between your location and IBM Cloud are secured through two levels of encryption: high-security encryption from the location\u2019s connector to IBM Cloud that is provided by IBM , and an optional additional encryption layer between the source and destination resources.\n\nAll data that is transported over Satellite Link is encrypted using TLS 1.3 standards. This level of encryption is managed by IBM.\n\nWhen you create an endpoint, you can optionally provide another level of encryption by specifying [data encryption protocols](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-link-location-cloudlink-protocols) for the endpoint connection between the client source and destination resource. For example, even if the traffic is not encrypted on the source side, you can specify TLS encryption for the connection that goes over the internet. You can provide your own signed certificates to ensure both internal security and operational auditability without exposing any data contents. IBM only transports the encrypted connection, and your resources must be configured for the data encryption protocols that you specify.\n\n\n\n\n\n\n\n Encryption protocols \n\nAll communication over Satellite Link is encrypted by IBM. When you create an endpoint, you can optionally specify an additional data encryption protocol for the endpoint connection between the client source and destination resource. For example, even if the traffic is not encrypted on the source side, you can specify your own additional TLS encryption for the connection that goes over the internet. Note that your resources must be configured for the data encryption protocols that you specify.\n\nReview the following information about how Satellite Link handles each type of connection protocol.\n\nIf you use the Satellite console to create an endpoint, the destination protocol is inherited from the source protocol that you select. To specify a destination protocol, use the CLI to create an endpoint and include the --dest-protocol option in the ibmcloud sat endpoint create command.\n\n\n\n TCP and TLS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-link-location-cloud"},{"document_id":"ibmcld_09081-7-2309","score":11.5067158638,"text":"\nProtecting data with envelope encryption \n\nKey Protect uses envelope encryption to assist in protecting your Key Protect data. Envelope encryption involves encrypting your data with a Data Encryption Key, then encrypting the Data Encryption Key with a root key. This topic describes the process of envelope encryption and how to use Key Protect to encrypt and decrypt your data.\n\nWhen working with sensitive data, it is important to use advanced encryption techniques to prevent a data breach. If you have large amounts of confidential data, it is often helpful to use a Key Management System to assist in keeping your data secure. Key Protect uses the envelope encryption technique to keep your data resilient. Envelope encryption is the process of using encrypted keys, Data Encryption Keys and Root Keys, to protect your sensitive data.\n\nImagine that you plan to send a letter to a colleague. You want to discuss information that is highly sensitive, so you generate a secret code (Data Encryption Key) that is used to write (encrypt) the message in the letter. The letter is delivered to a mailbox (wrapped Data Encryption Key) that can only be opened by those with a copy of the mailbox key (Root key), including the colleague. Anyone who does not have an exact copy of the key will be unable to open the mailbox and see it's contents. When your colleague uses the key to unlock (unencrypt) the mailbox, they will need to know the secret code that the letter is written in to be able to understand the message. Everyone who is not aware of the secret code will conclude that the letter is a random mix of characters and will not be able to understand the letter's contents.\n\nData encryption keys (DEKs) are designed to encrypt your data and can be generated and managed by your service or an IBM Cloud service.\n\nEnvelope encryption offers several benefits for protecting your data:\n\n\n\n* Protection under a combination of multiple algorithms Envelope encryption uses the best benefits from symmetric and public key algorithms to keep your keys secure.\n\n\n\n1. Symmetric key algorithms work faster, are more scalable, and more secure than public key algorithms. Public key algorithms use complicated mathematics that increase computational overhead, especially when dealing with large volumes of data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption"},{"document_id":"ibmcld_08766-8126-10005","score":11.4947000839,"text":"\n[IBM Db2 default encryption by using the standard PKCS #11 API](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/hs-crypto\/\/images\/pkcs-db2.svg)\n\nFigure 5. IBM Db2 default encryption by using the standard PKCS #11 API\n\n\n\nWith the PKCS #11 library integration, Hyper Protect Crypto Services supports the industry-standard PKCS #11 API. The Hyper Protect Crypto Services PKCS #11 library connects your database to Hyper Protect Crypto Services to perform cryptographic operations. The database system can invoke operations to manage the TDE master encryption keys or the master keys in the Hyper Protect Crypto Services PKCS #11 library. The Hyper Protect Crypto Services PKCS #11 library then interacts with your Hyper Protect Crypto Services instance to provide the highest level of security for storing and managing your TDE master encryption keys or your master keys in the cloud. It, in turn, provides the highest level of security to your data encryption keys and your data.\n\n\n\n* For a tutorial on how to use TDE with Hyper Protect Crypto Services, see\n\n[Tutorial: Using Oracle Transparent Database Encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-tde-pkcs11).\n* For a tutorial on how to use Db2 default encryption with Hyper Protect Crypto Services, see\n\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-use-cases"},{"document_id":"ibmcld_13108-7-2001","score":11.4594593042,"text":"\nAbout Key Protect \n\nIBM\u00ae Key Protect for IBM Cloud\u00ae is a full-service encryption solution that allows data to be secured and stored in IBM Cloud using the latest envelope encryption techniques that leverage FIPS 140-2 Level 3 certified cloud-based hardware security modules.\n\nSensitive data should not be stored on any cloud provider unencrypted (as \"plaintext\", in other words). But just as with any method of encryption, going back to the earliest known ciphertexts created thousands of years ago, the trick is not just to encrypt information so that it cannot be decoded easily but to protect the ciphers used to encrypt and decrypt it (since having a cipher is as good as having the data).\n\nWhile it is possible to set up a hardware security module (HSM) on premises to manage your data, this kind of system can be very expensive to establish and manage. Cloud-based storage, where encrypted data must be accessible at scale and at speed from a variety of permissioned actors, is less expensive, but has its own difficulties. How can you be sure that the data is secure when the key used to encrypt it (what's known as a \"data encryption key\") could exist on dozens if not hundreds of computers spread all over the world? In that scenario, your data is only as secure as the computers and connections of those with the data encryption key.\n\nThe solution is a key management system like Key Protect, which keeps data secure by encrypting the data encryption keys (DEKs) that encrypt your plaintext data with root keys managed by IBM via an impenetrable HSM. In this kind of a system, known as \"envelope encryption\", the process of decrypting the data means first \"unwrapping\" the encrypted DEK (opening its envelope, in other words) and then using the DEK to decrypt the data.\n\nFor more information about envelope encryption works, check out [Protecting data with envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption).\n\n\n\n What Key Protect offers","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/key-protect?topic=key-protect-about"},{"document_id":"ibmcld_00260-7-1922","score":11.3256993533,"text":"\nSecuring your data in Block Storage for Classic \n\nTo ensure that you can securely manage your data when you use Block Storage for Classic, it's important to know exactly what data is stored and encrypted and how you can delete personal data.\n\n\n\n How your data is stored and encrypted in Block Storage for Classic \n\nIBM Cloud\u00ae Block Storage for Classic that is provisioned with either Endurance or Performance option is secured with provider-managed encryption, at no extra cost and no impact to performance.\n\nThe provider-managed encryption-at-rest feature uses the following industry standard protocols:\n\n\n\n* Industry-Standard AES-256 encryption.\n* Keys are managed in-house with industry standard Key Management Interoperability Protocol (KMIP).\n* Storage is validated for US Federal Information Processing Standard (FIPS) Publication 140-2, Federal Information Security Management Act (FISMA), Health Insurance Portability and Accountability Act (HIPAA). Storage is also validated for Payment Card Industry (PCI), Basel II, California Security Breach Information Act (SB 1386), and EU General Data Protection Regulation (GDPR) compliance.\n\n\n\n\n\n\n\n Securing your snapshots or replicated storage \n\nAll snapshots and replicas of encrypted file storage are also encrypted by default. This feature can\u2019t be turned off on a volume basis. All cluster-to-cluster traffic is encrypted with TLS.\n\n\n\n\n\n Provisioning Storage with Encryption \n\nThe provider-managed encryption-at-rest feature is available for Block Storage for Classic in all IBM Cloud\u00ae [data centers](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-selectDC).\n\nWhen you order Block Storage for Classic, select a data center noted with an asterisk (). You can see a lock icon to the right of the LUN\/Volume Name field that indicates that the volume is encrypted.\n\nZoom\n\n![Figure 1. Example of the lock icon that indicates that the LUN is encrypted.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-mng-data"},{"document_id":"ibmcld_01261-7-1890","score":11.2956372259,"text":"\nSecuring your data in File Storage for Classic \n\nIBM Cloud\u00ae takes the need for security seriously, and understands the importance of being able to encrypt data to keep it safe. With provider-managed encryption, IBM Cloud\u00ae File Storage for Classic that is provisioned with either Endurance or Performance options, is secured by default at no additional cost and no impact on performance.\n\nThe provider-managed encryption-at-rest feature uses the following industry standard protocols:\n\n\n\n* Industry-Standard AES-256 encryption.\n* Keys are managed in-house with industry standard Key Management Interoperability Protocol (KMIP).\n* Storage is validated for US Federal Information Processing Standard (FIPS) Publication 140-2, Federal Information Security Management Act (FISMA), Health Insurance Portability and Accountability Act (HIPAA). Storage is also validated for Payment Card Industry (PCI), Basel II, California Security Breach Information Act (SB 1386), and EU General Data Protection Regulation (GDPR) compliance.\n\n\n\n\n\n Securing your snapshots or replicated storage \n\nAll snapshots and replicas of encrypted file storage are also encrypted by default. This feature can\u2019t be turned off on a volume basis. All cluster-to-cluster traffic is encrypted with TLS.\n\n\n\n\n\n Provisioning storage with encryption \n\nThe provider-managed encryption-at-rest feature is available in all [data centers](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-selectDC). All storage that is ordered in these data centers is automatically provisioned with encryption for data-at-rest.\n\nWhen you order File Storage for Classic, select a data center that is marked with an asterisk (). You can see a lock icon to the right of the Volume Name field that indicates that the volume is encrypted. See Figure 1.\n\nZoom\n\n![Figure 1. Example of the lock icon that indicates that the volume is encrypted.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-mng-data"},{"document_id":"ibmcld_15431-7-2097","score":11.2526798228,"text":"\nEncryption in transit - Securing mount connections between file share and virtual server instance \n\nNew\n\nYou can establish an encrypted mount connection between the virtual server instance and storage system by using the Internet Security Protocol (IPsec) security profile and X.509 certificates. By enabling encryption in transit, you create secure end-to-end encryption for your data.\n\nIBM Cloud\u00ae File Storage for VPC is available for customers with special approval to preview this service in the Frankfurt, London, Madrid, Dallas, Toronto, Washington, Sao Paulo, Sydney, Osaka, and Tokyo regions. Contact your IBM Sales representative if you are interested in getting access.\n\n\n\n Overview \n\nWith this feature, you can enable secure end-to-end encryption of your data when you use file shares with security-group-based access control mode and mount targets with virtual network interfaces. When such a mount target is attached and the share is mounted on a virtual server instance, the virtual network interface checks the security group policy to ensure only authorized instances can communicate with the share. The traffic between the authorized virtual server instance and the file share can be IPsec encapsulated by the client.\n\nIPsec is a group of protocols that together set up encrypted connections between devices. It helps keep data sent over public networks secure. IPsec Encrypts IP packets, and authenticates the source where the packets come from. To configure IPsec on your virtual server instance, you can use [strongSwan](https:\/\/www.strongswan.org\/), which is an open source IPsec-based VPN solution. For more information about how strongSwan works, see [Introduction to strongSwan](https:\/\/docs.strongswan.org\/docs\/5.9\/howtos\/introduction.html) and [IPsec Protocol](https:\/\/docs.strongswan.org\/docs\/5.9\/howtos\/ipsecProtocol.html), too.\n\nEncrypting data in transit can have some performance impact due to the processing that is needed to encrypt and decrypt the data at the endpoints.\n\nThe IPsec connection requires that you have an X.509 certificate for authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-eit"},{"document_id":"ibmcld_15436-7-2097","score":11.2526798228,"text":"\nEncryption in transit - Securing mount connections between file share and virtual server instance \n\nNew\n\nYou can establish an encrypted mount connection between the virtual server instance and storage system by using the Internet Security Protocol (IPsec) security profile and X.509 certificates. By enabling encryption in transit, you create secure end-to-end encryption for your data.\n\nIBM Cloud\u00ae File Storage for VPC is available for customers with special approval to preview this service in the Frankfurt, London, Madrid, Dallas, Toronto, Washington, Sao Paulo, Sydney, Osaka, and Tokyo regions. Contact your IBM Sales representative if you are interested in getting access.\n\n\n\n Overview \n\nWith this feature, you can enable secure end-to-end encryption of your data when you use file shares with security-group-based access control mode and mount targets with virtual network interfaces. When such a mount target is attached and the share is mounted on a virtual server instance, the virtual network interface checks the security group policy to ensure only authorized instances can communicate with the share. The traffic between the authorized virtual server instance and the file share can be IPsec encapsulated by the client.\n\nIPsec is a group of protocols that together set up encrypted connections between devices. It helps keep data sent over public networks secure. IPsec Encrypts IP packets, and authenticates the source where the packets come from. To configure IPsec on your virtual server instance, you can use [strongSwan](https:\/\/www.strongswan.org\/), which is an open source IPsec-based VPN solution. For more information about how strongSwan works, see [Introduction to strongSwan](https:\/\/docs.strongswan.org\/docs\/5.9\/howtos\/introduction.html) and [IPsec Protocol](https:\/\/docs.strongswan.org\/docs\/5.9\/howtos\/ipsecProtocol.html), too.\n\nEncrypting data in transit can have some performance impact due to the processing that is needed to encrypt and decrypt the data at the endpoints.\n\nThe IPsec connection requires that you have an X.509 certificate for authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-eit&interface=ui"},{"document_id":"ibmcld_01061-0-2080","score":11.1828045405,"text":"\n\n\n\n\n\n\n  Inter-node encryption \n\nFor the current generation of plans hosted on AWS, inter-node encryption is always enabled. For the Flex and Flex Performance plans hosted on IBM Cloud, you can optionally choose to enable this form of encryption.\n\nInter-node encryption is an additional layer of security that protects inter-node traffic between internal Db2 nodes in a massively parallel processing (MPP) cluster. It supplements the SSL encryption that is already in use between the server and your applications.\n\nInter-node encryption ensures that your data is processed with encryption at all points from your application to physical storage and back, which protects your information from physical and software-based attacks. Leaving inter-node traffic unencrypted means that your data is transferred in plain text between the physical hardware nodes that make up your Db2 MPP instance. IBM already employs a variety of security protocols to protect such traffic to ensure the security and integrity of the unencrypted internal data flows. With this new feature, IBM provides an additional security layer to protect the data.\n\nDue to the additional processing required to encrypt data on send and decrypt on receive, workloads with significant data movement may see a performance impact as little as 5% or as much as 20%. If your instance is hosted on IBM Cloud, your solution architect must evaluate this performance impact against your need to encrypt internal traffic flows. In some cases, it might be warranted (for instance in heavily regulated industries or where end users demand such encryption). In other cases, the existing in-depth security protocols may be sufficient.\n\nIBM Cloud plans only: To enable inter-node encryption, open the web console, select Administration, and navigate to the Security -> Encryption tab. Enabling or disabling inter-node encryption can be done online, and takes effect immediately. Choosing to enable inter-node encryption does not impact the Service Level Agreement (SLA), self-service backups, database replication, or scaling.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-Inter-node"},{"document_id":"ibmcld_09267-0-452","score":11.1741070385,"text":"\n\n\n\n\n\n\n  Setting back-end encryption \n\nBack-end encryption is supported to allow end-to-end data traffic encryption. Not only is the traffic between the load balancer and the client encrypted, but so is the traffic between the load balancer and the back-end server.\n\nTo enable back-end encryption:\n\n\n\n*  If you are adding a new HTTPS protocol, set the front end and back end to HTTPS.\n*  For existing HTTPS protocols, set the back end to HTTPS.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/loadbalancer-service?topic=loadbalancer-service-setting-backend-encryption"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14598-9419-11893","score":36.4700994508,"text":"\nResponsibilities for security and regulation compliance for VMware Solutions offerings (other than VMware Shared)\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Encryption Provide integration with Key Protect and Hyper Protect Crypto Services through KMIP service as an option for implementing data at-rest encryption. Configure and manage encryption for both data at rest and in transit, as needed. \n\n\n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as:\n\n\n\n* Providing dependencies on disaster recovery sites\n* Provision disaster recovery environments\n* Data and configuration backup\n* Replicating data and configuration to the disaster recovery environment\n* Fail over on disaster events\n\n\n\n\n\n Disaster recovery for VMware Shared \n\nThe following table describes the responsibilities that are related to disaster recovery for VMware Shared.\n\n\n\nTable 8. Responsibilities for disaster recovery for VMware Shared\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Backup of configuration data Backups are conducted of the shared management components to include customer environment configurations. Offsite backup copies are enabled and they run daily. \n Backup of workload Backup services are enabled for customer workload. Configure individual backup jobs to include critical systems. Offsite copies can be enabled per request. \n Recovery of configuration Recovery will be conducted in the original data center after the infrastructure is available. If long-term outage occurs, offsite recovery is conducted. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, customer restore services will be provided after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover. Restore systems from the configured backup jobs. \n\n\n\n\n\n\n\n Disaster recovery for VMware Solutions offerings (other than VMware Shared)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-understand-responsib"},{"document_id":"ibmcld_14738-7598-10031","score":34.8755667671,"text":"\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Encryption Provide secure SSL connections to administration portals and replication endpoints. Workload can be deployed by using AES 256-bit encrypted data stores with unique key per customer instance. Backups are encrypted uniquely per customer. Choose encrypted data stores when you are deploying workloads into the environment where appropriate. Use encrypted networking for workload to workload and workload to IBM Cloud Service connections. Use the IBM Cloud private network where appropriate. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Backup of management configuration data Conduct backups of the management component configurations. These backups include single-tenant vCenter Server, VMware NSX-T, VMware Cloud Director\u2122, and service configurations. Offsite immutable backup copies are enabled in an independent backup account and they run daily. \n Backup of workloads Enable backup services for customer workload. Choose and implement a backup provider for critical workloads. For more information, see [Understanding business continuity and disaster recovery](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-bc-dr). \n Recovery of configuration Conduct recovery in the original data center after the infrastructure is available. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, provide customer restore services after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vmaas-understand-responsib"},{"document_id":"ibmcld_07578-873193-875161","score":34.0469063545,"text":"\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.\n\n\n\n* Can I use data backups for disaster recovery?\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* How many copies of my backup can I create in other regions?\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-873070-875038","score":34.0469063545,"text":"\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.\n\n\n\n* Can I use data backups for disaster recovery?\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* How many copies of my backup can I create in other regions?\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-891912-893651","score":33.316135384,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-891789-893528","score":33.316135384,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08669-6042-7847","score":31.9632585823,"text":"\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities \n\n Instance backups Continuously perform in-region and cross-region backups of key resources and perform continuous testing of backups. Back up your master key; validate the backups and restore data when needed. \n Disaster recovery When an in-region disaster occurs, automatically recover and restart service components. When a regional disaster that affects all available zones occurs, ensure that all data except the master key is replicated to another region. IBM will also make additional crypto units available in a different region and manage routing requests to the new crypto units. When a regional disaster that affects all available zones occurs, load your master key to the new crypto units that IBM provisions in a different region for restoring data. You can also enable and initialize failover crypto units before a disaster occurs, which reduces the downtime. \n Availability Provide high availability capabilities, such as IBM-owned infrastructure in multizone regions, to meet local access and low latency requirements for each supported region. Use the list of [available regions](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-regions) to plan for and create new instances of the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-shared-responsibilities"},{"document_id":"ibmcld_15034-6870-7844","score":31.5322279271,"text":"\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-vpc-faq"},{"document_id":"ibmcld_15007-7-1759","score":31.3139145023,"text":"\nAbout Backup for VPC \n\nUse IBM Cloud\u00ae Backup for VPC to automatically create backups and restore Block Storage for VPC volumes from backup snapshots. By using this service, you can prevent data loss, manage risk, and improve data compliance. You can ensure that your data is backed up regularly, and you can retain the backups while you need them. You can create and manage backup policies and plans for your Block Storage for VPC volumes by using the UI, the CLI, the API, or Terraform.\n\nBackups and snapshots services are different than a disaster recovery (DR) solution, where your data is continually backed up with automatic failover. Restoring a volume from a backup or a snapshot is a manual operation that takes time. If you require a higher level of service for disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n Backup service concepts \n\nYou can create up to 10 backup policies for your Block Storage for VPC volumes in one region with the IBM Cloud Backup for VPC service. A backup policy contains one or more backup plans, which define a schedule for automated backups. You can create up to four plans per policy, and edit and delete them as needed. If you're undecided on the backup schedule or you don't know all the tags yet, you can create a backup policy without a plan and add one later.\n\nBefore you create backups, review the [planning your backups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backups-vpc-planning) topic. For more information, see [best practices for creating backups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backups-vpc-best-practices).\n\nIn a backup plan, you schedule the frequency of your backups. In the UI, you can choose daily, weekly, or monthly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about"},{"document_id":"ibmcld_15020-7-1759","score":31.3139145023,"text":"\nAbout Backup for VPC \n\nUse IBM Cloud\u00ae Backup for VPC to automatically create backups and restore Block Storage for VPC volumes from backup snapshots. By using this service, you can prevent data loss, manage risk, and improve data compliance. You can ensure that your data is backed up regularly, and you can retain the backups while you need them. You can create and manage backup policies and plans for your Block Storage for VPC volumes by using the UI, the CLI, the API, or Terraform.\n\nBackups and snapshots services are different than a disaster recovery (DR) solution, where your data is continually backed up with automatic failover. Restoring a volume from a backup or a snapshot is a manual operation that takes time. If you require a higher level of service for disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n Backup service concepts \n\nYou can create up to 10 backup policies for your Block Storage for VPC volumes in one region with the IBM Cloud Backup for VPC service. A backup policy contains one or more backup plans, which define a schedule for automated backups. You can create up to four plans per policy, and edit and delete them as needed. If you're undecided on the backup schedule or you don't know all the tags yet, you can create a backup policy without a plan and add one later.\n\nBefore you create backups, review the [planning your backups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backups-vpc-planning) topic. For more information, see [best practices for creating backups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backups-vpc-best-practices).\n\nIn a backup plan, you schedule the frequency of your backups. In the UI, you can choose daily, weekly, or monthly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16065-1526-3778","score":6.0950460155,"text":"\nThese nodes also run a small set of control plane agent services, as described in this table. \n Bare metal nodes Bare metal nodes are delivered to you dedicatedly with VMware ESXi installed during provision. The bare metal nodes are equipped with SmartNIC and local storage to support VMware clusters on VPC. Your bare metal server API requests are routed to services deployed across control nodes in the region. All communication between control plane services occurs over a secure, encrypted network. \n VPC control plane services Your VPC API requests are routed to services deployed across control nodes in the region. These services are replicated for availability and performance across multiple zones in the region whenever necessary. In addition to servicing API requests, these services monitor the region's hardware and capabilities, and perform orchestration to keep your VPC resources available and performing optimally. All communication between control plane services occurs over a secure, encrypted network. Since your instances do not run on control nodes, they are separated from these services. \n VPC control plane agent services A small set of VPC control plane agents is deployed across hypervisor nodes in the region. For example, agents are used to create new virtual server instances on the nodes, and to forward logs, metrics, and alerts off the node for use by the broader VPC control plane services. All communication between control plane services occurs over a secure, encrypted network. \n VPC control plane data store Your VPC resources are persisted in a data store that is replicated across all zones in the region. This store contains metadata about these resources only, and does not contain your data. For example, this store contains information about each VPC Image resource, such as its name, CRN, and creation date. However, it does not contain the image data itself, which is hosted on the storage devices. All communication between control plane services and the control plane data store is secure and encrypted. \n Block Storage Each zone of each region contains a set of replicated storage devices, which host the data for your VPC volumes. Your data is always encrypted at rest, and is isolated to your account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-isolation"},{"document_id":"ibmcld_15957-7-1803","score":5.7413055697,"text":"\nAvailability and Durability of VPC storage \n\nIn today's fast-paced economy, companies rely on data in their decision-making. They need secure and immediate access to their data on a moment's notice. Data integrity is of high priority because compromised or incomplete data is of no use. Not to mention the dangers that are presented if sensitive data goes missing. When you store your data in Block Storage for VPC volumes, snapshots, backups, or in File Storage for VPC shares, it's durable, highly available, and encrypted.\n\n\n\nTable 1. Block Storage for VPC Storage durability and availability chart.\n\n Block Storage for VPC Storage type Use Case Durability Availability Encryption \n\n 3 IOPS per GB tier It is designed for general-purpose workloads such as workloads that host small databases for web applications or store virtual machine disk images for a hypervisor. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption \n 5 IOPS per GB tier It is designed for high I\/O intensity workloads that are characterized by a large percentage of active data, such as transactional and other performance-sensitive databases. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption \n 10 IOPS per GB tier It is designed for demanding storage workloads such as data-intensive workloads created by NoSQL databases, data processing for video, machine learning, and analytics. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption \n custom Customers can specify capacity between 10 - 16000 MB with IOPS ranging 100 - 48000. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-storageavailability"},{"document_id":"ibmcld_15074-0-653","score":5.6350552092,"text":"\n\n\n\n\n\n\n  Storage overview for Bare Metal Servers for VPC \n\nAll profiles of Bare Metal Servers for VPC provide one 0.96 TB SATA M.2 mirrored SSD as the boot disk. Profile bx2d-metal-192x768 provides an extra set of NVMe (Non-Volatile Memory Express) U.2 solid-state drives (SSD) as secondary local storage. NVMe SSDs provides fast and affordable storage to support options such as VMware vSAN, or customer-managed RAID.\n\nStorage for Bare Metal Servers for VPC is unmanaged. You are responsible for encryption and backing up your data.\n\nThe following network-attached storages are not supported:\n\n\n\n*  Block Storage for VPC\n*  File Storage for VPC\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-bare-metal-servers-storage"},{"document_id":"ibmcld_15545-191627-192724","score":5.4947792316,"text":"\nibmcloud is image-create IMAGE_NAME ([--file IMAGE_FILE_LOCATION --os-name OPERATING_SYSTEM_NAME --encrypted-data-key ENCRYPTED_DATA_KEY --encryption-key ENCRYPTION_KEY]] | [--source-volume SOURCE_VOLUME --encryption-key-volume ENCRYPTION_KEY_VOLUME]) [--resource-group-id RESOURCE_GROUP_ID | --resource-group-name RESOURCE_GROUP_NAME] [--deprecate-at DEPRECATE_AT] [--obsolete-at OBSOLETE_AT] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64 --resource-group-id fee82deba12e4c0fb69c3b09d1f12345\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64 --resource-group-name Default\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64 --output JSON","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_15558-191679-192776","score":5.4947792316,"text":"\nibmcloud is image-create IMAGE_NAME ([--file IMAGE_FILE_LOCATION --os-name OPERATING_SYSTEM_NAME --encrypted-data-key ENCRYPTED_DATA_KEY --encryption-key ENCRYPTION_KEY]] | [--source-volume SOURCE_VOLUME --encryption-key-volume ENCRYPTION_KEY_VOLUME]) [--resource-group-id RESOURCE_GROUP_ID | --resource-group-name RESOURCE_GROUP_NAME] [--deprecate-at DEPRECATE_AT] [--obsolete-at OBSOLETE_AT] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64 --resource-group-id fee82deba12e4c0fb69c3b09d1f12345\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64 --resource-group-name Default\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64 --output JSON","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"},{"document_id":"ibmcld_16082-191523-192620","score":5.4947792316,"text":"\nibmcloud is image-create IMAGE_NAME ([--file IMAGE_FILE_LOCATION --os-name OPERATING_SYSTEM_NAME --encrypted-data-key ENCRYPTED_DATA_KEY --encryption-key ENCRYPTION_KEY]] | [--source-volume SOURCE_VOLUME --encryption-key-volume ENCRYPTION_KEY_VOLUME]) [--resource-group-id RESOURCE_GROUP_ID | --resource-group-name RESOURCE_GROUP_NAME] [--deprecate-at DEPRECATE_AT] [--obsolete-at OBSOLETE_AT] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64 --resource-group-id fee82deba12e4c0fb69c3b09d1f12345\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64 --resource-group-name Default\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64 --output JSON","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference"},{"document_id":"ibmcld_16092-191579-192676","score":5.4947792316,"text":"\nibmcloud is image-create IMAGE_NAME ([--file IMAGE_FILE_LOCATION --os-name OPERATING_SYSTEM_NAME --encrypted-data-key ENCRYPTED_DATA_KEY --encryption-key ENCRYPTION_KEY]] | [--source-volume SOURCE_VOLUME --encryption-key-volume ENCRYPTION_KEY_VOLUME]) [--resource-group-id RESOURCE_GROUP_ID | --resource-group-name RESOURCE_GROUP_NAME] [--deprecate-at DEPRECATE_AT] [--obsolete-at OBSOLETE_AT] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64 --resource-group-id fee82deba12e4c0fb69c3b09d1f12345\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64 --resource-group-name Default\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64 --output JSON","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference&interface=cli"},{"document_id":"ibmcld_00708-66805-68199","score":5.457989516,"text":"\nrule-faacfd1f-454f-4e60-95d7-8fe01158840d - Check whether Virtual Private Cloud (VPC) network access control lists don't allow egress from 0.0.0.0\/0 to any port\nrule-c0314fad-f377-465e-9f16-fa5aa3d5ebbe - Check whether Virtual Servers for VPC instance has the minimum interfaces\nrule-17b54156-373a-48f9-b340-a7e47acd87b6 - Check whether Virtual Servers for VPC instance doesn't have a floating IP\nrule-1af31459-ec38-4a58-91b0-956a17a38954 - Check whether Virtual Servers for VPC boot volumes are enabled with customer-managed encryption and Bring Your Own Key (BYOK)\nrule-4aead0cd-fe26-44f1-b552-8ffdbb86422a - Check whether Virtual Servers for VPC boot volumes are enabled with customer-managed encryption and Keep Your Own Key (KYOK)\nrule-a99b5f58-98ef-4208-9a23-e4fa25115d79 - Check whether Virtual Servers for VPC data volumes are enabled with customer-managed encryption and Bring Your Own Key (BYOK)\nrule-df7323fd-0b20-493c-89fe-c0b287817c99 - Check whether Virtual Servers for VPC data volumes are enabled with customer-managed encryption and Keep Your Own Key (KYOK)\nrule-6970e312-329d-44dc-b683-5ab14acd6a42 - Check whether Virtual Servers for VPC is provisioned from an encrypted image\nrule-24e259fb-608e-486f-bb9d-99b78ae0383c - Check whether Virtual Servers for VPC instances are identifable by the workload they are running based on the Auto Scale for VPC instance group definition","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"},{"document_id":"ibmcld_00684-66805-68199","score":5.457989516,"text":"\nrule-faacfd1f-454f-4e60-95d7-8fe01158840d - Check whether Virtual Private Cloud (VPC) network access control lists don't allow egress from 0.0.0.0\/0 to any port\nrule-c0314fad-f377-465e-9f16-fa5aa3d5ebbe - Check whether Virtual Servers for VPC instance has the minimum interfaces\nrule-17b54156-373a-48f9-b340-a7e47acd87b6 - Check whether Virtual Servers for VPC instance doesn't have a floating IP\nrule-1af31459-ec38-4a58-91b0-956a17a38954 - Check whether Virtual Servers for VPC boot volumes are enabled with customer-managed encryption and Bring Your Own Key (BYOK)\nrule-4aead0cd-fe26-44f1-b552-8ffdbb86422a - Check whether Virtual Servers for VPC boot volumes are enabled with customer-managed encryption and Keep Your Own Key (KYOK)\nrule-a99b5f58-98ef-4208-9a23-e4fa25115d79 - Check whether Virtual Servers for VPC data volumes are enabled with customer-managed encryption and Bring Your Own Key (BYOK)\nrule-df7323fd-0b20-493c-89fe-c0b287817c99 - Check whether Virtual Servers for VPC data volumes are enabled with customer-managed encryption and Keep Your Own Key (KYOK)\nrule-6970e312-329d-44dc-b683-5ab14acd6a42 - Check whether Virtual Servers for VPC is provisioned from an encrypted image\nrule-24e259fb-608e-486f-bb9d-99b78ae0383c - Check whether Virtual Servers for VPC instances are identifable by the workload they are running based on the Auto Scale for VPC instance group definition","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"},{"document_id":"ibmcld_04341-66786-68180","score":5.457989516,"text":"\nrule-faacfd1f-454f-4e60-95d7-8fe01158840d - Check whether Virtual Private Cloud (VPC) network access control lists don't allow egress from 0.0.0.0\/0 to any port\nrule-c0314fad-f377-465e-9f16-fa5aa3d5ebbe - Check whether Virtual Servers for VPC instance has the minimum interfaces\nrule-17b54156-373a-48f9-b340-a7e47acd87b6 - Check whether Virtual Servers for VPC instance doesn't have a floating IP\nrule-1af31459-ec38-4a58-91b0-956a17a38954 - Check whether Virtual Servers for VPC boot volumes are enabled with customer-managed encryption and Bring Your Own Key (BYOK)\nrule-4aead0cd-fe26-44f1-b552-8ffdbb86422a - Check whether Virtual Servers for VPC boot volumes are enabled with customer-managed encryption and Keep Your Own Key (KYOK)\nrule-a99b5f58-98ef-4208-9a23-e4fa25115d79 - Check whether Virtual Servers for VPC data volumes are enabled with customer-managed encryption and Bring Your Own Key (BYOK)\nrule-df7323fd-0b20-493c-89fe-c0b287817c99 - Check whether Virtual Servers for VPC data volumes are enabled with customer-managed encryption and Keep Your Own Key (KYOK)\nrule-6970e312-329d-44dc-b683-5ab14acd6a42 - Check whether Virtual Servers for VPC is provisioned from an encrypted image\nrule-24e259fb-608e-486f-bb9d-99b78ae0383c - Check whether Virtual Servers for VPC instances are identifable by the workload they are running based on the Auto Scale for VPC instance group definition","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cra-cli-plugin"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12667-1610-3287","score":6.057059492,"text":"\nYou can view more information by clicking Migration Details in the Applications sidebar.\n\n\n\nIf there is new data which gets inserted in the database, by default, the data is encrypted by using the default data encryption policy that is being selected by the user.\n\n\n\n\n\n Reference \n\n\n\n\n\n Format Preserving Encryption (FPE) Supported Data Types \n\nThe following tables lists the FPE supported data types for the data encryption in Data Security Broker Manager:\n\n\n\n\n\n PostgreSQL \n\n\n\nTable 1. FPE Supported Data Types caption-side=\n\n Original Data Type FPE Data Type \n\n smallint fpe-int \n int fpe-int \n integer fpe-int \n bigint fpe-int \n bytea fpe-int \n numeric fpe-decimal \n decimal fpe-decimal \n numeric (s,p) fpe-decimal \n decimal (s,p) fpe-decimal \n money fpe-decimal \n var - fpe-decimal - fpe-alphanum - fpe-latin1 \n char - fpe-win1252 - fpe-cc \n text - fpe-email1 - fpe-email2 \n date fpe-datetime \n time fpe-datetime \n timestamp fpe-datetime \n uuid fpe-hexadecimal \n\n\n\n\n\n\n\n Counter-Mode (CTR) Supported Data Types \n\nData Security Broker Shield only supports one word for a data type name. BYTEA is a PostgreSQL data type that has the capability to store hexadecimal data which is used to store encrypted data. BYTEA is an equivalent of VARBINARY in MySQL or RAW datatype in Oracle database.\n\nPostgreSQL The following table lists PostgreSQL supported data types for M_CTR mode in Data Security Broker Manager.\n\n\n\nTable 2. CTR Supported Data Types caption-side=\n\n Original Data Type Encrypted Data Type \n\n SMALLINT BYTEA \n INT, INTEGER BYTEA \n BIGINT BYTEA \n REAL, FLOAT4 BYTEA \n FLOAT8 - Used in Data Security Broker Shield for \"double precision\" BYTEA \n DECIMAL, NUMERIC BYTEA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_encrypt_data"},{"document_id":"ibmcld_04543-190647-191965","score":5.7191098698,"text":"\nValid visibility is: public or private.\n* --owner-type: Filters images with given owner type. Default is all. One of: all, provider, user.\n* --resource-group-id: ID of the resource group. This ID is mutually exclusive with --resource-group-name.\n* --resource-group-name: Name of the resource group. This name is mutually exclusive with --resource-group-id.\n* --all-resource-groups: Query all resource groups.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is image-create \n\nCreate an image.\n\nibmcloud is image-create IMAGE_NAME ([--file IMAGE_FILE_LOCATION --os-name OPERATING_SYSTEM_NAME --encrypted-data-key ENCRYPTED_DATA_KEY --encryption-key ENCRYPTION_KEY]] | [--source-volume SOURCE_VOLUME --encryption-key-volume ENCRYPTION_KEY_VOLUME]) [--resource-group-id RESOURCE_GROUP_ID | --resource-group-name RESOURCE_GROUP_NAME] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64 --resource-group-id fee82deba12e4c0fb69c3b09d1f12345","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-vpc-reference"},{"document_id":"ibmcld_12678-1977-2703","score":5.5982993877,"text":"\nMany of today's server and network technologies allow for easier configuration and implementation to minimize the impact on utilization. Implementing encryption of data in transit from endpoint to endpoint both remotely and internally is mandatory in today's cyber risk environment.\n\nThe following are considered equality check operators and are supported:\n\n\n\n* =\n* <>\n* IS NULL\n* IS NOT NULL\n* IN\n* NOT\n* JOIN (all types)\n* GROUP BY\n* DISTINCT\n\n\n\nIndexes can be created on encrypted columns, but the ciphertext will be used to create the index and not the underlying cleartext values.\n\n\n\n\n\n Unsupported Data Types \n\nOnly timestamptz and timetz data types are not supported for the PostgreSQL Database in Data Security Broker.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_limitations"},{"document_id":"ibmcld_15545-190796-192213","score":5.4800902609,"text":"\n* --visibility: List images with given visibility. Valid visibility is: public or private.\n* --owner-type: Filters images with given owner type. Default is all. One of: all, provider, user.\n* --status: Filters the collection to images with the comma-separated list of status values. Available values: available, deleting, deprecated, failed, obsolete, pending, unusable.\n* --resource-group-id: ID of the resource group. This ID is mutually exclusive with --resource-group-name.\n* --resource-group-name: Name of the resource group. This name is mutually exclusive with --resource-group-id.\n* --all-resource-groups: Query all resource groups.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is image-create \n\nCreate an image.\n\nibmcloud is image-create IMAGE_NAME ([--file IMAGE_FILE_LOCATION --os-name OPERATING_SYSTEM_NAME --encrypted-data-key ENCRYPTED_DATA_KEY --encryption-key ENCRYPTION_KEY]] | [--source-volume SOURCE_VOLUME --encryption-key-volume ENCRYPTION_KEY_VOLUME]) [--resource-group-id RESOURCE_GROUP_ID | --resource-group-name RESOURCE_GROUP_NAME] [--deprecate-at DEPRECATE_AT] [--obsolete-at OBSOLETE_AT] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference"},{"document_id":"ibmcld_15558-190848-192265","score":5.4800902609,"text":"\n* --visibility: List images with given visibility. Valid visibility is: public or private.\n* --owner-type: Filters images with given owner type. Default is all. One of: all, provider, user.\n* --status: Filters the collection to images with the comma-separated list of status values. Available values: available, deleting, deprecated, failed, obsolete, pending, unusable.\n* --resource-group-id: ID of the resource group. This ID is mutually exclusive with --resource-group-name.\n* --resource-group-name: Name of the resource group. This name is mutually exclusive with --resource-group-id.\n* --all-resource-groups: Query all resource groups.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is image-create \n\nCreate an image.\n\nibmcloud is image-create IMAGE_NAME ([--file IMAGE_FILE_LOCATION --os-name OPERATING_SYSTEM_NAME --encrypted-data-key ENCRYPTED_DATA_KEY --encryption-key ENCRYPTION_KEY]] | [--source-volume SOURCE_VOLUME --encryption-key-volume ENCRYPTION_KEY_VOLUME]) [--resource-group-id RESOURCE_GROUP_ID | --resource-group-name RESOURCE_GROUP_NAME] [--deprecate-at DEPRECATE_AT] [--obsolete-at OBSOLETE_AT] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference&interface=ui"},{"document_id":"ibmcld_16082-190692-192109","score":5.4800902609,"text":"\n* --visibility: List images with given visibility. Valid visibility is: public or private.\n* --owner-type: Filters images with given owner type. Default is all. One of: all, provider, user.\n* --status: Filters the collection to images with the comma-separated list of status values. Available values: available, deleting, deprecated, failed, obsolete, pending, unusable.\n* --resource-group-id: ID of the resource group. This ID is mutually exclusive with --resource-group-name.\n* --resource-group-name: Name of the resource group. This name is mutually exclusive with --resource-group-id.\n* --all-resource-groups: Query all resource groups.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is image-create \n\nCreate an image.\n\nibmcloud is image-create IMAGE_NAME ([--file IMAGE_FILE_LOCATION --os-name OPERATING_SYSTEM_NAME --encrypted-data-key ENCRYPTED_DATA_KEY --encryption-key ENCRYPTION_KEY]] | [--source-volume SOURCE_VOLUME --encryption-key-volume ENCRYPTION_KEY_VOLUME]) [--resource-group-id RESOURCE_GROUP_ID | --resource-group-name RESOURCE_GROUP_NAME] [--deprecate-at DEPRECATE_AT] [--obsolete-at OBSOLETE_AT] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference"},{"document_id":"ibmcld_16092-190748-192165","score":5.4800902609,"text":"\n* --visibility: List images with given visibility. Valid visibility is: public or private.\n* --owner-type: Filters images with given owner type. Default is all. One of: all, provider, user.\n* --status: Filters the collection to images with the comma-separated list of status values. Available values: available, deleting, deprecated, failed, obsolete, pending, unusable.\n* --resource-group-id: ID of the resource group. This ID is mutually exclusive with --resource-group-name.\n* --resource-group-name: Name of the resource group. This name is mutually exclusive with --resource-group-id.\n* --all-resource-groups: Query all resource groups.\n* --output: Specify output format, only JSON is supported. One of: JSON.\n* -q, --quiet: Suppress verbose output.\n\n\n\n--------------------\n\n\n\n\n\n\n\n ibmcloud is image-create \n\nCreate an image.\n\nibmcloud is image-create IMAGE_NAME ([--file IMAGE_FILE_LOCATION --os-name OPERATING_SYSTEM_NAME --encrypted-data-key ENCRYPTED_DATA_KEY --encryption-key ENCRYPTION_KEY]] | [--source-volume SOURCE_VOLUME --encryption-key-volume ENCRYPTION_KEY_VOLUME]) [--resource-group-id RESOURCE_GROUP_ID | --resource-group-name RESOURCE_GROUP_NAME] [--deprecate-at DEPRECATE_AT] [--obsolete-at OBSOLETE_AT] [--output JSON] [-q, --quiet]\n\n\n\n Command examples \n\n\n\n* ibmcloud is image-create my-ubuntu-16-amd64 --file cos:\/\/us-south\/custom-image-vpc-bucket\/customImage-0.qcow2 --os-name ubuntu-16-amd64","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-reference&interface=cli"},{"document_id":"ibmcld_12660-7-1969","score":5.4452129327,"text":"\nApply an RBAC policy to columns \n\nThis task demonstrates how to select an RBAC policy for an application and apply it to selected columns in a table. You may optionally select an encryption mode on the same columns, to transform the underlying data.\n\nNote:\n\n\n\n* Only one RBAC policy can be applied to a column.\n* RBAC policies are application-specific and cannot be shared with other applications.\n* RBAC policies have a dependency on data types, because only certain Mask Modes can be applied for certain data types. In the Column selector, only compatible RBAC Policies are available to select for each column.\n* Editing an RBAC policy affects all columns to which the policy is already applied.\n\n\n\nTo apply an RBAC policy to columns, do the following:\n\n\n\n1. In Data Security Broker Manager, navigate to the Applications dashboard, select an application from the listing, and click Encrypt to access the Schema Builder.\n2. In the Tree Menu, select a database, schema, and table. This populates the column selector with available columns.\n3. Select columns to define with an RBAC policy.\n4. In the Data Protection dropdown menu, select an RBAC policy from the list. RBAC policies have a dependency on data types, because only certain Mask Modes can be applied for certain data types. Therefore, in the Column selector, only compatible RBAC Policies are available to select for each column.\n5. By default, the standard Encryption mode 'DEFAULT_CTR_DET' is selected.\n\n\n\nWhen an RBAC Policy and encryption mode is selected on the same column, then the underlying database is encrypted as well. To apply an RBAC policy without encrypting, use the Clear Selections option, then select the RBAC policy.\n\n\n\n1. Optional: Specify a Key ID for each column from the drop-down menu or accept the default.\n2. Click REVIEW at the bottom left panel to review your selections.\n3. Review your policy and select a Migration Plan:\n4. Save: Saves the data schema for future use.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_apply_rbac_policy"},{"document_id":"ibmcld_15957-7-1803","score":5.4283929008,"text":"\nAvailability and Durability of VPC storage \n\nIn today's fast-paced economy, companies rely on data in their decision-making. They need secure and immediate access to their data on a moment's notice. Data integrity is of high priority because compromised or incomplete data is of no use. Not to mention the dangers that are presented if sensitive data goes missing. When you store your data in Block Storage for VPC volumes, snapshots, backups, or in File Storage for VPC shares, it's durable, highly available, and encrypted.\n\n\n\nTable 1. Block Storage for VPC Storage durability and availability chart.\n\n Block Storage for VPC Storage type Use Case Durability Availability Encryption \n\n 3 IOPS per GB tier It is designed for general-purpose workloads such as workloads that host small databases for web applications or store virtual machine disk images for a hypervisor. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption \n 5 IOPS per GB tier It is designed for high I\/O intensity workloads that are characterized by a large percentage of active data, such as transactional and other performance-sensitive databases. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption \n 10 IOPS per GB tier It is designed for demanding storage workloads such as data-intensive workloads created by NoSQL databases, data processing for video, machine learning, and analytics. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption \n custom Customers can specify capacity between 10 - 16000 MB with IOPS ranging 100 - 48000. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-storageavailability"},{"document_id":"ibmcld_15286-24296-25026","score":5.3774445227,"text":"\n\"id\": \"7e5bdb52-676d-43b2-991f-2053cf6855eb\",\n\"lifecycle_state\": \"pending\",\n\"mount_path\": \"\",\n\"name\": \"myshare-1\",\n\"primary_ip\": {\n\"address\": \"\"\n},\n\"resource_type\": \"share_target\",\n\"subnet\": {\n\"crn\": \"crn:[...]\",\n\"href\": \"$vpc_api_endpoint\/v1\/subnets\/4e95744c-7e64-48c9-b5d2-3b6481b1dfde\",\n\"id\": \"4e95744c-7e64-48c9-b5d2-3b6481b1dfde\",\n\"name\": \"subnet-2\",\n\"resource_type\": \"subnet\"\n},\n\"transit_encryption\": \"none\",\n\"virtual_network_interface\": {\n\"crn\": \"crn:[...]\",\n\"href\": \"$vpc_api_endpoint\/v1\/virtual_network_interface\/710y-b8aa945c-7eac-4c15-bad6-a56db9d1e9bd\",\n\"id\": \"710y-b8aa945c-7eac-4c15-bad6-a56db9d1e9bd\",\n\"name\": \"enlace-traverse-oat-console\",\n\"resource_type\": \"VirtualNetworkInterface\"\n},\n\"vpc\": {\n\"crn\": \"crn:[...]\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-create"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07549-2803-4897","score":15.0319106148,"text":"\nCopyright \u00a9 2007 Free Software Foundation, Inc. <https:\/\/fsf.org\/>Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.PreambleThe GNU General Public License is a free, copyleft license for software and other kinds of works.The licenses for most software and other practical works are designed to take away your freedom to share and change the works. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change all versions of a program--to make sure it remains free software for all its users. We, the Free Software Foundation, use the GNU General Public License for most of our software; it applies also to any other work released this way by its authors. You can apply it to your programs, too.When we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for them if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs, and that you know you can do these things.To protect your rights, we need to prevent others from denying you these rights, or asking you to surrender the rights. Therefore, you have certain responsibilities if you distribute copies of the software, or if you modify it: responsibilities to respect the freedom of others.For example, if you distribute copies of such a program, whether gratis or for a fee, you must pass on to the recipients the same freedoms that you received. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights.Developers that use the GNU GPL protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License giving you legal permission to copy, distribute and\/or modify it.For the developers' and authors' protection, the GPL clearly explains that there is no warranty for this free software.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-notices"},{"document_id":"ibmcld_07549-4444-6656","score":11.8439608058,"text":"\nYou must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights.Developers that use the GNU GPL protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License giving you legal permission to copy, distribute and\/or modify it.For the developers' and authors' protection, the GPL clearly explains that there is no warranty for this free software. For both users' and authors' sake, the GPL requires that modified versions be marked as changed so that their problems will not be attributed erroneously to authors of previous versions.Some devices are designed to deny users access to install or run modified versions of the software inside them, although the manufacturer can do so. This is fundamentally incompatible with the aim of protecting users' freedom to change the software. The systematic pattern of such abuse occurs in the area of products for individuals to use, which is precisely where it is most unacceptable. Therefore, we have designed this version of the GPL to prohibit the practice for those products. If such problems arise substantially in other domains, we stand ready to extend this provision to those domains in future versions of the GPL, as needed to protect the freedom of users.Finally, every program is threatened constantly by software patents. States should not allow patents to restrict development and use of software on general-purpose computers, but in those that do, we wish to avoid the special danger that patents applied to a free program could make it effectively proprietary. To prevent this, the GPL assures that patents cannot be used to render the program non-free.The precise terms and conditions for copying, distribution and modification follow.TERMS AND CONDITIONS<-- <\/section \"id=\"section-GPL-V3\" \"> --><-- <section \"id=\"section-en-notice-def\" \"> --> 0. Definitions \"This License\" refers to version 3 of the GNU General Public License.\"Copyright\" also means copyright-like laws that apply to other kinds of works, such as semiconductor masks.\"The Program\" refers to any copyrightable work licensed under this License. Each licensee is addressed as \"you\".","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-notices"},{"document_id":"ibmcld_08591-19690-21323","score":11.8257204192,"text":"\nliability or responsibility for the accuracy, completeness, or \n usefulness of any information, apparatus, product, or process \n disclosed, or represents that its use would not infringe \n privately-owned rights. Reference herein to any specific commer- \n cial products, process, or service by trade name, trademark, \n manufacturer, or otherwise, does not necessarily constitute or \n imply its endorsement, recommendation, or favoring by the United \n States Government or the University of California. The views and \n opinions of authors expressed herein do not necessarily state or \n reflect those of the United States Government or the University \n of California, and shall not be used for advertising or product \n endorsement purposes. \/\n---------------------------------------------------------------------\n\n(locale-gen.8) GFDL 1.1 [locales-all]\n\nEduard Bloch <blade@debian.org> for\nthe fBDebian GNU\/LinuxfP system (but may be used by others). Permission is\ngranted to copy, distribute and\/or modify this document under\nthe terms of the GNU Free Documentation\nLicense, Version 1.1 or any later version published by the Free\nSoftware Foundation; with no Invariant Sections, no Front-Cover\nTexts and no Back-Cover Texts.\n.\" created by instant \/ docbook-to-man, Sat 02 Mar 2002, 16:43\n End Of File \n\ngit-updates-2.diff [locales-all]\n\n@@ -441,15 +441,6 @@ Permission to use, copy, modify, and distribute\nthis\nsoftware is freely granted, provided that this notice\nis preserved.\n2\n-Part of stdio-common\/tst-printf.c is copyright C E Chew:\n-\n-(C) Copyright C E Chew\n-\n-Feel free to copy, use and distribute this software provided:\n-\n- 1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-open-source-licenses"},{"document_id":"ibmcld_04645-5074-6875","score":11.574689905,"text":"\nFree level of service [Yes, free tier available, that re-sets every month](https:\/\/www.ibm.com\/cloud\/code-engine\/pricing) [Yes, free limited cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov) No \n Latest community Kubernetes distribution Yes. IBM Cloud Code Engine is built on IBM Cloud Kubernetes Service. Yes Partially. Support is as close as possible to the latest major version.For example, right now OpenShift 4.10 is on Kubernetes 1.23, but we offer OpenShift 4.9 right now, which is on Kubernetes 1.22. Support is typically offered on the Kubernetes N-1 version. \n Scope IBM Cloud IAM access policies to access groups for service access roles that sync to cluster RBAC Yes Yes No \n Classic infrastructure cluster on only the private network Not applicable, built on Gen2 infrastructure. Yes No \n GPU bare metal worker nodes No Yes (but only for Classic, not for VPC) Yes (but only for Classic, not for VPC) \n Integrated IBM Cloud Paks and middleware Not applicable Not applicable Yes \n Built-in containers, builds, and tooling Yes No Yes \n Integrated CI\/CD Yes (with IBM Cloud Toolchain) No Yes (with Jenkins) \n Stricter app security context set up by default Yes No Yes \n Simplified Kubernetes developer experience, with an app console that is suited for beginners Yes No Yes \n Supported operating system Worker node OS same as IKS Container level OS (if using Docker) is what is supplied in the dockerfile Container level OS (if using buildpack) supports all runtimes available on paketo.io Ubuntu 18.04 x86_64, 16.04 x86_64 (deprecated) Red Hat Enterprise Linux 7 (RHEL); however, as of 4.9, it will be CoreOS (RHCOS) \n Secured routes encrypted with Hyper Protect Crypto Services No No Yes \n Subscribe to event producers, such as Cloud Object Storage and Cron Yes Yes Yes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-deprecation_option_comparison"},{"document_id":"ibmcld_07578-754408-756389","score":11.5267413232,"text":"\nYes, NetScaler VPX appliances support High Availability (HA) configurations.\n\nNetScaler VPX servers are not redundant, unless configured in HA mode with a partner. As part of your back up and recovery strategy, it is highly recommended to deploy an HA environment when using NetScaler VPX.\n\nIt is also important to provide redundancy for other hardware and software components. For example, power supplies and local disk drives may not have redundancy. A failure in these components may result in data loss.\n* Does the IBM Cloud NetScaler offering include SSL VPN functionality?\n\nYes, this feature is known as NetScaler Gateway\u2122 and is included in all editions. For more information regarding this feature please visit the [Citrix website\")](https:\/\/www.citrix.com\/products\/netscaler-adc\/)\n\n\n\nCloud Internet Services (CIS)\n\n\n\n* What do I get with a Free Trial Plan?\n\nThe Free Trial plan, by design, allows only one zone per account. It is recommended that only one instance be created per account and the zone name be verified. It is critical that the zone name be verified before it is added. If a zone is deleted, another zone or the same zone cannot be added during the Free Trial Plan.\n* How many Free Trial instances can I have?\n\nYou can have, at most, one Free Trial instance per account, for the lifetime of the account. If you already have a free trial instance, if you delete a free trial instance, or if the free trial expires, you are not allowed to create another free trial instance. You can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n* Can I downgrade from Standard to the Free Trial?\n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n* My Free Trial has expired. What are my options?\n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_05374-1704-3601","score":11.4649503324,"text":"\n* Deploy an application from code on your local system with Code Engine.\n\n\n\n\n\n* Video transcript\n\nHi, my name is JJ Asghar and I'm a developer advocate for IBM Cloud. Recently, you might have heard about Heroku changing their policy on free - the free tier. It's causing a challenge for a lot of developers out there so I want to take a handful of moments here to show you how you can migrate from Heroku to Code Engine from IBM Cloud in just a handful of steps. So let's go ahead and start playing around with it and see how quickly you can actually make your system work.\n\nSo first thing first, if you haven't seen it this is the actual line inside the official blog from Heroku, starting on November 28, 2022, we plan to stop free - offering the free product plans and plan on shutting down the free dynos and data services. We'll be sending out a series of email communications to affected users. This is challenging for a lot of beginner beginner web applications. I know for a fact personally I used Heroku when I first started back in the day so this is a pretty large hit for a lot of people and I want to show you how easy it is to convert from Heroku to Code Engine.\n\nSo first thing first, let's actually see a nice little application I've created. If I go ahead and bring up my application here, we have a nice little flask app. If you don't know what python is or flask is, it's a it's a format for python to be able to run an application on a standard port. So let's say we have this application; it says \u201cHello World!\u201d. I've already deployed it and we can check out right here We have our amazing production app at heroku.com. It says \u201chello world\u201d and we want to go ahead and change it. We wanted to update it so I'm going to go ahead and quickly update it to \u201cHello Moving from Heroku to Code Engine\u201d.\n\nLet\u2019s go ahead and come out of it. git add .git commit -m \u201cupdate hello line\u201d.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-heroku-migrate"},{"document_id":"ibmcld_16727-754871-756890","score":11.2915696447,"text":"\nYes, this feature is known as NetScaler Gateway\u2122 and is included in all editions. For more information regarding this feature please visit the [Citrix website\")](https:\/\/www.citrix.com\/products\/netscaler-adc\/)\n\n\n\nCloud Internet Services (CIS)\n\n\n\n* What do I get with a Free Trial Plan?\n\nThe Free Trial plan, by design, allows only one zone per account. It is recommended that only one instance be created per account and the zone name be verified. It is critical that the zone name be verified before it is added. If a zone is deleted, another zone or the same zone cannot be added during the Free Trial Plan.\n* How many Free Trial instances can I have?\n\nYou can have, at most, one Free Trial instance per account, for the lifetime of the account. If you already have a free trial instance, if you delete a free trial instance, or if the free trial expires, you are not allowed to create another free trial instance. You can, however, create instances of other paid plan types (for example, Standard), independent of any free trials you might have created.\n* Can I downgrade from Standard to the Free Trial?\n\nNo. Downgrading from Standard to a Free Trial plan is not allowed.\n* My Free Trial has expired. What are my options?\n\nTo avoid any data loss you must upgrade from Free Trial to Standard prior to the expiration date. After that, we only support upgrading the Plan or Deleting the CIS instance. If the instance is not deleted or upgraded after 45 days (from the initiation of the instance) the configuration domain, global load balancers, pools, and health checks are deleted automatically.\n* What happened to Enterprise Package plans?\n\nStarting on 21 June 2023, you can no longer configure the Enterprise package plan. The functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n* How do I delete my CIS instance?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16666-7-1960","score":11.0533153836,"text":"\nAllowing trial experience \n\nIBM provides promotion credits to allow a trial experience. The promotion code is sized to allow free trial of IBM\u00ae watsonx.data for seven days, if you carefully follow the tutorial. In this trial, you can explore and familiarize yourself with watsonx.data.\n\nIn this tutorial you learn how to claim your free promo code, apply it, monitor the usage of the credit, get started, size your starter instance of watsonx.data and try it out.\n\nAfter you fully use the promo credits, you are automatically billed at the advertised rate. So, watch the usage and consumption of the promotion code credits closely.\n\n\n\n Objective \n\n\n\n* Getting the promotion code\n* Monitoring the promotion credit usage\n* Getting started with watsonx.data\n* Loading data\n* Querying data\n\n\n\nZoom\n\n![Workflow diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4c3c4670556d1cad9f530a5c8a9edd2e63919b83\/watsonxdata\/images\/happypath_userjourney.svg)\n\nFigure 1. User journey\n\n\n\n\n\n Before you begin \n\n\n\n* To use the promotion credits, you must have an IBM Cloud\u00ae account with a payment method added.\n\n\n\n\n\n\n\n Step 1: Exploring key features \n\nExplore and review the following information in the watsonx.data IBM Cloud\u00ae catalog page.\n\n\n\n Viewing promotion code \n\nTo view the promotion code and to know about the free credits, follow the steps:\n\n\n\n1. Go to the watsonx.dataIBM Cloud\u00ae catalog page.\n2. The Summary section displays an information dialog box with the promotion code and the free credits information.\n\n\n\n\n\n\n\n Review price estimate and plan resource \n\nYour watsonx.data features an elastic scalable computation method with cost per hour that is computed in Resource Units per Hour (RU\/Hr). The cost varies depending on the resources that you add. It is important to right size the resources so that you can maximize the promotion credits. Take the time to carefully review the section and select minimum resources to conserve your promotion credits.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_hp_intro"},{"document_id":"ibmcld_15476-1717-3467","score":10.9840089155,"text":"\nLifecycle for CentOS operating systems\n\n Operating sytem End of support License model \n\n CentOS 8 minimal 31 December 2021 Free \n CentOS 7.9 minimal 30 June 2024 Free \n\n\n\n\n\n\n\n Debian \n\nThe following table describes the end of support date and license model for Debian operating systems. This guest OS is a free operating system. For more information, see [Debian community](https:\/\/www.debian.org\/).\n\n\n\nTable 2. Lifecycle for Debian operating systems\n\n Operating sytem End of support License model \n\n Debian 11 minimal 01 June 2026 Free \n Debian 10 minimal 01 June 2024 Free \n Debian 9 minimal 30 June 2022 Free \n\n\n\n\n\n\n\n Fedora CoreOS \n\nThe version of Fedora\u00ae CoreOS is updated regularly, with the previous release deprecating when a new version is released. This guest OS is a free operating system. For more information, see [Fedora](https:\/\/getfedora.org\/).\n\n\n\nTable 3. Lifecycle for Fedora CoreOS operating systems\n\n Operating sytem End of support License model \n\n Fedora CoreOS latest N\/A Free \n\n\n\n\n\n\n\n Red Hat Enterprise Linux (RHEL) \n\nThe following table describes the end of support date and license model for Red Hat\u00ae Enterprise Linux\u00ae operating systems. This guest OS is a paid operating system. For more information, see [Red Hat Enterprise Linux](https:\/\/www.redhat.com\/en\/technologies\/linux-platforms\/enterprise-linux).\n\n\n\nTable 4. Lifecycle for Red Hat Enterprise Linux (RHEL) operating systems\n\n Operating sytem End of support License model \n\n RHEL 9.0 minimal 31 May 2024 Pay-as-you-Go \/ BYOL \n RHEL 9.0 (SAP HANA and SAP applications) 31 May 2026 Pay-as-you-Go \n RHEL 8.6 minimal 31 May 2024 Pay-as-you-Go \/ BYOL \n RHEL 8.6 (SAP HANA and SAP applications) 31 May 2026 Pay-as-you-Go \n RHEL 8.4 minimal 31 May 2023 Pay-as-you-Go \/ BYOL","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-guest-os-lifecycle"},{"document_id":"ibmcld_11347-10510-12848","score":10.8538631098,"text":"\nWhen you attempt to resize the memory as well as CPU of a deployed virtual server instance through a single request it may fail due to the following reasons:\n\n\n\n* There is no free memory available on the host.\n* There is no free memory available on the logical partition as the resources on it are running.\n* The free memory available on the logical partition is less than that of the desired value indicated in the resizing request.\n* You have made multiple attempts for resizing.\n* Currently, there is no preference for memory or CPU on what should be resized first. If the first request being processed fails, the second one will also fail automatically.\n\n\n\nExample: When the currently allocated memory for the logical partition is 4GB and you are trying to reduce the value to 2GB and the logical partition at the time of request does not have free 2GB memory for resizing (considering the logical partition is using upto 3.2 GB for running resources in it), then there is a possibility that both the CPU and memory resize will fail.\n\n\n\n\n\n You request for resizing the memory but you get a partial resize \n\nWhen you attempt to resize the memory of a deployed virtual server instance through a request, it may partially resize or in the worst scenarios even fail due to the following reasons:\n\n\n\n* There is no free memory available on the host will result in failed request.\n* There is no free memory available on the logical partition as the resources are running on it. This will result in a failed request.\n* The free memory available on the logical partition is less than that of the desired value indicated in the resizing request. This will result in a partial resize.\n* You have made multiple attempts for resizing. This will result in a failed request.\n\n\n\nExample:When the currently allocated memory for the logical partition is 4GB and you are trying to reduce the value to 2GB and the logical partition at the time of request does not have free 2GB memory for resizing (considering the logical partition is using upto 3 GB for running resources in it) and can free up only 1 GB, then the partial resize should be possible to reduce the memory to 3GB.\n\nIn the current cloud environment, it may take upto 1.5 hours approximately for the change in memory to be updated to places referring to the memory of the logical partition.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-modifying-server"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15508-4525-6640","score":24.1785022054,"text":"\nYou [enable the metadata service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-imd-get-metadataimd-metadata-service-enable) by setting a toggle in the VPC UI, CLI, or API. You can enable the service when you create an instance or update an existing instance.\n\nThe metadata service intercepts all requests to the service's IP, and then routes them to the specific services to handle these requests. As part of the request to the metadata service, you have to include the instance identity access token.\n\n\n\n Compute resource identities \n\nThrough IAM, you can also assign access rights to instances by creating a [compute resource identity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-imd-trusted-profile-metadata), and then configure access rights to IBM-enabled services that are using that identity.\n\nThe compute resource identity service creates a trusted profile, against which you can assign access rights to enable the instance to call IAM-enabled services, such as IBM Cloud Object Storage and IBM Key Protect for IBM Cloud. You create a trusted profile within the virtual server instance. Trusted profiles define authorization for all applications that are running on the instance.\n\n\n\n\n\n User data \n\nThe metadata that you access from the instance includes user data. The user data is data that you specified when you provisioned the instance, and that is available when you provision another instances. (It's the same user data that is available from cloud-init for VPC instances.) For example, information to load database software, custom software for worker nodes, or information to make decisions about how to initialize the instance are provided in user data. For more information, see the topic on [User data](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-user-data).\n\nThe metadata that you access from within the instance is not protected by any encryption method. Any user with access to the instance and metadata service can potentially see the metadata. As a precaution, do not store sensitive data, such as passwords or customer encryption keys, as user data.\n\n\n\n\n\n\n\n\n\n Scenarios for using the metadata service","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-imd-about"},{"document_id":"ibmcld_01078-0-2519","score":23.4272711709,"text":"\n\n\n\n\n--------------------\n\n\n\n  Backup and restore \n\nA snapshot backup of the database is taken daily. Management and configuration of daily snapshot backups is built into the web console.\n\nYou can use the web console to restore from a snapshot backup if needed. While the restore is in progress, all writes in the system are queued, and all reads that don\u2019t depend on the queued writes will continue. The RPO for snapshot backups is 24 hours. The RTO when restoring from a snapshot backup is 1 hour.\n\n\n\n  IBM Cloud \n\nThe last 7 daily snapshots are retained by default. Snapshot backups are encrypted and stored in block storage local to the Db2 Warehouse on Cloud system. Snapshot backups are free of charge.\n\n\n\n\n\n  Amazon Web Services \n\nThe last 7 daily snapshots are retained by default. When deployed on Amazon Web Services, you can use the web console to configure a longer retention period for snapshot backups if desired. Potentially unlimited snapshots can be retained. Snapshot backups are encrypted and stored in Amazon Web services S3. S3 keeps copies of each snapshot backup across 3 availability zones (AZs) in each region by default, so there are 3 copies of each snapshot backup in total.\n\nWith the current generation of plans, you are charged for all backups. The backup process backs up data on both block and object storage. The backup in this case includes snapshots of block storage and AWS S3 backup of object storage data.\n\n\n\nTable 1. Snapshot backup frequency and retention period\n\n Cloud provider       Backup frequency  Number of retained backups                                                        Retention period                                                                                 \n\n IBM Cloud            1 \/ day           Up to 7                                                                           7 days; FIFO* rollover                                                                           \n Amazon Web Services  1 \/ day           Up to 7 by default. Can be configured to retain potentially unlimited backups.    7 days; FIFO* rollover by default. Can be configured to retain potentially unlimited backups.    \n\n\n\n*First in, first out\n\n\n\n\n\n  Logical schema backup and restore \n\nThis feature provides the ability to do full, cumulative incremental, or delta incremental backup of a Db2 schema followed by full restore of the schema or table(s) within the schema. Logical schema backup is a flexible and lightweight way to backup and restore table level data.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-br"},{"document_id":"ibmcld_14514-10966-13195","score":21.2790646859,"text":"\nIn vCenter, go to the Performance tab. On each of the datastores, review the average write latency per VM. \n Review VMs with virtual devices Virtual devices such as CD or diskette drives create an overhead, therefore, remove any devices that are not needed for a VM. \n vSAN capacity advice When any capacity device in your cluster reaches 80% full, vSAN automatically rebalances the cluster until the space available on all capacity devices is lower than the threshold. The following operations can cause disk capacity to reach 80% and initiate cluster rebalancing: hardware failures, vSAN hosts are placed in maintenance mode with the Evacuate all data option, or vSAN hosts are placed in maintenance mode with Ensure data accessibility when objects assigned PFTT=0 reside on the host. To provide enough space for maintenance and reprotection, and to minimize automatic rebalancing of events in the vSAN cluster, consider keeping 30% capacity available always. \n Cluster utilization check Using vCenter, review each cluster and identify which clusters are at 50% or greater utilization for CPU and RAM. 50% is chosen as a warning level to focus attention on potential expansion of this cluster with additional hosts or clusters. The difference between 50% utilization and a maximum of 80 to 90%, is your room for additional VMs due to service requests. At the 50% limit, you should be looking at the near-future requests and forecasting when more resources need to be added. \n Cluster consolidation review Using vCenter, review each cluster and identify which clusters are at 30% or less utilization for CPU and RAM. 30% is chosen as a warning level to focus attention on potential right-sizing of this cluster by removing hosts or removing this cluster and moving VMs to another cluster. \n Right-size over-sized VMs Use a simple approach to right-size oversized VMs: identify, profile and tune, and monitor demand trends. Using vCenter identify large VMs that have the potential for right-sizing. Navigate to Monitor, Performance, and profile the average CPU and RAM demand profile of the workload over time and adjust the virtual resources. Finally, continue to monitor the workloads to see that the performance is acceptable.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsprocs-proactive"},{"document_id":"ibmcld_00189-6588-8692","score":21.0432344391,"text":"\nThe SQL Server Restore dialog shows the most recent safe set for the job.\n7. To restore data from an older safe set, or from SSI (safe set image) files, take one of the following steps.\n\n\n\n* To restore data from an older safe set, click the calendar. In the calendar that appears, click the date of the safe set from which you want to restore. To the right of the calendar, click the specific safe set that you want to use.\n* To restore data from SSI (safe set image) files on disk, select Directory on disk from the Source Device list. Click the folder. In the Select Folder dialog, select the directory where the files are located, and click Okay.\n\n\n\nSSI files are full backups that were exported from the vault or backed up from a computer to disk instead of to a vault. It can be quicker to save backup files on physical media and transport them to a location for a restore than to restore data from a vault in a remote data center. Note: You cannot restore from backups to disk (SSI files) until the safe set is imported into the vault and the IBM Cloud Backup for Classic Agent is synchronized with the vault.\n8. In the Database Selection, select the checkbox for each database that you want to restore.\n9. In the Encryption Password field, enter the data encryption password. To view the password hint, click Hint.\n10. Under Restore Destination, enter a path for the destination, or click the folder. In the Select Folder dialog box, select the location where you want to restore, and click Okay.\n11. To change the log detail level, bandwidth throttling setting, or hard recovery option, click Advanced Restore Options. In the dialog box, you can select the options:\n\n\n\n* In the Log Level Detail list, select the level of detail for job logging.\n* Select or clear the Use all available bandwidth option.\n\n\n\n12. Click Run Restore. The Process Details dialog shows the restore progress and indicates when the restore is completed. Other recent job processes might also be listed in the dialog. To close the Process Details screen, click Close. Closing the window does not affect the restore process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-restoreMSSQLDB"},{"document_id":"ibmcld_00189-1695-3780","score":21.0155291042,"text":"\nClick the Jobs tab.\n4. Find the job with the database that you want to restore. In the job\u2019s Select Action menu, click Restore.\n5. In the Choose how to restore dialog box, select Restore database to an SQL Server instance.\n6. In the Instance list, click the SQL Server instance where you want to restore the database.\n7. Connect to the instance by using one of the following methods.\n\n\n\n* To connect to the instance by using a Windows\u00ae administrator account, select Windows\u00ae authentication. Enter the username, password, and domain in the appropriate fields.\n* To connect to the instance by using an SQL Server administrator account, select SQL Server authentication. Enter the username and password in the appropriate fields.\n\n\n\n8. Click Continue. The SQL Server Restore dialog box shows the most recent safe set for the job.\n9. To restore data from an older safe set, or from SSI (safe set image) files, take one of the following steps.\n\n\n\n* To restore data from an older safe set, click the calendar. In the calendar that appears, click the date of the safe set from which you want to restore. To the right of the calendar, click the specific safe set that you want to use.\n* To restore data from SSI (safe set image) files on disk, select Directory on disk from the Source Device list. Click the folder. In the Select Folder dialog box, select the directory where the files are located, and click Okay.\n\n\n\nSSI files are full backups that were exported from the vault or backed up from a computer to disk instead of to a vault. It can be quicker to save backup files on physical media and transport them to a location for a restore than to restore data from a vault in a remote data center. Note: You cannot restore from backups to disk (SSI files) until the safe set is imported into the vault and the IBM Cloud\u00ae Backup for Classic Agent is synchronized with the vault.\n10. In the Database Selection box, select the checkbox for each database that you want to restore.\n11. In the Encryption Password field, enter the data encryption password. To view the password hint, click Hint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Backup?topic=Backup-restoreMSSQLDB"},{"document_id":"ibmcld_15508-6189-8159","score":21.0033092518,"text":"\nFor more information, see the topic on [User data](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-user-data).\n\nThe metadata that you access from within the instance is not protected by any encryption method. Any user with access to the instance and metadata service can potentially see the metadata. As a precaution, do not store sensitive data, such as passwords or customer encryption keys, as user data.\n\n\n\n\n\n\n\n\n\n Scenarios for using the metadata service \n\nYou can use the metadata service in two ways:\n\n\n\n* Access the metadata from within the instance.\n\nIn this scenario, you retrieve metadata from within the instance to bootstrap the instance. For example, you might want to specify custom user data when you create the instance and then, retrieve that custom user data when the instance is initialized. For more information, see [Accessing metadata from an instance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-imd-access-instance-metadata).\n* Access an instance identity IAM token and call IAM-enabled services.\n\nIn this scenario, you create a trusted profile for a compute resource identity and assign access rights for IAM-enabled services to a virtual server instance. Make a call to create a new instance, which is configured with the metadata service, then link the instance to the trusted profile. Call the metadata service to get an instance identity access token, then [generate an IAM token](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-imd-configure-service&interface=apiimd-token-exchange) from that token. You can then call IAM-enabled services from the instance. Use this option when you want to call IAM-enabled services as part of instance bootstrapping. For example, you might want to set up a new Object Storage bucket to be used by the instance workload. For more information, see [Using a trusted profile to call IAM-enabled services](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-imd-trusted-profile-metadata).\n\n\n\nFigure 1 illustrates these scenarios.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-imd-about"},{"document_id":"ibmcld_15918-37367-38469","score":20.9848483246,"text":"\nThe Snapshot for VPC service is integrated with the IBM Cloud\u00ae Security and Compliance Center to help you manage security and compliance for your organization. For snapshots, you can set up a goal that checks whether snapshots are encrypted by using customer-managed keys. By using the Security and Compliance Center to validate the snapshot resource configurations in your account against a profile, you can identify potential issues as they arise.\n\nBecause snapshots are created from Block Storage for VPC volumes, Block Storage for VPC goals provide an extra level of security. For more information, see [Monitoring security and compliance posture with VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-security-compliancemonitor-vpc). For more information about creating security and compliance goals, see [Defining rules](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-rules-define&interface=ui) in the Security and Compliance Documentation.\n\n\n\n\n\n Next steps \n\nYou can [Restore a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-manage"},{"document_id":"ibmcld_15921-37405-38507","score":20.9848483246,"text":"\nThe Snapshot for VPC service is integrated with the IBM Cloud\u00ae Security and Compliance Center to help you manage security and compliance for your organization. For snapshots, you can set up a goal that checks whether snapshots are encrypted by using customer-managed keys. By using the Security and Compliance Center to validate the snapshot resource configurations in your account against a profile, you can identify potential issues as they arise.\n\nBecause snapshots are created from Block Storage for VPC volumes, Block Storage for VPC goals provide an extra level of security. For more information, see [Monitoring security and compliance posture with VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-security-compliancemonitor-vpc). For more information about creating security and compliance goals, see [Defining rules](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-rules-define&interface=ui) in the Security and Compliance Documentation.\n\n\n\n\n\n Next steps \n\nYou can [Restore a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-manage&interface=cli"},{"document_id":"ibmcld_15922-37393-38495","score":20.9848483246,"text":"\nThe Snapshot for VPC service is integrated with the IBM Cloud\u00ae Security and Compliance Center to help you manage security and compliance for your organization. For snapshots, you can set up a goal that checks whether snapshots are encrypted by using customer-managed keys. By using the Security and Compliance Center to validate the snapshot resource configurations in your account against a profile, you can identify potential issues as they arise.\n\nBecause snapshots are created from Block Storage for VPC volumes, Block Storage for VPC goals provide an extra level of security. For more information, see [Monitoring security and compliance posture with VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-manage-security-compliancemonitor-vpc). For more information about creating security and compliance goals, see [Defining rules](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-rules-define&interface=ui) in the Security and Compliance Documentation.\n\n\n\n\n\n Next steps \n\nYou can [Restore a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-manage&interface=ui"},{"document_id":"ibmcld_15955-7-1985","score":20.7186440517,"text":"\nSetting up your Block Storage for VPC data volume for use (Windows) \n\nIf you want to use your IBM\u00ae Cloud Block Storage for Virtual Private Cloud volume as a file system, you need to partition the volume, format it, and then mount it as a file system. You can perform this operation after you created a Block Storage for VPC volume and attached it to an instance.\n\nFollow this procedure to use your block storage volume on a Windows\u00ae system.\n\n\n\n Setting up your volume for use with the Disk Management utility \n\n\n\n1. Log in to your Windows instance by using Remote Desktop. For more information, see [Connecting to Windows instances](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vsi_is_connecting_windows).\n2. Start the Disk Management utility. On the taskbar, open the menu by right-clicking the Windows logo, and choose Disk Management.\n\nIn Windows Server 2008, choose Start > Administrative Tools > Computer Management > Disk Management.\n3. The Disk Management window shows the attached storage volume as an unknown, offline disk. Bring the volume online. Right-click the left panel for the Block Storage for VPC volume. Choose Online.\n4. If the disk is not initialized, you must initialize it before you can use it. If the disk is already initialized, skip to the next step.\n\nIf you're mounting a volume that already has data on it, do not reformat the volume as that deletes the existing data. For example, if you restored the volume from a snapshot, the volume contains the data from the snapshot. Do not initialize the volume or you lose the data that you restored.\n\n\n\n1. Right-click the left panel for the disk, and choose Initialize Disk.\n2. In the Initialize Disk dialog box, select a partition style, and choose OK.\n\n\n\n5. Right-click the right panel for the disk, and choose New Simple Volume.\n6. In the New Simple Volume Wizard, choose Next.\n7. If you want to change the default maximum value, specify the size in MB in the Simple volume size field, and then choose Next.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-start-using-your-block-storage-data-volume-win"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09647-1993-2943","score":12.4128722395,"text":"\nThe list of eligible server applications includes Microsoft SQL Server database software, Microsoft Exchange Server, Microsoft SharePoint Server, Microsoft Skype for Business Server, Microsoft System Center servers, and Microsoft Dynamics 365 Server for Customer Service and Sales applications. (Note: For SQL Server customers with core-based licensing and Software Assurance coverage, broader benefits are available under [Azure Hybrid Benefit](https:\/\/azure.microsoft.com\/en-us\/pricing\/hybrid-benefit\/) rights. For more information, see Azure Hybrid Benefit. The steps described below do not apply to Azure Hybrid Benefit use.) The Windows Server operating system licenses remain assigned to customers\u2019 on-premises hardware with their applicable license terms. For additional information and a full list of eligible products, please refer to the [Microsoft Product Terms](https:\/\/www.microsoft.com\/en-us\/licensing\/product-licensing\/products?rtc=1).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/microsoft?topic=microsoft-microsoft-license-mobility"},{"document_id":"ibmcld_01777-3308-4291","score":12.2873007642,"text":"\nComplete the following steps to add information to your product's About page:\n\n\n\n1. Click Actions... > Edit product page.\n2. Add or edit the following information:\n\n\n\n* Click Description. Using common language, provide a unique description that includes the benefits and what your product can do for potential users. This description helps users understand why and how they can use your product.\n* Click Features. Showcase your product\u2019s attributes that deliver value and differentiate it in the market. You want the information to be visually scannable by providing a descriptive title and one or two sentences for each feature.\n* Click Media. Add links to high-quality images or videos that show off your product. For example, provide an introductory walkthrough video or an illustration that shows user benefits or differences between certain features. The supported options are images, videos in MP4 or WebM file format, and videos hosted on YouTube or Vimeo.\n\n\n\n3. Click Update.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-cm-catalog-details"},{"document_id":"ibmcld_01447-1492-3786","score":12.0703882631,"text":"\nVulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nReview the following table to find an overview of benefits of using Container Registry.\n\n\n\nTable 1. Container Registry benefits\n\n Benefit Description \n\n Highly available and scalable private registry. Set up your own image namespace in a multi-tenant, highly available, scalable, encrypted private registry that is hosted and managed by IBM.<br><br>Store your private Docker images and share them with users in your IBM Cloud account. \n Image security compliance with Vulnerability Advisor. Benefit from automatic scanning of images in your namespace.<br><br>Review recommendations that are specific to the operating system to fix potential vulnerabilities and protect your containers from being compromised. \n Quota limits for storage and pull traffic. Benefit from free storage and pull traffic to your private images until you reach your free quota.<br><br>Set custom quota limits for the amount of storage and pull traffic per month to avoid exceeding your preferred payment level. \n\n\n\n\n\n Service plans \n\nYou can choose between the free or standard Container Registry service plans to store your Docker images and make these images available to users in your IBM Cloud account.\n\nThe IBM Cloud Container Registry service plan determines the amount of storage and pull traffic that you can use for your private images. The service plan is associated with your IBM Cloud account, and limits for storage and image pull traffic apply to all namespaces that you set up in your account.\n\nService plans are scoped to the specific registry instance (one of the regional registries or the global registry) that you're currently working with. Plan settings must all be managed separately for your account in each registry instance. For more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\nThe following table shows available IBM Cloud Container Registry service plans and their characteristics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"},{"document_id":"ibmcld_01447-7-2032","score":12.0181366485,"text":"\nAbout Container Registry \n\nUse IBM Cloud\u00ae Container Registry to store and access private container images in a highly available and scalable architecture.\n\nIBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image\n\nregistrythat is hosted and managed by IBM. You can use Container Registry by setting up your own imagenamespaceand pushing container images to your namespace.\n\nZoom\n\n![Diagram showing how you can interact with IBM Cloud Container Registry.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/images\/about_container_registry_v2.svg)\n\nFigure 1. How Container Registry interacts with your images\n\nA Docker image is the basis for every container that you create. An image is created from a\n\nDockerfile, which is a file that contains instructions to build the image. A Dockerfile might reference build artifacts in its instructions that are stored separately, such as an app, the configuration of the app, and its dependencies. Images are typically stored in a registry that can either be accessible by the public (public registry) or set up with limited access for a small group of users (private registry). By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nReview the following table to find an overview of benefits of using Container Registry.\n\n\n\nTable 1. Container Registry benefits\n\n Benefit Description \n\n Highly available and scalable private registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"},{"document_id":"ibmcld_09647-7-2622","score":11.5632363926,"text":"\nLicensed Mobility through Microsoft Software Assurance Overview \n\n\n\n Overview \n\nOrganizations around the world are benefitting from the power, flexibility, and efficiency of cloud computing. Whether you want to deploy server applications in a traditional customer on- premises environment, through a partner or a Microsoft cloud-hosted model, or a combination of all three, Microsoft gives you the flexibility to choose what is right for you, on your terms and on your schedule.\n\n\n\n\n\n License mobility through Microsoft Software Assurance \n\nWith more businesses adopting Infrastructure as a Service (IaaS), customers moving server workloads and applications to the cloud want to take advantage of their existing licensing investments as part of their IT strategy.\n\nLicense Mobility through Microsoft Software Assurance gives Microsoft Volume Licensing customers the flexibility to deploy certain server applications with active Software Assurance on-premises or in the cloud, without having to buy additional licenses. As a result, customers can take advantage of the lowest and flexible cost infrastructure for changing business priorities. Because of this new Software Assurance benefit, customers do not need to purchase new Microsoft Client Access Licenses (CALs), and no associated mobility fees exist.\n\n\n\n\n\n Products eligible for License mobility through Software Assurance \n\nFor specific Microsoft server products, [License Mobility through Software Assurance](https:\/\/www.microsoft.com\/en-us\/licensing\/licensing-programs\/software-assurance-license-mobility?rtc=1tab=3) gives customers enhanced flexibility. A customer can assign their application server licenses with active Software Assurance to run server instances on shared hardware via Microsoft Azure or a License Mobility through Software Assurance Partner\u2019s data center. Although sharing hardware, such server instances (virtual machines) must be dedicated to a single customer and are not shared with other customers.\n\nThe list of eligible server applications includes Microsoft SQL Server database software, Microsoft Exchange Server, Microsoft SharePoint Server, Microsoft Skype for Business Server, Microsoft System Center servers, and Microsoft Dynamics 365 Server for Customer Service and Sales applications. (Note: For SQL Server customers with core-based licensing and Software Assurance coverage, broader benefits are available under [Azure Hybrid Benefit](https:\/\/azure.microsoft.com\/en-us\/pricing\/hybrid-benefit\/) rights. For more information, see Azure Hybrid Benefit. The steps described below do not apply to Azure Hybrid Benefit use.)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/microsoft?topic=microsoft-microsoft-license-mobility"},{"document_id":"ibmcld_06459-1498-2185","score":11.5510519093,"text":"\nLarger disks have higher performance with baseline input\/output operations per second (IOPS) of 10 IOPS for each GB. etcd relies on writing data to disk to maintain its consensus algorithm, so exceeding your IOPS deployment's limits can cause cluster instability. Scaling your deployment's disk resources increases the IOPS available to your deployment.\n\n\n\n\n\n Memory Usage \n\netcd uses memory to cache data and can benefit from increasing the amount of memory to at least the size of the data set. Memory is also used to maintain the watchers, so if your use-case requires thousands of watchers, you can benefit from increasing the amount of RAM available to your deployment ever further.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-performance"},{"document_id":"ibmcld_05727-8804-11229","score":11.3910562871,"text":"\n* Shipping customers have real-time access to shipments\u2019 locations, delivery schedules, and even approved port records.\n* Transit partners at various shipping terminals are aware of manifests and shipment details so that onsite logistics are improved, instead of delayed.\n\n\n\n\n\n\n\n\n\n Airline delivers innovative Human Resources (HR) benefits site in under 3 weeks \n\nAn HR Exec (CHRO) needs a new HR benefits site with an innovative chatbot, but current Development tools and platform mean long lead times for apps to go live. This situation includes long waits for hardware procurement.\n\nIBM Cloud Kubernetes Service provides easy spin-up of compute. Then, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains. Their traditional software development tools get a boost when they add on IBM Watson Assistant. The new benefits site was created in less than 3 weeks.\n\n\n\n Context \n\nRapidly building and deploying innovative HR benefits site in less than 3 weeks.\n\n\n\n* Employee growth and changing HR policies meant that a whole new site would be required for annual enrollment.\n* Interactive features, such as a chatbot, were expected to help communicate new HR policies to existing employees.\n* Due to growth in number employees, the site traffic is increasing, but their infrastructure budget remains flat.\n* The HR team faced pressure to move faster: roll out new site features quickly and post last-minute benefit changes frequently.\n* The enrollment period lasts for two weeks, and so downtime for the new app isn't tolerated.\n\n\n\n\n\n\n\n Solution \n\nThe airline wants to design an open culture that puts people first. The HR Executive is well aware that a focus on rewarding and retaining talent impacts the airline\u2019s profitability. Thus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* IBM Cloud Kubernetes Service","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_uc_transport"},{"document_id":"ibmcld_10170-8677-11078","score":11.3456036321,"text":"\n* Microservices greatly reduce time to delivery for patches, bug fixes, and new features. Initial development is fast, and updates are frequent.\n* Shipping customers have real-time access to shipments\u2019 locations, delivery schedules, and even approved port records.\n* Transit partners at various shipping terminals are aware of manifests and shipment details so that onsite logistics are improved, instead of delayed.\n\n\n\n\n\n\n\n\n\n Airline delivers innovative Human Resources (HR) benefits site in under 3 weeks \n\nAn HR Exec (CHRO) needs a new HR benefits site with an innovative chatbot, but current Development tools and platform mean long lead times for apps to go live. This situation includes long waits for hardware procurement.\n\nRed Hat OpenShift on IBM Cloud provides easy spin-up of compute. Then, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains. Their traditional software development tools get a boost when they add on IBM Watson Assistant. The new benefits site was created in less than 3 weeks.\n\n\n\n Context \n\nRapidly building and deploying innovative HR benefits site in less than 3 weeks.\n\n\n\n* Employee growth and changing HR policies meant that a whole new site would be required for annual enrollment.\n* Interactive features, such as a chatbot, were expected to help communicate new HR policies to existing employees.\n* Due to growth in number employees, the site traffic is increasing, but their infrastructure budget remains flat.\n* The HR team faced pressure to move faster: roll out new site features quickly and post last-minute benefit changes frequently.\n* The enrollment period lasts for two weeks, and so downtime for the new app isn't tolerated.\n\n\n\n\n\n\n\n Solution \n\nThe airline wants to design an open culture that puts people first. The HR Executive is well aware that a focus on rewarding and retaining talent impacts the airline\u2019s profitability. Thus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_07578-565403-567284","score":11.3261230631,"text":"\nFor more information, see the [End of Service announcement](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-resellone-eos).\n* What are the benefits of migrating to Hover?\n\n What are the benefits of migrating to Hover? \n\nAs a Hover customer, you\u2019ll benefit from a clean and intuitive domain management control panel. You'll also get an expanded selection of premium top-level domains, and great customer support.\n* What are the benefits of migrating to OpenSRS?\n\n What are the benefits of migrating to OpenSRS? \n\nAs a direct OpenSRS reseller, you\u2019ll be able to fully manage your domains with greater ease. You'll get a greater selection of premium top-level domains and be able to offer your customers an expanded selection to automate your domain management experience. Post migration, you\u2019ll benefit from improved availability of your business-critical domain services and additional features, including:\n\n\n\n* Brandable end-user communications\n* Scalability\n* Exceptional reliability\n* Flexible integration\n\n\n\n* What service agreement do I follow after migration to Hover?\n\n What service agreement do I follow after migration to Hover? \n\nAfter migration, you are automatically transitioned to Tucows\u2019 retail domains brand Hover's [Terms Of Service](https:\/\/www.hover.com\/tos).\n* What service agreement do I follow after migration to a Tucows OpenSRS Reseller account?\n\n What service agreement do I follow after migration to a Tucows OpenSRS Reseller account? \n\nAfter migration, you are automatically transitioned to the OpenSRS\/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https:\/\/opensrs.com\/wp-content\/uploads\/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https:\/\/opensrs.com\/resources\/documentation\/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-565357-567238","score":11.3261230631,"text":"\nFor more information, see the [End of Service announcement](https:\/\/cloud.ibm.com\/docs\/dns?topic=dns-resellone-eos).\n* What are the benefits of migrating to Hover?\n\n What are the benefits of migrating to Hover? \n\nAs a Hover customer, you\u2019ll benefit from a clean and intuitive domain management control panel. You'll also get an expanded selection of premium top-level domains, and great customer support.\n* What are the benefits of migrating to OpenSRS?\n\n What are the benefits of migrating to OpenSRS? \n\nAs a direct OpenSRS reseller, you\u2019ll be able to fully manage your domains with greater ease. You'll get a greater selection of premium top-level domains and be able to offer your customers an expanded selection to automate your domain management experience. Post migration, you\u2019ll benefit from improved availability of your business-critical domain services and additional features, including:\n\n\n\n* Brandable end-user communications\n* Scalability\n* Exceptional reliability\n* Flexible integration\n\n\n\n* What service agreement do I follow after migration to Hover?\n\n What service agreement do I follow after migration to Hover? \n\nAfter migration, you are automatically transitioned to Tucows\u2019 retail domains brand Hover's [Terms Of Service](https:\/\/www.hover.com\/tos).\n* What service agreement do I follow after migration to a Tucows OpenSRS Reseller account?\n\n What service agreement do I follow after migration to a Tucows OpenSRS Reseller account? \n\nAfter migration, you are automatically transitioned to the OpenSRS\/Tucows\u2019 Inc. Master Services Agreement. You can find this from the [OpenSRS website](https:\/\/opensrs.com\/wp-content\/uploads\/Master_Services_Agreement.html).\n\nAdditional resources can be found in [OpenSRS Documentation](https:\/\/opensrs.com\/resources\/documentation\/).\n* If I have more questions, who can I contact?\n\n If I have more questions, who can I contact?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03113-4-2033","score":14.9099357573,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the \/dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the \/dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03270-3352-5135","score":14.5510070599,"text":"\nAdd a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\nFor more information about different service desk solutions, see the following resources:\n\n\n\n* [Adding service desk support to the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-support"},{"document_id":"ibmcld_02882-27313-29495","score":14.5297189556,"text":"\nThis response type only returns a valid response if the assistant to which you added this dialog skill also has a search skill associated with it.\n\n\n\n2. Click Add response to add another response type to the current response.\n\nYou might want to add multiple response types to a single response to provide a richer answer to a user query. For example, if a user asks for store locations, you could show a map and display a button for each store location that the user can click to get address details. To build that type of response, you can use a combination of image, options, and text response types. Another example is using a text response type before a pause response type so you can warn users before pausing the dialog.\n\nYou cannot add more than 5 response types to a single response. Meaning, if you define three conditional responses for a dialog node, each conditional response can have no more than 5 response types added to it.\n\nA single dialog node cannot have more than one Connect to human agent or more than one Search skill response.\n3. If you added more than one response type, you can click the Move up or down arrows to arrange the response types in the order you want your assistant to process them.\n\n\n\n\n\n\n\n\n\n Conditional responses \n\nA single dialog node can provide different responses, each one triggered by a different condition. Use this approach to address multiple scenarios in a single node.\n\nThe node still has a main condition, which is the condition for using the node and processing the conditions and responses that it contains.\n\nIn this example, your assistant uses information that it collected earlier about the user's location to tailor its response, and provide information about the store nearest the user. See [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables) for more information about how to store information collected from the user.\n\n![Shows a node that shows a user ask, Where are you located, and the dialog has three different responses depending on conditions that use info from the $state context variable to specify locations in those states.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_03188-1732-3801","score":14.4207797092,"text":"\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.\n* To add slightly different responses for a single dialog node based on the integration type, complete the following steps:\n\n\n\n* From the node's edit view, click Customize and then set the Multiple conditioned responses switch to On. Click Apply.\n* In the dialog node response section, add the appropriate condition and corresponding response for each custom response type.\n\n\n\nThe following examples show how to specify a hypertext link in the best format for the integration where the text response will be displayed. For the Web chat integration, which supports Markdown formatting, you can include a link label in the response text to make the response look nicer. For the SMS with Twilio integration, you can skip the formatting that makes sense in a web page, and add the straight URL.\n\n\n\nCustom conditioned responses\n\n Integration type Condition Sample text response \n\n SMS with Twilio `$integrations.text_messaging` `For more information, go to https:\/\/www.ibm.com.` \n Web chat `$integrations.chat` `For more information, go to [the ibm.com site](https:\/\/www.ibm.com).` \n Response to show if no other conditions are met. `true` `For more information, go to ibm.com.` \n\n\n\n\n\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"},{"document_id":"ibmcld_03113-4996-6502","score":14.3831447519,"text":"\n[UI location where the code that is triggered by named event handlers is authored](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/api-event-handlers.png)\n* A node of type event_handler with an event_name of generic can have a parent of type slot or frame.\n* A node of type event_handler with an event_name of focus, input, filled, or nomatch must have a parent of type slot.\n* If more than one event_handler with the same event_name is associated with the same parent node, then the order of the siblings reflects the order in which the event handlers will be executed.\n* For event_handler nodes with the same parent slot node, the order of execution is the same regardless of the placement of the node definitions. The events are triggered in this order by event_name:\n\n\n\n1. focus\n2. input\n3. filled\n4. generic*\n5. nomatch\n\n\n\n*If an event_handler with the event_name generic is defined for this slot or for the parent frame, then it is executed between the filled and nomatch event_handler nodes.\n\n\n\nThe following examples show how various modifications might cause cascading changes.\n\n\n\n Creating a node \n\nConsider the following simple dialog tree:\n\n![Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02952-3289-5462","score":14.3122240722,"text":"\nAdd meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\n\n\n\n\n Measuring containment \n\nFrom the Analytics page, you can measure conversation containment. Containment is the rate at which your assistant is able to satisfy a customer's request without human intervention per conversation.\n\nTo measure containment accurately, the metric must be able to identify when a human intervention occurs. The metric primarily uses the Connect to human agent response type as an indicator. If a user conversation log includes a call to a Connect to human agent response type, then the conversation is considered to be not contained.\n\nHowever, not all human interventions are transacted by using a Connect to human agent response type. If you use an alternate method to deliver additional support, you must take additional steps to register the fact that the customer's need was not fulfilled by the assistant. For example, you might direct customers to your call center phone number or to an online support ticket form URL.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03113-6206-7586","score":14.1838202977,"text":"\n[Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n![Example dialog 2](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_2.png)\n\nBecause node_8 was created without specifying a value for parent or previous_sibling, it is now the first node in the dialog. Note that in addition to creating node_8, the service also modified node_1 so that its previous_sibling property points to the new node.\n\nYou can create a node somewhere else in the dialog by specifying the parent and previous sibling:\n\n{\n\"dialog_node\": \"node_9\",\n\"parent\": \"node_2\",\n\"previous_sibling\": \"node_5\"\n}\n\nThe values you specify for parent and previous_node must be valid:\n\n\n\n* Both values must refer to existing nodes.\n* The specified parent must be the same as the parent of the previous sibling (or null, if the previous sibling has no parent).\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_3.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02952-1632-3754","score":14.1533231303,"text":"\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03054-27011-29125","score":14.1416165616,"text":"\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition with a search skill response type.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:\n\nintents[0].confidence > 0.5\n\nThis condition is applied to all of the nodes in the folder. The condition tells your assistant to process the nodes in the folder only if your assistant is at least 50% confident that it knows the user's intent.\n3. Move any dialog nodes that you do not want your assistant to process often into the folder.\n\n\n\nAfter changing the dialog, test the assistant to make sure the search skill is triggered as often as you want it to be.\n\nAn alternative approach is to teach the dialog about topics to ignore. To do so, you can add utterances that you want the assistant to send to the search skill immediately as test utterances in the dialog skill's Try it out pane. You can then select the Mark as irrevlant option within the Try it out pane to teach the dialog not to respond to this utterance or others like it.\n\n\n\n\n\n Disabling search \n\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03054-22692-24767","score":14.101578093,"text":"\n* Search response type: If you add a search skill response type to a dialog node, then your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed.\n\nThis approach is useful if you want to narrow down a user query before you trigger a search. For example, the dialog branch might collect information about the type of device the customer wants to buy. When you know the make and model, you can then send a model keyword in the query that is submitted to the search skill, and get better results.\n* Search skill only: If only a search skill is linked to an assistant, and no dialog skill is linked to the assistant, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Try it out pane of the search skill.\n\nYou cannot test the full end-to-end user experience from the dialog skill's Try it out pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its Try it out pane.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, you must test it by using the API.\n\n\n\n1. From the IBM Cloud Pak for Data web client, go to the details page for the provisioned instance.\n2. Copy the URL from the \"Access information\" section of the page. You will specify this value as the {url}.\n3. Copy the bearer token also. You will need to pass the token when you make an API call.\n4. From the dialog builder in the user interface, add a search skill response type to a dialog node.\n5. Make a note of the unique ID of the assistant to which you added the dialog that you edited in the previous step.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1934264036}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03334-12430-14290","score":20.7149448491,"text":"\nIf the top intent has a low confidence score (less than 0.2), the top intent is included in the intents array that is returned by the API, but any nodes that condition on the intent are not triggered. If you want to detect the case when no intents with good confidence scores were detected, use the irrelevant special condition in your dialog node. See [Special conditions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-special-conditions) for more information.\n\nAs intent confidence scores change, your dialogs might need restructuring. For example, if a dialog node uses an intent in its condition, and the intent's confidence score starts to consistently drop below 0.2, the dialog node stops being processed. If the confidence score changes, the behavior of the dialog can also change.\n\n\n\n\n\n Intent limits \n\nThe number of intents and examples you can create depends on your Watson Assistant plan type:\n\n\n\nPlan details\n\n Plan Intents per skill Examples per skill \n\n Enterprise 2,000 25,000 \n Premium (legacy) 2,000 25,000 \n Plus 2,000 25,000 \n Lite, Trial 100 25,000 \n\n\n\n\n\n\n\n Editing intents \n\nYou can click any intent in the list to open it for editing. You can make the following changes:\n\n\n\n* Rename the intent.\n* Delete the intent.\n* Add, edit, or delete examples.\n* Move an example to a different intent.\n\n\n\nYou can tab from the intent name to each example.\n\n\n\n1. To move or delete an example, click the checkbox that is associated with it, and then click Move or Delete.\n\n![Screen capture showing how to move or delete an example](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/move_example.png)\n\n\n\n\n\n\n\n Searching intents \n\nUse the Search feature to find user examples, intent names, and descriptions.\n\n\n\n1. From the Intents page, click the Search icon.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"},{"document_id":"ibmcld_03405-4-2057","score":20.6105376796,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding a node with slots to a dialog \n\nIn this tutorial, you will add slots to a dialog node to collect multiple pieces of information from a user within a single node. The node you create will collect the information that is needed to make a restaurant reservation.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Define the intents and entities that are needed by your dialog\n* Add slots to a dialog node\n* Test the node with slots\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 30 minutes to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-started). You will use the Watson Assistant tutorial skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\nYou can also start with a new dialog skill if you want. Just be sure to create the skill before you begin this tutorial.\n\n\n\n\n\n\n\n Step 1: Add intents and examples \n\nAdd an intent on the Intents tab. An intent is the purpose or goal that is expressed in user input. You will add a #reservation intent that recognizes user input that indicates that the user wants to make a restaurant reservation.\n\n\n\n1. From the Intents page of the tutorial skill, click Add intent.\n2. Add the following intent name, and then click Create intent:\n\nreservation\n\nThe #reservation intent is added. A number sign () is prepended to the intent name to label it as an intent. This naming convention helps you and others recognize the intent as an intent. It has no example user utterances associated with it yet.\n3. In the Add user examples field, type the following utterance, and then click Add example:\n\ni'd like to make a reservation\n4. Add these additional examples to help Watson recognize the reservation intent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots"},{"document_id":"ibmcld_03071-7-2056","score":20.6004776316,"text":"\nTutorial: Adding a node with slots to a dialog \n\nIn this tutorial, you will add slots to a dialog node to collect multiple pieces of information from a user within a single node. The node you create will collect the information that is needed to make a restaurant reservation.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Define the intents and entities that are needed by your dialog\n* Add slots to a dialog node\n* Test the node with slots\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 30 minutes to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started). You will use the Watson Assistant tutorial skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\nYou can also start with a new dialog skill if you want. Just be sure to create the skill before you begin this tutorial.\n\n\n\n\n\n\n\n Step 1: Add intents and examples \n\nAdd an intent on the Intents tab. An intent is the purpose or goal that is expressed in user input. You will add a #reservation intent that recognizes user input that indicates that the user wants to make a restaurant reservation.\n\n\n\n1. From the Intents page of the tutorial skill, click Add intent.\n2. Add the following intent name, and then click Create intent:\n\nreservation\n\nThe #reservation intent is added. A number sign () is prepended to the intent name to label it as an intent. This naming convention helps you and others recognize the intent as an intent. It has no example user utterances associated with it yet.\n3. In the Add user examples field, type the following utterance, and then click Add example:\n\ni'd like to make a reservation\n4. Add these additional examples to help Watson recognize the reservation intent.\n\nI want to reserve a table for dinner\nCan 3 of us get a table for lunch?\ndo you have openings for next Wednesday at 7?\nIs there availability for 4 on Tuesday night?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots"},{"document_id":"ibmcld_03010-11212-12967","score":20.3917724725,"text":"\nIf the top intent has a low confidence score (less than 0.2), the top intent is included in the intents array that is returned by the API, but any nodes that condition on the intent are not triggered. If you want to detect the case when no intents with good confidence scores were detected, use the irrelevant special condition in your dialog node. See [Special conditions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-special-conditions) for more information.\n\nAs intent confidence scores change, your dialogs might need restructuring. For example, if a dialog node uses an intent in its condition, and the intent's confidence score starts to consistently drop below 0.2, the dialog node stops being processed. If the confidence score changes, the behavior of the dialog can also change.\n\n\n\n\n\n Intent limits \n\n\n\nLimit details\n\n Intents per skill Examples per skill \n\n 2,000 25,000 \n\n\n\n\n\n\n\n Editing intents \n\nYou can click any intent in the list to open it for editing. You can make the following changes:\n\n\n\n* Rename the intent.\n* Delete the intent.\n* Add, edit, or delete examples.\n* Move an example to a different intent.\n\n\n\nYou can tab from the intent name to each example.\n\n\n\n1. To move or delete an example, click the checkbox that is associated with it, and then click Move or Delete.\n\n![Screen capture showing how to move or delete an example](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/move_example.png)\n\n\n\n\n\n\n\n Searching intents \n\nThe search capability was introduced with the 1.5.0 release.\n\nUse the Search feature to find user examples, intent names, and descriptions.\n\n\n\n1. From the Intents page header, click the Search icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents"},{"document_id":"ibmcld_02952-7-2097","score":20.3645692838,"text":"\nConnecting customers with support \n\nNo matter where you deploy your assistant, give your customers a way to get additional support when they need it.\n\nBuild your dialog to recognize when customers need help that cannot be provided by the assistant. Add logic that can connect your customers to whatever type of professional support you offer. Your solutions might include:\n\n\n\n* A toll-free phone number to a call center that is manned by human agents\n* An online support ticket form that customers fill out and submit\n* A service desk solution that is configured to work with your custom client application. The built-in Zendesk and Salesforce integrations aren\u2019t supported.\n\n\n\nDesign your dialog to recognize customer requests for help and address them. Add an intent that understands the customer request, and then add a dialog branch that handles the request.\n\nYou might add an intent and use it in a dialog node like these example intents:\n\n\n\nAlternative support request intent examples\n\n Intent name Intent user example 1 Intent user example 2 Response from dialog node that conditions on intent \n\n call_support How do I reach support? What's your toll-free number? Call 1-800-555-0123 to reach a call center agent at any time. \n support_ticket How do I get help? Who can help me with an issue I'm having? Go to [Support Center](https:\/\/example.com\/support) and open a support ticket. \n\n\n\n\n\n Adding chat transfer support \n\nDesign your dialog so that it can transfer customers to human agents. Consider adding support for initiating a transfer in the following scenarios:\n\n\n\n* Any time a user asks to speak to a person.\n\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03270-4-2215","score":20.1190689968,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Connecting customers with support \n\nNo matter where you deploy your assistant, give your customers a way to get additional support when they need it.\n\nBuild your dialog to recognize when customers need help that cannot be provided by the assistant. Add logic that can connect your customers to whatever type of professional support you offer. Your solutions might include:\n\n\n\n* A toll-free phone number to a call center that is manned by human agents\n* An online support ticket form that customers fill out and submit\n* An integration with Intercom\n* A service desk solution that is configured to work with your web chat integration or a custom client application\n\n\n\nDesign your dialog to recognize customer requests for help and address them. Add an intent that understands the customer request, and then add a dialog branch that handles the request.\n\nFor example, you might add an intent and use it in a dialog node like the intents that are shown in the table below.\n\n\n\nAlternative support request intent examples\n\n Intent name Intent user example 1 Intent user example 2 Response from dialog node that conditions on intent \n\n call_support How do I reach support? What's your toll-free number? Call 1-800-555-0123 to reach a call center agent at any time. \n support_ticket How do I get help? Who can help me with an issue I'm having? Go to [Support Center](https:\/\/example.com\/support) and open a support ticket. \n\n\n\nIf you deploy your assistant with an integration that has built-in service desk support, you can use the special Connect to human agent response type in your dialog response to initiate a transfer.\n\n\n\n Adding chat transfer support \n\nDesign your dialog so that it can transfer customers to human agents. Consider adding support for initiating a transfer in the following scenarios:\n\n\n\n* Any time a user asks to speak to a person.\n\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-support"},{"document_id":"ibmcld_03373-2953-4766","score":19.9417288874,"text":"\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\n![Diagram of a simple exchange between a customer and an actions skill step.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/action-skill-explained.png)\n\n\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. The name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.\n* [Dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-build): A dialog is a branching conversation flow that defines how your application responds when it recognizes the defined intents and entities. You use the dialog editor to create conversations with users, providing responses based on the intents and entities that you recognize in their input.\n\n![Diagram of a basic implementation that uses intent and dialog only.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_02952-1632-3754","score":19.9375889544,"text":"\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03403-10956-12338","score":19.9267766529,"text":"\nAdd a yes intent \n\nBefore you perform an action on the user's behalf, you must get confirmation that you are taking the proper action. Add a #yes intent to the dialog that can recognize when a user agrees with what your assistant is proposing.\n\n\n\n1. Click the Intents tab.\n2. Click Create intent.\n3. Enter yes in the Intent name field, and then click Create intent.\n4. Add the following user examples:\n\nYes\nCorrect\nPlease do.\nYou've got it right.\nPlease do that.\nthat is correct.\nThat's right\nyeah\nYup\nYes, I'd like to go ahead with that.\n\n![Shows that the #yes intent was added.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-ass-yes-intent-added.png)\n5. Click the Close![Close arrow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/close_arrow.png) icon to finish adding the yes intent.\n\n\n\n\n\n\n\n Add dialog nodes that can manage requests to cancel an order \n\nNow, add a dialog node that can handle requests to cancel a cake order.\n\n\n\n1. Click the Dialog tab.\n2. Find the menu node. Click the More![More options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the menu node, and then select Add node below.\n3. Start to type cancel_order into the If assistant recognizes field of this node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial"},{"document_id":"ibmcld_03069-7-2188","score":19.900510751,"text":"\nTutorial: Building a complex dialog \n\nIn this tutorial, you will use the Watson Assistant service to create a dialog for an assistant that helps users with inquiries about a fictitious restaurant called Truck Stop Gourmand.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Plan a dialog\n* Define custom intents\n* Add dialog nodes that can handle your intents\n* Add entities to make your responses more specific\n* Add a pattern entity, and use it in the dialog to find patterns in user input\n* Set and reference context variables\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 2 to 3 hours to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started).\n\nYou will use the dialog skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\n\n\n\n\n\n\n Step 1: Plan the dialog \n\nYou are building an assistant for a restaurant named Truck Stop Gourmand that has one location and a thriving cake-baking business. You want the simple assistant to answer user questions about the restaurant, its menu, and to cancel customer cake orders. Therefore, you need to create intents that handle inquiries related to the following subjects:\n\n\n\n* Restaurant information\n* Menu details\n* Order cancellations\n\n\n\nYou'll start by creating intents that represent these subjects, and then build a dialog that responds to user questions about them.\n\n\n\n\n\n Step 2: Answer questions about the restaurant \n\nAdd an intent that recognizes when customers ask for details about the restaurant itself. An intent is the purpose or goal expressed in user input. The General_About_You intent that is provided with the General content catalog serves a similar function, but its user examples are designed to focus on queries about the assistant as opposed to the business that is using the assistant to help its customers. So, you will add your own intent.\n\n\n\n Add the about_restaurant intent \n\n\n\n1. From the Intents tab, click Create intent.\n\n![Shows the the Create intent button on the Intents page.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03405-4-2057","score":8.1690299805,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding a node with slots to a dialog \n\nIn this tutorial, you will add slots to a dialog node to collect multiple pieces of information from a user within a single node. The node you create will collect the information that is needed to make a restaurant reservation.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Define the intents and entities that are needed by your dialog\n* Add slots to a dialog node\n* Test the node with slots\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 30 minutes to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-started). You will use the Watson Assistant tutorial skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\nYou can also start with a new dialog skill if you want. Just be sure to create the skill before you begin this tutorial.\n\n\n\n\n\n\n\n Step 1: Add intents and examples \n\nAdd an intent on the Intents tab. An intent is the purpose or goal that is expressed in user input. You will add a #reservation intent that recognizes user input that indicates that the user wants to make a restaurant reservation.\n\n\n\n1. From the Intents page of the tutorial skill, click Add intent.\n2. Add the following intent name, and then click Create intent:\n\nreservation\n\nThe #reservation intent is added. A number sign () is prepended to the intent name to label it as an intent. This naming convention helps you and others recognize the intent as an intent. It has no example user utterances associated with it yet.\n3. In the Add user examples field, type the following utterance, and then click Add example:\n\ni'd like to make a reservation\n4. Add these additional examples to help Watson recognize the reservation intent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots"},{"document_id":"ibmcld_03071-7-2056","score":8.1645130108,"text":"\nTutorial: Adding a node with slots to a dialog \n\nIn this tutorial, you will add slots to a dialog node to collect multiple pieces of information from a user within a single node. The node you create will collect the information that is needed to make a restaurant reservation.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Define the intents and entities that are needed by your dialog\n* Add slots to a dialog node\n* Test the node with slots\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 30 minutes to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started). You will use the Watson Assistant tutorial skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\nYou can also start with a new dialog skill if you want. Just be sure to create the skill before you begin this tutorial.\n\n\n\n\n\n\n\n Step 1: Add intents and examples \n\nAdd an intent on the Intents tab. An intent is the purpose or goal that is expressed in user input. You will add a #reservation intent that recognizes user input that indicates that the user wants to make a restaurant reservation.\n\n\n\n1. From the Intents page of the tutorial skill, click Add intent.\n2. Add the following intent name, and then click Create intent:\n\nreservation\n\nThe #reservation intent is added. A number sign () is prepended to the intent name to label it as an intent. This naming convention helps you and others recognize the intent as an intent. It has no example user utterances associated with it yet.\n3. In the Add user examples field, type the following utterance, and then click Add example:\n\ni'd like to make a reservation\n4. Add these additional examples to help Watson recognize the reservation intent.\n\nI want to reserve a table for dinner\nCan 3 of us get a table for lunch?\ndo you have openings for next Wednesday at 7?\nIs there availability for 4 on Tuesday night?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots"},{"document_id":"ibmcld_02844-1555-3643","score":8.0771594474,"text":"\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-audit-events"},{"document_id":"ibmcld_02952-1632-3754","score":7.9923097481,"text":"\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_02998-3401-4882","score":7.9735141024,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-add-content-catalog.png)\n3. Open the Intents tab to review the intents and associated example utterances that were added to your training data. You can recognize them because each intent name begins with the prefix General_. You will add the General_Greetings and General_Ending intents to your dialog in the next step.\n\n![Shows the intents that are displayed in the Intents tab after the General catalog is added.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-general-content-added.png)\n\n\n\nYou successfully started to build your training data by adding prebuilt content from IBM.\n\n\n\n\n\n Step 5: Build a dialog \n\nA dialog defines the flow of your conversation in the form of a logic tree. It matches intents (what users say) to responses (what the bot says back). Each node of the tree has a condition that triggers it, based on user input.\n\nWe'll create a simple dialog that handles greeting and ending intents, each with a single node.\n\n\n\n Adding a start node \n\n\n\n1. From the Skills menu, click Dialog.\n2. Two nodes were added to the dialog for you:\n\n\n\n* Welcome: Contains a greeting that is displayed to your users when they first engage with the assistant.\n* Anything else: Contains phrases that are used to reply to users when their input is not addressed by any of the existing dialog nodes.\n\n\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03069-7-2188","score":7.9575654345,"text":"\nTutorial: Building a complex dialog \n\nIn this tutorial, you will use the Watson Assistant service to create a dialog for an assistant that helps users with inquiries about a fictitious restaurant called Truck Stop Gourmand.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Plan a dialog\n* Define custom intents\n* Add dialog nodes that can handle your intents\n* Add entities to make your responses more specific\n* Add a pattern entity, and use it in the dialog to find patterns in user input\n* Set and reference context variables\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 2 to 3 hours to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started).\n\nYou will use the dialog skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\n\n\n\n\n\n\n Step 1: Plan the dialog \n\nYou are building an assistant for a restaurant named Truck Stop Gourmand that has one location and a thriving cake-baking business. You want the simple assistant to answer user questions about the restaurant, its menu, and to cancel customer cake orders. Therefore, you need to create intents that handle inquiries related to the following subjects:\n\n\n\n* Restaurant information\n* Menu details\n* Order cancellations\n\n\n\nYou'll start by creating intents that represent these subjects, and then build a dialog that responds to user questions about them.\n\n\n\n\n\n Step 2: Answer questions about the restaurant \n\nAdd an intent that recognizes when customers ask for details about the restaurant itself. An intent is the purpose or goal expressed in user input. The General_About_You intent that is provided with the General content catalog serves a similar function, but its user examples are designed to focus on queries about the assistant as opposed to the business that is using the assistant to help its customers. So, you will add your own intent.\n\n\n\n Add the about_restaurant intent \n\n\n\n1. From the Intents tab, click Create intent.\n\n![Shows the the Create intent button on the Intents page.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial"},{"document_id":"ibmcld_03334-12430-14290","score":7.8927750225,"text":"\nIf the top intent has a low confidence score (less than 0.2), the top intent is included in the intents array that is returned by the API, but any nodes that condition on the intent are not triggered. If you want to detect the case when no intents with good confidence scores were detected, use the irrelevant special condition in your dialog node. See [Special conditions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-special-conditions) for more information.\n\nAs intent confidence scores change, your dialogs might need restructuring. For example, if a dialog node uses an intent in its condition, and the intent's confidence score starts to consistently drop below 0.2, the dialog node stops being processed. If the confidence score changes, the behavior of the dialog can also change.\n\n\n\n\n\n Intent limits \n\nThe number of intents and examples you can create depends on your Watson Assistant plan type:\n\n\n\nPlan details\n\n Plan Intents per skill Examples per skill \n\n Enterprise 2,000 25,000 \n Premium (legacy) 2,000 25,000 \n Plus 2,000 25,000 \n Lite, Trial 100 25,000 \n\n\n\n\n\n\n\n Editing intents \n\nYou can click any intent in the list to open it for editing. You can make the following changes:\n\n\n\n* Rename the intent.\n* Delete the intent.\n* Add, edit, or delete examples.\n* Move an example to a different intent.\n\n\n\nYou can tab from the intent name to each example.\n\n\n\n1. To move or delete an example, click the checkbox that is associated with it, and then click Move or Delete.\n\n![Screen capture showing how to move or delete an example](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/move_example.png)\n\n\n\n\n\n\n\n Searching intents \n\nUse the Search feature to find user examples, intent names, and descriptions.\n\n\n\n1. From the Intents page, click the Search icon.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"},{"document_id":"ibmcld_03403-10956-12338","score":7.8454532539,"text":"\nAdd a yes intent \n\nBefore you perform an action on the user's behalf, you must get confirmation that you are taking the proper action. Add a #yes intent to the dialog that can recognize when a user agrees with what your assistant is proposing.\n\n\n\n1. Click the Intents tab.\n2. Click Create intent.\n3. Enter yes in the Intent name field, and then click Create intent.\n4. Add the following user examples:\n\nYes\nCorrect\nPlease do.\nYou've got it right.\nPlease do that.\nthat is correct.\nThat's right\nyeah\nYup\nYes, I'd like to go ahead with that.\n\n![Shows that the #yes intent was added.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-ass-yes-intent-added.png)\n5. Click the Close![Close arrow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/close_arrow.png) icon to finish adding the yes intent.\n\n\n\n\n\n\n\n Add dialog nodes that can manage requests to cancel an order \n\nNow, add a dialog node that can handle requests to cancel a cake order.\n\n\n\n1. Click the Dialog tab.\n2. Find the menu node. Click the More![More options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the menu node, and then select Add node below.\n3. Start to type cancel_order into the If assistant recognizes field of this node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial"},{"document_id":"ibmcld_03270-1613-3746","score":7.8370758261,"text":"\nIf you deploy your assistant with an integration that has built-in service desk support, you can use the special Connect to human agent response type in your dialog response to initiate a transfer.\n\n\n\n Adding chat transfer support \n\nDesign your dialog so that it can transfer customers to human agents. Consider adding support for initiating a transfer in the following scenarios:\n\n\n\n* Any time a user asks to speak to a person.\n\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-support"},{"document_id":"ibmcld_02952-7-2097","score":7.8278659067,"text":"\nConnecting customers with support \n\nNo matter where you deploy your assistant, give your customers a way to get additional support when they need it.\n\nBuild your dialog to recognize when customers need help that cannot be provided by the assistant. Add logic that can connect your customers to whatever type of professional support you offer. Your solutions might include:\n\n\n\n* A toll-free phone number to a call center that is manned by human agents\n* An online support ticket form that customers fill out and submit\n* A service desk solution that is configured to work with your custom client application. The built-in Zendesk and Salesforce integrations aren\u2019t supported.\n\n\n\nDesign your dialog to recognize customer requests for help and address them. Add an intent that understands the customer request, and then add a dialog branch that handles the request.\n\nYou might add an intent and use it in a dialog node like these example intents:\n\n\n\nAlternative support request intent examples\n\n Intent name Intent user example 1 Intent user example 2 Response from dialog node that conditions on intent \n\n call_support How do I reach support? What's your toll-free number? Call 1-800-555-0123 to reach a call center agent at any time. \n support_ticket How do I get help? Who can help me with an issue I'm having? Go to [Support Center](https:\/\/example.com\/support) and open a support ticket. \n\n\n\n\n\n Adding chat transfer support \n\nDesign your dialog so that it can transfer customers to human agents. Consider adding support for initiating a transfer in the following scenarios:\n\n\n\n* Any time a user asks to speak to a person.\n\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03085-4-2046","score":23.1991202335,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Managing access \n\nYou can give other people access to your Watson Assistant resources, and control the level of access they get.\n\nMaybe you want one development team to have access to a test assistant and another development team to have access to a production assistant. And you want data scientists to be able to view analytics for user conversation logs from both assistants. And maybe you want a writer to be able to author the dialogue that is used by your assistant to converse with your customers. To manage who can do what with your skills and assistants, you can assign different access roles to different people.\n\n\n\n Before you grant access to others \n\nFor each person to whom you grant access to your Watson Assistant service instance, decide whether you want to give the person a role with instance-level or resource-level access. Instance-level access applies to all of the assistants and skills in a single service instance. Resource-level access applies to individual skills and assistants within a service instance only.\n\n\n\n\n\n Granting users access to your resources \n\n\n\n1. If you plan to give a user access to a single skill or assistant in your service instance, get the ID for the skill or assistant. You need to provide the ID in a later step.\n\n\n\n* To get the assistant ID, go to the Assistants page. Click the overflow menu for the assistant, and then click Settings > API Details. Copy the assistant ID and paste it somewhere that you can access it from later.\n* To get the skill ID, go to the Skills page. Click the overflow menu for the skill, and then click View API Details. Copy the skill ID and paste it somewhere that you can access it from later.\n\n\n\n2. Click the User ![User](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/user-icon2.png) icon in the page header.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-access-control"},{"document_id":"ibmcld_03373-7076-8670","score":19.0699239308,"text":"\nYou can then create a collection from a data source and configure your search skill to search this collection for answers to customer queries.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question gets routed to the search skill.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/search-skill-diagram.png)\n\n\n\n\n\n Creating a skill \n\nYou can add one conversation skill (actions or dialog) and one search skill to an assistant.\n\n\n\n Conversation \n\n\n\n* [Actions skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-actions-add)\n* [Dialog Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add)\n\n\n\n\n\n\n\n Search \n\n\n\n* [Search Skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add)\n\n\n\n\n\n\n\n\n\n Skill limits \n\nThe number of skills you can create depends on your Watson Assistant plan type. Any sample dialog skills that are available for you to use do not count toward your limit unless you use them. A skill version does not count as a skill.\n\n\n\nPlan details\n\n Plan Maximum number of skills of each type per service instance \n\n Enterprise 100 \n Premium (legacy) 100 \n Plus 50 \n Standard (legacy) 20 \n Lite, Trial 5 \n\n\n\n* After 30 days of inactivity, an unused skill in a Lite plan service instance might be deleted to free up space.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"},{"document_id":"ibmcld_03054-19820-21851","score":18.9220716265,"text":"\nClick Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses any user input that it has a high confidence it can answer correctly. You can configure the dialog such that any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead. To do so, add a search skill response type to the Anything else node.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-disable).\n* If you want a specific search query to be triggered for specific questions, add a search skill response type to the appropriate dialog node. See [Responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia) for more details.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* Anything else node: Searches an external data source for a relevant answer when none of the dialog nodes can address the user's query.\n\nInstead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help: followed by the passage returned by the search. If a search skill is linked to your assistant, then whenever the anything_else node is triggered, rather than displaying the node response, you can set it up to trigger a search instead. The assistant passes the user input as the query to your search skill, and returns the search results as the response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03383-19002-21103","score":18.9142821377,"text":"\nWhen the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.\n\n\n\n* From the dialog skill's Anything else node: If the assistant has a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses user input that it has a high confidence it can answer correctly. Any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead.\n\nFor example, instead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help:. The assistant passes the user input as the query to your search skill, and returns the search results as the response.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-addsearch-skill-add-disable).\n* When only a search skill is used: If only a search skill is linked to an assistant, and no conversational skill is configured, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-19029-21139","score":18.9062904531,"text":"\nWhen the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.\n\n\n\n* From the dialog skill's Anything else node: If the assistant has a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses user input that it has a high confidence it can answer correctly. Any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead.\n\nFor example, instead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help:. The assistant passes the user input as the query to your search skill, and returns the search results as the response.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-addsearch-skill-add-disable).\n* When only a search skill is used: If only a search skill is linked to an assistant, and no conversational skill is configured, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03049-3966-5647","score":18.9043693552,"text":"\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Dialog Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific skill version, add it from the skill's Versions tab instead.\n\n\n\n\n\n\n\n Downloading a dialog skill \n\nYou can download a dialog skill in JSON format. You might want to download a skill if you want to use the same dialog skill in a different instance of the Watson Assistant service, for example. You can download it from one instance and import it to another instance as a new dialog skill.\n\nTo download a dialog skill, complete the following steps:\n\n\n\n1. Find the dialog skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03381-4-1869","score":18.8589916929,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant. See [Skill limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-limits) for information about limits per plan.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or upload a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. From the assistant where you want to add the skill, click Add an actions or dialog skill.\n2. Do one of the following:\n\n\n\n* To create a new dialog skill, remain on the Create skill tab.\n* To add the dialog sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, open the Use sample skill tab, and then click the sample labeled TYPE: Dialog. You can skip the remaining steps.\n* To add a skill that was downloaded previously, you can upload it as a JSON file. Open the Upload skill tab. Drag a file or click Drag and drop file here or click to select a file and select the JSON file you want to upload.\n\nThe uploaded JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10 MB. If you need to upload a larger skill, consider using the REST API. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1?curl=createworkspace).\n\nClick Upload.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add"},{"document_id":"ibmcld_03383-20671-22804","score":18.8531908099,"text":"\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-20707-22840","score":18.8531908099,"text":"\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane. The search skill is configured separately and attached to an assistant. The dialog skill has no way of knowing the details of the search, and therefore cannot show search results in its \"Try it out\" pane.\n\nConfigure at least one integration channel to test the search skill. In the channel, enter queries that trigger the search. If you initiate any type of search from your dialog, test the dialog to ensure that the search is triggered as expected. If you are not using search response types, test that a search is triggered only when no existing dialog nodes can address the user input. And any time a search is triggered, ensure that it returns meaningful results.\n\n\n\n\n\n Sending more requests to the search skill \n\nIf you want the dialog skill to respond less often and to send more queries to the search skill instead, you can configure the dialog to do so.\n\nYou must add both a dialog skill and search skill to your assistant for this approach to work.\n\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03043-7-2031","score":18.8416423518,"text":"\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1356519734}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02900-2946-5130","score":18.3154830917,"text":"\nHowever, the conversation cannot digress away from a node under the following circumstances:\n\n\n\n* If any of the child nodes of the current node contain the anything_else or true condition\n\n\n\nThese conditions are special in that they always evaluate to true. Because of their known behavior, they are often used in dialogs to force a parent node to evaluate a specific child node in succession. To prevent breaking existing dialog flow logic, digression are not allowed in this case. Before you can enable digressions away from such a node, you must change the child node's condition to something else.\n\n\n\n* If the node is configured to jump to another node or skip user input after it is processed\n\n\n\nThe final step section of a node specifies what should happen after the node is processed. When the dialog is configured to jump directly to another node, it is often to ensure that a specific sequence is followed. And when the node is configured to skip user input, it is equivalent to forcing the dialog to process the first child node after the current node in succession. To prevent breaking existing dialog flow logic, digressions are not allowed in either of these cases. Before you can enable digressions away from this node, you must change what is specified in the final step section.\n\n\n\n\n\n\n\n Customizing digressions \n\nYou do not define the start and end of a digression. The user is entirely in control of the digression flow at run time. You only specify how each node should or should not participate in a user-led digression. For each node, you configure whether:\n\n\n\n* a digression can start from and leave the node\n* a digression that starts elsewhere can target and enter the node\n* a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed\n\n\n\nTo change the digression behavior for an individual node, complete the following steps:\n\n\n\n1. Click the node to open its edit view.\n2. Click Customize, and then click the Digressions tab.\n\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"},{"document_id":"ibmcld_02900-4643-6783","score":18.2858809709,"text":"\n* a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed\n\n\n\nTo change the digression behavior for an individual node, complete the following steps:\n\n\n\n1. Click the node to open its edit view.\n2. Click Customize, and then click the Digressions tab.\n\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.\n\n\n\n Digressions away from this node \n\nIf the circumstances listed earlier do not apply, then you can make the following choices:\n\n\n\n* All node types: Choose whether to allow users to digress away from the current node before they reach the end of the current dialog branch.\n* All nodes that have children: Choose whether you want the conversation to come back to the current node after a digression if the current node's response has already been displayed and its child nodes are incidental to the node's goal. Set the Allow return from digressions triggered after this node's response toggle to No to prevent the dialog from returning to the current node and continuing to process its branch.\n\nFor example, if the user asks, Do you sell cupcakes? and the response, We offer cupcakes in a variety of flavors and sizes is displayed before the user changes subjects, you might not want the dialog to return to where it was. Especially, if the child nodes only address possible follow-up questions from the user and can safely be ignored.\n\nHowever, if the node relies on its child nodes to address the question, then you might want to force the conversation to return and continue processing the nodes in the current branch. For example, the initial response might be, We offer cupcakes in all shapes and sizes. Which menu do you want to see: gluten-free, dairy-free, or regular? If the user changes subjects at this point, you might want the dialog to return so the user can pick a menu type and get the information they wanted.\n* Nodes with slots: Choose whether you want to allow users to digress away from the node before all of the slots are filled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"},{"document_id":"ibmcld_03188-1732-3801","score":18.0146937658,"text":"\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.\n* To add slightly different responses for a single dialog node based on the integration type, complete the following steps:\n\n\n\n* From the node's edit view, click Customize and then set the Multiple conditioned responses switch to On. Click Apply.\n* In the dialog node response section, add the appropriate condition and corresponding response for each custom response type.\n\n\n\nThe following examples show how to specify a hypertext link in the best format for the integration where the text response will be displayed. For the Web chat integration, which supports Markdown formatting, you can include a link label in the response text to make the response look nicer. For the SMS with Twilio integration, you can skip the formatting that makes sense in a web page, and add the straight URL.\n\n\n\nCustom conditioned responses\n\n Integration type Condition Sample text response \n\n SMS with Twilio `$integrations.text_messaging` `For more information, go to https:\/\/www.ibm.com.` \n Web chat `$integrations.chat` `For more information, go to [the ibm.com site](https:\/\/www.ibm.com).` \n Response to show if no other conditions are met. `true` `For more information, go to ibm.com.` \n\n\n\n\n\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"},{"document_id":"ibmcld_03218-24900-26959","score":17.9407916979,"text":"\nFor each node, you configure whether:<-- <ul> --> * a digression can start from and leave the node * a digression that starts elsewhere can target and enter the node * a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed<-- <\/ul> -->To change the digression behavior for an individual node, complete the following steps:<-- <ol> -->1. Click the node to open its edit view.2. Click Customize, and then click the Digressions tab.\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.\n\nDigressions away from this node\n\nIf the circumstances listed earlier do not apply, then you can make the following choices:\n\n<-- <ul> -->\n\n* All node types: Choose whether to allow users to digress away from the current node before they reach the end of the current dialog branch.\n* All nodes that have children: Choose whether you want the conversation to come back to the current node after a digression if the current node's response has already been displayed and its child nodes are incidental to the node's goal. Set the Allow return from digressions triggered after this node's response switch to No to prevent the dialog from returning to the current node and continuing to process its branch.\n\nFor example, if the user asks, Do you sell cupcakes? and the response, We offer cupcakes in a variety of flavors and sizes is displayed before the user changes subjects, you might not want the dialog to return to where it left off. Especially, if the child nodes only address possible follow-up questions from the user and can safely be ignored.\n\nHowever, if the node relies on its child nodes to address the question, then you might want to force the conversation to return and continue processing the nodes in the current branch. For example, the initial response might be, We offer cupcakes in all shapes and sizes. Which menu do you want to see: gluten-free, dairy-free, or regular?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime"},{"document_id":"ibmcld_03156-4700-6686","score":17.4875923458,"text":"\n[Screenshot of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/disambig-node-purpose.png)\n\nDo not add an external node name to the root node that you created in Step 2. When an escalation occurs, your assistant looks at the external node name of the last processed node to learn which user goal was not met successfully. If you include an external node name in the node with the connect to human agent intent, then you will prevent your assistant from learning the last real, goal-oriented node that the user interacted with before escalating the issue.\n\n\n\n4. If a child node in the branch conditions on a follow-up request or question that you do not want the assistant to handle, add a Connect to human agent response type to the node.\n\nFor example, you might want to add this response type to nodes that cover sensitive issues only a human should handle or that track when an assistant repeatedly fails to understand a user.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point. Later, when you set up the Intercom integration, you can choose a human agent as a backup for each branch.\n\n\n\nYour dialog is now ready to support your assistant in Intercom.\n\n\n\n Dialog considerations \n\nSome rich responses that you add to a dialog are displayed differently within the \"Try it out\" pane from how they are displayed to Intercom users. The following table describes how the response types are treated by Intercom.\n\n\n\n Response type How displayed to Intercom users \n\n Option The options are displayed as a numbered list. In the title or description field, provide instructions that explain to the user how to choose an option from the list. \n Image The image title, description, and the image itself are rendered. \n Pause Whether or not you enable it, a typing indicator is not displayed during the pause.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-intercom"},{"document_id":"ibmcld_02882-18936-21214","score":17.3170837476,"text":"\nYou can return responses with multimedia or interactive elements such as images or clickable buttons to simplify the interaction model of your application and enhance the user experience.\n\nIn addition to the default response type of Text, for which you specify the text to return to the user as a response, the following response types are supported:\n\n\n\n* Connect to human agent: The dialog calls a service that you designate, typically a service that manages human agent support ticket queues, to pass off the conversation to a person. You can optionally include a message that summarizes the user's issue to be provided to the human agent. It is the responsibility of the external service to display a message that is shown to the user that explains that the conversation is being transferred. The dialog does not manage that communication itself. The dialog transfer does not occur when you are testing nodes with this response type in the Try it out pane. You must access a node that uses this response type from a test deployment to see how your users will experience it.\n* Image: Embeds an image into the response. The source image file must be hosted somewhere and have a URL that you can use to reference it. It cannot be a file that is stored in a directory that is not publicly accessible.\n* Option: Adds a list of one or more options. When a user clicks one of the options, an associated user input value is sent to your assistant. How options are rendered can differ depending on where you deploy the dialog. For example, in one integration channel the options might be displayed as clickable buttons, but in another they might be displayed as a dropdown list.\n* Pause: Forces the application to wait for a specified number of milliseconds before continuing with processing. You can choose to show an indicator that the dialog is working on typing a response. Use this response type if you need to perform an action that might take some time. For example, a parent node makes a Cloud Function call and displays the result in a child node. You could use this response type as the response for the parent node to give the programmatic call time to complete, and then jump to the child node to show the result. This response type does not render in the Try it out pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_03113-4-2033","score":16.9393253892,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the \/dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the \/dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03113-6206-7586","score":16.9130381382,"text":"\n[Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n![Example dialog 2](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_2.png)\n\nBecause node_8 was created without specifying a value for parent or previous_sibling, it is now the first node in the dialog. Note that in addition to creating node_8, the service also modified node_1 so that its previous_sibling property points to the new node.\n\nYou can create a node somewhere else in the dialog by specifying the parent and previous sibling:\n\n{\n\"dialog_node\": \"node_9\",\n\"parent\": \"node_2\",\n\"previous_sibling\": \"node_5\"\n}\n\nThe values you specify for parent and previous_node must be valid:\n\n\n\n* Both values must refer to existing nodes.\n* The specified parent must be the same as the parent of the previous sibling (or null, if the previous sibling has no parent).\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_3.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03273-11911-13556","score":16.8477345483,"text":"\n[More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the folder, and then select Add node to folder.\n\nThe dialog node is added to the end of the dialog tree within the folder.\n\n\n\n\n\n\n\n\n\n Deleting a folder \n\nYou can delete either a folder alone or the folder and all of the dialog nodes in it.\n\nTo delete a folder, complete the following steps:\n\n\n\n1. From the tree view of the Dialog tab, find the folder that you want to delete.\n2. Click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png) icon on the folder, and then select Delete.\n3. Do one of the following things:\n\n\n\n* To delete the folder only, and keep the dialog nodes that are in the folder, deselect the Delete the nodes inside the folder checkbox, and then click Yes, delete it.\n* To delete the folder and all of the dialog nodes in it, click Yes, delete it.\n\n\n\n\n\nIf you deleted the folder only, then the nodes that were in the folder are displayed in the dialog tree in the spot where the folder used to be.\n\n\n\n\n\n\n\n Dialog node limits \n\nThe number of dialog nodes you can create per skill depends on your plan type.\n\n\n\nPlan details\n\n Plan Dialog nodes per skill \n\n Enterprise 100,000 \n Premium (legacy) 100,000 \n Plus 100,000 \n Trial 25,000 \n Lite 25,000 \n\n\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\n\n\n\n\n Finding a dialog node by its node ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_02953-12940-14393","score":16.7631097178,"text":"\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\nYou can see the number of dialog nodes in a dialog skill from the assistant tile. If the skill is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object. Some fields that appear to be part of a single node are actually structured as separate dialog nodes in the underlying JSON object.\n\n\n\n* Each node and folder is represented as its own node.\n* Each conditional response that is associated with a single dialog node is represented as an individual node.\n* For a node with slots, each slot, slot found response, slot not found response, slot handler, and if set, the prompt for everything response is an individual node. In effect, one node with three slots might be equivalent to eleven dialog nodes.\n\n\n\nPrevious topic:[Controlling the dialog flow](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime)\n\nNext topic:[Dialog building tips](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tips)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasks"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02882-27313-29495","score":7.9398771725,"text":"\nThis response type only returns a valid response if the assistant to which you added this dialog skill also has a search skill associated with it.\n\n\n\n2. Click Add response to add another response type to the current response.\n\nYou might want to add multiple response types to a single response to provide a richer answer to a user query. For example, if a user asks for store locations, you could show a map and display a button for each store location that the user can click to get address details. To build that type of response, you can use a combination of image, options, and text response types. Another example is using a text response type before a pause response type so you can warn users before pausing the dialog.\n\nYou cannot add more than 5 response types to a single response. Meaning, if you define three conditional responses for a dialog node, each conditional response can have no more than 5 response types added to it.\n\nA single dialog node cannot have more than one Connect to human agent or more than one Search skill response.\n3. If you added more than one response type, you can click the Move up or down arrows to arrange the response types in the order you want your assistant to process them.\n\n\n\n\n\n\n\n\n\n Conditional responses \n\nA single dialog node can provide different responses, each one triggered by a different condition. Use this approach to address multiple scenarios in a single node.\n\nThe node still has a main condition, which is the condition for using the node and processing the conditions and responses that it contains.\n\nIn this example, your assistant uses information that it collected earlier about the user's location to tailor its response, and provide information about the store nearest the user. See [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables) for more information about how to store information collected from the user.\n\n![Shows a node that shows a user ask, Where are you located, and the dialog has three different responses depending on conditions that use info from the $state context variable to specify locations in those states.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_03196-24078-26023","score":7.8435311279,"text":"\n* [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill)![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png)\n\nThis response type is only visible to users of paid plans.\n* [Text](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-simple-text)\n\n\n\n2. To add another response type to the current response, click Add response type.\n\nYou might want to add multiple response types to a single response to provide a richer answer to a user query. For example, if a user asks for store locations, you could show a map and display a button for each store location that the user can click to get address details. To build that type of response, you can use a combination of image, options, and text response types. Another example is using a text response type before a pause response type so you can warn users before pausing the dialog.\n\nYou cannot add more than 5 response types to a single response. This means that if you define three conditioned responses for a dialog node, each conditioned response can have no more than 5 response types added to it.\n\nYou cannot add more than one Connect to human agent or more than one Search skill response type to a single dialog node.\n\nDo not add more than one option response type to a single dialog node because both lists are displayed at once, but the customer can choose an option from only one of them.\n3. If you added more than one response type, you can click the Move up or down arrows to arrange the response types in the order you want your assistant to process them.\n\n\n\n\n\n\n\n Adding a Connect to human agent response type \n\nIf your client application is able to transfer a conversation to a person, such as a customer support agent, then you can add a Connect to human agent response type to initiate the transfer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_03188-1732-3801","score":7.7339475124,"text":"\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.\n* To add slightly different responses for a single dialog node based on the integration type, complete the following steps:\n\n\n\n* From the node's edit view, click Customize and then set the Multiple conditioned responses switch to On. Click Apply.\n* In the dialog node response section, add the appropriate condition and corresponding response for each custom response type.\n\n\n\nThe following examples show how to specify a hypertext link in the best format for the integration where the text response will be displayed. For the Web chat integration, which supports Markdown formatting, you can include a link label in the response text to make the response look nicer. For the SMS with Twilio integration, you can skip the formatting that makes sense in a web page, and add the straight URL.\n\n\n\nCustom conditioned responses\n\n Integration type Condition Sample text response \n\n SMS with Twilio `$integrations.text_messaging` `For more information, go to https:\/\/www.ibm.com.` \n Web chat `$integrations.chat` `For more information, go to [the ibm.com site](https:\/\/www.ibm.com).` \n Response to show if no other conditions are met. `true` `For more information, go to ibm.com.` \n\n\n\n\n\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"},{"document_id":"ibmcld_03113-4996-6502","score":7.7031256336,"text":"\n[UI location where the code that is triggered by named event handlers is authored](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/api-event-handlers.png)\n* A node of type event_handler with an event_name of generic can have a parent of type slot or frame.\n* A node of type event_handler with an event_name of focus, input, filled, or nomatch must have a parent of type slot.\n* If more than one event_handler with the same event_name is associated with the same parent node, then the order of the siblings reflects the order in which the event handlers will be executed.\n* For event_handler nodes with the same parent slot node, the order of execution is the same regardless of the placement of the node definitions. The events are triggered in this order by event_name:\n\n\n\n1. focus\n2. input\n3. filled\n4. generic*\n5. nomatch\n\n\n\n*If an event_handler with the event_name generic is defined for this slot or for the parent frame, then it is executed between the filled and nomatch event_handler nodes.\n\n\n\nThe following examples show how various modifications might cause cascading changes.\n\n\n\n Creating a node \n\nConsider the following simple dialog tree:\n\n![Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03196-43073-44885","score":7.6008800459,"text":"\n}\n}\nShow more\n\nWhen you define an options list with only 3 items, the options are typically displayed as buttons. When you add a preference property that indicates dropdown as the preference, for example, you can see in the \"Try it out\" pane that the list is displayed as a drop-down list instead.\n\n![Shows a small options list in the Preview that is displayed as a drop-down menu.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/options-dropdown.png)\n\nSome integration types, such as the web chat, reflect your preference. Other integration types, such as Slack, do not reflect your preference when they render the options.\n\n\n\nDo not add more than one option response type to a single dialog node because both lists are displayed at once, but the customer can choose an option from only one of them.\n\nIf you need to be able to populate the list of options with different values based on some other factors, you can design a dynamic options list. For more information, see the [How to Dynamically Add Response Options to Dialog Nodes](https:\/\/medium.com\/ibm-watson\/how-to-dynamically-add-response-options-to-dialog-nodes-in-watson-assistant-e14c5e08beca) blog post.\n\n\n\n\n\n Adding a Pause response type \n\nAdd a pause response type to give the assistant time to respond. For example, you might add a pause response type to a node that calls a webhook. The pause indicates that the assistant is working on an answer, which gives the assistant time to make the webhook call and get a response. Then, you can jump to a child node to show the result.\n\nTo add a Pause response type, complete the following steps:\n\n\n\n1. From the dialog node where you want to add the response type, click the dropdown menu in the Assistant responds field, and then choose Pause.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_02882-18936-21214","score":7.5921298121,"text":"\nYou can return responses with multimedia or interactive elements such as images or clickable buttons to simplify the interaction model of your application and enhance the user experience.\n\nIn addition to the default response type of Text, for which you specify the text to return to the user as a response, the following response types are supported:\n\n\n\n* Connect to human agent: The dialog calls a service that you designate, typically a service that manages human agent support ticket queues, to pass off the conversation to a person. You can optionally include a message that summarizes the user's issue to be provided to the human agent. It is the responsibility of the external service to display a message that is shown to the user that explains that the conversation is being transferred. The dialog does not manage that communication itself. The dialog transfer does not occur when you are testing nodes with this response type in the Try it out pane. You must access a node that uses this response type from a test deployment to see how your users will experience it.\n* Image: Embeds an image into the response. The source image file must be hosted somewhere and have a URL that you can use to reference it. It cannot be a file that is stored in a directory that is not publicly accessible.\n* Option: Adds a list of one or more options. When a user clicks one of the options, an associated user input value is sent to your assistant. How options are rendered can differ depending on where you deploy the dialog. For example, in one integration channel the options might be displayed as clickable buttons, but in another they might be displayed as a dropdown list.\n* Pause: Forces the application to wait for a specified number of milliseconds before continuing with processing. You can choose to show an indicator that the dialog is working on typing a response. Use this response type if you need to perform an action that might take some time. For example, a parent node makes a Cloud Function call and displays the result in a child node. You could use this response type as the response for the parent node to give the programmatic call time to complete, and then jump to the child node to show the result. This response type does not render in the Try it out pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_03188-4-2198","score":7.590958526,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding custom dialog flows for integrations \n\nUse the JSON editor in dialog to access information that is submitted from the web chat integration.\n\nStarting with API version 2020-04-01, the context object that is passed as part of the v2 \/message API request contains an integrations object. This object makes it possible to pass information that is specific to a single integration type in the context. For more information about context variables, see [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-contextdialog-runtime-context-variables).\n\nThe integrations object is available from the v2 API in version 2020-04-01 or later only.\n\nTo take advantage of the context.integrations object, you can create context variables that are named as follows to get and set values for different integrations:\n\n\n\nIntegration-specific context variables\n\n Integration type Context variable syntax \n\n Phone $integrations.voice_telephony \n Salesforce service desk from web chat $integrations.salesforce \n SMS with Twilio $integrations.text_messaging \n Web chat (and assistant preview) $integrations.chat \n Zendesk service desk from web chat $integrations.zendesk \n\n\n\nThe following sections describe how to use integration-specific context variables to do common tasks.\n\n\n\n Building integration-specific dialog flow \n\nCreate a single dialog that is optimized to use the best features offered by each channel or client interface in which it is deployed.\n\nYou can customize the conversation in the following ways:\n\n\n\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"},{"document_id":"ibmcld_03150-1680-3886","score":7.5001149881,"text":"\n* Video: This response type embeds a native video from various file formats in the response. A title and description are not displayed, whether or not you specify them.\n* iframe: This response type inserts an embeddable third-party link in the response that displays interactive content (such as forms or maps). A title is displayed in the preview card. A description is not displayed, whether or not you specify it.\n* Option: This response type shows a list of options that the user can choose from.\n\n\n\n* A title is required and is displayed before the list of options.\n* A description is not displayed, whether you specify one or not.\n* After a user clicks one of the buttons, the button choices disappear and are replaced by the user input that is generated by the user's choice. If the assistant or the user enters new input, then the button-generated input disappears. Therefore, if you include multiple response types in a single response, position the option response type last. Otherwise, content from subsequent responses, such as text from a text response type, will replace the button-generated text.\n\n\n\n* Pause: This response type pauses the assistant's activity in the Messenger. However, activity does not resume after the pause unless another response type is triggered after it. Whenever you include this response type, add another, different response type, such as a text response, and position it after this one.\n\n\n\nSee [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-multimedia) for more information about response types.\n\n\n\n\n\n Chatting with the assistant \n\nTo start a chat with the assistant, complete the following steps:\n\n\n\n1. Open Facebook Messenger.\n2. Type the name of the page you created earlier.\n3. After the page comes up, click it, and then start chatting with the assistant.\n\n\n\nThe Welcome node of your dialog is not processed by the Facebook Messenger integration. The welcome message is not displayed in the Facebook chat like it is in the \"Try it out\" pane or in the assistant preview. It is not triggered from here because nodes with the welcome special condition are skipped in dialog flows that are started by users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-facebook"},{"document_id":"ibmcld_03156-4700-6686","score":7.4725863474,"text":"\n[Screenshot of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/disambig-node-purpose.png)\n\nDo not add an external node name to the root node that you created in Step 2. When an escalation occurs, your assistant looks at the external node name of the last processed node to learn which user goal was not met successfully. If you include an external node name in the node with the connect to human agent intent, then you will prevent your assistant from learning the last real, goal-oriented node that the user interacted with before escalating the issue.\n\n\n\n4. If a child node in the branch conditions on a follow-up request or question that you do not want the assistant to handle, add a Connect to human agent response type to the node.\n\nFor example, you might want to add this response type to nodes that cover sensitive issues only a human should handle or that track when an assistant repeatedly fails to understand a user.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point. Later, when you set up the Intercom integration, you can choose a human agent as a backup for each branch.\n\n\n\nYour dialog is now ready to support your assistant in Intercom.\n\n\n\n Dialog considerations \n\nSome rich responses that you add to a dialog are displayed differently within the \"Try it out\" pane from how they are displayed to Intercom users. The following table describes how the response types are treated by Intercom.\n\n\n\n Response type How displayed to Intercom users \n\n Option The options are displayed as a numbered list. In the title or description field, provide instructions that explain to the user how to choose an option from the list. \n Image The image title, description, and the image itself are rendered. \n Pause Whether or not you enable it, a typing indicator is not displayed during the pause.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-intercom"},{"document_id":"ibmcld_03054-21355-23324","score":7.4510092183,"text":"\nInstead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help: followed by the passage returned by the search. If a search skill is linked to your assistant, then whenever the anything_else node is triggered, rather than displaying the node response, you can set it up to trigger a search instead. The assistant passes the user input as the query to your search skill, and returns the search results as the response.\n\nTo see how this works at run time (where v2 API is used) from the Try it out pane (where v1 API is used), you must add a search skill response type to the Anything else node in your dialog. Doing so mimics the behavior that occurs at run time. Only keep this response type on the Anything else node for the duration of your dialog testing, and then remove it when you're done. The best way to see how the assistant will behave from end-to-end is to test by using the API. See [Test the search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-test-via-api).\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-disable).\n* Search response type: If you add a search skill response type to a dialog node, then your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed.\n\nThis approach is useful if you want to narrow down a user query before you trigger a search. For example, the dialog branch might collect information about the type of device the customer wants to buy. When you know the make and model, you can then send a model keyword in the query that is submitted to the search skill, and get better results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03383-17365-19519","score":29.2992747404,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-17392-19546","score":29.2992747404,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03054-18427-20301","score":28.5905924752,"text":"\nFor details about how to add a search skill response type, see [Adding rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia-add).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/) blog post.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. Open the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Search Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03381-2858-4802","score":28.5525472251,"text":"\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Troubleshooting skill upload issues \n\nHere are some solutions to typical upload issues:\n\n\n\n* If you get the message, Error. Should NOT be shorter than 1 character, then check whether your skill has a name. If not, add one.\n* The @sys-person and @sys-location system entities are no longer supported. If the skill you are uploading references them in its dialog, an error is displayed. Remove these system entities from your dialog.\n* If you receive a message that says the skill contains artifacts that exceed the limits imposed by your service plan, complete the following steps to upload the skill successfully:\n\n\n\n1. Purchase a plan with higher artifact limits.\n2. Create a service instance in the new plan.\n3. Upload the skill to the new service instance.\n4. If you don't want to keep the higher-level plan, make edits to the skill such that it meets the artifact limit requirements for the plan you want to use going forward.\n\n\n\nFor information about how to decrease the number of dialog nodes, see [How many nodes are in my dialog?](\/docs\/assistant?topic=assistant-dialog-tasksdialog-tasks-count-nodes).\n\n\n\n1. Download the edited skill to export it.\n2. Try again to upload the edited skill into the original service instance on the plan you want.\n\n\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one dialog skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-add"},{"document_id":"ibmcld_03049-2703-4536","score":28.3965302211,"text":"\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Troubleshooting skill import issues \n\nIf you receive warnings when you try to upload a skill, take a moment to try to fix the issues.\n\n\n\n1. Make a note of the warning message that are displayed when you try to upload the JSON file.\n2. Edit the skill to address the issues.\n\n\n\n* If you have access to a public service instance, open the skill from there and make edits. Export the edited skill by downloading it.\n* Otherwise, open the JSON file in a text editor and make edits.\n\n\n\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03126-3707-6008","score":28.2880064241,"text":"\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_03369-125488-127526","score":27.870203287,"text":"\nIf you are looking for other ways to analyze your user conversation logs in more detail, consider using Jupyter notebooks. See [Advanced tasks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resources) for more details.\n\n\n\n\n\n 9 November 2018 \n\nMajor user interface revision\n: The Watson Assistant service has a new look and added features.\n\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03049-3966-5647","score":27.6358625125,"text":"\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Dialog Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific skill version, add it from the skill's Versions tab instead.\n\n\n\n\n\n\n\n Downloading a dialog skill \n\nYou can download a dialog skill in JSON format. You might want to download a skill if you want to use the same dialog skill in a different instance of the Watson Assistant service, for example. You can download it from one instance and import it to another instance as a new dialog skill.\n\nTo download a dialog skill, complete the following steps:\n\n\n\n1. Find the dialog skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_16364-163116-165172","score":27.4999488298,"text":"\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time. No more passing context with each API call; the session state is managed for you as part of the assistant layer.\n\n\n\nWhat is presented in the tooling as a dialog skill is effectively a wrapper for a V1 workspace. There are currently no API methods for authoring skills and assistants with the V2 API. However, you can continue to use the V1 API for authoring workspaces.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03373-4-1923","score":27.4914936804,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding skills to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nConversational skills return responses that are authored by you to answer common questions, while a search skill searches for and returns passages from existing self-service content.\n\nYou can add the following types of skills to your assistant:\n\n\n\n* Conversational skills: Understand and address questions or requests that your customers typically ask about. You provide information about the subjects or tasks that your users need help with, and how they ask about them, and the product dynamically builds a machine learning model that is tailored to understand the same and similar user requests.\n\n\n\n* Actions skill : Offers a simple interface where anyone can build a conversational flow for your assistant to follow. The complex process of training data creation occurs behind the scenes automatically. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-actions-skill)\n* Dialog skill: Offers a set of editors that you use to define both your training data and the conversation. The conversation is represented as a dialog tree. You use the graphical dialog editor to create a script of sorts for your assistant to read from when it interacts with your customers. The dialog keys off the common customer goals that you teach it to recognize, and provides useful responses. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-dialog-skill)\n\n\n\nIf you can't decide which type of conversational skill to create, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n* Search skill!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03043-7-2031","score":26.7693258315,"text":"\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_03383-17365-19519","score":26.3628467922,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-17392-19546","score":26.3628467922,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03043-3079-5106","score":26.0885098306,"text":"\nIn the tool, the name of an entity is always prefixed with the @ character.\n\nYou can train the skill to recognize your entities by providing entity term values and synonyms, entity patterns, or by identifying the context in which an entity is typically used in a sentence. To fine tune your dialog, go back and add nodes that check for entity mentions in user input in addition to intents.\n\n\n\n![Diagram of a more complex implementation that uses intent, entity, and dialog.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/complex-impl.png)\n\nAs you add information, the skill uses this unique data to build a machine learning model that can recognize these and similar user inputs. Each time you add or change the training data, the training process is triggered to ensure that the underlying model stays up-to-date as your customer needs and the topics they want to discuss change.\n\nFor help creating a dialog skill, see [Creating a dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add).\n\n\n\n\n\n Search skill \n\nWhen Watson Assistant doesn't have an explicit solution to a problem, it routes the user question to a search skill to find an answer from across your disparate sources of self-service content. The search skill interacts with the IBM Watson\u00ae Discovery service to extract this information from a configured data collection.\n\nIf you already have Discovery for IBM Cloud Pak for Data installed and an instance provisioned, you can mine your existing data collections for source material that you can share with customers to address their questions.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question is sent to the Discovery service from a search skill.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_03054-27011-29125","score":26.0863751449,"text":"\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition with a search skill response type.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:\n\nintents[0].confidence > 0.5\n\nThis condition is applied to all of the nodes in the folder. The condition tells your assistant to process the nodes in the folder only if your assistant is at least 50% confident that it knows the user's intent.\n3. Move any dialog nodes that you do not want your assistant to process often into the folder.\n\n\n\nAfter changing the dialog, test the assistant to make sure the search skill is triggered as often as you want it to be.\n\nAn alternative approach is to teach the dialog about topics to ignore. To do so, you can add utterances that you want the assistant to send to the search skill immediately as test utterances in the dialog skill's Try it out pane. You can then select the Mark as irrevlant option within the Try it out pane to teach the dialog not to respond to this utterance or others like it.\n\n\n\n\n\n Disabling search \n\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03383-22222-24301","score":25.9007730692,"text":"\nChanging the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:\n\nintents[0].confidence > 0.5\n\nThis condition is applied to all of the nodes in the folder. The condition tells your assistant to process the nodes in the folder only if your assistant is at least 50% confident that it knows the user's intent.\n3. Move any dialog nodes that you do not want your assistant to process often into the folder.\n\n\n\nAfter changing the dialog, test the assistant to make sure the search skill is triggered as often as you want it to be.\n\nAn alternative approach is to teach the dialog about topics to ignore. To do so, you can add utterances that you want the assistant to send to the search skill immediately as test utterances in the dialog skill's \"Try it out\" pane. You can then select the Mark as irrelevant option within the \"Try it out\" pane to teach the dialog not to respond to this utterance or others like it. For more information, see [Teaching your assistant about topics to ignore](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-mark-irrelevant).\n\n\n\n\n\n Disabling search \n\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-22258-24337","score":25.9007730692,"text":"\nChanging the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:\n\nintents[0].confidence > 0.5\n\nThis condition is applied to all of the nodes in the folder. The condition tells your assistant to process the nodes in the folder only if your assistant is at least 50% confident that it knows the user's intent.\n3. Move any dialog nodes that you do not want your assistant to process often into the folder.\n\n\n\nAfter changing the dialog, test the assistant to make sure the search skill is triggered as often as you want it to be.\n\nAn alternative approach is to teach the dialog about topics to ignore. To do so, you can add utterances that you want the assistant to send to the search skill immediately as test utterances in the dialog skill's \"Try it out\" pane. You can then select the Mark as irrelevant option within the \"Try it out\" pane to teach the dialog not to respond to this utterance or others like it. For more information, see [Teaching your assistant about topics to ignore](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-mark-irrelevant).\n\n\n\n\n\n Disabling search \n\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_16364-98714-100707","score":25.8920154924,"text":"\nFor more information, see [Adding service desk support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa).\n\nAutolearning has been moved and improved\n: Go to the Analytics>Autolearning page to enable the feature and see visualizations that illustrate how autolearning impacts your assistant's performance over time. For more information, see [Empower your skill to learn automatically](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-autolearn).\n\nSearch from actions skill\n: The actions skill now supports triggering a search that uses your associated search skill from within an action step. For more information, see [Deciding what to do next](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-actionsactions-what-next).\n\nSystem entities language support change\n: The new system entities are now used by all skills except Korean-language dialog skills. If you have a Korean skill that uses the older version of the system entities, update it. The legacy version will stop being supported for Korean skills in March 2021. For more information, see [Legacy system entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-legacy-system-entities).\n\nDisambiguation selection enhancement\n: When a customer chooses an option from a disambiguation list, the corresponding intent is submitted. With this latest release, a confidence score of 1.0 is assigned to the intent. Previously, the original confidence score of the option was used.\n\nSkill import improvements\n: Importing of large skills from JSON data is now processed in the background. When you import a JSON file to create a skill, the new skill tile appears immediately. However, depending on the size of the skill, it might not be available for several minutes while the import is being processed. During this time, the skill cannot be opened for editing or added to an assistant, and the skill tile shows the text Processing.\n\n\n\n\n\n 23 November 2020 \n\nDeploy your assistant to WhatsApp!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03383-19002-21103","score":25.8003613141,"text":"\nWhen the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.\n\n\n\n* From the dialog skill's Anything else node: If the assistant has a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses user input that it has a high confidence it can answer correctly. Any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead.\n\nFor example, instead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help:. The assistant passes the user input as the query to your search skill, and returns the search results as the response.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-addsearch-skill-add-disable).\n* When only a search skill is used: If only a search skill is linked to an assistant, and no conversational skill is configured, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-19029-21139","score":25.7903713028,"text":"\nWhen the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.\n\n\n\n* From the dialog skill's Anything else node: If the assistant has a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses user input that it has a high confidence it can answer correctly. Any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead.\n\nFor example, instead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help:. The assistant passes the user input as the query to your search skill, and returns the search results as the response.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-addsearch-skill-add-disable).\n* When only a search skill is used: If only a search skill is linked to an assistant, and no conversational skill is configured, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10852-44214-45420","score":28.521246299,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-7-1802","score":28.2395733199,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-43319-44485","score":27.6919336132,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-2884-4620","score":24.5278650476,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_13724-72779-74671","score":24.4234064549,"text":"\nThe customization interface includes a collection of new HTTP methods that have the names POST \/v1\/customizations, POST \/v1\/customizations\/{customization_id}, POST \/v1\/customizations\/{customization_id}\/words, and PUT \/v1\/customizations\/{customization_id}\/words\/{word}. The service also provides a new GET \/v1\/pronunciation method that returns the pronunciation for any word and a new GET \/v1\/voices\/{voice} method that returns detailed information about a specific voice. In addition, existing methods of the service's interface now accept custom model parameters as needed.\n\nFor more information about customization and its interface, see [Understanding customization](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customIntro) and the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\nThe customization interface is a beta release that currently supports US English only. All customization methods and the GET \/v1\/pronunciation method can currently be used to create and manipulate custom models and word translations only in US English.\n\nNew Brazilian Portuguese voice: pt-BR_IsabelaVoice\n: The service supports a new voice, pt-BR_IsabelaVoice, to synthesize audio in Brazilian Portuguese with a female voice. For more information, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile Software Development Kits (SDKs) are available for the speech services. The SDKs enable mobile applications to interact with both the Text to Speech and Speech to Text services. You can use the SDKs to send text to the Text to Speech service and receive an audio response.\n\n\n\n* The Watson Swift SDK is available from the [swift-sdk repository](https:\/\/github.com\/watson-developer-cloud\/swift-sdk) in the watson-developer-cloud namespace on GitHub.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"},{"document_id":"ibmcld_02772-1628-3402","score":23.6414619312,"text":"\nFollowing registration, your users authenticate by using either the OAuth2 authorization code or resource owner password[authorization grant](https:\/\/datatracker.ietf.org\/doc\/html\/rfc6749section-1.3) flows to authenticate users.\n\n\n\n\n\n Dynamic client registration \n\n\n\n1. A user triggers a request by the client application to the App ID SDK.\n2. If your app is not registered as a mobile client yet, the SDK initiates a dynamic registration flow.\n3. On a successful registration, App ID returns your installation-specific client ID.\n\n\n\n\n\n\n\n Authorization flow \n\nZoom\n\n![App ID mobile request flow](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/mobile-flow.svg)\n\nFigure 1. App ID mobile request flow\n\n\n\n1. The App ID SDK starts the authorization process by using the App ID \/authorization endpoint.\n2. The login widget is displayed to the user.\n3. The user authenticates by using one of the configured identity providers.\n4. App ID returns an authorization grant.\n5. The authorization grant is exchanged for access, identity, and refresh tokens from the App ID \/token endpoint.\n\n\n\n\n\n\n\n\n\n Configuring your mobile app with the App ID SDKs \n\nGet started with the App ID SDKs.\n\n\n\n Before you begin \n\nYou need the following information:\n\n\n\n* An App ID instance\n* Your instance's tenant ID. This can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_10852-45155-46272","score":23.1347871889,"text":"\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)\n* [Invoking actions with mobile SDK from WhiskButton](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-actions-whiskbutton)\n\n\n\n\n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage)\n\n\n\n* [Packages for Object Storage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorageobstorage_packages)\n* [Setting up the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_ev)\n\n\n\n* [Prerequisites for working with the IBM Cloud Object Storage trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragecos_changes_pre)\n* [1. Assigning the Notifications Manager role to your Cloud Functions namespace](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_auth)\n* [2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02674-7-1766","score":23.0637532988,"text":"\nApp Configuration server SDK for Go \n\nApp Configuration service provides SDK to integrate with your Golang web and mobile applications, microservices, and distributed environments.\n\n\n\n Prerequisites \n\nFollowing is the prerequisite for using App Configuration service SDK for Go:\n\n\n\n* Go version 1.16 or later\n\n\n\n\n\n\n\n Integrating server SDK for Go \n\nThe v1.x.x versions of the App Configuration Go SDK have been retracted.\n\nApp Configuration service provides SDK to integrate with your Golang web and mobile applications, microservices, and distributed environments. You can evaluate the values of your property and feature flag by integrating the App Configuration SDK.\n\n\n\n1. Install the SDK by using the following code from the git repository.\n\ngo get -u github.com\/IBM\/appconfiguration-go-sdk@latest\n2. In your Golang microservice or application, include the SDK module with:\n\nimport (\nAppConfiguration \"github.com\/IBM\/appconfiguration-go-sdk\/lib\"\n)\n\nRun go mod tidy to download and install the new dependency and update your Go application's go.mod file.\n3. Initialize the SDK to connect with your App Configuration service instance.\n\ncollectionId := \"airlines-webapp\"\nenvironmentId := \"dev\"\n\nappConfiguration = AppConfiguration.GetInstance()\nappConfiguration.Init(\"region\", \"guid\", \"apikey\")\nappConfiguration.SetContext(\"collectionId\", \"environmentId\")\n\nWhere,\n\n\n\n* region: Region name where the service instance is created. Use AppConfiguration.REGION_US_SOUTH for Dallas, AppConfiguration.REGION_US_EAST for Washington DC, AppConfiguration.REGION_EU_GB for London, and AppConfiguration.REGION_AU_SYD for Sydney.\n* guid: Instance ID of the App Configuration service. Get it from the service credentials section of the App Configuration service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-golang"},{"document_id":"ibmcld_10817-6582-8092","score":22.9770005379,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-4213-5899","score":22.6985371222,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":32.1847021919,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-1426-3052","score":30.1208795346,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-43319-44485","score":29.5178399023,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10852-44214-45420","score":29.3681788882,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_04518-7-1743","score":29.3127326118,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_07551-14062-16080","score":25.4584421162,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_07551-15747-17355","score":25.3873156247,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10817-7-1802","score":24.3086518301,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12332-1034-2510","score":24.2028387847,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_13724-72779-74671","score":12.0956061993,"text":"\nThe customization interface includes a collection of new HTTP methods that have the names POST \/v1\/customizations, POST \/v1\/customizations\/{customization_id}, POST \/v1\/customizations\/{customization_id}\/words, and PUT \/v1\/customizations\/{customization_id}\/words\/{word}. The service also provides a new GET \/v1\/pronunciation method that returns the pronunciation for any word and a new GET \/v1\/voices\/{voice} method that returns detailed information about a specific voice. In addition, existing methods of the service's interface now accept custom model parameters as needed.\n\nFor more information about customization and its interface, see [Understanding customization](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customIntro) and the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\nThe customization interface is a beta release that currently supports US English only. All customization methods and the GET \/v1\/pronunciation method can currently be used to create and manipulate custom models and word translations only in US English.\n\nNew Brazilian Portuguese voice: pt-BR_IsabelaVoice\n: The service supports a new voice, pt-BR_IsabelaVoice, to synthesize audio in Brazilian Portuguese with a female voice. For more information, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile Software Development Kits (SDKs) are available for the speech services. The SDKs enable mobile applications to interact with both the Text to Speech and Speech to Text services. You can use the SDKs to send text to the Text to Speech service and receive an audio response.\n\n\n\n* The Watson Swift SDK is available from the [swift-sdk repository](https:\/\/github.com\/watson-developer-cloud\/swift-sdk) in the watson-developer-cloud namespace on GitHub.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6508205186,"ndcg_cut_10":0.798861474}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-2884-4620","score":13.1439127411,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_05262-9877-11808","score":12.7892701971,"text":"\nIf you created your app by using the app create command and you specified the --build-source option to build the container image from local or repository source, and you want to change your app to point to a different container image, you must first remove the association of the build from your app. For example, run ibmcloud ce application update -n APP_NAME --build-clear. After you remove the association of the build from your app, you can update the app to reference a different image.\n* If you are starting with source code that resides in a Git repository, you can choose to let Code Engine take care of building the image from your source and deploying the app with a single operation. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Deploying your app from repository source code](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-app-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you deploy your app.\n* If you are starting with source code that resides on a local workstation, you can choose to let Code Engine take care of building the image from your source and deploying the app with a single CLI command. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Deploying your app from local source code with the CLI](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-app-local-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you deploy your app.\n\nFor example, you might choose to let Code Engine handle the build of your local source while you evolve the development of your source for the app.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-app-local-source-code"},{"document_id":"ibmcld_05348-9343-11274","score":12.7892701971,"text":"\nIf you created your app by using the app create command and you specified the --build-source option to build the container image from local or repository source, and you want to change your app to point to a different container image, you must first remove the association of the build from your app. For example, run ibmcloud ce application update -n APP_NAME --build-clear. After you remove the association of the build from your app, you can update the app to reference a different image.\n* If you are starting with source code that resides in a Git repository, you can choose to let Code Engine take care of building the image from your source and deploying the app with a single operation. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Deploying your app from repository source code](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-app-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you deploy your app.\n* If you are starting with source code that resides on a local workstation, you can choose to let Code Engine take care of building the image from your source and deploying the app with a single CLI command. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Deploying your app from local source code with the CLI](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-app-local-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you deploy your app.\n\nFor example, you might choose to let Code Engine handle the build of your local source while you evolve the development of your source for the app.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-deploy-app-crimage"},{"document_id":"ibmcld_05349-8434-10365","score":12.7892701971,"text":"\nIf you created your app by using the app create command and you specified the --build-source option to build the container image from local or repository source, and you want to change your app to point to a different container image, you must first remove the association of the build from your app. For example, run ibmcloud ce application update -n APP_NAME --build-clear. After you remove the association of the build from your app, you can update the app to reference a different image.\n* If you are starting with source code that resides in a Git repository, you can choose to let Code Engine take care of building the image from your source and deploying the app with a single operation. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Deploying your app from repository source code](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-app-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you deploy your app.\n* If you are starting with source code that resides on a local workstation, you can choose to let Code Engine take care of building the image from your source and deploying the app with a single CLI command. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Deploying your app from local source code with the CLI](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-app-local-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you deploy your app.\n\nFor example, you might choose to let Code Engine handle the build of your local source while you evolve the development of your source for the app.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-deploy-app-private"},{"document_id":"ibmcld_05345-8896-10818","score":12.7426371396,"text":"\n* If you are starting with source code that resides in a Git repository, you can choose to let Code Engine take care of building the image from your source and creating (or updating) the job with a single operation. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating a job from repository source code](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-run-job-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n* If you are starting with source code that resides on a local workstation, you can choose to let Code Engine take care of building the image from your source and creating the job with a single CLI command. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating your job from local source code with the CLI](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-job-local-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n\n\n\nFor example, you might choose to let Code Engine handle the build of your local source while you evolve the development of your source for the job. Then, after the image is matured, you can update the job to reference the specific image that you want. You can repeat this process as needed.\n\nWhen you run your updated job, the latest version of your referenced container image is used for the job run, unless a tag is specified for the image. If a tag is specified for the image, then the tagged image is used for the job run.\n\n\n\nLooking for more code examples?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-create-job-crimage"},{"document_id":"ibmcld_05381-10648-12570","score":12.7426371396,"text":"\n* If you are starting with source code that resides in a Git repository, you can choose to let Code Engine take care of building the image from your source and creating (or updating) the job with a single operation. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating a job from repository source code](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-run-job-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n* If you are starting with source code that resides on a local workstation, you can choose to let Code Engine take care of building the image from your source and creating the job with a single CLI command. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating your job from local source code with the CLI](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-job-local-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n\n\n\nFor example, you might choose to let Code Engine handle the build of your local source while you evolve the development of your source for the job. Then, after the image is matured, you can update the job to reference the specific image that you want. You can repeat this process as needed.\n\nWhen you run your updated job, the latest version of your referenced container image is used for the job run, unless a tag is specified for the image. If a tag is specified for the image, then the tagged image is used for the job run.\n\n\n\nLooking for more code examples?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-job-local-source-code"},{"document_id":"ibmcld_05276-5947-7734","score":12.7258903879,"text":"\nWhen a job instance completes with a nonzero return code, Code Engine restarts the job instance. With Code Engine, you can specify to limit the number of retries to avoid restarting failed job instances.\n\n\n\n\n\n Running batch jobs \n\nWhether your code exists as source in a local file or in a Git repository, or your code is a container image that exists in a public or private registry, Code Engine provides a streamlined way for you to run your code as a job.\n\nYou can create and run batch jobs in Code Engine in the following ways:\n\n\n\n* Run an existing container image. Create a job and provide a reference to your image to use when you submit the job. For an example, see [Create and run a job](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-getting-startedfirst-job).\n* Start with source code. If you are starting with source code that is located in a Git repository or on your local workstation, you can point to the location of your source and Code Engine takes care of building the image for you. See [Create a job from repository source code](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-run-job-source-code) and [Create a job from local source code](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-job-local-source-code).\n\n\n\nFor more information, see [Working with jobs](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-job-plan).\n\n\n\n\n\n Scaling \n\nA job in Code Engine (batch job) consists of one or more job instances. While job instances run independent of each other, they run the same code. Suppose you have a database with 100 records to analyze. You can run your job such that each job instance analyzes 10 records each. For example, the first job instance analyzes records 0 - 9, the second job instance can analyze records 10 - 19, and so on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cebatchjobs"},{"document_id":"ibmcld_05344-6440-8274","score":12.7256176367,"text":"\nFor example, run ibmcloud ce job update -n JOB_NAME --build-clear. After you remove the association of the build from your job, you can update the job to reference a different image.\n* If you are starting with source code that resides in a Git repository, you can choose to let Code Engine take care of building the image from your source and creating (or updating) the job with a single operation. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating a job from repository source code](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-run-job-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n* If you are starting with source code that resides on a local workstation, you can choose to let Code Engine take care of building the image from your source and creating the job with a single CLI command. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating your job from local source code with the CLI](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-job-local-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n\n\n\nFor example, you might choose to let Code Engine handle the build of your local source while you evolve the development of your source for the job. Then, after the image is matured, you can update the job to reference the specific image that you want. You can repeat this process as needed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-create-job"},{"document_id":"ibmcld_05434-9714-11548","score":12.7256176367,"text":"\nFor example, run ibmcloud ce job update -n JOB_NAME --build-clear. After you remove the association of the build from your job, you can update the job to reference a different image.\n* If you are starting with source code that resides in a Git repository, you can choose to let Code Engine take care of building the image from your source and creating (or updating) the job with a single operation. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating a job from repository source code](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-run-job-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n* If you are starting with source code that resides on a local workstation, you can choose to let Code Engine take care of building the image from your source and creating the job with a single CLI command. In this scenario, Code Engine uploads your image to IBM Cloud\u00ae Container Registry. To learn more, see [Creating your job from local source code with the CLI](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-job-local-source-code). If you want more control over the build of your image, then you can choose to [build the image](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-build-image) with Code Engine before you create (or update) your job and run the job.\n\n\n\nFor example, you might choose to let Code Engine handle the build of your local source while you evolve the development of your source for the job. Then, after the image is matured, you can update the job to reference the specific image that you want. You can repeat this process as needed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-run-job-tutorial"},{"document_id":"ibmcld_05363-5023-6990","score":12.6397904995,"text":"\nMain: main()\n\nNow that your function is created from repository source code, you can update the function to meet your needs by using the [ibmcloud ce function update](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-function-update) command. If you want to update your source to use with your function, you must provide the --build-source option on the function update command.\n\nWhen your function is created from repository source code or from [local source](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-create-local) with the CLI, the resulting build run is not based on a build configuration. Build runs that complete are ultimately automatically deleted. Build runs that are not based on a build configuration are deleted after 1 hour if the build run is successful. If the build run is not successful, this build run is deleted after 24 hours. You can only display information about this build run with the CLI. You cannot view this build run in the console.\n\n\n\n Including dependencies for your Function \n\nYou can create Functions in many different programming languages. When your Function code grows complex, you can add code modules as dependencies for your Function. Each language has its own modules to use with your Function code. For example, Node.js dependencies are usually existing npm modules, whereas Python uses Python packages. These dependencies must be declared and created in a file with your source code\n\n\n\n Including modules for a Node.js Function \n\nCreate a function that includes a dependency for a specific Python module by creating a package.json file. In this case, both the source code and package file are located in the same folder.\n\n\n\n1. Create your source code by writing your code into a main.js file. For example, copy the following code example into a file called main.js.\n\nfunction main(args) {\nconst oneLinerJoke = require('one-liner-joke');\nlet getRandomJoke = oneLinerJoke.getRandomJoke();\n\nreturn {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-fun-create-repo"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14546-6172-8106","score":12.2735156748,"text":"\nMetric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges. You can view the charges on the IBM Cloud billing and usage view along with the usage and charges from all other IBM Cloud services.\n\nIn the IBM Cloud Usage view, locate the VMware Solutions service type. Locate the Organization plan to find the Veeam and Zerto usage across all virtual data centers in that organization. The virtual data center usage is located in a separate plan for either VMware Shared on-demand or VMware Shared Reserved.\n\nVeeam\n\nZerto\n\n\n\nTable 5. Licenses and fees for Veeam\n\n Metric Frequency Description \n\n MAX_VEEAM_LICENSES Monthly Veeam license charge for every VM under backup. The monthly charge is for the highest number of VMs under backup at any time period in the month. \n TOTAL_VEEAM_BLOCK_STORAGE_GB_HOURS Hourly Charge per GB of block storage used for all backups. \n TOTAL_VEEAM_OBJECT_STORAGE_GB_HOURS Hourly Charge per GB of object storage used for all backups. \n\n\n\nNo additional Veeam or Zerto usage charges for VMware Shared are incurred.\n\nFor the Veeam service, initially, all backups go to the block storage that is closest to their VM workloads. Backups that are a part of an inactive backup chain are immediately moved to Cloud Object Storage. The restore speed for these inactive backups might be impacted.\n\nYou can change how fast the inactive backup chains are moved to Cloud Object Storage by opening an IBM Cloud for VMware Solutions service ticket.\n\n\n\n\n\n Related links \n\n\n\n* [VMware Shared overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_13612-0-945","score":11.428265825,"text":"\n\n\n\n\n\n\n  Charge Metrics and Order consideration \n\n\n\n  Release Notes \n\n\n\n\n\n  Abstract \n\nBefore submitting an order, the following should be considered to ensure the order is 'right sized' and will meet the requirements of the client.\n\nImportant: Customers must purchase (or own) App Points for TRIRIGA Application Suite (TAS) prior to (or in conjunction with) ordering the IBM Managed Service. The managed service provides IBM Cloud based hosting, product installation, operation, maintenance and support for TAS.\n\nInformation should be gathered about the potential usage of the suite, including which applications will be required, how many users on each application and the primary usage of the applications.\n\nThere are three (3) TAS-MS part numbers:\n\nD02QTZX - Capacity\n\nD02QUZX - Data\n\nD02QWZX - VPC (Virtual Processor Core)\n\nFor additional information, please contact:\n\nPedro Echeverria [pedech@br.ibm.com](mailto:pedech@br.ibm.com)\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tas-ms?topic=tas-ms-charge-metrics"},{"document_id":"ibmcld_02775-4830-5961","score":11.4041497616,"text":"\nFor a complete list of the options and setup information, see [Advanced password management](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strengthcd-advanced-password). \n\n\n\nThese features are available only to those instances that are on the graduated tier pricing plan and that were created after 15 March 2018.\n\n\n\n\n\n When am I charged? \n\nYour first 1000 authentication events and 1000 authorized users per service instance are free of charge. You are charged monthly for any additional authentication events and authorized users, as well as any advanced security features that are enabled for each service instance.\n\n\n\n\n\n How do I stop getting charged for App ID? \n\nIf you no longer want to be charged for authentication events and authorized users, you need to ensure that no user can authenticate by using App ID. You must remove the App ID configuration from your app code or confirm that your users are not able to use the configuration to log in to your app. To stop getting charged for advance security features, you must disable them on the Manage Authentication > Authentication Settings page of the service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-pricing"},{"document_id":"ibmcld_03729-7-2197","score":10.9412523095,"text":"\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_04107-9120-10897","score":10.750000341,"text":"\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection \n\nCIS does not meter or bill for traffic that is blocked as part of DDoS mitigation, firewall, or rate limiting. Only requests that are passed through the CIS network to the origin destination incur charges or usage.\n\nCIS also helps keep egress bandwidth charges from your origin under control by only passing along good requests that the origin needs to respond to. All CIS plans offer unlimited and unmetered mitigation of DDoS attacks. You are never charged for attack traffic. There\u2019s no penalty for spikes due to attack traffic, so there's no chargeback by the customer.\n\n\n\n\n\n\n\n Reliability features \n\nZoom\n\n![reliability graphic](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/images\/reliability-graphic.png)\n\nFigure 2. Reliability features\n\n\n\n Global load balancing features \n\nThe global load balancing service distributes your traffic across multiple servers with a combination of origin pools, health checks, and a load balancer. Global load balancing has the following features:\n\n\n\n* Proxy and non-proxy options for load balancing\n* Origin pools and health checks\n\n\n\n\n\n Global anycast network \n\nThe available health check regions are based on the [Cloudflare Global Anycast Network](https:\/\/www.cloudflare.com\/network\/).\n\n\n\n\n\n\n\n DNS features \n\nDNS within CIS has the following features:\n\n\n\n* DNS management - Manage your DNS records, control proxying, and enable DNS security.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_03704-5798-7955","score":10.6949867509,"text":"\nFor more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.\n\nAn account that is invoiced in a currency other than US Dollars can't be converted to US Dollar invoicing.\n\n\n\n\n\n What is Business Continuity Insurance? \n\nBusiness Continuity Insurance is insurance that protects you from illegitimate charges against your servers. You can request this insurance through [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) to avoid overage charges if a documented network attack occurs against a covered server. IBM Cloud credits back any overages incurred on the affected server.\n\nTo receive the credits for illegitimate charges against your servers, contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and open a support case.\n\n\n\n\n\n What is the Service: Support and Services charge on my invoice? \n\nIf you create a VMWare cluster on your IBM Cloud account, you are charged for VMWare Level 2 Support for each cluster instance. This charge is in addition to any IBM Cloud Support charges for Premium or Advanced Support.\n\n\n\n\n\n What's the difference between promo codes and feature codes? \n\nPromo codes are for Pay-As-You-Go and Subscription accounts and give you limited-time credits toward your account and IBM Cloud products. The codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1047268-1049406","score":10.6949867509,"text":"\nFor more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.\n\nAn account that is invoiced in a currency other than US Dollars can't be converted to US Dollar invoicing.\n* What is Business Continuity Insurance?\n\nBusiness Continuity Insurance is insurance that protects you from illegitimate charges against your servers. You can request this insurance through [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) to avoid overage charges if a documented network attack occurs against a covered server. IBM Cloud credits back any overages incurred on the affected server.\n\nTo receive the credits for illegitimate charges against your servers, contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and open a support case.\n* What is the Service: Support and Services charge on my invoice?\n\nIf you create a VMWare cluster on your IBM Cloud account, you are charged for VMWare Level 2 Support for each cluster instance. This charge is in addition to any IBM Cloud Support charges for Premium or Advanced Support.\n* What's the difference between promo codes and feature codes?\n\nPromo codes are for Pay-As-You-Go and Subscription accounts and give you limited-time credits toward your account and IBM Cloud products. The codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1047139-1049277","score":10.6949867509,"text":"\nFor more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.\n\nAn account that is invoiced in a currency other than US Dollars can't be converted to US Dollar invoicing.\n* What is Business Continuity Insurance?\n\nBusiness Continuity Insurance is insurance that protects you from illegitimate charges against your servers. You can request this insurance through [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) to avoid overage charges if a documented network attack occurs against a covered server. IBM Cloud credits back any overages incurred on the affected server.\n\nTo receive the credits for illegitimate charges against your servers, contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and open a support case.\n* What is the Service: Support and Services charge on my invoice?\n\nIf you create a VMWare cluster on your IBM Cloud account, you are charged for VMWare Level 2 Support for each cluster instance. This charge is in addition to any IBM Cloud Support charges for Premium or Advanced Support.\n* What's the difference between promo codes and feature codes?\n\nPromo codes are for Pay-As-You-Go and Subscription accounts and give you limited-time credits toward your account and IBM Cloud products. The codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11408-1663-2873","score":10.4675406361,"text":"\nAll prices mentioned on this page are illustrative and do not represent the actual amounts used for billing. To calculate the exact pricing, use the [IBM cost estimator](https:\/\/cloud.ibm.com\/estimator).\n\n\n\nTable 2. Monthly LPAR charges\n\n Hours elapsed in a month Amount charged LPAR description \n\n 300 hours (300 hours x $0.343)\/month = $103 1 core, 8 GB memory, 150 GB disk, AIX \n 430 hours (430 hours x $0.465)\/month = $200 1 core, 16 GB memory, 150 GB disk, AIX \n 730 hours (Monthly Total) $103 + $200 = $303 (Monthly Total) 1 core, 16 GB memory, 150 GB disk, AIX \n\n\n\nIn this example, the LPAR resources are increased (after reaching 300 hours in the month) from 8 GB to 16 GB of memory. The price of the LPAR is prorated by the hour for the final monthly price of $303.\n\nFor detailed usage and billing information, you can refer to the part number in your invoice. The part numbers in the invoice represent the charge unit. Refer to the following table to view the part numbers and its corresponding description.\n\n\n\n Part number Description \n\n SOS_VIRTUAL_PROCESSOR_CORE_HOURS Scale out shared uncapped processor per core-hour \n SOD_VIRTUAL_PROCESSOR_CORE_HOURS Scale out dedicated processor per core-hour","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_07532-3613-6012","score":10.445737738,"text":"\nThe IBM Cloud push service has two components to pricing: a destination instance fee and a consumption price.\n\nA pre-production destination instance fee is charged monthly. Every pre-production destination added to your Event Notifications instance incurs the fee.\n\nConsumption: Only 500 devices or 5000 outbound digital messages is permitted per pre-production destination. If either the number of devices or the number of outbound digital messages exceeds the permitted limit, the permitted number of devices is moved by additional 500 devices or by additional 5000 messages and charged.\n\nFor example, if you tried to send 5001th message, the message cap automatically is raised to 10000 (another 5000 messages are added) for the month and the device cap is raised to 1000 (another 500 devices are added) per month. Notice that both limits are always raised even if only one cap has been exceeded.\n\n\n\n\n\n Push charges for changing from pre-production destination to production destination \n\nYou can change a pre-production destination to a production destination at any particular time and the charges are calculated accordingly.\n\nThe push service has two components to pricing: a destination instance fee and a consumption price.\n\nA pre-production destination instance fee is charged monthly. Every pre-production destination added to your Event Notifications instance incurs the fee.\n\nA production destination instance fee is also charged monthly and allows unlimited devices and outbound messages.\n\nIf you change a pre-production destination to a production destination, the charges for the transition month would be the pre-producdtion fee + pro-rated charge for the production instance.\n\nFor example, assume the pre-production instance fee is $15 per month and the production instance fee is $50 per month.\n\nThese prices are assumed for this example only. Current pricing may be different from the amounts shown in the example. See the Event Notifications catalog page for current pricing.\n\n\n\n* As of 31 July, you create a pre-production destination and does not register any devices or send messages, the charges for July will be $15.\n* As of 1 August, you register 500 devices and 5001 messages sent. The charges for August will be $30 (This is due to the message threshold exceeds the permitted limit.)\n* As of 5 August, you change from pre-production destination to production destination.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-destinations-push"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13455-24911-26512","score":17.2155480497,"text":"\n\"content-type\": \"audio\/l16;rate=22050\",\n\"interim_results\": true\n}\n<binary audio data>\n{\n\"action\": \"stop\"\n}\n* The service responds:\n\n{\"results\": [{\"alternatives\": {\"transcript\": \"name \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name may \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name may flour \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name the mayflower \",\n\"confidence\": 0.91}], \"final\": true}], \"result_index\": 0}\n{\"state\":\"listening\"}\n\n\n\n\n\n\n\n\n\n WebSocket return codes \n\nThe service can send the following return codes to the client over the WebSocket connection:\n\n\n\n* 1000 indicates normal closure of the connection, meaning that the purpose for which the connection was established has been fulfilled.\n* 1002 indicates that the service is closing the connection due to a protocol error.\n* 1006 indicates that the connection closed abnormally.\n* 1009 indicates that the frame size exceeded the 4 MB limit.\n* 1011 indicates that the service is terminating the connection because it encountered an unexpected condition that prevents it from fulfilling the request.\n\n\n\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_10863-7246-8495","score":16.8158594756,"text":"\n\/\/ returning the result here, makes sure that the top-most promise, we returned in main() returns the combined results of all\n\/\/ chained action invokes\n\n\/\/ since the result needs to be a valid JSON object, we cannot directly return the array, so we wrap it\nreturn {\naction_results: chained_action_results\n};\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\nconsole.log('Custom SEQUENCE with openwhisk-node-js-sdk FAILED');\n\n\/\/ This last throw is absolutely important to make the top-most promise, which we initially returned at the\n\/\/ top of the main() function REJECTS with the given error. If we did not throw here, it would still RESOLVE\n\/\/ even though the code herein failed.\nthrow error;\n});\n}\nShow more\n6. Click Save.\n7. Test your action by clicking Invoke and waiting for the following output to display.\n\nExample output\n\nResults:\n{\n\"action_results\": [\n{\n\"cos_message\": \"SUCCESS\"\n},\n{\n\"cloudant_result\": \"SUCCESS\"\n},\n{\n\"cos_message\": \"SUCCESS\"\n}\n]\n}\n\nLogs:\n[\n\"2020-04-17T04:31:20.965176Z stdout: Building custom sequence, using openwhisk node-js SDK...\",\n\"2020-04-17T04:31:31.670466Z stdout: Result from cos-access {\"cos_message\":\"SUCCESS\"}\",\n\"2020-04-17T04:31:31.670501Z stdout: Now invoking db-access...\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_10817-5370-6915","score":16.0893775635,"text":"\nTo fire a remote trigger, you can call the fireTrigger method, and pass in parameters as needed by using a dictionary.\n\n\/\/ In this example we are firing a trigger when our location has changed by a certain amount\nvar locationParams = Dictionary<String, String>()\nlocationParams[\"payload\"] = \"{\"lat\":41.27093, \"lon\":-73.77763}\"\ndo {\ntry whisk.fireTrigger(name: \"locationChanged\", package: \"mypackage\", namespace: \"mynamespace\", parameters: locationParams, callback: {(reply, error) -> Void in\nif let error = error {\nprint(\"Error firing trigger (error.localizedDescription)\")\n} else {\nprint(\"Trigger fired!\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nIn the previous example, you are firing a trigger that is called locationChanged.\n\n\n\n\n\n Use mobile SDK actions that return a result \n\nIf the action returns a result, set hasResult to true in the invokeAction call. The result of the action is returned in the reply dictionary, for example:\n\ndo {\ntry whisk.invokeAction(name: \"actionWithResult\", package: \"mypackage\", namespace: \"mynamespace\", parameters: params, hasResult: true, callback: {(reply, error) -> Void in\nif let error = error {\n\/\/do something\nprint(\"Error invoking Action (error.localizedDescription)\")\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10859-0-1629","score":15.8877503626,"text":"\n\n\n\n\n\n\n  Action terminates after one minute \n\n  What\u2019s happening \n\nYou are invoking an action that returns after one min with an http code 202 and the result is only showing the activation ID.\n\n  Why it\u2019s happening \n\nWhen invoking an action, there are two modes possible: blocking or non-blocking. The default for regular action invocations is non-blocking and for web actions, it is blocking. Blocking invocations use a request-response style and wait for the activation result to be available. The wait period is the lesser of 60 seconds or the action's timeout limit. At the end of the wait period (for example, after 60 sec), all invocations switch to non-blocking and instead of the result, these actions return the activation ID.\n\nThe following example shows possible output.\n\n{\n\"activationId\": \"27eca80056d54f93aca80056d5cf93b9\"\n}\n\nIf an invocation of a web action reaches the end of wait period, the response shows both the activation ID and the transaction ID as well as an indication that the request is returned, but the action continues to run.\n\nThe following example shows possible output.\n\n{\n\"activationId\": \"d13cfd3ce4b14f7cbcfd3ce4b11f7cce\",\n\"code\": \"42c15dc7f450df1e9a01104de158d489\",\n\"error\": \"Response not yet ready.\"\n}\n\n  How to fix it \n\nWith the activation ID, you can poll for the completion of the action and the result. For more information, see [CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-clicli_activation).\n\nFor more information about blocking actions, see [Testing blocking actions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-testtest-block).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-ts_action_terminated"},{"document_id":"ibmcld_10863-6347-7636","score":15.6373740101,"text":"\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {\nconsole.log('Result from db-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Now invoking cos-access...');\n\nreturn ow.actions.invoke({\nname: 'action-tutorial\/cos-access',\nblocking: true,\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {\nconsole.log('Result from cos-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Custom SEQUENCE with openwhisk-node-js-sdk completed.');\n\n\/\/ returning the result here, makes sure that the top-most promise, we returned in main() returns the combined results of all\n\/\/ chained action invokes\n\n\/\/ since the result needs to be a valid JSON object, we cannot directly return the array, so we wrap it\nreturn {\naction_results: chained_action_results\n};\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_12880-0-1003","score":15.4806898295,"text":"\n\n\n\n\n\n\n  Why can't I view any usage or rewards details in Partner Center? \n\nIf you can't view usage and rewards details in an account that you've been added to, you might not have the correct IAM access.\n\n  What\u2019s happening \n\nWhen you're working in an IBM Cloud\u00ae account that you've been added to, you can't view or access details about usage or rewards in Partner Center. Specifically, the chart on the Usage and offers page doesn't display any data. And, the following error message is displayed in the Your rewards section.\n\n> Oops! Your incentives details are currently unavailable.\n\n  Why it\u2019s happening \n\nBy default, only account owners can view usage and rewards details. For users of an account to view this information, specific IAM access is required: [viewer role on the Billing service](https:\/\/cloud.ibm.com\/docs\/sell?topic=account-account-servicespc-buildgrow-account-management).\n\n  How to fix it \n\nContact your account owner and request viewer access to usage and rewards details.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-ts-view-usage"},{"document_id":"ibmcld_10863-4041-5570","score":15.469463544,"text":"\nresolve({ cloudant_result: 'SUCCESS' });\n}, 5000);\n});\n}\nShow more\n6. Click Save.\n7. Test your action by clicking Invoke and waiting for the following output to display.\n\nExample output\n\nResults:\n{\n\"cloudant_result\": \"SUCCESS\"\n}\n\nLogs:\n[\n\"2020-04-21T01:53:36.739565Z stdout: fake db access done. Resolving Promise...\"\n]\n\n\n\n\n\nYour db-access action is ready!\n\n\n\n\n\n Step 3: Create the ow-sdk-action actionow-sdk-action action \n\nThe ow-sdk-action action is a Node.js program that calls the other two actions: cos-access and db-access. When invoked, the ow-sdk-action action code acts as a custom sequence, first calling cos-access, then db-access, and finally cos-access again. The results of each action are stored in a variable that is called chained_action_results, which is then returned at the end. When the action is invoked, follow the code comments to see what is happening.\n\n\n\n1. From the Actions page, create a third action called ow-sdk-action.\n\n\n\n1. Name your action ow-sdk-action.\n2. Select the action-tutorial package.\n3. Select Node.js 10 for the runtime.\n4. Click Create.\n5. Paste in the following code example:\n\n\/\n* main() will be run when you invoke this action\n* @param Cloud Functions actions accept a single parameter, which must be a JSON object.\n* @return The output of this action, which must be a JSON object.\n\/\nconst openwhisk = require('openwhisk');\nconst ow = openwhisk();\n\nfunction main(params) {\n\/\/ for demonstration purposes, we keep track of the individual results of each action that we invoke in our","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_02680-6103-7532","score":15.4542947461,"text":"\nval result = feature.getCurrentValue(entityId, entityAttributes) as JSONObject\nresult.get(\"key\") \/\/ returns the value of the key\n}\n\nval feature: Feature? = appConfiguration.getFeature(\"yaml-feature\")\nfeature.getFeatureDataType(); \/\/ STRING\nfeature.getFeatureDataFormat(); \/\/ YAML\nfeature.getCurrentValue(entityId, entityAttributes); \/\/ returns the stringified yaml (check Table 1)\n\n\n\n\n\n Property \n\nval property: Property? = appConfiguration.getProperty(\"json-property\")\nproperty.getPropertyDataType(); \/\/ STRING\nproperty.getPropertyDataFormat(); \/\/ JSON\n\n\/\/ Example below (traversing the returned JSONObject)\nif (property != null) {\nval result = property.getCurrentValue(entityId, entityAttributes) as JSONObject\nresult.get(\"key\") \/\/ returns the value of the key\n}\n\nval property: Property? = appConfiguration.getProperty(\"yaml-property\")\nproperty.getPropertyDataType(); \/\/ STRING\nproperty.getPropertyDataFormat(); \/\/ YAML\nproperty.getCurrentValue(entityId, entityAttributes); \/\/ returns the stringified yaml (check above Table 1)\n\n\n\n* Force fetch the configurations from server.\n\nappConfiguration.fetchConfigurations()\n\n\n\n\n\n\n\n\n\n\n\n Integrating client SDK for Android app written in Java \n\nApp Configuration service provides Android client SDK to integrate with your Android application. You can evaluate the values of your property and feature flag by integrating the SDK.\n\n\n\n1. Install the SDK by using either one of the options:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android"},{"document_id":"ibmcld_13499-51863-53314","score":15.0406127092,"text":"\n1.0\n\n\n\n\n\n sin \n\nsin(expr)\n: Returns the sine of expr.\n: Example of an SQL function usage fragment\n\n> SELECT sin(0)\n: Result value\n\n0.0\n\n\n\n\n\n sinh \n\nsinh(expr)\n: Returns the hyperbolic sine of expr.\n: Example of an SQL function usage fragment\n\n> SELECT sinh(0)\n: Result value\n\n0.0\n\n\n\n\n\n size \n\nsize(expr)\n: Returns the size of an array or a map. Returns -1 if null.\n: Example of an SQL function usage fragment\n\n> SELECT size(array('b', 'd', 'c', 'a'))\n: Result value\n\n4\n\n\n\n\n\n skewness \n\nskewness(expr)\n: Returns the skewness value that is calculated from values of a group.\n\n\n\n\n\n smallint \n\nsmallint(expr)\n: Casts the value expr to the target data type smallint.\n\n\n\n\n\n sort_array \n\nsort_array(array[, ascendingOrder])\n: Sorts the input array in ascending or descending order according to the natural ordering of the array elements.\n: Example of an SQL function usage fragment\n\n> SELECT sort_array(array('b', 'd', 'c', 'a'), true)\n: Result value\n\n[\"a\",\"b\",\"c\",\"d\"]\n\n\n\n\n\n soundex \n\nsoundex(str)\n: Returns Soundex code of the string.\n: Example of an SQL function usage fragment\n\n> SELECT soundex('Miller')\n: Result value\n\nM460\n\n\n\n\n\n space \n\nspace(n)\n: Returns a string that consists of n spaces.\n: Example of an SQL function usage fragment\n\n> SELECT concat(space(2), '1')\n: Result value\n\n1\n\n\n\n\n\n spark_partition_id \n\nspark_partition_id()\n: Returns the current partition ID.\n\n\n\n\n\n split \n\nsplit(str, regex)\n: Splits str around occurrences that match regex.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sqlfunctions"},{"document_id":"ibmcld_10863-5217-6577","score":15.0170536867,"text":"\n* @param Cloud Functions actions accept a single parameter, which must be a JSON object.\n* @return The output of this action, which must be a JSON object.\n\/\nconst openwhisk = require('openwhisk');\nconst ow = openwhisk();\n\nfunction main(params) {\n\/\/ for demonstration purposes, we keep track of the individual results of each action that we invoke in our\n\/\/ custom sequence and return it in the last step of the sequence as the overall action result.\n\n\/\/ Although the following .then() blocks are run asynchronously, the main() function acts as a closure that\n\/\/ makes sure that the chained_action_results variable is accessible for all .then() blocks\nconst chained_action_results = [];\n\nconsole.log('Building custom sequence, using openwhisk node-js SDK...');\nreturn ow.actions.invoke({\nname: 'action-tutorial\/cos-access',\nblocking: true,\nresult: true,\nparams: {}\n})\n.then((result) => {\nconsole.log('Result from cos-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Now invoking db-access...');\n\nreturn ow.actions.invoke({\nname: 'action-tutorial\/db-access',\nblocking: true,\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.510955994}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07549-19143-21543","score":11.3684121745,"text":"\nThe information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.If you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information. But this requirement does not apply if neither you nor any third party retains the ability to install modified object code on the User Product (for example, the work has been installed in ROM).The requirement to provide Installation Information does not include a requirement to continue to provide support service, warranty, or updates for a work that has been modified or installed by the recipient, or for the User Product in which it has been modified or installed. Access to a network may be denied when the modification itself materially and adversely affects the operation of the network or violates the rules and protocols for communication across the network.Corresponding Source conveyed, and Installation Information provided, in accord with this section must be in a format that is publicly documented (and with an implementation available to the public in source code form), and must require no special password or key for unpacking, reading or copying.<-- <\/section \"id=\"section-en-notice-non-source\" \"> --><-- <section \"id=\"section-en-notice-add-term\" \"> --> 7. Additional Terms \"Additional permissions\" are terms that supplement the terms of this License by making exceptions from one or more of its conditions. Additional permissions that are applicable to the entire Program shall be treated as though they were included in this License, to the extent that they are valid under applicable law. If additional permissions apply only to part of the Program, that part may be used separately under those permissions, but the entire Program remains governed by this License without regard to the additional permissions.When you convey a copy of a covered work, you may at your option remove any additional permissions from that copy, or from any part of it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-notices"},{"document_id":"ibmcld_10817-6582-8092","score":10.9935237043,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07549-17189-19772","score":10.3726078294,"text":"\nIf the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source. Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements.e) Convey the object code using peer-to-peer transmission, provided you inform other peers where the object code and Corresponding Source of the work are being offered to the general public at no charge under subsection 6d. A separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work.A \"User Product\" is either (1) a \"consumer product\", which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling. In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage. For a particular product received by a particular user, \"normally used\" refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product. A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product.\"Installation Information\" for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source. The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.If you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-notices"},{"document_id":"ibmcld_07161-6156-7991","score":10.3125143288,"text":"\n* On systems such as Ubuntu and Debian that use deb packages, use a command such as the following: dpkg -i \/full\/path\/to\/deb\/package\/deb-file-name\n* The Crawler scripts are installed into {installation directory}\/bin; for example, \/opt\/ibm\/crawler\/bin. Ensure that {installation_directory}\/bin is in your PATH environment variable for the Crawler commands to work correctly.\n\n\n\nCrawler scripts are also installed to \/usr\/local\/bin, so this can be added to your PATH environment variable as well.\n\n\n\n\n\n\n\n Create your working directory \n\nCopy the contents of the {installation_directory}\/share\/examples\/config directory to a working directory on your system, for example \/home\/config.\n\nDo not modify the provided configuration example files directly. Copy and then edit them. If you edit the example files in-place, your configuration might be overwritten when upgrading the Data Crawler, or it might be removed when uninstalling it.\n\nReferences in this guide to files in the config directory, such as config\/crawler.conf, refer to that file in your working directory, not in the installed {installation_directory}\/share\/examples\/config directory.\n\n\n\n\n\n Configure crawl options \n\nTo set up the Data Crawler to crawl your repository, you must specify which local system files you want to crawl, and which Discovery instance to send the collection of crawled files to after the crawl finishes.\n\n\n\n1. filesystem-seed.conf - Open the seeds\/filesystem-seed.con file in a text editor. Modify the value attribute directly under the name-\"url\" attribute to the file path that you want to crawl. For example: value-\"sdk-fs:\/\/\/TMP\/MY_TEST_DATA\/\"\n\nThe URLs must start with sdk-fs:\/\/. So to crawl, for example, \/home\/watson\/mydocs, the value of this URL is sdk-fs:\/\/\/home\/watson\/mydocs. The third \/ in the URL is necessary.\n\nSave and close the file.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-getting-started-with-the-data-crawler"},{"document_id":"ibmcld_16261-5514-7459","score":10.1578768488,"text":"\nThe Watson SDKs for other languages provide equivalent mechanisms for instantiating a service object.\n\nAfter creating the service object, we use it to send a message to the assistant, using the stateless message method. In this example, the message is empty; we just want to trigger the Greet customer action to start the conversation, so we don't need any input text. We then print any text responses returned in the generic array in the returned output.\n\nUse the node <filename.js> command to run the example application.\n\nUse the python3 <filename.py> command to run the example application.\n\nNote: Make sure you have installed the Watson SDK for Node.js using npm install ibm-watson.\n\nNote: Make sure you have installed the Watson SDK for Python using pip install --upgrade ibm-watson or easy_install --upgrade ibm-watson.\n\nAssuming everything works as expected, the assistant returns the output from the assistant, which the app then prints to the console:\n\nWelcome to the Watson Assistant example. What's your name?\n\nThis output tells us that we have successfully communicated with the assistant and received the greeting message specified by the Greet customer action. But we don't yet have a way of responding to the assistant's question.\n\n\n\n\n\n Processing user input \n\nTo be able to process user input, we need to add a user interface to our client application. For this example, we'll keep things simple and use standard input and output. We can use the Node.js prompt-sync module to do this. (You can install prompt-sync using npm install prompt-sync.) We can use the Python 3 input function to do this.\n\n\n\n* Python\n* Node\n\n\n\n Example 2: Adds user input.\n\nfrom ibm_watson import AssistantV2\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n\n Create Assistant service object.\nauthenticator = IAMAuthenticator('{apikey}') replace with API key\nassistant = AssistantV2(\nversion = '2021-11-27',\nauthenticator = authenticator\n)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_00580-33278-35323","score":9.5197275357,"text":"\nSo far, our API interactions were triggered by the dashboard or by using curl from the command line. In the following section, we see how IBM Cloudant is accessed programmatically.\n\nThe examples use Node.js, so if you want to try the code yourself, you need to install node and npm from nodejs.org.\n\nWe can then install the official IBM Cloudant Node.js library with npm install @cloudant\/cloudant. (Npm is the package manager that comes with Node.js - allowing you to access thousands of open source projects and build them into your application for free).\n\nOnce the IBM Cloudant library is installed, we can build some source code. Let's go through this code snippet line-by line:\n\nThe IBM Cloudant service URL is gleaned from the environment variable that we created earlier.\n\nThe @cloudant\/cloudant library is loaded into your Node.js app with the built-in required functions. We then create an instance of the library that is configured with the credentials we stored in the first line. We use the IBM Cloudant object to get a reference to the books database and store it in a variable database. We haven't made any API calls - only created data structures that store credentials and which database that we are working on. The main function calls db.list, which maps 1-1 with the _all_docs endpoint we saw earlier. The parameters passed to db.list must be familiar as the options that _all_docs expects to limit the result set and to return document bodies for each ID.\n\nSee another code snippet that writes a document.\n\nYou can see from the first line that standard JavaScript objects can be used in your code and sent to IBM Cloudant with no conversion, as they turn into JSON natively in JavaScript.\n\nWriting a document is simply a matter of calling db.insert, which maps to a PUT\/POST API call or to _bulk_docs.\n\nTo summarize, the official libraries for IBM Cloudant are Java\u2122, Python, and Nodejs. They are thin wrappers around the IBM Cloudant HTTP API - so it's worth understanding the underlying API to understand all the parameters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_14512-24543-25722","score":9.3926347638,"text":"\nFor more information, see [Add a logical switch](https:\/\/docs.vmware.com\/en\/VMware-NSX-Data-Center-for-vSphere\/6.4\/com.vmware.nsx.install.doc\/GUID-DD31D6BC-2E56-4E91-B45F-FCA3E80FF786.html). \n Add a DLR A Distributed Logical Router (DLR) is a virtual appliance that routes between connected logical switches (East-West traffic). For more information, see [Add a Distributed Logical Router](https:\/\/docs.vmware.com\/en\/VMware-NSX-Data-Center-for-vSphere\/6.4\/com.vmware.nsx.install.doc\/GUID-E825C0C7-F4CC-4B26-90AF-A2167AC519DB.html). \n Add an ESG An External Services Gateway (ESG) is a virtual appliance that routes between the physical network and the logical network (North-South traffic). For more information, see [Add an Edge Services Gateway](https:\/\/docs.vmware.com\/en\/VMware-NSX-Data-Center-for-vSphere\/6.4\/com.vmware.nsx.install.doc\/GUID-B9A97F20-4996-4E16-822C-0B98DDE70571.html). \n Configure NSX edge firewall rules An edge firewall monitors North-South traffic to provide perimeter security functions, including firewall, Network Address Translation (NAT), and site-to-site IPsec and SSL VPN. Only the firewall rules on management and uplink interfaces are applicable.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsprocs-configure"},{"document_id":"ibmcld_07705-0-1395","score":9.3812461323,"text":"\n\n\n\n\n\n\n  CM-11 - User-installed Software \n\n\n\n  Control requirements \n\nThe organization:\n\nCM-11 (a)\n:   Establishes [Assignment: organization-defined policies] governing the installation of software by users;\n\nCM-11 (b)\n:   Enforces software installation policies through [Assignment: organization-defined methods]; and\n\nCM-11 (c)\n:   Monitors policy compliance at [IBM Assignment: continuously].\n\n\n\n\n\n  NIST supplemental guidance \n\nIf provided the necessary privileges, users have the ability to install software in organizational information systems. To maintain control over the types of software installed, organizations identify permitted and prohibited actions regarding software installation. Permitted software installations may include, for example, updates and security patches to existing software and downloading applications from organization-approved \u201capp stores\u201d Prohibited software installations may include, for example, software with unknown or suspect pedigrees or software that organizations consider potentially malicious. The policies organizations select governing user-installed software may be organization-developed or provided by some external entity. Policy enforcement methods include procedural methods (e.g., periodic examination of user accounts), automated methods (e.g., configuration settings implemented on organizational information systems), or both.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-cm-11"},{"document_id":"ibmcld_07863-0-2804","score":9.3400172225,"text":"\n\n\n\n\n\n\n  SA-5 - Information System Documentation \n\n\n\n  Control requirements \n\nThe organization:\n\nSA-5 (a)\n:   Obtains administrator documentation for the information system, system component, or information system service that describes:\n\n\n\n1.  Secure configuration, installation, and operation of the system, component, or service;\n2.  Effective use and maintenance of security functions\/mechanisms; and\n3.  Known vulnerabilities regarding configuration and use of administrative (i.e., privileged) functions;\n\n\n\nSA-5 (b)\n:   Obtains user documentation for the information system, system component, or information system service that describes:\n\n\n\n1.  User-accessible security functions\/mechanisms and how to effectively use those security functions\/mechanisms;\n2.  Methods for user interaction, which enables individuals to use the system, component, or service in a more secure manner; and\n3.  User responsibilities in maintaining the security of the system, component, or service;\n\n\n\nSA-5 (c)\n:   Documents attempts to obtain information system, system component, or information system service documentation when such documentation is either unavailable or nonexistent and takes [Assignment: organization-defined actions] in response;\n\nSA-5 (d)\n:   Protects documentation as required, in accordance with the risk management strategy; and\n\nSA-5 (e)\n:   Distributes documentation to [Assignment: organization-defined personnel or roles].\n\n\n\n\n\n  NIST supplemental guidance \n\nThis control helps organizational personnel understand the implementation and operation of security controls associated with information systems, system components, and information system services. Organizations consider establishing specific measures to determine the quality\/completeness of the content provided. The inability to obtain needed documentation may occur, for example, due to the age of the information system\/component or lack of support from developers and contractors. In those situations, organizations may need to recreate selected documentation if such documentation is essential to the effective implementation or operation of security controls. The level of protection provided for selected information system, component, or service documentation is commensurate with the security category or classification of the system. For example, documentation associated with a key DoD weapons system or command and control system would typically require a higher level of protection than a routine administrative system. Documentation that addresses information system vulnerabilities may also require an increased level of protection. Secure operation of the information system, includes, for example, initially starting the system and resuming secure system operation after any lapse in system operation.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-sa-5"},{"document_id":"ibmcld_14129-3371-5555","score":9.2831552616,"text":"\nvzpkgcache Update a set of preinstalled container archives after new template installation. \n\n\n\n\n\n\n\n Supplementary tools \n\nSupplementary tools are used for miscellaneous tasks in the hardware node and container context.\n\n\n\nTable 6. Supplemental tools\n\n Supplementary Tools \n\n vzup2date Utility to update your Virtuozzo software and templates. \n vzup2date-mirror Utility to create local mirrors of the Virtuozzo official repository. \n vzfsutil Utility for the VZFS optimization and consistency checking. \n vzcache Utility to gain extra disk space by caching the files identical in different containers. \n vzsveinstall Utility to create the Service Container on the Hardware Node. \n vzsveupgrade Utility to update the packages inside the Service Container. \n vzps Utility working as the standard ps and htop utilities, with container-related functions added. \n vztop Utility working as the standard ps and htop utilities, with container-related functions added. \n vzsetxinetd Utility to switch some services between stand-alone mode and xinetddependent mode. \n vzdqcheck Print file space current usage from quota\u2019s point of view. \n vzdqdump Utility to dump the Container user or group quota limits and grace times from the kernel or the quota file or for loading them to a quota file. \n vzdqload Utility to dump the Container user or group quota limits and grace times from the kernel or the quota file or for loading them to a quota file. \n vznetstat Utility that prints network traffic usage statistic by containers. \n vzcpucheck Utility for checking CPU usage by containers. \n vzmemcheck Utility for checking the hardware node and container current memory parameters. \n vzcalc Utility to calculate resource usage by a container. \n vzcheckovr Utility to check the current system overcommitment and safety of the total resource control settings. \n vzstat Utility to monitor the hardware node and container resources consumption in real time. \n vzpid Utility that prints container ID that the process belongs to. \n vzsplit Utility to generate container configuration file sample, \u201csplitting\u201d the hardware node into equal parts. \n vzcfgscale Utility to scale the container configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-parallels-virtuozzo-containers-4-0-quick-reference-guide"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13160-14797-16607","score":31.7171376797,"text":"\nEnd the action under And then.\n13. Create a new step with the condition for 8 Ran successfully being false. Use something like It seems there was a problem creating the new event record for the Assistant to say and end the action under And then. Save and close the action with the icons in the upper right.\n14. Test the new action by clicking on Preview on the left and using the webchat. Type add new event and submit. When prompted by the bot, enter my conference as name, home office as location, pick dates for begin and end, and use [http:\/\/localhost](http:\/\/localhost) as URL. Thereafter, confirm that the data is correct.\n\n\n\nWhen creating a chatbot, you may want to [publish a chatbot](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish). It is the controlled release of a version which allows rolling back changes and to continue with development without impacting the chatbot interacting with real customers.\n\n\n\n\n\n Step 6: Integrate with Slack \n\nNow, you will integrate the chatbot with Slack.\n\n\n\n1. On the lower left, click on Integrations.\n2. In the integrations overview, in the section Channels, locate Slack and click Add.\n3. Follow the step by step instructions to integrate the Draft environment of your chatbot with Slack. More information about it is available in the topic [Integrating with Slack](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-slack).\n4. Once done, open up your Slack workspace. Begin a direct chat with the bot and say show me event details. Then, similar to above, answer with Think when prompted for an event name.\n\n\n\nZoom\n\n![Slack with the eventbot](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution19\/Slackbot_event.png)\n\nSlack with the eventbot","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"},{"document_id":"ibmcld_16324-3229-5312","score":30.6824024222,"text":"\nChoose a narrow set of user goals first. If you start small and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. After your assistant is live, the built-in metrics of active user conversations help you understand what your customers are asking about, how well your assistant is able to meet their needs, and what to focus on next.\n\n\n\n\n\n 3. Choose the tone and language of your assistant \n\nBefore you build your assistant, it can also be helpful to choose the tone with which your assistant communicates. Is your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Write conversations that reflect your assistant's personality. Don't overdo it by sacrificing usability for the sake of keeping your assistant in character. Strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe that the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chatbots to identify themselves as chatbots.\n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-language-support).\n\n\n\n\n\n 4. Connect to content sources \n\nThe answer to common questions might already be documented somewhere in your organization's technical information. Plan whether you want to connect the assistant to existing content sources by taking an inventory of relevant help content (for example, product information, knowledge articles, FAQs) available to your customers.\n\nYou can give your assistant access to this information by adding a [search integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-add) to your assistant. The search integration uses IBM Watson\u00ae Discovery to return smart answers to natural language questions.\n\n\n\n\n\n 5. Plan your handoff strategy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-plan-assistant"},{"document_id":"ibmcld_09228-1610-2667","score":30.5513439053,"text":"\n* [View on GitHub](https:\/\/github.com\/with-watson\/multilingual-chatbot)\n* [Try the demo](https:\/\/multilingual-chatbot.mybluemix.net\/)\n* [Read more](https:\/\/medium.com\/ibm-watson\/build-multilingual-chatbots-with-watson-language-translator-watson-assistant-8c38247e8af1)\n\n\n\n\n\n\n\n Real-time translation (Node.js) \n\nBy using Node.js and React components, you can create a web app that can be your personal translator. The app uses Watson Speech to Text, Watson Language Translator, and Watson Text to Speech services to transcribe, translate, and synthesize from your microphone to your headphones.\n\n\n\n* [Code Pattern](https:\/\/developer.ibm.com\/components\/watson-apis\/patterns\/build-a-real-time-translation-service-with-watson-api-kit)\n* [View on GitHub](https:\/\/github.com\/ibm\/watson-speech-translator)\n\n\n\n\n\n\n\n Korean Character Recognition (TensorFlow, Android) \n\nThis mobile application uses TensorFlow and Language Translator to recognize and translate handwritten Korean characters.\n\n\n\n* [View on GitHub](https:\/\/github.com\/IBM\/tensorflow-hangul-recognition)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-sample-apps"},{"document_id":"ibmcld_07148-7-2060","score":30.5106180178,"text":"\nUsing the COVID-19 kit \n\nThe COVID-19 kit is a special collection available in US instances of IBM Watson\u2122 Discovery. This pre-built collection includes more than 10 data sources you can use to fuel a dynamic chatbot built with IBM Watson\u2122 Assistant and Discovery to answer your customers' questions about COVID-19.\n\nFAQ extraction is a beta feature that was used to create question and answer pairs for the kit. The FAQ extraction beta feature is now deprecated and will stop being supported in v1 Discovery service instances on 1 March 2022. As a consequence, the COVID-19 kit data collection will stop being supported also.\n\nThe COVID-19 kit extracts answers from trusted sources and automatically updates your chatbot as the content from those sources are updated. It uses FAQ extraction machine learning models developed by IBM Research labs to extract question\/answer pairs. The kit is pre-configured with web crawl seeds from trusted sources such as the CDC, Harvard, and the United States Department of Labor. An expanded stopwords list and query expansions are also included in this collection to improve search results. It is designed to be augmented with your own data and customized to your needs.\n\nFor more information about this kit, and how you can create a chatbot and connect it to a data source with the IBM Watson\u2122 Assistant search skill using IBM Watson\u2122 Assistant and Discovery, see [COVID-19 \u2014 Are Your Virtual Assistant\u2019s Answers Up-To-Date?](https:\/\/medium.com\/ibm-watson\/covid-19-are-your-virtual-assistants-answers-up-to-date-c9e1ba70eb65654b).\n\nTo learn how to create a search skill in Watson Assistant, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add). (This feature is available only to Watson Assistant Plus or Premium plan users.)\n\nSee the following to learn more about working with Discovery:\n\n\n\n* To learn how to create a service instance, see [Getting started with the Discovery tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-getting-started).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-covidkit"},{"document_id":"ibmcld_09228-7-1878","score":30.486214979,"text":"\nSample apps \n\nIBM is announcing the deprecation of the IBM Watson\u00ae Language Translator service for IBM Cloud\u00ae in all regions. As of 10 June 2023, the Language Translator tile will be removed from the IBM Cloud Platform for new customers; only existing customers will be able to access the product. As of 10 June 2024, the service will reach its End of Support date. As of 10 December 2024, the service will be withdrawn entirely and will no longer be available to any customers.\n\nCheck out the following sample applications to see what you can build with Language Translator.\n\nThese systems are for demonstration purposes only and are not intended to process Personal Data. No Personal Data is to be entered into these systems as they may not have the necessary controls in place to meet the requirements of the General Data Protection Regulation (EU) 2016\/679.\n\n\n\n Snap and translate text in images (Node.js) \n\nThis sample app explains how to create a hybrid mobile app that uses Watson Language Translator and Tesseract OCR. With this sample app you can capture an image, extract the text, and translate that text.\n\n\n\n* [Read the blog](https:\/\/developer.ibm.com\/announcements\/snap-translate-using-tesseract-ocr-watson-language-translator\/)\n* [Code Pattern](https:\/\/developer.ibm.com\/patterns\/snap-translate-using-tesseract-ocr-watson-language-translator\/)\n* [View on GitHub](https:\/\/github.com\/IBM\/snap-and-translate)\n\n\n\n\n\n\n\n Multilingual Chatbot (Node.js, Python) \n\nThis chatbot that is built with Watson Assistant and Cloud Functions adds support for multiple languages with Language Translator.\n\n\n\n* [View on GitHub](https:\/\/github.com\/with-watson\/multilingual-chatbot)\n* [Try the demo](https:\/\/multilingual-chatbot.mybluemix.net\/)\n* [Read more](https:\/\/medium.com\/ibm-watson\/build-multilingual-chatbots-with-watson-language-translator-watson-assistant-8c38247e8af1)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-sample-apps"},{"document_id":"ibmcld_13160-7-1812","score":30.3556190694,"text":"\nBuild a database-driven Slackbot \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\nThe Slack integration sends messages between Slack and Watson Assistant. A custom extension, written in Python and deployed as serverless Code Engine app, exposes a REST API against the database backend.\n\nThis tutorial uses the new experience of Watson Assistant and an action skill. A former version was based on the dialog skill and the database was integrated using IBM Cloud\u00ae Functions with code written in Node.js. You can find that version of the tutorial in the [cloud-functions branch of the related code repository](https:\/\/github.com\/IBM-Cloud\/slack-chatbot-database-watson\/tree\/cloud-functions).\n\n\n\n Objectives \n\n\n\n* Build a chatbot using Watson Assistant which interacts with a database backend\n* Connect Watson Assistant to Slack using an integration\n* Create and deploy a Python database app to Code Engine\n* Access a Db2 on Cloud database via a Watson Assistant custom extension\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution19\/SlackbotArchitecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user interacts with [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant), either through Slack or using a web chat client\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"},{"document_id":"ibmcld_07223-2330-3654","score":29.9901484986,"text":"\n* [Get the Code](https:\/\/github.com\/IBM\/watson-discovery-analyze-data-breaches?cm_sp=IBMCode-_-import-enrich-and-gain-insight-from-data-_-Get-the-Code)\n* [View the Demo](https:\/\/www.youtube.com\/watch?v=zAu9tHefdDc&cm_sp=IBMCode-_-import-enrich-and-gain-insight-from-data-_-View-the-Demo)\n\n\n\n[Cognitive Retail Chatbot](https:\/\/developer.ibm.com\/patterns\/create-cognitive-retail-chatbot\/?cm_sp=Developer-_-code-_-retail_chatbot) Create a chatbot dialog using Watson Assistant, a Cloudant NoSQL database, Watson Discovery, and a Slack group.\n\n\n\n* [Get the Code](https:\/\/github.com\/IBM\/watson-online-store\/?cm_sp=IBMCode-_-create-cognitive-retail-chatbot-_-Get-the-Code)\n* [View the Demo](https:\/\/www.youtube.com\/watch?v=b-94B3O1czU&cm_sp=IBMCode-_-create-cognitive-retail-chatbot-_-View-the-Demo)\n\n\n\n[Cognitive News Search App](https:\/\/developer.ibm.com\/patterns\/create-a-cognitive-news-search-app\/?cm_sp=Developer-_-code-_-trending_news) Build your own news mining web application using JavaScript, Node.js, and the Watson Discovery service. Use the Watson Node.js SDK to build your news app to search the latest news, find trends, and even integrate it with other applications, such as Slack.\n\n\n\n* [Get the Code](https:\/\/github.com\/IBM\/watson-discovery-news\/?cm_sp=IBMCode-_-create-a-cognitive-news-search-app-_-Get-the-Code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sample-apps"},{"document_id":"ibmcld_03330-3253-5192","score":29.6363568071,"text":"\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https:\/\/medium.com\/ibm-watson\/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https:\/\/www.ibm.com\/blogs\/watson\/2020\/03\/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits\/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_03330-4-2191","score":29.2465046106,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_07080-6045-7467","score":28.9565032769,"text":"\n[checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Deploy your solution. [Deploying your project](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-deploy) \n\n\n\n\n\n\n\n Enhance your chatbot \n\nDelight your customers by fortifying your chatbot with an answer to every question. Discovery is designed to work seemlessly with Watson Assistant to search and deliver answers from help content that you already own.\n\nZoom\n\n![Shows a chat bot with emphasize the answer enabled.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/convo-search.png)\n\nFigure 3. Answer finding enabled in the Watson Assistant web chat\n\nIf enhancing your chatbot is your goal, complete the steps that are listed in the following table.\n\n\n\nChecklist for enhancing your chatbot\n\n Step Task Related information \n\n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Create a Conversational Search project. [Creating projects](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-projects) \n ![checkbox](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/checkbox.png) Add a collection that connects to an external data source or contains uploaded files.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-product-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2890648263}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09118-10321-12086","score":26.717741482,"text":"\n[View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Natural Language Understanding](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-startedgetting-started) You can use IBM Watson\u00ae Natural Language Understanding to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Personality Insights](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-about) You can use IBM Watson\u00ae Personality Insights to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n\n\n\n\n\n\n\n Container service integrations \n\nYou can integrate Key Protect with the following container services.\n\n\n\nTable 4. Supported container services.\n\n Service Description Integration docs \n\n [IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-started) You can use the IBM Cloud Kubernetes Service service to deploy highly available apps in Docker containers that run in Kubernetes clusters. [View docs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionkeyprotect)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-integrate-services"},{"document_id":"ibmcld_09919-7713-9881","score":26.2867907095,"text":"\n: Version 2 entity type support is now available, for all public and premium service instances, for the following languages: Russian and Swedish. For details, see [Entity type systems](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-type-systems).\n\n\n\n\n\n 3 August 2022 \n\nSupport for Single Label Classifications\n: Classifications now allows users to pass in a model_type training parameter when creating or updating a model, in order to train a single label classifier. See [Classifications training parameters](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-classificationsclassification-training-parameters) for more details.\n\n\n\n\n\n 11 July 2022 \n\nImproved [custom classifications](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-classifications) model - Japanese\n: Japanese custom classifications models now train and perform inference faster, with improved model results.\n\nImproved [custom categories](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-categories) model\n: Model contains improved word filtering, resulting in better category determination.\n\n\n\n\n\n 7 April 2022 \n\nCategories bug fix\n: Fixed a bug in the Version 2 Categories type system.\n\n\n\n\n\n 14 February 2022 \n\nEmotion support\n: Support for emotion is now available, for all public service instances, for French. For details, see [Language support](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support).\n\nImproved error handling and validation for emotion\n: If a request contains both an error in the emotion feature and a valid feature request for another feature, the response returns a 200 with a warning for the emotion feature.\n: The error log has changed from emotion request must specify at least one of: document, targets to emotion request must specify at least one of: document or targets.\n: Requests that include the emotion feature with any nonstring elements in the targets list returns an error.\n\n\n\n\n\n 1 December 2021 \n\nTone analytics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-release-notes"},{"document_id":"ibmcld_13074-16820-18514","score":26.1015174219,"text":"\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/discovery).\n\n\n\n\n\n Enrichment language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_07140-17709-19868","score":25.7117197682,"text":"\nThe emotion enrichment evaluates the overall emotional tone (for example anger) of entire document or specified target strings in the entire document. This enrichment can only be used with English content.\n\n\n\n* \"document\" : booleanoptional - When true the emotional tone of the entire document is evaluated.\n* \"targets\" : arrayoptional - A comma-separated array of target strings of which to evaluate the emotional state within the document.\n\n\n\n\n\n\n\n entities \n\nThe entities enrichment extracts instances of known entities such as people, places, and organizations. Optionally, a Knowledge Studio custom model can be specified to extract custom entities.\n\n\n\n* \"sentiment\" : boolean - optional - When true, sentiment analysis is performed on the extracted entity in the context of the surrounding content.\n* \"emotion\" : boolean - optional - When true, emotional tone analysis is performed on the extracted entity in the context of the surrounding content.\n* \"limit\" : INT - optional - The maximum number of entities to extract from the ingested document. The default is 50.\n* \"mentions\": boolean - optional - When true, the number of times that this entity is mentioned is recorded. The default is false.\n* \"mention_types\": boolean - optional - When true, the mention type for each mention of this entity is stored. The default is false.\n* \"sentence_location\": boolean - optional - When true, the sentence location of each entity mention is stored. The default is false.\n* \"model\" : string - optional - When specified, the custom model is used to extract entities instead of the public model. This option requires a Knowledge Studio custom model to be associated with your instance of Discovery. See [Integrating with Watson Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-integrating-with-wks) for more information.\n\n\n\n\n\n\n\n keywords \n\nThe keywords enrichment extracts instances of significant words within the text. To understand the difference between keywords, concepts, and entities, see [Understanding the difference between Entities, Concepts, and Keywords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceudbeck).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configref"},{"document_id":"ibmcld_09913-11527-13389","score":25.4983650489,"text":"\nRelations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Romanian \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Russian \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata X \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Slovak \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Spanish \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts X \n Emotion \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles X \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Swedish \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata X \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Turkish","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_09913-6894-8823","score":25.4802719005,"text":"\nClassifications X* X \n Concepts X \n Emotion X \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Indicates support for tone analysis; see [Tone analytics (Classifications)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-tone_analytics) for more information.\n\n\n\n\n\n German \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts X \n Emotion \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles X \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Hebrew \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Hindi \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Italian \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts X \n Emotion \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Japanese \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_09913-3804-5789","score":25.304029229,"text":"\nIf you are using IBM Cloud\u00ae Dedicated, check with your IBM salesperson to confirm which languages are supported in your environment.\n\n\n\n Arabic \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts \n Emotion \n Entities X* X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Chinese (Simplified) \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications \n Concepts \n Emotion \n Entities X* X \n Keywords X \n Metadata \n Relations X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Czech \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Danish \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Dutch \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications \n Concepts \n Emotion \n Entities X* X \n Keywords X \n Metadata \n Relations X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n English","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_09913-9920-11906","score":25.2840882434,"text":"\nNorwegian (Bokmal) \n\nPlease note that Natural Language Understanding considers Norwegian (standard language code no) as equivalent to Norwegian-Bokmal (standard language code nb), and uses the same Norwegian-Bokmal model for both language codes.\n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Norwegian (Nyorsk) \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Polish \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n* Relevance ranking is not supported.\n\n\n\n\n\n Portuguese \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories X \n Classifications X \n Concepts X \n Emotion \n Entities X X \n Keywords X \n Metadata X \n Relations X X \n Semantic roles \n Sentiment X \n Syntax X \n\n\n\n\n\n\n\n Romanian \n\n\n\n Feature Standard Support [Custom model](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing) support \n\n Categories \n Classifications \n Concepts \n Emotion \n Entities X* \n Keywords X \n Metadata \n Relations \n Semantic roles \n Sentiment X \n Syntax X","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_09906-2727-4077","score":25.0372235643,"text":"\nThe targets option for sentiment in the following example tells the service to search for the targets \"apples\", \"oranges\", and \"broccoli\". Since \"apples\" and \"oranges\" are located in the text, sentiment scores are returned for those targets.\n\nYou can also get sentiment and emotion results for entities and keywords that are detected in your text. In the example, the emotion option for keywords tells the service to analyze each detected keyword for emotion results.\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data '{\n\"text\": \"I love apples! I do not like oranges.\",\n\"features\": {\n\"sentiment\": {\n\"targets\": [\n\"apples\",\n\"oranges\",\n\"broccoli\"\n]\n},\n\"keywords\": {\n\"emotion\": true\n}\n}\n}' \"{url}\/v1\/analyze?version=2019-07-12\"\nShow more\n\nRunnable command for Windows users:\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data \"{\"text\":\"I love apples! I do not like oranges.\",\"features\":{\"sentiment\":{\"targets\":[\"apples\",\"oranges\",\"broccoli\"]},\"keywords\":{\"emotion\":true}}}\" \"{url}\/v1\/analyze?version=2019-07-12\"\n\n\n\n\n\n Next steps \n\n\n\n* View the [API reference](https:\/\/cloud.ibm.com\/apidocs\/natural-language-understanding).\n* Learn how to identify [custom entities and relations](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-started"},{"document_id":"ibmcld_09892-7-1976","score":24.8979908767,"text":"\nAbout \n\nWith IBM Watson\u00ae Natural Language Understanding, developers can analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment.\n\n\n\n Features \n\nSend requests to the API with text, HTML, or a public URL, and specify one or more of the following features to analyze:\n\n\n\n Categories \n\nCategorize your content using a five-level classification hierarchy. View the complete list of categories [here](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-categories-hierarchy). For example:\n\nInput\n\n> url: \"www.cnn.com\"\n\nResponse\n\n> \/news\n> \/art and entertainment\n> \/movies and tv\/television\n> \/news\n> \/international news\n\n\n\n\n\n Concepts \n\nIdentify high-level concepts that aren't necessarily directly referenced in the text. For example:\n\nInput\n\n> text: \"Natural Language Understanding uses natural language processing to analyze text.\"\n\nResponse\n\n> Linguistics\n> Natural language processing\n> Natural language understanding\n\n\n\n\n\n Emotion \n\nAnalyze emotion conveyed by specific target phrases or by the document as a whole. You can also enable emotion analysis for entities and keywords that are automatically detected by the service. For example:\n\nInput\n\n> text: \"I love apples, but I hate oranges.\"\n> targets: \"apples\", and \"oranges\"\n\nResponse\n\n> \"apples\": joy\n> \"oranges\": anger\n\n\n\n\n\n Entities \n\nFind people, places, events, and other types of entities mentioned in your content. View the complete list of entity types and subtypes [here](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-entity-type-systems). For example:\n\nInput\n\n> text: \"IBM is an American multinational technology company headquartered in Armonk, New York, United States, with operations in over 170 countries.\"\n\nResponse\n\n> IBM: Company\n> Armonk: Location\n> New York: Location\n> United States: Location\n\n\n\n\n\n Keywords","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-about"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.4367467095,"ndcg_cut_10":0.4367467095}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16306-2449-4025","score":12.495469779,"text":"\nFor more information, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid). \n Slack The Slack member ID (for example, U2147483697). \n Facebook The Facebook sender ID (for example, 4310101122439797). \n Whatsapp The customer's phone number. \n Phone The customer's phone number. \n SMS with Twilio The customer's phone number. \n\n\n\n\n\n\n\n\n\n chat \n\nIncluded only if the web chat integration is in use.\n\n\n\n Properties \n\n\n\nProperties of the chat object\n\n Name Type Description \n\n browser_info.browser_name String The browser name, such as chrome, edge, or firefox. \n browser_info.browser_version String The browser version, such as 109.0.0. \n browser_info.browser_OS String The operating system of the customer's computer, such as Mac OS. \n browser_info.language String The default locale code of the browser, such as en-US. \n browser_info.page_url String The URL of the web page where the web chat is embedded, not including any query parameters or hashes. \n browser_info.screen_resolution String The height and width of the browser window, such as width: 1440, height: 900. \n browser_info.user_agent String The content of the HTTP User-Agent request header. \n browser_info.client_ip_address String The IP address of the customer's computer. \n browser_info.ip_address_list Array Ann array IP addresses specified by HTTP X-Forwarded-For request headers. \n\n\n\n\n\n\n\n Example JSON \n\n\"chat\": {\n\"browser_info\": {\n\"browser_name\": \"chrome\",\n\"browser_version\": \"109.0.0\",\n\"browser_OS\": \"Mac OS\",\n\"language\": \"en-US\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-expression-integration-variables"},{"document_id":"ibmcld_16270-0-505","score":12.3815242931,"text":"\n\n\n\n\n\n\n  Browser support \n\nThe Watson Assistant application requires the same level of browser software as is required by IBM Cloud. For more information, see [IBM Cloud prerequisites](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nFor information about the web browsers that are supported by the web chat integration, see [Browser support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overviewweb-chat-architecture-browsers).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-browser-support"},{"document_id":"ibmcld_03162-9246-11517","score":12.075947105,"text":"\nHowever, there might be times when you want to route a customer to a different Salesforce agent queue. For example, your dialog might have a root dialog node that conditions on a close_account intent. For that branch of the conversation only, you want to transfer customers to agents in the sales queue who are authorized to offer incentives as a way to retain customers. You can direct transfers to specific agent queues by adding routing logic to your dialog.\n\nYou can specify alternate routing preferences based on:\n\n\n\n* browser information\n* the current topic of conversation\n\n\n\n\n\n Routing based on browser information \n\nWhen a customer interacts with the web chat, information about the current web browser session is collected. For example, the URL of the current page is collected. You can use this information to add custom routing rules to your dialog. For example, if the customer is on the Products page when a transfer to a human is requested, you might want to route the chat transfer to a queue with agents who are experts in your product portfolio. If the customer is on the Returns page, you might want to route the chat transfer to a queue with agents who know how to help customers return merchandise.\n\nFor more information, see [Web chat: Accessing browser information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrationsdialog-integrations-chat-browser-info).\n\n\n\n\n\n Routing by topic \n\nWhen you enable transfers to the Salesforce service desk, you copy and paste code snippets from Salesforce into the service desk transfer setup page. These code snippets define how transferred conversations are handled within Salesforce. Routing rules are included in the initial transfer configuration. The routing rules identify the queue of agents to which messages from the assistant are transferred by default.\n\nThe code that you add to the setup page when you configure the service desk integration shares the following required information with Watson Assistant:\n\n\n\n* organization_id: Unique ID of the organization. A company can have more than one organization set up in Salesforce.\n* chat_api_endpoint: Salesforce API endpoint that is used by the integration to communicate with Salesforce.\n* deployment_id: Unique ID of the deployment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-salesforce"},{"document_id":"ibmcld_16365-8408-10508","score":11.8175665664,"text":"\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16233-3661-5046","score":11.5388300034,"text":"\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https:\/\/www.ibm.com\/blogs\/watson\/2020\/03\/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits\/) blog on ibm.com.\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Building your assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-build-actions-overview)\n* [Publishing and deploying your assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overview)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application requires the same level of browser software as is required by IBM Cloud. For more information, see IBM Cloud [Prerequisites](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nFor information about the web browsers that are supported by the web chat integration, see [Browser support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architectureweb-chat-architecture-browsers).\n\n\n\n\n\n Language support \n\nLanguage support by feature is detailed in [Supported languages](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-language-supportadmin-language-support-codes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-about"},{"document_id":"ibmcld_16362-2897-4995","score":11.3927107468,"text":"\nThe assistant ID can be found in Assistant settings.\n\nIn Assistant settings, the assistant ID is in the Assistant IDs and API details section.\n\n\n\n\n\n\n\n What do the draft and live tags mean? \n\nA Draft tag indicates that the information is linked to your draft environment, which means that you can preview these updates but they are not visible to your users. A Live tag indicates that the information is linked to your live environment, which means that the content is available to your users to interact with.\n\nFor more information, see [Environments](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments).\n\n\n\n\n\n Why can't I log in? \n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n\n\n\n\n Why am I being asked to log in repeatedly? \n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan that you were using expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n\n\n\n\n Why don't I see the Analytics page? \n\nTo view the Analytics page, you must have a service role of Manager and a platform role of at least Viewer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-faqs"},{"document_id":"ibmcld_00362-2793-4475","score":11.3504177992,"text":"\n![cors-preflight](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/006fd22ab2811b7d19804c763a00568b3da4c03a\/CDN\/\/images\/cors-preflight.svg)\n\nFigure 2: First request (preflight)\n\nSecond request (resource access):\n\nZoom\n\n![cors-after-preflight](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/006fd22ab2811b7d19804c763a00568b3da4c03a\/CDN\/\/images\/cors-after-preflight.svg)\n\nFigure 3: Second request (resource access)\n\nFor more complex CORS communication between the browser and a CORS origin that's different than the requesting web page, a [preflight request](https:\/\/www.w3.org\/TR\/cors\/cross-origin-request-with-preflight-0) is required before an actual resource access. Certain situations might require preflighting CORS requests, such as HTTP methods that are not GET or POST methods, or using non-standard HTTP headers with the request - even if it is a GET or POST request, and so forth.\n\nIf a preflight request is needed, here's how the events unfold:\n\n\n\n* The browser sends a request using the HTTP OPTIONS method to the server with all of the intended CORS request headers.\n* The server processes those CORS request headers, and can respond with CORS response headers containing no actual content data.\n* The browser checks those CORS response headers to make sure that the CORS request is allowed.\n* If the browser sees that the intended resource request should be allowed by the server, it makes a second request to the browser with the intended HTTP method, whether GET, POST, PUT and so on, with the same CORS request headers.\n\n\n\nAfterward, the communication between the browser and CORS origin (different than that of the web page) proceeds as if it was a simple CORS request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-cors-and-cors-requests-through-your-cdn"},{"document_id":"ibmcld_16727-72473-74518","score":11.3371092517,"text":"\n[Integrations](https:\/\/cloud.ibm.com\/images\/integrations-icon.png). On the Integrations page, you can add search, channel, and extension integrations to your assistant. For more information, see [Adding integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-integration-add).\n* Where is the Assistant ID found in the new product experience?\n\n Where is the Assistant ID found in the new product experience? \n\nThe assistant ID can be found in Assistant settings.\n\nIn Assistant settings, the assistant ID is in the Assistant IDs and API details section.\n* What do the draft and live tags mean?\n\nA Draft tag indicates that the information is linked to your draft environment, which means that you can preview these updates but they are not visible to your users. A Live tag indicates that the information is linked to your live environment, which means that the content is available to your users to interact with.\n\nFor more information, see [Environments](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments).\n* Why can't I log in?\n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* Why am I being asked to log in repeatedly?\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan that you were using expired.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-72493-74543","score":11.3247070209,"text":"\n[Integrations](https:\/\/cloud.ibm.com\/docs\/images\/integrations-icon.png). On the Integrations page, you can add search, channel, and extension integrations to your assistant. For more information, see [Adding integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-integration-add).\n* Where is the Assistant ID found in the new product experience?\n\n Where is the Assistant ID found in the new product experience? \n\nThe assistant ID can be found in Assistant settings.\n\nIn Assistant settings, the assistant ID is in the Assistant IDs and API details section.\n* What do the draft and live tags mean?\n\nA Draft tag indicates that the information is linked to your draft environment, which means that you can preview these updates but they are not visible to your users. A Live tag indicates that the information is linked to your live environment, which means that the content is available to your users to interact with.\n\nFor more information, see [Environments](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments).\n* Why can't I log in?\n\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* Why am I being asked to log in repeatedly?\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan that you were using expired.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03330-4814-6444","score":11.2270676069,"text":"\n* [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud. For more information, see IBM Cloud [Prerequisites](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-prereqs-platformbrowsers-platform).\n\nFor information about the web browsers that are supported by the web chat integration, see [Browser Support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-browsers).\n\n\n\n\n\n Language support \n\nLanguage support by feature is detailed in the [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support) topic.\n\n\n\n\n\n Terms and notices \n\nSee [IBM Cloud Terms and Notices](https:\/\/cloud.ibm.com\/docs\/overview\/terms-of-use?topic=overview-terms) for information about the terms of service.\n\nUS Health Insurance Portability and Accountability Act (HIPAA) support is available with Enterprise with Data Isolation plans that are hosted in the Washington, DC location created on or after 1 April 2019. For more information, see [Enabling HIPAA support for your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-enabling-hipaa).\n\nTo learn more about service terms and data security, read the following information:\n\n\n\n* [Service terms](https:\/\/www-03.ibm.com\/software\/sla\/sladb.nsf\/sla\/saas?OpenDocument) (Search for the Watson Assistant offering)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.296081911,"ndcg_cut_10":0.296081911}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13074-16820-18514","score":33.352940734,"text":"\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/discovery).\n\n\n\n\n\n Enrichment language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_13074-15255-17243","score":30.5469194369,"text":"\nSee [Entity extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceentity-extraction) and [Keyword extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicekeyword-extraction) about those enrichments.\n\nThe subject, action, and object are extracted for every sentence that contains a relation.\n\n\n\n\n\n Sentiment analysis \n\nIdentifies attitude, opinions, or feelings in the content that is being analyzed. Discovery can calculate overall sentiment within a document, sentiment for user-specified targets, entity-level sentiment, quotation-level sentiment, directional-sentiment, and keyword-level sentiment. The combination of these capabilities supports a variety of use cases ranging from social media monitoring to trend analysis.\n\nExample portion of a document enriched with Sentiment Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"sentiment\": {\n\"document\": {\n\"score\": 0.459813,\n\"label\": \"positive\"\n}\n}\n\nIn the preceding example, you could query the sentiment label by accessing enriched_text.sentiment.document.label\n\nThe label is the overall sentiment of the document (positive, negative, or neutral). The sentiment label is based on the score; a score of 0.0 would indicate that the document is neutral, a positive number would indicate the document is positive, a negative number would indicate the document is negative.\n\n\n\n\n\n Emotion analysis \n\nDetects anger, disgust, fear, joy, and sadness implied in English text. Emotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_16313-10077-11045","score":20.3289785145,"text":"\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable. Each step sends a message to the customer, based on the error condition, and then uses the Connect to agent feature to transfer the conversation to a live agent. (For more information about this feature, see [Connecting to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-human-agent).) You can modify these steps if you want to handle an error condition in a different way.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errors"},{"document_id":"ibmcld_16356-7-2036","score":19.742645186,"text":"\nDetecting trigger words \n\nUse the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent. The second group shows customers a customizable warning message.\n\nBy default, this action has two steps\u2014the Connect to agent step and the Show warning step. To see how this action works, click Set by assistant in the list of actions, and then click Trigger word detected.\n\nThis is a beta feature that is available for evaluation and testing purposes.\n\n\n\n Connect to agent \n\nThe first step of the Trigger word detected action is the Connect to agent step. The Connect to agent step goes to the Fallback action if any trigger words are detected in the customer's input. Use this step to capture any key phrases where it\u2019s important to connect a customer with a live agent rather than activate any further actions.\n\nFor example, you might add hurt and harm as trigger words for the Connect to agent step:\n\nZoom\n\n![Adding trigger words to the Connect to agent step](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/connect-to-agent-phrases.png)\n\nAdding trigger words to the Connect to agent step\n\nIn this example, a customer enters a word or phrase including hurt or harm, which triggers the Fallback action. Step 4 has:\n\n\n\n* Danger word detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-phrases"},{"document_id":"ibmcld_16313-8575-10638","score":19.0568740439,"text":"\nFor more information on uploading or downloading example phrases, see [Adding more examples](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-adding-more-examples).\n\n\n\n\n\n\n\n Editing the fallback action \n\nThe built-in Fallback action is automatically provided with each assistant and cannot be deleted. However, you can edit the Fallback action to modify the conversation your users have with the assistant when errors occur. For example, you might want to add steps or modify step conditions to provide more control over how specific error conditions are handled.\n\nTo edit the Fallback action, click Set by assistant in the list of actions, and then click Fallback.\n\nZoom\n\n![Fallback built-in action](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/fallback-action.png)\n\nFallback built-in action\n\nWhenever the Fallback action is triggered, the assistant also sets a value for the Fallback reason session variable. This value indicates what kind of situation led to the Fallback action being triggered. By default, this variable can have one of five values:\n\n\n\n* Step validation failed: The customer repeatedly gave answers that were not valid for the expected customer response type.\n* Agent requested: The customer directly asked to be connected to a live agent.\n* No action matches: The customer repeatedly made requests or asked questions that the assistant did not understand.\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errors"},{"document_id":"ibmcld_13761-7-2364","score":17.5917599495,"text":"\nModifying speech synthesis with expressive neural voices \n\nThe expressive neural voices that are available with the IBM Watson\u00ae Text to Speech service offer some additional features that are not available with other types of voices: using speaking styles, emphasizing interjections, and emphasizing words. These features are available for both the HTTP and WebSocket interfaces.\n\nThe features involve the use of elements of the Speech Synthesis Markup Language (SSML). The descriptions of the features provide information about how they interact with related SSML elements and attributes.\n\n\n\n Using speaking styles \n\nThe expressive neural voices determine the sentiment of the text from the context of its words and phrases. The speech that they produce, in addition to having a very conversational style, reflects the mood of the text. The expressive voices naturally express gratitude, thankfulness, happiness, empathy, confusion, and other sentiments by default, with no explicit additional tagging.\n\nHowever, you can embellish the voices' natural tendencies by using the <express-as> element with the required style attribute to indicate that all or some of the text is to emphasize specific characteristics. These characteristics are referred to as speaking styles:\n\n\n\n* cheerful - Expresses happiness and good news. The style is upbeat, welcoming, and conveys a positive message.\n* empathetic - Expresses empathy and compassion. The style has sympathetic undertones, but it is not excessively sorrowful.\n* neutral - Expresses objectivity and evenness. The style strives for less emotion, and instead conveys a more even and instructional tone.\n* uncertain - Expresses uncertainty and confusion. The style conveys the feeling of being unsure or in doubt.\n\n\n\nIn many cases, the effect of the styles is very subtle. In such cases, the differences might not be readily discernible from the default expressive tone. But there are instances where the style can audibly enhance the voices' inherent ability to detect and express emotion. The differences are often detectable only on certain words and phrases.\n\nTable 1 provides examples of each available style for the <express-as> element. To demonstrate the effect of the styles, the table provides two samples for each example. The first sample speaks the text with the default en-US_EmmaExpressive voice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-synthesis-expressive"},{"document_id":"ibmcld_03353-8238-10149","score":17.5322854881,"text":"\n[Bidi options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever for some languages, like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as \"u\u00f1a\" vs. \"una\". In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_16356-1613-3336","score":17.4871717507,"text":"\nFor more information about the Fallback action, see [Editing the fallback action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input. Use this step to discourage customers from interacting with your assistant in unacceptable ways, such as using profanity.\n\nFor example, you might add darn, dang, and heck as trigger words for the Show warning step:\n\nZoom\n\n![Adding trigger words to the Show warning step](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/show-warning-phrases.png)\n\nAdding trigger words to the Show warning step\n\nIn this example, a customer enters darn, dang, or heck, the assistant responds with Please use appropriate language when interacting with the assistant. You can customize this message.\n\nIf the customer triggers the Show warning step again, the Fallback action is triggered. The default setting is if attempts exceed 2 total tries. You can customize this setting.\n\nIn the Fallback action, step 5 has:\n\n\n\n* Profanity detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-phrases"},{"document_id":"ibmcld_03027-8135-10108","score":17.4397581829,"text":"\nThis setting is not reflected in the Try it out panel.\n\n![Bidi options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever for some languages, like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as \"u\u00f1a\" vs. \"una\". In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_13333-7-2349","score":17.2004176945,"text":"\nSpeech activity detection \n\nThe IBM Watson\u00ae Speech to Text service offers two speech activity detection parameters to control what audio is used for speech recognition. The parameters specify the service's sensitivity to non-speech events and to background noise. The parameters are independent: You can use them individually or together.\n\nSpeech activity detection is supported for most language models. For more information, see [Language model support](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputdetection-support).\n\n\n\n How speech activity detection works \n\nSpeech activity detection consumes the input audio stream and determines which parts of the stream to pass for speech recognition. Speech recognition is adversely affected by background speech and noise, causing the service to transcribe the wrong words, to produce words where none are present, or to omit words that are part of the input audio. The speech activity detection feature can help ensure that only relevant audio is processed for speech recognition.\n\nYou can use the feature to control the following aspects of speech recognition:\n\n\n\n* Suppress background speech. Call-center data often contains cross-talk (\"overhearing\") from other agents. You can set a volume threshold below which such background speech is ignored.\n* Suppress background noise. Some audio, such as speech recorded in a factory, can contain a high level of background noise. You can set a threshold below which such background noise is ignored.\n* Suppress non-speech audio events. Background music and tone events, such as audio played to a client who is waiting on hold on a telephone line, can cause inaccurate recognition. Silence can also result in unnecessary recognition or transcription errors. You can set a threshold below which such events are ignored.\n\n\n\nBy default, speech activity detection is configured to provide optimal performance for the general case for each model. For specific cases, the default settings might not be optimal and can lead either to slow transcription or to word insertions and deletions. You are encouraged to experiment with different settings to determine which values work best for your audio.\n\n\n\n\n\n Speech detector sensitivity \n\nUse the speech_detector_sensitivity parameter to adjust the sensitivity of speech activity detection.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-detection"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03166-6034-7833","score":19.2838627905,"text":"\nYou add this script to your website in the next section, [Deploy your assistant in production](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-snippet).\n13. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.\n\n\n\n\n\n\n\n Deploy your assistant in production \n\n\n\n1. If the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n2. Open the HTML source for a web page on your website where you want the chat window to be displayed. Paste the code snippet into the page.\n\nPaste the code as close to the closing <\/body> tag as possible to ensure that your page renders faster.\n\nThe following HTML snippet is the source for a test page that you can copy and save as a file with a .html extension for testing purposes. You would replace the script element block here with the script elements you copied from the web chat integration setup page.\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16295-1365-2938","score":19.0015938076,"text":"\nThe script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5. Edit the HTML source for the web page where you want the web chat widget to appear. Paste the code snippet into the page. Paste the code as close as possible to the closing <\/body> tag to ensure that your page renders faster.\n\nDo not modify the integrationID or region property values in the generated embed script.\n\nIf you aren't ready to add the web chat to a live website, you can quickly test it using a local HTML file. Use this HTML code as the source for a test page:\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n\nJust copy this code into a file with the .html extension, and replace the script element with the embed script you copied in the previous step.\n\nThe identifiers in the embed script (such as integrationIDserviceInstanceID) are not considered secret, and are visible to anyone who has access to your website. For more information, see [Security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architectureweb-chat-architecture-security).\n6. If the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the URLs that host the web chat are accessible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_06007-23310-25401","score":18.093029935,"text":"\nHowever, you might need to also provide limited public egress from your worker nodes to a public endpoint, and want to ensure that this public egress is controlled and isolated in your cluster. For example, you might need your app pods to access an IBM Cloud service that does not support private cloud service endpoints, and must be accessed over the public network.\n\nZoom\n\n![Network setup for a cluster that allows limited, secure public access.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/cs_org_ov_vpc.png)\n\nFigure 1. Network setup for a VPC cluster that allows limited, secure public access\n\n\n\n Worker-to-worker communication \n\nTo achieve this setup in, for example, a multizone cluster that has worker nodes in two zones, you create a VPC subnet in one zone that has no public gateway attached, and a VPC subnet in another zone that does have a public gateway attached. Then, you create a VPC cluster that uses these VPC subnets and zones.\n\n\n\n\n\n Worker-to-master and user-to-master communication \n\nWhen you create the cluster you can choose to allow worker-to-master and user-to-master communication over the public and private networks, or over the private network only.\n\n\n\n* Public and private cloud service endpoints: Communication between worker nodes and master is established over the private network through the private cloud service endpoint. By default, all calls to the master that are initiated by authorized cluster users are routed through the public cloud service endpoint.\n* Private service endpoint only: Communication to master from both worker nodes and cluster users is established over the private network through the private cloud service endpoint. Cluster users must either be in your VPC network or connect through a [VPC VPN connection](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-vpnaas).\n\n\n\n\n\n\n\n Worker communication to other services or networks \n\nAfter the cluster is created, you create a worker pool that is deployed only to the zone where subnet has an attached public gateway.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basics"},{"document_id":"ibmcld_16362-4518-6470","score":18.0355572393,"text":"\nLite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n\n\n\n\n Why don't I see the Analytics page? \n\nTo view the Analytics page, you must have a service role of Manager and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control).\n\n\n\n\n\n Why am I unable to view the API details, API key, or service credentials? \n\nIf you cannot view the API details or service credentials, it is likely that you do not have Manager access to the service instance in which the resource was created. Only people with Manager access to the instance can use the service credentials.\n\n\n\n\n\n Can I export the user conversations from the Analytics page? \n\nYou cannot directly export conversations from the conversation page. However, you can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [V2 API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs). Or, you can use a Python script to export logs. For more information, see [export_logs_py](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py).\n\n\n\n\n\n Can I change my plan to a Lite plan? \n\nNo, you cannot change from a Trial, Plus, or Standard plan to a Lite plan. And you cannot upgrade from a Trial to a Standard plan.\n\n\n\n\n\n How many Lite plan instances of Watson Assistant can I create? \n\nYou can have only one Lite plan instance of Watson Assistant per resource group.\n\n\n\n\n\n How do I create a webhook?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-faqs"},{"document_id":"ibmcld_13785-6778-8202","score":17.8435793474,"text":"\n* [Watson GitHub repos](https:\/\/github.com\/watson-developer-cloud\/)\n\n\n\n* Help\n\n\n\n* [Known limitations](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-known-limitations)\n* [Usage FAQs](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-faq-usage)\n* Developer community\n\n\n\n* [StackOverflow](http:\/\/stackoverflow.com\/questions\/tagged\/ibm-watson-cognitive+text-to-speech)\n\n\n\n* [Accessibility](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-accessibility-platform)\n\n\n\n* [About this product](https:\/\/www.ibm.com\/cloud\/watson-text-to-speech)\n\n\n\nExpand all | Collapse all\n\nCollapse\n\n\n\n1. [IBM Cloud Docs](https:\/\/cloud.ibm.com\/docs)\n2. [Text to Speech](https:\/\/cloud.ibm.com\/docs\/text-to-speech)\n3.\n\n\n\nSearch in collection\n\nSearch in collection\n\n\n\n\n\nLangSwitcher dropdown\n\nEnglish\n\nClose menu\n\nDeutschEnglish\n\nEspa\u00f1olFran\u00e7aisItaliano\u65e5\u672c\u8a9e\ud55c\uad6d\uc5b4Portugu\u00eas\/Brasil\u7b80\u4f53\u4e2d\u6587\u7e41\u9ad4\u4e2d\u6587\n\n\n\n\n\n The HTTP interface * Last updated 2023-01-24 \n\nTo synthesize text to speech with the HTTP REST interface of the IBM Watson\u00ae Text to Speech service, you call the GET or POST \/v1\/synthesize method. You specify the text that is to be synthesized and the voice and format for the spoken audio. You can also specify a custom model that is to be used with the request.\n\nFor more information about the HTTP interface, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n Synthesizing text to audio","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingHTTP"},{"document_id":"ibmcld_11542-5856-7635","score":17.8106208637,"text":"\n* Text to Speech Example\n* Natural Language Understanding Example\n* Personality Insights Example\n* Language Translator Example\n\n\n\nEach of these example code snippets is included in the Git repository under the #Usage section of the documentation:\n\n\n\n[#Usage section with sample code for the ABAP SDK for IBM Watson, using SAP NetWeaver](https:\/\/github.com\/watson-developer-cloud\/abap-sdk-nwasusage)\n\n[#Usage section with sample code for the ABAP SDK for IBM Watson, using SAP Cloud Platform ABAP Environment](https:\/\/github.com\/watson-developer-cloud\/abap-sdk-scpusage)\n\n\n\n\n\n\n\n API Reference \n\nThe API Reference is built into the open source Git repository, and is therefore hosted by GitHub Pages:\n\n\n\n* [ABAP Client Library for Watson API Reference](https:\/\/watson-developer-cloud.github.io\/abap-sdk-nwas\/).\n\n\n\n\n\n\n\n\n\n Release and Support \n\nAs the ABAP SDK is a community release, it is not updated with the same schedule as IBM-supported SDKs. It is the choice and responsibility of application developers how this Community SDK is used.\n\nThe ABAP SDK is a Community SDK for IBM Watson, created by the IBM Watson development community and SAP's ABAP development community - written by ABAPers from IBM Cloud, IBM Services, and IBM Systems.\n\nTherefore, as a community release it is not updated with the same schedule as IBM-supported SDKs, and does not include support by IBM. For more information about IBM-supported SDKs and the update policy, see [Watson SDKs Reference information](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-using-sdks).\n\nIf you have questions about the IBM Watson services or are having difficulties with using the APIs, ask a question on [Stack Overflow under tag ibm-watson-cognitive](http:\/\/stackoverflow.com\/questions\/ask?tags=ibm-watson-cognitive).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-abap-sdk-watson"},{"document_id":"ibmcld_03364-5344-7201","score":17.8008276557,"text":"\n* [Dialog Skill Analysis for Watson Assistant](https:\/\/github.com\/watson-developer-cloud\/assistant-dialog-skill-analysis)\n* [Watson Assistant Recommendation notebooks (Measure and Analyze Effectiveness)](https:\/\/github.com\/watson-developer-cloud\/assistant-improve-recommendations-notebook)\n* [Watson Assistant Dialog Flow Analysis notebook](https:\/\/github.com\/watson-developer-cloud\/assistant-dialog-flow-analysis)\n\n\n\nAgain, the [Watson Assistant Continuous Improvement Best Practices Guide](https:\/\/github.com\/watson-developer-cloud\/assistant-improve-recommendations-notebook\/raw\/master\/notebook\/IBM%20Watson%20Assistant%20Continuous%20Improvement%20Best%20Practices.pdf) outlines which notebook to use at each stage of your improvement process.\n\n\n\n\n\n\n\n Using the logs API \n\nYou can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For conversations created by using the v2 \/message API, use the instance-level endpoint to [list log events in all workspaces](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1listalllogs), and then filter by Assistant ID. For more information about filtering logs, see [Filter query reference](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-filter-reference).\n\nThe API logs messages that are exchanged in conversations that are defined by a dialog skill only.\n\nThe number of days that logs are stored differs by service plan type. See [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-limits) for details.\n\nFor a Python script you can run to export logs and convert them to CSV format, download the export_logs_py.py file from the [Watson Assistant GitHub)](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py) repository.\n\n\n\n\n\n Understanding logs-related terminology","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resources"},{"document_id":"ibmcld_13785-5763-7073","score":17.5087989962,"text":"\n* [Protecting sensitive information in your Watson service](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-keyservice)\n* [Public and private network endpoints](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-public-private-endpoints)\n* [Virtual Private Endpoints](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-virtual-private-endpoints)\n\n\n\n* Service background\n\n\n\n* [The science behind the service](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-science)\n* [Research references](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-references)\n\n\n\n\n\n* Reference\n\n\n\n* [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech)\n* [High availability and disaster recovery](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-ha-dr)\n* [Activity Tracker events](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-at-events)\n* [Watson SDKs](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-using-sdks)\n* [Watson GitHub repos](https:\/\/github.com\/watson-developer-cloud\/)\n\n\n\n* Help\n\n\n\n* [Known limitations](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-known-limitations)\n* [Usage FAQs](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-faq-usage)\n* Developer community","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingHTTP"},{"document_id":"ibmcld_03364-6793-8946","score":17.4589698187,"text":"\nSee [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-limits) for details.\n\nFor a Python script you can run to export logs and convert them to CSV format, download the export_logs_py.py file from the [Watson Assistant GitHub)](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py) repository.\n\n\n\n\n\n Understanding logs-related terminology \n\nFirst, review the definitions of terms that are associated with Watson Assistant logs:\n\n\n\n* Assistant: An application - sometimes referred to as a 'chat bot' - that implements your Watson Assistant content.\n* Assistant ID: The unique identifier of an assistant.\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resources"},{"document_id":"ibmcld_10510-65064-67302","score":17.1136177243,"text":"\n* Compute resource limitation: To ensure that every team has the necessary resources to deploy services and run apps in the cluster, you must set up [resource quotas](https:\/\/kubernetes.io\/docs\/concepts\/policy\/resource-quotas\/) for every namespace. Resource quotas determine the deployment constraints for a project, such as the number of Kubernetes resources that you can deploy, and the amount of CPU and memory that can be consumed by those resources. After you set a quota, users must include resource requests and limits in their deployments.\n* Shared cluster resources: If you run multiple tenants in one cluster, some cluster resources, such as the Red Hat OpenShift router, Ingress application load balancer (ALB) or available portable IP addresses are shared across tenants. Smaller services might have a hard time using shared resources if they must compete against large services in the cluster.\n* Updates: You can run one Red Hat OpenShift API version at a time only. All apps that run in a cluster must comply with the current Red Hat OpenShift API version independent of the team that owns the app. When you want to update a cluster, you must ensure that all teams are ready to switch to a new Red Hat OpenShift API version and that apps are updated accordingly. This also means that individual teams have less control over the Red Hat OpenShift API version they want to run.\n* Changes in cluster setup: If you want to change the cluster setup or reschedule workloads onto new worker nodes, you must roll out this change across tenants. This roll out requires more reconciliation and testing than in a single-tenant cluster.\n* Communication process: When you manage multiple tenants, consider setting up a communication process so that tenants know where to go when an issue with the cluster exists, or when they need more resources for their services. This communication process also includes informing your tenants about all changes in the cluster setup or planned updates.\n\n\n\nAlthough single-tenant and multi-tenant clusters come with roughly the same costs, single-tenant clusters provide a higher level of isolation than the projects in a multi-tenant cluster. For better workload isolation, use single-tenant clusters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16281-0-376","score":14.7955272743,"text":"\n\n\n\n\n\n\n  Integrating with a custom client app \n\nIBM Cloud\n\nIf the available integration channels do not meet your needs, you can build your own client application as the interface between the assistant and your customers.\n\nFor more information, see [Building a custom client using the API](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-custom-app"},{"document_id":"ibmcld_02680-7025-8620","score":13.8395595635,"text":"\nproperty.getCurrentValue(entityId, entityAttributes); \/\/ returns the stringified yaml (check above Table 1)\n\n\n\n* Force fetch the configurations from server.\n\nappConfiguration.fetchConfigurations()\n\n\n\n\n\n\n\n\n\n\n\n Integrating client SDK for Android app written in Java \n\nApp Configuration service provides Android client SDK to integrate with your Android application. You can evaluate the values of your property and feature flag by integrating the SDK.\n\n\n\n1. Install the SDK by using either one of the options:\n\n\n\n* [Download](https:\/\/github.com\/IBM\/appconfiguration-android-client-sdk) and import the package to your Android studio project.\n* Get the package through Gradle by adding:\n\n\n\n* Add App Configuration Android client SDK dependency to Project level build.gradle file.\n\nrepositories {\nmavenCentral()\n}\n* Add App Configuration Android client SDK dependency to Module level build.gradle file.\n\ndependencies {\nimplementation \"com.ibm.cloud:appconfiguration-android-sdk:0.3.1\"\n}\n\n\n\n\n\n2. Configure the AndroidManifest.xml file for internet permission.\n\n<uses-permission android:name=\"android.permission.INTERNET\"\/>\n3. Integrate Kotlin to your Java project with these steps:\n\n\n\n* Add the Kotlin Gradle plug-in to the Module level build.gradle\n\ndependencies {\nclasspath \"com.android.tools.build:gradle:4.1.1\"\nclasspath \"org.jetbrains.kotlin:kotlin-gradle-plugin:$kotlin_version\"\n}\n* Add kotlin-android plugin to the App level build.gradle\n\nplugins {\nid 'com.android.application'\nid 'kotlin-android'\n}\n\n\n\n4. Initialize the SDK.\n\nAppConfiguration appConfiguration = AppConfiguration.getInstance();","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android"},{"document_id":"ibmcld_03893-74275-75877","score":13.7913499433,"text":"\nConfigure an HSM client image[See Build a Docker image](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-hsm-build-docker).\n3. Configure the node to use HSM. From the APIs or the console, when you deploy a peer, CA, or ordering node, you can select the advanced option to use an HSM. See [Configure the node to use the HSM](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-cfg-hsm-node).\n\n\n\n\n\n\n\n Before you begin \n\n\n\n* The Kubernetes CLI is required to configure the HSM. If you are using a Kubernetes cluster on IBM Cloud see [Getting started with IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-getting-started) or [Installing the OpenShift CLI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-cli).\n* You need access to a container registry, such as Docker or the [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-started).\n\n\n\n\n\n\n\n Build a Docker image \n\nConfigure HSM on your blockchain network by publishing an HSM client image to a container registry, as described below.\n\nBuild an HSM client image\n\nNext we build a Docker file that contains the HSM client image. These instructions assume that you have successfully configured your HSM appliance and HSM client. Use these steps to generate an image that is consumable by the IBM Blockchain Platform operator.\n\n\n\n* Step one: Modify the HSM client configuration.\n* Step two: Build the HSM client image.\n* Step three: Push the Docker image to your container registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deployment"},{"document_id":"ibmcld_02680-7-1762","score":13.5797600353,"text":"\nApp Configuration client SDK for Android \n\nApp Configuration service provides Android client SDK to integrate with your Android application that is written in Kotlin or Java programming language.\n\n\n\n Prerequisites \n\nFollowing are the prerequisites for using the App Configuration service SDK for Android:\n\n\n\n* Android API level 22 or later\n* [Android Studio](https:\/\/developer.android.com\/studio\/index.html)\n* [Gradle](https:\/\/gradle.org\/install)\n\n\n\n\n\n\n\n Integrating client SDK for Android app written in Kotlin \n\nApp Configuration service provides Android client SDK to integrate with your Android application. You can evaluate the values of your property and feature flag by integrating the SDK.\n\n\n\n1. Install the SDK by using either one of the options:\n\n\n\n* [Download](https:\/\/github.com\/IBM\/appconfiguration-android-client-sdk) and import the package to your Android studio project.\n* Get the package through Gradle by adding the:\n\n\n\n* Add App Configuration Android client SDK dependency to Project level build.gradle file.\n\nrepositories {\nmavenCentral()\n}\n* Add App Configuration Android client SDK dependency to Module level build.gradle file.\n\ndependencies {\nimplementation \"com.ibm.cloud:appconfiguration-android-sdk:0.3.1\"\n}\n\n\n\n\n\n2. Configure the AndroidManifest.xml file for internet permission.\n\n<uses-permission android:name=\"android.permission.INTERNET\"\/>\n3. Initialize the SDK.\n\nval appConfiguration = AppConfiguration.getInstance()\n\nappConfiguration.init( application,\n\"region\",\n\"guid\",\n\"apikey\")\n\n\/\/To start the configuration fetching operation, set the collectionId and environmentId in the following way.\nappConfiguration.setContext(\"collectionId\",\"environmentId\")\n\nWhere:\n\n\n\n* region - Region name where the service instance is created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android"},{"document_id":"ibmcld_03966-3327-5475","score":13.4527831381,"text":"\n* Org admins: When you join a consortium that is hosted by an ordering service, you provide the signing certificates of identities that will become the administrators for your organization. You can use these identities to create or edit channels.\n* Peer or orderer admins: IBM Blockchain Platform nodes are deployed with the signing certificates of component administrators identities inside of them. These certificates allow the admins to operate the component from a remote client or by using the console.\n* Applications: Your applications need to sign their transactions before submitting them to be validated by the network. You need to create identities you can use to sign transactions from your client applications.\n\n\n\nYou can use the console to create these identities by using the [registration process](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identitiesibp-console-identities-register). After you register your admin identities, you need to issue each identity a signing certificate and private key, provide the signing certificate to your organization MSP definition, and add the identity to your console wallet. You can complete these steps for one admin identity when you [create your organization MSP](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-organizationsconsole-organizations-create-msp). You can use separate identities as org admins or node admins, or you can use one identity to do both tasks. The [Build a network tutorial](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-networkibp-console-build-network) uses one identity to be an admin for each organization created in the tutorial.\n\n\n\n\n\n Associating the identity of the CA admin \n\nBefore you can create identities, you need to associate the identity of the CA admin. Open your CA on the Nodes tab. If you are using the CA for the first time, you can click the Associate identity button to generate the CA admin identity and import it into your console wallet. On the Associate identity side panel, provide the Enroll ID and Enroll secret of the CA admin that you provided when you created the CA.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-identities"},{"document_id":"ibmcld_03114-14238-16113","score":13.3901676105,"text":"\n\"object_1\": {\n\"property_1\": \"Another string value\"\n}\n}\n}\n]\n},\n\"user_id\": \"faf4a112-f09f-4a95-a0be-43c496e6ac9a\"\n}\nShow more\n\nYour application can parse and display the data in any way you choose.\n\n\n\n\n\n\n\n Example: Implementing option responses \n\nTo show how a client application might handle option responses, which prompt the user to select from a list of choices, we can extend the client example described in [Building a client application](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-client). This is a simplified client app that uses standard input and output to handle three intents (sending a greeting, showing the current time, and exiting from the app):\n\nWelcome to the Watson Assistant example!\n>> hello\nGood day to you.\n>> what time is it?\nThe current time is 12:40:42 PM.\n>> goodbye\nOK! See you later.\n\nIf you want to try the example code shown in this topic, you should first set up the required workspace and obtain the API details you will need. For more information, see [Building a client application](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-client).\n\n\n\n Receiving an option response \n\nThe option response can be used when you want to present the user with a finite list of choices, rather than interpreting natural language input. This can be used in any situation where you want to enable the user to quickly select from a set of unambiguous options.\n\nIn our simplified client app, we will use this capability to select from a list of the actions the assistant supports (greetings, displaying the time, and exiting). In addition to the three intents previously shown (hello, time, and goodbye), the example workspace supports a fourth intent: menu, which is matched when the use asks to see a list of available actions.\n\nWhen the workspace recognizes the menu intent, the dialog responds with an option response:\n\n{\n\"output\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-responses"},{"document_id":"ibmcld_03982-9793-12132","score":13.3010308312,"text":"\nBecause an MSP is the representation of an organization in the network, you select the MSP definition when you deploy your nodes (identifying the organization the node belongs to), are joined to the consortium (by an ordering service admin), create a channel, join a channel, edit a channel, or perform any action where you have to specify the organization that is performing the action.\n\n\n\n\n\n Downloading a connection profile \n\nAfter you create an organization MSP definition and create peers with that organization MSP definition, you can download a connection profile that can be used by a client application to connect to your network via one or more gateway peers. The gateway peers are the peers that are specified in the connection profile, and they are used to perform service discovery to find all of the endorsing peers in the network that will endorse transactions.\n\nClick the Organization MSP tile for the organization that your client application interacts with. Click Create connection profile to open a side panel where you can build and download your connection profile.\n\n![Create connection profile panel](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/create-connx-profile.png)\n\nIf you plan to use the client application to register and enroll users with the organization CA, you need to include the Certificate Authority in the connection profile definition.\n\nSelect the peers to include in the connection profile definition. When a peer is not available to process requests from a client application, service discovery ensures that the request is automatically sent to a different peer. Therefore, to accommodate for peer downtime during a maintenance cycle for example, it is recommended that you select more than one peer for redundancy. In addition to peers created by using the console or APIs, imported peers that have been imported into the console are eligible to be selected as well.\n\nThe list of channels that the selected peers have joined is also provided for your information. If a channel is missing from the list, it is likely because the peer joined to it is currently unavailable.\n\nYou can then download the connection profile to your local file system and use it with your client application to generate certificates and invoke smart contracts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-organizations"},{"document_id":"ibmcld_09154-9364-10844","score":13.0546141794,"text":"\necho \"$REQUIRED_PKG Version is: $PKG_VER. OQSSA requires cmake 3.5 and above.\"\nfi\nfi\ndone\nPKG_STATUS=$(yum grouplist Dev* |grep \"Development Tools\")\nif [ \"\" = \"$PKG_STATUS\" ]\nthen\necho \"Developement Tools is NOT installed\"\nfi\necho \"Prerequisites verification completed\"\nShow more\n3. Once prerequisite packages are installed and verified, execute script to build and install OQSSA:\n\nbash build-oqssa.sh\n4. Run the following command to set the Quantum library path:\n\nexport LD_LIBRARY_PATH=$HOME\/opt\/oqssa\/lib:$LD_LIBRARY_PATH\n\n\n\n\n\n\n\n Configuring the Key Protect SDK with your application \n\nOnce you have the prerequisites installed, follow these steps to configure the [Key Protect SDK](https:\/\/github.com\/IBM\/keyprotect-go-clientusage) with your application:\n\n\n\n1. Navigate to the folder where the go client resides by running the following command:\n\ncd $HOME\/keyprotect-go-client\n2. Set the Kyber algorithm in the initialization of the Key Protect client in your application code. If you do not specify an algorithm, your application will default to using the p384_kyber768 algorithm. Use the following code as an example of algorithm configuration:\n\nqscConfig := kp.ClientQSCConfig{\nAlgorithmID: kp.KP_QSC_ALGO_p384_KYBER768,\n}\n3. Compile the Key Protect SDK by running the following command:\n\nLD_LIBRARY_PATH=$HOME\/opt\/oqssa\/lib PKG_CONFIG_PATH=$HOME\/opt\/oqssa\/lib\/pkgconfig go build \u2013-tags quantum\n\n\n\n\n\n\n\n\n\n Using Quantum Safe Key Protect endpoints via CURL \n\n\n\n Prerequisites","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-quantum-safe-cryptography-tls-introduction"},{"document_id":"ibmcld_16261-17057-18537","score":12.9539575809,"text":"\nWhat day would you like to come in?\n>> Next Monday\nWhat time works for you?\n>> 10 AM\nOK, Robert. You have an appointment for 10:00 AM on Sep 12. See you then!\n\nSuccess! The application now uses the Watson Assistant service to understand natural-language input, and it displays the appropriate responses.\n\nThis simple example illustrates how you can build a custom client app to communicate with the assistant. Of course, a real-world application would use a more sophisticated user interface, and it might integrate with other applications such as a customer database or other business systems. It would also need to send additional data to the assistant, such as a user ID to identify each unique user. But the basic principles of how the application interacts with the Watson Assistant service would remain the same.\n\n\n\n\n\n Using the v1 runtime API \n\nUsing the v2 API is the recommended way to build a runtime client application that communicates with the Watson Assistant service. However, some older applications might still be using the v1 runtime API, which includes a similar method for sending messages to the workspace within a dialog skill. Note that if your app uses the v1 runtime API, it communicates directly with the workspace, bypassing the skill orchestration and state-management capabilities of the assistant.\n\nFor more information about the v1 \/message method and context, see the [v1 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1message).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_05514-3075-4395","score":12.9334517525,"text":"\ncurl -X POST \"https:\/\/dde-us-south.analytics.ibm.com\/daas\/v1\/session\" -H \"accept: application\/json\" -H \"authorization: Basic <base64 client_id:client_secret>\" -H \"Content-Type: application\/json\" -d \"{ \"expiresIn\": 3600, \"webDomain\": \"https:\/\/dde-us-south.analytics.ibm.com\"}\"\n\nResponse Example:\n\n{\n\"sessionId\": \"SN401234567801933ccccf\",\n\"sessionCode\": \"CDfc21234567875e06a\",\n\"keys\": [\n{\n\"kty\": \"RSA\",\n\"e\": \"AQAB\",\n\"use\": \"enc\",\n\"kid\": \"58110ceb123456787f417e6298\",\n\"alg\": \"RSA\",\n\"n\": \"AJG6QxPXGdn...clipped\"\n}\n]\n}\n\nUse the sessionCode value to create and initialize the Cognos Dashboard Embedded session.\n\nNote: The sessionCode expires after 60 seconds.\n\nThe keys object values can be used by the server application while the server application encrypts the credentials when it builds the dashboard specification. Do not use the keys directly within the browser application.\n\nWhen you use the Swagger documentation to test the Cognos Dashboard Embedded REST API, enter the client_id in the Username field and the client_secret in the Password field when you authorize the Swagger client using basic authentication. You can find the Swagger documentation for REST API here: [https:\/\/dde-us-south.analytics.ibm.com\/api-docs\/](https:\/\/dde-us-south.analytics.ibm.com\/api-docs\/).\n\nSee the following example screen capture:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10359-14691-16707","score":11.4796974841,"text":"\nThe source IP address of client requests is preserved by default in version 2.0 NLBs.\n\nWhen a client request to your app is sent to your cluster, a load balancer service pod receives the request. If no app pod exists on the same worker node as the load balancer service pod, the NLB forwards the request to a different worker node. The source IP address of the package is changed to the public IP address of the worker node where the load balancer service pod runs.\n\nTo preserve the original source IP address of the client request, you can [enable source IP](https:\/\/kubernetes.io\/docs\/tasks\/access-application-cluster\/create-external-load-balancer\/preserving-the-client-source-ip) for load balancer services. The TCP connection continues all the way to the app pods so that the app can see the actual source IP address of the initiator. Preserving the client\u2019s IP is useful, for example, when app servers have to apply security and access-control policies.\n\nAfter you enable the source IP, load balancer service pods must forward requests to app pods that are deployed to the same worker node only. Typically, load balancer service pods are also deployed to the worker nodes that the app pods are deployed to. However, some situations exist where the load balancer pods and app pods might not be scheduled onto the same worker node:\n\n\n\n* You have edge nodes that are tainted so that only load balancer service pods can deploy to them. App pods are not permitted to deploy to those nodes.\n* Your cluster is connected to multiple public or private VLANs, and your app pods might deploy to worker nodes that are connected only to one VLAN. Load balancer service pods might not deploy to those worker nodes because the NLB IP address is connected to a different VLAN than the worker nodes.\n\n\n\nTo force your app to deploy to specific worker nodes where load balancer service pods can also deploy to, you must add affinity rules and tolerations to your app deployment.\n\n\n\n Adding edge node affinity rules and tolerations","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-loadbalancer"},{"document_id":"ibmcld_05967-15142-16962","score":11.4647575757,"text":"\nIf no app pod exists on the same worker node as the load balancer service pod, the NLB forwards the request to a different worker node. The source IP address of the package is changed to the public IP address of the worker node where the load balancer service pod runs.\n\nTo preserve the original source IP address of the client request, you can [enable source IP](https:\/\/kubernetes.io\/docs\/tasks\/access-application-cluster\/create-external-load-balancer\/preserving-the-client-source-ip) for load balancer services. The TCP connection continues all the way to the app pods so that the app can see the actual source IP address of the initiator. Preserving the client\u2019s IP is useful, for example, when app servers have to apply security and access-control policies.\n\nAfter you enable the source IP, load balancer service pods must forward requests to app pods that are deployed to the same worker node only. Typically, load balancer service pods are also deployed to the worker nodes that the app pods are deployed to. However, some situations exist where the load balancer pods and app pods might not be scheduled onto the same worker node:\n\n\n\n* You have edge nodes that are tainted so that only load balancer service pods can deploy to them. App pods are not permitted to deploy to those nodes.\n* Your cluster is connected to multiple public or private VLANs, and your app pods might deploy to worker nodes that are connected only to one VLAN. Load balancer service pods might not deploy to those worker nodes because the NLB IP address is connected to a different VLAN than the worker nodes.\n\n\n\nTo force your app to deploy to specific worker nodes where load balancer service pods can also deploy to, you must add affinity rules and tolerations to your app deployment.\n\n\n\n Adding edge node affinity rules and tolerations","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-loadbalancer"},{"document_id":"ibmcld_06209-36554-38368","score":11.3565532851,"text":"\nYou can use worker pools to spread worker nodes evenly across zones and build a balanced cluster. Balanced clusters are more available and resilient to failures. If a worker node is removed from a zone, you can rebalance the worker pool and automatically provision new worker nodes to that zone. Worker pools are also used to install Kubernetes version updates to all your worker nodes.\n\nIf you created clusters before multizone clusters became available, your worker nodes are still stand-alone and not automatically grouped into worker pools. You must update these clusters to use worker pools. If not updated, you can't change your single zone cluster to a multizone cluster.\n\nReview the following image to see how your cluster setup changes when you move from stand-alone worker nodes to worker pools.\n\nZoom\n\n![Update your cluster from stand-alone worker nodes to worker pools](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/cs_cluster_migrate.png)\n\nFigure 1. Update your cluster from stand-alone worker nodes to worker pools\n\nBefore you begin:\n\n\n\n* Ensure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms) for the cluster.\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\nTo update stand-alone worker nodes to worker pools:\n\n\n\n1. List existing stand-alone worker nodes in your cluster and note the ID, the Machine Type, and Private IP.\n\nibmcloud ks worker ls --cluster <cluster_name_or_ID>\n2. Create a worker pool and decide on the flavor and the number of worker nodes that you want to add to the pool.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10203-2544-4340","score":11.23867034,"text":"\noc new-app --name <app_name> https:\/\/github.com\/<path_to_app_repo> [--context-dir=<subdirectory>]\n\nWhat does the new-app command do?\n: The new-app command creates a build configuration and app image from the source code, a deployment configuration to deploy the container to pods in your cluster, and a service to expose the app within the cluster. For more information about the build process and other sources besides Git, see the [Red Hat OpenShift documentation](https:\/\/docs.openshift.com\/container-platform\/4.11\/applications\/creating_applications\/odc-creating-applications-using-developer-perspective.html).\n\n\n\n\n\n\n\n Deploying apps to specific worker nodes by using labels \n\nWhen you deploy an app, the app pods indiscriminately deploy to various worker nodes in your cluster. Sometimes, you might want to restrict the worker nodes that the app pods to deploy to. For example, you might want app pods to deploy to only worker nodes in a certain worker pool because those worker nodes are on bare metal machines. To designate the worker nodes that app pods must deploy to, add an affinity rule to your app deployment.\n\nBefore you begin\n\n\n\n* [Access your Red Hat OpenShift cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_cluster).\n* Make sure that you are assigned a [service access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms) that grants the appropriate Kubernetes RBAC role so that you can work with Kubernetes resources in the Red Hat OpenShift project.\n* Optional: [Set a label for the worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersworker_pool_labels) that you want to run the app on.\n\n\n\nTo deploy apps to specific worker nodes,\n\n\n\n1. Get the ID of the worker pool that you want to deploy app pods to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-deploy_app"},{"document_id":"ibmcld_03955-14886-16907","score":10.9572872675,"text":"\nReplica sets guarantee that if the CA node goes down, the CA replica immediately begins processing requests. You must provision an instance of a PostgreSQL database if you plan to use CA replica sets. See these instructions for more information about [how to configure CA replica sets](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-ha-ca).\n\nThis scenario uses redundant peers, ordering nodes, and CAs on a single worker node, which protects against component failure, but cannot protect from node failure. Therefore, it is only suitable for development and testing purposes.\n2. Worker node failure.\n\nSingle-zone cluster with multiple worker nodes and anti-affinity:\n\nA worker node is a VM that runs on a physical hardware. Worker node failures include hardware outages, such as power, cooling, or networking, and issues on the VM itself. You can account for a worker node failure by setting up multiple worker nodes when you provision your cluster. When blockchain components are distributed across multiple worker nodes, you are protected from a worker node failure.\n\nPeers The IBM Blockchain Platform deployer anti-affinity policy distributes redundant peers, that is peers from the same organization, across the worker nodes in their cluster.\n\nOrdering service Whenever you deploy a Raft ordering service, the five ordering nodes are automatically distributed across the worker nodes in your cluster, using the anti-affinity policy and based on resource availability on the nodes.\n\nCAs Like peers and ordering nodes, if replica sets are chosen for a CA, an anti-affinity policy automatically distributes the CA replica sets across worker nodes in the cluster, based on resource availability.\n\nThis scenario uses redundant peers, ordering nodes, and CA replica sets, across multiple worker nodes in a single cluster or zone, which protects against node failure, but cannot protect from a cluster or zone failure. Therefore, it is not recommended for production.\n\n\n\n\n\n\n\n Multizone HA \n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-ha"},{"document_id":"ibmcld_05768-7-1932","score":10.9488610889,"text":"\nRestricting network traffic to edge worker nodes \n\nClassic clusters\n\nEdge worker nodes can improve the security of your IBM Cloud\u00ae Kubernetes Service cluster by allowing fewer worker nodes by isolating the networking workload.\n\nWhen you mark these worker nodes for networking only, other workloads can't consume the CPU or memory of the worker node and interfere with networking.\n\nIf you want to restrict network traffic to edge worker nodes in a multizone cluster, you must have at least two edge worker nodes per zone for high availability of load balancer or Ingress pods. Create an edge node worker pool that spans all the zones in your cluster, with at least two worker nodes per zone.\n\n\n\n Isolating networking workloads to edge nodes \n\nAdd the dedicated=edge label to worker nodes on each public or private VLAN in your cluster. The labels ensure that network load balancers (NLBs) and Ingress application load balancers (ALBs) are deployed to those worker nodes only. For NLBs, ensure that two or more worker nodes per zone are edge nodes. For ALBs, ensure that three or more worker nodes per zone are edge nodes. Both public and private NLBs and ALBs can deploy to edge worker nodes.\n\nBefore you begin\n\n\n\n* Ensure that you have the following [IBM Cloud IAM roles](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms):\n\n\n\n* Any platform access role for the cluster\n* Writer or Manager service access role for all namespaces\n\n\n\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\nTo create an edge node worker pool,\n\n\n\n1. [Create a worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workersadd_pool) that spans all zones in your cluster and has at least two workers per zone if you use NLBs or 3 or more workers per zone if you use ALBs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-edge"},{"document_id":"ibmcld_08923-7-2074","score":10.9425567362,"text":"\nSetting up an HPC cluster \n\n\n\n Objectives \n\n\n\n* Deploy an HPC cluster with your choice of configuration properties\n\n\n\n\n\n\n\n Architecture overview and NFS file system setup \n\nThe HPC cluster consists of a login node, a storage node where the block storage volume is attached, 1 - 3 LSF management nodes, and a number of LSF worker nodes.\n\n\n\n* The login node is served as a jump host and it is the only node that has the public IP address. Other nodes have only private IP addresses and the only way to reach these nodes is through the login node. You can log in to the primary LSF management host and do most of the operations from the LSF management host. By default, lsfadmin is the only user ID created on the cluster. The SSH passwordless setup is configured between the LSF management host and workers. You can reach any other worker node with the lsfadmin user ID from the LSF primary.\n* The worker node can be a static resource. In this case, its lifecycle is managed by Schematics. You can request a number of static worker nodes, and these workers remain available in the LSF cluster until a Schematics-destroy action is performed. The LSF resource connector function creates extra workers when there is not enough capacity to run jobs and destroys workers when the demands decrease. The lifecycle of these dynamic workers is managed by the LSF resource connector. Wait until these dynamic resources are returned to the cloud before you destroy the entire VPC cluster through Schematics.\n* The storage node is configured as an NFS server and the block storage volume is mounted to \/data, which is exported to share with LSF cluster nodes. At the NSF client end, the LSF cluster nodes in this case, the remote directory, \/data, is mounted to \/mnt\/data locally. A soft link, \/home\/lsfadmin\/shared, also points to \/mnt\/data. You can use \/home\/lsfadmin\/shared as a shared file system for your applications.\n\n\n\nThe HPC cluster solution provides a base custom image, which includes the LSF installation. You can create your own custom image on top of the base image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-spectrum-lsf?topic=ibm-spectrum-lsf-using-hpc-cluster"},{"document_id":"ibmcld_05838-25355-26994","score":10.9272446562,"text":"\nThe Autorecovery system uses various checks to query worker node health status. If Autorecovery detects an unhealthy worker node based on the configured checks, Autorecovery triggers a corrective action like rebooting a VPC worker node or reloading the operating system in a classic worker node. Only one worker node undergoes a corrective action at a time. The worker node must complete the corrective action before any other worker node undergoes a corrective action. For more information, see this [Autorecovery blog post](https:\/\/www.ibm.com\/cloud\/blog\/autorecovery-utilizes-consistent-hashing-high-availability).\n\nAutorecovery requires at least one healthy worker node to function properly. Configure Autorecovery with active checks only in clusters with two or more worker nodes.\n\nBefore you begin:\n\n\n\n* Ensure that you have the following [IBM Cloud IAM roles](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms):\n\n\n\n* Administrator platform access role for the cluster\n* Writer or Manager service access role for the kube-system namespace\n\n\n\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\nTo configure Autorecovery:\n\n\n\n1. [Follow the instructions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-helminstall_v3) to install the Helm version 3 client on your local machine.\n2. Create a configuration map file that defines your checks in JSON format. For example, the following YAML file defines three checks: an HTTP check and two Kubernetes API server checks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitor"},{"document_id":"ibmcld_05717-7-1768","score":10.8565211505,"text":"\nWhy can't I SSH into my worker node? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n What\u2019s happening \n\nYou can't access your worker node by using an SSH connection.\n\n Why it\u2019s happening \n\nSSH by password is unavailable on the worker nodes.\n\n How to fix it \n\nTo run actions on every worker node, use a Kubernetes [DaemonSet](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/daemonset\/), or use jobs for one-time actions.\n\nTo get host access to worker nodes for debugging and troubleshooting purposes, review the following options.\n\n\n\n Debugging by using kubectl debug \n\nUse the kubectl debug node command to deploy a pod with a privileged securityContext to a worker node that you want to troubleshoot.\n\nThe debug pod is deployed with an interactive shell so that you can access the worker node immediately after the pod is created. For more information about how the kubectl debug node command works, see [debug command in Kubernetes reference](https:\/\/kubernetes.io\/docs\/reference\/generated\/kubectl\/kubectl-commandsdebug).\n\n\n\n1. Get the name of the worker node that you want to access. The worker node name is its private IP address.\n\nkubectl get nodes -o wide\n2. Create a debug pod that has host access. When the pod is created, the pod's interactive shell is automatically opened. If the kubectl debug node command fails, continue to option 2. The Docker alpine image here is used as an example. If the worker node doesn't have public network access, you can maintain a copy of the image for debugging in your own ICR repository or build a customized image with other tools to fit your needs.\n\nkubectl debug node\/<NODE_NAME> --image=docker.io\/library\/alpine:latest -it\n3. Run debug commands to help you gather information and troubleshoot issues.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ssh_worker"},{"document_id":"ibmcld_10160-7-1782","score":10.8391988345,"text":"\nWhy can't I SSH into my worker node? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n What\u2019s happening \n\nYou can't access your worker node by using an SSH connection.\n\n Why it\u2019s happening \n\nSSH by password is unavailable on the worker nodes.\n\n How to fix it \n\nTo run actions on every worker node, use a Kubernetes [DaemonSet](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/daemonset\/), or use jobs for one-time actions.\n\nTo get host access to worker nodes for debugging and troubleshooting purposes, review the following options.\n\n\n\n Debugging by using oc debug \n\nUse the oc debug node command to deploy a pod with a privileged securityContext to a worker node that you want to troubleshoot.\n\nThe debug pod is deployed with an interactive shell so that you can access the worker node immediately after the pod is created. For more information about how the oc debug node command works, see [this Red Hat blog post](https:\/\/www.redhat.com\/sysadmin\/how-oc-debug-works).\n\n\n\n1. Get the name of the worker node that you want to access. The worker node name is its private IP address.\n\noc get nodes -o wide\n2. Create a debug pod that has host access. When the pod is created, the pod's interactive shell is automatically opened. If the oc debug node command fails, continue to option 2. The Docker alpine image here is used as an example. If the worker node doesn't have public network access, you can maintain a copy of the image for debugging in your own ICR repository or build a customized image with other tools to fit your needs.\n\noc debug node\/<NODE_NAME>\n3. Run debug commands to help you gather information and troubleshoot issues. Commands that you might use to debug, such as tcpdump, curl, ip, ifconfig, nc, ping, and ps, are already available in the shell.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ssh_worker"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05891-127567-129211","score":12.0822237143,"text":"\n--name NAME\n: Required: Set the name for the worker pool.\n\n-c, --cluster CLUSTER\n: Required: Specify the name or ID of the cluster. To list VPC clusters, run ibmcloud ks cluster ls --provider vpc-gen2.\n\n--size-per-zone NUMBER_WORKERS_PER_ZONE\n: Specify the number of worker nodes to create per zone in this worker pool. No worker nodes are created until you [add zones](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clicli_zone-add-vpc-gen2) to the worker pool. This value is required, and must be 1 or greater. For more information, see [What is the smallest size cluster that I can make?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqssmallest_cluster).\n\n--operating-system SYSTEM\n: Optional. The operating system of the worker nodes you want to provision in your cluster. For a list of available operating systems by cluster version, see [IBM Cloud Kubernetes Service version information](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions).\n\n--flavor FLAVOR\n: Choose a flavor for your worker nodes. You can deploy your worker nodes as virtual machines on shared or dedicated hardware. To see flavors that are available in a VPC zone, run ibmcloud ks flavors --zone <vpc_zone> --provider vpc-gen2.\n\n--vpc-id VPC_ID\n: Optional: Specify the ID of the VPC in which to create the worker pool's worker nodes. The value must match the VPC ID that the cluster is in. To list the cluster's VPC ID, run ibmcloud ks cluster get -c <cluster_name_or_ID>. If this option is not provided, then the worker pool defaults to the VPC ID of existing worker pools in the cluster.\n\n-l, --label KEY1=VALUE1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_10442-1449-3496","score":12.0629837383,"text":"\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone. After the worker node is provisioned, the worker node IP address persists after a reboot operation, but the worker node IP address changes after replace and update operations.\n\nSubnets provide a channel for connectivity among the worker nodes within the cluster. Additionally, any system that is connected to any of the private subnets in the same VPC can communicate with workers. For example, all subnets in one VPC can communicate through private layer 3 routing with a built-in VPC router. If you have multiple clusters that must communicate with each other, you can create the clusters in the same VPC. However, if your clusters don't need to communicate, you can achieve better network segmentation by creating the clusters in separate VPCs. You can also create [access control lists (ACLs)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-acls) for your VPC subnets to mediate traffic on the private network. ACLs consist of inbound and outbound rules that define which ingress and egress is permitted for each VPC subnet.\n\nWhen you create a VPC cluster and enable both the public and private cloud service endpoints during cluster creation, the public cloud service endpoint is used by default for access to components such as the Red Hat OpenShift web console for your cluster. In order for console pods to establish a secure, public connection over the internet through the public service endpoint, you must enable a public gateway on each VPC subnet that your worker nodes are deployed to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basics"},{"document_id":"ibmcld_10041-35993-37421","score":12.0623060564,"text":"\nGET\/v1\/clusters\/{idOrName}\/workers\/{workerId} View details of a worker node. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorker View details of a worker node for classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkerPool View details of a worker pool for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkerPools View details of a worker pool for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkers View all workers for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorker View details of a worker node for cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkerPool View details of a worker pool for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkerPools View details of a worker pool for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkers View all workers for cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorker View details of a worker node for VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkerPool View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkerPools View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkers View all workers for VPC cluster. containers-kubernetes.cluster.read N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-35959-37387","score":12.0623060564,"text":"\nGET\/v1\/clusters\/{idOrName}\/workers\/{workerId} View details of a worker node. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorker View details of a worker node for classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkerPool View details of a worker pool for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkerPools View details of a worker pool for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/classic\/getWorkers View all workers for a classic cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorker View details of a worker node for cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkerPool View details of a worker pool for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkerPools View details of a worker pool for a cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/getWorkers View all workers for cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorker View details of a worker node for VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkerPool View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkerPools View details of a worker pool for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getWorkers View all workers for VPC cluster. containers-kubernetes.cluster.read N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_06007-1457-3349","score":12.0492091654,"text":"\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone. After the worker node is provisioned, the worker node IP address persists after a reboot operation, but the worker node IP address changes after replace and update operations.\n\nSubnets provide a channel for connectivity among the worker nodes within the cluster. Additionally, any system that is connected to any of the private subnets in the same VPC can communicate with workers. For example, all subnets in one VPC can communicate through private layer 3 routing with a built-in VPC router. If you have multiple clusters that must communicate with each other, you can create the clusters in the same VPC. However, if your clusters don't need to communicate, you can achieve better network segmentation by creating the clusters in separate VPCs. You can also create [access control lists (ACLs)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-acls) for your VPC subnets to mediate traffic on the private network. ACLs consist of inbound and outbound rules that define which ingress and egress is permitted for each VPC subnet.\n\nIf your worker nodes must access a public endpoint outside of the cluster, you can enable a public gateway on the VPC subnet that the worker nodes are deployed to. A public gateway can be attached to or detached from a subnet at any time.\n\nThe default IP address range for VPC subnets is 10.0.0.0 \u2013 10.255.255.255.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basics"},{"document_id":"ibmcld_04489-128045-129633","score":12.0312858373,"text":"\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service.\n\nCommand options:\n\n--name NAME\n: Required: Set the name for the worker pool.\n\n-c, --cluster CLUSTER\n: Required: Specify the name or ID of the cluster. To list VPC clusters, run ibmcloud ks cluster ls --provider vpc-gen2.\n\n--size-per-zone NUMBER_WORKERS_PER_ZONE\n: Specify the number of worker nodes to create per zone in this worker pool. No worker nodes are created until you [add zones](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-clicli_zone-add-vpc-gen2) to the worker pool. This value is required, and must be 1 or greater. For more information, see [What is the smallest size cluster that I can make?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqssmallest_cluster).\n\n--operating-system SYSTEM\n: Optional. The operating system of the worker nodes you want to provision in your cluster. For a list of available operating systems by cluster version, see [IBM Cloud Kubernetes Service version information](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions).\n\n--flavor FLAVOR\n: Choose a flavor for your worker nodes. You can deploy your worker nodes as virtual machines on shared or dedicated hardware. To see flavors that are available in a VPC zone, run ibmcloud ks flavors --zone <vpc_zone> --provider vpc-gen2.\n\n--vpc-id VPC_ID\n: Optional: Specify the ID of the VPC in which to create the worker pool's worker nodes. The value must match the VPC ID that the cluster is in. To list the cluster's VPC ID, run ibmcloud ks cluster get -c <cluster_name_or_ID>.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_06286-7-1968","score":11.9931172366,"text":"\nConfiguring VPC subnets \n\nVirtual Private Cloud\n\nChange the pool of available portable public or private IP addresses by adding subnets to your IBM Cloud\u00ae Kubernetes Service VPC cluster.\n\nThe content on this page is specific to VPC clusters. For information about classic clusters, see [Configuring subnets and IP addresses for classic clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-subnets).\n\n\n\n Overview of VPC networking in IBM Cloud Kubernetes Service \n\nUnderstand the basic concepts of VPC networking in IBM Cloud Kubernetes Service clusters.\n\n\n\n Subnets \n\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you can specify only one existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone. After the worker node is provisioned, the worker node IP address persists after a reboot operation, but the worker node IP address changes after replace and update operations.\n\nDo not delete the subnets that you attach to your cluster during cluster creation or when you add worker nodes in a zone. If you delete a VPC subnet that your cluster used, any load balancers that use IP addresses from the subnet might experience issues, and you might be unable to create new load balancers.\n\n\n\n How many IP addresses do I need for my VPC subnet? \n\nWhen you [create your VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network), make sure to create a subnet with enough IP addresses for your cluster, such as 256. You can't change the number of IP addresses that a VPC subnet has later.\n\nKeep in mind the following IP address reservations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-subnets"},{"document_id":"ibmcld_06007-7-1994","score":11.9819214964,"text":"\nUnderstanding network basics of VPC clusters \n\nWhen you create your cluster, you must choose a networking setup so that certain cluster components can communicate with each other and with networks or services outside of the cluster.\n\n\n\n* [Worker-to-worker communication](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-worker-worker): All worker nodes must be able to communicate with each other on the private network through VPC subnets.\n* [Worker-to-master and user-to-master communication](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-workeruser-master): Your worker nodes and your authorized cluster users can communicate with the Kubernetes master securely over virtual private endpoints or cloud service endpoints.\n* [Worker communication to other services or networks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-worker-services-onprem): Allow your worker nodes to securely communicate with other IBM Cloud services, such as IBM Cloud\u00ae Container Registry, to on-premises networks, to other VPCs, or to classic infrastructure resources.\n* [External communication to apps that run on worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-external-workers): Allow public or private requests into the cluster as well as requests out of the cluster to a public endpoint.\n\n\n\n\n\n Worker-to-worker communication using VPC subnets \n\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basics"},{"document_id":"ibmcld_10691-7-1974","score":11.9773687349,"text":"\nConfiguring VPC subnets \n\nVirtual Private Cloud\n\nChange the pool of available portable public or private IP addresses by adding subnets to your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae VPC cluster.\n\nThe content on this page is specific to VPC clusters. For information about classic clusters, see [Configuring subnets and IP addresses for classic clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-subnets).\n\n\n\n Overview of VPC networking in Red Hat OpenShift on IBM Cloud \n\nUnderstand the basic concepts of VPC networking in Red Hat OpenShift on IBM Cloud clusters.\n\n\n\n Subnets \n\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you can specify only one existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone. After the worker node is provisioned, the worker node IP address persists after a reboot operation, but the worker node IP address changes after replace and update operations.\n\nDo not delete the subnets that you attach to your cluster during cluster creation or when you add worker nodes in a zone. If you delete a VPC subnet that your cluster used, any load balancers that use IP addresses from the subnet might experience issues, and you might be unable to create new load balancers.\n\n\n\n How many IP addresses do I need for my VPC subnet? \n\nWhen you [create your VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network), make sure to create a subnet with enough IP addresses for your cluster, such as 256. You can't change the number of IP addresses that a VPC subnet has later.\n\nKeep in mind the following IP address reservations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-subnets"},{"document_id":"ibmcld_10700-0-1757","score":11.9706799389,"text":"\n\n\n\n\n\n\n  VPC clusters: Why do I see VPC load balancer health status failures? \n\nVirtual Private Cloud\n\n  What\u2019s happening \n\nIn the [Load balancers for VPC dashboard](https:\/\/cloud.ibm.com\/vpc-ext\/network\/loadBalancers), you view the details of the VPC load balancer that exposes your cluster's Ingress controller.\n\nAlthough traffic to your apps is flowing correctly in your cluster, the Health status of the VPC load balancer shows that at most 2 instances (worker nodes) are Passing, while all other instances are Failing. For example, if you have 4 worker nodes in your cluster, the health status shows 2\/4.\n\n  Why it\u2019s happening \n\nIn VPC clusters, a VPC load balancer that exposes the Ingress controller is automatically created outside of your cluster. In the configuration for the load balancer, externalTrafficPolicy is set to Local, which offers better routing performance than Cluster.\n\nThis externalTrafficPolicy: Local setting indicates that when the VPC load balancer receives a request to your app service's node port, the load balancer forwards the traffic only to Ingress controller pods that are also on the same worker node as the app service's node port.\n\nBy default in the OpenShift Container Platform Ingress controller, only 2 Ingress controller pods are deployed to your cluster, so only 2 worker nodes have Ingress controller pods. Because the VPC load balancer forwards traffic only to worker nodes that contain Ingress controller pods, the load balancer's health check only reports the 2 worker nodes that have the Ingress controller pods as Passing, and the other worker nodes as Failing. For this reason, the failures are expected, and don't indicate that your VPC load balancer is unable to forward traffic to your cluster.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_lb_healthcheck"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10041-17616-19200","score":10.855476555,"text":"\nPOST\/v2\/alb\/updateAlb Update ALBs in a cluster. containers-kubernetes.cluster.update cluster-alb.update \n POST\/v2\/alb\/vpc\/createAlb Create a public or private ALB in a VPC cluster. containers-kubernetes.cluster.update cluster-alb.create \n POST\/v2\/alb\/vpc\/disableAlb Disable an ALB in a VPC cluster. containers-kubernetes.cluster.update cluster-alb.delete \n POST\/v2\/alb\/vpc\/enableAlb Enable an existing ALB in a VPC cluster. containers-kubernetes.cluster.update cluster-alb.enable \n PUT\/v1\/alb\/albsecrets Update an ALB secret that you imported from Secrets Manager. containers-kubernetes.cluster.create cluster-ingress-secret.update \n PUT\/v1\/alb\/clusters\/{idOrName}\/update Force a one-time update of all ALB pods to the latest build. containers-kubernetes.cluster.update cluster-alb.update \n PUT\/v1\/alb\/clusters\/{idOrName}\/updatepolicy Enable or disable automatic updates for the Ingress ALBs in a cluster. containers-kubernetes.cluster.update cluster-alb-policy.update \n PUT\/v1\/alb\/clusters\/{idOrName}\/updaterollback Roll back all ALB pods in a cluster to their previously running build. containers-kubernetes.cluster.update cluster-alb-policy.update \n\n\n\n\n\n\n\n Ingress load balancer \n\n\n\nIngress load balancer API methods, IAM actions, and Activity Tracker events.\n\n API Method Description IAM action for the API Activity Tracker event \n\n GET\/ingress\/v2\/load-balancer\/configuration Get the configuration of load balancers for Ingress ALBs. containers-kubernetes.cluster.read N\/A \n PATCH\/ingress\/v2\/load-balancer\/configuration Update the configuration of load balancers for Ingress ALBs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-17596-19180","score":10.855476555,"text":"\nPOST\/v2\/alb\/updateAlb Update ALBs in a cluster. containers-kubernetes.cluster.update cluster-alb.update \n POST\/v2\/alb\/vpc\/createAlb Create a public or private ALB in a VPC cluster. containers-kubernetes.cluster.update cluster-alb.create \n POST\/v2\/alb\/vpc\/disableAlb Disable an ALB in a VPC cluster. containers-kubernetes.cluster.update cluster-alb.delete \n POST\/v2\/alb\/vpc\/enableAlb Enable an existing ALB in a VPC cluster. containers-kubernetes.cluster.update cluster-alb.enable \n PUT\/v1\/alb\/albsecrets Update an ALB secret that you imported from Secrets Manager. containers-kubernetes.cluster.create cluster-ingress-secret.update \n PUT\/v1\/alb\/clusters\/{idOrName}\/update Force a one-time update of all ALB pods to the latest build. containers-kubernetes.cluster.update cluster-alb.update \n PUT\/v1\/alb\/clusters\/{idOrName}\/updatepolicy Enable or disable automatic updates for the Ingress ALBs in a cluster. containers-kubernetes.cluster.update cluster-alb-policy.update \n PUT\/v1\/alb\/clusters\/{idOrName}\/updaterollback Roll back all ALB pods in a cluster to their previously running build. containers-kubernetes.cluster.update cluster-alb-policy.update \n\n\n\n\n\n\n\n Ingress load balancer \n\n\n\nIngress load balancer API methods, IAM actions, and Activity Tracker events.\n\n API Method Description IAM action for the API Activity Tracker event \n\n GET\/ingress\/v2\/load-balancer\/configuration Get the configuration of load balancers for Ingress ALBs. containers-kubernetes.cluster.read N\/A \n PATCH\/ingress\/v2\/load-balancer\/configuration Update the configuration of load balancers for Ingress ALBs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_05653-237608-239360","score":10.3539078765,"text":"\n: With the latest version of the cluster autoscaler, you can [enable autoscaling for worker pools during the Helm chart installation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-scaling-helm) instead of modifying the config map after installation.\n\nIngress ALB change log\n: Updated the ALB [nginx-ingress image to build 524 and ingress-auth image to build 337](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-add-ons-changelogkube_ingress_changelog).\n\n\n\n\n\n 23 August 2019 \n\nApp networking in VPC\n: Updated the [Planning in-cluster and external networking for apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_network_planning) topic with information for planning app networking in a VPC cluster.\n\nIstio in VPC\n: Updated the [managed Istio add-on](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio) topic with information for using Istio in a VPC cluster.\n\nRemove bound services from cluster\n: Added instructions for how to remove an IBM Cloud service that you added to a cluster by using service binding. For more information, see [Removing a service from a cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-bindingunbind-service).\n\n\n\n\n\n 20 August 2019 \n\nIngress ALB change log\n: Updated the ALB [nginx-ingress image to build 519](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-add-ons-changelogkube_ingress_changelog) for a custom-ports bug fix.\n\n\n\n\n\n 19 August 2019 \n\nNew! Virtual Private Cloud\n: You can create standard Kubernetes clusters on classic infrastructure in the next generation of the IBM Cloud platform, in your Virtual Private Cloud. VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-containers-relnotes"},{"document_id":"ibmcld_05863-8906-10403","score":10.2653194461,"text":"\nWhen you create a multizone cluster, a default public ALB is created in each zone where you have worker nodes. If you later remove one of these original three zones and add workers in a different zone, a default public ALB is not created in that new zone. You can manually create an ALB to process connections in that new zone.\n\n\n\n1. In each zone where you have worker nodes, create an ALB.\n\nThe following command applies to classic clusters. For more information and command options, see the [CLI reference](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_alb_create).\n\nibmcloud ks ingress alb create --cluster <cluster_name_or_ID> --type <public_or_private> --zone <zone> --vlan <VLAN_ID> [--ip <IP_address>] [--version image_version]\n\nThe following command applies to VPC clusters. For more information and command options, see the [CLI reference](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clicli_alb-create-vpc-gen2).\n\nibmcloud ks ingress alb create vpc-gen2 --cluster <cluster_name_or_ID> --type <public_or_private> --zone <vpc_zone> [--version image_version]\n2. Verify that the ALBs that you created in each zone have a Status of enabled. For classic clusters, check that an ALB IP is assigned. For VPC clusters, check that Load Balancer Hostname is assigned.\n\nibmcloud ks ingress alb ls --cluster <cluster_name_or_ID>\n\nExample output for a classic cluster.\n\nALB ID Enabled Status Type ALB IP Zone Build ALB VLAN ID NLB Version","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ingress-alb-manage"},{"document_id":"ibmcld_05869-4079-5594","score":10.1246,"text":"\nreserved_private_ip:\n----\n\nreserved_private_vlan_id:\n----\n\nreserved_public_ip:\n----\n\nEvents: <none>\n\n\n\n* VPC clusters: Verify that the VPC load balancer for your ALBs exists. In the output, look for the VPC load balancer Name that starts with kube-<cluster_ID>. If you did not install the infrastructure-service plug-in, install it by running ibmcloud plugin install infrastructure-service.\n\nibmcloud is load-balancers\n\n\n\nEven though the VPC load balancer is listed, its DNS entry might still be registering. When a VPC load balancer is created, the hostname is registered through a public DNS. Sometimes, it can take several minutes for this DNS entry to be replicated to the specific DNS that your client is using.\n3. Check whether an ALB exists for your cluster and that the ALB has an IP address (classic clusters) or hostname (VPC clusters) assigned.\n\nibmcloud ks ingress alb ls -c <cluster_name_or_ID>\n\nExample output\n\nALB ID Enabled Status Type ALB IP Zone Build ALB VLAN ID NLB Version\nprivate-crbmnj1b1d09lpvv3oof0g-alb1 false disabled private - dal10 ingress:1.1.2_2507_iks 2234947 2.0\npublic-crbmnj1b1d09lpvv3oof0g-alb1 true enabled public 169.XX.XXX.XX dal10 ingress:1.1.2_2507_iks 2234945 2.0\n\n\n\n* If a public ALB is listed and is assigned an IP address (classic clusters) or hostname (VPC clusters), continue to the next step.\n* If a public ALB is listed and but is not assigned an IP address (classic clusters) or hostname (VPC clusters), try to disable and re-enable the ALBs.\n\n\n\n* Classic clusters:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ingress_subdomain"},{"document_id":"ibmcld_14751-1472-3648","score":10.0154591569,"text":"\nWhen you are planning the sizing for your VMware vSphere clusters in IBM Cloud VPC, consider the VMware best practices that are documented in [VMware validated designs](https:\/\/docs.vmware.com\/en\/VMware-Validated-Design\/5.1\/sddc-architecture-and-design\/) to meet your capacity and high availability targets.\n\nTheoretically, as each IBM Cloud VPC Bare Metal Server is deployed individually, you can build a solution as small as one ESXi host per IBM Cloud VPC zone. However, you need to take the high availability aspects into account. To protect your VMware workloads from host failures, for example in case one host stops functioning, you need to have a cluster with at least two hosts. To keep the workloads running, you need to size enough reserve capacity in each cluster even if a host would fail. In most use cases, a three node cluster is far more appropriate because you have the option of running maintenance tasks on ESXi hosts (such as host updates) without having to disable HA.\n\nAs the central point of SDDC management (vCenter Server and NSX-T Managers) runs on the same IBM Cloud VPC Bare Metal Servers, protecting them is key. You can use vSphere HA and anti-affinity rules (to prevent specific VMs from running on a same host) for these in the vSphere HA cluster. As your initial cluster is typically a management cluster, VMware best practice is to build a management cluster of four hosts or more allowing the cluster to tolerate host failures better and you to perform maintenance tasks much easier, especially with NSX-T and vSAN deployments. Typically, it's not suitable to have three or fewer hosts for a management or a converged management and workload cluster in production.\n\nIn general, when you are deploying vSphere HA clusters, it is also important to consider the overall size of the cluster. Smaller sized clusters require a larger relative percentage of all the available cluster resources to be reserved to handle failures. For example, a cluster of three nodes requires at least 33% of the cluster resources to be held on reserve for failover where a cluster of eight nodes requires 12.5% of cluster resources that are reserved for failover.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vpc-ryo-considerations"},{"document_id":"ibmcld_05653-238867-240677","score":9.9409354482,"text":"\n: Updated the ALB [nginx-ingress image to build 519](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-add-ons-changelogkube_ingress_changelog) for a custom-ports bug fix.\n\n\n\n\n\n 19 August 2019 \n\nNew! Virtual Private Cloud\n: You can create standard Kubernetes clusters on classic infrastructure in the next generation of the IBM Cloud platform, in your Virtual Private Cloud. VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. Classic on VPC clusters are available for only standard, Kubernetes clusters and are not supported in free or Red Hat OpenShift clusters.\n: With classic clusters in VPC, IBM Cloud Kubernetes Service introduces version 2 of the API, which supports multiple infrastructure providers for your clusters. Your cluster network setup also changes, from worker nodes that use public and private VLANs and the public cloud service endpoint to worker nodes that are on a private subnet only and have the private cloud service endpoint enabled. For more information, check out the following links.\n\n\n\n* [Overview of Classic and VPC infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers)\n* [About the v2 API](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_api_installapi_about)\n* [Understanding network basics of VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basics)\n\n\n\n: Ready to get started? Try out the [Creating a classic cluster in your VPC tutorial](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc_ks_tutorial).\n\nKubernetes 1.14\n: [Kubernetes 1.14](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionscs_versions_available) is now the default version.\n\n\n\n\n\n 17 August 2019 \n\nIBM Cloud\u00ae Activity Tracker","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-containers-relnotes"},{"document_id":"ibmcld_08285-7-1923","score":9.9332856497,"text":"\nDeployment values \n\nThe following deployment values can be used to configure the Slurm cluster instance on IBM Cloud.\n\n\n\nTable 1. Deployment values\n\n Value Description Type Is it required? Default value \n\n api_key This is the IBM Cloud API key for the IBM Cloud account where the Slurm cluster needs to be deployed. For more information on how to create an API key, see [Managing user API keys](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userapikey). String Yes None \n cluster_id Unique ID of the cluster used by Slurm for configuration of resources. This must be up to 39 alphanumeric characters including the underscore (_), the hyphen (-), and the period (.). Other special characters and spaces are not allowed. Do not use the name of any host or user as the name of your cluster. You cannot change it after installation. String No SlurmCluster \n cluster_prefix Prefix that is used to name the Slurm cluster and IBM Cloud resources that are provisioned to build the Slurm cluster instance. You cannot create more than one instance of the Slurm cluster with the same name. Make sure that the name is unique. String No hpcc-slurm \n image_name Name of the image that you want to use to create virtual server instances in your IBM Cloud account to deploy as worker nodes in the Slurm cluster. By default, the automation uses a stock operating system image. If you would like to include your application-specific binary files, follow the instructions in [Planning for custom images](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-planning-custom-images) to create your own custom image and use that to build the Slurm cluster through this offering. Note that use of your own custom image might require changes to the cloud-init scripts, and potentially other files, in the Terraform code repository if different post-provisioning actions or variables need to be implemented. String No ibm-ubuntu-20-04-minimal-amd64-2","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-slurm?topic=hpc-slurm-deployment-values"},{"document_id":"ibmcld_10702-11424-12919","score":9.8358862616,"text":"\nNAME READY STATUS RESTARTS AGE\nhello-world-1-9cv7d 1\/1 Running 0 30m\nhello-world-1-build 0\/1 Completed 0 31m\nhello-world-1-deploy 0\/1 Completed 0 31m\n\n\n\n\n\n\n\n\n\n Step 3: Set up a VPC load balancer to expose your app publicly \n\nSet up a VPC load balancer to expose your app to external requests on the public network.\n\nWhen you create a Kubernetes LoadBalancer service in your cluster, a VPC load balancer is automatically created in your VPC outside of your cluster. The VPC load balancer is multizonal and routes requests for your app through the private NodePorts that are automatically opened on your worker nodes. The following diagram illustrates how a user accesses an app's service through the VPC load balancer, even though your worker node is connected to only a private subnet.\n\nZoom\n\n![VPC load balancing for an Red Hat OpenShift cluster.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/openshift\/images\/vpc_roks_tutorial_lesson4_lb.png)\n\nFigure 1. VPC load balancing for an Red Hat OpenShift cluster\n\nInterested in using a Red Hat OpenShift route to expose your app instead? Check out [How does a request via route get to my app in a VPC cluster?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_routesroute_vpc) and [Setting up public routes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_routesroutes-setup).\n\n\n\n1. Create a Kubernetes LoadBalancer service in your cluster to publicly expose the hello world app.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc_rh_tutorial"},{"document_id":"ibmcld_06282-17354-19397","score":9.8275861533,"text":"\nWhen you create your VPC cluster, you can also attach additional security groups alongside, or instead of, the default VPC security groups. The security groups applied to the workers in the cluster are a combination of the security groups applied when you create the cluster and [when you create the worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-groupvpc-sg-worker-pool). A total of five security groups can be applied to workers, including the default security groups and any security groups applied to the worker pool. Note that these security group options are only available in the CLI.\n\nThe security groups applied to a cluster cannot be changed once the cluster is created. You can [change the rules of the security groups](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-groupvpc-sg-create-rules) that are applied to the cluster, but you cannot add or remove security groups at the cluster level. If you apply the incorrect security groups at cluster create time, you must delete the cluster and create a new one.\n\n\n\n If you only want the default VPC and cluster security groups and no additional security groups \n\nVPC security group\n\nCluster security group\n\nNote that this is the default behavior at cluster create time.\n\nWhen you create your cluster, do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the default VPC and kube-<cluster-id> cluster security groups:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id>\n\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-security-group"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08921-1291-2538","score":15.5872489287,"text":"\n\"name\": \"Schematic Dev Workspace\",\n\u00a0 \"type\": [\n\u00a0\u00a0\u00a0 \"terraform_v0.13.7\"\n\u00a0 ],\n\u00a0 \"location\": \"us-south\",\n\u00a0 \"description\": \"Schematic Dev Workspace\",\n\u00a0 \"tags\": [],\n\u00a0 \"template_repo\": {\n\u00a0\u00a0\u00a0 \"url\": \"<GitHub repo URL>\",\n\u00a0\u00a0\u00a0 \"githubtoken\": \"<github-token>\"\n\u00a0 }\n\n\n\n Example Python request for schematics_variables_update.py file \n\nThe following Python example request is for the example file, schematics_variables_update.py.\n\nimport logging, os, json\n\nlogging.basicConfig()\nlogging.root.setLevel(logging.NOTSET)\nlogging.basicConfig(level=logging.NOTSET)\n\nfrom schematics_env_class import HPCCEnvironmentValues\n\nlogging.info(\"Schematic Variable Update Started\")\n\nif __name__ == '__main__':\n\n\u00a0\u00a0\u00a0 json_files = os.path.join(os.path.abspath(\".\"), \"config.json\")\n\n\u00a0\u00a0\u00a0 with open(json_files, \"r\") as file:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 config_data = json.load(file)\n\n\u00a0\u00a0\u00a0 api_key = config_data[\"template_data\"][\"variablestore\"][\"value\"]\n\n\u00a0\u00a0\u00a0 schematic_obj = HPCCEnvironmentValues(api_key)\n\n\u00a0\u00a0\u00a0 workspace_response = schematic_obj.schematics_service.get_workspace(w_id=\"<workspace id>\").get_result()\n\u00a0\u00a0\u00a0 schematic_obj.update_variables(w_id=\"<workspace id>\",\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 t_id=workspace_response[\"template_data\"][\"id\"],\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 variablestore=config_data[\"template_data\"][\"variablestore\"]\n\u00a0\u00a0\u00a0 )","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-spectrum-lsf?topic=ibm-spectrum-lsf-update-variables"},{"document_id":"ibmcld_12008-4112-6332","score":15.3191991633,"text":"\nCorrect the Terraform config error at source and push a new release to its Git source repository.\n\nIf explicit version of the blueprint modules is used on specific branches. The blueprint template requires updating in its Git repository to specify the new release tag or branch for the module statement.\n\n\n\n* Update the blueprint module statements to specify the new module version.\n* Push the new release of the blueprint template to its Git source repository. With an updated release tag for the template if needed.\n\n\n\nFor modules, when no Git release is specified on the blueprint module statements and relaxed module version are used. No update to the blueprint template is needed. The current change to the module repository is pulled automatically by Schematics.\n\nRun the ibmcloud schematics blueprint update command to refresh the blueprint configuration that is stored by Schematics with the update to the blueprint template. With latest release, Schematics identifies the updated module Git repository and run the Pull-Latest to update any modules with the modified Terraform configurations.\n\nibmcloud schematics blueprint update -id <blueprint_ID>\u00a0\n\nIf explicit version is used with release tags for each blueprint template release, the blueprint configuration must be updated in Schematics with the new release tag.\n\nibmcloud schematics blueprint update --id <blueprint_ID> --bp-git-release x.y.z\u00a0\u00a0\n\nFinally, run the ibmcloud schematics blueprint apply command to rerun the failed Terraform Apply operation and to complete all operations against all modules.\n\nibmcloud schematics blueprint apply -id <blueprint_ID>\u00a0\n\n\n\n\n\n Blueprint apply failure due to Terraform timeouts or transient failures \n\n What\u2019s happening \n\nWhen you run the blueprint apply command, it fails with message that the install of module fails.\n\n Why it\u2019s happening \n\nAnalysis of the logs indicates that the modules Terraform apply operation that is timed out or a transient failure occurs.\n\n How to fix it \n\nNo user action must be necessary to recover and the apply operation can be retried.\n\nRun the ibmcloud schematics blueprint apply command to rerun the failed Terraform Apply operation and complete all operations against all modules.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-bp-apply-fails"},{"document_id":"ibmcld_04516-141225-142546","score":15.2530072074,"text":"\nTo find the ID of your workspace, run ibmcloud schematics workspace list command. || --file or -f | Required | Enter the full file path on your local machine where your .tar file is stored. || --template or -tid | Required | The unique identifier of the Terraform template for which you want to show the content of the Terraform state file. To find the ID of the template, run ibmcloud schematics workspace get --id <workspace_ID> and find the template ID in the Template Variables for: field of your command-line output. || --output or -o | Optional | Returns the command-line output in JSON format. Currently only JSON file format is supported. || --json or -j | Deprecated | Prints the output in the JSON format. |<-- <\/table \"\"> -->Example ibmcloud schematics workspace upload --id myworkspace-a1aa1a1a-a11a-11 --file \/Users\/myuser\/Documents\/mytar\/vpc.tar --template 25111111-0000-4c\nCreate the TAR file of your template repo by using the TAR command given tar -cvf vpc.tar $TEMPLATE_REPO_FOLDER<-- <section \"id=\"section-syntax_of_variablevalue\" \"> --> Example of the variable value \"variablestore\":\n{\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ]\",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\"\n},\n] ! ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-schematics-cli-reference"},{"document_id":"ibmcld_08295-131806-133131","score":15.2530072074,"text":"\nTo find the ID of your workspace, run ibmcloud schematics workspace list command. || --file or -f | Required | Enter the full file path on your local machine where your .tar file is stored. || --template or -tid | Required | The unique identifier of the Terraform template for which you want to show the content of the Terraform state file. To find the ID of the template, run ibmcloud schematics workspace get --id <workspace_ID> and find the template ID in the Template Variables for: field of your command-line output. || --output or -o | Optional | Returns the command-line output in JSON format. Currently only JSON file format is supported. || --json or -j | Deprecated | Prints the output in the JSON format. |<-- <\/table \"\"> -->Example ibmcloud schematics workspace upload --id myworkspace-a1aa1a1a-a11a-11 --file \/Users\/myuser\/Documents\/mytar\/vpc.tar --template 25111111-0000-4c\nCreate the TAR file of your template repo by using the TAR command given tar -cvf vpc.tar $TEMPLATE_REPO_FOLDER<-- <section \"id=\"section-syntax_of_variablevalue\" \"> --> Example of the variable value \"variablestore\":\n{\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ]\",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\"\n},\n] ! ! ! ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-slurm?topic=hpc-slurm-schematics-cli-reference"},{"document_id":"ibmcld_08331-133303-134628","score":15.2530072074,"text":"\nTo find the ID of your workspace, run ibmcloud schematics workspace list command. || --file or -f | Required | Enter the full file path on your local machine where your .tar file is stored. || --template or -tid | Required | The unique identifier of the Terraform template for which you want to show the content of the Terraform state file. To find the ID of the template, run ibmcloud schematics workspace get --id <workspace_ID> and find the template ID in the Template Variables for: field of your command-line output. || --output or -o | Optional | Returns the command-line output in JSON format. Currently only JSON file format is supported. || --json or -j | Deprecated | Prints the output in the JSON format. |<-- <\/table \"\"> -->Example ibmcloud schematics workspace upload --id myworkspace-a1aa1a1a-a11a-11 --file \/Users\/myuser\/Documents\/mytar\/vpc.tar --template 25111111-0000-4c\nCreate the TAR file of your template repo by using the TAR command given tar -cvf vpc.tar $TEMPLATE_REPO_FOLDER<-- <section \"id=\"section-syntax_of_variablevalue\" \"> --> Example of the variable value \"variablestore\":\n{\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ]\",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\"\n},\n] ! ! ! ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-scale?topic=hpc-spectrum-scale-schematics-cli-reference"},{"document_id":"ibmcld_12258-141046-142367","score":15.2530072074,"text":"\nTo find the ID of your workspace, run ibmcloud schematics workspace list command. || --file or -f | Required | Enter the full file path on your local machine where your .tar file is stored. || --template or -tid | Required | The unique identifier of the Terraform template for which you want to show the content of the Terraform state file. To find the ID of the template, run ibmcloud schematics workspace get --id <workspace_ID> and find the template ID in the Template Variables for: field of your command-line output. || --output or -o | Optional | Returns the command-line output in JSON format. Currently only JSON file format is supported. || --json or -j | Deprecated | Prints the output in the JSON format. |<-- <\/table \"\"> -->Example ibmcloud schematics workspace upload --id myworkspace-a1aa1a1a-a11a-11 --file \/Users\/myuser\/Documents\/mytar\/vpc.tar --template 25111111-0000-4c\nCreate the TAR file of your template repo by using the TAR command given tar -cvf vpc.tar $TEMPLATE_REPO_FOLDER<-- <section \"id=\"section-syntax_of_variablevalue\" \"> --> Example of the variable value \"variablestore\":\n{\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ]\",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\"\n},\n] ! ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-schematics-cli-reference&interface=cli"},{"document_id":"ibmcld_08295-130293-131214","score":15.2264095174,"text":"\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-slurm?topic=hpc-slurm-schematics-cli-reference"},{"document_id":"ibmcld_12258-139533-140454","score":15.2264095174,"text":"\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-schematics-cli-reference&interface=cli"},{"document_id":"ibmcld_04516-139667-140633","score":15.1461464783,"text":"\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace. Initial support for files up to 4MB in size.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-schematics-cli-reference"},{"document_id":"ibmcld_08331-131395-132711","score":15.0305951211,"text":"\ntemplate_data[0].variablestore[v].use_default Optional Set the use_default parameter to true to override the default .tfvars parameter. By default, this parameter is set to false. \n github_source_repo_url Optional Enter the link to your GitHub repository. The link can point to the master branch, a different branch, or a subdirectory. \n\n\n\n\n\n\n\n Example for variable store \n\n\"variablestore\": [\n{\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- <\/section \"id=\"section-syntax_of_variablestore\" \"> --><-- <\/section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-spectrum-scale?topic=hpc-spectrum-scale-schematics-cli-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10116-16035-17814","score":13.1793488989,"text":"\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zoneszones-vpc) that you create the cluster in. The uplift charge is a percentage (%) of the hourly rate (r), and is added to the hourly rate of the worker node. The total hourly rate cost for a worker node can be calculated as r + (r \u00d7 %). In the [Red Hat OpenShift cluster creation console](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/create?platformType=openshift), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month. For more information, expand the Sustained usage discounts on IBM Cloud Virtual Servers for VPC section on the [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs) page.\n\n\n\n\n\n\n\n Estimating costs \n\nSee [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as tiered pricing for increased hourly usage. For more information, see [Understanding costs for your clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costscosts-for-clusters).\n\n\n\n\n\n Managing costs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_05666-8826-10757","score":12.5149548023,"text":"\nReview each product documentation and use the IBM Cloud console to [estimate costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\nOperators and other [third-party integrations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers. Keep in mind that you are responsible for additional charges and how these services operate in your cluster, from deployment and maintenance to integration with your apps. If you have issues with an operator or third-party integration, work with the appropriate provider to troubleshoot the issue.\n\n\n\n\n\n VPC worker nodes \n\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zoneszones-vpc) that you create the cluster in. The uplift charge is a percentage (%) of the hourly rate (r), and is added to the hourly rate of the worker node. The total hourly rate cost for a worker node can be calculated as r + (r \u00d7 %). In the [Kubernetes cluster creation console](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/create), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_05666-6093-7968","score":12.2117957487,"text":"\nClassic clusters: When you create a standard cluster, a portable public subnet with 8 public IP addresses is ordered and charged to your account monthly. For pricing information, see the [Subnets and IPs](https:\/\/cloud.ibm.com\/docs\/subnets) documentation or estimate your costs in the [classic subnets console)](https:\/\/cloud.ibm.com\/classic\/network\/subnet\/provision). If you already have available portable public subnets in your infrastructure account, you can use these subnets instead. Create the cluster with the --no-subnets[flag](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_create), and then [reuse your subnets](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-subnetssubnets_custom).\n\nVPC clusters: For more information about charges for floating IPs and other networking costs, see [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n Multizone load balancer \n\nWhen you create a multizone cluster or add zones to a single zone cluster, you must have a load balancer to health check Ingress and load balancer IP addresses in each zone, and forward requests to your apps across zones in the region.\n\nThe type of load balancer that is automatically created varies depending on the type of cluster.\n\n\n\n* Classic clusters: An Akamai MZLB is automatically created for each multizone cluster. You can view the hourly rate in the pricing summary when you create the cluster.\n* VPC clusters: A Load Balancer for VPC is automatically created in your VPC for your cluster. For cost information, see [Pricing for Load Balancer for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n\n\n Storage \n\nWhen you provision storage, you can choose the storage type and storage class that is correct for your use case. Charges vary depending on the type of storage, the location, and the specs of the storage instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_11408-13151-14243","score":12.123315455,"text":"\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change. To calculate your pricing, use the [IBM cost estimator](https:\/\/cloud.ibm.com\/estimator) in IBM Cloud console.\n\n\n\n\n\n End of billing \n\nThe monthly billing cycle ends when you delete the LPAR. If you scale your infrastructure up and down in response to workload requirements, your billing follows the timing of the LPAR provision change. If you stop the LPAR, the billing process is not stopped. You must delete the LPAR to stop the billing cycle.\n\nYou are still charged if the VM is in a suspended state. When your VM is inactive, you can use Dynamic Logical Partitioning (DLPAR) to resize it to a minimal state. You can drastically decrease the price per hour by reducing the VM's core count and memory.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_07578-692271-694037","score":11.969141315,"text":"\nWebSphere Application Server\n\n\n\n* What products can I install with WebSphere Application Server?\n\nYou can install a WebSphere Application Server traditional environment on a virtual server instance (VSI) on IBM Cloud. For a description of the topologies that you can install with WebSphere Application Server, see [Topologies](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-topologies).\n* What permissions do I need to use this tile?\n\nYou need Manager role on the Schematics service in at least one resource group. You also need Administrator role for VPC Infrastructure Services in the resource group for the Schematics workspace, VPC, and VSIs.\n* Where can I see the installation logs?\n\nTo see the Installation logs, look under the [Schematics workspace](https:\/\/cloud.ibm.com\/schematics\/workspaces).\n* Where can I see my installation history?\n\nTo see the installation history, look under the [Schematics workspace](https:\/\/cloud.ibm.com\/schematics\/workspaces).\n* How do I uninstall?\n\nFollow the instructions in [Uninstalling your workspace or resources](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-uninstalling).\n* Do I get charged for using the tile?\n\nNo, but you get charged for the infrastructure. Refer to [Topologies](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-topologies) for infrastructure resources provisioned and to [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing) for the associated cost.\n* Can I use the tile to upgrade WebSphere Application Server after initial installation?\n\nNo, you can use the tile only for one installation. After the initial installation, it is your responsibility to manage and upgrade the installation.\n\n\n\nIntegration Event Streams\n\n\n\n* How do I use Kafka APIs to create and delete topics?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-692229-693995","score":11.969141315,"text":"\nWebSphere Application Server\n\n\n\n* What products can I install with WebSphere Application Server?\n\nYou can install a WebSphere Application Server traditional environment on a virtual server instance (VSI) on IBM Cloud. For a description of the topologies that you can install with WebSphere Application Server, see [Topologies](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-topologies).\n* What permissions do I need to use this tile?\n\nYou need Manager role on the Schematics service in at least one resource group. You also need Administrator role for VPC Infrastructure Services in the resource group for the Schematics workspace, VPC, and VSIs.\n* Where can I see the installation logs?\n\nTo see the Installation logs, look under the [Schematics workspace](https:\/\/cloud.ibm.com\/schematics\/workspaces).\n* Where can I see my installation history?\n\nTo see the installation history, look under the [Schematics workspace](https:\/\/cloud.ibm.com\/schematics\/workspaces).\n* How do I uninstall?\n\nFollow the instructions in [Uninstalling your workspace or resources](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-uninstalling).\n* Do I get charged for using the tile?\n\nNo, but you get charged for the infrastructure. Refer to [Topologies](https:\/\/cloud.ibm.com\/docs\/was-for-vsi?topic=was-for-vsi-topologies) for infrastructure resources provisioned and to [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing) for the associated cost.\n* Can I use the tile to upgrade WebSphere Application Server after initial installation?\n\nNo, you can use the tile only for one installation. After the initial installation, it is your responsibility to manage and upgrade the installation.\n\n\n\nIntegration Event Streams\n\n\n\n* How do I use Kafka APIs to create and delete topics?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05666-3176-5101","score":11.8964482478,"text":"\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.\n* Longer ordering process: After you order or cancel a bare metal server, the process is completed manually in your IBM Cloud infrastructure account. Therefore, it can take more than one business day to complete.\n\nVPC Generation 2 only: Prices vary by region where the underlying worker node infrastructure resides, and you can get sustained usage discounts. For more information, see [What are the regional uplift charges and sustained usage discounts for VPC worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costscharges_vpc_gen2).\n\n\n\nFor more information about worker node specifications, see [Available hardware for worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesplanning_worker_nodes).\n\n\n\n\n\n Public bandwidth \n\nBandwidth refers to the public data transfer of inbound and outbound network traffic, both to and from IBM Cloud resources in data centers around the globe.\n\nClassic clusters: Public bandwidth is charged per GB. You can review your current bandwidth summary by logging into the [IBM Cloud console](https:\/\/cloud.ibm.com\/), from the menu ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_15276-7-1903","score":11.7268201342,"text":"\nFAQs for auto scale \n\n\n\n What elements do I need to create to set up auto scaling? \n\nIf you are using IBM Cloud console, you need to create an instance template, an instance group, and if you choose the dynamic scaling method, you must create scaling policies. For more information, see [Setting up auto scale with the UI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-groupsetting-up-autoscale-overview). If you are using the IBM Cloud CLI or API you must also create an instance group manager. For more information, see [Setting up auto scale with the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-groupsetting-up-auto-scale-with-the-cli).\n\n\n\n\n\n How much am I charged for using auto scale? \n\nAuto scale for VPC is free, but you are charged for the resources that you consume. For example, you are charged for virtual server instances that are created in the instance group.\n\n\n\n\n\n How does auto scaling work? \n\nYou set scaling policies that define your desired average utilization for metrics like CPU, memory, and network usage. The policies that you define determine when virtual server instances are added or removed from your instance group.\n\nAuto scale uses the following computation to determine how many instances are running at any given time:\n\n\u03a3(Current average utilization of each instance)\/target utilization = membership count\n\nFor more information about how it works, see [Auto Scale for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-groupauto-scale-vpc).\n\n\n\n\n\n What permissions do I need for using auto scale? \n\nYou can check the required permissions for actions on instance templates, instance groups, instance group managers, memberships, and policies in the [Required permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resource-authorizations-required-for-api-and-cli-calls).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-faqs-auto-scale"},{"document_id":"ibmcld_04031-1609-3779","score":11.7224214237,"text":"\nFor IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges. You will not be charged for the cluster that the Operational Tooling instance, also known as the console, is running on. See the [Architecture reference](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-architecture) topic for an illustration. More details on how to calculate charges are described below.\n\n\n\n Benefits of the new pricing model \n\n\n\n* No membership fees: Freedom from membership fees means that you can invest directly in your blockchain components.\n* Estimation clarity: A simple hourly pricing model makes cost estimation clear and easy by using the cost estimator tool that is available in the IBM Cloud dashboard.\n* No minimum fee required: Pay for only what you use, no minimum VPC hourly package is required, which makes it very inexpensive to get started.\n* Scalability of compute: You have the option to scale your compute up during peak usage periods or down to a minute fraction of capacity for when the compute is not needed to minimize expense.\n\n\n\nIn summary, these features remove the complexity of accounting for membership limitations or purchasing compute ahead of your needs.\n\n\n\n\n\n Find out how to preview the platform free for 30 days \n\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_05666-4707-6582","score":11.7170242884,"text":"\n[Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.\n* Pay-As-You-Go for VM: Because VMs are billed at an hourly rate, your VM worker node machines have a Pay-As-You-Go allocation of outbound networking based on GB usage.\n* Included bandwidth and tiered packages for BM: Bare metal worker nodes might come with a certain allocation of outbound networking per month that varies by geography: 20 TB for North America and Europe, or 5 TB for Asia Pacific and South America. After you exceed your included bandwidth, you are charged according to a tiered usage scheme for your geography. If you exceed a tier allotment, you might also be charged a standard data transfer fee. For more information, see [Bandwidth packages](https:\/\/www.ibm.com\/cloud\/bandwidth).\n\n\n\nVPC clusters: For more information about how internet data transfer works in your Virtual Private Cloud, see [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n Subnet IP addresses \n\nSubnets for IBM Cloud Kubernetes Service clusters vary by infrastructure provider.\n\nClassic clusters: When you create a standard cluster, a portable public subnet with 8 public IP addresses is ordered and charged to your account monthly. For pricing information, see the [Subnets and IPs](https:\/\/cloud.ibm.com\/docs\/subnets) documentation or estimate your costs in the [classic subnets console)](https:\/\/cloud.ibm.com\/classic\/network\/subnet\/provision). If you already have available portable public subnets in your infrastructure account, you can use these subnets instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1412669729}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04031-6179-7910","score":12.0331433877,"text":"\n[Elements of pricing](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/elements-of-pricing.svg)\n\nFigure 1. Elements of pricing\n\n\n\n* IBM Blockchain Platform: Based on a flat rate of $0.29 USD\/VPC-hour. This fee represents the charge for your blockchain component VPC allocation in your Kubernetes cluster.\n* IBM Cloud Kubernetes Service: While you can link your IBM Blockchain Platform service instance to either an IBM Cloud Kubernetes service cluster or an OpenShift cluster, this pricing model is based on the usage of an IBM Cloud Kubernetes service cluster. The IBM Cloud Kubernetes service uses a tiered pricing model that is visible in IBM Cloud when you provision your paid cluster. This includes the charges for your compute, that is, CPU and memory. IBM Cloud Kubernetes Services are priced on a tiered model that is based on the number of hours of usage per month. Therefore, when you examine pricing plans, consider that 24x7 usage is equivalent to 720 hours per month. Refer to the table on the [Kubernetes Service Catalog page](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about) for more details on cluster pricing. Customers who are interested in pricing OpenShift clusters can review [Red Hat OpenShift on IBM Cloud Pricing](https:\/\/www.ibm.com\/cloud\/openshift\/pricing).\n* Storage: Choose the storage plan that works for your needs. See [Understanding Kubernetes storage basics](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kube_conceptskube_concepts) to learn more about your storage class options and how much they [cost](https:\/\/www.ibm.com\/cloud\/file-storage\/pricing). The IBM Blockchain Platform nodes use the default storage class for the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_14886-1801-3922","score":11.8712742617,"text":"\nBenefits \n\n\n\n BYOL \n\nRenting licenses can get expensive. Bringing your own license is an option for IBM Cloud Bare Metal Servers for VPC.\n\n\n\n\n\n Rapid scaling \n\nScale your dedicated, bare metal server environment for your needs quickly. Often, in 10 minutes or less when resources are available.\n\n\n\n\n\n Network orchestration \n\nA network orchestration layer handles the networking for all bare metal servers that are within an IBM Cloud VPC across regions and zones. Create multiple, virtual private clouds in multizone regions. Network orchestration also helps improve security, reduce latency, and increase high availability.\n\nYou are responsible for security on your bare metal server. That means upgrading or patching the operating system as needed to make sure that vulnerabilities are addressed in a timely manner. Bare metal servers with associated floating IP addresses are internet-facing and you need to take appropriate precautions. For more information, see [Understanding your responsibilities](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-responsibilities-vpcsecurity-compliance).\n\n\n\n\n\n\n\n Pricing options \n\nPay-as-you-go bandwidth is per gigabyte. Your billing charges accrue from provision to cancellation, and are billed in arrears. Total pricing includes bare metal server instance profiles and software, internet data transfers, and optional VPC services. Each additional component is priced separately and included as part of your total IBM Cloud VPC charge. Service tiers are bound to your account, not to any specific VPC.\n\nFor more information about pricing, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricingtab_2651670).\n\n\n\n\n\n Bare Metal Servers for VPC versus bare metal server on classic infrastructure \n\nWith Bare Metal Servers for VPC, you can enjoy the security and performance of the private cloud with the flexibility and scalability of the public cloud. Compared to the classic bare metal infrastructures, Bare Metal Servers for VPC provides better connectivity and networking throughput by using VPC concepts.\n\nBare Metal Servers for VPC has local NVMe, which you can use to create VMWare vSAN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-bare-metal-servers"},{"document_id":"ibmcld_03994-15948-17676","score":11.7859615562,"text":"\nIf you do not want to use the default File Storage that is pre-selected for you when you provision a Kubernetes cluster in IBM Cloud, you can provision storage of your choice. See this topic on [Persistent storage considerations](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iksibp-console-storage) to learn more.\n* If you decide to include IBM Cloud multi-zone support in your Kubernetes cluster on IBM Cloud, you must provision your own storage. See [Using Multizone (MZR) clusters with IBM Blockchain Platform](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iksibp-console-mzr) for more details.\n* You can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster. Performance will be limited by throughput, storage and functionality. IBM Cloud will delete your cluster after 30 days and you cannot migrate any nodes or data from a free cluster to a paid cluster. If you choose a paid Kubernetes cluster instead of the limited free cluster, you will incur charges for the Kubernetes service to your IBM Cloud account.\n* Kubernetes clusters that are configured with private VLANs are not supported.\n\n\n\n\n\n\n\n License and pricing \n\nIBM Blockchain Platform for IBM Cloud introduces a new hourly pricing model based on virtual processor core (VPC) usage. The simplified model is based on the amount of CPU (or VPC) that your IBM Blockchain Platform nodes consume on an hourly basis, at a flat rate of $0.29 USD\/VPC-hour, where 1 VPC = 1 CPU. See this topic on [Pricing](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing) for more details.\n\n\n\n\n\n Getting started","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overview"},{"document_id":"ibmcld_07578-882118-884014","score":11.5442121253,"text":"\nYou can also [create stand-alone volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-881995-883891","score":11.5442121253,"text":"\nYou can also [create stand-alone volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-block-storagecreate-standalone-vol) and later attach them to your instances.\n* How many instances can share a provisioned Block Storage for VPC volume?\n\n How many instances can share a provisioned Block Storage for VPC volume? \n\nA Block Storage for VPC volume can be attached to only one instance at a time. Instances cannot share a volume.\n* How many Block Storage for VPC secondary data volumes can be attached to an instance?\n\n How many Block Storage for VPC secondary data volumes can be attached to an instance? \n\nYou can create 12 Block Storage for VPC data volumes per instance, plus the boot volume.\n* How am I charged for usage?\n\n How am I charged for usage? \n\nCost for Block Storage for VPC is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The volume exists on the account until you delete the volume or you reach the end of a billing cycle, whichever comes first.\n\nPricing is also affected when you [expand volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile. For example, expanding volume capacity increases costs, and changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-985053-986983","score":11.4894893833,"text":"\n* What metrics am I charged for if I am using VPN gateway for VPC?\n\nThe following metrics are collected for VPN gateway billing on a monthly basis:\n\n\n\n* VPN Gateway Instance Hour: How much time your VPN gateway instance is up and running.\n* VPN Connection Hour: How much time each of your VPN connections is established and maintained on the VPN gateway.\n* Floating IP: The number of active floating IP addresses being used by the VPN gateway instance.\n\n\n\nSee the IBM Cloud VPN tab on the [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing) page for the unit pricing per hour in each region for VPN gateway.\n\nWhile using a VPN gateway, you are also charged for all outbound public internet traffic billed at VPC data rates. See the Data Transfer tab on the [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing) page for details about the unit pricing for outbound data transfer.\n* Why doesn't the route-based VPN gateway route the traffic?\n\nIf you configured a VPC route and its next hop is a VPN connection, the following use cases block the traffic forwarded through the VPN connection.\n\n\n\n* The security groups associated with the VPC instance do not permit the traffic; the network ACLs associated with the subnet of the VPC instance and VPN gateway blocked the traffic. For more information about configuring security groups and network ACLs, see [Configuring ACLs and security groups for use with VPN](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-acls-security-groups-vpn).\n* The traffic source IP is not in any subnet associated with the VPC routing table. For example, the VPC routing table is associated with subnet A and includes a route whose next hop is a VPN connection. However, when the traffic reaches the VPN gateway, the source IP is not in subnet A or any other subnets that are associated with the routing table. Therefore, the VPN gateway drops the traffic.\n\n\n\n\n\nVirtual Private Networks (VPN)\n\n\n\n* What is IBM Cloud VPN?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-984929-986859","score":11.4894893833,"text":"\n* What metrics am I charged for if I am using VPN gateway for VPC?\n\nThe following metrics are collected for VPN gateway billing on a monthly basis:\n\n\n\n* VPN Gateway Instance Hour: How much time your VPN gateway instance is up and running.\n* VPN Connection Hour: How much time each of your VPN connections is established and maintained on the VPN gateway.\n* Floating IP: The number of active floating IP addresses being used by the VPN gateway instance.\n\n\n\nSee the IBM Cloud VPN tab on the [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing) page for the unit pricing per hour in each region for VPN gateway.\n\nWhile using a VPN gateway, you are also charged for all outbound public internet traffic billed at VPC data rates. See the Data Transfer tab on the [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing) page for details about the unit pricing for outbound data transfer.\n* Why doesn't the route-based VPN gateway route the traffic?\n\nIf you configured a VPC route and its next hop is a VPN connection, the following use cases block the traffic forwarded through the VPN connection.\n\n\n\n* The security groups associated with the VPC instance do not permit the traffic; the network ACLs associated with the subnet of the VPC instance and VPN gateway blocked the traffic. For more information about configuring security groups and network ACLs, see [Configuring ACLs and security groups for use with VPN](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-acls-security-groups-vpn).\n* The traffic source IP is not in any subnet associated with the VPC routing table. For example, the VPC routing table is associated with subnet A and includes a route whose next hop is a VPN connection. However, when the traffic reaches the VPN gateway, the source IP is not in subnet A or any other subnets that are associated with the routing table. Therefore, the VPN gateway drops the traffic.\n\n\n\n\n\nVirtual Private Networks (VPN)\n\n\n\n* What is IBM Cloud VPN?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_15284-4415-6444","score":11.3586864633,"text":"\nApproved Scanning Vendor (ASV) quarterly scanning is a requirement of the Payment Card Industry (PCI) Security Standards Council. ASV scanning of VPN data-plane appliances is solely a customer responsibility. IBM does not use ASVs to scan data-plane appliances because these scans can negatively impact customer workload functions and performance.\n\n\n\n\n\n What metrics am I charged for if I am using VPN gateway for VPC? \n\nThe following metrics are collected for VPN gateway billing on a monthly basis:\n\n\n\n* VPN Gateway Instance Hour: How much time your VPN gateway instance is up and running.\n* VPN Connection Hour: How much time each of your VPN connections is established and maintained on the VPN gateway.\n* Floating IP: The number of active floating IP addresses being used by the VPN gateway instance.\n\n\n\nSee the IBM Cloud VPN tab on the [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing) page for the unit pricing per hour in each region for VPN gateway.\n\nWhile using a VPN gateway, you are also charged for all outbound public internet traffic billed at VPC data rates. See the Data Transfer tab on the [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing) page for details about the unit pricing for outbound data transfer.\n\n\n\n\n\n Why doesn't the route-based VPN gateway route the traffic? \n\nIf you configured a VPC route and its next hop is a VPN connection, the following use cases block the traffic forwarded through the VPN connection.\n\n\n\n* The security groups associated with the VPC instance do not permit the traffic; the network ACLs associated with the subnet of the VPC instance and VPN gateway blocked the traffic. For more information about configuring security groups and network ACLs, see [Configuring ACLs and security groups for use with VPN](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-acls-security-groups-vpn).\n* The traffic source IP is not in any subnet associated with the VPC routing table. For example, the VPC routing table is associated with subnet A and includes a route whose next hop is a VPN connection.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-faqs-vpn"},{"document_id":"ibmcld_11408-11687-13539","score":11.2217579803,"text":"\nData volumes of 235 GB\n\nBoot volumes of 200 GB\n\nDeployed VMs of 160 GB\n\n\n\nTable 10. Account billable for storage use case\n\n Name Size State\/Description \n\n data-volume-1 20 GB Available \n data-volume-2 25 GB In-use (attached to vm-1) \n data-volume-3 100 GB In-use (attached to vm-1) \n data-volume-4 30 GB Available \n data-volume-5 60 GB In-use (attached to vm-2) \n\n\n\nTotal billable storage = 595 GB\n\n\n\n* Data volumes: 235 GB\n* Image volumes: 200 GB\n* Deployed VMs: 160 GB\n\n\n\n\n\n\n\n\n\n Pricing for VPN connection \n\nWhen you use a VPN connection, you are billed monthly.\n\nIBM charges with the base price hourly per connection. The base price varies per geography. So if you use one vpn connection that is active for a month, the monthly bill would be $base price X 24 hours X 30 days.\n\n\n\n\n\n Pricing for Power Edge Router \n\nAs a Power Systems Virtual Server user, you are charged based on the Transit Gateway connections that you use:\n\n\n\n* New Transit Gateway that you create in a PER workspace.\n* Existing Transit Gateways that add Power Systems Virtual Server workspace to their existing connection.\n\n\n\nHere are some more PER charges based on the following Transit Gateway specifics:\n\n\n\n* Routing option\n* Number of connections\n\n\n\nThe following table shows the charges based on the routing option that you select:\n\n\n\nTable 13. TGW charges based on routing\n\n Routing type Charges \n\n Local routing data transfer No charges \n Global routing data transfer $0.009405 GB \n\n\n\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_05666-6093-7968","score":11.1973278853,"text":"\nClassic clusters: When you create a standard cluster, a portable public subnet with 8 public IP addresses is ordered and charged to your account monthly. For pricing information, see the [Subnets and IPs](https:\/\/cloud.ibm.com\/docs\/subnets) documentation or estimate your costs in the [classic subnets console)](https:\/\/cloud.ibm.com\/classic\/network\/subnet\/provision). If you already have available portable public subnets in your infrastructure account, you can use these subnets instead. Create the cluster with the --no-subnets[flag](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_create), and then [reuse your subnets](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-subnetssubnets_custom).\n\nVPC clusters: For more information about charges for floating IPs and other networking costs, see [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n Multizone load balancer \n\nWhen you create a multizone cluster or add zones to a single zone cluster, you must have a load balancer to health check Ingress and load balancer IP addresses in each zone, and forward requests to your apps across zones in the region.\n\nThe type of load balancer that is automatically created varies depending on the type of cluster.\n\n\n\n* Classic clusters: An Akamai MZLB is automatically created for each multizone cluster. You can view the hourly rate in the pricing summary when you create the cluster.\n* VPC clusters: A Load Balancer for VPC is automatically created in your VPC for your cluster. For cost information, see [Pricing for Load Balancer for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n\n\n Storage \n\nWhen you provision storage, you can choose the storage type and storage class that is correct for your use case. Charges vary depending on the type of storage, the location, and the specs of the storage instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.3191471545,"ndcg_cut_10":0.3191471545}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1076793-1078629","score":19.8936546572,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":19.8936546572,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04488-133306-134586","score":19.8851485277,"text":"\ncreate a Cloud Object Storage (COS) instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\nCreating service instance my-cos-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-cos-1 was created.\nName: my-cos-1\nID: crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8::\nGUID: 4b636e74-f3ca-40bb-80b8-3bd21801ccb8\nLocation: global\nState: active\nType: service_instance\nSub Type:\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation: Status create succeeded Message Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\nCreating service instance my-kms-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-kms-1 was created.\nName: my-kms-1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_01660-7085-8964","score":19.8844975957,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07578-1075256-1077185","score":19.1305238365,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1077752-1079681","score":19.1305238365,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_09055-96989-98298","score":19.0443905038,"text":"\nThe ibmcloud resource service-instance-create command requires a service plan name and a location, which is in the catalog. show the catalog offerings for cloud object storage (COS) and Key Protect\n$ ibmcloud catalog service cloud-object-storage\n\n$ ibmcloud catalog service kms\n create a Cloud Object Storage (COS) instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\nCreating service instance my-cos-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-cos-1 was created.\nName: my-cos-1\nID: crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8::\nGUID: 4b636e74-f3ca-40bb-80b8-3bd21801ccb8\nLocation: global\nState: active\nType: service_instance\nSub Type:\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation:\nStatus create succeeded\nMessage Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_09055-104201-105670","score":18.5059094401,"text":"\nService instance my-cos-1 with ID crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8:: is deleted successfully\n\n view resources (COS and KMS should no longer exist)\n$ ibmcloud resource service-instances\n\nRetrieving instances with type service_instance in resource group Default in all locations under account <account name> as <email address>...\nOK\nNo service instance found.\n<-- <\/section \"id=\"section-kp-registrations-example-2\" \"> --><-- <section \"id=\"section-kp-registrations-example-3\" \"> --> Example 3 This example shows what happens when one of the following occurs between COS and Key Protect (KP) - COS is not able to access the Key Protect root key.<-- <ul> --> * Delete the KP root key * Remove the CMS\/KP authorization policy<-- <\/ul> -->This example does not show command output except when relevant. create a Cloud Object Storage (COS) service instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=c488e11a-c8a0-4688-b002-9327266ea55f\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\n capture the Key Protect (KP) instance id (GUID)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_09120-142300-143775","score":18.4776545957,"text":"\nService instance my-cos-1 with ID crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8:: is deleted successfully\n\n view resources (COS and KMS should no longer exist)\n$ ibmcloud resource service-instances\n\nRetrieving instances with type service_instance in resource group Default in all locations under account <account name> as <email address>...\nOK\nNo service instance found.\n\n\n\n\n\n Example 3 \n\nThis example shows what happens when one of the following occurs between COS and Key Protect (KP) - COS is not able to access the Key Protect root key.\n\n\n\n* Delete the KP root key\n* Remove the CMS\/KP authorization policy\n\n\n\nThis example does not show command output except when relevant.\n\n create a Cloud Object Storage (COS) service instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=c488e11a-c8a0-4688-b002-9327266ea55f\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\n capture the Key Protect (KP) instance id (GUID)\n$ KP_INSTANCE_ID=26f4b198-952a-47ab-9f44-ef69c038b3c5\n\n create a policy for COS to read KMS; source is COS, target is KMS (Key Protect)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_04488-140232-141707","score":18.4776545957,"text":"\nService instance my-cos-1 with ID crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8:: is deleted successfully\n\n view resources (COS and KMS should no longer exist)\n$ ibmcloud resource service-instances\n\nRetrieving instances with type service_instance in resource group Default in all locations under account <account name> as <email address>...\nOK\nNo service instance found.\n\n\n\n\n\n Example 3 \n\nThis example shows what happens when one of the following occurs between COS and Key Protect (KP) - COS is not able to access the Key Protect root key.\n\n\n\n* Delete the KP root key\n* Remove the CMS\/KP authorization policy\n\n\n\nThis example does not show command output except when relevant.\n\n create a Cloud Object Storage (COS) service instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=c488e11a-c8a0-4688-b002-9327266ea55f\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\n capture the Key Protect (KP) instance id (GUID)\n$ KP_INSTANCE_ID=26f4b198-952a-47ab-9f44-ef69c038b3c5\n\n create a policy for COS to read KMS; source is COS, target is KMS (Key Protect)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01660-7085-8964","score":17.2341561729,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":17.2195875051,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":17.2195875051,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1075256-1077185","score":16.6569996432,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1077752-1079681","score":16.6569996432,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04488-133306-134586","score":15.9921373773,"text":"\ncreate a Cloud Object Storage (COS) instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\nCreating service instance my-cos-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-cos-1 was created.\nName: my-cos-1\nID: crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8::\nGUID: 4b636e74-f3ca-40bb-80b8-3bd21801ccb8\nLocation: global\nState: active\nType: service_instance\nSub Type:\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation: Status create succeeded Message Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\nCreating service instance my-kms-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-kms-1 was created.\nName: my-kms-1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-key-protect-cli-reference"},{"document_id":"ibmcld_01660-8584-10307","score":15.5169301703,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_09055-96989-98298","score":15.1488906092,"text":"\nThe ibmcloud resource service-instance-create command requires a service plan name and a location, which is in the catalog. show the catalog offerings for cloud object storage (COS) and Key Protect\n$ ibmcloud catalog service cloud-object-storage\n\n$ ibmcloud catalog service kms\n create a Cloud Object Storage (COS) instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\nCreating service instance my-cos-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-cos-1 was created.\nName: my-cos-1\nID: crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8::\nGUID: 4b636e74-f3ca-40bb-80b8-3bd21801ccb8\nLocation: global\nState: active\nType: service_instance\nSub Type:\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation:\nStatus create succeeded\nMessage Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_09055-104201-105670","score":14.7962544307,"text":"\nService instance my-cos-1 with ID crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8:: is deleted successfully\n\n view resources (COS and KMS should no longer exist)\n$ ibmcloud resource service-instances\n\nRetrieving instances with type service_instance in resource group Default in all locations under account <account name> as <email address>...\nOK\nNo service instance found.\n<-- <\/section \"id=\"section-kp-registrations-example-2\" \"> --><-- <section \"id=\"section-kp-registrations-example-3\" \"> --> Example 3 This example shows what happens when one of the following occurs between COS and Key Protect (KP) - COS is not able to access the Key Protect root key.<-- <ul> --> * Delete the KP root key * Remove the CMS\/KP authorization policy<-- <\/ul> -->This example does not show command output except when relevant. create a Cloud Object Storage (COS) service instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=c488e11a-c8a0-4688-b002-9327266ea55f\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\n capture the Key Protect (KP) instance id (GUID)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_09120-142300-143775","score":14.7731525384,"text":"\nService instance my-cos-1 with ID crn:v1:bluemix:public:cloud-object-storage:global:a\/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8:: is deleted successfully\n\n view resources (COS and KMS should no longer exist)\n$ ibmcloud resource service-instances\n\nRetrieving instances with type service_instance in resource group Default in all locations under account <account name> as <email address>...\nOK\nNo service instance found.\n\n\n\n\n\n Example 3 \n\nThis example shows what happens when one of the following occurs between COS and Key Protect (KP) - COS is not able to access the Key Protect root key.\n\n\n\n* Delete the KP root key\n* Remove the CMS\/KP authorization policy\n\n\n\nThis example does not show command output except when relevant.\n\n create a Cloud Object Storage (COS) service instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=c488e11a-c8a0-4688-b002-9327266ea55f\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\n capture the Key Protect (KP) instance id (GUID)\n$ KP_INSTANCE_ID=26f4b198-952a-47ab-9f44-ef69c038b3c5\n\n create a policy for COS to read KMS; source is COS, target is KMS (Key Protect)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6934264036,"ndcg_cut_5":0.6934264036,"ndcg_cut_10":0.6934264036}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01660-7085-8964","score":9.2017288051,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":9.0622547043,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":9.0622547043,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01660-8584-10307","score":8.8784415723,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07578-1075256-1077185","score":8.8319925346,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1077752-1079681","score":8.8319925346,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02143-0-1216","score":8.6259754892,"text":"\n\n\n\n\n\n\n  Why can't I create a new Lite plan instance? \n\nYou try to create more than one instance in your Lite account.\n\n  What\u2019s happening \n\nYou receive the following error message when you try to create a new Lite plan instance:\n\n> Unable to provision new Lite instance\n>\n> The account already has an instance created with the Lite plan\n\n  Why it\u2019s happening \n\nThere's a limit of one instance per Lite plan to ensure that these plans stay free. For more information about Lite account features, see [Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n  How to fix it \n\nYou can create more instances of the service by selecting one of the billable service plans, which are available in the billable accounts. To upgrade to a billable account from the console, go to Manage > Account in the IBM Cloud console, and select Account settings.\n\nIf you don't want to upgrade from a Lite account and are no longer using your existing Lite service instance, you can delete the existing Lite plan instance from the dashboard and then create a new instance. When you delete the Lite plan instance, all of the data that is associated with that instance is deleted and isn't recoverable.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-nosecondlite"},{"document_id":"ibmcld_02145-0-1025","score":8.463222422,"text":"\n\n\n\n\n\n\n  Why can't I access a different IBM Cloud location? \n\nYou're unable to create a new location because your account type doesn't allow it.\n\n  What\u2019s happening \n\nYou receive an error message when you try to create a new IBM Cloud location.\n\n  Why it\u2019s happening \n\nThis error typically occurs because you're using a Lite account, which supports development in one public location only. For more information about Lite account features, see [Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n  How to fix it \n\nTo access more locations, upgrade to a billable account. Go to Manage > Account in the IBM Cloud console, and select Account settings. In the Account upgrade section, select your upgrade option.\n\nTo view information about using a different region for a service within the account, see [Using service endpoints](https:\/\/cloud.ibm.com\/docs\/account?topic=account-vrf-service-endpointuse-service-endpoint) for global or regional endpoints for a particular service instance.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-nosecondreg"},{"document_id":"ibmcld_01660-4245-6093","score":8.4150884278,"text":"\nIn the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) for more information.\n\n\n\n\n\n If I upgrade my Lite account, can I continue to use my existing instances? \n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account. However, if you want to use the capabilities that are not available in a service's Lite plan, you must [upgrade the plan](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-changing) for the specific service. After you change a service plan, it might be necessary to restage your application.\n\n\n\n\n\n Can I convert my account? \n\nYes, the following options are available depending on your account type:\n\n\n\n* If you have a feature code from an online course or educational event, you can use it to convert your Lite account to a trial account. Go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console to apply the code to your account.\n* To convert your Pay-As-You-Go account to a Subscription account, contact [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule).\n\n\n\n\n\n\n\n Can I convert my Pay-As-You-Go account to a trial account? \n\nIf you upgrade your trial account to a Pay-As-You-Go account by entering a credit card, it can't be converted back to a trial account.\n\n\n\n\n\n Can I add an educational feature code to an account after I have added a credit card? \n\nWhen you add a credit card to your trial account, your account is upgraded to a Pay-As-You-Go account. Educational feature codes can't be used in a Pay-As-You-Go account. In addition, a Pay-As-You-Go account can't be converted back to a trial account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07578-1072769-1074598","score":8.4150884278,"text":"\nIn the Account Upgrade section, click Add credit card to upgrade to a Pay-As-You-Go account, or click Upgrade for a Subscription account.\n\nSee [Upgrading your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) for more information.\n* If I upgrade my Lite account, can I continue to use my existing instances?\n\nYes, when you upgrade to a Pay-As-You-Go or Subscription account, you can continue to use the instances that you created with your Lite account. However, if you want to use the capabilities that are not available in a service's Lite plan, you must [upgrade the plan](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-changing) for the specific service. After you change a service plan, it might be necessary to restage your application.\n* Can I convert my account?\n\nYes, the following options are available depending on your account type:\n\n\n\n* If you have a feature code from an online course or educational event, you can use it to convert your Lite account to a trial account. Go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console to apply the code to your account.\n* To convert your Pay-As-You-Go account to a Subscription account, contact [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule).\n\n\n\n* Can I convert my Pay-As-You-Go account to a trial account?\n\nIf you upgrade your trial account to a Pay-As-You-Go account by entering a credit card, it can't be converted back to a trial account.\n* Can I add an educational feature code to an account after I have added a credit card?\n\nWhen you add a credit card to your trial account, your account is upgraded to a Pay-As-You-Go account. Educational feature codes can't be used in a Pay-As-You-Go account. In addition, a Pay-As-You-Go account can't be converted back to a trial account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05013-2864-3381","score":6.681711038,"text":"\nCan I create more than one Object Storage service with a Lite account? \n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n\n\n\n\n\n What happens if I exceed the maximum usage allowed for a Lite plan? \n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq-provision"},{"document_id":"ibmcld_01025-1621-3657","score":6.1919759736,"text":"\nIf needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n\n\n\n\n\n I am having trouble with reactivation. What should I do? \n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.\n\n\n\n\n\n I'm getting an error when creating a new instance. What's the problem? \n\nThere's a limit of one instance per Lite plan. You may see an error 500 message if you try to create a second Lite instance. To create a new Lite plan instance, you must first delete your existing one.\n\n\n\n\n\n I'm getting an error when creating a new schema or database. What's the problem? \n\nThe free Lite plan does not allow you to create new schemas or databases. There is an existing schema created for you to use. Use that schema.\n\n\n\n\n\n Why can\u2019t I open the web console? \n\nIf the Db2 web console does not load or returns an error message, try the following steps:\n\n\n\n* Go to the service page to check whether your Lite instance has expired. The Open Console button no longer appears for expired instances. Delete the expired instance and create a new one.\n* Try using the direct URL to open the console to check for errors. Select the Service credentials tab from your service page and expand the credentials that you want to view. If there are no existing credentials, click New credential. Use the values in the https_url, username, and password to open the web console.\n* To reset the password, select the Service credentials tab from your service page and then delete the existing service lite-tier service credential. Then click New credential to generate a new password for the existing username.\n* When you create a Lite instance, be sure to provide an email address so you receive reactivation notices and password reset notices.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-faq_db2oc_lite"},{"document_id":"ibmcld_07578-496072-498088","score":6.1919759736,"text":"\nIf needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.\n* I'm getting an error when creating a new instance. What's the problem?\n\nThere's a limit of one instance per Lite plan. You may see an error 500 message if you try to create a second Lite instance. To create a new Lite plan instance, you must first delete your existing one.\n* I'm getting an error when creating a new schema or database. What's the problem?\n\nThe free Lite plan does not allow you to create new schemas or databases. There is an existing schema created for you to use. Use that schema.\n* Why can\u2019t I open the web console?\n\nIf the Db2 web console does not load or returns an error message, try the following steps:\n\n\n\n* Go to the service page to check whether your Lite instance has expired. The Open Console button no longer appears for expired instances. Delete the expired instance and create a new one.\n* Try using the direct URL to open the console to check for errors. Select the Service credentials tab from your service page and expand the credentials that you want to view. If there are no existing credentials, click New credential. Use the values in the https_url, username, and password to open the web console.\n* To reset the password, select the Service credentials tab from your service page and then delete the existing service lite-tier service credential. Then click New credential to generate a new password for the existing username.\n* When you create a Lite instance, be sure to provide an email address so you receive reactivation notices and password reset notices.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-496054-498070","score":6.1919759736,"text":"\nIf needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.\n* I'm getting an error when creating a new instance. What's the problem?\n\nThere's a limit of one instance per Lite plan. You may see an error 500 message if you try to create a second Lite instance. To create a new Lite plan instance, you must first delete your existing one.\n* I'm getting an error when creating a new schema or database. What's the problem?\n\nThe free Lite plan does not allow you to create new schemas or databases. There is an existing schema created for you to use. Use that schema.\n* Why can\u2019t I open the web console?\n\nIf the Db2 web console does not load or returns an error message, try the following steps:\n\n\n\n* Go to the service page to check whether your Lite instance has expired. The Open Console button no longer appears for expired instances. Delete the expired instance and create a new one.\n* Try using the direct URL to open the console to check for errors. Select the Service credentials tab from your service page and expand the credentials that you want to view. If there are no existing credentials, click New credential. Use the values in the https_url, username, and password to open the web console.\n* To reset the password, select the Service credentials tab from your service page and then delete the existing service lite-tier service credential. Then click New credential to generate a new password for the existing username.\n* When you create a Lite instance, be sure to provide an email address so you receive reactivation notices and password reset notices.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_02143-0-1216","score":5.9767654807,"text":"\n\n\n\n\n\n\n  Why can't I create a new Lite plan instance? \n\nYou try to create more than one instance in your Lite account.\n\n  What\u2019s happening \n\nYou receive the following error message when you try to create a new Lite plan instance:\n\n> Unable to provision new Lite instance\n>\n> The account already has an instance created with the Lite plan\n\n  Why it\u2019s happening \n\nThere's a limit of one instance per Lite plan to ensure that these plans stay free. For more information about Lite account features, see [Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n  How to fix it \n\nYou can create more instances of the service by selecting one of the billable service plans, which are available in the billable accounts. To upgrade to a billable account from the console, go to Manage > Account in the IBM Cloud console, and select Account settings.\n\nIf you don't want to upgrade from a Lite account and are no longer using your existing Lite service instance, you can delete the existing Lite plan instance from the dashboard and then create a new instance. When you delete the Lite plan instance, all of the data that is associated with that instance is deleted and isn't recoverable.\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-nosecondlite"},{"document_id":"ibmcld_07578-1076793-1078629","score":5.6542259443,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":5.6542259443,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1323355-1325090","score":5.6130507503,"text":"\nSelect the \"standard\" plan and hit save.\n\nIn cases where the instance has been locked due to exceeding the maximum allowed size of a Lite instance it may be necessary to use the CLI. The plan ID for a standard Object Storage instance is 744bfc56-d12c-4866-88d5-dac9139e0e5d (if curious, this can be found by issuing the CLI command ic catalog service cloud-object-storage). You'll need to know the name of the instance you are trying to upgrade. For example, to upgrade the instance \"My Object Storage\", you can issue the command:\n\nic resource service-instance-update \"My Object Storage\" --service-plan-id 744bfc56-d12c-4866-88d5- dac9139e0e5d\n* Are bucket names case-sensitive?\n\nBucket names are required to be DNS addressable and are not case-sensitive.\n* What is the maximum number of characters that can be used in a key, or Object name?\n\nKeys have a 1024-character limit.\n* What are some tools unable to render object names?\n\nObject names that contain unicode characters that are not allowed by the XML standard will result in \"Malformed XML\" messages. For more information, see [the XML reference documentation](https:\/\/www.w3.org\/TR\/xml\/charsets).\n* Can I create more than one Object Storage service with a Lite account?\n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n* What happens if I exceed the maximum usage allowed for a Lite plan?\n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.\n* How can I find out the total size of my bucket by using the API?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1326020-1327755","score":5.6130507503,"text":"\nSelect the \"standard\" plan and hit save.\n\nIn cases where the instance has been locked due to exceeding the maximum allowed size of a Lite instance it may be necessary to use the CLI. The plan ID for a standard Object Storage instance is 744bfc56-d12c-4866-88d5-dac9139e0e5d (if curious, this can be found by issuing the CLI command ic catalog service cloud-object-storage). You'll need to know the name of the instance you are trying to upgrade. For example, to upgrade the instance \"My Object Storage\", you can issue the command:\n\nic resource service-instance-update \"My Object Storage\" --service-plan-id 744bfc56-d12c-4866-88d5- dac9139e0e5d\n* Are bucket names case-sensitive?\n\nBucket names are required to be DNS addressable and are not case-sensitive.\n* What is the maximum number of characters that can be used in a key, or Object name?\n\nKeys have a 1024-character limit.\n* What are some tools unable to render object names?\n\nObject names that contain unicode characters that are not allowed by the XML standard will result in \"Malformed XML\" messages. For more information, see [the XML reference documentation](https:\/\/www.w3.org\/TR\/xml\/charsets).\n* Can I create more than one Object Storage service with a Lite account?\n\nIf you already have a Lite plan instance created, you may create other Standard plan instances, but only one Lite plan instance is allowed.\n* What happens if I exceed the maximum usage allowed for a Lite plan?\n\nOnce you exceed the allowed usage, the service instance associated with the Lite plan becomes inaccessible. You will receive a warning notification email with corrective steps. If you do not take action, the instance is removed.\n* How can I find out the total size of my bucket by using the API?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-494591-496583","score":5.480301605,"text":"\n* Will my free plan expire?\n\nYou can continue using the free plan for as long as you need. However, you must reactivate the free plan every 45 days. This reactivation process keeps resources available for other users by turning off inactive usage.\n\nWhen your plan nears its reactivation date, you will receive a reactivation request at the email address that you provided when creating the instance. Alternatively, you can reactivate in your Db2 on Cloud console.\n* Will my data be deleted?\n\nAfter you create a Lite instance, you have 45 days before the next reactivation.\n\n\n\n* If you do not reactivate, your Lite plan will be disabled, but IBM Cloud still has your data. You will then have 60 days to reactivate your account.\n* If you don't reactivate within 60 days, your account and data will be deleted. We will send you multiple emails reminding you to reactivate.\n\n\n\nEach time you reactivate, the day counter resets, and you'll have another 45 days before being disabled (and 60 days before deletion).\n* How can I download a backup of my data on the Lite plan?\n\nHere are two simple options for backing up Lite plan data:\n\n\n\n* Use Db2 tools like the command line tool (clp) or IBM Data Studio to do an export. You can then import at another time.\n* To quickly make a backup, use the Web console, run a query, then download the results to a CSV file.\n\n\n\n* Can I change the email I use for reactivation?\n\nCreate a new Lite instance with the email you want to use going forward. If needed, first back up your data, delete your current Lite plan instance to create a new one, then load your data. You cannot change the email address associated with an existing Db2 Lite instance if you have only a Lite account with community support.\n* I am having trouble with reactivation. What should I do?\n\nIf you have trouble with reactivation of a Lite plan instance, you can delete that faulty instance and create a new one. If needed, first back up your data so you can load it to this new instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01468-7-2067","score":18.6206530198,"text":"\nManaging quota limits for storage and pull traffic \n\nYou can limit the amount of storage and pull traffic that can be used in your IBM Cloud account by setting and managing custom quota limits in IBM Cloud\u00ae Container Registry.\n\n\n\n Setting quota limits for storing and pulling images \n\nYou can limit the amount of storage and pull traffic to your private images by setting your own quota limits.\n\nWhen you upgrade to the IBM Cloud Container Registry standard plan, you benefit from unlimited amount of storage and pull traffic to your private images. To avoid exceeding your preferred payment level, you can set individual quotas for the amount of storage and pull traffic. Quota limits are applied to all\n\nnamespacesthat you set up in IBM Cloud Container Registry. If you're using the free service plan, you can also set custom quotas within your free amount of storage and pull traffic.\n\nTo set a quota, complete the following steps.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Review your current quota limits for storage and pull traffic.\n\nibmcloud cr quota\n\nYour output looks similar to the following example.\n\nGetting quotas and usage for the current month, for account '<account_owner> Account'...\n\nQUOTA LIMIT USED\nPull traffic 5.1 GB 0 B\nStorage 512 MB 511 MB\n\nOK\n3. Change the quota limit for storage and pull traffic. To change the pull traffic usage, specify the traffic option, and replace <traffic_quota> with the value in megabytes that you want to set for the pull traffic quota. If you want to change the amount of storage in your account, specify the storage option, and replace <storage_quota> with the value in megabytes that you want to set.\n\nIf you are on the free plan, you cannot set your quota to an amount that exceeds the free tier. The free tier allowance for storage is 512 MB and traffic is 5120 MB.\n\nibmcloud cr quota-set --traffic <traffic_quota> --storage <storage_quota>\n\nExample to set your quota limit for storage to 600 megabytes, and the pull traffic to 7000 megabytes:\n\nibmcloud cr quota-set --storage 600 --traffic 7000","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_quota"},{"document_id":"ibmcld_00348-11019-12529","score":18.5261008848,"text":"\n\"Total number of megabytes transferred between the Edge to the end user in the region - Australasia\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - EMEA\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - India\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Japan\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - North America\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Rest Of APAC\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - South America\"\n],\n\"totals\": [\n15, \/\/ Total Hits from start time to end time.\n4.9301e-5, \/\/ Total Bandwidth from start time to end time.\n0, \/\/ Hits by type 0XX\n0, \/\/ Hits by type 200\n0, \/\/ Hits by type 206\n0, \/\/ Hits by type 2XX\n0, \/\/ Hits by type 302\n0, \/\/ Hits by type 304\n0, \/\/ Hits by type 3XX\n0, \/\/ Hits by type 404\n13, \/\/ Hits by type 4XX\n2, \/\/ Hits by type 5XX\n0, \/\/ Hits by type Other\n0, \/\/ Bandwidth by region Australasia\n3.6554e-5, \/\/ Bandwidth by region EMEA\n0, \/\/ Bandwidth by region India\n0, \/\/ Bandwidth by region Japan\n1.1524e-5, \/\/ Bandwidth by region North America\n1.223e-6, \/\/ Bandwidth by region Rest Of APAC\n0 \/\/ Bandwidth by region South America\n],\n\"percentage\": [ \/\/ The percentage of the bandwidth by regions\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\n0, \/\/ Australasia","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-code-examples-using-the-cdn-api"},{"document_id":"ibmcld_00348-10050-11511","score":18.4860245844,"text":"\n\"type\": \"INTEGRATED\",\n\"names\": [\n\"TotalHits\",\n\"TotalBandwidth\",\n\"0XX\",\n\"200\",\n\"206\",\n\"2XX\",\n\"302\",\n\"304\",\n\"3XX\",\n\"404\",\n\"4XX\",\n\"5XX\",\n\"Other\",\n\"Australasia\",\n\"EMEA\",\n\"India\",\n\"Japan\",\n\"North America\",\n\"Rest Of APAC\",\n\"South America\"\n],\n\"descriptions\": [\n\"All hits to the Edge servers from the end-users.\",\n\"Total number of megabytes transferred between the Edge to the end user.\",\n\"Number of hits that returned response code - 0XX\",\n\"Number of hits that returned response code - 200\",\n\"Number of hits that returned response code - 206\",\n\"Number of hits that returned response code - 2XX\",\n\"Number of hits that returned response code - 302\",\n\"Number of hits that returned response code - 304\",\n\"Number of hits that returned response code - 3XX\",\n\"Number of hits that returned response code - 404\",\n\"Number of hits that returned response code - 4XX\",\n\"Number of hits that returned response code - 5XX\",\n\"Number of hits that returned response code not within 2XX to 5XX\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Australasia\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - EMEA\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - India\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Japan\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - North America\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-code-examples-using-the-cdn-api"},{"document_id":"ibmcld_04340-46955-48852","score":17.5204043816,"text":"\n: (Optional) Check whether the use of public connections is prevented for image pushes or pulls in your account.\n\n\n\n\n\n Example \n\nPrevent image pulls or pushes over public network connections for your account.\n\nibmcloud cr private-only --enable\n\n\n\n\n\n\n\n ibmcloud cr quota \n\nDisplays your current quotas for traffic and storage, and usage information against those quotas for the registry region that you're targeting.\n\nibmcloud cr quota\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for configuring Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n\n\n ibmcloud cr quota-set \n\nModify the specified quota for the registry region that you're targeting.\n\nibmcloud cr quota-set [--traffic TRAFFIC] [--storage STORAGE]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for configuring Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n Command options \n\n--traffic TRAFFIC\n: (Optional) Changes your traffic quota to the specified value in megabytes. The operation fails if you are not authorized to set traffic, or if you set a value that exceeds your current pricing plan.\n\n--storage STORAGE\n: (Optional) Changes your storage quota to the specified value in megabytes. The operation fails if you are not authorized to set storage quotas, or if you set a value that exceeds your current pricing plan.\n\n\n\n\n\n Example \n\nSet your quota limit for pull traffic to 7000 megabytes and storage to 600 megabytes.\n\nibmcloud cr quota-set --traffic 7000 --storage 600\n\n\n\n\n\n\n\n ibmcloud cr region \n\nDisplays the targeted region and the registry.\n\nibmcloud cr region\n\nFor more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\n\n\n Prerequisites \n\nNone\n\n\n\n\n\n\n\n ibmcloud cr region-set","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-containerregcli"},{"document_id":"ibmcld_01329-48362-50241","score":17.3883829567,"text":"\nibmcloud cr quota-set [--traffic TRAFFIC] [--storage STORAGE]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for configuring Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n Command options \n\n--traffic TRAFFIC\n: (Optional) Changes your traffic quota to the specified value in megabytes. The operation fails if you are not authorized to set traffic, or if you set a value that exceeds your current pricing plan.\n\n--storage STORAGE\n: (Optional) Changes your storage quota to the specified value in megabytes. The operation fails if you are not authorized to set storage quotas, or if you set a value that exceeds your current pricing plan.\n\n\n\n\n\n Example \n\nSet your quota limit for pull traffic to 7000 megabytes and storage to 600 megabytes.\n\nibmcloud cr quota-set --traffic 7000 --storage 600\n\n\n\n\n\n\n\n ibmcloud cr region \n\nDisplays the targeted region and the registry.\n\nibmcloud cr region\n\nFor more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\n\n\n Prerequisites \n\nNone\n\n\n\n\n\n\n\n ibmcloud cr region-set \n\nSet a target region for the IBM Cloud Container Registry commands. To list the available regions, run the command with no options.\n\nibmcloud cr region-set [REGION]\n\n\n\n Prerequisites \n\nNone\n\n\n\n\n\n Command options \n\nREGION\n: (Optional) The name of your target region, for example, us-south. For more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\n\n\n\n\n Example \n\nTarget the US South region.\n\nibmcloud cr region-set us-south\n\n\n\n\n\n\n\n ibmcloud cr retention-policy-list \n\nList the image retention policies for your account. Image retention policies retain the specified number of images for each repository within a namespace in IBM Cloud Container Registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_11421-1359-2601","score":16.4777170328,"text":"\nVOLUME GROUP: rootvg VG IDENTIFIER: 00f6db0a00004c000000016b94f02\nVG STATE: active PP SIZE: 32 megabyte(s)\nVG PERMISSION: read\/write TOTAL PPs: 639 (20448 megabytes)\nMAX LVs: 256 FREE PPs: 477 (15264 megabytes)\nLVs: 12 USED PPs: 162 (5184 megabytes)\nOPEN LVs: 11 QUORUM: 2 (Enabled)\nTOTAL PVs: 1 VG DESCRIPTIORS: 2\nSTALE PVs: 0 STALE PPs: 0\nACTIVE PVs: 1 AUTO ON: yes\nMAX PPs per VG: 32512\nMAX PPs per PV: 1016 MAX PVs: 32\nLTG size(Dynamic): 512 kilobyte(s) AUTO SYNC: no\nHOT SPARE: no BB POLICY: relocatable\nPV RESTRICTION: none INFINITE RETRY: no\nDISK BLOCK SIZE: 512 CRITICAL VG: no\nFS SYNC OPTION: no CRITICAL PVs: no\n\nShow more\n\nRunning the df -g command displays information about the total space and available space on a file system. In this instance, the rootvg volume group has enough space for creating a new file system, expanding an existing one, and storing the mksysb source image.\n\nThe storage information is shown as follow:\n\n df -g\nFilesystem GB blocks Free %Used Iused %Iused Mounted on\n\/dev\/hd4 0.09 0.06 41% 2619 17% \/\n\/dev\/hd2 2.16 0.26 89% 36565 37% \/usr\n\/dev\/hd9var 0.19 0.16 17% 953 3% \/var\n\/dev\/hd3 0.22 0.22 1% 33 1% \/tmp\n\/dev\/hd1 0.03 0.03 2% 7 1% \/home\n\/dev\/hd11admin 0.12 0.12 1% 5 1% \/admin\n\/proc - - - - - \/proc","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-restoring-aix-mksysb-image"},{"document_id":"ibmcld_11421-7-1608","score":15.9427109035,"text":"\nRestoring an AIX mksysb image onto an IBM Power Systems Virtual Server instance \n\nLearn how to restore an AIX mksysb image onto an IBM Power Systems Virtual Server instance\n\nThe IPv6 interface that is used for VM management might be affected when you restore an AIX mksysb image. Before proceeding onto the next section, review [Recommended Reliable Scalable Cluster Technology (RSCT) package levels for imported AIX images](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-recommended-rsct-package).\n\n\n\n Defining an AIX Helper VM \n\nYou can use an existing AIX VM to copy an AIX mksysb archive. The alt_disk_mksysb command copies the mksysb archive onto a new volume. The alt_disk_mksysb command also gives you the option of rebooting from a specific disk image.\n\nBefore you can copy an AIX mksysb archive, determine the amount of space the helper VM needs to hold the mksysb image. In the following example, the mksysb image (gdrh10v1.sysb) is roughly 5.8 GB. Determining the space needed as follow:\n\n:>ls -l gdrh10v1.sysb\n-rw-r--r-- 1 root system 5806899200 Jul 18 2017 gdrh10v1.sysb\n\nNext, you must identify a helper VM file system with enough space to hold the mksysb image. If such a file system does not exist, you can attach a data volume as a staging area. To display information about a volume group, use the lsvg command.\n\n lsvg rootvg\nVOLUME GROUP: rootvg VG IDENTIFIER: 00f6db0a00004c000000016b94f02\nVG STATE: active PP SIZE: 32 megabyte(s)\nVG PERMISSION: read\/write TOTAL PPs: 639 (20448 megabytes)\nMAX LVs: 256 FREE PPs: 477 (15264 megabytes)\nLVs: 12 USED PPs: 162 (5184 megabytes)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-restoring-aix-mksysb-image"},{"document_id":"ibmcld_01468-1672-3502","score":15.7425308747,"text":"\nIf you are on the free plan, you cannot set your quota to an amount that exceeds the free tier. The free tier allowance for storage is 512 MB and traffic is 5120 MB.\n\nibmcloud cr quota-set --traffic <traffic_quota> --storage <storage_quota>\n\nExample to set your quota limit for storage to 600 megabytes, and the pull traffic to 7000 megabytes:\n\nibmcloud cr quota-set --storage 600 --traffic 7000\n\n\n\n\n\n\n\n Reviewing quota limits and usage \n\nYou can review your quota limits and check your current storage and pull traffic usage for your account.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Review your current quota limits for storage and pull traffic.\n\nibmcloud cr quota\n\nYour output looks similar to the following example.\n\nGetting quotas and usage for the current month, for account '<account_owner> Account'...\n\nQUOTA LIMIT USED\nPull traffic 5.1 GB 0 B\nStorage 512 MB 511 MB\n\nOK\n\n\n\n\n\n\n\n Staying within quota limits \n\nIf you exceed the quota limits that are set for your IBM Cloud account, you can free up storage and change your service plan or quota limits so that you can continue pushing and pulling images to and from your namespace.\n\nFrom 1 February 2022, both [tagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) and [untagged](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images are charged for.\n\nTo free up image storage in your IBM Cloud account, complete the following steps.\n\nDepending on the size of the image, it might take a while for the image to be removed and for the storage to be available.\n\n\n\n1. Find the names of the images that you want to remove.\n\n\n\n* To list only tagged images, run the [ibmcloud cr image-list](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_list) command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_quota"},{"document_id":"ibmcld_06110-19432-20896","score":15.7367044635,"text":"\nParameters: ibm.io\/chunk-size-mb=16,ibm.io\/curl-debug=false,ibm.io\/debug-level=warn,ibm.io\/iam-endpoint=https:\/\/iam.bluemix.net,ibm.io\/kernel-cache=true,ibm.io\/multireq-max=20,ibm.io\/object-store-endpoint=https:\/\/s3-api.dal-us-geo.objectstorage.service.networklayer.com,ibm.io\/object-store-storage-class=us-standard,ibm.io\/parallel-count=2,ibm.io\/s3fs-fuse-retry-count=5,ibm.io\/stat-cache-size=100000,ibm.io\/tls-cipher-suite=AESGCM\nAllowVolumeExpansion: <unset>\nMountOptions: <none>\nReclaimPolicy: Delete\nVolumeBindingMode: Immediate\nEvents: <none>\n\nibm.io\/chunk-size-mb\n: The size of a data chunk that is read from or written to IBM Cloud Object Storage in megabytes. Storage classes with perf in their name are set up with 52 megabytes. Storage classes without perf in their name use 16 megabyte chunks. For example, if you want to read a file that is 1GB, the plug-in reads this file in multiple 16 or 52-megabyte chunks.\n\nibm.io\/curl-debug\n: Enable the logging of requests that are sent to the IBM Cloud Object Storage service instance. If enabled, logs are sent to syslog and you can [forward the logs to an external logging server](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-healthlogging). By default, all storage classes are set to false to disable this logging feature.\n\nibm.io\/debug-level\n: The logging level that is set by the IBM Cloud Object Storage plug-in. All storage classes are set up with the WARN logging level.\n\nibm.io\/iam-endpoint","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_cos_install"},{"document_id":"ibmcld_10551-19210-20674","score":15.7367044635,"text":"\nParameters: ibm.io\/chunk-size-mb=16,ibm.io\/curl-debug=false,ibm.io\/debug-level=warn,ibm.io\/iam-endpoint=https:\/\/iam.bluemix.net,ibm.io\/kernel-cache=true,ibm.io\/multireq-max=20,ibm.io\/object-store-endpoint=https:\/\/s3-api.dal-us-geo.objectstorage.service.networklayer.com,ibm.io\/object-store-storage-class=us-standard,ibm.io\/parallel-count=2,ibm.io\/s3fs-fuse-retry-count=5,ibm.io\/stat-cache-size=100000,ibm.io\/tls-cipher-suite=AESGCM\nAllowVolumeExpansion: <unset>\nMountOptions: <none>\nReclaimPolicy: Delete\nVolumeBindingMode: Immediate\nEvents: <none>\n\nibm.io\/chunk-size-mb\n: The size of a data chunk that is read from or written to IBM Cloud Object Storage in megabytes. Storage classes with perf in their name are set up with 52 megabytes. Storage classes without perf in their name use 16 megabyte chunks. For example, if you want to read a file that is 1GB, the plug-in reads this file in multiple 16 or 52-megabyte chunks.\n\nibm.io\/curl-debug\n: Enable the logging of requests that are sent to the IBM Cloud Object Storage service instance. If enabled, logs are sent to syslog and you can [forward the logs to an external logging server](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-healthlogging). By default, all storage classes are set to false to disable this logging feature.\n\nibm.io\/debug-level\n: The logging level that is set by the IBM Cloud Object Storage plug-in. All storage classes are set up with the WARN logging level.\n\nibm.io\/iam-endpoint","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_cos_install"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07280-34964-36511","score":9.8322238831,"text":"\nibmcloud dl locations|locs OFFERING_TYPE [\u2013-output format] [--help|-h]\n\n\n\n Command options \n\nOFFERING_TYPE\n: Specify the Direct Link offering type. Values are dedicated or connect.\n\n--output value\n: Specify whether you want the output displayed in JSON format. Currently, json is the only supported format. Optional.\n\n--help|-h\n: Get help on this command. Optional.\n\n\n\n\n\n Examples \n\n\n\n* ibmcloud dl locations dedicated\n* ibmcloud dl locs dedicated --output json\n\n\n\n\n\n\n\n\n\n ibmcloud dl offering-speeds \n\nLists all offering speeds for an offering type.\n\nibmcloud dl offering-speeds|ospeeds OFFERING_TYPE [--output format] [--help|-h]\n\n\n\n Command options \n\nOFFERING_TYPE\n: Specify the Direct Link offering type. Values are dedicated or dedicated_hosting.\n\n--output value\n: Specify whether you want the output displayed in JSON format. Currently, json is the only supported format. Optional.\n\n--help|-h\n: Get help on this command. Optional.\n\n\n\n\n\n Examples \n\n\n\n* ibmcloud dl offering-speeds dedicated\n* ibmcloud dl ospeeds dedicated_hosting --output json\n\n\n\n\n\n\n\n\n\n ibmcloud dl port \n\nView details of a port.\n\nibmcloud dl port PORT_ID [--help|-h] [--output format]\n\n\n\n Command options \n\nPORT_ID\n: Specify the ID of the port.\n\n--help|-h\n: Get help on this command. Optional.\n\n--output value\n: Specify whether you want the output displayed in JSON format. Currently, json is the only supported format. Optional.\n\n\n\n\n\n Examples \n\n\n\n* ibmcloud dl port a771366f-2c8c-49f6-a23b-9d49fad035a3\n* ibmcloud dl port a771366f-2c8c-49f6-a23b-9d49fad035a3 --output json","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-dl-cli"},{"document_id":"ibmcld_01660-7085-8964","score":9.6375921311,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_07280-33738-35344","score":9.6106831167,"text":"\nibmcloud dl loa GATEWAY_ID [--file OUTPUT_DIRECTORY_PATH] [--help|-h]\n\n\n\n Command options \n\nGATEWAY_ID\n: Specify the ID of the gateway.\n\n--file OUTPUT_DIRECTORY_PATH\n: Specify the output directory path. For example, specify to download the LOA in the \/tmp directory. Optional.\n\n--help|-h\n: Get help on this command. Optional.\n\n\n\n\n\n Examples \n\n\n\n* ibmcloud dl loa 5cc19d0a-792c-4595-adfc-f90fc650de01\n* ibmcloud dl loa 5cc19d0a-792c-4595-adfc-f90fc650de01 --file \/tmp\n\n\n\n\n\n\n\n\n\n ibmcloud dl location \n\nRetrieves location-specific information for a specific offering type.\n\nibmcloud dl location|loc LOCATION_NAME OFFERING_TYPE [--help|-h] [--output format]\n\n\n\n Command options \n\nLOCATION_NAME\n: Specify the name of the location.\n\nOFFERING_TYPE\n: Specify the Direct Link offering type. Currently only dedicated is supported.\n\n--help|-h\n: Get help on this command. Optional.\n\n--output value\n: Specify whether you want the output displayed in JSON format. Currently, json is the only supported format. Optional.\n\n\n\n\n\n Examples \n\n\n\n* ibmcloud dl location \"Washington 2\" dedicated\n* ibmcloud dl loc \"Washington 2\" dedicated --output json\n\n\n\n\n\n\n\n\n\n ibmcloud dl locations \n\nList the locations for a specific Direct Link offering type.\n\nibmcloud dl locations|locs OFFERING_TYPE [\u2013-output format] [--help|-h]\n\n\n\n Command options \n\nOFFERING_TYPE\n: Specify the Direct Link offering type. Values are dedicated or connect.\n\n--output value\n: Specify whether you want the output displayed in JSON format. Currently, json is the only supported format. Optional.\n\n--help|-h\n: Get help on this command. Optional.\n\n\n\n\n\n Examples","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-dl-cli"},{"document_id":"ibmcld_01705-7-1620","score":9.6067428458,"text":"\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_07578-1076793-1078629","score":9.5858508243,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1079289-1081125","score":9.5858508243,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_08063-4144-5315","score":9.5258668875,"text":"\n\"offering\": {\n\"name\": \"Cloud Object Storage\",\n\"type\": {\n\"group\": \"crn_service_name\",\n\"key\": \"cloud-object-storage\",\n\"kind\": \"service\",\n\"id\": \"dff97f5c-bc5e-4455-b470-411c3edbe49c\"\n}\n},\n\"resources\": [\n{\n\"crn\": \"crn:v1:staging:public:cloud-object-storage:global:a\/2dded3de4a4d4a098ebd0998be5cc845:723a59c4-9338-43fe-9dc4-e4a87cc78c8e::\",\n\"note\": \"Resource note\"\n}\n]\n}'\n\nOfferingType offeringType = new OfferingType.Builder()\n.group(OfferingType.Group.CRN_SERVICE_NAME)\n.key(\"cloud-object-storage\")\n.build();\nOffering offeringPayload = new Offering.Builder()\n.name(\"Cloud Object Storage\")\n.type(offeringType)\n.build();\nCreateCaseOptions createCaseOptions = new CreateCaseOptions.Builder()\n.type(\"technical\")\n.subject(\"Example technical case\")\n.description(\"This is an example case description. This is where the problem would be described.\")\n.offering(offeringPayload)\n.severity(4)\n.build();\n\nResponse<Case> response = service.createCase(createCaseOptions).execute();\nCase xCase = response.getResult();\n\nSystem.out.println(xCase);\n\noffering_type = OfferingType(\ngroup='crn_service_name',\nkey='cloud-object-storage'\n)\noffering_payload = Offering(\nname='Cloud Object Storage',","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui"},{"document_id":"ibmcld_02114-9608-11655","score":9.4935379035,"text":"\n: Provide a comma-separated list of pricing plans that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--provider PROVIDER (optional)\n: Provide a comma-separated list of providers that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--release RELEASE (optional)\n: Provide a comma-separated list of categories that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--type TYPE (optional)\n: Provide a comma-separated list of software types that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n\n\n\n\n\n\n ibmcloud catalog filter delete \n\nRun the following command to delete an applied filter. This filter defaults to the account level unless a catalog is specified. As a result, the filter is reset to include all products in the public catalog.\n\nibmcloud catalog filter delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n\n\n\n\n\n\n ibmcloud catalog filter offering \n\nUpdate the filter to include or exclude a particular product and any applicable pricing plans. This filter defaults to the account level unless a catalog or account group is specified.\n\nibmcloud catalog filter offering --offering PRODUCT-NAME\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n--plans-list PLANS LIST\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-manage-catalogs-plugin"},{"document_id":"ibmcld_04491-9608-11655","score":9.4935379035,"text":"\n: Provide a comma-separated list of pricing plans that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--provider PROVIDER (optional)\n: Provide a comma-separated list of providers that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--release RELEASE (optional)\n: Provide a comma-separated list of categories that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--type TYPE (optional)\n: Provide a comma-separated list of software types that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n\n\n\n\n\n\n ibmcloud catalog filter delete \n\nRun the following command to delete an applied filter. This filter defaults to the account level unless a catalog is specified. As a result, the filter is reset to include all products in the public catalog.\n\nibmcloud catalog filter delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n\n\n\n\n\n\n ibmcloud catalog filter offering \n\nUpdate the filter to include or exclude a particular product and any applicable pricing plans. This filter defaults to the account level unless a catalog or account group is specified.\n\nibmcloud catalog filter offering --offering PRODUCT-NAME\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n--plans-list PLANS LIST\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-plugin"},{"document_id":"ibmcld_12577-9608-11655","score":9.4935379035,"text":"\n: Provide a comma-separated list of pricing plans that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--provider PROVIDER (optional)\n: Provide a comma-separated list of providers that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--release RELEASE (optional)\n: Provide a comma-separated list of categories that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--type TYPE (optional)\n: Provide a comma-separated list of software types that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n\n\n\n\n\n\n ibmcloud catalog filter delete \n\nRun the following command to delete an applied filter. This filter defaults to the account level unless a catalog is specified. As a result, the filter is reset to include all products in the public catalog.\n\nibmcloud catalog filter delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n\n\n\n\n\n\n ibmcloud catalog filter offering \n\nUpdate the filter to include or exclude a particular product and any applicable pricing plans. This filter defaults to the account level unless a catalog or account group is specified.\n\nibmcloud catalog filter offering --offering PRODUCT-NAME\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n--plans-list PLANS LIST\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-manage-catalogs-plugin"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2640681226,"ndcg_cut_10":0.2640681226}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12544-4880-7097","score":15.695314259,"text":"\nUsers in a child account can't access billing and payment information, such as invoices, payments, or subscriptions, even if they previously had access in the account. To view or manage billing, users need to be invited to the enterprise account and given access to the Billing service in that account.\n* Usage is invoiced to the enterprise account for the entire month when the account was added. For example, if you add an account to the enterprise on 15 June, all of the usage for the month of June is reflected in the July invoice.\n\n\n\n\n\n\n\n Shared credit pool \n\nThe enterprise credit pool consolidates credit from all accounts in the enterprise and shares it with the accounts. The pool includes credit from all sources, including platform subscription credit, promotional credit, and support credit. When accounts in the enterprise create and use resources, the cost for this usage is deducted from the credit pool.\n\nWhen existing subscriptions are added to the enterprise, each individual subscription term is re-created within the credit pool, including characteristics such as the remaining credit balance, start dates, and end dates. As credit is used, the subscription terms burn down individually according to when they expire. For example, you imported two accounts with existing subscriptions in August 2019. One subscription, 32100456, is for $1,000 for 18 months that began in January 2019. Because it spans multiple years, the subscription is divided into terms of up to one year each. The other subscription, 55543210 is for $500 a month for two years that began in April 2019, which is also divided into multiple terms. Then, you purchased a new one-year subscription, 00012345, through your enterprise for $1,500 a month that starts in July 2020. As enterprise users use resources, credit is deducted from the first term from subscription 32100456 because it expires the soonest, then the first term from subscription 55543210 because it expires next, and so on. This behavior ensures optimum usage of your purchased subscription credit.\n\n\n\nTable 1. Subscriptions in an enterprise credit pool\nThis table has column headers and a summary row. The row headers identify the subscription and attributes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"},{"document_id":"ibmcld_03749-1776-3774","score":13.8493146975,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/enterprise-billing-usage.svg)\n\nFigure 1.Enterprise billing and usage management\n\n\n\n\n\n Billing options \n\nEnterprises require subscription billing or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). In subscription billing, you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate. The Enterprise Savings Plan billing model is similar to subscription billing. You commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nThe account that you use to create the enterprise must be a [Subscription account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). After the enterprise is created, you can add more accounts to the enterprise. If you add a Lite or trial account, the account is automatically upgraded to a Pay-As-You-Go account.\n\nSome Pay-As-You-Go accounts can't be directly imported into an enterprise, such as many Pay-As-You-Go accounts that are billed in United States dollars (USD). However, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency. All accounts must use the enterprise billing currency before you add them to the enterprise. Existing accounts that are imported into the enterprise no longer separately manage their billing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"},{"document_id":"ibmcld_12544-1669-3632","score":13.7573119973,"text":"\nUsage access is managed separately and can be targeted to the enterprise, an account group, or an account.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d4595e5202a9a27767cf034e81b038cdf772e0d5\/secure-enterprise\/includes\/billing-usage\/includes\/billing-usage\/images\/enterprise-billing-usage.svg)\n\nFigure 1.Enterprise billing and usage management\n\n\n\n\n\n Billing options \n\nEnterprises require subscription billing or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). In subscription billing, you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate. The Enterprise Savings Plan billing model is similar to subscription billing. You commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nThe account that you use to create the enterprise must be a [Subscription account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). After the enterprise is created, you can add more accounts to the enterprise. If you add a Lite or trial account, the account is automatically upgraded to a Pay-As-You-Go account.\n\nSome Pay-As-You-Go accounts can't be directly imported into an enterprise, such as many Pay-As-You-Go accounts that are billed in United States dollars (USD). However, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"},{"document_id":"ibmcld_02660-1509-3609","score":13.097913316,"text":"\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-create-an-instance"},{"document_id":"ibmcld_03749-5133-7297","score":12.9206112735,"text":"\n* Usage is invoiced to the enterprise account for the entire month when the account was added. For example, if you add an account to the enterprise on 15 June, all of the usage for the month of June is reflected in the July invoice.\n\n\n\n\n\n\n\n Shared credit pool \n\nThe enterprise credit pool consolidates credit from all accounts in the enterprise and shares it with the accounts. The pool includes credit from all sources, including platform subscription credit, promotional credit, and support credit. When accounts in the enterprise create and use resources, the cost for this usage is deducted from the credit pool.\n\nWhen existing subscriptions are added to the enterprise, each individual subscription term is re-created within the credit pool, including characteristics such as the remaining credit balance, start dates, and end dates. As credit is used, the subscription terms burn down individually according to when they expire. For example, you imported two accounts with existing subscriptions in August 2019. One subscription, 32100456, is for $1,000 for 18 months that began in January 2019. Because it spans multiple years, the subscription is divided into terms of up to one year each. The other subscription, 55543210 is for $500 a month for two years that began in April 2019, which is also divided into multiple terms. Then, you purchased a new one-year subscription, 00012345, through your enterprise for $1,500 a month that starts in July 2020. As enterprise users use resources, credit is deducted from the first term from subscription 32100456 because it expires the soonest, then the first term from subscription 55543210 because it expires next, and so on. This behavior ensures optimum usage of your purchased subscription credit.\n\n\n\nTable 1. Subscriptions in an enterprise credit pool\nThis table has column headers and a summary row. The row headers identify the subscription and attributes. The last row has a header in the first column and a summation of values from previous rows in the second column.\n\n Originating Subscription Remaining Credit Valid From Valid Until \n\n IBM Cloud Platform - 32100456, term 1 $5,000 2019-01-01 2019-12-31","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"},{"document_id":"ibmcld_07067-6420-8417","score":12.5658227337,"text":"\nMany other API methods changed and some are not available in v2. For a detailed comparison of the v1 and v2 API methods, see [API version comparison](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api).\n\n\n\n\n\n\n\n Picking a service plan \n\nChoose among the Plus, Enterprise, and Premium managed plans or opt for an on-premises installation by purchasing the Discovery Cartridge for IBM Cloud Pak for Data. Review the benefits and limits of each type of plan before you choose one.\n\n\n\n* For more information about the plans, see [Discovery pricing plans](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-pricing-plans).\n* For more information about artifact limits, see [Limit details](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-chooseplan-limit-links).\n\n\n\nThe following table shows plan types for managed deployments that are generally similar between v1 and v2.\n\n\n\nSimilar plans\n\n Current v1 plan Example v1 data usage Similar v2 plan \n\n Lite Not applicable Plus Trial (no charge for 30 days only) \n Advanced (low usage) 10,000 documents, 10,000 queries per month Plus \n Advanced (high usage) 100,000 documents, 100,000 queries per month Enterprise \n Premium Not applicable Enterprise or Premium \n\n\n\nTo get information about the current storage, documents, and collections used, click the Environment details icon from the product user interface header.\n\nYou cannot do an in-place upgrade from a v1 plan, such as Lite or Advanced, to a v2 plan. You must create a new v2 plan, and then move your data to the new service instance. While you migrate your data from v1 to v2, you will likely have both a v1 and v2 instance deployed at the same time. Consider using the 30-day no charge trial that is available with your first Plus plan instance during this time.\n\n\n\n\n\n\n\n Collecting metrics \n\nMake a note of the following information so you can compare it to your service instance data after the migration:\n\n\n\n* Number of collections","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2"},{"document_id":"ibmcld_12544-6645-8733","score":12.4123240251,"text":"\nAs enterprise users use resources, credit is deducted from the first term from subscription 32100456 because it expires the soonest, then the first term from subscription 55543210 because it expires next, and so on. This behavior ensures optimum usage of your purchased subscription credit.\n\n\n\nTable 1. Subscriptions in an enterprise credit pool\nThis table has column headers and a summary row. The row headers identify the subscription and attributes. The last row has a header in the first column and a summation of values from previous rows in the second column.\n\n Originating Subscription Remaining Credit Valid From Valid Until \n\n IBM Cloud Platform - 32100456, term 1 $5,000 2019-01-01 2019-12-31 \n IBM Cloud Platform - 55543210, term 1 $4,000 2019-04-01 2020-03-31 \n IBM Cloud Platform - 32100456, term 2 $6,000 2020-01-01 2020-06-30 \n IBM Cloud Platform - 55543210, term 2 $6,000 2020-04-01 2021-03-31 \n IBM Cloud Platform - 00012345 $18,000 2020-07-01 2021-06-30 \n Credit pool total $39,000 -- -- \n\n\n\nThe billing administrator in the enterprise account can view and monitor the total amount of available credit in the enterprise dashboard. If more credit is needed to cover the enterprise's usage, a new subscription can be purchased and then added to the enterprise account.\n\nSubscriptions can be added only to the enterprise account and cannot be added to other accounts in the enterprise.\n\nBecause subscriptions can be sized for the entire enterprise rather than per account, you get the following benefits:\n\n\n\n* Simpler sizing for a subscription because the subscriptions apply to more than one account\n* Better discounts on usage costs because subscriptions are larger\n* Fewer expiration dates to track and manage after existing subscriptions expire\n\n\n\nIn an enterprise, subscriptions are managed from the enterprise account the same way as for a stand-alone account. For more information about managing your platform and support subscriptions, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n Usage reporting","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"},{"document_id":"ibmcld_07578-45764-47767","score":12.3691061573,"text":"\nYou must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n* What is the price for using the Speech to Text Plus plan?\n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:\n\n\n\n* Users who recognize 1 to 999,999 minutes of audio in a given month pay $0.02 (USD) per minute of audio for that month.\n* Users who recognize at least 1,000,000 minutes of audio in a given month pay $0.01 (USD) per minute of audio for that month.\n\n\n\nThe Plus plan is intended for small businesses. It is also a good choice for large enterprises that want to develop and test larger applications before considering moving to a Premium plan. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text).\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-45749-47752","score":12.3691061573,"text":"\nYou must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n* What is the price for using the Speech to Text Plus plan?\n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:\n\n\n\n* Users who recognize 1 to 999,999 minutes of audio in a given month pay $0.02 (USD) per minute of audio for that month.\n* Users who recognize at least 1,000,000 minutes of audio in a given month pay $0.01 (USD) per minute of audio for that month.\n\n\n\nThe Plus plan is intended for small businesses. It is also a good choice for large enterprises that want to develop and test larger applications before considering moving to a Premium plan. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text).\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/%7BDomainName%7D\/catalog\/speech-to-text).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_14816-1663-3421","score":12.3626477718,"text":"\n* VMware Site Recovery Manager\n* VMware Aria Automation Enterprise\n* VMware Aria Operation Enterprise\n* VMware Aria Operations for Logs\n\n\n\nSmall differences exist between NSX-T Data Center and Data Center SP editions. For more information, see [Product offerings for VMware NSX-T Data Center 3.2.x](https:\/\/kb.vmware.com\/s\/article\/86095).\n\n\n\n\n\n Licensing options \n\nUsing individual license keys together with the combined license keys does not meet the payment requirements for the licenses you need.\n\nYou have the following options for licensing the selected VMware components:\n\n\n\n* Include license with purchase: In this case, a new license for the VMware component is purchased on your behalf. A combined VMware license is generated to match the cluster size of the order.\n\nWhen you purchase any license, except for vSphere Enterprise Plus and vCenter Server, and you order multiple VMware ESXi\u2122 servers, an IBM Cloud ticket is opened automatically to combine license keys. You are responsible to follow up with the ticket to ensure that you use only the license keys that the VMware Solutions Support team generates.\n* I will provide the license: Bring your own license (BYOL) is no longer allowed for VMware components except if you are migrating or upgrading an existing BYOL cluster. If you are upgrading your cluster, do not enter your BYOL licenses when you create your order for the first time, but do it later when the vSphere instance is created.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Bare metal server](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_orderinginstances-bare-metal-settings)\n* [Procedure to order VMware vSphere instances](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_orderinginstances-procedure)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vs_orderinginstances-licensing-settings"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01705-7074-9036","score":18.7297834487,"text":"\nAlso, with a Pay-As-You-Go account, you can order Advanced or Premium support plans to get extra help with your production workloads. Learn more in [Basic, Advanced, and Premium Support plans](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans).\n\nA subset of Pay-As-You-Go accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use).\n\n\n\n\n\n Subscription account \n\nSubscription accounts offer many of the same benefits as Pay-As-You-Go accounts, including access to the full IBM Cloud catalog and the ability to create multiple resource groups. In addition, Subscription accounts provide discounts for platform services and support and more consistent billing through subscriptions. You can also [set up spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) to get notified when your account or a particular service reaches a specific spending threshold that you set.\n\nWhen you purchase a subscription, you commit to a minimum spending amount for a certain period of time and receive a discount on the overall cost. For example, if you commit to spend $1,000 a month for 6 months, you might get a 5% discount. For the duration of the subscription, you get $6,000 of usage but pay only $5,700 for it. The larger the subscription, the better the discount.\n\nLarge organizations and other users with large cloud workloads can benefit from the savings and predictable billing that are provided by subscriptions. IBM Cloud offers multiple types of subscriptions to fit your usage needs.\n\nA subset of subscription accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountscommitment-model).\n\n\n\n Platform subscriptions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_01705-8543-10743","score":18.3753514598,"text":"\nLarge organizations and other users with large cloud workloads can benefit from the savings and predictable billing that are provided by subscriptions. IBM Cloud offers multiple types of subscriptions to fit your usage needs.\n\nA subset of subscription accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountscommitment-model).\n\n\n\n Platform subscriptions \n\nWhen you purchase a subscription for the IBM Cloud platform, you get discounted credit that pays for services and other resources that you create from the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog).\n\nYour resource usage is deducted from your total subscription amount. Even if your usage varies from month to month, you get predictable, consistent billing. If your usage exceeds your total subscription amount, you're charged the non-discounted rate for the overage. For more information about tracking your subscription usage, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYour subscription applies to most services in the catalog. However, some services use a specific pricing plan that requires you to purchase it separately.\n\n\n\n\n\n Support subscriptions \n\nBasic support is included with your Subscription account. If you want to enhance your support experience for production-critical resources, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to purchase a support subscription for an Advanced or Premium support plan. With a support subscription, you commit to a monthly spending amount that goes towards your support costs.\n\nSupport subscription credit is separate from any platform or service subscription credit in your account and can't be spent on resource usage. For more information, see [How subscription credit is spent](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptionssubscription-basics).\n\n\n\n\n\n Service bundle subscriptions \n\nService bundle subscriptions give you access and credit toward a set of services within a particular domain that are targeted for popular use cases.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_12544-4880-7097","score":17.4382785609,"text":"\nUsers in a child account can't access billing and payment information, such as invoices, payments, or subscriptions, even if they previously had access in the account. To view or manage billing, users need to be invited to the enterprise account and given access to the Billing service in that account.\n* Usage is invoiced to the enterprise account for the entire month when the account was added. For example, if you add an account to the enterprise on 15 June, all of the usage for the month of June is reflected in the July invoice.\n\n\n\n\n\n\n\n Shared credit pool \n\nThe enterprise credit pool consolidates credit from all accounts in the enterprise and shares it with the accounts. The pool includes credit from all sources, including platform subscription credit, promotional credit, and support credit. When accounts in the enterprise create and use resources, the cost for this usage is deducted from the credit pool.\n\nWhen existing subscriptions are added to the enterprise, each individual subscription term is re-created within the credit pool, including characteristics such as the remaining credit balance, start dates, and end dates. As credit is used, the subscription terms burn down individually according to when they expire. For example, you imported two accounts with existing subscriptions in August 2019. One subscription, 32100456, is for $1,000 for 18 months that began in January 2019. Because it spans multiple years, the subscription is divided into terms of up to one year each. The other subscription, 55543210 is for $500 a month for two years that began in April 2019, which is also divided into multiple terms. Then, you purchased a new one-year subscription, 00012345, through your enterprise for $1,500 a month that starts in July 2020. As enterprise users use resources, credit is deducted from the first term from subscription 32100456 because it expires the soonest, then the first term from subscription 55543210 because it expires next, and so on. This behavior ensures optimum usage of your purchased subscription credit.\n\n\n\nTable 1. Subscriptions in an enterprise credit pool\nThis table has column headers and a summary row. The row headers identify the subscription and attributes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"},{"document_id":"ibmcld_02379-3588-5834","score":17.2923952578,"text":"\nglobalcatalog-collection.instance.read An event is generated when you view a catalog. \n globalcatalog-collection.instance.update An event is generated when you update a catalog. \n globalcatalog-collection.instances.list An event is generated when you get a list of the catalogs in an account. \n\n\n\n\n\n\n\n Events for managing products in a private catalog \n\n\n\nTable 5. Actions that generate events for products in a private catalog\n\n Action Description \n\n globalcatalog-collection.offerings.list An event is generated when you get a list of the products in a catalog. \n globalcatalog-collection.offering.read An event is generated when you view a product in a catalog. \n globalcatalog-collection.offering.create An event is generated when you create a product. \n globalcatalog-collection.offering.update An event is generated when you update a product. \n globalcatalog-collection.offering.delete An event is generated when you delete a product. \n\n\n\n\n\n\n\n Events for managing catalog settings at the account level \n\n\n\nTable 6. Actions that generate events related to catalog management settings\n\n Action Description \n\n globalcatalog-collection.account-settings.read An event is generated when you view the account settings. \n globalcatalog-collection.account-settings.update An event is generated when you update the account settings. \n\n\n\n\n\n\n\n Events for managing catalog settings in enterprise accounts \n\n\n\nTable 7. Actions that generate events related to catalog management settings in enterprise accounts\n\n Action Description \n\n globalcatalog-collection.enterprise-settings.read An event is generated when you view the enterprise settings. \n globalcatalog-collection.enterprise-settings.update An event is generated when you update the enterprise settings. \n globalcatalog-collection.enterprise-settings.list An event is generated when you get a list of the enterprises in an account and their corresponding settings. \n\n\n\n\n\n\n\n Events for managing software licenses and entitlements \n\nThe following table lists the actions that generate an event:\n\n\n\nTable 8. Actions that generate events related to licenses and entitlements\n\n Action Description \n\n entitlement.entitlement.create An event is generated when an initiator binds a license to an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-at_events_acc_mgt"},{"document_id":"ibmcld_03435-3588-5834","score":17.2923952578,"text":"\nglobalcatalog-collection.instance.read An event is generated when you view a catalog. \n globalcatalog-collection.instance.update An event is generated when you update a catalog. \n globalcatalog-collection.instances.list An event is generated when you get a list of the catalogs in an account. \n\n\n\n\n\n\n\n Events for managing products in a private catalog \n\n\n\nTable 5. Actions that generate events for products in a private catalog\n\n Action Description \n\n globalcatalog-collection.offerings.list An event is generated when you get a list of the products in a catalog. \n globalcatalog-collection.offering.read An event is generated when you view a product in a catalog. \n globalcatalog-collection.offering.create An event is generated when you create a product. \n globalcatalog-collection.offering.update An event is generated when you update a product. \n globalcatalog-collection.offering.delete An event is generated when you delete a product. \n\n\n\n\n\n\n\n Events for managing catalog settings at the account level \n\n\n\nTable 6. Actions that generate events related to catalog management settings\n\n Action Description \n\n globalcatalog-collection.account-settings.read An event is generated when you view the account settings. \n globalcatalog-collection.account-settings.update An event is generated when you update the account settings. \n\n\n\n\n\n\n\n Events for managing catalog settings in enterprise accounts \n\n\n\nTable 7. Actions that generate events related to catalog management settings in enterprise accounts\n\n Action Description \n\n globalcatalog-collection.enterprise-settings.read An event is generated when you view the enterprise settings. \n globalcatalog-collection.enterprise-settings.update An event is generated when you update the enterprise settings. \n globalcatalog-collection.enterprise-settings.list An event is generated when you get a list of the enterprises in an account and their corresponding settings. \n\n\n\n\n\n\n\n Events for managing software licenses and entitlements \n\nThe following table lists the actions that generate an event:\n\n\n\nTable 8. Actions that generate events related to licenses and entitlements\n\n Action Description \n\n entitlement.entitlement.create An event is generated when an initiator binds a license to an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/atracker?topic=atracker-at_events_acc_mgt"},{"document_id":"ibmcld_01705-4111-6013","score":17.2522916641,"text":"\nIf you have an account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console to apply the code.\n\nIf you upgrade your trial account to a Pay-As-You-Go account by entering a credit card, it can't be converted back to a trial account. IBM Cloud trial accounts are available for faculty and students at accredited academic institutions. Trial accounts expire after 30 days. Your account is deactivated when the trial period ends. To reactivate your account, log in to your account and upgrade it to a Pay-As-You-Go account.\n\nIf you import a trial account into an enterprise, it's automatically upgraded to a [Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\nSupport for a trial account is limited to nontechnical support issues that are related to account access and billing. Users with trial accounts can view the [IBM Cloud documentation](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar), Chat with Watson, and use [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud).\n\n\n\n\n\n Pay-As-You-Go account \n\nWith a Pay-As-You-Go account, you can access the full IBM Cloud catalog, including all Free and Lite plans. You pay only for billable services that you use and monthly commitments, with no long-term contracts or commitments. When you register with IBM Cloud, you get a Pay-As-You-Go account, and you receive a [$200 credit](https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account) to help get you started. You can use the $200 credit on IBM Cloud products.\n\nYour resource usage consists of recurring and fluctuating costs. If you purchase classic infrastructure services, you're billed on an hourly or monthly recurring basis in advance of use, like a rent bill. If you purchase platform services, your invoice fluctuates as your resource usage fluctuates, similar to a utility bill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_03735-2945-4853","score":17.134863522,"text":"\nClick the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Share.\n3. Click Copy link and share the link with users in your account.\n\n\n\n\n\n\n\n Creating quotes for classic infrastructure services \n\nYou can generate and view quotes for only Bare Metal Servers, Virtual Server, and Gateway add-ons. Any user with access to the account can create quotes. To view quotes, you need to either be the account owner or have the Add\/Upgrade Storage (StorageLayer), Add Server, or Add\/Upgrade Services [classic infrastructure permission](https:\/\/cloud.ibm.com\/docs\/account?topic=account-mngclassicinfra).\n\n\n\n1. Generate a quote by clicking Save as quote from the Order Summary section on the product details page. Or contact a IBM Cloud sales representative.\n\nIf you're in a Lite account, select Email quote when you enter your contact details so that you can view your quote after you create it. Only billable accounts can view quotes in the console.\n2. View your quote by going to Manage > Billing and usage, and select Sales > Device quotes. If you have access, you can purchase the quoted product by clicking the quote and confirming the order.\n\n\n\n\n\n\n\n Supported billing currencies \n\nThe following table lists the supported billing currencies.\n\nAny Pay-As-You-Go accounts created after 25 October 2021 are billed in USD. There are exceptions that apply to users in India who are billed in INR by using a credit card. Also, if you're working with IBM Cloud Sales to set up a Subscription account or the Enterprise Savings Plan billing model, you can still be billed in your local currency.\n\n\n\nTable 1. Supported currencies\n\n ISO 4217 code Currency \n\n AUD Australian dollar \n BRL Brazilian real \n CAD Canadian dollar \n CHF Swiss franc \n DKK Danish krone \n EUR Euro \n GBP Pound sterling \n INR Indian rupee \n JPY Japanese yen","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_12528-1615-3608","score":16.3221340185,"text":"\n* Share to this enterprise or account groups to select the enterprise or specific account groups within the enterprise.\n* Share with other enterprises to add IDs for enterprises or account groups in other enterprises that you are assigned Editor role or higher on. This option is used to create an allowlist of other enterprises or account groups to which you want to share your product. You must have the Editor role on the enterprise or account group that you are trying to add. Select Add accounts, enter the enterprise ID, and click Add > Share.\n\n\n\nWhen you share your product with another enterprise, the enterprise is added to a list of IDs that are granted access to your product. This list is also known as the allowlist. Any account that is not included in the allowlist can't access your product.\n7. Click Share.\n\n\n\n\n\n\n\n Sharing your product by using the CLI \n\nWhen you share a product with users in your account, enterprise, or account groups, they can create instances of any version that is validated and in the ready state. Versions that are in the draft state are not shared with users.\n\nRun the [ibmcloud catalog offering publish enterprise](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-pluginpublish-offering-enterprise) command to share your product to your enterprise:\n\nibmcloud catalog offering publish enterprise [--catalog CATALOG]\n\nRun the [ibmcloud catalog offering publish allowlist](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-pluginpublish-offering-allowllist) command to share your product to an allowlisted set of accounts:\n\nibmcloud catalog offering publish allowlist [--catalog CATALOG][--account-ids ACCOUNT-IDS]\n\nThe ibmcloud catalog offering publish allowlist command shares your product with stand-alone accounts, enterprises, or account groups based on the IDs listed in the command. You must have Editor role or higher on the other enterprise or enterprise account groups that you add to the list to successfully share the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-catalog-enterprise-share"},{"document_id":"ibmcld_02660-1509-3609","score":16.2809624287,"text":"\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-create-an-instance"},{"document_id":"ibmcld_01316-2609-4002","score":15.879390293,"text":"\nWatson IoT Platform Standard The Standard service plan includes the free data-transfer limit that is offered in the Lite plan and then usage-based billing beyond the free quote for data exchanged, data analyzed, and edge data analyzed. \n Watson IoT Platform Advanced Security The Advanced Security service plan includes the free data-transfer limit that is offered in the Lite plan and then usage-based billing beyond the free quote for data exchanged, data analyzed, and edge data analyzed. This plan also provides advanced Risk and Security Management features. \n\n\n\n\n\n\n\n\n\n Upgrading service plans \n\nIf you are an existing customer and want to take advantage of the full [Watson IoT Platform feature set ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.ibm.com\/support\/knowledgecenter\/SSQP8H\/iot\/overview\/overview.html), you can purchase one of the Connection and Analytics Service plans and then migrate your existing environment.\n\nTo migrate plans, contact your IBM\u00ae representative or raise a support ticket.\n\nTo migrate from Watson IoT Platform Lite plan, or to migrate to other plans with only the essential configuration settings included, see the instructions in [Migrating Watson IoT Platform Lite to Watson IoT Platform Non-production or Production](https:\/\/cloud.ibm.com\/docs\/services\/IoT?topic=IoT-org_migrationorg_migration).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/IoT?topic=IoT-plans_overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-414710-416563","score":21.8608201195,"text":"\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n\n\n\n\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"host\": \"2922d728-27c0-4c7f-aa80-1e59fbeb04d0-bluemix.cloudant.com\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-414684-416537","score":21.8608201195,"text":"\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n\n\n\n\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"host\": \"2922d728-27c0-4c7f-aa80-1e59fbeb04d0-bluemix.cloudant.com\",","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00589-8040-10059","score":21.7547696438,"text":"\niam_apikey_description\n: Description of IAM API key.\n\niam_apikey_name\n: ID of IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of service ID.\n\npassword\n: The IBM Cloudant legacy credential password.\n\nport\n: IBM Cloudant service port.\n\nurl\n: IBM Cloudant service URL, including embedded IBM Cloudant legacy credentials.\n\nusername\n: The IBM Cloudant legacy credential username.\n\nNote the included username and password are always equivalent to IAM's Manager credentials. Therefore, the use of Use both legacy credentials and IAM is insecure when used with Reader, Writer, Monitor, or Checkpointer IAM roles.\n\n\n\n\n\n\n\n Must I use Use only IAM or Use both legacy credentials and IAM? \n\nIf possible, Use only IAM is preferred. The major advantages for using IBM Cloud IAM are shown in the following list:\n\n\n\n* Management of access to IBM Cloudant with the standard tools of IBM Cloud rather than a combination of IBM Cloud and IBM Cloudant-specific credential management.\n* Credentials can be easily revoked and rotated when you use IBM Cloud IAM.\n\n\n\nFurther description of the advantages and disadvantages of each approach follows.\n\nWhen you use IAM roles other than Manager, such as Reader, Writer, Monitor, or Checkpointer, you must use Use only IAM to avoid supplying users with legacy credentials that include greater access permissions.\n\n\n\n Advantages and disadvantages of the two access control mechanisms \n\nOverall, IBM Cloud IAM is the recommended authentication model. However, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_07578-419683-421572","score":21.7480470915,"text":"\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-419665-421554","score":21.7480470915,"text":"\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00531-7-2145","score":20.8860894742,"text":"\nAuthenticating with IBM Cloudant FAQ \n\nIBM Cloud\u00ae Identity and Access Management (IAM) combines managing user identities, services, and access control into one approach. IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae integrates with IBM Cloud Identity and Access Management.\n\n\n\n What is the difference between IBM Cloudant legacy and IAM access controls? \n\n\n\n IBM Cloud IAM \n\n\n\n* Centrally managed access management across IBM Cloud.\n* Allows a user or service to access many different resources by using the same set of credentials (for example, same username and password or IAM API key).\n* IAM API keys can be granted access to account management functions, like creating new databases.\n\n\n\n\n\n\n\n IBM Cloudant legacy \n\n\n\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\n Why is the Use only IAM mode preferred? \n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\n How can I create an instance by using the command line? \n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" cloudantnosqldb Standard us-south -p '{\"legacyCredentials\": false}'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-authenticating-cloudant"},{"document_id":"ibmcld_00579-7-1988","score":20.7508024247,"text":"\nIndexing and querying \n\nThe Index and querying document is the second best practice document in the series. It shows you the following best practices:\n\n\n\n* How to understand the different results between emitting data into a view or not.\n* Why you must never rely on IBM Cloudant Query's ability to query without creating explicit indexes.\n* Why you must limit the number of fields with IBM Cloudant Search (or IBM Cloudant Query indexes of type text).\n* How to manage design documents.\n* Why partitioned queries are faster and cheaper.\n* How to use the primary index as a free search index.\n\n\n\nFor more information, see [Data modeling](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling) or [IBM Cloudant in practice](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-in-practice).\n\nThe content in this document was originally written by Stefan Kruger as a [Best and worst practice](https:\/\/blog.cloudant.com\/2019\/11\/21\/Best-and-Worst-Practices.html) blog post on 21 November 2019.\n\n\n\n Understand the tradeoffs in emitting data or not into a view \n\nAs the document that is referenced by a view is always available by using include_docs=true, it is possible to do something like the following example to allow lookups on indexed_field:\n\nemit(doc.indexed_field, null);\n\nThis example has the following advantages and disadvantages:\n\n\n\n* The index is compact. This index size is good, since index size contributes to storage costs.\n* The index is robust. Since the index does not store the document, you can access any field without thinking ahead about what to store in the index.\n* The disadvantage is that getting the document back is more costly than the alternative of emitting data into the index itself. First, the database has to look up the requested key in the index and then read the associated document. Also, if you\u2019re reading the whole document, but need only a single field, you\u2019re making the database read and transmit data that you don\u2019t need.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-indexing-and-querying"},{"document_id":"ibmcld_00589-9560-11733","score":20.1539903455,"text":"\nHowever, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.\n* Fine-grained permissions (for example, Reader, Writer, Monitor, or Checkpointer).\n\n\n\n\n\n\n\n Disadvantages of IAM mode \n\n\n\n* If you are not using the supported libraries from IBM Cloudant, application changes are likely to be required to use IAM's API keys and access tokens.\n* No database-level permissions (yet).\n* Some endpoints are not available. For more information, see [unavailable endpoints](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudantunavailable-endpoints).\n* No way to specify a database as \"public\", that is, not requiring an authorized user to access.\n\n\n\n\n\n\n\n Advantages of legacy mode \n\n\n\n* No need to change existing applications or client library dependencies.\n* Database-level permissions.\n\n\n\n\n\n\n\n Disadvantages of legacy mode \n\n\n\n* Separate management of IBM Cloudant credentials, so unable to get full overview of all access within centralized interface.\n\n\n\n\n\n\n\n\n\n\n\n Create a replication job by using IAM credentials only \n\nFollow these instructions to generate IAM API keys, generate the bearer token, create the _replicator database, and create the replication job.\n\n\n\n Generating IAM API keys for Source and Target and one for IBM Cloudant API access \n\nIn this exercise, the first two API keys are created so that the two instances can talk to each other during the replication process. The third API key is for the user to access the IBM Cloudant API, create the _replicator database, and then add the replication document to it.\n\nFollow these steps to generate IAM API keys and API access for IBM Cloudant. You must write down the credentials that are requested in the following steps to continue with the example.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-managing-access-for-cloudant"},{"document_id":"ibmcld_05138-7979-9034","score":19.0431263584,"text":"\nAfter your bucket is created with Activity Tracker and Monitoring, it may take a few minutes for the rules to take effect.\n\nYou are now ready to store data in a secure content store with encryption, monitoring, and audit observability!\n\n\n\n\n\n Get started by uploading data \n\n\n\n* See [uploading data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-upload) for more information.\n\n\n\n\n\n\n\n Add capabilities \n\nAdd capabilities to protect objects from ransomware and accidental deletion such as [versioning](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-versioning) and [immutable retention polices](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview) for supporting immutable storage, and immutable backup and archive data.\n\n\n\n\n\n Library of Object Storage tutorials \n\nCheck out the IBM Cloud Tutorials library for more tutorials when deploying solutions with [Cloud Object Storage](https:\/\/cloud.ibm.com\/docs?tab=tutorials&page=1&pageSize=20&tags=cloud-object-storage).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-secure-content-store"},{"document_id":"ibmcld_02361-24500-26305","score":18.9827796689,"text":"\n[Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-6428-8391","score":29.5772096618,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-6428-8442","score":29.3180786745,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_03618-1804-3397","score":22.7399012212,"text":"\nThe TPM device is integrated within the server system and provides a range of Intel TXT security-related functions.\n\n\n\n\n\n What does Intel TXT does for you \n\nIntel TXT is especially advantageous for large enterprises subject to compliance and audit regulations, such as healthcare, financial services, and government organizations. It helps assure that tracking of all trusted resources can be integrated, managed, and reported on with the relevant compliance organizations (HIPAA, PCI, FedRAMP, ISO, FISMA, and SSAE 16). For the first time, these organizations are able to certify that a cloud computing system is secured for workloads such as\n\n\n\n* Governance and enterprise risk\n* Information and lifecycle management\n* Compliance and audit\n* Application security\n* Identity and access management\n* Incident response\n\n\n\nFor more information about Intel TXT on IBM Cloud Bare Metal Servers, see [Intel\u00ae Trusted Execution Technology](https:\/\/www.ibm.com\/cloud\/bare-metal-servers\/intel-txt).\n\n\n\n\n\n Special technical notice \n\nIntel TXT is provided by Intel\u00ae and operates on the IBM Cloud Bare Metal Servers that require specific technical knowledge to support and manage. The IBM Cloud current delivery model can turn Intel\u00ae TXT either on or off. IBM Cloud can't assist with configuration of Intel TXT settings because of the sensitivity of customer environments and data. The recommendation is that you either include staff who is trained in Intel TXT technologies or engage with a consulting firm with expertise in orchestrating root of trust and measured launch environment (MLE) architecture.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-bm-hardware-monitroing-security-controls"},{"document_id":"ibmcld_07679-0-891","score":20.9444630491,"text":"\n\n\n\n\n\n\n  AU-14 - Session Audit \n\n\n\n  Control requirements \n\nAU-14 - 0\n:   The information system provides the capability for authorized users to select a user session to capture\/record or view\/hear.\n\n\n\n\n\n  Implementation guidance \n\nSee the resources that follow to learn more about how to implement this control.\n\n\n\n*  [Running operator actions through a bastion host](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-bastion)\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nSession audits include, for example, monitoring keystrokes, tracking websites visited, and recording information and\/or file transfers. Session auditing activities are developed, integrated, and used in consultation with legal counsel in accordance with applicable federal laws, Executive Orders, directives, policies, regulations, or standards.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-au-14"},{"document_id":"ibmcld_05075-3718-5743","score":20.5767402768,"text":"\nHowever, legal holds are more flexible and don't have a defined temporal component. Instead they simply remain in effect until removed. Legal holds can be freely placed and removed by any user who has the cloud-object-storage.object.put_object_lock_legal_hold and cloud-object-storage.object.put_object_lock_legal_hold_version actions.\n\nLegal holds have the additional benefit of acting as method for applying indefinite retention on an object.\n\nLegal holds and retention periods operate independently. Legal holds have no impact on retention periods, and vice-versa.\n\nImagine an object with both a legal hold and a retention period. When the retention period ends, the object version remains protected until the legal hold is removed. If you remove a legal hold while an object version is subject to a retention period it remains protected until the retention period is complete.\n\nObjects locked and stored with a retention period cannot be deleted until retention period expires and any associated legal hold is removed.\n\nLocking objects with a Governance Mode is not supported.\n\n\n\n\n\n\n\n Getting started with Object Lock \n\nIn order to get started, there are some some prerequisites:\n\n\n\n* You'll need the Writer or Manager platform role on a bucket, or a custom role with the appropriate actions (such as cloud-object-storage.bucket.put_object_lock_configuration) assigned.\n* Object Versioning must be enabled\n* You will need to use Standard pricing plan, see [pricing](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-billing) for details.\n* You will need to pick a region where Object Lock is supported, refer to [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-service-availability) for details.\n* A maximum default retention period of 100 years (or 36500 days) is supported.\n* When using the console, it is also possible to set a Retain Until Date in months, in addition to days or years.\n\n\n\nThe retention period for an object cannot be decreased.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview"},{"document_id":"ibmcld_05075-10227-12120","score":19.9997730847,"text":"\nThere should be no adverse interactions when using Object Lock with other Object Storage features, such as setting CORS policies, setting IP firewalls or condition based restrictions, bucket quotas, or Code Engine.\n\n\n\n\n\n\n\n IAM actions \n\nThere are new IAM actions associated with Object Lock.\n\n\n\n IAM Action Role \n\n cloud-object-storage.bucket.get_object_lock_configuration Manager, Writer, Reader \n cloud-object-storage.bucket.put_object_lock_configuration Manager, Writer \n cloud-object-storage.object.get_object_lock_retention Manager, Writer, Reader \n cloud-object-storage.object.put_object_lock_retention Manager, Writer \n cloud-object-storage.object.get_object_lock_retention_version Manager, Writer, Reader \n cloud-object-storage.object.put_object_lock_retention_version Manager, Writer \n cloud-object-storage.object.get_object_lock_legal_hold Manager, Writer, Reader \n cloud-object-storage.object.put_object_lock_legal_hold Manager, Writer \n cloud-object-storage.object.get_object_lock_legal_hold_version Manager, Writer, Reader \n cloud-object-storage.object.put_object_lock_legal_hold_version Manager, Writer \n\n\n\nBe advised that users with the Writer role are capable of making objects un-deletable for many years (possibly thousand of years). Be careful, and consider crafting custom roles that do not allow most users to set a Retain Until Date.\n\n\n\n\n\n Activity Tracker events \n\nObject Lock generates additional events.\n\n\n\n* cloud-object-storage.bucket-object-lock.create\n* cloud-object-storage.bucket-object-lock.read\n* cloud-object-storage.object-object-lock-legal-hold.create\n* cloud-object-storage.object-object-lock-legal-hold.read\n* cloud-object-storage.object-object-lock-retention.create\n* cloud-object-storage.object-object-lock-retention.read\n\n\n\nFor cloud-object-storage.bucket-object-lock.create events, the following fields provide extra information:\n\n\n\n Field Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview"},{"document_id":"ibmcld_05070-21841-23262","score":19.9685407362,"text":"\nIf both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\nfunction putObjectAddLegalHold(bucketName, objectName, legalHoldId) {\nconsole.log(Add legal hold ${legalHoldId} to ${objectName} in bucket ${bucketName} with a putObject operation.);\nreturn cos.putObject({\nBucket: bucketName,\nKey: objectName,\nBody: 'body',\nRetentionLegalHoldId: legalHoldId\n}).promise()\n.then((data) => {\nconsole.log(Legal hold ${legalHoldId} added to object ${objectName} in bucket ${bucketName});\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\nfunction copyProtectedObject(sourceBucketName, sourceObjectName, destinationBucketName, newObjectName, ) {\nconsole.log(Copy protected object ${sourceObjectName} from bucket ${sourceBucketName} to ${destinationBucketName}\/${newObjectName}.);\nreturn cos.copyObject({\nBucket: destinationBucketName,\nKey: newObjectName,\nCopySource: sourceBucketName + '\/' + sourceObjectName,\nRetentionDirective: 'Copy'\n}).promise()\n.then((data) => {\nconsole.log(Protected object copied from ${sourceBucketName}\/${sourceObjectName} to ${destinationBucketName}\/${newObjectName});\n})\n.catch((e) => {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_04939-58862-60352","score":19.7009208368,"text":"\nIf neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {\nSystem.out.printf(\"Add legal hold %s to %s in bucket %s with a putObject operation.n\", legalHoldId, objectName, bucketName);\n\nInputStream newStream = new ByteArrayInputStream(fileText.getBytes(StandardCharsets.UTF_8));\n\nObjectMetadata metadata = new ObjectMetadata();\nmetadata.setContentLength(fileText.length());\n\nPutObjectRequest req = new PutObjectRequest(\nbucketName,\nobjectName,\nnewStream,\nmetadata\n);\nreq.setRetentionLegalHoldId(legalHoldId);\n\ncos.putObject(req);\n\nSystem.out.printf(\"Legal hold %s added to object %s in bucket %sn\", legalHoldId, objectName, bucketName);\n}\n\npublic static void copyProtectedObject(String sourceBucketName, String sourceObjectName, String destinationBucketName, String newObjectName) {\nSystem.out.printf(\"Copy protected object %s from bucket %s to %s\/%s.n\", sourceObjectName, sourceBucketName, destinationBucketName, newObjectName);\n\nCopyObjectRequest req = new CopyObjectRequest(\nsourceBucketName,\nsourceObjectName,\ndestinationBucketName,\nnewObjectName\n);\nreq.setRetentionDirective(RetentionDirective.COPY);\n\ncos.copyObject(req);","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-java"},{"document_id":"ibmcld_05044-58842-60332","score":19.7009208368,"text":"\nIf neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {\nSystem.out.printf(\"Add legal hold %s to %s in bucket %s with a putObject operation.n\", legalHoldId, objectName, bucketName);\n\nInputStream newStream = new ByteArrayInputStream(fileText.getBytes(StandardCharsets.UTF_8));\n\nObjectMetadata metadata = new ObjectMetadata();\nmetadata.setContentLength(fileText.length());\n\nPutObjectRequest req = new PutObjectRequest(\nbucketName,\nobjectName,\nnewStream,\nmetadata\n);\nreq.setRetentionLegalHoldId(legalHoldId);\n\ncos.putObject(req);\n\nSystem.out.printf(\"Legal hold %s added to object %s in bucket %sn\", legalHoldId, objectName, bucketName);\n}\n\npublic static void copyProtectedObject(String sourceBucketName, String sourceObjectName, String destinationBucketName, String newObjectName) {\nSystem.out.printf(\"Copy protected object %s from bucket %s to %s\/%s.n\", sourceObjectName, sourceBucketName, destinationBucketName, newObjectName);\n\nCopyObjectRequest req = new CopyObjectRequest(\nsourceBucketName,\nsourceObjectName,\ndestinationBucketName,\nnewObjectName\n);\nreq.setRetentionDirective(RetentionDirective.COPY);\n\ncos.copyObject(req);","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-java"},{"document_id":"ibmcld_05088-36762-38638","score":19.6919993573,"text":"\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to get bucket protection config: {0}\".format(e))\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time that is specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\ndef put_object_add_legal_hold(bucket_name, object_name, file_text, legal_hold_id):\nprint(\"Add legal hold {0} to {1} in bucket {2} with a putObject operation.n\".format(legal_hold_id, object_name, bucket_name))\n\ncos.put_object(\nBucket=bucket_name,\nKey=object_name,\nBody=file_text,\nRetentionLegalHoldId=legal_hold_id)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-1541-3629","score":30.915742394,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-1541-3629","score":30.915742394,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-7925-10174","score":28.2412742323,"text":"\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time. A Content-MD5 header is required to ensure data integrity, and is automatically sent when using an SDK.\n\n\n\n Add a retention policy on an existing bucket \n\nThis implementation of the PUT operation uses the protection query parameter to set the retention parameters for an existing bucket. This operation allows you to set or change the minimum, default, and maximum retention period. This operation also allows you to change the protection state of the bucket.\n\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object-specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nA Content-MD5 header is required. This operation does not make use of extra query parameters.\n\nFor more information about endpoints, see [Endpoints and storage locations](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints)\n\nSyntax\n\nPUT https:\/\/{endpoint}\/{bucket-name}?protection= path style\nPUT https:\/\/{bucket-name}.{endpoint}?protection= virtual host style\n\nExample request","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-7904-10153","score":28.2412742323,"text":"\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time. A Content-MD5 header is required to ensure data integrity, and is automatically sent when using an SDK.\n\n\n\n Add a retention policy on an existing bucket \n\nThis implementation of the PUT operation uses the protection query parameter to set the retention parameters for an existing bucket. This operation allows you to set or change the minimum, default, and maximum retention period. This operation also allows you to change the protection state of the bucket.\n\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object-specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nA Content-MD5 header is required. This operation does not make use of extra query parameters.\n\nFor more information about endpoints, see [Endpoints and storage locations](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints)\n\nSyntax\n\nPUT https:\/\/{endpoint}\/{bucket-name}?protection= path style\nPUT https:\/\/{bucket-name}.{endpoint}?protection= virtual host style\n\nExample request","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04939-55110-56793","score":27.6525818524,"text":"\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\npublic static void addProtectionConfigurationToBucket(String bucketName) {\nSystem.out.printf(\"Adding protection to bucket: %sn\", bucketName);\n\nBucketProtectionConfiguration newConfig = new BucketProtectionConfiguration()\n.withStatus(BucketProtectionStatus.Retention)\n.withMinimumRetentionInDays(10)\n.withDefaultRetentionInDays(100)\n.withMaximumRetentionInDays(1000);\n\ncos.setBucketProtection(bucketName, newConfig);\n\nSystem.out.printf(\"Protection added to bucket %sn\", bucketName);\n}\n\npublic static void addProtectionConfigurationToBucketWithRequest(String bucketName) {\nSystem.out.printf(\"Adding protection to bucket: %sn\", bucketName);\n\nBucketProtectionConfiguration newConfig = new BucketProtectionConfiguration()\n.withStatus(BucketProtectionStatus.Retention)\n.withMinimumRetentionInDays(10)\n.withDefaultRetentionInDays(100)\n.withMaximumRetentionInDays(1000);","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-java"},{"document_id":"ibmcld_05044-55090-56773","score":27.6525818524,"text":"\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\npublic static void addProtectionConfigurationToBucket(String bucketName) {\nSystem.out.printf(\"Adding protection to bucket: %sn\", bucketName);\n\nBucketProtectionConfiguration newConfig = new BucketProtectionConfiguration()\n.withStatus(BucketProtectionStatus.Retention)\n.withMinimumRetentionInDays(10)\n.withDefaultRetentionInDays(100)\n.withMaximumRetentionInDays(1000);\n\ncos.setBucketProtection(bucketName, newConfig);\n\nSystem.out.printf(\"Protection added to bucket %sn\", bucketName);\n}\n\npublic static void addProtectionConfigurationToBucketWithRequest(String bucketName) {\nSystem.out.printf(\"Adding protection to bucket: %sn\", bucketName);\n\nBucketProtectionConfiguration newConfig = new BucketProtectionConfiguration()\n.withStatus(BucketProtectionStatus.Retention)\n.withMinimumRetentionInDays(10)\n.withDefaultRetentionInDays(100)\n.withMaximumRetentionInDays(1000);","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-java"},{"document_id":"ibmcld_04939-57496-59284","score":26.4968025249,"text":"\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-java"},{"document_id":"ibmcld_05044-57476-59264","score":26.4968025249,"text":"\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-java"},{"document_id":"ibmcld_04866-3142-5463","score":26.4484364819,"text":"\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-3142-5463","score":26.4484364819,"text":"\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07120-22745-24224","score":25.4520681542,"text":"\n[Shows that multiple responses are returned for the query.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-sdu-rule-response.png)\n\nFigure 26. Multiple responses are returned for the query\n\nOur updates only improved the quality of the accurate responses that were returned before.\n3. Now, let's ask a question that returned poor results previously. Enter What are PTFs? as the search query.\n\nThe same response that was returned as the only response last time is returned again. However, this time we get more than one response. And we can see that the second response that is returned defines the acronym for us.\n\n(\u201cprincipal trading firms\u201d or \u201cPTFs\u201d)\n\nZoom\n\n![Shows responses that are returned to answer the question about PTFs.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-sdu-ptf-responses.png)\n\nFigure 27. Responses that answer the question about PTFs\n4. Let's try the other problematic search query. Enter Where do muni bond trades get reported to? as the search query.\n\nThis time it's the third response that provides an answer to the question. You must view the full passage to see the entire definition.\n\nZoom\n\n![Shows responses that are returned to answer the question about muni bonds.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-sdu-muni-responses.png)\n\nFigure 28.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-sdu"},{"document_id":"ibmcld_06981-12510-14371","score":24.944510509,"text":"\nAlthough, it might be difficult to know which field to search later for information that you need if the field names don't match the content. The default set are representative field types that are meant to help you get started. Only the text and table fields have special significance. Do not use them to identify anything other than text and tables.\n\n\n\nDefault field labels\n\n Field Definition \n\n answer In a question-and-answer pair (often in an FAQ), the answer to the question. \n author Name of author or authors. \n footer Use this tag to denote meta-information about the document (such as the page number or references), that appear at the end of the page. \n header Use this tag to denote meta-information about the document that appears at the start of the page. \n question In a question-and-answer pair (often in an FAQ), the question. \n subtitle The secondary title of the document. \n table_of_contents Use this tag on lists in the document table of contents. \n text By default, every block of text in the document is labeled as text. Apply different labels only to blocks of text with special meaning. \n title The main title of the document. \n table Use this tag to annotate tables in your document. \n image Images are not shown in the document preview. If you enable OCR, text from an image or diagram is displayed in the preview instead. If you want to prevent text from some images from being included in search results, tag the image text as an image. You can exclude the image field from the index later. \n\n\n\n\n\n\n\n Reusing SDU models \n\nAfter you define a model with the SDU tool, you can save it and reuse it in other collections by exporting it from one collection and importing it to another.\n\nTo reuse a model, complete the following steps:\n\n\n\n1. Export the model that you want to reuse. From the SDU toolbar menu, select Export model.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-configuring-fields"},{"document_id":"ibmcld_07224-7650-9752","score":24.9406429697,"text":"\nRe-upload the documents in your collection. After uploading is complete, you are redirected to the Overview screen.\n\n\n\n\n\nDefault field labels\n\n Field Definition \n\n answer In a Q\/A pair (often in an FAQ), the answer to the question. \n author Name of author (or authors). \n footer Use this tag to denote meta-information about the document (such as the page number or references), that appear at the bottom of the \n header Use this tag to denote meta-information about the document that appears at the top of the page. \n question In a Q\/A pair (often in an FAQ), the question. \n subtitle The secondary title of the document being annotated. \n table_of_contents Use this tag on listings in the document table of contents. \n text Use this tag for standard copy text, including paragraphs, definitions, or any set of words that is not a title, part of a table, answer, author, subtitle, header, or a footer. \n title The main title of the document being annotated. \n table Use this tag to annotate tables in your document. \n image Use this tag to annotate images and diagrams in your document. \n\n\n\n\n\n\n\n Splitting documents \n\nThe Manage fields tab contains the option to Improve query results by splitting your documents. This option allows you to split your documents into segments based on a field name. After the document splits, each segment is a separate document that is enriched, indexed, and returned as a separate query result.\n\nDocuments are split based on a single field name, for example: title, author, question.\n\nConsiderations:\n\n\n\n* The number of segments per document is limited to 250. Any document content remaining after 249 segments are stored within segment 250.\n* Each segment counts towards the document limit of your plan. Discovery indexes segments, until the plan limit is reached. For document limits, see [Discovery pricing plans](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans).\n* PDF and Word metadata, as well as any custom metadata, is extracted and included in the index with each segment. Every segment of a document includes identical metadata.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu"},{"document_id":"ibmcld_02361-22962-24900","score":22.7845707871,"text":"\nIn the UI, you can define custom views, dashboards, parsing templates, screens, and exclusion rules that you can use to view and analyze data.\n\nTo reuse resource definitions that you define in your auditing instance, you can export these resources from an IBM Cloud Activity Tracker instance as a JSON file. Then, you can import the definitions into other auditing instances. For example, you can reuse your resources across different environments for your stage, pre-production, and production instances. [Learn more](https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-reuse_resource_definitions).\n\nBackup resource definitions into a version control system such as a git repository where you can control access to the archived files and manage versions.\n\n\n\n\n\n Archive log data to a COS bucket \n\nEnable archiving of your data from an auditing instance to an IBM Cloud Object Storage (COS) bucket.\n\nAfter you provision an auditing instance, you can configure archiving to an IBM Cloud Object Storage (COS) bucket. You can create different types of buckets based on your requirements.\n\nWhen you plan the bucket for an auditing instance, consider the following information:\n\n\n\nTable 5. COS bucket requirements\n\n Requirement Question to answer Information \n\n Type of workload [1] How often do you need to access the data? [Information about storage classes](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-classesclasses-about) \n Retention policy [2] Do you need to protect data from being deleted? [Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_07098-1507-3651","score":22.3202810997,"text":"\nWhen the answer-finding feature is enabled, Discovery also provides a \"short answer\" within the passage, and a confidence score to show whether the \"short answer\" answers the question that is explicit or implicit in the user query. Applications that use the answer-finding feature can display the short answer alone or can display the short answer emphasized in the context of the full passage. For most applications, displaying the short answer emphasized within the full passage is preferable, because answers generally make more sense in context.\n\nThe answer finding feature behaves in the following ways:\n\nIn the passage examples that follow, the short answers are shown in bold font.\n\n\n\n* Finds answers. It doesn\u2019t create answers. The answer must be part of the text; it can't be inferred.\n\n\u201cWhat was IBM\u2019s revenue in 2022?\u201d can get a correct answer if you have a document that states what IBM\u2019s revenue was in 2022. However, if you have a document that lists what IBM\u2019s revenue was in each quarter of 2022, it doesn't add them up and give you a total.\n* Handles synonyms and lexical variations if the answer is available.\n\n\n\n* Example question: \u201cWhen did IBM purchase Red Hat?\u201d\n* Passage: \u201cIBM closed its $34 billion acquisition of Red Hat in July of 2019.\"\n\n\n\n* Combines information across multiple sentences if they are close together (within approximately 2,000 characters).\n\n\n\n* Example question: \u201cWhen did IBM purchase Red Hat?\u201d\n* Passage: \u201cIBM acquired Red Hat for $34 billion. The deal closed in July of 2019.\"\n\n\n\n* Handles implicit questions similar to the way it would handle the equivalent explicit question.\n\nExample questions:\n\n\n\n* company that developed the AS\/400\n* What company developed the AS\/400?\n\n\n\n* Works well with questions with longer phrase or clause answers.\n\n\n\n* Example question: How do I flip a pancake?\n* Passage: The key to getting a world-class pancake is flipping it properly. The best way to flip a pancake is to stick a spatula under it, lift it at least 4 inches in the air, and quickly rotate the spatula 180 degrees.\n\n\n\n* Many how or why questions are only fully answered by much longer spans of text.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"},{"document_id":"ibmcld_06981-10904-13027","score":22.0428566631,"text":"\nContinue annotating documents until Watson can correctly and consistently map different types of content to the appropriate fields for you.\n8. After you teach Watson to identify fields, click Apply changes and reprocess.\n\n\n\nCustom fields that you define by using the SDU tool are indexed as root-level fields.\n\n\n\n What to do next \n\nWhen you build a user-trained model, you change where information is stored in your documents. Next, change how the search results are configured. By default, search results are retrieved from passages or the text field. You might have a better field to use as the source of the result body. For more information, see [Changing the result content](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-resultsquery-results-content).\n\nIf your project is being used by a virtual assistant, update the search skill configuration to pull the answer body from a different field. For more information, see [Configure the search](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-addskill-search-add-configure).\n\nYou can apply enrichments, either custom or prebuilt enrichments, to the new root fields that are generated by the SDU model.\n\nIf you want to return shorter text snippet with a search result, you can split your documents based on one of the new fields that you defined, such as chapter or section.\n\n\n\n\n\n Available fields \n\nThe following fields are available for you to apply to documents by using the Smart Document Understanding tool.\n\nThe fields are arbitrary. You can apply the image field to every title in the document if you want. Although, it might be difficult to know which field to search later for information that you need if the field names don't match the content. The default set are representative field types that are meant to help you get started. Only the text and table fields have special significance. Do not use them to identify anything other than text and tables.\n\n\n\nDefault field labels\n\n Field Definition \n\n answer In a question-and-answer pair (often in an FAQ), the answer to the question. \n author Name of author or authors.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-configuring-fields"},{"document_id":"ibmcld_09755-1450-3171","score":21.709971531,"text":"\nThe Stack Overflow forum, for technical questions, and the IBM Developer Answers forum, for general questions, both provide a wide variety of searchable answers to your IBM Cloud questions.\n\nIf you don't find an existing answer to a question, ask a new one.\n\nYou can access Stack Overflow and IBM Developer Answers from the Support Center, or use the following links:\n\n\n\n* Go to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud) to ask technical questions about the IBM Cloud Monitoring service.\n* Go to [IBM Developer Answers](https:\/\/developer.ibm.com\/answers\/topics\/ibm-cloud\/) to ask general questions about the IBM Cloud Monitoring service and about getting started instructions.\n\n\n\nTag your questions with ibm-cloud and monitoring.\n\nIBM Cloud development and support teams actively monitor Stack Overflow and IBM Developer Answers, and follow the questions that are tagged with ibm-cloud. When you create a question in either forum, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.\n\n\n\n\n\n Opening a support case \n\nIf you don't find answers to your questions, and you experience problems with IBM Cloud, you can use support cases to get help with technical, account and access, billing and invoice or sales inquiry issues.\n\nYou can [create](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case) and [manage](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-managing-support-cases) a support case by using the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). After you submit a support case, the support team works to investigate and resolve the issue depending on your type of support plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-gettinghelp"},{"document_id":"ibmcld_16692-1490-3300","score":21.6096307412,"text":"\nThe Stack Overflow forum, for technical questions, and the IBM Developer Answers forum, for general questions, both provide a wide variety of searchable answers to your IBM Cloud questions.\n\nIf you don't find an existing answer to a question, ask a new one.\n\nYou can access Stack Overflow and IBM Developer Answers from the Support Center, or use the following links:\n\n\n\n* Go to [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud) to ask technical questions about the IBM Cloud Security and Compliance Center Workload Protection service.\n* Go to [IBM Developer Answers](https:\/\/developer.ibm.com\/answers\/topics\/ibm-cloud\/) to ask general questions about the IBM Cloud Security and Compliance Center Workload Protection service and about getting started instructions.\n\n\n\nTag your questions with ibm-cloud and workload-protection.\n\nIBM Cloud development and support teams actively monitor Stack Overflow and IBM Developer Answers, and follow the questions that are tagged with ibm-cloud. When you create a question in either forum, add the ibm-cloud tag to your question to ensure that it's seen by the IBM Cloud development and support teams.\n\n\n\n\n\n Opening a support case \n\nIf you don't find answers to your questions, and you experience problems with IBM Cloud, you can use support cases to get help with technical, account and access, billing and invoice or sales inquiry issues.\n\nYou can [create](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case) and [manage](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-managing-support-cases) a support case by using the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). After you submit a support case, the support team works to investigate and resolve the issue depending on your type of support plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-gettinghelp"},{"document_id":"ibmcld_07120-23998-25469","score":21.5250834041,"text":"\n![Shows responses that are returned to answer the question about muni bonds.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-sdu-muni-responses.png)\n\nFigure 28. Responses that answer the question about muni bonds\n\nClick the View passage in document link to see the full definition highlighted in the document.\n\nTransactions in municipal bonds must be reported to the Municipal Securities Rulemaking Board\u2019s (MSRB) Real-time Transaction Reporting System (RTRS).\n\n\n\nCongratulations! You successfully added a user-trained Smart Document Understanding (SDU) model that improves the quality of your search project.\n\n\n\n\n\n Step 9: Filter results with a dictionary-based facet \n\nNow that we are getting more passages returned per query, it might be useful to filter the results. To filter the results based on the types of financial instruments that are mentioned, we can add a search facet. One available source for a facet is a dictionary.\n\n\n\n1. To create a dictionary, from the Improvement tools panel of the Improve and customize page, expand Teach domain concepts, and then click Dictionaries.\n\nZoom\n\n![Shows the Dictionaries option from the Teach domain concepts tool panel.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/tut-sdu-dictionary.png)\n\nFigure 29. Dictionaries tool\n2. Click New.\n\nZoom\n\n![Shows the New button in the dictionary page.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-tutorial-sdu"},{"document_id":"ibmcld_07098-3231-5441","score":21.5217949574,"text":"\n* Works well with questions with longer phrase or clause answers.\n\n\n\n* Example question: How do I flip a pancake?\n* Passage: The key to getting a world-class pancake is flipping it properly. The best way to flip a pancake is to stick a spatula under it, lift it at least 4 inches in the air, and quickly rotate the spatula 180 degrees.\n\n\n\n* Many how or why questions are only fully answered by much longer spans of text. The answer-finding feature does not return a whole document as the answer (and it doesn't summarize a document length answer).\n* Handles yes or no questions that are factual and have a concise answer in the text\n\n\n\n* Example question: Is there a library in Timbuktu\n* Passage: Timbuktu's main library, officially called the Ahmed Baba Institute of Higher Islamic Studies and Research, is a treasure house that contains more than 20,000 manuscripts that cover centuries of Mali's history.\n\n\n\n* Handles questions with very short answers, such as names and dates, especially when the type of answer that is required is explicit in the text.\n* Handles opinion questions, but only by finding a statement of that opinion; it does not assess the validity of the opinion.\n\n\n\n* Example question: Should I try blue eyeshadow?\n* Passage: We think blue eye shadow is trending this year.\n\n\n\n\n\n\n\n How the answer-finding feature works \n\nAfter a user submits a query, the query is analyzed by the Discovery service. Query analysis transforms the user's original query in ways that improve the chances of finding the best search results. For example, it lemmatizing words, removes stop words, and adds query expansions. The search is performed and the resulting documents and passages are returned.\n\nAnswer finding is applied to the returned passages. Up to 60 passages are sent to the answer-finding service. How these 60 passages are chosen differs based on the passages.per_document parameter value.\n\n\n\n* If passages.per_document is false, the top 60 passages from all of the documents that are returned by search are chosen based on their passage scores only.\n* If passages.per_document is true, the returned documents are ranked first, and then the top 60 passages from these top documents are chosen.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-1672-3877","score":34.3938475987,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":31.9334177865,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":26.2964119089,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04146-1603-3385","score":22.5998865308,"text":"\nhttp.request.method String POST The HTTP method, in upper case \n http.request.uri String \/articles\/index?section=539061&expand=comments The absolute URI of the request \n http.request.uri.path String \/articles\/index The path of the request \n http.request.uri.query String section=539061&expand=comments The whole query string, minus the delimiting prefix \"?\" \n http.user_agent String Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/65.0.3325.181 Safari\/537.36 The whole HTTP user agent \n http.x_forwarded_for String The full X-Forwarded-For HTTP header \n ip.src IP address 93.155.208.22 The client TCP IP address, which can be adjusted to reflect the real client IP of the original client as applicable (for example, using HTTP headers like X-Forwarded-For or X-Real-IP) \n ip.geoip.asnum Number 222 The [Autonomous System](https:\/\/ibm.biz\/BdzqdD) (AS) number \n ip.geoip.country String GB The [2-letter country code](https:\/\/www.iso.org\/obp\/ui\/search\/code\/) \n ssl Boolean true Whether the HTTP connection to the client is encrypted \n\n\n\nThese standard fields follow the naming convention of the Wireshark display field reference. However, some subtle variations might exist in the preceding example values.\n\nIn addition to the standard fields, the following Cloudflare-defined fields are also available:\n\n\n\nTable 2. Available Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04146-2946-5057","score":22.5998865308,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04111-35313-36062","score":20.2212606136,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04105-5067-6335","score":19.8041391078,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04111-34153-35639","score":18.529220488,"text":"\nGET \/v1\/{crn}\/zones\/{domain_id}\/setting\/origin_error_page_pass_thru internet-svcs.zones.update internet-svcs.origin-error-page-pass-thru-setting.update \n Get brotli compression settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.read internet-svcs.brotli-setting.read \n Update brotli compression settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.update internet-svcs.brotli-setting.update \n Get Email obfuscation settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.read internet-svcs.email-obfuscation-setting.read \n Update Email obfuscation settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.update internet-svcs.email-obfuscation-setting.update \n Get ciphers settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.read internet-svcs.ciphers-setting.read \n Update ciphers settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.update internet-svcs.ciphers-setting.update \n\n\n\n\n\n\n\n Bot Management \n\n\n\nTable 22. Bot Management\n\n Action Method IAM ACTION AT ACTION \n\n Get Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_16286-1338-3308","score":18.0657647324,"text":"\nClick Next to begin app registration.\n\n\n\n\n\n App registration \n\n\n\n1. Go to the [Microsoft Azure portal](https:\/\/portal.azure.com\/), and log in with your admin credentials.\n2. On the App registrations page, click New registration.\n3. On the Register an application page, enter a name, select the multi-tenant option that applies to your app, and then click Register.\n4. Copy the application ID from the Overview page of your app, and paste it into the App registration field of your Watson Assistant Microsoft Teams integration.\n5. On the same Microsoft Azure Overview page, click the hyperlink Add a certificate or secret next to Client Credentials.\n6. On the Certificates & secrets page for token creation, click New client secret. Enter a description and then select Recommended 180 days. Click Add.\n7. Copy the string under Value and paste into Client secret value on the App registration page of your Watson Assistant Microsoft Teams integration. Note: You must generate a new value before the current one expires on day 180.\n8. Click Next to create your bot.\n\n\n\n\n\n\n\n Create your bot \n\n\n\n1. Go to the [Microsoft Bot Framework developer portal](https:\/\/dev.botframework.com\/bots\/new), and log in with your admin credentials.\n2. On the Tell us about your bot page, complete your bot profile.\n3. Copy the generated endpoint from the Create your bot page of your Watson Assistant Microsoft Teams integration and paste into the Messaging endpoint field of the Configuration section.\n4. Select Multi-Tenant as the app type.\n5. Copy and paste your app ID, and then click Register.\n6. On the Connect to channels page, click Configure Microsoft Teams channel in the Add a featured channel section.\n7. On the Configure Microsoft Teams page, specify options in the Messaging, Calling, and Publish tabs that fit your bot needs, and then click Save.\n8. In your Watson Assistant Microsoft Teams integration, click Next to create your Teams app.\n\n\n\n\n\n\n\n Create your Teams app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-microsoft-teams"},{"document_id":"ibmcld_04170-7-2189","score":18.0448624371,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04170-7-2189","score":34.7024339255,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04105-5067-6335","score":33.5706396591,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":33.0579998533,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04168-6066-7283","score":30.186406307,"text":"\n* [Querying Edge Functions metrics with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_events)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_04172-7-2047","score":26.9914171482,"text":"\nAccessing log fields \n\nIf fields are not specified in the request, a limited set of default fields are returned. Find the full list of all available fields using the following request.\n\nibmcloud cis logpull DNS_DOMAIN_ID --available-fields\n\nFields are passed as a comma-separated list. For example, to have \"ZoneID\" and \"RayID\", use:\n\nibmcloud cis logpull DNS_DOMAIN_ID --start 2019-01-02T01:00:00+00:00 --end 2019-01-02T01:00:00+00:00 --fields ZoneId,RayID\n\n\n\n Available Fields \n\nThe following tables describe the fields available by log category.\n\n\n\n HTTP requests \n\nThis table contains the fields available for HTTP requests.\n\n\n\nTable 1. HTTP events\n\n Field Value Type \n\n BotScore Cloudflare Bot Score (available for Bot Management customers; please contact your account team to enable) int \n BotScoreSrc Underlying detection engine or source on where a Bot Score is calculated. Possible values are Not ComputedHeuristicsMachine LearningBehavioral AnalysisVerified Bot string \n CacheCacheStatus unknownmissexpiredupdatingstalehitignoredbypassrevalidated string \n CacheResponseBytes Number of bytes returned by the cache int \n CacheResponseStatus HTTP status code returned by the cache to the edge; all requests (including non-cacheable ones) go through the cache; also see CacheStatus field int \n CacheTieredFill Tiered Cache was used to serve this request bool \n ClientASN Client AS number int \n ClientCountry Country of the client IP address string \n ClientDeviceType Client device type string \n ClientIP IP address of the client string \n ClientIPClass unknowncleanbadHostsearchEnginewhitelistgreylistmonitoringServicesecurityScannernoRecordscanbackupServicemobilePlatformtor string \n ClientRequestBytes Number of bytes in the client request int \n ClientRequestHost Host requested by the client string \n ClientRequestMethod HTTP method of client request string \n ClientRequestPath URI path requested by the client string \n ClientRequestProtocol HTTP protocol of client request string \n ClientRequestReferer HTTP request referrer string","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-log-fields"},{"document_id":"ibmcld_04105-1672-3877","score":26.4565980515,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04175-0-1274","score":26.0286218541,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_16286-2915-4657","score":25.7544133449,"text":"\n6. On the Connect to channels page, click Configure Microsoft Teams channel in the Add a featured channel section.\n7. On the Configure Microsoft Teams page, specify options in the Messaging, Calling, and Publish tabs that fit your bot needs, and then click Save.\n8. In your Watson Assistant Microsoft Teams integration, click Next to create your Teams app.\n\n\n\n\n\n\n\n Create your Teams app \n\n\n\n1. Go to the [Microsoft Teams Developer Portal](https:\/\/dev.teams.microsoft.com\/home), and log in with your admin credentials.\n2. On the Apps tab, click New App.\n3. Enter a name, and click Add.\n4. On the Basic information page, enter app names, app ID, descriptions, developer information, and app URLs, and then copy and paste your app ID into Application (client) ID. Click Save.\n5. In the Configure section, select App features, and then Bot.\n6. On the Identify your bot page, select your bot.\n7. In the Select the scope in which people can use this command section, select Personal, Team, and Group Chat.\n8. Click Save, but keep the window open.\n9. In your Watson Assistant Microsoft Teams integration, click Finish.\n10. Click Publish to publish your bot.\n\n\n\n\n\n\n\n\n\n Publishing your Teams app \n\n\n\n1. In the Microsoft Teams Developer Portal window where you created and saved your Teams app, click Publish to publish your bot.\n2. Click Download the app package.\n3. Go to [Microsoft Teams](https:\/\/teams.microsoft.com), and log in with your admin credentials.\n4. Click Apps in the sidebar menu, and then click Manage your apps and Upload an app.\n5. Select Upload a custom app and specify the app package .zip file you downloaded.\n6. Click Add to finish.\n7. Test your actions and responses in the Chat section of your Teams app.\n\n\n\n\n\n\n\n Response types","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-microsoft-teams"},{"document_id":"ibmcld_04105-7-2225","score":25.5380828012,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_16286-1338-3308","score":25.3360094349,"text":"\nClick Next to begin app registration.\n\n\n\n\n\n App registration \n\n\n\n1. Go to the [Microsoft Azure portal](https:\/\/portal.azure.com\/), and log in with your admin credentials.\n2. On the App registrations page, click New registration.\n3. On the Register an application page, enter a name, select the multi-tenant option that applies to your app, and then click Register.\n4. Copy the application ID from the Overview page of your app, and paste it into the App registration field of your Watson Assistant Microsoft Teams integration.\n5. On the same Microsoft Azure Overview page, click the hyperlink Add a certificate or secret next to Client Credentials.\n6. On the Certificates & secrets page for token creation, click New client secret. Enter a description and then select Recommended 180 days. Click Add.\n7. Copy the string under Value and paste into Client secret value on the App registration page of your Watson Assistant Microsoft Teams integration. Note: You must generate a new value before the current one expires on day 180.\n8. Click Next to create your bot.\n\n\n\n\n\n\n\n Create your bot \n\n\n\n1. Go to the [Microsoft Bot Framework developer portal](https:\/\/dev.botframework.com\/bots\/new), and log in with your admin credentials.\n2. On the Tell us about your bot page, complete your bot profile.\n3. Copy the generated endpoint from the Create your bot page of your Watson Assistant Microsoft Teams integration and paste into the Messaging endpoint field of the Configuration section.\n4. Select Multi-Tenant as the app type.\n5. Copy and paste your app ID, and then click Register.\n6. On the Connect to channels page, click Configure Microsoft Teams channel in the Add a featured channel section.\n7. On the Configure Microsoft Teams page, specify options in the Messaging, Calling, and Publish tabs that fit your bot needs, and then click Save.\n8. In your Watson Assistant Microsoft Teams integration, click Next to create your Teams app.\n\n\n\n\n\n\n\n Create your Teams app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-microsoft-teams"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-5067-6335","score":28.9678390952,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":28.8842547425,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":28.843405509,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04168-6066-7283","score":26.4910576684,"text":"\n* [Querying Edge Functions metrics with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_events)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_04172-7-2047","score":23.037430655,"text":"\nAccessing log fields \n\nIf fields are not specified in the request, a limited set of default fields are returned. Find the full list of all available fields using the following request.\n\nibmcloud cis logpull DNS_DOMAIN_ID --available-fields\n\nFields are passed as a comma-separated list. For example, to have \"ZoneID\" and \"RayID\", use:\n\nibmcloud cis logpull DNS_DOMAIN_ID --start 2019-01-02T01:00:00+00:00 --end 2019-01-02T01:00:00+00:00 --fields ZoneId,RayID\n\n\n\n Available Fields \n\nThe following tables describe the fields available by log category.\n\n\n\n HTTP requests \n\nThis table contains the fields available for HTTP requests.\n\n\n\nTable 1. HTTP events\n\n Field Value Type \n\n BotScore Cloudflare Bot Score (available for Bot Management customers; please contact your account team to enable) int \n BotScoreSrc Underlying detection engine or source on where a Bot Score is calculated. Possible values are Not ComputedHeuristicsMachine LearningBehavioral AnalysisVerified Bot string \n CacheCacheStatus unknownmissexpiredupdatingstalehitignoredbypassrevalidated string \n CacheResponseBytes Number of bytes returned by the cache int \n CacheResponseStatus HTTP status code returned by the cache to the edge; all requests (including non-cacheable ones) go through the cache; also see CacheStatus field int \n CacheTieredFill Tiered Cache was used to serve this request bool \n ClientASN Client AS number int \n ClientCountry Country of the client IP address string \n ClientDeviceType Client device type string \n ClientIP IP address of the client string \n ClientIPClass unknowncleanbadHostsearchEnginewhitelistgreylistmonitoringServicesecurityScannernoRecordscanbackupServicemobilePlatformtor string \n ClientRequestBytes Number of bytes in the client request int \n ClientRequestHost Host requested by the client string \n ClientRequestMethod HTTP method of client request string \n ClientRequestPath URI path requested by the client string \n ClientRequestProtocol HTTP protocol of client request string \n ClientRequestReferer HTTP request referrer string","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-log-fields"},{"document_id":"ibmcld_04175-0-1274","score":22.3551043612,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04105-7-2225","score":22.2655463125,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04111-35313-36062","score":22.071561682,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04118-5438-6061","score":21.9496226824,"text":"\nAdvanced rate limiting No No Yes Yes Yes \n Bot management No No No Yes No \n\n\n\n\n\n Deprecated plans \n\nThe following plans are scheduled for deprecation or deprecated.\n\n\n\n* The Standard plan reached the end of marketing on 30 April 2023. End of support is not yet determined.\n* Enterprise Package, Enterprise GLB, and Enterprise Security plans will reach the end of marketing on 31 August, 2023. End of support is not yet determined.\n\n\n\nFor more information about changing to a new plan if you are currently on a deprecated plan, see [Transitioning to updated plans](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transition-plans).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-plan-comparison"},{"document_id":"ibmcld_04105-1672-3877","score":21.7140796081,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04175-0-1274","score":23.2052556097,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_05455-2559-3773","score":20.5031659793,"text":"\nRay [Ray](https:\/\/www.ray.io\/) is an open technology that enables data scientists and application developers to run their code in a distributed fashion. It also provides a lean and easy interface for distributed programming with many different libraries, best suited to perform machine learning and other intensive compute tasks. See [Ray on IBM Cloud Code Engine: Boost Your Serverless Compute](https:\/\/www.ibm.com\/cloud\/blog\/ray-on-ibm-cloud-code-engine). \n Iter8 [Iter8](https:\/\/iter8.tools) is the release engineering tool for Kubernetes that enables SLO validation, A\/B testing, and progressive rollouts for Kubernetes applications. You can use Iter8 to validate your Code Engine applications. See [Validating your application code and latency with Iter8](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-slovalidationtut). \n Guard [Guard](https:\/\/pkg.go.dev\/knative.dev\/security-guardsection-readme) is a workload runtime-security solution, well-equipped to protect Serverless Services. Code Engine users may use Guard as a security layer to protect Code Engine applications. See [Securing your application with Guard](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-getting-started-with-guard).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-supported-integrations"},{"document_id":"ibmcld_04105-5067-6335","score":18.0074761704,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_05455-1282-3016","score":17.6416729503,"text":"\nFor more information, see [Working with the IBM Cloud Object Storage event producer](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-eventing-cosevent-producer). \n IBM\u00ae Event Streams for IBM Cloud\u00ae Subscribe to Kafka and Event Streams event producers from your application or job. For more information, see [Working with the Kafka event producer](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-working-kafkaevent-producer). \n IBM Cloud Continuous Delivery Automate your app and job builds by using a toolchain. For more information about the setup, see [Integrating Code Engine workloads with Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-toolchain-ce). \n\n\n\n\n\n\n\n Third-party integrations \n\nCode Engine is supported by the following third-party integrations. For issues in open source projects that are used by IBM Cloud, see the [IBM open source and third-party policy](https:\/\/www.ibm.com\/support\/pages\/node\/737271).\n\n\n\nTable 2. Third-party integrations\n\n Integration Description \n\n Lithops [Lithops](https:\/\/lithops-cloud.github.io\/) is an open source framework that designed to massively scale your Python applications. See [Running jobs with Lithops framework](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-lithops). \n Ray [Ray](https:\/\/www.ray.io\/) is an open technology that enables data scientists and application developers to run their code in a distributed fashion. It also provides a lean and easy interface for distributed programming with many different libraries, best suited to perform machine learning and other intensive compute tasks. See [Ray on IBM Cloud Code Engine: Boost Your Serverless Compute](https:\/\/www.ibm.com\/cloud\/blog\/ray-on-ibm-cloud-code-engine).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-supported-integrations"},{"document_id":"ibmcld_16445-4-1979","score":17.0487550547,"text":"\n{{{site.data.keyword.attribute-definition-list}}\n\n\n\n Using the machine learning model \n\nLeverage a machine learning model that you trained with Knowledge Studio for IBM Cloud Pak for Data by making it available to other Watson applications.\n\nYou can deploy or export a machine learning model. A dictionary can only be used to pre-annotate documents within Knowledge Studio.\n\nYou can also pre-annotate new documents with the machine learning model. See [Pre-annotating documents with the machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannotsire) for details.\n\n\n\n Exporting a machine learning model \n\nTo export a machine learning model as a .zip file, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Versions.\n3. Choose the version of the model that you want to export, or select Export current model.\n\nIf there is only one working version of the model, create a snapshot of the current model. This versions the model, which enables you to deploy one version, while you continue to improve the current version. The option to deploy does not appear until you create at least one version.\n4. Click Export, and then click Export again to confirm.\n\n\n\n\n\n\n\n Deploying a machine learning model to IBM Watson Discovery for IBM Cloud Pak for Data \n\nWhen you are satisfied with the performance of the model, you can export a version to IBM Watson\u2122 Discovery for IBM Cloud Pak for Data. This feature enables your applications to use the deployed machine learning model to enrich the insights that you get from your data to include the recognition of entities and relations that are relevant to your domain.\n\n\n\n Before you begin \n\nYou must have administrative access to a [Discovery for IBM Cloud Pak for Data](https:\/\/cloud.ibm.com\/docs\/discovery-data) deployment.\n\n\n\n\n\n Procedure \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-publish-ml"},{"document_id":"ibmcld_04168-6066-7283","score":17.0201891563,"text":"\n* [Querying Edge Functions metrics with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_events)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-http-concepts"},{"document_id":"ibmcld_16511-3250-5366","score":16.9885572093,"text":"\nSelect Machine Learning Model > Versions.\n2. Click Export current model.\n\nIf you have a Lite plan subscription, no export option is available.\n\nThe model is saved as a ZIP file, and you are prompted to download the file.\n3. Download the file to your local system.\n4. From the Discovery service, follow the steps to create a Machine Learning enrichment, which include uploading the ZIP file. For more details, see [Machine Learning models](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domainmachinelearning) in the Discovery v2 documentation.\n\n\n\nIf you're using a Discovery v1 service instance, you must provide the model ID when it is requested during the Discovery service enrichment configuration process. For more information, see [Integrating your custom model with the Discovery tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-integrating-with-wksintegrate-customtooling) in the Discovery v1 documentation.\n\n\n\n\n\n\n\n Deploying a machine learning model to IBM Watson Natural Language Understanding \n\nWhen you are satisfied with the performance of the model, you can deploy a version of it to IBM Watson Natural Language Understanding. This feature enables your applications to use the deployed machine learning model to analyze semantic features of text input, including entities and relations.\n\n\n\n Before you begin \n\nYou must have a Natural Language Understanding service to deploy to. And you must know the IBM Cloud space and instance names that are associated with the service. If you do not remember the space or instance names, find them by logging in to IBM Cloud. If you do not have an IBM Cloud account, sign up for one.\n\n\n\n\n\n About this task \n\nWhen you deploy the machine learning model, you select the version of it that you want to deploy.\n\n\n\n\n\n Procedure \n\nTo deploy a machine learning model to the Natural Language Understanding service, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Versions.\n3. Choose the version of the model that you want to deploy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-ml"},{"document_id":"ibmcld_16511-7-2162","score":16.959004516,"text":"\nUsing the machine learning model \n\nLeverage a machine learning model that you trained with Knowledge Studio by making it available to other Watson applications.\n\nYou can deploy or export a machine learning model. A dictionary or Natural Language Understanding pre-annotator can only be used to pre-annotate documents within Knowledge Studio.\n\nBefore you can deploy a model for use by a service, you must have a subscription to the service. IBM Watson services are hosted on IBM Cloud\u00ae, which is the cloud platform for IBM. For more information about the platform, see [What is IBM Cloud?](https:\/\/cloud.ibm.com\/docs\/overview). To subscribe to one of the IBM Watson services, create an account from the [IBM Cloud](https:\/\/cloud.ibm.com\/) website.\n\nFor some of the services, you must know details about the service instance that you plan to deploy to, such as the IBM Cloud space name and service instance name. The space and instance name information is available from the IBM Cloud Services page.\n\nYou can also pre-annotate new documents with the machine learning model. See [Pre-annotating documents with the machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotsire) for details.\n\n\n\n Deploying a machine learning model to IBM Watson Discovery \n\nWhen you are satisfied with the performance of the model, you can deploy a version of it to IBM Watson Discovery. This feature enables your applications to use the deployed machine learning model to enrich the insights that you get from your data to include the recognition of concepts and relations that are relevant to your domain.\n\n\n\n About this task \n\nWhen you deploy the machine learning model, you select the version of it that you want to deploy.\n\n\n\n\n\n Procedure \n\nTo deploy a machine learning model, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Versions.\n3. Choose the version of the model that you want to deploy.\n\nIf there is only one working version of the model, create a snapshot of the current model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-ml"},{"document_id":"ibmcld_16445-1443-3501","score":16.826476563,"text":"\nWhen you are satisfied with the performance of the model, you can export a version to IBM Watson\u2122 Discovery for IBM Cloud Pak for Data. This feature enables your applications to use the deployed machine learning model to enrich the insights that you get from your data to include the recognition of entities and relations that are relevant to your domain.\n\n\n\n Before you begin \n\nYou must have administrative access to a [Discovery for IBM Cloud Pak for Data](https:\/\/cloud.ibm.com\/docs\/discovery-data) deployment.\n\n\n\n\n\n Procedure \n\n\n\n1. [Export a machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-publish-mlexporting-a-machine-learning-model).\n2. From the Discovery service, follow the steps to create a Machine Learning enrichment, which include uploading the ZIP file. For more details, see [Machine Learning models](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-domainmachinelearning) in the Discovery v2 documentation.\n\n\n\n\n\n\n\n\n\n Deploying a machine learning model to IBM Watson Natural Language Understanding for IBM Cloud Pak for Data \n\nWhen you are satisfied with the performance of the model, you can deploy a version of it to IBM Watson Natural Language Understanding. This feature enables your applications to use the deployed machine learning model to analyze custom entities and relations.\n\n\n\n Before you begin \n\nYou must have a [Natural Language Understanding for IBM Cloud Pak for Data](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding-data) deployment.\n\n\n\n\n\n Procedure \n\n\n\n1. [Export a machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-publish-mlexporting-a-machine-learning-model).\n2. Follow the [Customizing](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding-data?topic=natural-language-understanding-data-customizing) instructions in the Natural Language Understanding for IBM Cloud Pak for Data documentation to create an entities model with the .zip file that you downloaded.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-publish-ml"},{"document_id":"ibmcld_16511-10740-12806","score":16.6617754867,"text":"\nFrom the list of deployed models, find the model you want to view or undeploy.\n4. To undeploy the model, from the last column of that row, click Undeploy model.\n5. To find the model ID, see the Model ID column.\n\n\n\nAlternatively, you can undeploy models from the Versions pages for rule-based models and machine learning models.\n\n\n\n\n\n\n\n Deleting a version \n\nIf you wish to delete a specific version a same machine learning model, navigate to the Versions page and click the Delete link on the row of the version that you want to delete. Note: The Delete model version link is only active if there are no deployed models associated with it. Undeploy all associated models before deleting the a version.\n\n\n\n\n\n Leveraging a machine learning model in IBM Watson Explorer \n\nExport the trained machine learning model so it can be used in IBM Watson Explorer.\n\n\n\n Before you begin \n\nIf you choose to identify relation types and annotate them, then you must define at least two relation types, and annotate instances of the relationships in the ground truth before you export the model. Defining and annotating only one relation type can cause subsequent issues in IBM Watson Explorer, release 11.0.1.0.\n\n\n\n\n\n About this task \n\nNow that the machine learning model is trained to recognize entities and relationships for a specific domain, you can leverage it in IBM Watson Explorer.\n\n[Watch a brief video](https:\/\/www.youtube.com\/watch?v=1VoS-xczBow&feature=youtu.be) that illustrates how to export a model and use it in IBM Watson Explorer.\n\n\n\n\n\n Procedure \n\nTo leverage a machine learning model in IBM Watson Explorer, complete the following steps.\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Versions.\n3. Click Export current model.\n\nIf you have a Lite plan subscription, no export option is available.\n\nThe model is saved as a ZIP file, and you are prompted to download the file.\n4. Download the file to your local system.\n5. From the IBM Watson Explorer application, import the model.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-publish-ml"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-3403-5572","score":22.5705946377,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-5067-6335","score":21.7910852453,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":21.3414434478,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-1672-3877","score":21.1723228099,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04170-7-2189","score":21.0782331464,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04111-35313-36062","score":20.6819478184,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_04111-34153-35639","score":18.97857366,"text":"\nGET \/v1\/{crn}\/zones\/{domain_id}\/setting\/origin_error_page_pass_thru internet-svcs.zones.update internet-svcs.origin-error-page-pass-thru-setting.update \n Get brotli compression settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.read internet-svcs.brotli-setting.read \n Update brotli compression settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/brotli internet-svcs.performance.update internet-svcs.brotli-setting.update \n Get Email obfuscation settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.read internet-svcs.email-obfuscation-setting.read \n Update Email obfuscation settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/email_obfuscation internet-svcs.security.update internet-svcs.email-obfuscation-setting.update \n Get ciphers settings. GET \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.read internet-svcs.ciphers-setting.read \n Update ciphers settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/setting\/ciphers internet-svcs.security.update internet-svcs.ciphers-setting.update \n\n\n\n\n\n\n\n Bot Management \n\n\n\nTable 22. Bot Management\n\n Action Method IAM ACTION AT ACTION \n\n Get Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_16286-1338-3308","score":18.6971329894,"text":"\nClick Next to begin app registration.\n\n\n\n\n\n App registration \n\n\n\n1. Go to the [Microsoft Azure portal](https:\/\/portal.azure.com\/), and log in with your admin credentials.\n2. On the App registrations page, click New registration.\n3. On the Register an application page, enter a name, select the multi-tenant option that applies to your app, and then click Register.\n4. Copy the application ID from the Overview page of your app, and paste it into the App registration field of your Watson Assistant Microsoft Teams integration.\n5. On the same Microsoft Azure Overview page, click the hyperlink Add a certificate or secret next to Client Credentials.\n6. On the Certificates & secrets page for token creation, click New client secret. Enter a description and then select Recommended 180 days. Click Add.\n7. Copy the string under Value and paste into Client secret value on the App registration page of your Watson Assistant Microsoft Teams integration. Note: You must generate a new value before the current one expires on day 180.\n8. Click Next to create your bot.\n\n\n\n\n\n\n\n Create your bot \n\n\n\n1. Go to the [Microsoft Bot Framework developer portal](https:\/\/dev.botframework.com\/bots\/new), and log in with your admin credentials.\n2. On the Tell us about your bot page, complete your bot profile.\n3. Copy the generated endpoint from the Create your bot page of your Watson Assistant Microsoft Teams integration and paste into the Messaging endpoint field of the Configuration section.\n4. Select Multi-Tenant as the app type.\n5. Copy and paste your app ID, and then click Register.\n6. On the Connect to channels page, click Configure Microsoft Teams channel in the Add a featured channel section.\n7. On the Configure Microsoft Teams page, specify options in the Messaging, Calling, and Publish tabs that fit your bot needs, and then click Save.\n8. In your Watson Assistant Microsoft Teams integration, click Next to create your Teams app.\n\n\n\n\n\n\n\n Create your Teams app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-microsoft-teams"},{"document_id":"ibmcld_16286-2915-4657","score":18.5078045588,"text":"\n6. On the Connect to channels page, click Configure Microsoft Teams channel in the Add a featured channel section.\n7. On the Configure Microsoft Teams page, specify options in the Messaging, Calling, and Publish tabs that fit your bot needs, and then click Save.\n8. In your Watson Assistant Microsoft Teams integration, click Next to create your Teams app.\n\n\n\n\n\n\n\n Create your Teams app \n\n\n\n1. Go to the [Microsoft Teams Developer Portal](https:\/\/dev.teams.microsoft.com\/home), and log in with your admin credentials.\n2. On the Apps tab, click New App.\n3. Enter a name, and click Add.\n4. On the Basic information page, enter app names, app ID, descriptions, developer information, and app URLs, and then copy and paste your app ID into Application (client) ID. Click Save.\n5. In the Configure section, select App features, and then Bot.\n6. On the Identify your bot page, select your bot.\n7. In the Select the scope in which people can use this command section, select Personal, Team, and Group Chat.\n8. Click Save, but keep the window open.\n9. In your Watson Assistant Microsoft Teams integration, click Finish.\n10. Click Publish to publish your bot.\n\n\n\n\n\n\n\n\n\n Publishing your Teams app \n\n\n\n1. In the Microsoft Teams Developer Portal window where you created and saved your Teams app, click Publish to publish your bot.\n2. Click Download the app package.\n3. Go to [Microsoft Teams](https:\/\/teams.microsoft.com), and log in with your admin credentials.\n4. Click Apps in the sidebar menu, and then click Manage your apps and Upload an app.\n5. Select Upload a custom app and specify the app package .zip file you downloaded.\n6. Click Add to finish.\n7. Test your actions and responses in the Chat section of your Teams app.\n\n\n\n\n\n\n\n Response types","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-microsoft-teams"},{"document_id":"ibmcld_03164-1607-3518","score":18.2818188485,"text":"\nFor more information about it, read the [Slack blog post](https:\/\/medium.com\/slack-developer-blog\/more-precision-less-restrictions-a3550006f9c3) about it.\n8. Assign bot token scopes to your Slack app. At a minimum, apply the following scopes:\n\n\n\n* app_mentions:read\n* chat:write\n* im:history\n* im:read\n* im:write\n\n\n\n9. Click Install App to Workspace, and then allow the installation when prompted.\n\nIf you are editing scopes for an existing application, reinstall it.\n10. From the Slack settings App Home page, enable the Always Show My Bot As Online setting.\n11. Go to the OAuth and Permissions page in Slack, copy the Bot User OAuth Access Token.\n12. From the Watson Assistant Slack integration configuration page, paste the token that you copied in the previous step into both the OAuth access token and Bot user OAuth access token fields.\n13. On the Slack app settings page, go to the Basic Information page, and then find the App Credentials section. Copy the app credential verification token.\n14. From the Watson Assistant Slack integration configuration page, paste the verification token that you copied in the previous step into the Verification token field.\n15. Click Generate request URL, and then copy the generated request URL.\n16. Return to the Slack app settings page. Open the Event Subscriptions page, and then turn on Enable Events. Paste the request URL that you copied in the previous step into the field.\n17. On the Event Subscriptions page in Slack, find the Subscribe to Bot Events section. Click Add Bot User Event, and then select the event types you want to subscribe to. You must select at least one of the following types:\n\n\n\n* message.im: Listens for message events that are posted in a direct message channel.\n* app_mention: Listens for only message events that mention your app or bot.\n\nChoose the app_mention entry in normal font, not the app_mention entry that is in bold font.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-slack"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.4306765581,"ndcg_cut_10":0.4306765581}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16286-1338-3308","score":12.3088405435,"text":"\nClick Next to begin app registration.\n\n\n\n\n\n App registration \n\n\n\n1. Go to the [Microsoft Azure portal](https:\/\/portal.azure.com\/), and log in with your admin credentials.\n2. On the App registrations page, click New registration.\n3. On the Register an application page, enter a name, select the multi-tenant option that applies to your app, and then click Register.\n4. Copy the application ID from the Overview page of your app, and paste it into the App registration field of your Watson Assistant Microsoft Teams integration.\n5. On the same Microsoft Azure Overview page, click the hyperlink Add a certificate or secret next to Client Credentials.\n6. On the Certificates & secrets page for token creation, click New client secret. Enter a description and then select Recommended 180 days. Click Add.\n7. Copy the string under Value and paste into Client secret value on the App registration page of your Watson Assistant Microsoft Teams integration. Note: You must generate a new value before the current one expires on day 180.\n8. Click Next to create your bot.\n\n\n\n\n\n\n\n Create your bot \n\n\n\n1. Go to the [Microsoft Bot Framework developer portal](https:\/\/dev.botframework.com\/bots\/new), and log in with your admin credentials.\n2. On the Tell us about your bot page, complete your bot profile.\n3. Copy the generated endpoint from the Create your bot page of your Watson Assistant Microsoft Teams integration and paste into the Messaging endpoint field of the Configuration section.\n4. Select Multi-Tenant as the app type.\n5. Copy and paste your app ID, and then click Register.\n6. On the Connect to channels page, click Configure Microsoft Teams channel in the Add a featured channel section.\n7. On the Configure Microsoft Teams page, specify options in the Messaging, Calling, and Publish tabs that fit your bot needs, and then click Save.\n8. In your Watson Assistant Microsoft Teams integration, click Next to create your Teams app.\n\n\n\n\n\n\n\n Create your Teams app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-microsoft-teams"},{"document_id":"ibmcld_06832-5042-7090","score":12.180814252,"text":"\nThis format allows for greater flexibility because you can reference secrets from an Secrets Manager instance in a different account if the correct [authorization](https:\/\/cloud.ibm.com\/iam\/authorizations) is in place. For more information see [Configuring Secrets Manager](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager).\n\nThe secrets that are used in both CI and CD are outlined as follows:\n\nA Hint is a suggested default name that is automatically resolved against the first matching secret with the same name across any of the available by name secrets integrations that are bound to the toolchain.\n\n\n\n DevSecOps Pipeline Secrets \n\n\n\nTable 1. DevSecOps Secrets\n\n Secret Hint Information \n\n IBM Cloud API Key ibmcloud-api-key Required: CI & CDUsed to authenticate with IBM public cloud and perform a wide range of operations \n GPG Private Key signing_key Required: CI onlyThis is the certificate that is used to sign images built by the CI pipeline \n IBM Private Worker Service API Key private-worker-service-api-key Required: CI onlyA Service ID API Key Used to run delivery pipeline workloads on a Tekton Private Worker Service \n GitHub Access Token git-token Optional: CI & CDUsed to authenticate with GitHub and provide access to the repositories \n Artifactory API token artifactory-token Required: CI & CDUsed to access images used by pipeline tasks \n Slack Web Hook slack-webhook Optional: CI & CDThis webhook is required if you choose to use the Slack tool integration to post toolchain status notifications \n ServiceNow API Token servicenow-token Required: CD onlyUsed to access Service Now for change management operations \n HashiCorp Vault Role ID role-id Required: CI & CDUsed to authenticate with the HashiCorp Vault server \n HashiCorp Vault Secret ID secret-id Required: CI & CDUsed to authenticate with the HashiCorp Vault server \n IBM Cloud Object Storage Writer API Key cos-api-key Required: CI & CDUsed to authenticate with the Object Storage service - This key must have writer permission","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-toolchains-secrets"},{"document_id":"ibmcld_04105-5067-6335","score":12.1656663176,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_12469-46952-48500","score":11.6991372583,"text":"\n--type (string)\n: The type of configuration. Value options differ depending on the config_element property that you want to define. Required.\n\nAllowable values are: letsencrypt, letsencrypt-stage, cis, classic_infrastructure, root_certificate_authority, intermediate_certificate_authority, certificate_template. The maximum length is 128 characters. The minimum length is 2 characters.\n\n--config ([ConfigElementDefConfig](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-manager-cli-v1cli-config-element-def-config-example-schema-v1))\n: The configuration to define for the specified secret type. Required.\n\n\n\n\n\n Examples \n\nibmcloud secrets-manager config-element-create --secret-type=public_cert --config-element=certificate_authorities --name=cis-example-config --type=cis --config='{\"cis_crn\": \"crn:v1:bluemix:public:internet-svcs:global:a\/<account-id>:<service-instance>::\", \"cis_apikey\": \"cis_apikey_value\"}'\n\n\n\n\n\n\n\n ibmcloud secrets-manager config-elements \n\nList the configuration elements that are associated with a specified secret type.\n\nibmcloud secrets-manager config-elements --secret-type SECRET-TYPE --config-element CONFIG-ELEMENT\n\n\n\n Command options \n\n--secret-type (string)\n: The secret type. Required.\n\nAllowable values are: public_cert, private_cert.\n\n--config-element (string)\n: The configuration element to define or manage. Required.\n\nAllowable values are: certificate_authorities, dns_providers, root_certificate_authorities, intermediate_certificate_authorities, certificate_templates.\n\n\n\n\n\n Examples","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-manager-cli-v1"},{"document_id":"ibmcld_05342-7-2160","score":11.6156853376,"text":"\nWorking with secrets \n\nLearn how to work with secrets in Code Engine. In Code Engine, you can store your information as key-value pairs in secrets that can be consumed by your job or application by using environment variables.\n\n\n\n What are secrets and why would I use them? \n\nIn Code Engine, secrets (and configmaps) are a collection of key-value pairs. When mapped to environment variables, the NAME=VALUE relationships are set such that the name of the environment variable corresponds to the \"key\" of each entry in those maps, and the value of the environment variable is the \"value\" of that key.\n\nA secret provides a method to include sensitive configuration information, such as passwords or SSH keys, to your deployment. By referencing values from your secret, you can decouple sensitive information from your deployment to keep your app or job portable. Anyone who is authorized to your project can also view your secrets; be sure that you know that the secret information can be shared with those users. Secrets contain information in key-value pairs.\n\nBecause secrets and configmaps are similar entities (except secrets are stored more securely), the way you interact and work with secrets and configmaps is also similar. To learn more about configmaps, see [Working with configmaps](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-configmap).\n\n\n\n What kind of secrets can I create in Code Engine? \n\nCode Engine supports various secrets and provides options for creating and working with secrets.\n\nThe following table summarizes the supported secrets in Code Engine.\n\n\n\nTable 1. Secrets in Code Engine\n\n Name Description \n\n Basic authentication A secret that contains a username and password key. <br>Use basic authentication secrets when you access a service that requires basic HTTP authentication. \n Generic A secret that stores simple key-value pairs and Code Engine makes no assumptions about the defined key-value pairs nor about the intended use of the secret. <br>Use generic secrets when you want to define your own key-value pairs to access a service. \n Registry A secret that stores credentials to access a container registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-configmap-secret"},{"document_id":"ibmcld_05436-7-2160","score":11.6156853376,"text":"\nWorking with secrets \n\nLearn how to work with secrets in Code Engine. In Code Engine, you can store your information as key-value pairs in secrets that can be consumed by your job or application by using environment variables.\n\n\n\n What are secrets and why would I use them? \n\nIn Code Engine, secrets (and configmaps) are a collection of key-value pairs. When mapped to environment variables, the NAME=VALUE relationships are set such that the name of the environment variable corresponds to the \"key\" of each entry in those maps, and the value of the environment variable is the \"value\" of that key.\n\nA secret provides a method to include sensitive configuration information, such as passwords or SSH keys, to your deployment. By referencing values from your secret, you can decouple sensitive information from your deployment to keep your app or job portable. Anyone who is authorized to your project can also view your secrets; be sure that you know that the secret information can be shared with those users. Secrets contain information in key-value pairs.\n\nBecause secrets and configmaps are similar entities (except secrets are stored more securely), the way you interact and work with secrets and configmaps is also similar. To learn more about configmaps, see [Working with configmaps](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-configmap).\n\n\n\n What kind of secrets can I create in Code Engine? \n\nCode Engine supports various secrets and provides options for creating and working with secrets.\n\nThe following table summarizes the supported secrets in Code Engine.\n\n\n\nTable 1. Secrets in Code Engine\n\n Name Description \n\n Basic authentication A secret that contains a username and password key. <br>Use basic authentication secrets when you access a service that requires basic HTTP authentication. \n Generic A secret that stores simple key-value pairs and Code Engine makes no assumptions about the defined key-value pairs nor about the intended use of the secret. <br>Use generic secrets when you want to define your own key-value pairs to access a service. \n Registry A secret that stores credentials to access a container registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret"},{"document_id":"ibmcld_12492-87895-89178","score":11.5759313207,"text":"\n\"cis_crn\": \"crn:v1:bluemix:public:internet-svcs:global:a\/a5ebf2570dcaedf18d7ed78e216c263a:0f4c764e-dc3d-44d1-bd60-a2f7cd91e0c0::\"\n},\n\"name\": \"my-cis-instance\",\n\"type\": \"cis\"\n},\n\"wrap_info\": null,\n\"warnings\": null,\n\"auth\": null\n}\n\n\n\n\n\n\n\n Delete a configuration \n\nRemoves a configuration for a secrets engine that serves as the backend for a specific type of secret. You can delete configurations for the following secret types: public_cert, private_cert\n\n\n\n Example requests \n\nDelete a public certificate authority configuration.\n\ncurl -X DELETE 'https:\/\/https:\/\/{instance_id}.{region}.secrets-manager.appdomain.cloud\/v1\/ibmcloud\/public_cert\/config\/certificate_authorities\/my-lets-encrypt' -H 'X-Vault-Token: {Vault-Token}'\n\nDelete the DNS provider configuration.\n\ncurl -X DELETE 'https:\/\/https:\/\/{instance_id}.{region}.secrets-manager.appdomain.cloud\/v1\/ibmcloud\/public_cert\/config\/dns_providers\/my-cis-instance' -H 'X-Vault-Token: {Vault-Token}'\n\nDelete a private certificate authority configuration.\n\ncurl -X DELETE 'https:\/\/https:\/\/{instance_id}.{region}.secrets-manager.appdomain.cloud\/v1\/ibmcloud\/private_cert\/config\/root_certificate_authorities\/my-root-ca' -H 'X-Vault-Token: {Vault-Token}'\n\n\n\n\n\n Example response \n\nA successful request returns an HTTP 204 No Content response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-api"},{"document_id":"ibmcld_13877-25808-27295","score":11.5221984172,"text":"\nsecure-file-storage.example.com-account-info.json secure-file-storage.example.com-private-key.pem\nShow more\n\n\n\n2. Connect the Let's Encrypt ACME account to the Secrets Manager instance. See [Adding a certificate authority configuration in the UI](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-add-certificate-authority&interface=uiadd-certificate-authority-ui) for more details:\n\n\n\n1. Open the Secrets Managerservice instance, you can find it in the [Resource List](https:\/\/cloud.ibm.com\/resources).\n2. Open Secrets engines on the left and click Public certificates.\n3. Under Certificate authorities click Add.\n4. Name: LetsEncrypt and Certificate authority: Let's Encrypt.\n5. For the Private key under Select file click Add file and choose the secure-file-storage.example.com-private-key.pem or your existing .pem file from the chooser.\n6. Click Add.\n\n\n\n3. Connect the CIS as a DNS provider:\n\n\n\n1. Under DNS providers click Add.\n2. Name cis and choose Cloud Internet Services from the dropdown.\n3. Click Next.\n4. In the Authorization tab choose the CIS instance.\n5. Click Add.\n\n\n\n4. Add the TLS certificate secret to Secrets Manager:\n\n\n\n1. Click the Secrets tab on the left.\n2. Click Add.\n3. Click TLS certificates.\n4. Click Order a public certificate.\n5. Name secure-file-storage.example.com.\n6. Certificate authority: LetsEncrypt created earlier.\n7. Key algorithm: RSA2048.\n8. DNS provider: cis created earlier.\n9. Select domains .\n10. Open the cis example.com.\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-cloud-e2e-security"},{"document_id":"ibmcld_05339-3697-5345","score":11.2293118187,"text":"\nTo create a secret to access a service with an SSH key, such as to authenticate to a Git repository like GitHub or GitLab, use the [ibmcloud ce secret create --format ssh](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-secret-create) command. An SSH secret is also used as a Git repository access secret. To learn more about working with secrets in Code Engine, see [Working with secrets](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret).\n\nAn SSH secret contains the credentials to access the private repository that contains the source code to build your container image. An SSH secret is also used as a Git repository access secret.\n\nTo create an SSH secret with the CLI, use the secret create --format ssh command. This command requires a name and a key path, and also allows other optional arguments such as the path to the known hosts file. For a complete listing of options, see the [ibmcloud ce secret create --format ssh](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-secret-create) command.\n\nFor example, the following command creates an SSH secret that is called myrepossh to a repository at github.com that uses your personal SSH private key that is found at the default location on your system.\n\nMac OS or Linux\u00ae\n\nibmcloud ce secret create --format ssh --name myrepossh --key-path $HOME\/.ssh\/id_rsa --known-hosts-path $HOME\/.ssh\/known_hosts\n\nWindows\n\nibmcloud ce secret create --format ssh --name myrepossh --key-path \"%HOMEPATH%.sshid_rsa\" --known-hosts-path \"%HOMEPATH%.sshknown_hosts\"\n\nThe following table summarizes the options that are used with the repo create command in this example.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-code-repositories"},{"document_id":"ibmcld_12492-86346-87418","score":11.0005108173,"text":"\n\"issuing_certificates_urls_encoded\": true,\n\"key_bits\": 2048,\n\"key_type\": \"rsa\",\n\"locality\": [],\n\"max_path_length\": -1,\n\"max_ttl\": 157788000,\n\"organization\": [],\n\"other_sans\": [],\n\"ou\": [],\n\"permitted_dns_domains\": [],\n\"postal_code\": [],\n\"private_key_format\": \"der\",\n\"province\": [],\n\"status\": \"configured\",\n\"street_address\": [],\n\"ttl\": 157788000\n},\n\"name\": \"my-configured-root-ca\",\n\"type\": \"root_certificate_authority\"\n},\n\"wrap_info\": null,\n\"warnings\": null,\n\"auth\": null\n}\n\n\n\n\n\n\n\n Update a configuration \n\nUpdates the configuration of a secrets engine that serves as the backend for a specific type of secret. You can update the configuration for the following secret types: iam_credentials, private_cert, public_cert\n\n\n\n Example requests \n\nUpdate a DNS provider configuration for the public_cert secrets engine.\n\ncurl -X PUT 'https:\/\/https:\/\/{instance_id}.{region}.secrets-manager.appdomain.cloud\/v1\/ibmcloud\/public_cert\/config\/dns_providers' -H 'X-Vault-Token: {Vault-Token}' -H 'Content-Type: application\/json' -d'{\n\"name\": \"my-cis-instance\",\n\"type\": \"cis\",\n\"config\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-api"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13616-13587-15670","score":19.7787409417,"text":"\n[https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/dpa.html)\n\n\n\n\n\n Data Privacy and Subject Rights \n\n\n\n* IBM Privacy Statement\n\n\n\nIBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\n\n\n* Right to Lodge a Complaint\n\n\n\nIn the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\n\n\n* IBM TRIRIGA Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\n\n\n* IBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the TRIRIGA Application Suite applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n* IBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n\n\n DDoS Protection \n\n\n\n* IBM Cloud provides DDoS (Distributed Denial of Service) protection for its environment, designed to protect the entire network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tas-ms?topic=tas-ms-security"},{"document_id":"ibmcld_02776-3988-5695","score":19.5666979925,"text":"\n* To prevent or investigate possible wrongdoing in connection with development and testing activities\n* To protect the safety of Personal Data\n* To protect against legal liability\n\n\n\n\n\n\n\n\n\n Security Of Data \n\nDeveloper will strive to use appropriate means to protect all Personal Data used in performing the Permitted Uses of the Service.\n\n\n\n\n\n Service Providers \n\nDeveloper may employ third-party companies and individuals (\"Service Providers\") to facilitate Permitted Uses of the Service, including to perform development and testing, or to analyze development and testing activities.\n\nThese Service Providers have access to Personal Data only to perform these tasks on Developer\u2019s behalf and are obligated not to disclose or use it for any other purpose.\n\n\n\n\n\n Children's Privacy \n\nThe Permitted Use of the Service does not address anyone under the age of 18 (\"Children\").\n\nDeveloper does not knowingly collect Personal Data from anyone under the age of 18. If Developer becomes aware of the collection or processing of Personal Data from Children without verification of parental consent, Developer will take steps to remove that information from the default settings of App ID.\n\n\n\n\n\n Changes To This Privacy Policy \n\nThis Privacy Policy may be updated from time to time and any changes will be reflected by posting the new Privacy Policy on this page. Before the change becomes effective and updated, notification is made via prominent notice on our Service.\n\nThis Privacy Policy should be reviewed periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\n\n\n\n\n\n Contact Us \n\nFor any questions about this Privacy Policy, please contact the Developer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-privacy-policy"},{"document_id":"ibmcld_09492-16883-18851","score":18.6804686292,"text":"\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=en#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\nIBM SRE team does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only. Database auditing is enabled and logs are retained for 365 days. Customers configure and manage the data their users can view, update and export within the Maximo Application Sutie applications, as well as determine which of their users is permitted direct read-only access to their database(s).\n\nIBM purchases Professional Errors and Omissions including cyber risk insurance (see below) for IBM's liability arising out of actual or alleged breach of duty, neglect, error, misstatement, misleading statements or omission committed in the conduct of IBM\u2019s professional services. This includes coverage for loss of intangible property, such as customer data, due to IBM\u2019s negligence. This coverage is global in scope.\n\n\n\n\n\n DDoS Protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-Security"},{"document_id":"ibmcld_04997-3175-3972","score":18.3613022989,"text":"\nSee [IBM Cloud Docs: Enabling the HIPAA Supported setting](https:\/\/cloud.ibm.com\/docs\/account?topic=account-eu-hipaa-supportedenabling-hipaa) for additional information.\n\n\n\n\n\n General Data Protection Regulation (GDPR) readiness \n\nPlease visit [IBM's commitment to GDPR readiness](https:\/\/www.ibm.com\/data-responsibility\/gdpr\/) page to learn about IBM\u2019s GDPR readiness journey and our GDPR capabilities and offerings to support your compliance journey.\n\n\n\n* [IBM Data Processing Addendum (DPA)](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=dpa)\n\n\n\n\n\n\n\n Privacy shield \n\nIBM Cloud Object Storage is privacy shield certified. For more information please visit [IBM Privacy Shield Privacy Policy for Certified IBM Cloud Services](https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-compliance"},{"document_id":"ibmcld_12035-7-1995","score":18.2549595951,"text":"\nCompliance \n\nIBM Cloud\u00ae Schematics actively participates in several industry compliance programs. As compliance focal, you can use the Schematics goals to check that your organization is adhering to the external and internal standards for your industry. For more information about monitoring compliance, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nTo monitor your resources with Schematics, see [Managing security and compliance with Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-monitoring-instances).\n\n\n\n General Data Protection Regulation (GDPR) readiness \n\nAbout GDPR and how Schematics adheres to it, see [General Data Protection Regulation](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdpr). View [IBM's commitment to GDPR readiness](https:\/\/www.ibm.com\/data-responsibility\/gdpr\/) to learn about IBM's GDPR readiness journey and the GDPR capabilities and offerings to support your compliance journey.\n\n\n\n\n\n Privacy shield \n\nSchematics is privacy shield that is certified. For more information, see the [IBM Privacy Shield Privacy Policy for Certified IBM Cloud Services](https:\/\/www.ibm.com\/us-en\/privacy\/privacy-shield).\n\n\n\n\n\n International Organization for Standardization (ISO) \n\nSchematics is audited by a Third-party security firm and meet ISO 27001, ISO 27017, ISO 27018, and ISO 27701 requirements. For more information, see the [Schematics Compliance page](https:\/\/www.ibm.com\/cloud\/compliance) for links to the certificates. The following descriptions on the Schematics compliance page cover the Schematics service and respective certifications:\n\n\n\n* IBM Cloud Services (PaaS and SaaS) certified cloud product listing\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27001\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27017\n* IBM Cloud Services (PaaS and SaaS) certificate - ISO 27018","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-compliance"},{"document_id":"ibmcld_09513-12728-14481","score":17.9946374964,"text":"\nThis is applicable to EU-US and Swiss-US customers: [https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html](https:\/\/www.ibm.com\/privacy\/details\/us\/en\/privacy_shield.html)\n\nData Responsibility at IBM [https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/](https:\/\/www.ibm.com\/blogs\/policy\/dataresponsibility-at-ibm\/) If a government wants access to data held by IBM on behalf of a SaaS client, IBM would expect that government to deal directly with that client\n\nData Processing Addendum (GDPR)\n\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=en#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?id=Z126-7870&lc=endetail-document)\n\n\n\n\n\n Data Privacy and Subject Rights \n\nIBM Privacy Statement IBM's Privacy Statement describes IBM's general privacy practices and subject rights that apply to personal information. For complete statement details click on the link below. [https:\/\/www.ibm.com\/privacy\/us\/en\/](https:\/\/www.ibm.com\/privacy\/us\/en\/)\n\nRight to Lodge a Complaint In the event a client or customer considers our processing of personal information not to be compliant with applicable data protection laws, a complaint can be submitted directly with IBM by using the form in the link below. [https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/](https:\/\/www.ibm.com\/scripts\/contact\/contact\/us\/en\/privacy\/)\n\n\n\n\n\n NIST \n\nIBM Maximo Application Suite Manage Servers (commercial public offerings) follow NIST guidelines and assess against NIST controls, but claim no specific NIST compliance(s).\n\n\n\n\n\n Data Leakage Prevention \/ Data Loss Prevention (DLP) \n\nIBM Cloud Delivery Services does not use DLP monitoring. Access controls are implemented on all databases restricted to privileged users only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-Security"},{"document_id":"ibmcld_12297-14875-16224","score":17.4894351081,"text":"\n* [Creating network zones by using the CBR UI](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-zone-ui)\n\n\n\n* [Understanding network rules](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-network-rules)\n\n\n\n* [Create network rules by using the CBR API](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-rules-api)\n* [Creating network rules by using the CBR UI](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-create-rules-ui)\n\n\n\n* [Next steps](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access-control-cbrcbr-next-steps)\n\n\n\n[Data privacy and governance](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-data-privacy-and-governancedata-privacy-and-governance)\n\n[General Data Protection Regulation (GDPR)](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprgeneral-data-protection-regulation-gdpr)\n\n\n\n* [How do you audit access to Schematics?](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprhow-do-i-audit-access-to-ibm-schematics)\n* [Supporting classifications of personal data](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-general-data-protection-regulation-gdprsupported-classifications-of-personal-data)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-sitemap"},{"document_id":"ibmcld_09105-6159-7945","score":17.3270850536,"text":"\n<br> <br>When you set the return_preference variable to return=minimal, the service returns only the key metadata, such as the key name and ID value, in the response entity-body. When you set the variable to return=representation, the service returns both the key material and the key metadata. \n key_name Required. A unique, human-readable name for easy identification of your key. To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional. One or more unique, human-readable aliases assigned to your key. <br> <br>Important: To protect your privacy, do not store your personal data as metadata for your key. <br> <br>Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies. registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. \n key_description Optional. An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional. The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_material Required. The base64-encoded key material, an existing key-wrapping key, that you want to store and manage in the service. For more information, check out [Base64 encoding your key material](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-root-keyshow-to-encode-root-key-material).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-root-keys"},{"document_id":"ibmcld_09060-4951-6938","score":17.2006329556,"text":"\nThe unique identifier of the target key ring that you would like the newly create key to be a part of. If unspecified, the header is automatically set to 'default' and the key will sit in the default key ring in the specified Key Protect service instance. For more information, see [Grouping keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys). \n correlation_ID Optional.The unique identifier that is used to track and correlate transactions. \n return_preference A header that alters server behavior for POST and DELETE operations. When you set the return_preference variable to return=minimal, the service returns only the key metadata, such as the key name and ID value, in the response entity-body. When you set the variable to return=representation, the service returns both the key material and the key metadata. \n key_name Required. A human-readable name for convenient identification of your key. To protect your privacy, do not store your personal data as metadata for your key. \n alias_list Optional.One or more unique, human-readable aliases assigned to your key. Important: To protect your privacy, do not store your personal data as metadata for your key. Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than - or _. The alias cannot be a UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be between 2 - 90 characters (inclusive). \n key_description Optional.An extended description of your key. To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional.The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-standard-keys"},{"document_id":"ibmcld_09059-7769-9779","score":17.1965512641,"text":"\nA human-readable name for convenient identification of your key. Important: To protect your privacy, do not store your personal data as metadata for your key. \n alias_list One or more unique, human-readable aliases assigned to your key. Important: To protect your privacy, do not store your personal data as metadata for your key. Each alias must be alphanumeric, case sensitive, and cannot contain spaces or special characters other than dashes (-) or underscores (_). The alias cannot be a version 4 UUID and must not be a Key Protect reserved name: allowed_ip, key, keys, metadata, policy, policies, registration, registrations, ring, rings, rotate, wrap, unwrap, rewrap, version, versions. Alias size can be between 2 - 90 characters (inclusive). \n key_description An extended description of your key. Important: To protect your privacy, do not store your personal data as metadata for your key. \n expiration_date Optional. The date and time that the key expires in the system, in RFC 3339 format (YYYY-MM-DD HH:MM:SS.SS, for example 2019-10-12T07:20:50.52Z). The key will transition to the deactivated state within one hour past the key's expiration date. If the expirationDate attribute is omitted, the key does not expire. \n key_type A boolean value that determines whether the key material can leave the service. When you set the extractable attribute to false, the service creates a root key that you can use for wrap or unwrap operations. \n\n\n\nTo protect the confidentiality of your personal data, avoid entering personally identifiable information (PII), such as your name or location, when you add keys to the service.\n\nIf the expirationDate is provided in your create key request, the key will transition to the deactivated state within one hour past the key's expiration date.\n\nA successful POST api\/v2\/keys response returns the ID value for your key, along with other metadata. The ID is a unique identifier that is assigned to your key and is used for subsequent calls to the Key Protect API.\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-root-keys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":32.3788620234,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":32.3342774819,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-365833-367834","score":28.9257744793,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-365807-367808","score":28.9257744793,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01533-6329-8623","score":28.6279376891,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":28.6279376891,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01415-6473-8616","score":28.4379733168,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_00882-2700-4149","score":27.5113663816,"text":"\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".\/Report-final.xml\" --type staticsecurityscan\n\nChange the type to dynamicsecurityscan if the report is from a dynamic scan.\n\n\n\n\n\n Uploading SonarQube results \n\nTo upload data from SonarQube, you must provide the SonarQube server token by using --token. Your SonarQube server is required to be accessible from your CI\/CD tool.\n\nAfter you run a scan by using SonarQube, you can upload SonarQube results by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".scannerwork\/report-task.txt\" --type=sonarqube --token=$SONARQUBE_TOKEN\n\nreport-task.txt is a file that is generated during the SonarQube scan.\n\n\n\n\n\n Uploading IBM Vulnerability Advisor results \n\nTo get the result of the vulnerability advisor scan from the CLI, use the following command:\n\nibmcloud cr va ${PIPELINE_IMAGE_URL} -o json > vulnerability_advisor.json\n\nYou can get your image's repository and tag from the Vulnerability Advisor UI or in the CLI by using ibmcloud cr image-list. DevOps Insights accepts only the JSON output. You can upload Vulnerability Advisor output file to DevOps Insights by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"${APP_NAME}\" --buildnumber \"${BUILD_NUMBER}\" --filelocation \"vulnerability_advisor.json\" --type vulnerabilityadvisor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publishing-test-data"},{"document_id":"ibmcld_07971-2155-4528","score":27.4376844717,"text":"\n* Document and evidence the execution of the system\/service and security testing\/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https:\/\/github.com\/IBM\/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-development-processes"},{"document_id":"ibmcld_06004-36463-38401","score":27.1006340503,"text":"\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, encrypt traffic between app microservices, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images. When you add an image to your organization's IBM Cloud Container Registry namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n\nKubernetes secrets\n: When you deploy your app, don't store confidential information, such as credentials or keys, in the YAML configuration file, configmaps, or scripts. Instead, use [Kubernetes secrets](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitypi), such as an image pull secret for registry credentials. You can then reference these secrets in your deployment YAML file.\n\nSecret encryption\n: You can encrypt the Kubernetes secrets that you create in your cluster by using a key management service (KMS) provider. To get started, see [Encrypt secrets by using a KMS provider](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionkeyprotect) and [Verify that secrets are encrypted](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionverify_kms).\n\nMicroservice traffic encryption","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_deploy"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":36.181775902,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":36.1430941681,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":34.818436134,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":34.818436134,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-365833-367834","score":34.3615941065,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-365807-367808","score":34.3615941065,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01415-6473-8616","score":33.9613009468,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_00882-2700-4149","score":33.1639323977,"text":"\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".\/Report-final.xml\" --type staticsecurityscan\n\nChange the type to dynamicsecurityscan if the report is from a dynamic scan.\n\n\n\n\n\n Uploading SonarQube results \n\nTo upload data from SonarQube, you must provide the SonarQube server token by using --token. Your SonarQube server is required to be accessible from your CI\/CD tool.\n\nAfter you run a scan by using SonarQube, you can upload SonarQube results by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".scannerwork\/report-task.txt\" --type=sonarqube --token=$SONARQUBE_TOKEN\n\nreport-task.txt is a file that is generated during the SonarQube scan.\n\n\n\n\n\n Uploading IBM Vulnerability Advisor results \n\nTo get the result of the vulnerability advisor scan from the CLI, use the following command:\n\nibmcloud cr va ${PIPELINE_IMAGE_URL} -o json > vulnerability_advisor.json\n\nYou can get your image's repository and tag from the Vulnerability Advisor UI or in the CLI by using ibmcloud cr image-list. DevOps Insights accepts only the JSON output. You can upload Vulnerability Advisor output file to DevOps Insights by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"${APP_NAME}\" --buildnumber \"${BUILD_NUMBER}\" --filelocation \"vulnerability_advisor.json\" --type vulnerabilityadvisor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publishing-test-data"},{"document_id":"ibmcld_01533-4-2366","score":32.7749750654,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4-2366","score":32.7749750654,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.4,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.200136681}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4-2366","score":30.1226735607,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4-2366","score":30.1226735607,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":29.8614296548,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":29.8614296548,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01441-7-2257","score":29.5116924826,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":29.5116924826,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-1679-3819","score":29.1300716119,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-1679-3832","score":29.1099487884,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01533-4546-6910","score":28.9938926099,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":28.9640161131,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.75,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1510196182,"ndcg_cut_10":0.4202024811}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01329-58331-60199","score":33.1885635103,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01442-1679-3832","score":33.1291000984,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-1679-3819","score":32.6360461149,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01441-7-2257","score":31.9469890683,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":31.9469890683,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01533-10805-12534","score":31.0666763237,"text":"\nRed Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support. [Ubuntu CVE Tracker](https:\/\/launchpad.net\/ubuntu-cve-tracker). \n\n\n\n\n\n\n\n Configuration issues - version 3 only \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nConfiguration issues are potential security issues that are related to how an\n\nappis set up. Configuration issues are not supported in version 4.\n\nMany of the reported problems can be fixed by updating your\n\nDockerfile.\n\nImages are scanned only if they are using an operating system that is supported by Vulnerability Advisor. Vulnerability Advisor checks the configuration settings for the following types of apps:\n\n\n\n* MySQL\n* NGINX\n* Apache\n\n\n\n\n\n\n\n\n\n Setting the Vulnerability Advisor version \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nStarting from version 1.0.0 of the Container Registry plug-in, you can choose whether to fetch results from either version 3, v3 (the default), or version 4, v4, of Vulnerability Advisor for the following commands:\n\n\n\n* [ibmcloud cr va IMAGE](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va), where IMAGE is the name of the image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-10857-12586","score":31.0666763237,"text":"\nRed Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support. [Ubuntu CVE Tracker](https:\/\/launchpad.net\/ubuntu-cve-tracker). \n\n\n\n\n\n\n\n Configuration issues - version 3 only \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nConfiguration issues are potential security issues that are related to how an\n\nappis set up. Configuration issues are not supported in version 4.\n\nMany of the reported problems can be fixed by updating your\n\nDockerfile.\n\nImages are scanned only if they are using an operating system that is supported by Vulnerability Advisor. Vulnerability Advisor checks the configuration settings for the following types of apps:\n\n\n\n* MySQL\n* NGINX\n* Apache\n\n\n\n\n\n\n\n\n\n Setting the Vulnerability Advisor version \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nStarting from version 1.0.0 of the Container Registry plug-in, you can choose whether to fetch results from either version 3, v3 (the default), or version 4, v4, of Vulnerability Advisor for the following commands:\n\n\n\n* [ibmcloud cr va IMAGE](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va), where IMAGE is the name of the image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-367408-369576","score":30.4170828404,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-367382-369550","score":30.4170828404,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01533-4-2366","score":30.4121848479,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01442-1679-3832","score":38.3924405199,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-1679-3819","score":38.2552864966,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01441-7-2257","score":36.2302046169,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":36.2302046169,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01329-58331-60199","score":35.906205164,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01533-4-2366","score":34.8069133924,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4-2366","score":34.8069133924,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-10805-12534","score":34.1501285719,"text":"\nRed Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support. [Ubuntu CVE Tracker](https:\/\/launchpad.net\/ubuntu-cve-tracker). \n\n\n\n\n\n\n\n Configuration issues - version 3 only \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nConfiguration issues are potential security issues that are related to how an\n\nappis set up. Configuration issues are not supported in version 4.\n\nMany of the reported problems can be fixed by updating your\n\nDockerfile.\n\nImages are scanned only if they are using an operating system that is supported by Vulnerability Advisor. Vulnerability Advisor checks the configuration settings for the following types of apps:\n\n\n\n* MySQL\n* NGINX\n* Apache\n\n\n\n\n\n\n\n\n\n Setting the Vulnerability Advisor version \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nStarting from version 1.0.0 of the Container Registry plug-in, you can choose whether to fetch results from either version 3, v3 (the default), or version 4, v4, of Vulnerability Advisor for the following commands:\n\n\n\n* [ibmcloud cr va IMAGE](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va), where IMAGE is the name of the image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-10857-12586","score":34.1501285719,"text":"\nRed Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support. [Ubuntu CVE Tracker](https:\/\/launchpad.net\/ubuntu-cve-tracker). \n\n\n\n\n\n\n\n Configuration issues - version 3 only \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nConfiguration issues are potential security issues that are related to how an\n\nappis set up. Configuration issues are not supported in version 4.\n\nMany of the reported problems can be fixed by updating your\n\nDockerfile.\n\nImages are scanned only if they are using an operating system that is supported by Vulnerability Advisor. Vulnerability Advisor checks the configuration settings for the following types of apps:\n\n\n\n* MySQL\n* NGINX\n* Apache\n\n\n\n\n\n\n\n\n\n Setting the Vulnerability Advisor version \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nStarting from version 1.0.0 of the Container Registry plug-in, you can choose whether to fetch results from either version 3, v3 (the default), or version 4, v4, of Vulnerability Advisor for the following commands:\n\n\n\n* [ibmcloud cr va IMAGE](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va), where IMAGE is the name of the image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01471-7-1919","score":33.904736784,"text":"\nRelease notes for Container Registry \n\nLearn about the changes to IBM Cloud\u00ae Container Registry and Vulnerability Advisor. The changes are grouped by date.\n\n\n\n 19 June 2023 \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023\n: For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\n\n\n 19 May 2023 \n\nUpdate Vulnerability Advisor to version 4 by 19 June 2023\n: The Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\nFor more information, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4).\n\n\n\n\n\n 26 April 2023 \n\nUsing Portieris to block the deployment of images with issues is deprecated.\n: The use of Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n\n\n 11 November 2022 \n\nChange to virtual private endpoints\n: Virtual private endpoints are changing.\n\nOn 11 November 2022, virtual private endpoints (VPEs) for IBM Cloud Container Registry are being updated and the existing VPE version is being deprecated on 15 December 2022. If you use Container Registry VPE gateways, you must create new VPE gateways and remove your VPE gateways that were created before 11 November 2022 at the earliest opportunity so that you pick up these changes. VPE gateways that were created before 11 November 2022 are deprecated and will not work after 15 December 2022.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.156426242}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":36.3107688208,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":36.265869958,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":33.5028448219,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":33.5028448219,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-365833-367834","score":33.1147603862,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-365807-367808","score":33.1147603862,"text":"\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01415-6473-8616","score":32.9497738471,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_07971-2155-4528","score":31.2751722275,"text":"\n* Document and evidence the execution of the system\/service and security testing\/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https:\/\/github.com\/IBM\/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-development-processes"},{"document_id":"ibmcld_00882-2700-4149","score":30.994253436,"text":"\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".\/Report-final.xml\" --type staticsecurityscan\n\nChange the type to dynamicsecurityscan if the report is from a dynamic scan.\n\n\n\n\n\n Uploading SonarQube results \n\nTo upload data from SonarQube, you must provide the SonarQube server token by using --token. Your SonarQube server is required to be accessible from your CI\/CD tool.\n\nAfter you run a scan by using SonarQube, you can upload SonarQube results by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".scannerwork\/report-task.txt\" --type=sonarqube --token=$SONARQUBE_TOKEN\n\nreport-task.txt is a file that is generated during the SonarQube scan.\n\n\n\n\n\n Uploading IBM Vulnerability Advisor results \n\nTo get the result of the vulnerability advisor scan from the CLI, use the following command:\n\nibmcloud cr va ${PIPELINE_IMAGE_URL} -o json > vulnerability_advisor.json\n\nYou can get your image's repository and tag from the Vulnerability Advisor UI or in the CLI by using ibmcloud cr image-list. DevOps Insights accepts only the JSON output. You can upload Vulnerability Advisor output file to DevOps Insights by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"${APP_NAME}\" --buildnumber \"${BUILD_NUMBER}\" --filelocation \"vulnerability_advisor.json\" --type vulnerabilityadvisor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publishing-test-data"},{"document_id":"ibmcld_07578-367408-369576","score":30.9642477346,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01409-5613-7424","score":12.5847669314,"text":"\nPOST \/api\/v1\/trash\/{digest}\/restoretags container-registry.image.push container-registry.trash.restore \n Restore deleted image. POST \/api\/v1\/trash\/{image}\/restore container-registry.image.push container-registry.trash.restore \n\n\n\n\n\n\n\n\n\n Vulnerability Advisor API methods \n\n\n\n Report API methods \n\n\n\nTable 11. Report\n\n Action Method IAM ACTION AT ACTION \n\n Get the vulnerability assessment for all images. GET \/va\/api\/v3\/report\/account container-registry.exemption.list container-registry.account-vulnerability-report.list \n Get vulnerability assessment status for all images. GET \/va\/api\/v3\/report\/account\/status container-registry.exemption.list container-registry.account-vulnerability-status.list \n Get vulnerability status. GET \/va\/api\/v3\/report\/image\/status\/{name} container-registry.exemption.list container-registry.image-vulnerability-status.read \n Get vulnerability assessment status. GET \/va\/api\/v3\/report\/image\/{name} container-registry.exemption.list container-registry.image-vulnerability-report.read \n\n\n\n\n\n\n\n Exemption API methods \n\n\n\nTable 12. Exemption\n\n Action Method IAM ACTION AT ACTION \n\n List account-level exemptions. GET \/va\/api\/v3\/exempt\/image container-registry.exemption.list \n Get an account-level exemption. GET \/va\/api\/v3\/exempt\/image\/issue\/{issueType}\/{issueID} container-registry.exemption.list \n Create or update an account-level exemption. POST \/va\/api\/v3\/exempt\/image\/issue\/{issueType}\/{issueID} container-registry.exemption.manager container-registry.exemption.create \n Delete an account-level exemption. DELETE \/va\/api\/v3\/exempt\/image\/issue\/{issueType}\/{issueID} container-registry.exemption.manager container-registry.exemption.delete \n List resource exemptions. GET \/va\/api\/v3\/exempt\/image\/{resource} container-registry.exemption.list \n Get details of a resource exemption.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_at_iam"},{"document_id":"ibmcld_01409-4151-6017","score":11.9029132554,"text":"\nGET \/api\/v1\/retentions container-registry.retention.list container-registry.retention.list \n Set the retention policy for the specified namespace. POST \/api\/v1\/retentions container-registry.retention.set container-registry.retention.set \n Analyze a retention policy, and get a list of what would be deleted by it. POST \/api\/v1\/retentions\/analyze container-registry.retention.analyze container-registry.retention.analyze \n Get the retention policy for the specified namespace. GET \/api\/v1\/retentions\/{namespace} container-registry.retention.get container-registry.retention.get \n\n\n\n\n\n\n\n Settings API methods \n\n\n\nTable 8. Settings\n\n Action Method IAM ACTION AT ACTION \n\n Get registry service settings for the targeted account, such as whether platform metrics are enabled. GET \/api\/v1\/settings container-registry.settings.get container-registry.settings.get \n Update registry service settings for the targeted account, such as enabling platform metrics. PATCH \/api\/v1\/settings container-registry.settings.set container-registry.settings.set \n\n\n\n\n\n\n\n Tag API methods \n\n\n\nTable 9. Tags\n\n Action Method IAM ACTION AT ACTION \n\n Delete tag. DELETE \/api\/v1\/tags\/{image} container-registry.image.delete container-registry.image.untag \n\n\n\n\n\n\n\n Trash API methods \n\n\n\nTable 10. Trash\n\n Action Method IAM ACTION AT ACTION \n\n List images in the trash. GET \/api\/v1\/trash container-registry.image.delete container-registry.trash.list \n Restore a digest and all associated tags. POST \/api\/v1\/trash\/{digest}\/restoretags container-registry.image.push container-registry.trash.restore \n Restore deleted image. POST \/api\/v1\/trash\/{image}\/restore container-registry.image.push container-registry.trash.restore \n\n\n\n\n\n\n\n\n\n Vulnerability Advisor API methods \n\n\n\n Report API methods \n\n\n\nTable 11. Report\n\n Action Method IAM ACTION AT ACTION \n\n Get the vulnerability assessment for all images.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_at_iam"},{"document_id":"ibmcld_07844-2925-4586","score":11.3822725977,"text":"\nRA-5 (a) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_01377-7418-9272","score":11.3152712982,"text":"\nView, inspect, and pull images.<br><br>View and analyze namespaces.<br><br>View quotas.<br><br>View vulnerability reports.<br><br>View image signatures.<br><br>View retention policies.<br><br>View the contents of the trash.<br><br>View the contents of the manifest for an image.<br><br>List Vulnerability Advisor security exemption policies and types of security exemptions. \n Writer The Writer role can edit information. Push, delete, and restore images.<br><br>View quotas.<br><br>Sign images.<br><br>Set and run retention policies.<br><br>Delete all untagged images in your Container Registry account. \n Manager The Manager role can perform all actions. View, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-7444-9298","score":11.3152712982,"text":"\nView, inspect, and pull images.<br><br>View and analyze namespaces.<br><br>View quotas.<br><br>View vulnerability reports.<br><br>View image signatures.<br><br>View retention policies.<br><br>View the contents of the trash.<br><br>View the contents of the manifest for an image.<br><br>List Vulnerability Advisor security exemption policies and types of security exemptions. \n Writer The Writer role can edit information. Push, delete, and restore images.<br><br>View quotas.<br><br>Sign images.<br><br>Set and run retention policies.<br><br>Delete all untagged images in your Container Registry account. \n Manager The Manager role can perform all actions. View, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_01533-4546-6910","score":11.1602186349,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":11.1534007268,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01377-8075-10005","score":10.9678599558,"text":"\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-8101-10031","score":10.9678599558,"text":"\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":10.171617387,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16729-71418-73421","score":20.2889481042,"text":"\nIBM Cloud\u00ae Container Registry provides a multi-tenant private image registry that you can use to store and share your container images with users in your IBM Cloud account.\n\nKubernetes service Container Registry\n\n\n\n* 45 minutes\n* 2023-06-02\n\n\n\n[Encrypting images for content confidentiality](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_encrypt)Encrypting images for content confidentiality\n\nYou can protect the confidentiality of your IBM Cloud\u00ae Container Registry images, and ensure that hosts that aren't trusted can't run the images.\n\nKey Protect Container Registry\n\n\n\n* 2 hours\n* 2023-01-25\n\n\n\n[Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access)Granting access to Container Registry resources tutorial\n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nContainer Registry\n\n\n\n* 45 minutes\n* 2023-01-31\n\n\n\n[Container Registry and Vulnerability Advisor workflow tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflow)Container Registry and Vulnerability Advisor workflow tutorial\n\nUse this tutorial to find out about the basic functions of both IBM Cloud\u00ae Container Registry and Vulnerability Advisor.\n\nKubernetes service Container Registry\n\n\n\n* 2 hours\n* 2023-06-19\n\n\n\n[Onboarding a Certified Operator from a Red Hat registry](https:\/\/cloud.ibm.com\/docs\/account?topic=account-catalog-opbundle-tutorial)Onboarding a Certified Operator from a Red Hat registry\n\nThis tutorial walks you through how to onboard a sample Operator bundle from a Red Hat\u00ae registry to your account. By completing this tutorial, you learn how to create a private catalog in your account, import the Operator bundle, and validate that it can be installed on a Red Hat OpenShift on IBM Cloud cluster.\n\nContainer Registry Managing your account, resources, and access\n\n\n\n* 45 minutes\n* 2022-10-26","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_01377-8075-10005","score":19.129373126,"text":"\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-8101-10031","score":19.129373126,"text":"\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_01471-37693-39572","score":18.6441769738,"text":"\nYou can use the new region by using the domain name jp.icr.io.\n\nFor more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\n\n\n\n\n 21 February 2019 \n\nAutomating access to your namespaces\n: Using tokens to automate pushing and pulling Docker images to and from your namespaces is deprecated. You must now use API keys to automate access to your Container Registry namespaces so that you can push and pull images.\n\nFor more information, see [Creating a user API key manually](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_accessregistry_access_user_apikey_create).\n\n\n\n\n\n 8 January 2019 \n\nEnd of support for Vulnerability Advisor API version 2\n: Vulnerability Advisor\u2019s API version 2 is deprecated and is no longer usable. Use version 3 of the API, see [Vulnerability Advisor for IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/apidocs\/container-registry\/va).\n\n\n\n\n\n 4 October 2018 \n\nManaging user access\n: Use IBM Cloud Identity and Access Management (IAM) to control access by users in your account to Container Registry. When IAM access policies are enabled for your account in Container Registry, every user that accesses the service in your account must be assigned an IAM\n\naccess policywith an IAM user role defined. That policy determines the role that the user has within the context of the service, and what actions the user can perform.\n\nFor more information, see [Managing IAM access with Cloud Identity and Access Management](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamiam), [Defining IAM access policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-useruser), and [Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access).\n\n\n\n\n\n 7 August 2018 \n\nExemption policies available in Vulnerability Advisor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"},{"document_id":"ibmcld_01471-39117-41118","score":18.1819354796,"text":"\nFor more information, see [Managing IAM access with Cloud Identity and Access Management](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamiam), [Defining IAM access policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-useruser), and [Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access).\n\n\n\n\n\n 7 August 2018 \n\nExemption policies available in Vulnerability Advisor\n: If you want to manage the security of an IBM Cloud organization, you can use your policy setting to determine whether an issue is exempt or not. You can use Portieris to ensure that deployment is allowed only from images that contain no security issues after accounting for any issues that are exempted by your policy.\n\nFor more information, see [Setting organizational exemption policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_managing_policy).\n\n\n\n\n\n 25 July 2018 \n\nIBM Cloud Activity Tracker available for Vulnerability Advisor\n: Use the IBM Cloud Activity Tracker service to track how users and applications interact with the Container Registry service in IBM Cloud.\n\nFor more information, see [Auditing events for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-at_events).\n\n\n\n\n\n 12 July 2018 \n\nVulnerability Advisor API version 3\n: Version 3 of the API changes the behavior of the API endpoints that are used to list exemptions. You must check that your use of the API does not rely on the behavior of version 2.\n\nFor more information, see [Vulnerability Advisor for IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/apidocs\/container-registry\/va).\n\n\n\n\n\n 31 May 2018 \n\nUse Helm for Passport Advantage images\n: Import IBM software that is downloaded from [IBM Passport Advantage Online for customers](https:\/\/www.ibm.com\/software\/passportadvantage\/pao_customer.html) and packaged for use with Helm into your Container Registry namespace.\n\n\n\n\n\n 21 March 2018 \n\nContainer Scanner","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"},{"document_id":"ibmcld_01494-31513-33000","score":18.0654691222,"text":"\n* [Enforce security in your cluster](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_enforce_security)\n* [Resolve vulnerabilities in your image](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_resolve_vulnerabilities)\n\n\n\n* [Deploying to nondefault Kubernetes namespaces](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_deploy_nondefault_namespaces)\n\n\n\n\n\n\n\n Granting access to Container Registry resources tutorial \n\n[Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessiam_access_prereq)\n* [Authorize a user to configure the registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessconfigure_registry)\n* [Authorize a user to access specific namespaces](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessaccess_resources)\n* [Create a service ID and grant access to a resource](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessservice_id)\n* [Cleaning up your account](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_accessclean_up)\n\n\n\n\n\n\n\n Solution tutorials \n\n[Moving a VM based app to Kubernetes](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-vm-to-containers-and-kubernetesvm-to-containers-and-kubernetes)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-sitemap"},{"document_id":"ibmcld_01377-13470-15034","score":17.2681214344,"text":"\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam"},{"document_id":"ibmcld_01387-13496-15060","score":17.2681214344,"text":"\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam&interface=ui"},{"document_id":"ibmcld_01473-1885-4068","score":16.432308262,"text":"\nFor more information, see [Auditing events for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-at_events). \n\n\n\n\n\n\n\n Change management \n\nChange management includes tasks such as deployment, configuration, upgrades, patching, configuration changes, and deletion.\n\n\n\nTable 2. Responsibilities for change management\nThe first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Provisioning. It is the responsibility of IBM to provision the service. \n Deprovisioning. It is the responsibility of IBM to deprovision the service. \n Update package versions. It is your responsibility to update package versions inside container images. You can use Vulnerability Advisor to identify the required updates. For more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui). \n\n\n\n\n\n\n\n Identity and access management \n\nIdentity and access management includes tasks such as authentication, authorization, access control policies, and approving, granting, and revoking access.\n\n\n\nTable 3. Responsibilities for identity and access management\nThe first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Authentication It is the responsibility of IBM to implement authentication. \n Process access policies It is the responsibility of IBM to ensure that the policies are processed. \n Set up access policies It is your responsibility to set up access policies. For more information, see [Creating policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-usercreate). \n Access to back-end resources It is the responsibility of IBM to access to back-end resources. \n Access to namespaces It is your responsibility to set up access to namespaces.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_responsibilities"},{"document_id":"ibmcld_01530-1294-3025","score":16.2916141328,"text":"\n* Decide on the roles that each user needs and on which resources in IBM Cloud Container Registry, see [IAM roles](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamiam). You can create multiple policies, for example, you can grant write access on a resource but grant read access only on another resource. Policies are additive, which means that a global read policy and a resource-scoped write policy grants both read and write access on that resource.\n* [Invite users to an account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamuserinviamuserinv).\n\nIf you want users to create clusters in IBM Cloud Kubernetes Service, ensure that you assign the IBM Cloud Container Registry Administrator role to those users, and don't assign a resource group. For more information, see [Preparing to create clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusterscluster_prepare).\n\n\n\nTo create policies for IBM Cloud Container Registry, the service name field must be container-registry.\n\nIf you want to access resources, you must assign roles to users or service IDs. If you want to grant access to everything, don't specify a resource type or a resource. If you want to grant access to a specific namespace, specify the resource type as namespace and use the namespace name as the resource.\n\n\n\n* To create a policy for users, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n* To create a policy for service IDs, run the ibmcloud iam service-policy-create command or use the IBM Cloud console to bind roles to your service IDs. To create policies, you must have the Administrator role. You automatically have the Administrator role on your own account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-user"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04340-56606-58228","score":23.8560533196,"text":"\nibmcloud cr trash-list [--restrict NAMESPACE] [--json]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--restrict NAMESPACE\n: (Optional) Limit the output to display only images in the specified namespace.\n\n--json\n: (Optional) Outputs JSON that contains the details of the contents of the trash.\n\n\n\n\n\n Example \n\nDisplay the images that are in the trash in the birds namespace.\n\nibmcloud cr trash-list --restrict birds\n\n\n\n\n\n\n\n ibmcloud cr va-version \n\nFind out which version of Vulnerability Advisor you're using.\n\nibmcloud cr va-version\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n\n\n ibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-containerregcli"},{"document_id":"ibmcld_01488-11005-12525","score":23.4844499926,"text":"\nView the security.yaml file in the [GitHub repository](https:\/\/github.com\/IBM\/registry-va-workflow), and read about customizing [policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-security_enforce_portierispolicies_portieris) to understand this file's contents. In short, this policy requires all images in your namespace to have no issues reported by Vulnerability Advisor.\n3. Update the following line in the security.yaml file by replacing <my_namespace> with your namespace:\n\n- name: us.icr.io\/<my_namespace>\/\n4. Apply the custom policies:\n\nkubectl apply -f security.yaml\n5. To update hello-world.yaml so that it references your vulnerable image, change the tag from 1 to 2 as shown here:\n\nimage: us.icr.io\/<my_namespace>\/hello-world:2\n6. Try to patch the existing deployment by running the following command:\n\nkubectl apply -f hello-world.yaml\n\nYou see the following error message:\n\nDeny \"us.icr.io\/<my_namespace>\/hello-world:2\", the Vulnerability Advisor image scan assessment\nfound issues with the container image that are not exempted. Refer to your image vulnerability\nreport for more details by using the ibmcloud cr va command.\n\nThe Vulnerability Advisor verdict is subject to any [exemption policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_managing_policy) that you create. If you want to use an image that Vulnerability Advisor considers vulnerable, you can exempt one, or more vulnerabilities so that Vulnerability Advisor doesn't consider them in its verdict.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflow"},{"document_id":"ibmcld_01329-56937-58704","score":23.3701194455,"text":"\nImages remain in the trash for 30 days after they are deleted from your live repository.\n\nIf you want to restore an image from the trash, run the [ibmcloud cr image-restore](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_image_restore) command, see [Restoring images](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_images_registry_images_restore).\n\nibmcloud cr trash-list [--restrict NAMESPACE] [--json]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--restrict NAMESPACE\n: (Optional) Limit the output to display only images in the specified namespace.\n\n--json\n: (Optional) Outputs JSON that contains the details of the contents of the trash.\n\n\n\n\n\n Example \n\nDisplay the images that are in the trash in the birds namespace.\n\nibmcloud cr trash-list --restrict birds\n\n\n\n\n\n\n\n ibmcloud cr va-version \n\nFind out which version of Vulnerability Advisor you're using.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n\n\n ibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_10261-16096-18060","score":22.7259546844,"text":"\nOr, you might push a Docker image that you work with to your namespace so that other users can access the image. To get started, see [Adding images to your namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_images_).\n\n\n\n\n\n Managing security of images in IBM Cloud Container Registry with Vulnerability Advisor \n\nVulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's IBM Cloud Container Registry namespace.\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n\n\n\n\n\n Setting up trusted content for container images \n\nYou can build containers from trusted images that are signed and stored in IBM Cloud Container Registry, and prevent deployments from unsigned or vulnerable images.\n\n\n\n1. [Sign images for trusted content](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_trustedcontentregistry_trustedcontent). After you set up trust for your images, you can manage trusted content and signers that can push images to your registry.\n2. To enforce a policy so that only signed images can be used to build containers in your cluster, [install the open source Portieris project](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-imagesportieris-image-sec).\n3. Cluster users can deploy apps that are built from trusted images.\n\n\n\n1. [Deploy to the default Kubernetes namespace](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-imagesnamespace).\n2. [Deploy to a different Kubernetes namespace, or from a different IBM Cloud region or account](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryother).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-images"},{"document_id":"ibmcld_05856-5461-7410","score":22.5047028596,"text":"\nFor example, you might pull an image from any private or public registry source, and then tag it for later use in IBM Cloud Container Registry. Or, you might push a Docker image that you work with to your namespace so that other users can access the image. To get started, see [Adding images to your namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_images_).\n\n\n\n\n\n Managing security of images in IBM Cloud Container Registry with Vulnerability Advisor \n\nVulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's IBM Cloud Container Registry namespace.\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n\n\n\n\n\n Setting up trusted content for container images \n\nYou can build containers from trusted images that are signed and stored in IBM Cloud Container Registry, and prevent deployments from unsigned or vulnerable images.\n\n\n\n1. [Sign images for trusted content](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_trustedcontentregistry_trustedcontent). After you set up trust for your images, you can manage trusted content and signers that can push images to your registry.\n2. To enforce a policy so that only signed images can be used to build containers in your cluster, [install the open source Portieris project](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-imagesportieris-image-sec).\n3. Cluster users can deploy apps that are built from trusted images.\n\n\n\n1. [Deploy to the default Kubernetes namespace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-imagesnamespace).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-images"},{"document_id":"ibmcld_01533-4-2366","score":22.409312008,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4-2366","score":22.409312008,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07971-2155-4528","score":22.2411766039,"text":"\n* Document and evidence the execution of the system\/service and security testing\/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https:\/\/github.com\/IBM\/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-shared-development-processes"},{"document_id":"ibmcld_01327-9280-11431","score":22.0256255302,"text":"\ncontainer-registry.exemption.create Create a Vulnerability Advisor exemption. \n container-registry.exemption.delete Delete a Vulnerability Advisor exemption. \n\n\n\n\n\n\n\n\n\n Analyzing Activity Tracker events \n\nThe following fields are populated as described, depending on how you populate the request:\n\n\n\n* target.name shows the image name and, if you request an image name with a tag, a tag. If you request an image name by digest, the digest is shown instead of the tag because the digest might have many tags.\n* target.id shows the image name by digest to represent a searchable unique ID for the image, unless the request is for an image with a tag and the request fails before the digest is discovered. To see all the events for this digest across all tags, you can search by target.id.\n* target.resourceGroupId shows the resource group ID that is associated with a namespace and its resources. For more information, see [Set up a namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgs_registry_namespace_add).\n\nEarlier namespaces that aren't migrated to IAM don't have a resource group, therefore this field is not available.\n\n\n\n\n\n Request data for vulnerability events \n\nGet the data for vulnerability events in Container Registry.\n\n\n\n Request data for the account vulnerability report \n\nGet the vulnerability assessment (container-registry.account-vulnerability-report.list) for the list of registry images that belong to a specific account.\n\nThe following table lists the fields that are available through the requestData field in events with the action container-registry.account-vulnerability-report.list.\n\n\n\nTable 18. Custom event fields for Container Registry account vulnerability reports list\n\n Custom Event Fields Type Description \n\n requestData.RequestParameters.repository String The name of the repository that you want to see image vulnerability assessments for. For example, us.icr.io\/namespace\/image. \n requestData.RequestParameters.includeIBM String When set to true, the returned list contains IBM public images and the account images. If not set, or set to false, the list contains only the account images.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-at_events"},{"document_id":"ibmcld_01533-16920-18657","score":21.2713226918,"text":"\nYou can review the security of Docker images that are stored in your namespaces in IBM Cloud Container Registry by using the CLI.\n\n\n\n1. List the images in your IBM Cloud account. A list of all images is returned, independent of the namespace where they are stored.\n\nibmcloud cr image-list\n2. Check the status in the SECURITY STATUS column.\n\n\n\n* No Issues No security issues were found.\n* <X> Issues The number of potential security issues or vulnerabilities that are found, where <X> is the number of issues.\n* Scanning The image is being scanned and the final vulnerability status is not determined.\n* Unsupported OS The scan found no supported operating system (OS) distribution and no active configuration issues.\n\n\n\n3. To view the details for the status, review the Vulnerability Advisor report:\n\nibmcloud cr va <region>.icr.io\/<my_namespace>\/<my_image>:<tag>\n\nIn the CLI output, you can view the following information about the configuration issues.\n\n\n\n* Security practice A description of the vulnerability.\n* Corrective action Details about how to fix the vulnerability.\n\n\n\n\n\n\n\n\n\n\n\n Setting organizational exemption policies \n\nIf you want to manage the security of an IBM Cloud organization, you can use your policy setting to determine whether an issue is exempt or not.\n\nYou can deploy containers from any image regardless of security status.\n\nTo find out about the required permissions for working with exemptions, see [Access roles for configuring IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_configure).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n Setting exemption policies by using the console","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05838-12220-14151","score":12.1332560708,"text":"\nYou can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitor"},{"document_id":"ibmcld_10189-3187-5240","score":12.0421731842,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_master"},{"document_id":"ibmcld_05754-3185-5238","score":12.0421731842,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_master"},{"document_id":"ibmcld_10642-1365-3347","score":11.9923745755,"text":"\nThen, [update the worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) for any potential impact and choose to safely use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10246-14143-16190","score":11.8837966933,"text":"\nCheck the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-monitor"},{"document_id":"ibmcld_06209-2829-4687","score":11.8729427432,"text":"\nIn any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) for any potential impact and choose to safely use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n![Master update process diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/\/images\/updating-master2.svg)\n\nFigure 1. Updating Kubernetes master process diagram\n\n\n\n\n\n Steps to update the cluster master \n\nBefore you begin, make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\nTo update the Kubernetes master major or minor version:\n\n\n\n1. Review the [Kubernetes changes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) and make any updates marked Update before master.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10246-15672-17685","score":11.8725226973,"text":"\nDuring the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n\n\n Disabling remote health reporting \n\nOpenShift Container Platform collects anonymized health reports about your cluster through a [telemetry component that is enabled by default](https:\/\/docs.openshift.com\/container-platform\/4.11\/support\/remote_health_monitoring\/about-remote-health-monitoring.html) in your Red Hat OpenShift on IBM Cloud cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-monitor"},{"document_id":"ibmcld_10290-70537-72315","score":11.8645641435,"text":"\nibmcloud oc cluster master refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nApply configuration changes for the Kubernetes master that are requested with the ibmcloud oc cluster master commands. The highly available Kubernetes master components are restarted in a rolling restart. Your worker nodes, apps, and resources are not modified and continue to run.\n\nThe apiserver-refresh and cluster-refresh aliases for this command are deprecated.\n\nibmcloud oc cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud oc cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\nUpdate the Kubernetes master and API server. During the update, you can't access or change the cluster. Worker nodes, apps, and resources that were deployed are not modified and continue to run.\n\nYou might need to change your YAML files for future deployments. Review this [release note](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) for details.\n\nThe cluster-update alias for this command is deprecated.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--version MAJOR.MINOR.PATCH\n: Optional: The Kubernetes version of the cluster. If you don't specify a version, the Kubernetes master is updated to the default API version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_10189-1607-3670","score":11.8572446063,"text":"\nThe status includes a timestamp of how long the master has been in the same state, such as Ready (1 month ago). The Master State reflects the lifecycle of possible operations that can be performed on the master, such as deploying, updating, and deleting. Each state is described in the following table.\n\n\n\nMaster states\n\n Master state Description \n\n deployed The master is successfully deployed. Check the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_master"},{"document_id":"ibmcld_05754-1605-3668","score":11.8572446063,"text":"\nThe status includes a timestamp of how long the master has been in the same state, such as Ready (1 month ago). The Master State reflects the lifecycle of possible operations that can be performed on the master, such as deploying, updating, and deleting. Each state is described in the following table.\n\n\n\nMaster states\n\n Master state Description \n\n deployed The master is successfully deployed. Check the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_master"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10070-7-1616","score":26.0877125124,"text":"\nCIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations.\n\nWhen a new Kubernetes version is released as part of a [supported Red Hat OpenShift version](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions), IBM engineers compare the default configuration of a cluster that runs that Kubernetes version against the benchmark and publishes the results in this documentation. You can review how specific versions of your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters meet the CIS Kubernetes Benchmark.\n\n\n\n Available benchmark versions \n\nUse the list to find CIS Kubernetes Benchmark results for available versions.\n\n\n\n* [Version 4.12](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-412)\n* [Version 4.11](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-411)\n* [Version 4.10](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-410)\n* [Version 4.9](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-49)\n* [Version 4.8](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-48)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark"},{"document_id":"ibmcld_05608-7-1899","score":26.0310916228,"text":"\nCIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations.\n\nWhen a new [Kubernetes version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) is released, IBM engineers compare the default configuration of a cluster that runs that Kubernetes version against the benchmark and publishes the results in this documentation. You can review how specific versions of your IBM Cloud\u00ae Kubernetes Service clusters meet the CIS Kubernetes Benchmark.\n\n\n\n Available benchmark versions \n\nUse the list to find CIS Kubernetes Benchmark results for available versions.\n\n\n\n* [Version 1.27](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-127)\n* [Version 1.26](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-126)\n* [Version 1.25](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125)\n* [Version 1.24](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124)\n* [Version 1.23](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_05612-7-1934","score":25.5397544846,"text":"\nVersion 1.21 CIS Kubernetes benchmark \n\nKubernetes version 1.21 becomes unsupported on 14 September 2022. Update your cluster to at least [version 1.22](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_122) as soon as possible.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.21. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-121"},{"document_id":"ibmcld_05610-7-1993","score":24.8929902826,"text":"\nVersion 1.19 CIS Kubernetes benchmark \n\nKubernetes version 1.19 is unsupported.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.19. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-119"},{"document_id":"ibmcld_05615-7-1945","score":24.884007993,"text":"\nVersion 1.24 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.24. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124"},{"document_id":"ibmcld_05616-7-1945","score":24.884007993,"text":"\nVersion 1.25 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.25. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125"},{"document_id":"ibmcld_05611-7-1955","score":24.8682669382,"text":"\nVersion 1.20 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.20. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-120"},{"document_id":"ibmcld_05613-7-1955","score":24.8682669382,"text":"\nVersion 1.22 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.22. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-122"},{"document_id":"ibmcld_05614-7-1955","score":24.8682669382,"text":"\nVersion 1.23 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.23. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123"},{"document_id":"ibmcld_10077-4-1906","score":24.8197843175,"text":"\np\n\n\n\n Red Hat OpenShift on IBM Cloud version 4.8 CIS Kubernetes Benchmark \n\nThis version is deprecated.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Red Hat OpenShift on IBM Cloud version 4.8 For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cis-benchmark-48"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13480-4908-6825","score":13.5788971073,"text":"\nIncorrect column name specification results in an empty column, that is, the column seems to contain no data. To solve such a problem, use the automatic schema detection, reorder the columns, or omit some columns.\n\nThe SHOW TABLES statement provides you with an overview of the existing tables in your instance. This statement allows an optional search filter to limit the number of results:\n\nSHOW TABLES LIKE 'cus'\n\nIt is not possible to use a different namespace than default.\n\nTo clean up catalog entries for unused data, use the DROP TABLE statement. This statement removes the table definition from the catalog without affecting the actual data on Object Storage:\n\nDROP TABLE customers\n\n\n\n\n\n Partitioned tables \n\nYou can manage a table in the catalog that references data that is organized in multiple partitions on Object Storage. The naming of the objects must adhere to the Hive-style partition naming convention: The object names must include the structure \/columm=value\/. The column must be a column name that is included in the schema definition of the CREATE TABLE statement. You can also have more than one partitioning columns in the object names, such as \/columm1=value\/column2=value\/.\n\nFollowing is an example list of object names on Object Storage that is partitioned on the country column with the Hive-style partition naming convention:\n\ncustomers_partitioned.csv\/country=Germany\/cust-1.csv\ncustomers_partitioned.csv\/country=Germany\/cust-2.csv\ncustomers_partitioned.csv\/country=Spain\/cust-1.csv\ncustomers_partitioned.csv\/country=Austria\/cust-1.csv\ncustomers_partitioned.csv\/country=Austria\/cust-2.csv\ncustomers_partitioned.csv\/country=USA\/cust-1.csv\ncustomers_partitioned.csv\/country=USA\/cust-2.csv\ncustomers_partitioned.csv\/country=USA\/cust-3.csv\ncustomers_partitioned.csv\/country=Sweden\/cust-1.csv\n\nTo query partitioned tables, you must perform two mandatory steps:\n\n\n\n Step 1: Register the table","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_13498-7173-9446","score":12.6018045461,"text":"\nWhen specified in combination with PARTITIONED BY, it sorts the rows within each partition by the sort order that is specified in the SORT BY clause. When specified in combination with PARTITIONED INTO, the same is done, which is often referred to as clustering the rows by the specified columns into the fixed number of partitions specified by PARTITIONED INTO. When specified without the PARTITIONED clause, it is equivalent to an ORDER BY clause specified at the top level of the SQL SELECT statement. If PARTITIONED INTO is specified, the ORDER BY clause is ignored.\n\n\n\n Partition by columns \n\nWhen you use the PARTITIONED BY (column-list) clause without specifying INTO x BUCKETS\/OBJECTS, you can store the query result by using Hive-style partitioning, which is to create partitions that contain only rows that have certain values for one or more columns. Choose this physical layout if the stored object is further analyzed by using SQL queries that specify predicates on the partition columns.\n\nFor example, a result object that contains worldwide order data has a column country to represent the country that the order is initiated from. Partitioning the result object by the column PARTITIONED BY (country), would create a result object with a partition for each country present in the query result.\n\nWhen the result object is stored this way on Cloud Object Storage, each SQL query that contains a predicate, such as country = 'USA' or country in ('MALTA', 'ITALY', 'VATICAN CITY'), benefits from this physical layout. The reason is that during SQL query execution partitions must be read only if they contain data for the countries of interest. This layout tremendously cuts down the I\/O traffic of the SQL query.\n\nSee the following extra remarks on Hive-style partitioning.\n\n\n\n* Hive-style partitions have an eye-catching naming scheme because the column names that are used for partitioning are part of the partition object prefix, for example, \/order\/COUNTRY=USA\/part-m-00000.snappy.parquet.\n* Hive-style partitions do not contain any values for partition columns since their values are stored in the object prefix of the partition. Thus, if you copy a HIVE-style partition and rename the object prefix by removing the partition column values, you lose data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_00576-8941-10714","score":11.9273416367,"text":"\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)\n* [Partitioned databases - data design](https:\/\/blog.cloudant.com\/2019\/03\/05\/Partition-Databases-Data-Design.html)\n\n\n\n\n\n\n\n Making the most of the primary index \n\nIBM Cloudant has a primary index on the document's _id attribute. This index allows documents to be retrieved by _id (GET \/db\/id) or a range of _ids (GET \/db\/_all_docs?startkey=\"a\"&endkey=\"z\"). By storing data in the primary key and ensuring that each _id is unique, the primary index can be used to fetch documents and ranges of documents without secondary indexing. See the following list of ideas:\n\n\n\n* If you have something unique in your object that would be useful to query against, use it as your _id field, for example, bob.smith@gmail.com, isbn9780241265543, or oakland,ca.\n* If your objects contain a hierarchy, model that in your _id: usa:ca:oakland or books:fiction:9780241265543. The hierarchy goes from largest to smallest, so you can use the primary index to find all the cities in usa or all the cities in usa:ca, without secondary indexing.\n* If you're storing time-series data, encoding time at the start of your _id sorts the primary index by time, for example, 001j40Ox1b2c1B2ubbtm4CsuLB4L35wQ.\n* Partitioned databases group documents that share a partition key together. A partition key must have many values and must not include hot spots to avoid directing a large proportion of your application's traffic to a few partitions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00381-3303-3948","score":11.6129521745,"text":"\nSierra Leone,\nSan Marino,\nSenegal,\nSomalia,\nSuriname,\nSao Tome and Principe,\nEl Salvador,\nSint Maarten,\nSyrian Arab Republic,\nSwaziland,\nTurks and Caicos Islands,\nChad,\nFrench Southern Territories,\nTogo,\nThailand,\nTajikistan,\nTokelau,\nTurkmenistan,\nTunisia,\nTonga,\nEast Timor,\nTurkey,\nTrinidad and Tobago,\nTuvalu,\nTaiwan,\nTanzania, United Republic of,\nUkraine,\nUganda,\nUSA Minor Outlying Islands,\nUnited States,\nUruguay,\nUzbekistan,\nVatican City State,\nSt Vincent and the Grenadines,\nVenezuela,\nVirgin Islands, British,\nVirgin Islands, U.S.,\nViet Nam,\nVanuatu,\nWallis and Futuna,\nSamoa,\nYemen,\nMayotte,\nSouth Africa,\nZambia,\nZimbabwe\n]\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-geoblocking-class"},{"document_id":"ibmcld_13118-27377-28138","score":11.0833444812,"text":"\nnull 7634piweba3y.prodigy.comGET \/shuttle\/miss... 20001\/Jul\/1995:04:1...\n null25218 ntigate.nt.comGET \/software\/win... 20001\/Jul\/1995:04:1...\n null 4441 ntigate.nt.comGET \/software\/win... 20001\/Jul\/1995:04:1...\n null 1414 ntigate.nt.comGET \/images\/const... 20001\/Jul\/1995:04:1...\n null45308line03.pm1.abb.mi...GET \/shuttle\/miss... 20001\/Jul\/1995:04:1...\n null 669 source.iconz.co.nzGET \/images\/WORLD... 20001\/Jul\/1995:04:1...\n null 234 source.iconz.co.nzGET \/images\/USA-l... 20001\/Jul\/1995:04:1...\n null 363 source.iconz.co.nzGET \/images\/MOSAI... 20001\/Jul\/1995:04:1...\n null13372 ntigate.nt.comGET \/software\/win... 20001\/Jul\/1995:04:1...\n+---------------------------+-----+--------------------+--------------------+------------+--------------------+\n\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analytics"},{"document_id":"ibmcld_13480-6528-8270","score":10.9913112094,"text":"\ncustomers_partitioned.csv\/country=USA\/cust-1.csv\ncustomers_partitioned.csv\/country=USA\/cust-2.csv\ncustomers_partitioned.csv\/country=USA\/cust-3.csv\ncustomers_partitioned.csv\/country=Sweden\/cust-1.csv\n\nTo query partitioned tables, you must perform two mandatory steps:\n\n\n\n Step 1: Register the table \n\nThis data partitioning is reflected in the PARTITIONED BY clause of the following CREATE TABLE statement:\n\nCREATE TABLE customers (\ncustomerID string,\ncompanyName string,\ncontactName string,\ncontactTitle string,\naddress string,\nregion string,\npostalCode string,\ncountry string,\nphone string,\nfax string\n)\nUSING CSV\nPARTITIONED BY (country)\nLOCATION cos:\/\/us-geo\/sql\/customers_partitioned.csv\n\nAutomatic schema detection also recognizes partitioned tables from the structure of the object names, so the same table definition is created from the following statement:\n\nCREATE TABLE customers\nUSING CSV\nLOCATION cos:\/\/us-geo\/sql\/customers_partitioned.csv\n\nIf your data on Object Storage does not adhere to this naming convention, you can convert it to a Hive-partitioned layout by using Data Engine in a data preparation step. Use SELECT * to copy the data to a new location and specify [PARTITION BY](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencepartitionedClause) in the INTO clause:\n\nSELECT * FROM cos:\/\/us-geo\/sql\/customers.csv\nINTO cos:\/\/us-geo\/mybucket\/customers_partitioned.csv\nPARTITIONED BY (country)\n\n\n\n\n\n Step 2: Attach table partitions \n\nAfter you defined a partitioned table, it is initially empty and you must attach the partitions to it explicitly. A convenient way to add all partitions that exist on Object Storage, is to use the following RECOVER PARTITIONS clause.\n\nALTER TABLE customers RECOVER PARTITIONS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_10041-7462-8947","score":10.1629078732,"text":"\nGET\/v2\/getFlavors List available flavors types for a VPC zone (data center). N\/A N\/A \n GET\/v2\/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N\/A \n GET\/v2\/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET\/v2\/getOperatingSystems Get a list of available worker node operating systems. N\/A cluster-worker-pool-supported-operating-systems.get \n GET\/v2\/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET\/v2\/vpc\/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPC View details of a VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-7444-8929","score":10.1629078732,"text":"\nGET\/v2\/getFlavors List available flavors types for a VPC zone (data center). N\/A N\/A \n GET\/v2\/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N\/A \n GET\/v2\/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET\/v2\/getOperatingSystems Get a list of available worker node operating systems. N\/A cluster-worker-pool-supported-operating-systems.get \n GET\/v2\/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET\/v2\/vpc\/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPC View details of a VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_10041-38301-39909","score":10.0246522653,"text":"\nPOST\/v2\/rebalanceWorkerPool Rebalance workers in a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/removeWorker Delete a worker node from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.account.delete \n POST\/v2\/removeWorkerPool Removes a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.delete \n POST\/v2\/replaceWorker Replace a worker node with a new worker node. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/resizeWorkerPool Resize an existing worker pool. containers-kubernetes.cluster.operate containers-kubernetes.workerpool.update \n POST\/v2\/setWorkerPoolLabels Set custom labels for a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/setWorkerPoolTaints Set custom taints for a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/vpc\/createWorkerPool Create a worker pool for a VPC cluster. containers-kubernetes.cluster.operate containers-kubernetes.account.create \n POST\/v2\/vpc\/createWorkerPoolZone Create a zone in the specified worker pool for a VPC cluster. containers-kubernetes.cluster.operate containers-kubernetes.account.create \n POST\/v2\/vpc\/replaceWorker Replace a worker node with a new worker node. containers-kubernetes.cluster.operate containers-kubernetes.account.create \n PUT\/v1\/clusters\/{idOrName}\/workers\/{workerId} Reboot, reload, or update a worker node for a cluster. containers-kubernetes.cluster.operate containers-kubernetes.worker.update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-38267-39875","score":10.0246522653,"text":"\nPOST\/v2\/rebalanceWorkerPool Rebalance workers in a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/removeWorker Delete a worker node from a cluster. containers-kubernetes.cluster.operate containers-kubernetes.account.delete \n POST\/v2\/removeWorkerPool Removes a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.delete \n POST\/v2\/replaceWorker Replace a worker node with a new worker node. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/resizeWorkerPool Resize an existing worker pool. containers-kubernetes.cluster.operate containers-kubernetes.workerpool.update \n POST\/v2\/setWorkerPoolLabels Set custom labels for a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/setWorkerPoolTaints Set custom taints for a worker pool. containers-kubernetes.cluster.operate containers-kubernetes.account.update \n POST\/v2\/vpc\/createWorkerPool Create a worker pool for a VPC cluster. containers-kubernetes.cluster.operate containers-kubernetes.account.create \n POST\/v2\/vpc\/createWorkerPoolZone Create a zone in the specified worker pool for a VPC cluster. containers-kubernetes.cluster.operate containers-kubernetes.account.create \n POST\/v2\/vpc\/replaceWorker Replace a worker node with a new worker node. containers-kubernetes.cluster.operate containers-kubernetes.account.create \n PUT\/v1\/clusters\/{idOrName}\/workers\/{workerId} Reboot, reload, or update a worker node for a cluster. containers-kubernetes.cluster.operate containers-kubernetes.worker.update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10046-2975-4892","score":7.7780238346,"text":"\nProfiling is enabled by default in Red Hat OpenShift, but the profiling data is sent via healthz port and the port must be protected by RBAC. \n 1.4.2 Ensure that the --bind-address option is set to 127.0.0.1. Verify that the scheduler API service is protected by authentication and authorization. Red Hat OpenShift has different operator than vanilla kubernetes, and configuration for its security differs \n 4.1.3 Ensure that the proxy kubeconfig file permissions are set to 644 or more restrictive. If proxy kubeconfig file exists,ensure that permissions are set to 644 or more restrictive. In Red Hat OpenShift, the file is automatically created by sdn controller in a secure manner. \n 4.1.4 Ensure that the proxy kubeconfig file ownership is set to root:root. If proxy kubeconfig file exists,ensure that ownership is set to root:root In Red Hat OpenShift, the file is automatically created by sdn controller in a secure manner. \n\n\n\n\n\n\n\n Minor differences \n\n\n\nMinor difference between the CIS Kubernetes Benchmark and the Red Hat OpenShift Compliance Operator Benchmark\n\n Section CIS Kubernetes benchmark Compliance Operator benchmark Description \n\n 1.1.19 Ensure that the Kubernetes PKI directory and file ownership is set to root:root. Ensure that the Red Hat OpenShift PKI directory and file ownership is set to root:root. Kubernetes > Red Hat OpenShift \n 1.1.20 Ensure that the Kubernetes PKI certificate file permissions are set to 644 or more restrictive. Ensure that the Red Hat OpenShift PKI certificate file permissions are set to 644 or more restrictive Kubernetes > Red Hat OpenShift \n 1.1.21 Ensure that the Kubernetes PKI key file permissions are set to 600 Ensure that the Red Hat OpenShift PKI key file permissions are set to 600 Kubernetes > Red Hat OpenShift \n 1.2.4 Ensure that the --kubelet-https option is set to true Use https for kubelet connections. No option specified for Red Hat OpenShift.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmark-comparison"},{"document_id":"ibmcld_10046-7-2003","score":7.631496672,"text":"\nComparing the CIS Kubernetes and the Compliance Operator benchmarks \n\nReview the following tables for an overview of the differences between the CIS Kubernetes and the compliance operator benchmarks.\n\n\n\n Major differences \n\n\n\nMajor difference between the CIS Kubernetes Benchmark and the Red Hat OpenShift Compliance Operator Benchmark\n\n Section CIS Kubernetes benchmark Compliance Operator benchmark Description \n\n 1.2.1 Ensure that the --anonymous-auth option is set to false. Ensure that anonymous requests are authorized. Different approaches to achieve the same purpose. \n 1.2.10 Ensure that the admission control plug-in EventRateLimit is set. Ensure that the APIPriorityAndFairness feature gate is enabled. Different approaches to achieve the same purpose. \n 1.2.12 Ensure that the admission control plug-in AlwaysPullImages is set. Ensure that the admission control plug-in AlwaysPullImages is not set AlwaysPullImages causes error on Red Hat OpenShift. \n 1.2.13 Ensure that the admission control plug-in SecurityContextDeny is set if PodSecurityPolicy is not used. Ensure that the admission control plug-in SecurityContextDeny is not set SecurityContextDeny admission controller can't be enabled as it conflicts with the SecurityContextConstraint admission controller. \n 1.2.16 Ensure that the admission control plug-in PodSecurityPolicy is set. Ensure that the admission control plug-in SecurityContextConstraint is set. SecurityContextConstraint is unique to Red Hat OpenShift \n 1.2.21 Ensure that the --profiling option is set to false. Ensure that the healthz endpoint is protected by RBAC. Profiling is enabled by default in Red Hat OpenShift, but the profiling data is sent through the healthz port and the port must be protected by RBAC. \n 1.2.23 Ensure that the --audit-log-maxage option is set to 30 or as appropriate. Ensure that the audit logs are forwarded off the cluster for retention. Red Hat OpenShift has an operator for logging instead of retaining logs in the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-benchmark-comparison"},{"document_id":"ibmcld_10392-139958-141622","score":7.0475246322,"text":"\n* containers-kubernetes.logging-autoupdate.changed\n* containers-kubernetes.masterlog-retrieve\n* containers-kubernetes.masterlog-status\n* containers-kubnertes.cluster.rbac.update\n* containers-kubernetes.service.create\n* containers-kubernetes.service.delete\n* containers-kubernetes.subnet.add\n* containers-kubernetes.subnet.create\n* containers-kubernetes.subnet.update\n* containers-kubernetes.vlan.create\n* containers-kubernetes.vlan.delete\n* containers-kubernetes.worker.create\n* containers-kubernetes.worker.delete\n* containers-kubernetes.worker.update\n* containers-kubernetes.workerpool.create\n* containers-kubernetes.workerpool.delete\n* containers-kubernetes.workerpool.update\n* containers-kubernetes.zone.delete\n* containers-kubernetes.zone.update\n\n\n\nDeprecated fields across events\n: The following fields are deprecated and replaced by or updated with new values across events.\n\n\n\n* The correlationID is replaced by correlationId to align with field casing standards.\n* The resourceGroupID field is no longer used. Instead, the resource group ID can be found in the target.resourceGroupId field.\n* The reason.reasonCode field is now formatted as an integer (int) instead of string (string).\n* The requestData field is now formatted as a JSON object instead of a JSON string.\n* The responseData field is now formatted as a JSON object instead of string.\n* The target.typeURI values are updated for consistency. All values now have a prefix of containers-kubernetes\/ instead of container\/. For example, container\/cluster is now containers-kubernetes\/cluster and container\/worker is now containers-kubernetes\/worker.\n\n\n\n\n\n\n\n 16 March 2021 \n\nIngress ALB change log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-relnotes"},{"document_id":"ibmcld_10041-7462-8947","score":6.9237441726,"text":"\nGET\/v2\/getFlavors List available flavors types for a VPC zone (data center). N\/A N\/A \n GET\/v2\/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N\/A \n GET\/v2\/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET\/v2\/getOperatingSystems Get a list of available worker node operating systems. N\/A cluster-worker-pool-supported-operating-systems.get \n GET\/v2\/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET\/v2\/vpc\/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPC View details of a VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-7444-8929","score":6.9237441726,"text":"\nGET\/v2\/getFlavors List available flavors types for a VPC zone (data center). N\/A N\/A \n GET\/v2\/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N\/A \n GET\/v2\/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET\/v2\/getOperatingSystems Get a list of available worker node operating systems. N\/A cluster-worker-pool-supported-operating-systems.get \n GET\/v2\/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET\/v2\/vpc\/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPC View details of a VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_05608-1309-3624","score":6.9024952445,"text":"\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.\n\n\n\n What does the benchmark cover? \n\nThe benchmark covers recommendations for master components, etcd, control plane configurations, worker nodes, and policies such as for users, network, and pod security.\n\n\n\n\n\n What do the benchmark recommendations mean? \n\nThe benchmark recommendations have scoring, levels, result status, and responsibilities as follows.\n\n\n\n* Scoring\n\n\n\n* Scored: The overall benchmark score increases or decreases depending on whether the recommendation is met.\n* Not scored: The overall benchmark score is not impacted, whether the recommendation is met.\n\n\n\n* Levels\n\n\n\n* Level 1: Practical security measures that can be configured without inhibiting the service.\n* Level 2: More in-depth security measures that might reduce the performance or functionality of a service.\n\n\n\n* Result\n\n\n\n* Pass: The service complies with the benchmark recommendation.\n* Fail: The service does not comply with the benchmark recommendation by default. Refer to the remediation section for an explanation and possible actions that you can take to comply with the benchmark recommendation.\n\n\n\n* Responsibility\n\n\n\n* IBM: IBM is responsible for configuring the setting that the benchmark recommends.\n* Shared: You and IBM share responsibility for configuring the setting that the benchmark recommends.\n\n\n\n\n\n\n\n\n\n What parts of the benchmark am I responsible for? \n\nBecause IBM Cloud Kubernetes Service is a managed offering, IBM already configures many security settings for you. For example, IBM manages and automatically applies updates to your cluster master. For your worker nodes, IBM provides security and version updates, but you must apply the updates. You are also responsible for your workload applications and data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_09785-11224-13266","score":6.8760590266,"text":"\n* New configuration panel allowing you to include or exclude a set of labels for a cluster or namespace.\n* Adding the ability to label IPs not mapped to Kubernetes or OpenShift entities.\n* Adding the ability to to configure internal subnets for clusters.\n* Adding additional information when hovering over a network connection or network node.\n* Adding unresolved IP filtering.\n* Adding Network as an item in the navigation.\n\n\n\n\n\n\n\n 1 June 2021 \n\nPromQL library\n: A library of PromQL queries now available.\n\nPrometheus remote write\n: Prometheus remote write support is now supported for ingesting metrics.\n\nImproved dashboard templates\n: Dashboard templates have been improved for better data display and improved results.\n\n\n\n\n\n 27 May 2021 \n\nSecure beta support for Falco policy tuner\n: A managed version of the Falco policy tuner is new available.\n\n\n\n\n\n 19 May 2021 \n\nSecure compliance support\n: New compliance features for ISO27001:2013 and HIPAA are available.\n\nSecure support for Inline Scanner\n: V2.4.1 is supported.\n\n\n\n\n\n 18 May 2021 \n\nSecure updates for new and improved host OS and container scanning tools\n: Functional updates include:\n\n\n\n* The ability to scan hosts in addition to container images.\n* Host benchmarks have been updated with additional checks and cluster aggregation.\n* Image scanning is updated to automatically scan images if they have not been scanned.\n\n\n\n\n\n\n\n 10 May 2021 \n\nSilencing alert notifications\n: You can silence alert notifications for a given scope or period of time.\n\nNew Kubernetes labels\n: The following labels have been added that can be used to scope dashboards and configure groups.\n\n\n\n* kubernetes.workload.name\n* kubernetes.workload.type\n\n\n\nNew Kubernetes dashboards\n: A number of new Kubernetes dashboards are available in beta.\n\n\n\n\n\n 29 April 2021 \n\nSecure updates to scan results page\n: The layout of the scan results page has been reorganize to clearly distinguish policy evaluation from vulnerability matching and better summarize the information.\n\n\n\n\n\n 26 April 2021 \n\nExtended label set","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-monitoring-release-notes"},{"document_id":"ibmcld_06279-79845-81330","score":6.8617528123,"text":"\nList your Kubernetes services and find the name of the LoadBalancer service you want to change.\n\nkubectl get services\n\nExample output.\n\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nmy-load-balancer LoadBalancer 172.21.77.198 52.118.150.107 8080:32767\/TCP,443:30943\/TCP 5d\n3. Find the VPC load balancer that corresponds with the Kubernetes LoadBalancer service.\n\nVPC load balancer names are in the format kube-<cluster_ID>-<kubernetes_lb_service_UID>. To see your cluster ID, run ibmcloud ks cluster get --cluster <cluster_name>. To see the Kubernetes LoadBalancer service UID, run kubectl get svc <load-balancer-name> -o yaml and look for the metadata.uid field in the output. The dashes (-) are removed from the Kubernetes LoadBalancer service UID in the VPC load balancer name.\n\nibmcloud is load-balancers\n\nExample output.\n\nID Name Family Subnets Is public Provision status Operating status Resource group\nr000-5aaaa11f6-c111-111f-b2e0-1c11aaaaf0dc0 kube-c441c43d02mb8mg00r70-3e25d0b5bf11111111fe4ca3f11111cb Network subnet-1 true active online default Application\n4. Get the Kubernetes LoadBalancer service definition and save the output as a yaml file called my-lb.yaml.\n\nkubectl describe service my-load-balancer -o yaml\n5. Delete the Kubernetes LoadBalancer service. This also deletes the corresponding VPC load balancer.\n\nkubectl delete service my-load-balancer\n6. Update the Kubernetes LoadBalancer service definition file with the subnet or zone changes you want to implement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-lbaas"},{"document_id":"ibmcld_05653-130131-131729","score":6.8559807195,"text":"\n* containers-kubernetes.logging-config.refresh\n* containers-kubernetes.logging-filter.create\n* containers-kubernetes.logging-filter.delete\n* containers-kubernetes.logging-filter.update\n* containers-kubernetes.logging-autoupdate.changed\n* containers-kubernetes.masterlog-retrieve\n* containers-kubernetes.masterlog-status\n* containers-kubnertes.cluster.rbac.update\n* containers-kubernetes.service.create\n* containers-kubernetes.service.delete\n* containers-kubernetes.subnet.add\n* containers-kubernetes.subnet.create\n* containers-kubernetes.subnet.update\n* containers-kubernetes.vlan.create\n* containers-kubernetes.vlan.delete\n* containers-kubernetes.worker.create\n* containers-kubernetes.worker.delete\n* containers-kubernetes.worker.update\n* containers-kubernetes.workerpool.create\n* containers-kubernetes.workerpool.delete\n* containers-kubernetes.workerpool.update\n* containers-kubernetes.zone.delete\n* containers-kubernetes.zone.update\n\n\n\nDeprecated fields across events\n: The following fields are deprecated and replaced by or updated with new values across events.\n\n\n\n* The correlationID is replaced by correlationId to align with field casing standards.\n* The resourceGroupID field is no longer used. Instead, the resource group ID can be found in the target.resourceGroupId field.\n* The reason.reasonCode field is now formatted as an integer (int) instead of string (string).\n* The requestData field is now formatted as a JSON object instead of a JSON string.\n* The responseData field is now formatted as a JSON object instead of string.\n* The target.typeURI values are updated for consistency.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-containers-relnotes"},{"document_id":"ibmcld_10686-79500-81017","score":6.8503177537,"text":"\nList your Kubernetes services and find the name of the LoadBalancer service you want to change.\n\noc get services\n\nExample output.\n\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nmy-load-balancer LoadBalancer 172.21.77.198 52.118.150.107 8080:32767\/TCP,443:30943\/TCP 5d\n3. Find the VPC load balancer that corresponds with the Kubernetes LoadBalancer service.\n\nVPC load balancer names are in the format kube-<cluster_ID>-<kubernetes_lb_service_UID>. To see your cluster ID, run ibmcloud ks cluster get --cluster <cluster_name>. To see the Kubernetes LoadBalancer service UID, run oc get svc <load-balancer-name> -o yaml and look for the metadata.uid field in the output. The dashes (-) are removed from the Kubernetes LoadBalancer service UID in the VPC load balancer name.\n\nibmcloud is load-balancers\n\nExample output.\n\nID Name Family Subnets Is public Provision status Operating status Resource group\nr000-5aaaa11f6-c111-111f-b2e0-1c11aaaaf0dc0 kube-c441c43d02mb8mg00r70-3e25d0b5bf11111111fe4ca3f11111cb Network subnet-1 true active online default Application\n4. Get the Kubernetes LoadBalancer service definition and save the output as a yaml file called my-lb.yaml.\n\noc describe service my-load-balancer -o yaml\n5. Delete the Kubernetes LoadBalancer service. This also deletes the corresponding VPC load balancer.\n\noc delete service my-load-balancer\n6. Update the Kubernetes LoadBalancer service definition file with the subnet or zone changes you want to implement. Do not change the name of the LoadBalancer service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-lbaas"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13309-7-2156","score":8.9255685753,"text":"\nWorking with corpora and custom words for next-generation models \n\nThis information is specific to custom models that are based on next-generation models. For information about corpora and custom words for custom models that are based on previous-generation models, see [Working with corpora and custom words for previous-generation models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-corporaWords).\n\nYou populate a custom language model with words by adding corpora to the model or by adding custom words directly to the model. You use the same methods and operations for both previous- and next-generation models. For more information about adding corpora and custom words to a model, see [Working with corpora for next-generation models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-corporaWords-ngworkingCorpora-ng) and [Working with custom words for next-generation models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-corporaWords-ngworkingWords-ng).\n\nAlthough language model customization is similar in usage and intent for previous- and next-generation models, there are differences between the two types of models at the implementation level. To understand how language model customization works for next-generation models, and how you can make the best use of customization, you need a high-level understanding of the differences.\n\n\n\n* When you create and use a custom language model that is based on a previous-generation model, the service relies on words from the custom model to create transcripts that contain domain-specific terms. In combination with words from its base vocabulary, the service uses these words from the custom model to predict and transcribe speech from audio. You provide the information for a custom language model in the form of corpora, custom words, and grammars. The service stores this information in the words resource for the custom model.\n* When you create a custom language model that is based on a next-generation model, the services relies on sequences of characters from the custom model to create transcripts that reflect domain-specific terms.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-corporaWords-ng"},{"document_id":"ibmcld_09585-8248-9899","score":8.8832705116,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-tutorial-k8s-app"},{"document_id":"ibmcld_06394-8247-9898","score":8.8832705116,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-tutorial-k8s-app"},{"document_id":"ibmcld_06474-8242-9893","score":8.8832705116,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-tutorial-k8s-app"},{"document_id":"ibmcld_06367-8260-9911","score":8.8832705116,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-tutorial-k8s-app"},{"document_id":"ibmcld_06669-8254-9905","score":8.8832705116,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-tutorial-k8s-app"},{"document_id":"ibmcld_06728-8244-9895","score":8.8832705116,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-tutorial-k8s-app"},{"document_id":"ibmcld_06602-8244-9895","score":8.8832705116,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-tutorial-k8s-app"},{"document_id":"ibmcld_06534-8248-9899","score":8.8832705116,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-tutorial-k8s-app"},{"document_id":"ibmcld_04581-8236-9887","score":8.8832705116,"text":"\nChange the image name to the repository name that you got from the previous step:\n\nimage: \"<region>.icr.io\/mynamespace\/<container_name>\" Edit me\n\nNow, under secretKeyRef, change the name of <db-secret-name> to match the name of the secret that was created when you bound your database deployment to your Kubernetes cluster.\n\nsecretKeyRef:\nname: <db-secret-name> Edit me\n\nAs for the service configuration at the end of the file, [nodePort](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) indicates the port that the application can be accessed from. You have ports in the range 30000 - 32767 that you can use, but we chose 30081. The TCP port is set to 8080, which is the port the Node.js application runs on in the container.\n\n\n\n\n\n\n\n Deploying your Kubernetes App \n\n\n\n1. Deploy the application to Kubernetes Service. When you deploy the application, it is automatically bound to your Kubernetes cluster.\n\nkubectl apply -f clouddb-deployment.yaml\n2. Get the IP for the application.\n\nibmcloud ks workers -c <cluster_name>\n\nThe result is something like:\n\nID Public IP PrivateIP Machine Type State Status Zone Version\nkube-hou02-pa1a59e9fd92f44af9b4147a27a31db5c4-w1 199.199.99.999 10.76202.188 free normal Ready hou02 1.10.11_1536\n\nNow you can access the application from the Public IP from port 30082.\n\nThe clouddatabases-helloworld app displays the contents of an examples database. To demonstrate that the app is connected to your service, add some words to the database. The words are displayed as you add them, with the most recently added words displayed first.\n\n\n\n\n\n\n\n Code Structure \n\n\n\nTable 1. Code structure\n\n File Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-tutorial-k8s-app"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11886-2994-4812","score":7.7338748857,"text":"\nFor more information, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/authorization\/).\n\nIf you choose a custom access option, some Satellite Config components might not work. For example, if you grant access to view only certain resources, you cannot use subscriptions to create Kubernetes resources in your cluster group. To view an inventory of your Kubernetes resources in a cluster, Satellite Config must have an appropriate role that is bound to the razee-viewer service account. To deploy Kubernetes resources to a cluster by using subscriptions, Satellite Config must have an appropriate role that is bound to the razee-editor service account.\n\n\n\n\n\n Cluster admin access \n\nGrant the Satellite Config service accounts access to the cluster admin role.\n\nkubectl create clusterrolebinding razee-cluster-admin --clusterrole=razee-cluster-admin --serviceaccount=razeedeploy:razee-viewer --serviceaccount=razeedeploy:razee-editor --serviceaccount=razeedeploy:razee-satcon\n\n\n\n\n\n Custom access, cluster-wide \n\nCreate custom RBAC policies to grant Satellite Config access to the actions and Kubernetes resources that you want for the cluster.\n\n\n\n1. Create a cluster role with the actions and resources that you want to grant. For example, the following command creates a viewer role so that Satellite Config can list all the Kubernetes resources in a cluster, but cannot modify them.\n\nkubectl create clusterrole razee-viewer --verb=get,list,watch --resource=\".\"\n\n\n\nUnderstanding this command's components\n\n Component Description \n\n razee-viewer The name of the cluster role, such as razee-viewer. \n --verb=get,list,watch A comma-separated list of actions that the role authorizes. In this example, the action verbs are for roles typical for a viewer or auditor, get,list,watch.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig"},{"document_id":"ibmcld_11886-4420-6199","score":7.0619799516,"text":"\nkubectl create clusterrole razee-viewer --verb=get,list,watch --resource=\".\"\n\n\n\nUnderstanding this command's components\n\n Component Description \n\n razee-viewer The name of the cluster role, such as razee-viewer. \n --verb=get,list,watch A comma-separated list of actions that the role authorizes. In this example, the action verbs are for roles typical for a viewer or auditor, get,list,watch. For other possible verbs, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/authorization\/determine-the-request-verb). \n --resource=\".\" A comma-separated list of the Kubernetes resources that the role authorizes actions to. In this example, access is granted for all Kubernetes resources in all API groups, \".\". For other possible resources, run kubectl api-resources -o wide. \n\n\n\n2. Create a cluster role binding that binds the Satellite Config service account to the cluster role that you previously created. Now, Satellite Config has the custom access to the cluster.\n\nkubectl create clusterrolebinding razee-viewer --clusterrole=razee-viewer --serviceaccount=razeedeploy:razee-viewer\n\n\n\nUnderstanding this command's components\n\n Component Description \n\n razee-viewer The name of the cluster role binding, such as razee-viewer. \n --clusterrole=razee-viewer The name of the cluster role that you previously created, such as razee-viewer. \n --serviceaccount=razeedeploy:razee-viewer The name of one of the service accounts that the Satellite Config components are set up by default to use, either razeedeploy:razee-viewer or razeedeploy:razee-editor. \n\n\n\n\n\n\n\n\n\n Custom access, scoped to a project \n\nCreate custom RBAC policies to grant Satellite Config access to the actions, Kubernetes resources, and projects (namespaces) that you want.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig"},{"document_id":"ibmcld_05557-5511-7293","score":6.9455720817,"text":"\nIn Kubernetes cluster versions 1.21 and later, Konnectivity replaced the OpenVPN solution. If you have cluster version 1.21 and later, and your webhook uses the ClusterIP, you must update your webhook to use a Kubernetes service instead.\n\nYou can configure a webhook by referencing the webhook app as a Kubernetes service, or by referencing the webhook app as an IP address or publicly registered DNS name.\n\nExample configuration for referencing the webhook app as a Kubernetes service\n\n {: codeblock}\nclientConfig:\ncaBundle: CA_BUNDLE_BASE64\nservice:\nname: admission-webhook\nnamespace: default\npath: \/validate\nport: 443\n\nExample configuration for referencing the webhook app as an IP address or publicly registered DNS name\n\n {: codeblock}\nclientConfig:\ncaBundle: CA_BUNDLE_BASE64\nurl: https:\/\/WEBHOOK_URL:443\/validate\n\nShow more\n\nNote the following limitations for referencing the webhook app as an IP address or DNS name:\n\n\n\n* If the URL is a DNS, then this DNS must be a publicly registered DNS name. Private DNS configurations are not supported.\n* If the URL is an external IP address, which means the webhook service is outside of the cluster, the control plane network is used to connect to the service. The control plane must be able to reach the IP address. If, for example, the IP address is from an on-premises network and the control plane can't reach the IP address, the webhook service does not work.\n* If the URL is a cluster IP address, which means the webhook service is inside of the cluster, the Kubernetes API needs to connect to cluster network. If you have cluster version 1.21 and later, and your webhook uses the cluster IP address, you must update your webhook to use a Kubernetes service instead.\n\n\n\n\n\n\n\n\n\n I need help with a broken webhook. What can I do?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_webhooks"},{"document_id":"ibmcld_10392-139958-141622","score":6.8991556203,"text":"\n* containers-kubernetes.logging-autoupdate.changed\n* containers-kubernetes.masterlog-retrieve\n* containers-kubernetes.masterlog-status\n* containers-kubnertes.cluster.rbac.update\n* containers-kubernetes.service.create\n* containers-kubernetes.service.delete\n* containers-kubernetes.subnet.add\n* containers-kubernetes.subnet.create\n* containers-kubernetes.subnet.update\n* containers-kubernetes.vlan.create\n* containers-kubernetes.vlan.delete\n* containers-kubernetes.worker.create\n* containers-kubernetes.worker.delete\n* containers-kubernetes.worker.update\n* containers-kubernetes.workerpool.create\n* containers-kubernetes.workerpool.delete\n* containers-kubernetes.workerpool.update\n* containers-kubernetes.zone.delete\n* containers-kubernetes.zone.update\n\n\n\nDeprecated fields across events\n: The following fields are deprecated and replaced by or updated with new values across events.\n\n\n\n* The correlationID is replaced by correlationId to align with field casing standards.\n* The resourceGroupID field is no longer used. Instead, the resource group ID can be found in the target.resourceGroupId field.\n* The reason.reasonCode field is now formatted as an integer (int) instead of string (string).\n* The requestData field is now formatted as a JSON object instead of a JSON string.\n* The responseData field is now formatted as a JSON object instead of string.\n* The target.typeURI values are updated for consistency. All values now have a prefix of containers-kubernetes\/ instead of container\/. For example, container\/cluster is now containers-kubernetes\/cluster and container\/worker is now containers-kubernetes\/worker.\n\n\n\n\n\n\n\n 16 March 2021 \n\nIngress ALB change log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-relnotes"},{"document_id":"ibmcld_11886-5796-7575","score":6.7881891226,"text":"\n--serviceaccount=razeedeploy:razee-viewer The name of one of the service accounts that the Satellite Config components are set up by default to use, either razeedeploy:razee-viewer or razeedeploy:razee-editor. \n\n\n\n\n\n\n\n\n\n Custom access, scoped to a project \n\nCreate custom RBAC policies to grant Satellite Config access to the actions, Kubernetes resources, and projects (namespaces) that you want.\n\n\n\n1. Create a role with the actions and resources that you want to grant in the project that you want to scope the role to. For example, the following command creates an editor role so that Satellite Config can deploy and update all the Kubernetes resources in the project.\n\nkubectl create role razee-editor --namespace=default --verb=get,list,watch,create,update,patch,delete --resource=\".\"\n\n\n\nUnderstanding this command's components\n\n Component Description \n\n razee-editor The name of the cluster role, such as razee-editor. \n --namespace default The project (namespace) to scope the role to, such as default. \n --verb=get,list,watch,create,update,patch,delete A comma-separated list of actions that the role authorizes. In this example, the action verbs are for roles typical for an editor, get,list,watch,create,update,patch,delete. For other possible verbs, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/authorization\/determine-the-request-verb). \n --resource=\".\" A comma-separated list of the Kubernetes resources that the role authorizes actions to. In this example, access is granted for all Kubernetes resources in all API groups, \".\". For other possible resources, run kubectl api-resources -o wide. \n\n\n\n2. Create a role binding that binds the Satellite Config service account to the cluster role that you previously created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-clusters-satconfig"},{"document_id":"ibmcld_10041-7462-8947","score":6.7623154095,"text":"\nGET\/v2\/getFlavors List available flavors types for a VPC zone (data center). N\/A N\/A \n GET\/v2\/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N\/A \n GET\/v2\/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET\/v2\/getOperatingSystems Get a list of available worker node operating systems. N\/A cluster-worker-pool-supported-operating-systems.get \n GET\/v2\/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET\/v2\/vpc\/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPC View details of a VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-api-at-iam"},{"document_id":"ibmcld_05567-7444-8929","score":6.7623154095,"text":"\nGET\/v2\/getFlavors List available flavors types for a VPC zone (data center). N\/A N\/A \n GET\/v2\/getKMSInstances Get key management service (KMS) instances tied to an account containers-kubernetes.cluster.read N\/A \n GET\/v2\/getKubeconfig Get the cluster's kubeconfig file. Optionally include the network configuration file. containers-kubernetes.cluster.read containers-kubernetes.account.get \n GET\/v2\/getOperatingSystems Get a list of available worker node operating systems. N\/A cluster-worker-pool-supported-operating-systems.get \n GET\/v2\/getRBACStatus Get the status of an RBAC. containers-kubernetes.cluster.view cluster-rbac.status \n GET\/v2\/vpc\/getCluster Get detailed information for a VPC cluster. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getClusters List the VPC clusters that you have access to. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getSubnets View subnets for a given VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPC View details of a VPC. containers-kubernetes.cluster.read N\/A \n GET\/v2\/vpc\/getVPCs View available VPCs for the infrastructure provider. containers-kubernetes.cluster.read N\/A \n PATCH\/v1\/clusters\/{idOrName}\/addons Enable, disable, or update add-ons for a cluster. containers-kubernetes.cluster.create containers-kubernetes.cluster.update \n PATCH\/v1\/clusters\/{idOrName}\/subnets\/{subnetId} Detach a public or private portable subnet from a cluster. containers-kubernetes.cluster.operate \n POST\/v1\/clusters Create a cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-api-at-iam"},{"document_id":"ibmcld_10646-26054-27582","score":6.7422043816,"text":"\nverbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n\n\n\nTable 3. Understanding the YAML parameters\n\n Parameter Description \n\n kind Use Role to grant access to resources within a specific namespace. Use ClusterRole to grant access to cluster-wide resources such as worker nodes, or to namespace-scoped resources such as pods in all namespaces. \n apiVersion <br><br> * For clusters that run Kubernetes 1.8 or later, use rbac.authorization.k8s.io\/v1.<br> * For earlier versions, use apiVersion: rbac.authorization.k8s.io\/v1beta1.<br><br><br> \n metadata.namespace For kind Role only: Specify the Kubernetes namespace to which access is granted. \n metadata.name Name the role or cluster role. \n rules.apiGroups Specify the Kubernetes [API groups](https:\/\/kubernetes.io\/docs\/reference\/using-api\/api-groups) that you want users to be able to interact with, such as \"apps\", \"batch\", or \"extensions\". For access to the core API group at REST path api\/v1, leave the group blank: [\"\"]. \n rules.resources Specify the Kubernetes [resource types](https:\/\/kubernetes.io\/docs\/reference\/kubectl\/cheatsheet\/) to which you want to grant access, such as \"daemonsets\", \"deployments\", \"events\", or \"ingresses\". If you specify \"nodes\", then the kind must be ClusterRole. \n rules.verbs Specify the types of [actions](https:\/\/kubectl.docs.kubernetes.io\/) that you want users to be able to do, such as \"get\", \"list\", \"describe\", \"create\", or \"delete\". \n\n\n\n2. Create the role or cluster role in your cluster.\n\noc apply -f my_role.yaml\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-users"},{"document_id":"ibmcld_05653-130131-131729","score":6.7377845372,"text":"\n* containers-kubernetes.logging-config.refresh\n* containers-kubernetes.logging-filter.create\n* containers-kubernetes.logging-filter.delete\n* containers-kubernetes.logging-filter.update\n* containers-kubernetes.logging-autoupdate.changed\n* containers-kubernetes.masterlog-retrieve\n* containers-kubernetes.masterlog-status\n* containers-kubnertes.cluster.rbac.update\n* containers-kubernetes.service.create\n* containers-kubernetes.service.delete\n* containers-kubernetes.subnet.add\n* containers-kubernetes.subnet.create\n* containers-kubernetes.subnet.update\n* containers-kubernetes.vlan.create\n* containers-kubernetes.vlan.delete\n* containers-kubernetes.worker.create\n* containers-kubernetes.worker.delete\n* containers-kubernetes.worker.update\n* containers-kubernetes.workerpool.create\n* containers-kubernetes.workerpool.delete\n* containers-kubernetes.workerpool.update\n* containers-kubernetes.zone.delete\n* containers-kubernetes.zone.update\n\n\n\nDeprecated fields across events\n: The following fields are deprecated and replaced by or updated with new values across events.\n\n\n\n* The correlationID is replaced by correlationId to align with field casing standards.\n* The resourceGroupID field is no longer used. Instead, the resource group ID can be found in the target.resourceGroupId field.\n* The reason.reasonCode field is now formatted as an integer (int) instead of string (string).\n* The requestData field is now formatted as a JSON object instead of a JSON string.\n* The responseData field is now formatted as a JSON object instead of string.\n* The target.typeURI values are updated for consistency.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-containers-relnotes"},{"document_id":"ibmcld_05739-8121-9783","score":6.6714866895,"text":"\nTo check your auto update settings, run the ibmcloud ks ingress alb autoupdate get command.<br> * ALB OAuth-Proxy add-on: networking.k8s.io\/v1beta1 is compatible with ALB OAuth-Proxy add-on version 2.0.0 only. If you use the ALB OAuth-Proxy add-on you must update the add-on to version 2.0.0 before updating your cluster to 1.22.<br><br><br> \n Unsupported: Service service.alpha.kubernetes.io\/tolerate-unready-endpoints annotation Services no longer support the service.alpha.kubernetes.io\/tolerate-unready-endpoints annotation. The annotation has been deprecated since Kubernetes version 1.11 and has been replaced by the spec.publishNotReadyAddresses field. If your services rely on this annotation, update them to use the spec.publishNotReadyAddresses field instead. For more information on this field, see [DNS for Services and Pods](https:\/\/kubernetes.io\/docs\/concepts\/services-networking\/dns-pod-service\/). \n\n\n\n\n\n\n\n Update after master \n\nThe following table shows the actions that you must take after you update the Kubernetes master.\n\n\n\nChanges to make after you update the master to Kubernetes 1.22\n\n Type Description \n\n Endpoint Security Mitigation Kubernetes cluster role system:aggregate-to-edit has removed endpoints permissions as a security mitigation for [CVE-2021-25740](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-25740). If your cluster does not require any customizations to the system:aggregate-to-edit cluster role, besides removing the endpoints permission, allow Kubernetes to reconcile the permissions by running the kubectl annotate --overwrite clusterrole\/system:aggregate-to-edit rbac.authorization.kubernetes.io\/autoupdate=true command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_122"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05891-56316-58277","score":11.3782933589,"text":"\nClassic infrastructure\n\nView the pod security admission configuration for a cluster's Kubernetes API server.\n\nibmcloud ks cluster master pod-security get --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Viewer platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security get command \n\nibmcloud ks cluster master pod-security get --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master pod-security policy disable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nDisable the pod security policy for a cluster's Kubernetes API server.\n\nibmcloud ks cluster master pod-security policy disable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security policy disable command \n\nibmcloud ks cluster master pod-security policy disable --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master pod-security policy enable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nEnable the pod security policy for a cluster's Kubernetes API server. Note that pod security policies are not available in clusters that run version 1.25 or later.\n\nibmcloud ks cluster master pod-security policy enable --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-57102-59063","score":11.3782933589,"text":"\nClassic infrastructure\n\nView the pod security admission configuration for a cluster's Kubernetes API server.\n\nibmcloud ks cluster master pod-security get --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Viewer platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security get command \n\nibmcloud ks cluster master pod-security get --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master pod-security policy disable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nDisable the pod security policy for a cluster's Kubernetes API server.\n\nibmcloud ks cluster master pod-security policy disable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security policy disable command \n\nibmcloud ks cluster master pod-security policy disable --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master pod-security policy enable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nEnable the pod security policy for a cluster's Kubernetes API server. Note that pod security policies are not available in clusters that run version 1.25 or later.\n\nibmcloud ks cluster master pod-security policy enable --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_10290-56135-58151","score":11.3719300388,"text":"\nibmcloud oc cluster master pod-security policy disable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nDisable the pod security policy for a cluster's Kubernetes API server.\n\nibmcloud oc cluster master pod-security policy disable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security policy disable command \n\nibmcloud oc cluster master pod-security policy disable --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud oc cluster master pod-security policy enable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nEnable the pod security policy for a cluster's Kubernetes API server. Note that pod security policies are not available in clusters that run version 1.25 or later.\n\nibmcloud oc cluster master pod-security policy enable --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security policy enable command \n\nibmcloud oc cluster master pod-security policy enable --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud oc cluster master pod-security policy get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView the pod security policy configuration for a cluster's Kubernetes API server. Note that pod security policies are not available in clusters that run version 1.25 or later.\n\nibmcloud oc cluster master pod-security policy get --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Viewer platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_05891-57911-59861","score":11.2782201404,"text":"\nibmcloud ks cluster master pod-security policy enable --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security policy enable command \n\nibmcloud ks cluster master pod-security policy enable --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master pod-security policy get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView the pod security policy configuration for a cluster's Kubernetes API server. Note that pod security policies are not available in clusters that run version 1.25 or later.\n\nibmcloud ks cluster master pod-security policy get --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Viewer platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security policy get command \n\nibmcloud ks cluster master pod-security policy get --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master pod-security set \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSet and enable the [pod security admission](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission&interface=ui) for a cluster's Kubernetes API server.\n\nibmcloud ks cluster master pod-security set --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Editor platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-58697-60647","score":11.2782201404,"text":"\nibmcloud ks cluster master pod-security policy enable --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security policy enable command \n\nibmcloud ks cluster master pod-security policy enable --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master pod-security policy get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView the pod security policy configuration for a cluster's Kubernetes API server. Note that pod security policies are not available in clusters that run version 1.25 or later.\n\nibmcloud ks cluster master pod-security policy get --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Viewer platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security policy get command \n\nibmcloud ks cluster master pod-security policy get --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master pod-security set \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSet and enable the [pod security admission](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission&interface=ui) for a cluster's Kubernetes API server.\n\nibmcloud ks cluster master pod-security set --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Editor platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_06153-7-2024","score":11.2141556514,"text":"\nWhy does my cluster upgrade fail due to Pod Security upgrade prerequisites? \n\n What\u2019s happening \n\nWhen you upgrade your IBM Cloud Kubernetes Service from Kubernetes version 1.24 to version 1.25, the upgrade fails and you see an error message similar to the following example.\n\nVersion update cancelled. CAE009: Cannot complete cluster master operations because the cluster does not pass Pod Security upgrade prerequisites. Reason: [ClusterRoleBinding 'restricted-psp-user' does not have expected subjects]. For more information, see the troubleshooting docs: 'https:\/\/ibm.biz\/master_pod_security_upgrade_iks_125'\n\n Why it\u2019s happening \n\nThe Kubernetes PodSecurityPolicy admission controller was removed in Kubernetes 1.25 and replaced with a new Pod Security Admission controller.\n\nTo safely upgrade IBM Cloud Kubernetes Service clusters from version 1.24 to version 1.25, the cluster PodSecurityPolicies (PSP) and associated role-based access control must satisfy the following prerequisites.\n\n\n\n* No PSPs beyond the 5 IBM Cloud defined PSPs can exist.\n* The IBM Cloud defined cluster role bindings that give all users and service accounts authority to use the IBM Cloud defined privileged and restricted PSPs must exist.\n\n\n\nThese prerequisites ensure that the cluster's version 1.24 PodSecurityPolicy configuration is equivalent to version 1.25 Pod Security Admission configuration and the upgrade and switch to Pod Security Admission does not break existing applications. Note these prerequisite do not preclude use of third party pod security providers.\n\nBefore you begin\n\n\n\n* Review the [1.25 version information and update actions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_125).\n* Review the [Migrating from PSPs to Pod Security Admission](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission-migration) guide.\n\n\n\nIf you are not ready to migrate to Pod Security Admission, you can clear the status message by performing a cluster master refresh.\n\n How to fix it","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-app-pod-security"},{"document_id":"ibmcld_10290-57733-59569","score":11.1542817548,"text":"\nClassic infrastructure\n\nView the pod security policy configuration for a cluster's Kubernetes API server. Note that pod security policies are not available in clusters that run version 1.25 or later.\n\nibmcloud oc cluster master pod-security policy get --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Viewer platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security policy get command \n\nibmcloud oc cluster master pod-security policy get --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud oc cluster master pod-security set \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSet and enable the [pod security admission](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission&interface=ui) for a cluster's Kubernetes API server.\n\nibmcloud oc cluster master pod-security set --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Editor platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security set command \n\nibmcloud oc cluster master pod-security set --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud oc cluster master pod-security unset \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nRemove the [pod security admission](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission&interface=ui) configuration for a cluster's Kubernetes API server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"},{"document_id":"ibmcld_05891-59427-61300","score":11.1266460532,"text":"\nSet and enable the [pod security admission](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission&interface=ui) for a cluster's Kubernetes API server.\n\nibmcloud ks cluster master pod-security set --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Editor platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security set command \n\nibmcloud ks cluster master pod-security set --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master pod-security unset \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nRemove the [pod security admission](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission&interface=ui) configuration for a cluster's Kubernetes API server.\n\nibmcloud ks cluster master pod-security unset --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Editor platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security unset command \n\nibmcloud ks cluster master pod-security unset --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master private-service-endpoint allowlist \n\nManage a private cloud service endpoint allowlist so that authorized users can access your private cloud service endpoint from only the subnets that are specified in the allowlist.\n\n\n\n ibmcloud ks cluster master private-service-endpoint allowlist add \n\nVirtual Private Cloud\n\nClassic infrastructure","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli"},{"document_id":"ibmcld_04489-60213-62086","score":11.1266460532,"text":"\nSet and enable the [pod security admission](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission&interface=ui) for a cluster's Kubernetes API server.\n\nibmcloud ks cluster master pod-security set --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Editor platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security set command \n\nibmcloud ks cluster master pod-security set --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master pod-security unset \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nRemove the [pod security admission](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-pod-security-admission&interface=ui) configuration for a cluster's Kubernetes API server.\n\nibmcloud ks cluster master pod-security unset --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Editor platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security unset command \n\nibmcloud ks cluster master pod-security unset --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master private-service-endpoint allowlist \n\nManage a private cloud service endpoint allowlist so that authorized users can access your private cloud service endpoint from only the subnets that are specified in the allowlist.\n\n\n\n ibmcloud ks cluster master private-service-endpoint allowlist add \n\nVirtual Private Cloud\n\nClassic infrastructure","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-kubernetes-service-cli"},{"document_id":"ibmcld_10290-54697-56544","score":11.0940128645,"text":"\n: Viewer platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n--provider (classic | vpc-gen2)\n: Optional: Filter output based on infrastructure provider type.\n\n-l, --location LOCATION\n: Filter output by a specific location. To see supported locations, run ibmcloud oc locations. To specify multiple locations, use one option for each location, such as -l dal -l seo.\n\n--output json\n: Optional: Prints the command output in JSON format. Note: If you don't include the --provider option, only classic clusters are returned.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster ls command \n\nibmcloud oc cluster ls -l ams03 -l wdc -l ap\n\n\n\n\n\n\n\n ibmcloud oc cluster master pod-security get \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nView the pod security admission configuration for a cluster's Kubernetes API server.\n\nibmcloud oc cluster master pod-security get --cluster CLUSTER [--output OUTPUT] [-q]\n\nMinimum required permissions\n: Viewer platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--output json\n: Optional: Prints the command output in JSON format.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n Example cluster master pod-security get command \n\nibmcloud oc cluster master pod-security get --cluster mycluster\n\n\n\n\n\n\n\n ibmcloud oc cluster master pod-security policy disable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nDisable the pod security policy for a cluster's Kubernetes API server.\n\nibmcloud oc cluster master pod-security policy disable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12814-3598-4802","score":8.8926723963,"text":"\nTo maintain security, do not include any personal information, sensitive data, or device or service credentials in case responses. For example, don't include passwords, API keys, secrets, or credit card information.\n6. The following steps are optional:\n\n\n\n* Attach files and resources to provide more details about the issue you're experiencing.\n* If you'd like a user in you account to be updated about the case, add them by using the Contact watchlist. For more information about assigning users access to your account, see [Adding users to your case management access group](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-accessadd-user-access-group).\n* Select Email me updates about this case to receive support case notifications.\n\n\n\n7. Click Next, review your case summary, and click Submit case. After you receive email verification for the case, follow the instructions for further communication on the issue.\n\n\n\nAfter your support case is created, you can follow its progress on the [Manage cases page](https:\/\/cloud.ibm.com\/unifiedsupport\/cases). For more information, see [Managing your support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-managing-support-cases).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-pc-support"},{"document_id":"ibmcld_12814-2351-4052","score":8.7158502366,"text":"\nIf you're experiencing issues with Partner Center, you can create a support case by using the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nTo create a support case, you must have a Pay-As-You-Go or Subscription account. Also, ensure that you're assigned at least the editor role on the Support Center account management service to create, edit, or view support cases. For more information about actions and roles for account management services, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-servicesaccount-management-actions-roles) or to assign other users access, see [Assigning user access for working with support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-access).\n\nTo create a support case for Partner Center related issues, complete the following steps:\n\n\n\n1. Click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/icons\/help.svg) > Support center from the console menu bar.\n2. From the Contact support section, click Create a case.\n3. Select All products.\n4. Select Partner Center - Sell as the topic and click Next.\n5. Complete the required fields.\n\nTo maintain security, do not include any personal information, sensitive data, or device or service credentials in case responses. For example, don't include passwords, API keys, secrets, or credit card information.\n6. The following steps are optional:\n\n\n\n* Attach files and resources to provide more details about the issue you're experiencing.\n* If you'd like a user in you account to be updated about the case, add them by using the Contact watchlist.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-pc-support"},{"document_id":"ibmcld_05818-2659-4377","score":8.5879963301,"text":"\n* See [Getting help](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) for more details about using the forums.\n\n\n\n\n\n\n\n\n\n Contacting support \n\nBefore you open a support case, gather relevant information about your cluster environment.\n\n\n\n1. Get your cluster details.\n\nibmcloud ks cluster get -c <cluster_name_or_ID>\n2. If your issue involves worker nodes, get the worker node details.\n\n\n\n1. List all worker nodes in the cluster, and note the ID of any worker nodes with an unhealthy State or Status.\n\nibmcloud ks worker ls -c <cluster_name_or_ID>\n2. Get the details of the unhealthy worker node.\n\nibmcloud ks worker get -w <worker_ID> -c <cluster_name_or_ID>\n\n\n\n3. For issues with resources within your cluster such as pods or services, log in to the cluster and use the Kubernetes API to get more information about them.\n\nYou can also use the [IBM Cloud Kubernetes Service Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) to gather and export pertinent information to share with IBM Support.\n4. Contact IBM Support by [opening a case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form). To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n5. For the Problem type, search for or select Kubernetes Service.\n6. For the Case details, provide a descriptive title and include the details that you previously gathered. From the Resources, you can also select the cluster that the issue is related to.\n\n\n\n\n\n\n\n Requesting access to allowlisted features \n\n\n\n1. [Create a ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help"},{"document_id":"ibmcld_08063-1403-3121","score":8.5683691001,"text":"\nTechnical support for Lite accounts with free support is provided by the [IBM Cloud docs](https:\/\/cloud.ibm.com\/docs) and [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud?tab=Newest).\n\nBy default, account users don't have access to create, update, search, or view cases. The account owner must provide users access by assigning an Identity and Access Management (IAM) access policy. For more information, see [Assigning user access for working with support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-accessaccess).\n\n\n\n Creating a support case \n\nComplete the following steps to create a support case:\n\n\n\n1. From the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9147bc2ffd9bafd03e4559b378e714fac17a4977\/icons\/help.svg) > Support center.\n2. From the Contact support section, click Create a case.\n3. Select the category for your issue.\n4. Select the topic and the associated subtopic that is most closely related to your issue, and click Next.\n5. Complete the required fields.\n\nTo maintain security, do not include any personal information, sensitive data, or device or service credentials in case responses. For example, don't include passwords, API keys, secrets, or credit card information.\n6. Optional:\n\n\n\n* Attach files and resources to provide more details about the issue you're experiencing.\n* If you'd like a user in you account to be updated about the case, add them by using the Contact watchlist. For more information about assigning users access to your account, see [Adding users to your case management access group](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-accessadd-user-access-group).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui"},{"document_id":"ibmcld_14241-0-1025","score":8.3738141861,"text":"\n\n\n\n\n\n\n  Contacting IBM Support \n\nIf you need help with IBM Cloud\u00ae for VMware as a Service, create a case from the IBM Cloud Support Center to get assistance.\n\n\n\n  Procedure to create a case for VMware as a Service \n\n\n\n1.  Go to the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n2.  Log in with your IBMid account.\n3.  Select All Products and type VMware as a Service where prompted for the product name, then click IBM Cloud for VMware as a Service.\n4.  Review the various solutions offered. If you do not see an answer to your problem, click Create a case.\n5.  On the New support case page, provide the following information:\n\n\n\n1.  Enter a subject for your issue.\n2.  Describe your issue in detail, such as the error messages, steps to re-create, and the URL that you are accessing.\n3.  Under Add attachments, upload screen captures of the issue.\n4.  If you want to be notified of updates on the issue, select the Email me updates about this case checkbox.\n\n\n\n6.  Click Submit.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-support"},{"document_id":"ibmcld_10227-2655-4315","score":8.3371138129,"text":"\n* See [Getting help](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) for more details about using the forums.\n\n\n\n\n\n\n\n\n\n Contacting support \n\nBefore you open a support case, gather relevant information about your cluster environment.\n\n\n\n1. Get your cluster details.\n\nibmcloud oc cluster get -c <cluster_name_or_ID>\n2. If your issue involves worker nodes, get the worker node details.\n\n\n\n1. List all worker nodes in the cluster, and note the ID of any worker nodes with an unhealthy State or Status.\n\nibmcloud oc worker ls -c <cluster_name_or_ID>\n2. Get the details of the unhealthy worker node.\n\nibmcloud oc worker get -w <worker_ID> -c <cluster_name_or_ID>\n\n\n\n3. For issues with resources within your cluster such as pods or services, log in to the cluster and use the Kubernetes API to get more information about them.\n\nYou can also use the [IBM Cloud Kubernetes Service Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool) to gather and export pertinent information to share with IBM Support.\n4. Contact IBM Support by [opening a case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form). To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n5. For the Problem type, search for or select Red Hat OpenShift on IBM Cloud.\n6. For the Case details, provide a descriptive title and include the details that you previously gathered. From the Resources, you can also select the cluster that the issue is related to.\n\n\n\n\n\n\n\n Requesting access to allowlisted features \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help"},{"document_id":"ibmcld_06180-0-1064","score":8.3349508732,"text":"\n\n\n\n\n\n\n  Why does the Ingress status show an ESSSMI error? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\n  What\u2019s happening \n\nWhen you check the status of your cluster's Ingress components by running the ibmcloud ks ingress status-report get command, you see an error similar to the following example.\n\nCould not access Secrets Manager instance (ESSSMI).\n\n  Why it\u2019s happening \n\nIBM Cloud Kubernetes Service receives an unauthorized message when attempting to update or apply secrets from the Secrets Manager instance registered with the cluster.\n\n  How to fix it \n\n\n\n1.  Follow the steps to ensure you have a valid [service-to-service authorization policy](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-secrets-mgrsecrets-mgr_setup_s2s) in place for the Kubernetes Service and Secrets Manager.\n2.  If the issue persists, contact support. Open a [support case](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar). In the case details, be sure to include any relevant log files, error messages, or command outputs.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-ingress-esssmi"},{"document_id":"ibmcld_08063-2713-4328","score":8.1367211541,"text":"\n* Attach files and resources to provide more details about the issue you're experiencing.\n* If you'd like a user in you account to be updated about the case, add them by using the Contact watchlist. For more information about assigning users access to your account, see [Adding users to your case management access group](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-accessadd-user-access-group).\n* Select Email me updates about this case to receive support case notifications.\n\n\n\n7. Click Next, review your case summary, and click Submit case. After you receive email verification for the case, follow the instructions for further communication on the issue.\n\n\n\nAfter your support case is created, you can follow its progress on the [Manage cases page](https:\/\/cloud.ibm.com\/unifiedsupport\/cases).\n\n\n\n\n\n Creating a support case by using the API \n\nYou can programmatically open a support case by calling the Case Management API as shown in the following sample requests. For more information about the API, see [Case Management](https:\/\/cloud.ibm.com\/apidocs\/case-managementcasemanagement-createcase).\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl --location --request POST 'support-center.cloud.ibm.com\/case-management\/v1\/cases' --header 'Content-Type: application\/json' --header 'Content-Type: text\/plain' --data-raw '{ \"type\": \"technical\",\n\"subject\": \"Case subject\",\n\"description\": \"Case description\",\n\"severity\":4,\n\"offering\": {\n\"name\": \"Cloud Object Storage\",\n\"type\": {\n\"group\": \"crn_service_name\",\n\"key\": \"cloud-object-storage\",\n\"kind\": \"service\",\n\"id\": \"dff97f5c-bc5e-4455-b470-411c3edbe49c\"\n}\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui"},{"document_id":"ibmcld_07540-7-2006","score":8.122092802,"text":"\nGetting help and support \n\nIBM Cloud\u00ae Event Notifications provides troubleshooting information to isolate and resolve problems, and also offers support. If you cannot resolve your issue with the troubleshooting guide, open an IBM support case.\n\nBy default, account users don't have access to create, update, search, or view cases. The account owner must provide users access by assigning an IBM Cloud\u00ae Identity and Access Management (IAM) access policy. For more information, see [Assigning user access for working with support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-accessaccess).\n\n\n\n Creating a cloud support case \n\nFor more information, see [Using the Support Center](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\n\n\n Creating a support case for a UI issue \n\nCollecting the following information can help a faster support case resolution for UI issues\n\n\n\n* Provide error codes and reference IDs.\n* Save the full URL of the console when the problem occurred, for example: https:\/\/cloud.ibm.com\/event-notifications\/provision\/ac\n* Include the steps to reproduce the issue, along with your inputs and expected outputs.\n* Note the approximate time that the error occurred.\n* Provide the code version and error details:\n\n\n\n1. Right-click on the console page and select the Inspect or Inspect Element option.\n2. Scroll to the end of the output and copy any errors or stack traces.\n\n\n\n* Provide the network response:\n\n\n\n1. While you inspect the page, click the Network tab.\n2. Refresh the page and reproduce the problem.\n3. Starting at the end of the list, click each request and view the Preview tab. If the request has an \"errors\" node, expand that node to show the full error.\n4. Click the Response tab and include the full response string and the URL that generated the response.\n\n\n\n\n\n\n\n\n\n Creating a support case for non-UI issues \n\nCollect the following information to get a faster support case resolution for non-UI issues:\n\n\n\n* guid\n* sourceName","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-getting-help-and-support"},{"document_id":"ibmcld_10612-0-1064","score":7.9887169115,"text":"\n\n\n\n\n\n\n  Why does the Ingress status show an ESSSMI error? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\n  What\u2019s happening \n\nWhen you check the status of your cluster's Ingress components by running the ibmcloud oc ingress status-report get command, you see an error similar to the following example.\n\nCould not access Secrets Manager instance (ESSSMI).\n\n  Why it\u2019s happening \n\nRed Hat OpenShift on IBM Cloud receives an unauthorized message when attempting to update or apply secrets from the Secrets Manager instance registered with the cluster.\n\n  How to fix it \n\n\n\n1.  Follow the steps to ensure you have a valid [service-to-service authorization policy](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-secrets-mgrsecrets-mgr_setup_s2s) in place for the Kubernetes Service and Secrets Manager.\n2.  If the issue persists, contact support. Open a [support case](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar). In the case details, be sure to include any relevant log files, error messages, or command outputs.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-ingress-esssmi"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15845-18362-19949","score":16.1829354245,"text":"\ninvalid_generation_parameter \n\nMessage: The generation query parameter is invalid.\n\nFor versions on and after 5\/31\/2019, the 'generation' query parameter must be set to 1 to allow VPC API requests for use with generation 1 compute resources and set to 2 to allow VPC API requests for use with generation 2 compute resources.\n\nHow to set the generation parameter\n\nIn the CLI: ibmcloud is target --gen 1\n\nIn the API:\n\ncurl -X GET \"$rias_endpoint\/v1\/regions?version=$version&generation=1\"\n-H \"Authorization: $iam_token\"\n\n\n\n\n\n invalid_id_format \n\nMessage: Bad ID format. Ensure format is correct.\n\nMake sure that the ID you provided does not contain any malformed data.\n\nYou may get this error message if you provide a malformed start query when making a pagination request. For example, GET \/v1\/network_acls?start=23fbba08-ceb3-4cbe-a951-84ff20a06069?version=$version&generation=1 contains two ?s. Fix the query and try again.\n\n\n\n\n\n invalid_route \n\nMessage: The requested route does not exist.\n\nThe requested route on the API URL you provided does not exist. Verify that the URL you specified to call the API endpoint is correct.\n\n\n\n\n\n invalid_request_field \n\nMessage: A field provided in the request is not valid.\n\nFor example, to update the network ACL used by a subnet use the PATCH \/v1\/subnets\/{subnet_id}?version=$version&generation=1 -d '{ \"network_acl\":{ \"id\": \u201c{network_acl_id}\u201d } }\u2019 API.\n\nThe following request would be invalid because \u201cnetworkacl\u201d is not a valid field, PATCH \/v1\/subnets\/{subnet_id}?version=$version&generation=1 -d '{ \"networkacl\":{ \"id\": \u201c{network_acl_id}\u201d } }\u2019","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-rias-error-messages"},{"document_id":"ibmcld_15559-2851-5046","score":16.0460293765,"text":"\nExample message: The value provided for the expires_in field must be between 5 and 3600.\n\n\n\n\n\n missing_field \n\nUsed in any situation where a required header, query parameter, or property is not provided.\n\nmissing_field error code can accompany a 400 HTTP status code.\n\nExample message: A trusted profile ID was not passed in the request body.\n\n\n\n\n\n missing_value \n\nUsed for missing required headers, query parameters, or body properties (identified by the target).\n\nmissing_value error code can accompany a 400 HTTP status code.\n\nExample message: A value such as ibm must be provided in the Metadata-Flavor header.\n\n\n\n\n\n not_found \n\nUsed for headers, query parameters, path parameters, or body properties (identified by the target) that are syntactically valid but refer to a resource that does not exist.\n\nnot_found error code can accompany the following HTTP status codes:\n\n\n\n* 404 for path parameters\n* 400 for all other cases\n\n\n\nExample message: Placement group not found.\n\n\n\n\n\n profile_not_linked \n\nUsed when a trusted profile is not linked to a virtual server instance. This error code is returned only for the POST \/instance_identity\/v1\/iam_token method.\n\nprofile_not_linked error code can accompany a 400 HTTP status code.\n\nExample message: The virtual server instance is not linked to the specified trusted profile.\n\n\n\n\n\n service_error \n\nUsed when the client encounters a service-side issue.\n\nservice_error error code can accompany a 500 HTTP status code.\n\nExample message: An internal error occurred.\n\n\n\n\n\n unauthenticated \n\nUsed when a Bearer token is provided in the Authorization header, but the token is expired, malformed, or otherwise syntactically correct but not valid.\n\nunauthenticated error code can accompany a 401 HTTP status code.\n\nExample message: The provided token is invalid or expired.\n\n\n\n\n\n unauthorized \n\nUsed for headers, parameters, paths, or properties (identified by the target) that are syntactically valid but refer to a resource that you are not authorized to operate on in the requested manner.\n\nunauthorized error code can accompany a 403 HTTP status code.\n\nExample message: The metadata service is not enabled on the provided instance.\n\n\n\n\n\n unknown_field","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-instance-metadata-error-codes"},{"document_id":"ibmcld_13446-15041-17074","score":15.9362018547,"text":"\nAvailability and usage Description \n\n Previous-generation models Not available. \n Next-generation models Generally available or beta for next-generation models that support low latency. For more information, see [Supported next-generation language models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-ngmodels-ng-supported). \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n max_alternatives \n\nAn optional integer that specifies the maximum number of alternative hypotheses that the service returns. By default, the service returns a single final hypothesis. For more information, see [Maximum alternatives](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metadatamax-alternatives).\n\n\n\nTable 17. The max_alternatives parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n model \n\nAn optional model that specifies the language in which the audio is spoken and the rate at which it was sampled: broadband\/multimedia or narrowband\/telephony. By default, en-US_BroadbandModel is used. For more information, see [Using a model for speech recognition](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-use).\n\n\n\nTable 18. The model parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Query parameter of \/v1\/recognize connection request \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n processing_metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"},{"document_id":"ibmcld_03285-5746-7932","score":15.843944825,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16321-5729-7915","score":15.843944825,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_13446-16507-18479","score":15.7434559882,"text":"\nFor more information, see [Using a model for speech recognition](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-use).\n\n\n\nTable 18. The model parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Query parameter of \/v1\/recognize connection request \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n processing_metrics \n\nAn optional boolean that indicates whether the service returns metrics about its processing of the input audio. By default (false), the service returns no processing metrics. For more information, see [Processing metrics](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metricsprocessing-metrics).\n\n\n\nTable 19. The processing_metrics parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Not available. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Not supported \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n processing_metrics_interval \n\nAn optional float of at least 0.1 that indicates the interval at which the service is to return processing metrics. If the processing_metrics parameter is true, the service returns processing metrics every 1.0 seconds by default. For more information, see [Processing metrics](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metricsprocessing-metrics).\n\n\n\nTable 20. The processing_metrics_interval parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Not available. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Not supported \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"},{"document_id":"ibmcld_15845-33451-35257","score":15.6699620232,"text":"\nMessage: Member port is missing.\n\nMember port is a required field. Provide a value for member port.\n\n\n\n\n\n member_not_found \n\nMessage: Member with ID <member_id> cannot be found.\n\nProvide a member ID where the user has read access and read access to the subnet where the member resides.\n\n\n\n\n\n member_over_quota \n\nMessage: Member cannot be created. Quota of member instances under the pool has reached maximum limit.\n\nThe quotas per resource are specified in [Quotas and limits for VPC](https:\/\/cloud.ibm.com\/docs\/vpc-on-classic?topic=vpc-on-classic-quotas).\n\n\n\n\n\n missing_generation_parameter \n\nMessage: The generation query parameter is required.\n\nFor versions on and after 5\/31\/2019, the generation query parameter is required for VPC for generation 1 compute resources API requests.\n\n\n\n\n\n missing_ims_account_id \n\nMessage: There is no classic infrastructure (IMS) account linked to your account.\n\nTo create a Classic Access VPC, your account must be linked to a classic infrastructure (IMS) account. See [Setting up access to your Classic Infrastructure from VPC](https:\/\/cloud.ibm.com\/docs\/vpc-on-classic?topic=vpc-on-classic-setting-up-access-to-your-classic-infrastructure-from-vpc) to learn more.\n\n\n\n\n\n missing_version \n\nMessage: The version parameter is required, and it must be of the form YYYY-MM-DD.\n\nA version parameter is required for all API requests. The version must comply with the format YYYY-MM-DD. For single-digit months or dates, such as January 1st, the version should look like 2019-01-01. The date given in the version parameter must be later than 2019-01-01 but before the current date. Check out these [API examples](https:\/\/cloud.ibm.com\/docs\/vpc-on-classic?topic=vpc-on-classic-creating-a-vpc-using-the-rest-apis) for how to provide the version parameter.\n\n\n\n\n\n network_conflict","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-rias-error-messages"},{"document_id":"ibmcld_09087-8435-10092","score":15.6678792268,"text":"\nPlease see reasons for more details.\",\n\"reasons\":\n{\n\"code\": \"COLLECTION_TOTAL_MISMATCH_ERR\",\n\"message\": \"Collection total does not match number of resources\",\n\"status\": 400,\n\"moreInfo\": \"https:\/\/cloud.ibm.com\/apidocs\/key-protect\"\n}\n]\n}\n]\n}\n\n\n\n\n\n\n\n\n\n 2 - Data in body does not match data required... \n\n\n\n Message \n\nData in body does not match data required by query parameter\n\nReason code: BODY_QUERY_PARAM_MISMATCH_ERR\n\n\n\n\n\n HTTP status code \n\n400 - Bad Request\n\nThe HTTP 400 Bad Request response status code indicates that the server cannot or will not process the request due to something that is perceived to be a client error (e.g., malformed request syntax, invalid request message framing, or deceptive request routing).\n\nThe client should not repeat this request without modification.\n\n\n\n\n\n Context \n\nThis error occurs when an [instance policy](https:\/\/cloud.ibm.com\/apidocs\/key-protectset-instance-policies) is created.\n\nThe query parameter, which specifies the policy (dualAuthDelete, allowedNetwork, or allowedIP), does not match the first policy_type in the resources array.\n\nThe create instance policy request fails because the policy query parameter (dualAuthDelete) does not match the resources.policy_type (badName).\n\n this request fails because the query parameter does not match the resource\n$ curl -X PUT \"https:\/\/us-south.kms.cloud.ibm.com\/api\/v2\/instance\/policies?policy=dualAuthDelete\" -H \"authorization: Bearer $ACCESS_TOKEN\" -H \"bluemix-instance: $KP_INSTANCE_ID\" -H \"content-type: application\/vnd.ibm.kms.policy+json\" -d '{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.policy+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_13446-19419-21379","score":15.5548701923,"text":"\nIf you set the redaction parameter to true, the service automatically forces the smart_formatting parameter to be true, and it disables the keywords, keywords_threshold, max_alternatives, and (for the WebSocket interface) interim_results parameters. For more information, see [Numeric redaction](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-formattingnumeric-redaction).\n\n\n\nTable 22. The redaction parameter\n\n Availability and usage Description \n\n Previous-generation models Beta for US English, Japanese, and Korean. \n Next-generation models Beta for US English, Japanese, and Korean. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n smart_formatting \n\nAn optional boolean that indicates whether the service converts dates, times, numbers, currency, and similar values into more conventional representations in the final transcript. For US English, the feature also converts certain keyword phrases into punctuation symbols. By default (false), smart formatting is not performed. For more information, see [Smart formatting](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-formattingsmart-formatting).\n\n\n\nTable 23. The smart_formatting parameter\n\n Availability and usage Description \n\n Previous-generation models Beta for US English, Japanese, and Spanish (all dialects). \n Next-generation models Beta for US English, Japanese, and Spanish (all dialects). It also also available for the en-WW_Medical_Telephony model when US English audio is recognized. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n speaker_labels \n\nAn optional boolean that indicates whether the service identifies which individuals spoke which words in a multi-participant exchange.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"},{"document_id":"ibmcld_13446-4441-6470","score":15.5370890126,"text":"\nTable 5. The base_model_version parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Query parameter of \/v1\/recognize connection request \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n character_insertion_bias \n\nAn optional float between -1.0 and 1.0 that indicates whether the service is biased to recognize shorter (negative values) or longer (positive values) strings of characters when developing transcription hypotheses. By default, the service uses a default bias of 0.0. The value that you specify represents a change from a model's default. For more information, see [Character insertion bias](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-parsinginsertion-bias).\n\n\n\nTable 6. The character_insertion_bias parameter\n\n Availability and usage Description \n\n Previous-generation models Not available. \n Next-generation models Beta for all models. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n Content-Type \n\nAn optional audio format (MIME type) that specifies the format of the audio data that you pass to the service. The service can automatically detect the format of most audio, so the parameter is optional for most formats. It is required for the audio\/alaw, audio\/basic, audio\/l16, and audio\/mulaw formats. For more information, see [Specifying an audio format](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-audio-formatsaudio-formats-specifying).\n\n\n\nTable 7. The Content-Type parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket content-type parameter of JSON start message","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03285-5746-7932","score":18.0252502853,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16321-5729-7915","score":18.0252502853,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_13790-1284-2889","score":17.8372804434,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_10833-0-1231","score":17.3750501782,"text":"\n\n\n\n\n\n\n  WebSocket \n\nThe preinstalled \/whisk.system\/websocket package for IBM Cloud\u00ae Functions offers a convenient way to post messages to a WebSocket.\n\nThe package includes the following actions.\n\n\n\nTable 1. WebSocket package entities\n\n Entity                          Type     Parameters        Description                                 \n\n \/whisk.system\/websocket         Package  uri               Utilities for communicating with WebSockets \n \/whisk.system\/websocket\/send    Action   uri, payload      Send the payload to the WebSocket URI.      \n\n\n\nIf you plan to send many messages to the same WebSocket URI, creating a package binding with the uri value is suggested. With binding, you don't need to specify the value each time that you use the send action.\n\n\n\n  Send a message to a WebSocket \n\nThe \/whisk.system\/websocket\/send action sends a payload to a WebSocket URI. The parameters are as follows.\n\n\n\nTable 2. WebSocket send action parameters\n\n Parameter  Description                                                                \n\n uri        The URI of the WebSocket server. For example, ws:\/\/mywebsockethost:80.     \n payload    The message to send to the WebSocket.                                      \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocket"},{"document_id":"ibmcld_13790-7-1700","score":17.2324742314,"text":"\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its \/v1\/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST \/v1\/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13455-7-1568","score":17.1949702314,"text":"\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the \/v1\/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13429-163247-165127","score":16.9438778325,"text":"\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https:\/\/github.com\/watson-developer-cloud\/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_16321-12507-14690","score":16.6252477496,"text":"\nDynamically reconfigures the Text to Speech service by applying a set of configuration parameters, which can be based on the conversation flow. For example, you might want to choose a particular voice at a specific point in the conversation.\n\n\n\n parameter description required default \n\n synthesize The Text to Speech service configuration to use when synthesizing audio. The parameters defined by this object are used when connecting to the Text to Speech service for speech synthesis requests. For more information about these parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speechsynthesize-audio-websockets-). yes Current Text to Speech configuration \n update_strategy Specifies the update strategy to use when setting the speech configuration. Possible values include:<br><br><br><br> * replace: Replaces the configuration for the rest of the session. Any root-level fields in the new configuration completely overwrite the previous configuration.<br> * replace_once: Replaces the configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03285-12413-14528","score":16.5734132258,"text":"\n\"parameter name\": \"parameter value\",\n\"parameter name\": \"parameter value\"\n}\n}\n}\n]\n}\n}\nShow more\n\n\n\nEach command type along with its related parameters are described in the following sections.\n\n\n\n command_info.type : configure \n\nDynamically reconfigures the Text to Speech service by applying a set of configuration parameters, which can be based on the dialog or action flow. For example, you might want to choose a particular voice at a specific point in the conversation.\n\n\n\n parameter description required default \n\n synthesize The Text to Speech service configuration to use when synthesizing audio. The parameters defined by this object are used when connecting to the Text to Speech service for speech synthesis requests. For more information about these parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speechsynthesize-audio-websockets-). yes Current Text to Speech configuration \n update_strategy Specifies the update strategy to use when setting the speech configuration. Possible values include:<br><br><br><br> * replace: Replaces the configuration for the rest of the session. Any root-level fields in the new configuration completely overwrite the previous configuration.<br> * replace_once: Replaces the configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_03285-13886-15581","score":16.026086786,"text":"\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.4227898344}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13790-7-1700","score":17.4888349065,"text":"\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its \/v1\/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST \/v1\/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13790-1284-2889","score":17.4692921747,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13455-7-1568","score":17.4118623402,"text":"\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the \/v1\/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_10833-0-1231","score":17.4024742171,"text":"\n\n\n\n\n\n\n  WebSocket \n\nThe preinstalled \/whisk.system\/websocket package for IBM Cloud\u00ae Functions offers a convenient way to post messages to a WebSocket.\n\nThe package includes the following actions.\n\n\n\nTable 1. WebSocket package entities\n\n Entity                          Type     Parameters        Description                                 \n\n \/whisk.system\/websocket         Package  uri               Utilities for communicating with WebSockets \n \/whisk.system\/websocket\/send    Action   uri, payload      Send the payload to the WebSocket URI.      \n\n\n\nIf you plan to send many messages to the same WebSocket URI, creating a package binding with the uri value is suggested. With binding, you don't need to specify the value each time that you use the send action.\n\n\n\n  Send a message to a WebSocket \n\nThe \/whisk.system\/websocket\/send action sends a payload to a WebSocket URI. The parameters are as follows.\n\n\n\nTable 2. WebSocket send action parameters\n\n Parameter  Description                                                                \n\n uri        The URI of the WebSocket server. For example, ws:\/\/mywebsockethost:80.     \n payload    The message to send to the WebSocket.                                      \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_websocket"},{"document_id":"ibmcld_13429-163247-165127","score":16.2941036005,"text":"\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https:\/\/github.com\/watson-developer-cloud\/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13361-1589-2935","score":15.77960095,"text":"\n* For the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the \/v1\/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n\nYou then specify the name of the grammar with the grammar_name parameter in the JSON start message for the active connection. Passing this value with the start message allows you to change the grammar dynamically for each request that you send over the connection.\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/l16;rate=22050',\ngrammar_name: '{grammar_name}'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n* For the [synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http), pass both parameters with the POST \/v1\/recognize method.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio\/flac\" --data-binary @audio-file.flac \"{url}\/v1\/recognize?language_customization_id={customization_id}&grammar_name={grammar_name}\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse"},{"document_id":"ibmcld_03285-5746-7932","score":15.7728994167,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16321-5729-7915","score":15.7728994167,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_13297-4312-5935","score":15.7348563144,"text":"\nTo use the WebSocket interface, you first use the \/v1\/recognize method to establish a connection with the service. You specify parameters such as the language model and any custom models that are to be used for requests that are sent over the connection. You then register event listeners to handle responses from the service. To make a request, you send a JSON text message that includes the audio format and any additional parameters. You pass the audio as a binary message (blob), and then send a text message to signal the end of the audio.\n\nThe following example provides JavaScript code that establishes a connection and sends the text and binary messages for a recognition request. The basic example does not include the code to define all of the necessary event handlers for the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token;\nvar websocket = new WebSocket(wsURI);\n\nwebsocket.onopen = function(evt) { onOpen(evt) };\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/flac'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\nwebsocket.send(JSON.stringify({action: 'stop'}));\n}\nShow more\n\n\n\n\n\n Using the synchronous HTTP interface \n\n[The synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http) provides the simplest way to make a recognition request. You use the POST \/v1\/recognize method to make a request to the service. You pass the audio and all parameters with the single request. The following curl example shows a basic HTTP recognition request:\n\nIBM Cloud","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-basic-request"},{"document_id":"ibmcld_13455-8123-9745","score":15.730371192,"text":"\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token\n+ '&model=es-ES_BroadbandModel';\nvar websocket = new WebSocket(wsURI);\n\nwebsocket.onopen = function(evt) { onOpen(evt) };\nwebsocket.onclose = function(evt) { onClose(evt) };\nwebsocket.onmessage = function(evt) { onMessage(evt) };\nwebsocket.onerror = function(evt) { onError(evt) };\n\nThe client can open multiple concurrent WebSocket connections to the service. The number of concurrent connections is limited only by the capacity of the service, which generally poses no problems for users.\n\n\n\n\n\n Initiate a recognition request \n\nTo initiate a recognition request, the client sends a JSON text message to the service over the established connection. The client must send this message before it sends any audio for transcription. The message must include the action parameter but can usually omit the content-type parameter:\n\naction (required string)\n: Specifies the action to be performed:\n\n\n\n* start begins a recognition request. It can also specify new parameters for subsequent requests. For more information, see [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more).\n* stop signals that all audio for a request has been sent. For more information, see [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop).\n\n\n\ncontent-type (optional string)\n: Identifies the format (MIME type) of the audio data for the request. The parameter is required for the audio\/alaw, audio\/basic, audio\/l16, and audio\/mulaw formats.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.585570075,"ndcg_cut_10":0.8421423593}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03285-5746-7932","score":11.3679255476,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16321-5729-7915","score":11.3679255476,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_13361-1589-2935","score":11.1461449633,"text":"\n* For the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the \/v1\/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n\nYou then specify the name of the grammar with the grammar_name parameter in the JSON start message for the active connection. Passing this value with the start message allows you to change the grammar dynamically for each request that you send over the connection.\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/l16;rate=22050',\ngrammar_name: '{grammar_name}'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n* For the [synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http), pass both parameters with the POST \/v1\/recognize method.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio\/flac\" --data-binary @audio-file.flac \"{url}\/v1\/recognize?language_customization_id={customization_id}&grammar_name={grammar_name}\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse"},{"document_id":"ibmcld_13446-12090-13986","score":11.1069702465,"text":"\nAsynchronous HTTP Not supported \n\n\n\n\n\n\n\n keywords \n\nAn optional array of keyword strings that the service spots in the input audio. By default, keyword spotting is not performed. For more information, see [Keyword spotting](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-spottingkeyword-spotting).\n\n\n\nTable 13. The keywords parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Not available. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n keywords_threshold \n\nAn optional double between 0.0 and 1.0 that indicates the minimum threshold for a positive keyword match. By default, keyword spotting is not performed. For more information, see [Keyword spotting](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-spottingkeyword-spotting).\n\n\n\nTable 14. The keywords_threshold parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Not available. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n language_customization_id \n\nAn optional customization ID for a custom language model that includes terminology from your domain. By default, no custom model is used. For more information, see [Using a custom language model for speech recognition](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-languageUse).\n\n\n\nTable 15. The language_customization_id parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available or beta for all models that support language model customization.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"},{"document_id":"ibmcld_13429-108147-110176","score":10.8095156136,"text":"\n28 January 2019 \n\nNew support for IBM Cloud IAM by WebSocket interface\n: The WebSocket interface now supports token-based Identity and Access Management (IAM) authentication from browser-based JavaScript code. The limitation to the contrary has been removed. To establish an authenticated connection with the WebSocket \/v1\/recognize method:\n\n\n\n* If you use IAM authentication, include the access_token query parameter.\n* If you use Cloud Foundry service credentials, include the watson-token query parameter.\n\n\n\nFor more information, see [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open).\n\n\n\n\n\n 20 December 2018 \n\nNew beta grammars feature for custom language models now available\n: The service now supports grammars for speech recognition. Grammars are available as beta functionality for all languages that support language model customization. You can add grammars to a custom language model and use them to restrict the set of phrases that the service can recognize from audio. You can define a grammar in Augmented Backus-Naur Form (ABNF) or XML Form.\n\nThe following four methods are available for working with grammars:\n\n\n\n* POST \/v1\/customizations\/{customization_id}\/grammars\/{grammar_name} adds a grammar file to a custom language model.\n* GET \/v1\/customizations\/{customization_id}\/grammars lists information about all grammars for a custom model.\n* GET \/v1\/customizations\/{customization_id}\/grammars\/{grammar_name} returns information about a specified grammar for a custom model.\n* DELETE \/v1\/customizations\/{customization_id}\/grammars\/{grammar_name} removes an existing grammar from a custom model.\n\n\n\nYou can use a grammar for speech recognition with the WebSocket and HTTP interfaces. Use the language_customization_id and grammar_name parameters to identify the custom model and the grammar that you want to use. Currently, you can use only a single grammar with a speech recognition request.\n\nFor more information about grammars, see the following documentation:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13712-4613-6343","score":10.6835299008,"text":"\nA customer ID that you specify is associated with the instance of the service whose credentials are used with the request; only credentials for that instance of the service can delete data associated with the ID.\n\nUse the X-Watson-Metadata header with the following methods:\n\n\n\n* With HTTP requests:\n\n\n\n* POST \/v1\/synthesize\n* GET \/v1\/synthesize\n\n\n\nThe customer ID is associated with data that is sent with the request.\n* With WebSocket requests:\n\n\n\n* \/v1\/synthesize\n\n\n\nYou specify the customer ID with the x-watson-metadata query parameter to associate the ID with data that is sent with the request. You must URL-encode the argument to the query parameter, for example, customer_id%3dmy_customer_ID.\n* With requests to add custom words to custom models:\n\n\n\n* POST \/v1\/customizations\/{customization_id}\n* POST \/v1\/customizations\/{customization_id}\/words\n* PUT \/v1\/customizations\/{customization_id}\/words\/{word}\n\n\n\nThe customer ID is associated with the custom words that are added or updated by the request.\n\n\n\n\n\n\n\n Deleting data \n\nTo delete all data that is associated with a customer ID, use the DELETE \/v1\/user_data method. You pass the string customer_id={id} as a query parameter with the request. The following example deletes all data for the customer ID my_customer_ID:\n\nIBM Cloud\n\ncurl -X DELETE -u \"apikey:{apikey}\" \"{url}\/v1\/user_data?customer_id=my_customer_ID\"\n\nIBM Cloud Pak for Data\n\ncurl -X DELETE --header \"Authorization: Bearer {token}\" \"{url}\/v1\/user_data?customer_id=my_customer_ID\"\n\nThe \/v1\/user_data method deletes all data that is associated with the specified customer ID, regardless of the method by which the information was added. The method has no effect if no data is associated with the customer ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-information-security"},{"document_id":"ibmcld_13361-7-1989","score":10.6038180199,"text":"\nUsing a grammar for speech recognition \n\nOnce you create and train your custom language model with your grammar, you can use the grammar in speech recognition requests:\n\n\n\n* Use the language_customization_id query parameter to specify the customization ID (GUID) of the custom language model for which the grammar is defined. A custom model can be used only with the base model for which it is created. If your custom model is based on a model other than the default, you must also specify that base model with the model query parameter. For more information, see [Using the default model](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models-usemodels-use-default). You must issue the request with credentials for the instance of the service that owns the model.\n* Use the grammar_name parameter to specify the name of the grammar. You can specify only a single grammar with a request.\n\n\n\nWhen you use a grammar, the service recognizes only words from the specified grammar. The service does not use custom words that were added from corpora, that were added or modified individually, or that are recognized by other grammars.\n\nFor more information about the languages and models that support grammars and their level of support (generally available or beta), see [Language support for customization](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-custom-support).\n\n\n\n Examples of using a grammar with a custom language model \n\nThe following examples show the use of a grammar with a custom language model for each speech recognition interface:\n\n\n\n* For the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the \/v1\/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse"},{"document_id":"ibmcld_13724-68545-70490","score":10.4857143068,"text":"\nFor more information, see [Understanding customization](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customIntro).\n\nVoices updated for improved speech synthesis\n: The service features improved expressiveness and naturalness for the most frequently used voices. The improvements are based on Recursive Neural Network (RNN)-based prosody prediction from input text. They are made available as a new service engine and voice-model updates for the following languages:\n\n\n\n* en-US_AllisonVoice\n* en-US_LisaVoice\n* en-US_MichaelVoice\n* es-ES_EnriqueVoice\n* fr-FR_ReneeVoice\n\n\n\nNew customization ID parameter for word pronunciation\n: The GET \/v1\/pronunciation method now accepts an optional customization_id query parameter. The parameter obtains a word translation from a specified custom model. If the custom model does not contain the word, the method returns the word's default pronunciation. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\nWhen using the GET \/v1\/pronunciation method without a customization ID and for a language other than US English, you can request a word's pronunciation only in IBM SPR notation. For a language other than US English, you must specify spr with the method's format option.\n\nNew support for audio\/basic audio format\n: The list of supported audio formats now includes audio\/basic, which provides single-channel audio that is encoded using 8-bit u-law (or mu-law) data that is sampled at 8 kHz. For more information, see [Using audio formats](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-audio-formats).\n\nHTTP and WebSocket interfaces can now return warnings\n: The HTTP and WebSocket \/v1\/synthesize methods can return a warnings response that includes messages about invalid query parameters or JSON fields that are included with a request. The format of the warnings changed. The following example shows the previous format:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"},{"document_id":"ibmcld_13429-38145-40029","score":10.4221270366,"text":"\nDifferences exist between the use of the sounds_like field for custom models that are based on next-generation and previous-generation models. For more information about using the sounds_like field with custom models that are based on next-generation models, see [Working with custom words for next-generation models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-corporaWords-ngworkingWords-ng).\n\nImportant: Deprecated customization_id parameter removed from the documentation\n: Important: On [9 October 2018](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notesspeech-to-text-9october2018), the customization_id parameter of all speech recognition requests was deprecated and replaced by the language_customization_id parameter. The customization_id parameter has now been removed from the documentation for the speech recognition methods:\n\n\n\n* \/v1\/recognize for WebSocket requests\n* POST \/v1\/recognize for synchronous HTTP requests (including multipart requests)\n* POST \/v1\/recognitions for asynchronous HTTP requests\n\n\n\nNote: If you use the Watson SDKs, make sure that you have updated any application code to use the language_customization_id parameter instead of the customization_id parameter. The customization_id parameter will no longer be available from the equivalent methods of the SDKs as of their next major release. For more information about the speech recognition methods, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text\/speech-to-textservice-endpoint).\n\n\n\n\n\n 17 March 2022 \n\nGrammar support for next-generation models is now generally available\n: Grammar support is now generally available (GA) for next-general models that meet the following conditions:\n\n\n\n* The models are generally available.\n* The models support language model customization.\n\n\n\nFor more information, see the following topics:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_03109-6402-8167","score":10.4017093127,"text":"\nTo specify the customer ID for any messages sent using the \/message API, include the X-Watson-Metadata: customer_id property in your header. For example:\n\ncurl -X POST -u \"apikey:3Df... ...Y7Pc9\"\n--header\n'Content-Type: application\/json'\n'X-Watson-Metadata: customer_id=abc'\n--data\n'{\"input\":{\"text\":\"hello\"}}'\n'{url}\/v2\/assistants\/{assistant_id}\/sessions\/{session_id}\/message?version=2019-02-28'\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2service-endpoint).\n\nThe customer_id string cannot include the semicolon (;) or equal sign (=) characters. You are responsible for ensuring that each customer ID property is unique across your customers.\n\nOnly the first customer ID value that is passed in the X-Watson-Metadata header is used as the customer_id string for the message log. This customer ID value can be deleted with DELETE \/user_data v1 API calls.\n\nIf you add search to an assistant, user input that is submitted to the assistant is passed to the Discovery service as a search query. If the Watson Assistant integration provides a customer ID, then the resulting \/message API request includes the customer ID in the header, and the ID is passed through to the Discovery \/query API request. To delete any query data that is associated with a specific customer, you must send a separate delete request directly to the Discovery service instance that is linked your the assistant. See the Discovery [information security](https:\/\/cloud.ibm.com\/docs\/discovery\/information-security?topic=discovery-information-security) topic for details.\n\n\n\n\n\n Querying user data \n\nUse the v1 \/logs method filter parameter to search an application log for specific user data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-securing"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16288-1733-3996","score":23.9290873695,"text":"\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16291-1353-3298","score":22.0259969709,"text":"\nClick Users, and then locate and click the user account you want to use for the integration.\n4. Click the Access Keys tab.\n5. Click Generate New Access Key.\n6. Click Show Secret Key, and copy the secret key to a secure location.\n\nYou cannot retrieve the secret key again after you complete the next step and Save. You must generate a new key if the current one is lost or forgotten.\n7. Click Save.\n\n\n\n\n\n\n\n Set up the integration \n\nTo complete setup, you must have an assistant ready to deploy, your NICE CXone access keys, and phone numbers allocated for this integration.\n\nTo integrate your assistant with NICE CXone:\n\n\n\n1. In the Integrations section on the main page for your assistant under Essential Channels, you will see a tile for Phone.\n2. On the Phone tile, click Add.\n3. On the pop-up window, click Add again.\n4. Select NICE CXone on the Select contact center page.\n\nClick Next.\n5. On the Connect to contact center page, specify the following values: - the Authentication URL from NICE CXone - the API URL, which is the Admin API endpoint from NICE CXone - the Access key ID - the Access key secret\n\nClick Test connection to verify the credentials.\n\nClick Next.\n6. On the Phone number page, enter a phone number you allocated for the NICE CXone integration. You can add more phone numbers later.\n\nClick Next.\n7. On the Speech to Text page, select the instance of the Speech to Text service you want to use.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus or Enterprise instance.\n\n\n\n8. In the Choose your Speech to Text language model field, select the language you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"},{"document_id":"ibmcld_03179-4-1759","score":21.7957324547,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Integrating with WhatsApp](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with WhatsApp \n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the All Products and Services menu ![Twilio All products and services icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/twilio-products.png), click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-whatsapp"},{"document_id":"ibmcld_16280-3111-5196","score":21.4899362664,"text":"\nExtensions are not required for an assistant, but they are recommended.\n\n\n\nWhen you add a channel to your assistant, at least two instances of the channel are created. One instance of the channel is connected to the draft environment and the other instance is connected to the live environment. If you are using [multiple environments](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-multiple-environments), instances of the channel are added to your extra environments. To connect your assistant to a new channel, go to the Integrations catalog. For more information about adding integrations to your assistant, see [Adding integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-integration-add).\n\nAlthough a channel always exists in environments, you can configure your integration separately in each environment. For example, this allows you to test integrations on your draft environment before you go live with any integration configuration. After you add an integration, you must set it up to use it with your assistant. The Finish setup icon appears on any integration that you added but didn't yet set up.\n\nYou have multiple options for deploying your assistant, depending on how you want your customers to interact with it. In most cases, an assistant is deployed by using one of the following integrations:\n\n\n\n* [Web chat integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): The web chat integration provides a secure and highly customizable widget you can add to your website. You can configure how and where the web chat widget appears, and you can use theming to align it with your branding and website design. If a customer needs help from a person, the web chat integration can transfer the conversation to an agent.\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone): The phone integration enables your assistant to converse with customers on the phone by using the IBM Watson Text to Speech and Speech to Text services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-assistant"},{"document_id":"ibmcld_16297-7-1893","score":21.3830889842,"text":"\nIntegrating with WhatsApp \n\nIBM Cloud\n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the Develop tab, click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\nKeep the Twilio web page open in a web browser tab so you can refer to it again later.\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1. To register, go to the [Facebook Business Manager](https:\/\/business.facebook.com\/overview) website, and click Create account. Follow the instructions to create an account.\n2. Get your Facebook Business Manager ID. In [Settings](https:\/\/business.facebook.com\/settings), click the Business info tab. The Facebook Business Manager ID is at the top of the page.\n3. Submit the Request to enable your Twilio numbers for WhatsApp form from the [Twilio API for WhatsApp](https:\/\/www.twilio.com\/whatsapp\/request-access) web page.\n\nTips for specifying the following values:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp"},{"document_id":"ibmcld_03158-4-2042","score":21.0199584145,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with phone ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) \n\nBy adding the phone integration to your assistant, you can make your assistant available to customers over the phone.\n\nWhen you add the phone integration to your assistant, you can automatically generate a working phone number that is automatically connected to your assistant. Or, if you prefer, you can connect the assistant to your existing infrastructure by configuring an existing Session Initiation Protocol (SIP) trunk.\n\nA SIP trunk is equivalent to an analog telephone line, except it uses Voice over Internet Protocol (VoIP) to transmit voice data and can support multiple concurrent calls. The trunk can connect to the public switched telephone network (PSTN) or your company's on-premises private branch exchange (PBX). If you choose to generate a free phone number for your assistant, a SIP trunk is automatically provisioned from IntelePeer. You can also choose to use an existing SIP trunk from a provider such as IntelePeer, Genesys, or Twilio.\n\nGenerating a free phone number is available only with new phone integrations. If you have an existing phone integration and you want to switch to a free phone number, you must delete the existing integration and create a new one.\n\nWhen your customer makes a phone call using the telephone number connected to your assistant, the phone integration answers. The integration converts output from your assistant into voice audio by using the IBM Watson\u00ae Text to Speech service. The audio is sent to the telephone network through the SIP trunk. When the customer replies, the voice input is converted into text by using the IBM Watson\u00ae Speech to Text service.\n\nThis feature is available only to Plus or Enterprise plan users.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16291-7-1781","score":20.6459712856,"text":"\nIntegrating with phone and NICE CXone contact center ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/plus.png) \n\nIBM Cloud\n\nConnect your assistant to a NICE CXone contact center with live agents.\n\nTransfer customers from a chat with your assistant to live agents who can help them by phone. If customers ask to speak to someone, your assistant can forward them directly to customer support with the conversation history.\n\nThis integration creates a connection between your assistant and a contact center using NICE CXone.\n\nYou need a Plus or Enterprise Plan to use this feature.\n\n\n\n Before you begin \n\nYou must have a NICE CXone account and phone numbers allocated for this integration.\n\n\n\n1. Go to the [NICE website](https:\/\/www.nice.com\/).\n2. Create an account.\n3. Follow the instructions to get phone numbers or select existing phone numbers.\n\n\n\n\n\n\n\n Generate NICE CXone access keys \n\nAccess keys are used for authentication and consist of two parts: an access key ID and a secret access key.\n\nTo generate NICE CXone access keys to use with your assistant:\n\n\n\n1. Log in to the NICE CXone console.\n2. Click the app selector ![appselectoricon.png](https:\/\/help.nice-incontact.com\/content\/resources\/images\/icons\/appselectoricon.png) and select Admin.\n3. Click Users, and then locate and click the user account you want to use for the integration.\n4. Click the Access Keys tab.\n5. Click Generate New Access Key.\n6. Click Show Secret Key, and copy the secret key to a secure location.\n\nYou cannot retrieve the secret key again after you complete the next step and Save. You must generate a new key if the current one is lost or forgotten.\n7. Click Save.\n\n\n\n\n\n\n\n Set up the integration","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"},{"document_id":"ibmcld_16287-2974-4988","score":20.5517811445,"text":"\nChoose whether to generate a free phone number for your assistant, integrate with your contact center, or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To integrate with a [contact center](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone), click Integrate with your contact center.\n* To use an existing phone number you have already configured with a [SIP trunk provider](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-sip-providers), click Use an existing phone number with an external provider.\n\n\n\nClick Next.\n5. If you are integrating with a contact center, follow the instructions to configure the contact center. Skip this step if you are generating a free phone number.\n\n\n\n1. On the Select contact center page, select the tile of the connect center you would like to use.\n2. On the Connect to contact center page, enter the required information. There is a Test Connection button on the page to validate the connection. Click Next.\n\n\n\n6. If you are using an existing phone number, follow the instructions to configure the SIP trunk. Skip this step if you are generating a free phone number.\n\n\n\n1. On the Bring your own SIP trunk page, copy the SIP URI and assign it to your SIP trunk. Click Next.\n\n\n\n7. On the Phone number page (only for Integrate with your contact center and Use an existing phone number with an external provider), specify the phone number of the SIP trunk. Specify the number by using the international phone number format: +1 958 555 0123. Do not surround the area code with parentheses.\n\nCurrently, only one primary phone number can be added during initial setup of the phone integration. You can add more phone numbers in the phone integration settings later.\n\nClick Next.\n8.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_16287-7-2037","score":20.3551899041,"text":"\nIntegrating with phone ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/plus.png) \n\nIBM Cloud\n\nAdding the phone integration to your assistant makes your assistant available to customers over the phone.\n\nIf an end user asks to speak to a person, the phone integration can transfer the call to an agent. Supported live agent and contact center integrations:\n\n\n\n* Genesys\n* Twilio Flex\n* NICE CXone\n* Bring your own\n\n\n\nThere are several ways to add the phone integration to your assistant:\n\n\n\n* You can generate a free phone number that is automatically provisioned from IntelePeer. This is available only with new phone integrations. If you have an existing phone integration, you must delete it and create a new one to switch to a free phone number.\n* You can connect to a contact center with live agents. For more information about setting up the integration, see [Integrating with phone and NICE CXone contact center](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone).\n* You can use and connect an existing number by configuring a Session Initiation Protocol (SIP) trunk from a provider such as Genesys, IntelePeer, or Twilio.\n\n\n\nA SIP trunk is equivalent to an analog telephone line, except it uses Voice over Internet Protocol (VoIP) to transmit voice data and can support multiple concurrent calls. The trunk can connect to the public switched telephone network (PSTN) or your company's on-premises private branch exchange (PBX).\n\nWhen a customer makes a phone call using the telephone number connected to your assistant, the phone integration makes it possible for your assistant to answer. The integration converts output from your assistant into voice audio by using the IBM Watson\u00ae Text to Speech service, and the audio is sent to the telephone network through the SIP trunk. When the customer replies, the voice input is converted into text by using the IBM Watson\u00ae Speech to Text service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone"},{"document_id":"ibmcld_03285-5746-7932","score":20.3276212074,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16288-1733-3996","score":22.0153178077,"text":"\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03165-4477-6547","score":21.2749128119,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_16288-6287-8401","score":20.9710485416,"text":"\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have a live agent backup available. You can design your assistant to transfer a call to a human in case the phone connection fails, or if a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another. For example, if you use the web chat integration with service desk support, you cannot transfer a phone call to the service desk that is set up for the web chat.\n\nYou must provide the call center SIP URI for the call center service you use. You must specify this information in your assistant when you enable a call transfer from a dialog node or action step. For more information, see [Transferring a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\n\n\n\n\n Optimize your actions for phone interaction \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your action responses. To add formatting, use Markdown. For more information, see [Formatting responses](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-respondrespond-formatting).\n* You can use a search extension to include search results in actions that the phone integration will read. When search results are returned, the phone integration reads the introductory message (for example, I found this information that might be helpful), and then the body of only the first search result.\n\nThe entire search response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16297-7-1893","score":20.4416383861,"text":"\nIntegrating with WhatsApp \n\nIBM Cloud\n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the Develop tab, click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\nKeep the Twilio web page open in a web browser tab so you can refer to it again later.\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1. To register, go to the [Facebook Business Manager](https:\/\/business.facebook.com\/overview) website, and click Create account. Follow the instructions to create an account.\n2. Get your Facebook Business Manager ID. In [Settings](https:\/\/business.facebook.com\/settings), click the Business info tab. The Facebook Business Manager ID is at the top of the page.\n3. Submit the Request to enable your Twilio numbers for WhatsApp form from the [Twilio API for WhatsApp](https:\/\/www.twilio.com\/whatsapp\/request-access) web page.\n\nTips for specifying the following values:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp"},{"document_id":"ibmcld_03179-4-1759","score":20.2798026952,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Integrating with WhatsApp](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with WhatsApp \n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the All Products and Services menu ![Twilio All products and services icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/twilio-products.png), click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-whatsapp"},{"document_id":"ibmcld_16280-3111-5196","score":18.6105535536,"text":"\nExtensions are not required for an assistant, but they are recommended.\n\n\n\nWhen you add a channel to your assistant, at least two instances of the channel are created. One instance of the channel is connected to the draft environment and the other instance is connected to the live environment. If you are using [multiple environments](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-multiple-environments), instances of the channel are added to your extra environments. To connect your assistant to a new channel, go to the Integrations catalog. For more information about adding integrations to your assistant, see [Adding integrations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-integration-add).\n\nAlthough a channel always exists in environments, you can configure your integration separately in each environment. For example, this allows you to test integrations on your draft environment before you go live with any integration configuration. After you add an integration, you must set it up to use it with your assistant. The Finish setup icon appears on any integration that you added but didn't yet set up.\n\nYou have multiple options for deploying your assistant, depending on how you want your customers to interact with it. In most cases, an assistant is deployed by using one of the following integrations:\n\n\n\n* [Web chat integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): The web chat integration provides a secure and highly customizable widget you can add to your website. You can configure how and where the web chat widget appears, and you can use theming to align it with your branding and website design. If a customer needs help from a person, the web chat integration can transfer the conversation to an agent.\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone): The phone integration enables your assistant to converse with customers on the phone by using the IBM Watson Text to Speech and Speech to Text services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-assistant"},{"document_id":"ibmcld_16321-7-1807","score":18.4154464532,"text":"\nHandling phone interactions \n\nIf your assistant uses the phone integration, you can use various response types to customize the behavior of the integration or manage the flow of conversations that your assistant has with customers over the telephone.\n\nYou can use response types to perform the following phone-specific actions:\n\n\n\n* [Apply advanced settings to the Speech to Text service](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-speech-advanced)\n* [Apply advanced settings to the Text to Speech service](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-text-advanced)\n* [Transfer a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer)\n* [Play hold music or a voice recording](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hold-music)\n* [Enable keypad entry](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-dtmf)\n* [Transfer the conversation to the web chat integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer-channel)\n* [End the call](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hangup)\n* [Send a text message during a phone conversation](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same action step. For more information, see the following:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03216-18448-20174","score":18.3953846002,"text":"\ndtmf \n\nSends commands to the phone integration to control input or output using dual-tone multi-frequency (DTMF) signals. (DTMF is a protocol used to transmit the tones that are generated when a user presses keys on a push-button phone.)\n\n\n\n Fields \n\n\n\n Name Type Description Required? \n\n response_type string dtmf Y \n command_info object Information specifying the DTMF command to send to the phone integration. Y \n command_info.type string The DTMF command to send (collect, disable_barge_in, enable_barge_in, or send). Y \n command_info.parameters object See [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions) N \n\n\n\nThe command_info.type field can specify any of the following supported commands:\n\n\n\n* collect: Collects DTMF keypad input.\n* disable_barge_in: Disables DTMF barge-in so that playback from the phone integration is not interrupted when the customer presses a key.\n* enable_barge_in: Enables DTMF barge-in so that the customer can interrupt playback from the phone integration by pressing a key.\n* send: Sends DTMF signals.\n\n\n\nFor detailed information about how to use each of these commands, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions).\n\n\n\n\n\n Example \n\nThis example shows the dtmf response type with the collect command, used to collect DTMF input. For more information, including examples of other DTMF commands, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions).\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"dtmf\",\n\"command_info\": {\n\"type\": \"collect\",\n\"parameters\": {\n\"termination_key\": \"\",\n\"count\": 16,\n\"ignore_speech\": true\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-responses-json"},{"document_id":"ibmcld_03158-21896-24017","score":18.3281814268,"text":"\nYou can use the same SIP account and phone number that you configured for use with Voice Agent with Watson in the phone integration.\n\nThe phone integration provides a more seamless integration with your assistant. However, the integration currently does not support the following functions:\n\n\n\n* Outbound calling\n* Configuring backup locations\n* Event forwarding to save call detail reports in the IBM Cloudant for IBM Cloud database service\n* Reviewing the usage summary page. Use IBM Log Analysis instead. For more information, see [Viewing logs](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-logs).\n\n\n\nTo migrate from Voice Agent with Watson to the Watson Assistant phone integration, complete the following steps:\n\n\n\n1. From the Voice Agent with Watson page, copy the phone number or numbers that you used for your SIP account.\n2. When you set up the Watson Assistant phone integration, add the phone number or set of numbers that you copied in the previous step.\n3. From the phone integration setup page, copy the SIP uniform resource identifier (URI).\n4. In your SIP trunk account, replace the Voice Agent with Watson URI that you specified previously with the URI that you copied from the phone integration setup page in the previous step.\n\nFor example, if you use a Twilio SIP trunk, you would add the assistant's SIP uniform resource identifier (URI) to the Twilio Origination SIP URI field.\n\n\n\n\n\n\n\n Call routing details \n\nIncoming calls to your assistant follow this path:\n\n\n\n1. A customer calls the customer support phone number that is managed by your Session Initiation Protocol (SIP) trunk provider.\n2. The SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).\n\nRTP is a network protocol for delivering audio and video over IP networks.\n5. The welcome node of the dialog is processed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16288-15027-17056","score":18.2269301728,"text":"\n* Outbound calling\n* Configuring backup locations\n* Event forwarding to save call detail reports in the IBM Cloudant for IBM Cloud database service\n* Reviewing the usage summary page. Use IBM Log Analysis instead. For more information, see [Viewing logs](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-troubleshootingphone-troubleshooting-logs).\n\n\n\nTo migrate from Voice Agent with Watson to the Watson Assistant phone integration, complete the following steps:\n\n\n\n1. From the Voice Agent with Watson page, copy the phone number or numbers that you used for your SIP account.\n2. When you set up the Watson Assistant phone integration, add the phone number or set of numbers that you copied in the previous step.\n3. From the phone integration setup page, copy the SIP uniform resource identifier (URI).\n4. In your SIP trunk account, replace the Voice Agent with Watson URI that you specified previously with the URI that you copied from the phone integration setup page in the previous step.\n\nFor example, if you use a Twilio SIP trunk, you would add the assistant's SIP uniform resource identifier (URI) to the Twilio Origination SIP URI field.\n5. If your SIP trunk provider is not already allowlisted with the Watson Assistant region you are migrating to, follow these [instructions](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-request-setup) to get access to your SIP trunk.\n\n\n\n\n\n\n\n Call routing details \n\nIncoming calls to your assistant follow this path:\n\n\n\n1. A customer calls the customer support phone number that is managed by your Session Initiation Protocol (SIP) trunk provider.\n2. The SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.9197207891,"ndcg_cut_5":0.9197207891,"ndcg_cut_10":0.9197207891}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03165-4477-6547","score":24.9764929534,"text":"\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https:\/\/community.ibm.com\/community\/user\/watsonapps\/viewdocument\/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"},{"document_id":"ibmcld_03179-4-1759","score":22.1223814163,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Integrating with WhatsApp](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Integrating with WhatsApp \n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the All Products and Services menu ![Twilio All products and services icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/twilio-products.png), click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-whatsapp"},{"document_id":"ibmcld_16290-4708-6492","score":22.0552122156,"text":"\n[Genesys simulate call](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/phone-genesys-simulate-call.png)\n16. Go to Phone Management and click Create new. Specify the following information:\n\n\n\n* In the Phone Name field, specify a descriptive name.\n* In the Base Settings field, select WebRTCPhone.\n* In the Site field, select the site you want to use.\n* In the Person field, select yourself.\n\n\n\n17. In the Watson Assistant user interface, [create a new phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phonedeploy-phone-setup). Specify the following information:\n\n\n\n* When prompted, select Use an existing phone number with an external provider.\n* Specify the phone number you assigned in the Genesys Number Plans setting. This is not necessarily a real phone number; it is just the identifier you assigned.\n* Complete the phone integration setup process. For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone).\n* After the phone integration is set up, go to the SIP trunk tab and uncheck the Don't place callers on hold while transferring to a live agent option.\n\n\n\n18. In the Genesys Cloud console, click the circle in the upper left corner. Select Phone, and then choose the phone you created in the Phone management section. Set yourself as available. The phone icon on the left should now be active.\n19. Click + to start a new call. Specify the number you assigned to Watson Assistant and then click Dial. You should now hear your assistant speak.\n\n\n\nIf you encounter any errors, click Performance -> Interactions and view the PCAP file to read the diagnostics.\n\n\n\n\n\n Transferring to a live agent","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-genesys"},{"document_id":"ibmcld_16297-7-1893","score":22.0251627928,"text":"\nIntegrating with WhatsApp \n\nIBM Cloud\n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https:\/\/www.twilio.com\/).\n2. Create an account.\n3. From the Develop tab, click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\nKeep the Twilio web page open in a web browser tab so you can refer to it again later.\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1. To register, go to the [Facebook Business Manager](https:\/\/business.facebook.com\/overview) website, and click Create account. Follow the instructions to create an account.\n2. Get your Facebook Business Manager ID. In [Settings](https:\/\/business.facebook.com\/settings), click the Business info tab. The Facebook Business Manager ID is at the top of the page.\n3. Submit the Request to enable your Twilio numbers for WhatsApp form from the [Twilio API for WhatsApp](https:\/\/www.twilio.com\/whatsapp\/request-access) web page.\n\nTips for specifying the following values:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-whatsapp"},{"document_id":"ibmcld_03161-5817-7635","score":22.0048813843,"text":"\n* In the Person field, select yourself.\n\n\n\n17. In the Watson Assistant user interface, create a new phone integration. Specify the following information:\n\n\n\n* When prompted, select Use an existing phone number with an external provider.\n* Specify the phone number you assigned in the Genesys Number Plans setting. (Remember, this is not necessarily a real phone number; it is just the identifier you assigned.)\n* Complete the phone integration setup process. (For more information, see [Integrating with phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone).)\n* After the phone integration is setup, go to the SIP trunk tab and uncheck the Don't place callers on hold while transferring to a live agent option.\n\n\n\n18. In the Genesys Cloud console, click the circle in the upper left corner. Select Phone, and then choose the phone you created in the Phone management section. Set yourself as available. The phone icon on the left should now be active.\n19. Click + to start a new call. Specify the number you assigned to Watson Assistant and then click Dial. You should now hear your assistant speak.!\n\n\n\nIf you encounter any errors, click Performance -> Interactions and view the PCAP file to read the diagnostics.\n\n\n\n\n\n Transferring to an agent \n\nNow that your Genesys Cloud environment can connect to Watson Assistant, you can set up the ability for your assistant to transfer calls back to your human agents. To do so, follow these steps:\n\n\n\n1. In the Genesys Cloud console, go to DID Numbers -> DID Ranges and create a new range. Specify the following information:\n\n\n\n* In the DID Start and DID End fields, specify a phone number. (Once again, you do not need to use a real phone number; you can just make up an identifier for your Genesys environment, such as 1-888-888-1234.)\n\n\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone-genesys"},{"document_id":"ibmcld_16288-6287-8401","score":21.8599697607,"text":"\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have a live agent backup available. You can design your assistant to transfer a call to a human in case the phone connection fails, or if a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another. For example, if you use the web chat integration with service desk support, you cannot transfer a phone call to the service desk that is set up for the web chat.\n\nYou must provide the call center SIP URI for the call center service you use. You must specify this information in your assistant when you enable a call transfer from a dialog node or action step. For more information, see [Transferring a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\n\n\n\n\n Optimize your actions for phone interaction \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your action responses. To add formatting, use Markdown. For more information, see [Formatting responses](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-respondrespond-formatting).\n* You can use a search extension to include search results in actions that the phone integration will read. When search results are returned, the phone integration reads the introductory message (for example, I found this information that might be helpful), and then the body of only the first search result.\n\nThe entire search response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03158-23545-25765","score":21.7194213866,"text":"\nThe SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).\n\nRTP is a network protocol for delivering audio and video over IP networks.\n5. The welcome node of the dialog is processed. The response text is sent to the Text to Speech service to be converted to audio and the audio is sent to the caller.\n6. When the customer says something, the audio is converted to text by the Speech to Text service and is sent to your assistant's dialog skill for evaluation.\n7. The dialog processes the input and calculates the best response. The response text from the dialog node is sent to the Text to Speech service to be converted to audio and the audio is sent back to the caller over the existing connection.\n8. If the caller asks to speak to a person, the assistant can transfer the person to a call center. A SIP REFER request is sent to the SIP trunk provider so it can transfer the call to the call center SIP URI that is specified in the dialog node where the transfer action is configured.\n9. When one of the participants of the call hangs up, a SIP BYE HTTP request is sent to the other participant.\n\n\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges that are incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000 \n Plus 100 \n Trial 5 \n\n\n\n\n\n\n\n Troubleshooting the phone integration \n\nFind solutions to problems that you might encounter while using the integration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03367-4-2117","score":21.6393839326,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Phone integration context variables \n\nYou can use context variables to manage the flow of conversations with customers who interact with your assistant over the telephone.\n\nThe following tables describe the context variables that have special meaning in the context of the phone integration. They should not be used for any purpose other than the documented use.\n\n\n\n Context variables that are set by your dialog or actions \n\n\n\nVoice context variables set by the dialog or actions\n\n Name Type Description Default \n\n final_utterance_timeout_count Number The time (in milliseconds) that the phone integration waits to receive a final utterance from the Speech to Text service. The timeout occurs if the phone integration does not receive a final utterance within the specified time limit, even if hypotheses continue to be generated. When the timeout occurs, the phone integration sends Watson Assistant a text update that includes the word vgwFinalUtteranceTimeout to indicate that no final utterance was received. N\/A \n post_response_timeout_count Number The time (in milliseconds) to wait for a new utterance after the response is played back to the caller. When this timeout occurs, the phone integration channel sends a text message to the assistant that includes the word vgwPostResponseTimeout and sets the context variable input.integrations.voice_telephony.post_response_timeout_occurred to true. 7000 \n turn_settings.timeout_count Number The time (in milliseconds) to wait for a response from Watson Assistant. If this time is exceeded, the phone integration tries again to contact Watson Assistant. If the service still can't be reached, the call fails. N\/A \n cdr_custom_data object Any JSON key\/value pairs to collect and store with the CDR record at the end of the phone call. Each time this object is received, it is merged with any previously received cdr_custom_data context. N\/A \n\n\n\n\n\n Example \n\n{\n\"output\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-phone-context"},{"document_id":"ibmcld_03158-21896-24017","score":21.352649313,"text":"\nYou can use the same SIP account and phone number that you configured for use with Voice Agent with Watson in the phone integration.\n\nThe phone integration provides a more seamless integration with your assistant. However, the integration currently does not support the following functions:\n\n\n\n* Outbound calling\n* Configuring backup locations\n* Event forwarding to save call detail reports in the IBM Cloudant for IBM Cloud database service\n* Reviewing the usage summary page. Use IBM Log Analysis instead. For more information, see [Viewing logs](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-logs).\n\n\n\nTo migrate from Voice Agent with Watson to the Watson Assistant phone integration, complete the following steps:\n\n\n\n1. From the Voice Agent with Watson page, copy the phone number or numbers that you used for your SIP account.\n2. When you set up the Watson Assistant phone integration, add the phone number or set of numbers that you copied in the previous step.\n3. From the phone integration setup page, copy the SIP uniform resource identifier (URI).\n4. In your SIP trunk account, replace the Voice Agent with Watson URI that you specified previously with the URI that you copied from the phone integration setup page in the previous step.\n\nFor example, if you use a Twilio SIP trunk, you would add the assistant's SIP uniform resource identifier (URI) to the Twilio Origination SIP URI field.\n\n\n\n\n\n\n\n Call routing details \n\nIncoming calls to your assistant follow this path:\n\n\n\n1. A customer calls the customer support phone number that is managed by your Session Initiation Protocol (SIP) trunk provider.\n2. The SIP trunk service sends a SIP INVITE HTTP request to your assistant's phone integration to establish a connection.\n3. The phone integration connects to the speech services that are required to support the interaction.\n4. After the services are ready, the connection is established, and audio is sent over the Real-time Transport Protocol (RTP).\n\nRTP is a network protocol for delivering audio and video over IP networks.\n5. The welcome node of the dialog is processed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03165-7676-8581","score":21.2464621506,"text":"\nIf you want to use the same dialog for an assistant that you deploy to many different platforms, add custom responses per integration type. You can add a conditioned response that tells the assistant to show the response only when the SMS with Twilio integration is being used. For more information, see [Building integration-specific responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrationsdialog-integrations-condition-by-type).\n\nFor reference documentation, see [Handling SMS with Twilio interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-sms-actions).\n\n\n\n\n\n Troubleshooting \n\nFind solutions to problems that you might encounter while using the integration.\n\n\n\n* If you get a Forbidden message, it means the phone number that you specified when you configured the integration cannot be verified. Make sure the number fully matches the SMS phone number.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-sms"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16321-19290-20983","score":30.431402334,"text":"\n\"uri\": \"sip:12345556789\\@myhost.com\"\n\n\n\n Transferring after hangup \n\nBy default, the phone integration transfers calls by using a SIP REFER request. Depending on the IVR service provider, you might need to configure call transfer to use a SIP BYE request instead. Use the transfer_method attribute to specify how to transfer the call, using either refer or hangup. When transfer_method is set to hangup instead of refer, the behavior of the transfer action changes. Instead of sending a SIP REFER request, the phone integration plays back any associated text and then hangs up the call by sending a SIP BYE request.\n\nAfter the hangup, the phone integration passes the transfer destination that is specified in the url attribute to the call anchor in the BYE message. The header field that contains the transfer target is determined by the transfer_target_header attribute. If the transfer_target_header attribute isn't specified, the phone integration uses Transfer-Target.\n\n{\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"transfer_info\": {\n\"target\": {\n\"service_desk\": {\n\"sip\": {\n\"uri\": \"sip:user\\@domain.com\",\n\"transfer_method\": \"hangup\",\n\"transfer_target_header\": \"Transfer-Target\"\n}\n}\n}\n},\n\"agent_available\": {\n\"message\": \"Please hold on while I connect you with a live agent.\"\n},\n\"agent_unavailable\": {\n\"message\": \"Sorry, I could not find an agent.\"\n},\n\"message_to_human_agent\": \"The caller needs help resetting their password\"\n}\n]\n}\nShow more\n\n\n\n\n\n Transferring upon failure \n\nTo configure transfer on failures, go to the Advanced tab in the phone integration settings. The following selections can be configured:\n\n\n\n* Transfer failure message\n* Disconnect call on transfer failure","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_16288-7-2218","score":30.0881766093,"text":"\nPhone integration configuration \n\nIBM Cloud\n\nAfter you have set up the phone integration for your assistant, you can modify the phone integration settings to customize the call behavior.\n\n\n\n Handling call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, go to the Advanced tab in the phone integration settings, and make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup call center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-transfer-service).\n* Call failure message: Add the message you want the assistant to say to a caller before it transfers the call to a human agent.\n\n\n\nIf, after you transfer the call to a human, the connection to a live agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message you want the assistant to say to a caller if transfer to a live agent fails. The message can be up to 150 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after the failure message. This option is enabled by default. If this option is disabled, when a call transfer fails, your assistant can disconnect or process a different action.\n\nIf you choose to leave a call connected despite a transfer failure, Watson Assistant will initiate a new turn to determine the next step. It's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16250-5445-7809","score":27.1787588004,"text":"\nTo support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call. Using only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_03312-5487-7760","score":26.8606896811,"text":"\nIf a failover is automated and a regional backup is enabled, it is always best to try a different zone first and only redirect traffic to the passive backup region if a preconfigured number of failures occur within a short period of time. This prevents an unnecessary failover between regions if only a short outage occurs.\n\nNote that Watson Assistant provides a round-robin fully qualified domain name (FQDN) that includes the IPs for each zone in the region. Many SIP trunking providers automatically retry each IP in the FQDN when failures occur. To support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-failover"},{"document_id":"ibmcld_16321-20604-22275","score":26.7538267517,"text":"\n\"message\": \"Sorry, I could not find an agent.\"\n},\n\"message_to_human_agent\": \"The caller needs help resetting their password\"\n}\n]\n}\nShow more\n\n\n\n\n\n Transferring upon failure \n\nTo configure transfer on failures, go to the Advanced tab in the phone integration settings. The following selections can be configured:\n\n\n\n* Transfer failure message\n* Disconnect call on transfer failure\n\n\n\nFor more information, see [Handling call and transfer failures](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-failure).\n\n\n\n\n\n Passing Watson Assistant Metadata in SIP Signaling \n\nTo support loading the conversational history between the caller and Watson Assistant, the phone integration specifies a value for the User-to-User header as a key that can be used with the web chat integration. If User-to-User is specified in the transfer_headers list, the session history key is sent in the X-Watson-Assistant-Session-History-Key header.\n\nThe value of the SIP header is limited to 1024 bytes.\n\nHow this data is presented in the SIP REFER message also depends on the value of transfer_headers_send_method(as defined in [Generic Service Desk SIP Parameters](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsgeneric-service-desk-sip-parameters)).\n\nThe following example shows the data included as headers:\n\nREFER sip:b@atlanta.example.com SIP\/2.0\nVia: SIP\/2.0\/UDP agenta.atlanta.example.com;branch=z9hG4bK2293940223\nTo: <sip:b@atlanta.example.com>\nFrom: <sip:a@atlanta.example.com>;tag=193402342\nCall-ID: 898234234@agenta.atlanta.example.com\nCSeq: 23 REFER\nMax-Forwards: 7\nRefer-To: sip:user@domain.com","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03158-8929-11062","score":26.4179873515,"text":"\nFor more information, see [Configuring backup support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after sharing the failure message. This option is enabled by default. If disabled, when a call transfer fails, your assistant can disconnect or process a different dialog node.\n\n\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by selecting one or both of the following configuration options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Apply advanced SIP trunk configuration settings \n\n\n\n* SIP INVITE headers to extract: List headers that you want to use in your dialog.\n\nThe SIP request often sends INVITE headers with information about the request that is used by the SIP network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_03158-7739-9484","score":26.1708167448,"text":"\n[checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/phone-checkmark-save.png) to save each number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (![Add phone number](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/phone-integ-import-number.png)), and then find the CSV file that contains the list of phone numbers.\n\nThe phone numbers you upload will replace any existing numbers in the table.\n\n\n\n\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the call behavior:\n\n\n\n Handle call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16288-10521-12298","score":25.9809792919,"text":"\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Add a number and then Buy a Number.\n* If you already have a number, you can click Add a number and then Add an Existing Number.\n\n\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target. For more information, see the [Twilio documentation](https:\/\/support.twilio.com\/hc\/en-us\/articles\/223136107-How-does-Twilio-s-Free-Trial-work-).\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https:\/\/www.five9.com\/products\/capabilities\/contact-center-software)\n* [Genesys](https:\/\/www.genesys.com\/en-sg\/definitions\/what-is-a-trunk)\n* [Vonage](https:\/\/www.vonage.com\/communications-apis\/sip-trunking\/)\n* [Voximplant](https:\/\/voximplant.com\/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_03158-17978-19852","score":25.6844034097,"text":"\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Buy a Number.\n* If you already have a number, you can click the plus sign (+) to provision a new phone number in your region.\n\n\n\n8. Assign the number to the SIP trunk you created by going back to the SIP trunk and clicking the number sign (#) icon.\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target.\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https:\/\/www.five9.com\/products\/capabilities\/contact-center-software)\n* [Genesys](https:\/\/www.genesys.com\/en-sg\/definitions\/what-is-a-trunk)\n* [Vonage](https:\/\/www.vonage.com\/communications-apis\/sip-trunking\/)\n* [Voximplant](https:\/\/voximplant.com\/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1. Create a [IBM Cloud case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form).\n2. Click Customer success as the case type.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phone"},{"document_id":"ibmcld_16291-8926-10529","score":25.0155800692,"text":"\nIf an error occurs during a conversation, the phone integration disconnects the call by sending a SIP BYE request.\n\nUse [Onrelease](https:\/\/help.nice-incontact.com\/content\/studio\/actions\/onrelease\/onrelease.htm) to process the BYE request and transfer a call to a live agent.\n\nIn this example, when Onrelease is triggered, the script verifies whether the call was already transferred. If not, it calls the Signal action and sets an indication that the call is being transferred to a live agent. The indication is set using the Assign action.\n\n\n\n* Variable transferred\n* Value true\n\n\n\n![Image of call disconnect on failure](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/cxone-disconnect-on-failure.png)\n\nIf the Hangup action is executed and an [Onrelease](https:\/\/help.nice-incontact.com\/content\/studio\/actions\/onrelease\/onrelease.htm) event action is present, CXone will hang up on the caller, and the script will jump to the OnRelease action. Design your script so it can distinguish whether the OnRelease event is triggered due to a transfer or hangup.\n\n\n\n\n\n\n\n\n\n Adding transfer support to your assistant \n\nConfigure your assistant to transfer calls to an agent using the Connect To Agent response_type. For instructions, see [Transferring a call to a live agent](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\nUse the following format:\n\n{\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"transfer_info\": {\n\"target\": {\n\"nice_cxone\": {\n\"custom_data\": {\n\"p2\": \"test\"\n}\n}\n}\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.5802792109}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04621-58586-59933","score":16.2946187917,"text":"\n* The alternate Liberty runtime GA version [19.0.0.1](https:\/\/openliberty.io\/blog\/2019\/02\/01\/open-liberty-19001.html) was added.\n* The monthly Liberty beta release has been removed.\n* The IBM JRE version was updated to 8 SR5 FP27.\n* The MQ client was updated to the 9.1.0.0 release.\n* The auto-scaling agent was updated.\n\n\n\n\n\n\n\n 23 January 2019 \n\nUpdated Node.js buildpack v3.25.1\n: The SDK for Node.js buildpack v3.25.1 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.14.4, 6.16.0, 8.11.4, 8.15.0, 10.10.0 and 10.15.0. The default is latest 6.x, so it is currently 6.16.0. The versions 6.15.0, 8.14.0 and 10.14.0 that were included in the last buildpack had a regression. The regressions has been fixed in 6.16.0, 8.15.0 and 10.15.0 which are now included instead.\n\n\n\n\n\n 7 January 2019 \n\nUpdated Node.js buildpack v3.25\n: The SDK for Node.js buildpack v3.25 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.14.4, 6.15.0, 8.11.4, 8.14.0, 10.10.0 and 10.14.0. The default is latest 6.x, so it is currently 6.15.0. The buildpack also fixes a minor bug in the Dynatrace hook.\n\n\n\n\n\n 14 December 2018 \n\nUpdated Liberty buildpack v3.27-20181130-1702\n: The buildpack now includes Java Platform, Enterprise Edition 8.0. Java EE 8 no longer needs to be installed when an app is pushed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"},{"document_id":"ibmcld_04621-57662-58966","score":15.0638951754,"text":"\n* Update Node.js version to 6.17.0\n\n\n\n\n\n\n\n 18 March 2019 \n\nUpdated Node.js buildpack v3.26\n: The SDK for Node.js buildpack v3.26 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.16.0, 6.17.0, 8.15.0, 8.15.1, 10.15.0 and 10.15.3. The default is latest 6.x, so it is currently 6.17.0.\n\n\n\n\n\n 1 March 2019 \n\nUpdated Liberty buildpack v3.29-20190223-2128\n: The default Liberty runtime GA version is the [18.0.0.4](https:\/\/openliberty.io\/blog\/2018\/12\/14\/microprofile21-18004.html) release.\n\n\n\n* The alternate Liberty runtime GA version [19.0.0.2](https:\/\/openliberty.io\/blog\/2019\/03\/01\/sharding-keys-jdbc43-19002.html) was added.\n* The Cloudant client libraries were updated to 2.14.0.\n\n\n\n\n\n\n\n 1 February 2019 \n\nUpdated Liberty buildpack v3.28-20190127-1723\n: The default Liberty runtime GA version is the [18.0.0.4](https:\/\/openliberty.io\/blog\/2018\/12\/14\/microprofile21-18004.html) release.\n\n\n\n* The alternate Liberty runtime GA version [19.0.0.1](https:\/\/openliberty.io\/blog\/2019\/02\/01\/open-liberty-19001.html) was added.\n* The monthly Liberty beta release has been removed.\n* The IBM JRE version was updated to 8 SR5 FP27.\n* The MQ client was updated to the 9.1.0.0 release.\n* The auto-scaling agent was updated.\n\n\n\n\n\n\n\n 23 January 2019 \n\nUpdated Node.js buildpack v3.25.1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"},{"document_id":"ibmcld_05598-32183-33356","score":15.0365731812,"text":"\nGateway-enabled cluster controller 1348 1444 Updated image for [CVE-2021-36159](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-36159). \n GPU device plug-in and installer 82ee77b a9461a8 Updated to use Go version 1.16.6. \n IBM Calico extension 747 763 Updated to use Go version 1.16.6. Updated UBI to the latest 8.4-205 version to resolve CVEs. \n IBM Cloud Controller Manager v1.19.13-1 v1.19.14-1 Updated to support the Kubernetes 1.19.14 release and to use Go version 1.15.15. \n IBM Cloud File Storage for Classic plug-in and monitor 395 398 Updated to use Go version 1.16.6. Updated image for [CVE-2021-33910](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-33910). \n Key Management Service provider v2.3.6 v2.3.7 Updated to use Go version 1.15.15. Updated universal base image (UBI) to the latest 8.4 version to resolve CVEs. \n Kubernetes v1.19.13 v1.19.14 See the [Kubernetes release notes](https:\/\/github.com\/kubernetes\/kubernetes\/releases\/tag\/v1.19.14). \n Kubernetes Dashboard metrics scraper v1.0.6 v1.0.7 See the [Kubernetes Dashboard metrics scraper release notes](https:\/\/github.com\/kubernetes-sigs\/dashboard-metrics-scraper\/releases\/tag\/v1.0.7).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_119"},{"document_id":"ibmcld_10402-64992-66123","score":14.8875126327,"text":"\nUpdated universal base image (UBI) to the latest 8.4-205 version to resolve CVEs. \n IBM Cloud Block Storage for Classic plug-in and driver v2.0.8 v2.0.9 Updated to use Go version 1.16.6. Updated image for [CVE-2021-33910](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-33910). \n IBM Cloud Controller Manager v1.19.13-1 v1.19.14-1 Updated to support the Kubernetes 1.19.14 release and to use Go version 1.15.15. \n IBM Cloud File Storage for Classic plug-in and monitor 395 398 Updated to use Go version 1.16.6. Updated image for [CVE-2021-33910](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-33910). \n Key Management Service provider v2.3.6 v2.3.7 Updated to use Go version 1.15.15. Updated universal base image (UBI) to the latest 8.4 version to resolve CVEs. \n Load balancer and load balancer monitor for IBM Cloud Provider 1328 1510 Updated image for [CVE-2020-27780](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-27780). \n Red Hat OpenShift 4.6.38 4.6.42 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.6\/release_notes\/ocp-4-6-release-notes.htmlocp-4-6-42).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_46"},{"document_id":"ibmcld_00861-222303-223263","score":14.4611045503,"text":"\ndc (GNU bc 1.07.1) 1.4.1\n\n ed --version\nGNU Ed 1.10\nShow more\n\n\n\n\n\n Version 2.14 \n\nTo view the contents of version 2.14, from the running image, type default_versions.sh. This image includes the following tools:\n\n node --version\nv14.17.6\n\n npm --version\n6.14.15\n\n jq --version\njq-1.6\n\n yq --version\nyq version 2.4.1\n\n yq3 --version\nyq version 3.4.1\n\n yq4 --version\nyq (https:\/\/github.com\/mikefarah\/yq\/) version 4.12.1\n\n kubectl version --client\nClient Version: version.Info{Major:\"1\", Minor:\"20\", GitVersion:\"v1.20.5\", GitCommit:\"6b1d87acf3c8253c123756b9e61dac642678305f\", GitTreeState:\"clean\", BuildDate:\"2021-03-18T01:10:43Z\", GoVersion:\"go1.15.8\", Compiler:\"gc\", Platform:\"linux\/amd64\"}\n\n buildctl --version\nbuildctl github.com\/moby\/buildkit v0.9.0 c8bb937807d405d92be91f06ce2629e6202ac7a9\n\n helm version --client\nClient: &version.Version{SemVer:\"v2.17.0\", GitCommit:\"a690bad98af45b015bd3da1a41f6218b1a451dbe\", GitTreeState:\"clean\"}\n\n helm3 version --client","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_10068-5032-6188","score":14.4039144556,"text":"\nCluster health image v1.2.14 v1.2.15 Updated to use Go version 1.15.15. Updated universal base image (UBI) to the latest 8.4 version to resolve CVEs. \n Gateway-enabled cluster controller 1348 1444 Updated image for [CVE-2021-36159](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-36159). \n IBM Calico extension 747 763 Updated to use Go version 1.16.6. Updated universal base image (UBI) to the latest 8.4-205 version to resolve CVEs. \n IBM Cloud Block Storage for Classic plug-in and driver v2.0.8 v2.0.9 Updated to use Go version 1.16.6. Updated image for [CVE-2021-33910](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-33910). \n IBM Cloud File Storage for Classic plug-in and monitor 395 398 Updated to use Go version 1.16.6. Updated image for [CVE-2021-33910](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-33910). \n Key Management Service provider v2.3.6 v2.3.7 Updated to use Go version 1.15.15. Updated UBI to the latest 8.4 version to resolve CVEs. \n Load balancer and load balancer monitor for IBM Cloud Provider 1328 1510 Updated image for [CVE-2020-27780](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-27780).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"},{"document_id":"ibmcld_05529-4907-6368","score":14.3579529416,"text":"\nThe following table shows the changes that are in the master fix pack patch update 1.18.20_1562. Master patch updates are applied automatically.\n\n\n\nChanges since version 1.18.20_1559\n\n Component Previous Current Description \n\n Cluster health image v1.2.14 v1.2.15 Updated to use Go version 1.15.15. Updated universal base image (UBI) to the latest 8.4 version to resolve CVEs. \n Gateway-enabled cluster controller 1348 1444 Updated image for [CVE-2021-36159](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-36159). \n GPU device plug-in and installer 82ee77b a9461a8 Updated to use Go version 1.16.6. \n IBM Calico extension 747 763 Updated to use Go version 1.16.6. Updated universal base image (UBI) to the latest 8.4-205 version to resolve CVEs. \n IBM Cloud File Storage for Classic plug-in and monitor 395 398 Updated to use Go version 1.16.6. Updated image for [CVE-2021-33910](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2021-33910). \n Key Management Service provider v2.3.6 v2.3.7 Updated to use Go version 1.15.15. Updated UBI to the latest 8.4 version to resolve CVEs. \n Kubernetes Dashboard metrics scraper v1.0.6 v1.0.7 See the [Kubernetes Dashboard metrics scraper release notes](https:\/\/github.com\/kubernetes-sigs\/dashboard-metrics-scraper\/releases\/tag\/v1.0.7). \n Load balancer and load balancer monitor for IBM Cloud Provider 1328 1510 Updated image for [CVE-2020-27780](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-27780).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-118_changelog"},{"document_id":"ibmcld_04621-69165-70572","score":14.3499227995,"text":"\nPlease note that it fixes PSIRT Advisory ID: 10237 Product Record ID: 104487 Title: Node.js zlib DOS security vulnerability, October 2017 (CVE-2017-14919). It is recommended to upgrade to v3.16.1 to get fixes for security vulnerabilities affecting 8.6.0.0 and earlier, 6.10.2.0 to 6.11.4.0 and 4.8.2.0 to 4.8.4.0.\n\n\n\n\n\n 1 November 2017 \n\nUpdated Node.js buildpack v3.15\n: The SDK for Node.js buildpack v3.15 provides IBM SDK for Node.js versions 4.8.3, 4.8.4, 6.11.3, 6.11.4, 8.3.0 and 8.6.0. The default is latest 6.x, so it is currently 6.11.4.\n\n\n\n\n\n 31 October 2017 \n\nUpdated Liberty buildpack v3.15\n: The monthly Liberty runtime version was updated to 2017.10.0.0.\n\n\n\n\n\n 17 October 2017 \n\nUpdated Liberty buildpack v3.14-20171013-1023\n: The default Liberty runtime version was updated to the 17.0.0.3 release.\n\n\n\n* The monthly Liberty runtime version was updated to 2017.9.0.1.\n* The IBM JRE version was updated to 8 SR5.\n\n\n\n\n\n\n\n 6 October 2017 \n\nUpdated ASP.NET Core buildpack v1.0.26-20170913-1346\n: This release includes the following updates:\n\n\n\n* Add support for .NET Core runtime 2.0.0\n* Add support for .NET Core SDK 1.1.0\n* Add support for .NET Core SDK 2.0.0\n* Remove support for .NET Core SDK 1.1.0-preview1-005051\n* Remove support for .NET Core SDK 2.0.0-preview1-005977\n* Remove support for .NET Core runtime 1.0.3\n* Remove support for .NET Core runtime 1.1.0\n* Update Node version to 6.11.2","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"},{"document_id":"ibmcld_04621-53410-54611","score":14.3033862777,"text":"\n* Remove support for .NET Runtime 2.2.1\n* Remove support for .NET Runtime 2.2.2\n* Remove support for .NET SDK 1.0.4\n* Remove support for .NET SDK 1.1.11\n* Remove support for .NET SDK 1.1.12\n* Remove support for .NET SDK 2.1.504\n* Remove support for .NET SDK 2.2.104\n* Update Node.js version to 10.15.2`\n\n\n\n\n\n\n\n 14 June 2019 \n\nUpdated Liberty buildpack v3.33-20190619-1058\n: The default Liberty runtime GA version was changed to the [19.0.0.6](https:\/\/openliberty.io\/blog\/2019\/06\/21\/microprofile-rest-client-19006.html) release.\n\n\n\n* The alternate Liberty runtime GA version is also the 19.0.0.6 release.\n* The IBM JRE version was updated to 8 SR5 FP36.\n\n\n\n\n\n\n\n 31 May 2019 \n\nUpdated Node.js buildpack v3.27\n: The SDK for Node.js buildpack v3.27 provides IBM SDK for Node.js versions 4.8.5, 4.8.7 and Node.js community versions 6.17.0, 6.17.1, 8.15.1, 8.16.1, 10.15.0 and 10.16.0. The default is latest 6.x, so it is currently 6.17.1. This is the last SDK for Node.js buildpack that includes v6.x runtimes.\n\n\n\n\n\n 17 May 2019 \n\nUpdated Liberty buildpack v3.32-20190523-1138\n: The default Liberty runtime GA version is [19.0.0.3](https:\/\/openliberty.io\/blog\/2019\/03\/28\/microprofile22-liberty-19003.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-cloud-foundry-public-release-notes"},{"document_id":"ibmcld_00861-218236-219417","score":14.2377883698,"text":"\ned --version\nGNU Ed 1.10\nShow more\n\n\n\n\n\n Version 2.15 \n\nTo view the contents of version 2.15, from the running image, type default_versions.sh.\n\nThe IBM Cloud CLI provides code risk analysis commands. You can use the IBM Cloud CLI to analyze your code for vulnerabilities and compliance with certain rules. Code Risk Analyzer is available in all IBM Cloud regions where toolchains are supported. For more information about Code Risk Analyzer, see [Code Risk Analyzer plug-in](https:\/\/cloud.ibm.com\/docs\/code-risk-analyzer-cli-plugin).\n\nThis image includes the following tools:\n\n node --version\nv14.17.6\n\n npm --version\n6.14.15\n\n jq --version\njq-1.6\n\n yq --version\nyq version 2.4.1\n\n yq3 --version\nyq version 3.4.1\n\n yq4 --version\nyq (https:\/\/github.com\/mikefarah\/yq\/) version 4.13.2\n\n kubectl version --client\nClient Version: version.Info{Major:\"1\", Minor:\"20\", GitVersion:\"v1.20.5\", GitCommit:\"6b1d87acf3c8253c123756b9e61dac642678305f\", GitTreeState:\"clean\", BuildDate:\"2021-03-18T01:10:43Z\", GoVersion:\"go1.15.8\", Compiler:\"gc\", Platform:\"linux\/amd64\"}\n\n buildctl --version\nbuildctl github.com\/moby\/buildkit v0.9.0 c8bb937807d405d92be91f06ce2629e6202ac7a9\n\n helm version --client","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16034-7-1778","score":13.9107722405,"text":"\nVPC CLI release notes \n\nThe following release notes are for the IBM Cloud\u00ae Virtual Private Cloud (VPC) command line interface (CLI).\n\n\n\n v6.15.0 \n\nVersion 6.15.0 was released on 2023-07-11.\n\n\n\n New commands \n\n\n\n* New commands image-obsolete and image-deprecate are introduced to support image lifecycle management.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for image lifecycle management in image-create, image-update, and images commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.14.1 \n\nVersion 6.14.1 was released on 2023-06-30.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed issue with using the SSH key generated from UI in CLI.\n\n\n\n\n\n\n\n\n\n v6.14.0 \n\nVersion 6.14.0 was released on 2023-06-23.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for more algorithms in the SSH key key-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.13.0 \n\nVersion 6.13.0 was released on 2023-06-22.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for snapshot and backup cross region copy in snaphot-create, snapshots, backup-policy-plan-create and backup-policy-plan-update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.12.0 \n\nVersion 6.12.0 was released on 2023-06-01.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for fileshare mount targets in share commands (Beta).\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces, bare-metal-server-profiles and bare-metal-servers commands to print correct response values.\n\n\n\n\n\n\n\n\n\n v6.11.1 \n\nVersion 6.11.1 was released on 2023-05-03.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-2811-4611","score":13.5732237883,"text":"\n* Updated load-balancer-create and load-balancer-update commands to support load balancer private DNS service.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.8.0 \n\nVersion 6.8.0 was released on 2023-03-15.\n\n\n\n New commands \n\nN\/A\n\n\n\n\n\n Updated commands \n\n\n\n* Updated vpc-routing-table-route-create and vpc-routing-table-route-update commands to support route priority feature.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.7.2 \n\nVersion 6.7.2 was released on 2023-03-13.\n\n\n\n New commands \n\nN\/A\n\n\n\n\n\n Updated commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Fixed instances list command to show the floating IP.\n* Fixed instance-volume-attachment-add command optional field issue.\n\n\n\n\n\n\n\n\n\n v6.7.0 \n\nVersion 6.7.0 was released on 2023-03-07.\n\n\n\n New commands \n\nN\/A\n\n\n\n\n\n Updated commands \n\n\n\n* Updated load-balancer-listener-create, and load-balancer-listener-update commands to support load balancer idle connection timeout.\n* Updated volumes command to support attachment-state, encryption, operating-system-family, operating-system-architecture and zone filters.\n* Updated instance-create command to support instance creation from existing boot volume.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.6.0 \n\nVersion 6.6.0 was released on 2023-02-15.\n\n\n\n New commands \n\nN\/A\n\n\n\n\n\n Updated commands \n\n\n\n* Updated instance-create, instance-create-from-template, instance-update, instance-template-create and instance-template-create-override-source-template commands to support instance metadata service.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.5.0 \n\nVersion 6.5.0 was released on 2023-02-07.\n\n\n\n New commands \n\n\n\n* Added snapshot-clone, snapshot-clone-create, snapshot-clone-delete and snapshot-clonescommands to support snapshot fast restore.\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-1402-3222","score":12.9562060571,"text":"\n* Added support for fileshare mount targets in share commands (Beta).\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces, bare-metal-server-profiles and bare-metal-servers commands to print correct response values.\n\n\n\n\n\n\n\n\n\n v6.11.1 \n\nVersion 6.11.1 was released on 2023-05-03.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces and bare-metal-server-network-interface command to print MAC address value.\n\n\n\n\n\n\n\n\n\n v6.11.0 \n\nVersion 6.11.0 was released on 2023-04-27.\n\n\n\n New commands \n\n\n\n* Added image-export-job, image-export-jobs, image-export-job-create, image-export-job-update and image-export-job-delete for image export functionality.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.10.0 \n\nVersion 6.10.0 was released on 2023-03-24.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated instance-profilesand instance-profile commands to support network_interface_count property in the response.\n* Updated bare-metal-server-profiles and bare-metal-server-profile commands to support network_interface_count and console_types properties in the response.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.9.0 \n\nVersion 6.9.0 was released on 2023-03-23.\n\n\n\n New commands \n\nN\/A\n\n\n\n\n\n Updated commands \n\n\n\n* Updated load-balancer-create and load-balancer-update commands to support load balancer private DNS service.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.8.0 \n\nVersion 6.8.0 was released on 2023-03-15.\n\n\n\n New commands \n\nN\/A\n\n\n\n\n\n Updated commands \n\n\n\n* Updated vpc-routing-table-route-create and vpc-routing-table-route-update commands to support route priority feature.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16261-10613-12744","score":12.315361262,"text":"\nBecause we need a way to end the conversation, the client app is also watching for the literal command quit to indicate that the program should exit.\n\nBut something still isn't right:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nI'm afraid I don't understand. Please rephrase your question.\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Thursday\nI'm afraid I don't understand. Please rephrase your question.\n>>\n\nThe assistant is starting out with the correct greeting, but it doesn't understand when you tell it your name. And if you tell it you want to make an appointment, the correct action is triggered; but once again, it doesn't understand when you answer the follow-up question.\n\nThis is happening because we are using the stateless message method, which means that it is the responsibility of our client application to maintain state information for the conversation. Because we are not yet doing anything to maintain state, the assistant sees every round of user input as the first turn of a new conversation. Because it has no memory of asking a question, it tries to interpret your answer as a new question or request.\n\n\n\n\n\n Maintaining state \n\nState information for your conversation is maintained using the context. The context is an object that is passed back and forth between your application and the assistant, storing information that can be preserved and updated as the conversation goes on. Because we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_14118-7-1862","score":12.0726522613,"text":"\nInstalling QuantaStor StorageLink Xenserver \n\n\n\n Installing the QuantaStor Adapter for Citrix StorageLink \n\n\n\n1. Make sure that your installation of XenServer is properly licensed for StorageLink.\n\nOnly customers who subscribe to the \"Enterprise\" or \"Platinum\" licenses through Citrix can use the StorageLink feature. Customers who have the \"Advanced\" Citrix XenServer license can't access the StorageLink feature.\n2. Stop the StorageLink service by entering the following command at an administrator prompt. Or, you can stop the StorageLink service from the Services Panel in XenServer.\n\nC:> net stop storagelink\n3. Download and run the StorageLink adapter available from OSNexus.\n4. After the service stops, you can install the QuantaStor StorageLink adapter by running the following command:\n\nosn_quantastor_csladapter.exe\n5. Add this block of XML to the end of the StorageLink configuration at:\n\n\n\n* C:Program FilesCitrixStorageLinkServerscsi_device_id_config.xml\n* OSNEXUS\n* QUANTASTOR1\n* At the beginning of this file you see a version number that that is similar to 2.0.0.4. Increase the version number, for example: 2.0.0.5. The version number tells StorageLink that it needs to upgrade your XenServer systems with these new device identification rules.\n\n\n\n6. Restart the Citrix StorageLink service:\n\nC:> net start storagelink\n\n\n\n\n\n\n\n Verifying that StorageLink loaded properly \n\n\n\n1. Log in to Citrix StorageLink Manager, select the \"Administration\" tree on the left, and look for OS NEXUS QuantaStor in the QuantaStor list.\n2. Add your storage system credentials so StorageLink can dynamically configure and allocate storage volumes for your QuantaStor storage system.\n\n\n\n\n\n\n\n Installing the XenServer multipath configuration settings \n\nXenServer uses the Linux device-mapper multipath driver (dmmp) to enable support for hardware multi-pathing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-installing-quantastor-storagelink-xenserver"},{"document_id":"ibmcld_16034-17328-19156","score":12.0688645523,"text":"\nInstance commands can now use an ID or name for the command option values.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v1.7.0 \n\nVersion 1.7.0 was released on 2021-10-07.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update load-balancer, vpc-routing-table-route-create, snapshots, vpn-gateway and vpn-server commands with \"by name\" support. These commands can now use an ID or name for the command option values.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v1.6.0 \n\nVersion 1.6.0 was released on 2021-09-15.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update load-balancer-create\/load-balancer-listener-create\/load-balancer-update\/load-balancer-listener-update commands to support the load-balancer vnf support.\n* Update subnet, public gateway, image, floating IP, key, placement-group, flow-log, security group, virtual private endpoint gateway, dedicated host and volume commands with \"by name\" support. These commands can now use an ID or name for the command option values.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v1.5.0 \n\nVersion 1.5.0 was released on 2021-08-27.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance-create\/instance-update\/instance-template-create commands to support the instance attached block storage bandwidth setting.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v1.4.0 \n\nVersion 1.4.0 was released on 2021-08-26.\n\n\n\n New commands \n\n\n\n* Add client-to-site VPN server commands (Beta).\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update vpc\/address-prefix\/routing-table\/route commands with \"by name\" support. These commands can now use an ID or name for the command option values.\n* Update network ACL and network ACL rule commands with \"by name\" support. These commands can now use an ID or name for the command option values.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-25914-27753","score":12.0544494259,"text":"\nVersion 0.7.0 was released on 2020-10-30.\n\n\n\n New commands \n\n\n\n* Add 'create', 'update', 'list', 'get', 'delete' commands for VPC routing-table and routes (custom routes) feature\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add 'allow-ip-spoofing' flag for network-interface in instance create and network-interface create\/update commands\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.6.6 \n\nVersion 0.6.6 was released on 2020-10-23.\n\n\n\n New commands \n\n\n\n* Add load-balancer-pool-members-update command to replace the entire pool members\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Remove the DNS service from endpoint-gateway-targets command output\n* Add --members flag to load-balancer-pool-create command to support creating pool with members\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.6.4 \n\nVersion 0.6.4 was released on 2020-09-16.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update all deletion commands to support batch deletion.\n* Update vpc-routing-table-create and vpc-routing-table-update to support ingress custom routing feature.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.6.3 \n\nVersion 0.6.3 was released on 2020-08-24.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update VPC API version to 2020-08-11\n* Update network load balancer create command with '--family network' instead of the --profile option.\n* Update load-balancer-pool-update command to reset the session-persistence to null with '--session-persistence-type none'.\n* Update \u2018target\u2019 command to support only the accounts that have generation 1 access.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* Hide 'load-balancer-profiles' command and it will be removed in next major release.\n* Hide 'load-balancer-profile' command and it will be removed in next major release.\n* Hide the 'target' command for the account that doesn't have generation 1 access.\n\n\n\n\n\n\n\n\n\n v0.6.2","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-4138-5877","score":12.0017246551,"text":"\n* Updated instance-create, instance-create-from-template, instance-update, instance-template-create and instance-template-create-override-source-template commands to support instance metadata service.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.5.0 \n\nVersion 6.5.0 was released on 2023-02-07.\n\n\n\n New commands \n\n\n\n* Added snapshot-clone, snapshot-clone-create, snapshot-clone-delete and snapshot-clonescommands to support snapshot fast restore.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated snapshot-create, backup-policy-create, backup-policy-plan-create and backup-policy-plan-update commands to support snapshot and backup fast restore.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.4.0 \n\nVersion 6.4.0 was released on 2023-01-31.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated bare-metal-server-create, bare-metal-server-update and bare-metal-server commands to support secure boot mode and TPM.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.3.0 \n\nVersion 6.3.0 was released on 2023-01-13.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated ike-policy-create, ike-policy-update, ipsec-policy-create and ipsec-policy-update commands to remove the weak ciphers.\n* Updated vpn-server-create, vpn-server-update, load-balancer-listener-create and load-balancer-listener-update commands to remove the certificate manager support.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.2.0 \n\nVersion 6.2.0 was released on 2022-12-14.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated volume-create command to support creation of volume from snapshot.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.1.0 \n\nVersion 6.1.0 was released on 2022-11-21.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-5546-7299","score":11.9941620474,"text":"\nv6.2.0 \n\nVersion 6.2.0 was released on 2022-12-14.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated volume-create command to support creation of volume from snapshot.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.1.0 \n\nVersion 6.1.0 was released on 2022-11-21.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated vpc-default-routing-table, vpc-routing-table , vpc-routing-table-create, vpc-routing-table-update commands to support Public Ingress Routing.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.0.0 \n\nVersion 6.0.0 was released on 2022-11-03.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated VPC API version to 2022-09-13.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Fixed backup-policy-job and backup-policy-jobs commands to support Backup As A Service Amendment.\n\n\n\n\n\n\n\n\n\n v5.4.0 \n\nVersion 5.4.0 was released on 2022-10-06.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated instance-create and instance-update commands to support VNF Scalability.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v5.3.0 \n\nVersion 5.3.0 was released on 2022-09-23.\n\n\n\n New commands \n\n\n\n* Added ibmcloud is catalog-image-offerings and ibmcloud is catalog-image-offering commands to support Enterprise Image Sharing.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated instance-create , instance-create-from-template , instance-template-create and instance-template-create-override-source-template commands to support Enterprise Image Sharing.\n* Updated ike-policy-create , ike-policy-update , ipsec-policy-create and ipsec-policy-update commands to support Additional Cipher Suites for VPN.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v5.2.0 \n\nVersion 5.2.0 was released on 2022-09-16.\n\n\n\n New commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-24499-26290","score":11.6556051526,"text":"\nVersion 0.7.7 was released on 2021-02-08.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Remove the restriction for Generation 1 target switching.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.4 \n\nVersion 0.7.4 was released on 2020-12-10.\n\n\n\n New commands \n\n\n\n* Add instance storage disk get, list, and update commands.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add flag aliases for routing table create and update commands.\n* Updated usage for ibmcloud is vpc-address-prefix-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.3 \n\nVersion 0.7.3 was released on 2020-11-19.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add datapath logging support for load balancer create and update commands\n* Add ingress routing support for VPC routing table create and update commands\n* Add required family\/class flags for dedicated host group create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.2 \n\nVersion 0.7.2 was released on 2020-11-12.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add static, route-based mode support for creating a VPN gateway and connection.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.1 \n\nVersion 0.7.1 was released on 2020-11-05.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add proxy-protocol feature support for load balancer listener\/pool create and update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.0 \n\nVersion 0.7.0 was released on 2020-10-30.\n\n\n\n New commands \n\n\n\n* Add 'create', 'update', 'list', 'get', 'delete' commands for VPC routing-table and routes (custom routes) feature\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add 'allow-ip-spoofing' flag for network-interface in instance create and network-interface create\/update commands\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.6.6","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14118-7-1862","score":11.9592330951,"text":"\nInstalling QuantaStor StorageLink Xenserver \n\n\n\n Installing the QuantaStor Adapter for Citrix StorageLink \n\n\n\n1. Make sure that your installation of XenServer is properly licensed for StorageLink.\n\nOnly customers who subscribe to the \"Enterprise\" or \"Platinum\" licenses through Citrix can use the StorageLink feature. Customers who have the \"Advanced\" Citrix XenServer license can't access the StorageLink feature.\n2. Stop the StorageLink service by entering the following command at an administrator prompt. Or, you can stop the StorageLink service from the Services Panel in XenServer.\n\nC:> net stop storagelink\n3. Download and run the StorageLink adapter available from OSNexus.\n4. After the service stops, you can install the QuantaStor StorageLink adapter by running the following command:\n\nosn_quantastor_csladapter.exe\n5. Add this block of XML to the end of the StorageLink configuration at:\n\n\n\n* C:Program FilesCitrixStorageLinkServerscsi_device_id_config.xml\n* OSNEXUS\n* QUANTASTOR1\n* At the beginning of this file you see a version number that that is similar to 2.0.0.4. Increase the version number, for example: 2.0.0.5. The version number tells StorageLink that it needs to upgrade your XenServer systems with these new device identification rules.\n\n\n\n6. Restart the Citrix StorageLink service:\n\nC:> net start storagelink\n\n\n\n\n\n\n\n Verifying that StorageLink loaded properly \n\n\n\n1. Log in to Citrix StorageLink Manager, select the \"Administration\" tree on the left, and look for OS NEXUS QuantaStor in the QuantaStor list.\n2. Add your storage system credentials so StorageLink can dynamically configure and allocate storage volumes for your QuantaStor storage system.\n\n\n\n\n\n\n\n Installing the XenServer multipath configuration settings \n\nXenServer uses the Linux device-mapper multipath driver (dmmp) to enable support for hardware multi-pathing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtualization?topic=virtualization-installing-quantastor-storagelink-xenserver"},{"document_id":"ibmcld_03040-17293-19179","score":11.5377532058,"text":"\n: You can deploy IBM Cloud Pak\u00ae for Data Version 4.5 on the following versions of Red Hat OpenShift Container Platform:\n\n\n\n* Version 4.6.29 or later fixes\n* Version 4.8.0 or later fixes\n* Version 4.10.0 or later fixes\n\n\n\nNew IBM Cloud Pak\u00ae for Data CLI commands and reference\n: Starting in IBM Cloud Pak\u00ae for Data Version 4.5, the cpd-cli includes new commands and a new command reference. For more information, see the [cpd-cli command reference](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-data\/4.5.x?topic=interface-cpd-cli-command-reference).\n\nMicrosoft Edge browser support\n: Beginning in Version 4.5, Microsoft Edge is fully supported for use with IBM Cloud Pak\u00ae for Data. For more information, see [Browser support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-indexindex-browser-support).\n\nLanguage support improvements\n: Entity recognition and intent classification for Japanese and Korean languages changed to improve the reliability of Watson Assistant. You might see minor differences in how Watson Assistant handles entity recognition and intent classification.\n\nAny visible changes are most likely to be seen in dictionary-based or pattern-based entity matching. For more information about defining entities, see [Adding entities](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entities). As a suggested practice, you can test your dialog skill with your current test framework to determine whether your workspace is impacted before you update your production workspace.\n\nIf entity values or synonyms that previously matched no longer match, you can update the entity and add a synonym with white space between the tokens, for example:\n\n\n\n* Japanese: Add \u201c\u898b \u305f\u201d as a synonym for \u201c\u898b\u305f\u201d\n* Korean: Add \u201c\uc798 \uc790 \uc694\u201d as a synonym for \u201c\uc798\uc790\uc694\u201d\n\n\n\nAssistant preview link can be disabled\n: Assistant preview now includes a toggle to disable the preview link.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-release-notes"},{"document_id":"ibmcld_16034-5546-7299","score":11.0336206594,"text":"\nv6.2.0 \n\nVersion 6.2.0 was released on 2022-12-14.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated volume-create command to support creation of volume from snapshot.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.1.0 \n\nVersion 6.1.0 was released on 2022-11-21.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated vpc-default-routing-table, vpc-routing-table , vpc-routing-table-create, vpc-routing-table-update commands to support Public Ingress Routing.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.0.0 \n\nVersion 6.0.0 was released on 2022-11-03.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated VPC API version to 2022-09-13.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Fixed backup-policy-job and backup-policy-jobs commands to support Backup As A Service Amendment.\n\n\n\n\n\n\n\n\n\n v5.4.0 \n\nVersion 5.4.0 was released on 2022-10-06.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated instance-create and instance-update commands to support VNF Scalability.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v5.3.0 \n\nVersion 5.3.0 was released on 2022-09-23.\n\n\n\n New commands \n\n\n\n* Added ibmcloud is catalog-image-offerings and ibmcloud is catalog-image-offering commands to support Enterprise Image Sharing.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated instance-create , instance-create-from-template , instance-template-create and instance-template-create-override-source-template commands to support Enterprise Image Sharing.\n* Updated ike-policy-create , ike-policy-update , ipsec-policy-create and ipsec-policy-update commands to support Additional Cipher Suites for VPN.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v5.2.0 \n\nVersion 5.2.0 was released on 2022-09-16.\n\n\n\n New commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16261-10613-12744","score":10.9877667624,"text":"\nBecause we need a way to end the conversation, the client app is also watching for the literal command quit to indicate that the program should exit.\n\nBut something still isn't right:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nI'm afraid I don't understand. Please rephrase your question.\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Thursday\nI'm afraid I don't understand. Please rephrase your question.\n>>\n\nThe assistant is starting out with the correct greeting, but it doesn't understand when you tell it your name. And if you tell it you want to make an appointment, the correct action is triggered; but once again, it doesn't understand when you answer the follow-up question.\n\nThis is happening because we are using the stateless message method, which means that it is the responsibility of our client application to maintain state information for the conversation. Because we are not yet doing anything to maintain state, the assistant sees every round of user input as the first turn of a new conversation. Because it has no memory of asking a question, it tries to interpret your answer as a new question or request.\n\n\n\n\n\n Maintaining state \n\nState information for your conversation is maintained using the context. The context is an object that is passed back and forth between your application and the assistant, storing information that can be preserved and updated as the conversation goes on. Because we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client"},{"document_id":"ibmcld_16034-7-1778","score":10.8767500952,"text":"\nVPC CLI release notes \n\nThe following release notes are for the IBM Cloud\u00ae Virtual Private Cloud (VPC) command line interface (CLI).\n\n\n\n v6.15.0 \n\nVersion 6.15.0 was released on 2023-07-11.\n\n\n\n New commands \n\n\n\n* New commands image-obsolete and image-deprecate are introduced to support image lifecycle management.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for image lifecycle management in image-create, image-update, and images commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.14.1 \n\nVersion 6.14.1 was released on 2023-06-30.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed issue with using the SSH key generated from UI in CLI.\n\n\n\n\n\n\n\n\n\n v6.14.0 \n\nVersion 6.14.0 was released on 2023-06-23.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for more algorithms in the SSH key key-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.13.0 \n\nVersion 6.13.0 was released on 2023-06-22.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for snapshot and backup cross region copy in snaphot-create, snapshots, backup-policy-plan-create and backup-policy-plan-update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.12.0 \n\nVersion 6.12.0 was released on 2023-06-01.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for fileshare mount targets in share commands (Beta).\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces, bare-metal-server-profiles and bare-metal-servers commands to print correct response values.\n\n\n\n\n\n\n\n\n\n v6.11.1 \n\nVersion 6.11.1 was released on 2023-05-03.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-14851-15753","score":10.8206220036,"text":"\n* N\/A\n\n\n\n\n\n\n\n\n\n v3.0.0 \n\nVersion 3.0.0 was released on 2022-01-19.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update security-group-target, security-group-target-add, security-group-target-remove, and endpoint-gateway-create commands to add security group support for endpoint-gateway.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Removed the support for creation of load balancer listener with port and protocol as arguments.\n\n\n\n\n\n\n\n\n\n v2.1.0 \n\nVersion 2.1.0 was released on 2021-11-29.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update vpn-server-update command to support VPN server upgrade and downgrade.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Linux_S390x build support added.\n\n\n\n\n\n\n\n\n\n v2.0.0 \n\nVersion 2.0.0 was released on 2021-11-18.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance commands with \"by name\" support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-12689-13797","score":10.7937115956,"text":"\nVersion 3.4.0 was released on 2022-02-24.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance-create, instance-update, instance-template-create, instance-template-create-override-source-template and instance-create-from-template commands to support metadata service.\n* Update instance-create and instance-create-from-template commands to support trusted profile.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v3.3.0 \n\nVersion 3.3.0 was released on 2022-02-17.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance-create, instance-update, instance-template-create, instance-template-create-override-source-template and instance-create-from-template, commands to add support for vm-host-failure-policy.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v3.2.0 \n\nVersion 3.2.0 was released on 2022-02-11.\n\n\n\n New commands \n\n\n\n* N\/A.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance-create, instance-update and volume-update commands to support resize boot volume.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v3.1.0 \n\nVersion 3.1.0 was released on 2022-01-28.\n\n\n\n New commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-24499-26290","score":10.7527354238,"text":"\nVersion 0.7.7 was released on 2021-02-08.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Remove the restriction for Generation 1 target switching.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.4 \n\nVersion 0.7.4 was released on 2020-12-10.\n\n\n\n New commands \n\n\n\n* Add instance storage disk get, list, and update commands.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add flag aliases for routing table create and update commands.\n* Updated usage for ibmcloud is vpc-address-prefix-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.3 \n\nVersion 0.7.3 was released on 2020-11-19.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add datapath logging support for load balancer create and update commands\n* Add ingress routing support for VPC routing table create and update commands\n* Add required family\/class flags for dedicated host group create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.2 \n\nVersion 0.7.2 was released on 2020-11-12.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add static, route-based mode support for creating a VPN gateway and connection.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.1 \n\nVersion 0.7.1 was released on 2020-11-05.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add proxy-protocol feature support for load balancer listener\/pool create and update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.7.0 \n\nVersion 0.7.0 was released on 2020-10-30.\n\n\n\n New commands \n\n\n\n* Add 'create', 'update', 'list', 'get', 'delete' commands for VPC routing-table and routes (custom routes) feature\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add 'allow-ip-spoofing' flag for network-interface in instance create and network-interface create\/update commands\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.6.6","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-4138-5877","score":10.6592417186,"text":"\n* Updated instance-create, instance-create-from-template, instance-update, instance-template-create and instance-template-create-override-source-template commands to support instance metadata service.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.5.0 \n\nVersion 6.5.0 was released on 2023-02-07.\n\n\n\n New commands \n\n\n\n* Added snapshot-clone, snapshot-clone-create, snapshot-clone-delete and snapshot-clonescommands to support snapshot fast restore.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated snapshot-create, backup-policy-create, backup-policy-plan-create and backup-policy-plan-update commands to support snapshot and backup fast restore.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.4.0 \n\nVersion 6.4.0 was released on 2023-01-31.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated bare-metal-server-create, bare-metal-server-update and bare-metal-server commands to support secure boot mode and TPM.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.3.0 \n\nVersion 6.3.0 was released on 2023-01-13.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated ike-policy-create, ike-policy-update, ipsec-policy-create and ipsec-policy-update commands to remove the weak ciphers.\n* Updated vpn-server-create, vpn-server-update, load-balancer-listener-create and load-balancer-listener-update commands to remove the certificate manager support.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.2.0 \n\nVersion 6.2.0 was released on 2022-12-14.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated volume-create command to support creation of volume from snapshot.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.1.0 \n\nVersion 6.1.0 was released on 2022-11-21.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-20235-22099","score":10.6220072557,"text":"\n* Update ibmcloud is instance command to show the placement group as the placement target if the instance is created with the specific placement group.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v1.1.0 \n\nVersion 1.0.0 was released on 2021-07-16.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update ibmcloud is volume-update command to expand all volume sizes up to 16 TB.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v1.0.0 \n\nVersion 1.0.0 was released on 2021-07-08.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Hide the ibmcloud is target command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* Remove generation 1 support from commands.\n* Remove the target generation switching in ibmcloud is target command.\n\n\n\n\n\n\n\n\n\n v0.8.6 \n\nVersion 0.8.6 was released on 2021-06-17.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add cookie persistence support for load-balancer-pool-create, load-balancer-pool-update and load-balancer-pool commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v0.8.5 \n\nVersion 0.8.5 was released on 2021-05-20.\n\n\n\n New commands \n\n\n\n* Add commands snapshots, snapshot, snapshot-create, snapshot-update, snapshot-delete-from-source, snapshot-delete for the snapshot feature.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Add --source-volume option of the image-create command for the image from volume feature.\n* Update --boot-volume, --volume-attach options of the instance-create command to support JSON format with source_snapshot property setting that supports restoring volume from source snapshot.\n\n\n\n\n\n\n\n\n\n v0.8.4 \n\nVersion 0.8.4 was released on 2021-05-18.\n\n\n\n New commands \n\n\n\n* Add commands instance-group-manager-actions, instance-group-manager-action, instance-group-manager-action-create, instance-group-manager-action-delete, instance-group-manager-action-update for scheduled scaling feature.\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15507-5434-7003","score":45.2635482891,"text":"\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-25256-26940","score":43.8873781644,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-25269-26966","score":43.8008694194,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15647-27849-29558","score":42.1870786118,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15646-27823-29559","score":41.9612308112,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_16601-1150-2518","score":41.2120704743,"text":"\n* [Salesforce SDK](https:\/\/github.com\/watson-developer-cloud\/salesforce-sdk)\n* [Swift SDK](https:\/\/github.com\/watson-developer-cloud\/swift-sdk)\n* [Unity SDK](https:\/\/github.com\/watson-developer-cloud\/unity-sdk)\n\n\n\n\n\n\n\n SDK updates and deprecation \n\nThe supported Watson SDKs are updated according to the following guidelines.\n\n\n\n Semantic versioning \n\nSupported Watson SDKs adhere to semantic versioning with releases labeled as {major}.{minor}.{patch}.\n\n\n\n\n\n Release frequency \n\nSDKs are released independently and might not update on the same schedule.\n\n\n\n* The current releases of the Watson SDKs are updated on a 2- to 6-week schedule. These releases are either minor updates or patches that do not include breaking changes. You can update to any version of the SDK with the same major version number.\n* Major updates that might include breaking changes are released approximately every 6 months.\n\n\n\n\n\n\n\n Deprecated release \n\nWhen a major version is released, support continues on the previous major release for 12 months in a deprecation period. The deprecated release might be updated with bug fixes, but no new features will be added and documentation might not be available.\n\n\n\n\n\n Obsolete release \n\nAfter the 12-month deprecation period, a release is obsolete. The release might be functional but is unsupported and not updated. Update to the current release.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-using-sdks"},{"document_id":"ibmcld_15507-8094-9618","score":40.3054981423,"text":"\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15507-6657-8493","score":39.7749632753,"text":"\nIf you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Removing previously scheduled image from volume lifecycle statuses by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Changing an image from volume lifecycle status by using the API \n\nYou can change the lifecycle status of a IBM Cloud VPC image from volume by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15175-10224-11754","score":39.3265327,"text":"\necc68c2f-96a1-4862-bc86-14f47e5d9ed8 aa-1-bx-boot-1617035447000\nCreated 2021-05-20T09:43:16+08:00\nVisibility private\nFile size(GB) -\nEncryption none\nResource group f22cf48f-8836-4527-9131-1d7c73ba85e9\n\n\n\n\n\n\n\n Schedule custom image lifecycle status changes by using the CLI \n\nWhen you import a custom image by using the command-line interface (CLI), you can also schedule the lifecycle status changes of the IBM Cloud VPC custom image at the same time by using options of the ibmcloud is image-create command.\n\nSpecify the name of the custom image to be created by using the IMAGE_NAME variable and the source by using the --source-volume option to indicate that the source is an existing boot volume.\n\nTo schedule the deprecate-at or obsolete-at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates and times, the deprecate-at date must be after the obsolete-at date and time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-ifv"},{"document_id":"ibmcld_15646-26617-28366","score":39.1053540132,"text":"\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again. The previous dates and times are then replaced with the new dates and times.\n\n\n\n\n\n Remove a previously scheduled custom image lifecycle status change by using the CLI \n\nYou can remove a scheduled status change by using the --reset-deprecate-at or --reset-obsolete-at options. If you use either of these options with the ibmcloud is image-update command, the date and time are removed from the image. The image is no longer scheduled for that status change.\n\nibmcloud is image-update IMAGE [--reset-deprecate-at] [--reset-obsolete-at]\n\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.2857142857,"recall_5":0.2857142857,"recall_10":0.4285714286,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.3835663674,"ndcg_cut_10":0.3975796519}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":21.8633239808,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_06843-4238-6198","score":20.1997347662,"text":"\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline"},{"document_id":"ibmcld_12498-9696-11699","score":18.6124355994,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_06836-7569-8653","score":17.8918634775,"text":"\nup from the environment-properties configmap\n\n Eg. if there's a prop: my-config entry in the environment properties,\n then my-config is going to be used for $prop\nconfigmap: $prop\n\n the mechanism described works for secrets as well!\nsecret: $my-secrets\n\n the script is executed inside the checked out app repo\nscript: \n!\/bin\/sh\n...\n\n test runs after setup, but before building the docker image\ntest:\nimage: ibmcom\/pipeline-base-image:2.7\nscript: \n!\/bin\/sh\n...\n\n static-scan runs after test, but before building the docker image\nstatic-scan:\nimage: ibmcom\/pipeline-base-image:2.12\nscript: \n!\/bin\/sh\n...\n\n deploy runs after building the docker image\ndeploy:\nimage: ibmcom\/pipeline-base-image:2.7\n\n the script has access to the built docker image, which is available at \/config\/image\nscript: \n!\/bin\/sh\n\ncat \/config\/image\n\n dynamic-scan runs after deploy, but before the acceptance test run\ndynamic-scan:\nimage: ibmcom\/pipeline-base-image:2.12\nscript: \n!\/bin\/sh\n...\n\n acceptance-test runs after deploy\nacceptance-test:\nimage: ibmcom\/pipeline-base-image:2.7\nscript: \n!\/bin\/sh\n...\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-scripts"},{"document_id":"ibmcld_07844-4589-6711","score":16.6160855109,"text":"\nRA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n RA-5 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nSecurity categorization of information systems guides the frequency and comprehensiveness of vulnerability scans. Organizations determine the required vulnerability scanning for all information system components, ensuring that potential sources of vulnerabilities such as networked printers, scanners, and copiers are not overlooked. Vulnerability analyses for custom software applications may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_16729-294066-295916","score":15.9765456031,"text":"\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Getting started with Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started)Getting started with Secrets Manager\n\nThis tutorial focuses on storing and managing a username and password in IBM Cloud\u00ae Secrets Manager. With Secrets Manager, you can create, lease, and centrally manage secrets that are used in IBM Cloud services or your custom-built applications. Secrets are stored in a dedicated Secrets Manager instance, built on open source HashiCorp Vault.\n\nSecrets Manager\n\n\n\n* 10 minutes\n* 2023-03-01\n\n\n\n[Access a storage bucket by using a dynamic secret](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket)Access a storage bucket by using a dynamic secret\n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nSecrets Manager Object Storage\n\n\n\n* 1 hour\n* 2023-05-30\n\n\n\n[Secure secrets for apps that run in your Kubernetes cluster](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-kubernetes-secrets)Secure secrets for apps that run in your Kubernetes cluster\n\nThis tutorial is for the Classic flavor of Kubernetes Service clusters. External Secrets is also available as an OpenShift operator.\n\nSecrets Manager\n\n\n\n* 45 minutes\n* 2023-06-15\n\n\n\n[Part 2: Create a GitHub issue when your certificates are about to expire](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-expiring-secrets-part-2)Part 2: Create a GitHub issue when your certificates are about to expire","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_07844-3757-5369","score":15.9452264358,"text":"\nRA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_07844-2925-4586","score":15.8376976385,"text":"\nRA-5 (a) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_12415-7-1973","score":15.4206614234,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_07899-3004-4915","score":15.0752335227,"text":"\nSI-2 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain verifies source code branch protection rules to enforce security policies<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes unit tests to validate all code changes<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br> \n SI-2 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-si-2"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.8315546296}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07899-3004-4915","score":22.3771513654,"text":"\nSI-2 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain verifies source code branch protection rules to enforce security policies<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes unit tests to validate all code changes<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br> \n SI-2 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-si-2"},{"document_id":"ibmcld_07899-4108-6235","score":21.8313244362,"text":"\nSI-2 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br> \n SI-2 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain verifies source code branch protection rules to enforce security policies<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain collects software bills of materials (SBOM) to provide transparency in build artifacts<br> * Check whether DevSecOps Toolchain passes unit tests to validate all code changes<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br> * Check whether DevSecOps Toolchain signs build artifacts to attest their provenance<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-si-2"},{"document_id":"ibmcld_12724-3197-5566","score":21.3088865818,"text":"\n6.3 Ensure Toolchain has Code Risk Analyzer configured that collects a bill of materials for pipeline run Ensure DevSecOps Toolchain collects software bills of materials (SBOM) to provide transparency in build artifacts \n 6.4 Ensure Toolchain is configured with image signing Ensure DevSecOps Toolchain signs build artifacts to attest their provenance \n 6.5 Ensure Toolchain source code meets Center for Internet Security Docker benchmarks Ensure DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely \n 6.6 Ensure Toolchain has branch protection rules enabled Ensure DevSecOps Toolchain verifies source code branch protection rules to enforce security policies \n 6.7 Ensure Toolchain has secret detection scans enabled for source code Ensure DevSecOps Toolchain source code contains no secrets \n 6.8 Ensure Toolchain production change request exists and is approved Ensure DevSecOps Toolchain deployment has approved change documentation including security impact analysis \n 6.9 Ensure Toolchain Container Registry Vulnerability Advisor scans images for OS vulnerability detection Ensure DevSecOps Toolchain scans build artifacts to identify vulnerabilities \n 6.12 Ensure Toolchain acceptance tests exist and have passed Ensure DevSecOps Toolchain passes acceptance tests to validate every deployment \n 6.16 Ensure that only the tool integrations within the toolchain are included in the allow list parameter array Ensure Toolchain is configured only with the allowed integration tools \n 6.17 Ensure a Toolchain static scan exists and has passed Ensure DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code \n 6.18 Ensure a Toolchain dynamic scan exists and has passed Ensure DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts \n\n\n\n\n\n\n\n 13 March 2023 \n\nThe following new controls have been added to the IBM Cloud Security Best Practices library and profile as of 17 March 2023.\n\n\n\nTable. Summary of IBM Cloud Security Best Practices profile changes for Version 1.1.0\n\n Control ID Control Description \n\n 6.1 Ensure Toolchain scans during continuous integration the source code to identify vulnerabilities \n 6.2 Ensure Toolchain has unit tests that are continuously run to validate source code changes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-ibm-sec-best-practices-change-log"},{"document_id":"ibmcld_07844-4589-6711","score":20.811011829,"text":"\nRA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n RA-5 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nSecurity categorization of information systems guides the frequency and comprehensiveness of vulnerability scans. Organizations determine the required vulnerability scanning for all information system components, ensuring that potential sources of vulnerabilities such as networked printers, scanners, and copiers are not overlooked. Vulnerability analyses for custom software applications may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_06836-18833-20499","score":20.6039009763,"text":"\nPull request pipeline stages setup, test, detect-secrets, and branch-protection. The detect-secrets and branch-protection stages are not custom stages. They are provided by the pipelines by default. \n Continuous integration pipeline stages setup, test, static-scan, containerize, sign-artifact, deploy, acceptance-test, scan-artifact, release, detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan. The detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan stages are not custom stages. They are provided by the pipelines by default. \n continuous deployment pipeline stages setup, deploy, acceptance-test, create-change-request, change-request-check-approval, change-request-change-state-to-implement, and close-change-request. The create-change-request, change-request-check-approval, change-request-change-state-to-implement, and close-change-request stages are not custom stages. They are provided by the pipelines by default. \n Continuous compliance pipeline stages setup, test, static-scan, scan-artifact, acceptance-test, detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan. The detect-secrets, branch-protection, bom-check, cis-check, and vulnerability-scan stages are not custom stages. They are provided by the pipelines by default. \n\n\n\n\n\n Example usage \n\n List saved stage results\n$ get_data result\ndetect-secrets\nbranch-protection\n\n Get stage result\n$ get_data result detect-secrets\nsuccess\n\nFor more information about the Stage Results API, see [Using the Stage Results API in custom scripts](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-stage-results).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-scripts"},{"document_id":"ibmcld_07844-2925-4586","score":20.4485352996,"text":"\nRA-5 (a) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_07844-3757-5369","score":20.3153638797,"text":"\nRA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_06843-4238-6198","score":20.0047145434,"text":"\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline"},{"document_id":"ibmcld_07851-2592-4584","score":20.0002015391,"text":"\nSA-10 (c) <br><br> * Check whether DevSecOps Toolchain signs build artifacts to attest their provenance<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br> \n SA-10 (d) <br><br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br> \n SA-10 (e) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain verifies source code branch protection rules to enforce security policies<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nThis control also applies to organizations conducting internal information systems development and integration. Organizations consider the quality and completeness of the configuration management activities conducted by developers as evidence of applying effective security safeguards. Safeguards include, for example, protecting from unauthorized modification or destruction, the master copies of all material used to generate security-relevant portions of the system hardware, software, and firmware. Maintaining the integrity of changes to the information system, information system component, or information system service requires configuration control throughout the system development life cycle to track authorized changes and prevent unauthorized changes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-sa-10"},{"document_id":"ibmcld_07844-5372-7725","score":19.672736499,"text":"\nRA-5 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nSecurity categorization of information systems guides the frequency and comprehensiveness of vulnerability scans. Organizations determine the required vulnerability scanning for all information system components, ensuring that potential sources of vulnerabilities such as networked printers, scanners, and copiers are not overlooked. Vulnerability analyses for custom software applications may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches. Organizations can employ these analysis approaches in a variety of tools (e.g., web-based application scanners, static analysis tools, binary analyzers) and in source code reviews. Vulnerability scanning includes, for example: (i) scanning for patch levels; (ii) scanning for functions, ports, protocols, and services that should not be accessible to users or devices; and (iii) scanning for improperly configured or incorrectly operating information flow control mechanisms. Organizations consider using tools that express vulnerabilities in the Common Vulnerabilities and Exposures (CVE) naming convention and that use the Open Vulnerability Assessment Language (OVAL) to determine\/test for the presence of vulnerabilities. Suggested sources for vulnerability information include the Common Weakness Enumeration (CWE) listing and the National Vulnerability Database (NVD). In addition, security control assessments such as red team exercises provide other sources of potential vulnerabilities for which to scan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3154648768}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":26.7348755844,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12498-9696-11699","score":24.5575227326,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_00894-7096-9156","score":23.6281807149,"text":"\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"},{"document_id":"ibmcld_12960-7096-9156","score":23.6281807149,"text":"\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"},{"document_id":"ibmcld_12415-7-1973","score":23.5761482461,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_12422-4077-6158","score":23.0085883563,"text":"\nIf you'd like to continue to use those credentials through the end of the lease of your secret, you can set Reuse IAM credentials until lease expires to On. When you enable this option, your secret retains its current service ID, and API key values and reuses them on each read while the secret remains valid. After the secret reaches the end of its lease, the credentials are revoked automatically.\n\nIf the reuse IAM credentials option is set to Off, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. Or, if you prefer to generate both a service ID and an API key, you can assign access by choosing an access group.\n\nIn the Assign access step of the Create IAM credentials wizard, choose a scope of access for your credentials.\n\n\n\n1. To use an existing service ID, select an ID from the list.\n\nChoose this option when you need Secrets Manager to generate and manage only an API key for your IAM credentials secret, and not the service ID itself. The API key inherits the access policy of the service ID that you select from your account. Only the service IDs that you have access to are displayed.\n2. To generate both a new service ID and API key for the secret, select an access group.\n\nBy selecting an access group from your IBM Cloud account, you determine the scope of access to assign to the service ID and the API key. The API key is dynamically generated and associated with your new IAM credential. This step ensures that your IAM credentials are scoped with the preferred level of permissions in your IBM Cloud account. You can assign up to 10 access groups.\n\n\n\nIf you used an existing service ID, the API key that was generated by Secrets Manager is automatically locked.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_12428-3937-6070","score":22.8914706171,"text":"\nBy default, the service ID and API key are single-use, ephemeral values that are generated and deleted each time that an IAM credentials secret is read or accessed.\n\nIf you'd like to continue to use those credentials through the end of the lease of your secret, you can set Reuse IAM credentials until lease expires to On. When you enable this option, your secret retains its current service ID, and API key values and reuses them on each read while the secret remains valid. After the secret reaches the end of its lease, the credentials are revoked automatically.\n\nIf the reuse IAM credentials option is set to Off, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. Or, if you prefer to generate both a service ID and an API key, you can assign access by choosing an access group.\n\nIn the Assign access step of the Create IAM credentials wizard, choose a scope of access for your credentials.\n\n\n\n1. To use an existing service ID, select an ID from the list.\n\nChoose this option when you need Secrets Manager to generate and manage only an API key for your IAM credentials secret, and not the service ID itself. The API key inherits the access policy of the service ID that you select from your account. Only the service IDs that you have access to are displayed.\n2. To generate both a new service ID and API key for the secret, select an access group.\n\nBy selecting an access group from your IBM Cloud account, you determine the scope of access to assign to the service ID and the API key. The API key is dynamically generated and associated with your new IAM credential. This step ensures that your IAM credentials are scoped with the preferred level of permissions in your IBM Cloud account. You can assign up to 10 access groups.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"},{"document_id":"ibmcld_12945-5261-7283","score":22.8745684343,"text":"\nBy using references to secrets that are managed by secret providers such as Key Protect, your secret values are centralized and stored securely in a single location. This approach resolves secrets sprawl and proliferation, and means that you can update secrets without updating your toolchain. When you use secret references, the actual secret value is resolved when the toolchain runs by dynamically retrieving it from Key Protect. This approach is useful when you must rotate the value of your toolchain secrets periodically.\n\n\n\n\n\n Adding a Key Protect tool integration to your toolchain template \n\nYou can add a Key Protect tool integration to your toolchain template by adding a service definition to the toolchain.yml file in your template repo. This file is the design blueprint for your toolchain and includes all of the tool integrations that are available when you create a toolchain instance based on that template. To customize an existing toolchain template to include a Key Protect tool integration, insert a YAML definition.\n\nkp-tool:\nservice_id: keyprotect\nparameters:\nname: kp-compliance-secrets\nregion: us-south\nresource-group: default\ninstance-name: ffs-secrets\n\nFor more information about customizing toolchain templates, see [Create a template for a custom toolchain](https:\/\/www.ibm.com\/cloud\/architecture\/tutorials\/create-a-template-for-a-custom-toolchain).\n\nIn certain scenarios, you can add a Key Protect tool integration dynamically while creating a toolchain. For example, if you click New to mint a new API key, you can select the Save this key in a secrets store for reuse checkbox to save the API key in a Key Protect instance to use it again later. If you do not already have a Key Protect instance, a new instance is created for you.\n\n\n\n\n\n Authorizing your toolchain to access secrets \n\nReferences to secrets that are stored in Key Protect are dynamically resolved when the toolchain runs. To access the required secrets, you must authorize your toolchain to access the Key Protect instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-keyprotect"},{"document_id":"ibmcld_07578-1215486-1217535","score":22.7476242857,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1218119-1220168","score":22.7476242857,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.39038005}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":18.9874553527,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12422-4-1817","score":18.6183975684,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Creating IAM credentials \n\nYou can use IBM Cloud\u00ae Secrets Manager to dynamically generate IAM credentials for accessing an IBM Cloud resource that requires IAM authentication.\n\nIAM credentials are\n\ndynamic secretsthat you can use to access an IBM Cloud resource. A set of IAM credentials consists of a service ID and an API key that is generated each time that the protected resource is read or accessed. You can define a time-to-live (TTL) or a lease duration for your IAM credential at its creation so that you shorten the amount of time that the secret exists.\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\nIAM credentials require an extra configuration step before you can start to create or manage them in the service. For more information, see [Configuring the IAM credentials engine](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-configure-iam-engine).\n\nAn account administrator (or any entity with the required level of access) can externally alter IAM Credentials that are created and managed by Secrets Manager. If such a service ID or API key is deleted outside of Secrets Manager, the service might behave unexpectedly. For example, you might be unable to create, or rotate credentials.\n\n\n\n\n\n Creating IAM credentials in the UI \n\nTo create IAM credentials by using the Secrets Manager UI, complete the following steps.\n\n\n\n1. In the console, click the Menu icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_12428-4-1817","score":18.6183975684,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Creating IAM credentials \n\nYou can use IBM Cloud\u00ae Secrets Manager to dynamically generate IAM credentials for accessing an IBM Cloud resource that requires IAM authentication.\n\nIAM credentials are\n\ndynamic secretsthat you can use to access an IBM Cloud resource. A set of IAM credentials consists of a service ID and an API key that is generated each time that the protected resource is read or accessed. You can define a time-to-live (TTL) or a lease duration for your IAM credential at its creation so that you shorten the amount of time that the secret exists.\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\nIAM credentials require an extra configuration step before you can start to create or manage them in the service. For more information, see [Configuring the IAM credentials engine](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-configure-iam-engine).\n\nAn account administrator (or any entity with the required level of access) can externally alter IAM Credentials that are created and managed by Secrets Manager. If such a service ID or API key is deleted outside of Secrets Manager, the service might behave unexpectedly. For example, you might be unable to create, or rotate credentials.\n\n\n\n\n\n Creating IAM credentials in the UI \n\nTo create IAM credentials by using the Secrets Manager UI, complete the following steps.\n\n\n\n1. In the console, click the Menu icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"},{"document_id":"ibmcld_12479-7-1826","score":18.576176878,"text":"\nAccess a storage bucket by using a dynamic secret \n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nAs an enterprise developer, you might be looking for ways to improve the security of your application secrets. When it comes to managing API keys, you want the ability to create your credentials dynamically so that they exist only when you need them to. You also want to lease an API key to someone else on your team and ensure that it is automatically revoked after a time duration that you specify.\n\nWith Secrets Manager, you can create a\n\ndynamic secretthat you can use to access a protected resource, such as deployment logs that you store in a Cloud Object Storage bucket. For example, consider the following scenario.\n\nZoom\n\n![The diagram shows the basic flow between the Secrets Manager and Cloud Object Storage services.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/secrets-manager\/images\/iam-credential-flow.svg)\n\nFigure 1. IAM credential flow\n\n\n\n1. As an admin user, you want to create a dynamic secret that your team can use to access a Cloud Object Storage bucket in your account. You send a request to create IAM credentials in Secrets Manager.\n2. Secrets Manager creates the secret and validates it against your defined IAM access policies.\n3. Later, a developer wants to access the contents of your storage bucket. The developer sends a request to retrieve the value of your IAM credential.\n4. Secrets Manager validates the request and generates a single-use API key that the developer can use to authenticate to Cloud Object Storage. After the API key reaches the end of its lease, the API key is revoked automatically.\n\n\n\n\n\n Before you begin","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket"},{"document_id":"ibmcld_12498-9696-11699","score":18.5208381899,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12404-7597-8376","score":18.4390897651,"text":"\nYou can configure a secrets engine programmatically by using Terraform for Secrets Manager.\n\nThe following example shows a configuration that you can use to configure the IAM credentials engine.\n\nresource \"ibm_sm_iam_credentials_configuration\" \"iam_credentials_configuration\" {\ninstance_id = local.instance_id\nregion = local.region\nname = \"iam_credentials_config\"\napi_key = var.ibmcloud_api_key\n}\n\n\n\n\n\n Next steps \n\nNow you can use Secrets Manager to dynamically generate IAM credentials for your apps. In the Secrets Manager UI, click Secrets > Add > IAM credentials to start creating secrets.\n\n\n\n* [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials)\n\n\n\nThe metadata update operation uses a secret ID as part of the path.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-configure-iam-engine"},{"document_id":"ibmcld_00894-7096-9156","score":18.3637063657,"text":"\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"},{"document_id":"ibmcld_12960-7096-9156","score":18.3637063657,"text":"\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"},{"document_id":"ibmcld_12479-10614-12085","score":18.2928893173,"text":"\nTo configure the IAM secrets engine from the IBM Cloud CLI, run the [ibmcloud secrets-manager config-update](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-clisecrets-manager-cli-configuration-update-command) command.\n\nibmcloud secrets-manager config-update --engine-config '{\"api_key\": \"$API_KEY\"}'\n\nSuccess! Now you can [create an IAM credential](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentialsiam-credentials-ui) that you can use to dynamically generate service IDs and API keys. Continue to the next step.\n\n\n\n\n\n\n\n\n\n Step 2: Create an IAM credential \n\nIAM credentials are dynamic secrets that you can use to access an IBM Cloud resource on-demand, such as a Cloud Object Storage bucket. A set of IAM credentials consists of a service ID and an API key that is generated each time that the protected resource is read or accessed. You can define a time-to-live (TTL) or a lease duration for your IAM credential at its creation so that you shorten the amount of time that the secret exists.\n\nTo create an IAM credential from the IBM Cloud CLI, run the [ibmcloud secrets-manager secret-create](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-clisecrets-manager-cli-secret-create-command) command.\n\nexport SECRET_ID=ibmcloud secrets-manager secret-create --resources '[{\"name\":\"test-iam-credentials\",\"description\":\"Extended description for my secret.\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket"},{"document_id":"ibmcld_12404-6204-7960","score":18.1880492779,"text":"\nTo allow your IBM Cloud API key to create and manage other API keys dynamically, its associated service ID must have Editor platform access for the IAM Access Groups Service, and Operator platform access for the IAM Identity Service.\n\nFor step-by-step instructions to create an IBM Cloud API key with the correct level of access, switch to the UI or CLI steps.\n\nThe following example shows a query that you can use to configure a secrets engine for your instance. When you call the API, replace the API key variables and IAM token with the values that are specific to your Secrets Manager instance.\n\ncurl -X POST\n--H \"Authorization: Bearer {iam_token}\" --H \"Accept: application\/json\" --H \"Content-Type: application\/json\" --d '{\n\"api_key\": \"2epu_ykv0PMp2MhxQmDMn7VzrkSlBwi6BOI8uthi_RCS\", \"config_type\": \"iam_credentials_configuration\",\n\"name\": \"iam-configuration\"\n}' \n\"https:\/\/{instance_ID}.{region}.secrets-manager.appdomain.cloud\/api\/v2\/configurations\"\n\nA successful response returns the ID value of the secret, along with other metadata. For more information about the required and optional request parameters, see [Create a secret](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2create-secret).\n\n\n\n\n\n Configuring the IAM credentials engine with Terraform \n\nBefore you can create dynamic IAM credentials, you must configure the IAM secrets engine for your service instance. You can configure a secrets engine programmatically by using Terraform for Secrets Manager.\n\nThe following example shows a configuration that you can use to configure the IAM credentials engine.\n\nresource \"ibm_sm_iam_credentials_configuration\" \"iam_credentials_configuration\" {\ninstance_id = local.instance_id\nregion = local.region\nname = \"iam_credentials_config\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-configure-iam-engine"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-9696-11699","score":20.096590561,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12498-8087-10171","score":19.3986281937,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12447-1578-3681","score":17.062774098,"text":"\nIf the IAM credentials secret was created by using an existing service ID in the account, only the API key is regenerated as part of a manual rotation. In contrast, if the secret was created by selecting an access group, both the service ID and API key values are regenerated when they're manually rotated.<br><br>The Reuse IAM credentials until lease expires (reuse_api_key) option for an IAM credentials secret impacts whether it can be rotated manually. If this field is false or set to Off in the UI, manual rotation isn't supported. The API key that is dynamically generated for the secret on each read is already a single-use, ephemeral value. \n [Imported certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatesimport-certificates) Certificates that were initially imported to a service instance are immediately replaced with the data that you reimport on rotation. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) Key-value secrets are immediately replaced with the data that you provide on rotation. \n [Private certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatescreate-certificates) Private certificates are immediately replaced with a certificate that is signed by its parent or issuing certificate authority. \n [Public certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatesorder-certificates) Public certificates move to the Active, Rotation pending status to indicate that a request to rotate a certificate is being processed. Secrets Manager sends the request to the configured certificate authority (CA), for example Let's Encrypt, to validate the ownership of your domains. If the validation completes successfully, a new certificate is issued. \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) Passwords that are associated with user credentials secrets are immediately replaced with the data that you provide on rotation. \n\n\n\n\n\n\n\n\n\n Creating new secret versions in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"},{"document_id":"ibmcld_12479-7-1826","score":16.7665596522,"text":"\nAccess a storage bucket by using a dynamic secret \n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nAs an enterprise developer, you might be looking for ways to improve the security of your application secrets. When it comes to managing API keys, you want the ability to create your credentials dynamically so that they exist only when you need them to. You also want to lease an API key to someone else on your team and ensure that it is automatically revoked after a time duration that you specify.\n\nWith Secrets Manager, you can create a\n\ndynamic secretthat you can use to access a protected resource, such as deployment logs that you store in a Cloud Object Storage bucket. For example, consider the following scenario.\n\nZoom\n\n![The diagram shows the basic flow between the Secrets Manager and Cloud Object Storage services.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/secrets-manager\/images\/iam-credential-flow.svg)\n\nFigure 1. IAM credential flow\n\n\n\n1. As an admin user, you want to create a dynamic secret that your team can use to access a Cloud Object Storage bucket in your account. You send a request to create IAM credentials in Secrets Manager.\n2. Secrets Manager creates the secret and validates it against your defined IAM access policies.\n3. Later, a developer wants to access the contents of your storage bucket. The developer sends a request to retrieve the value of your IAM credential.\n4. Secrets Manager validates the request and generates a single-use API key that the developer can use to authenticate to Cloud Object Storage. After the API key reaches the end of its lease, the API key is revoked automatically.\n\n\n\n\n\n Before you begin","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket"},{"document_id":"ibmcld_12463-30147-31055","score":16.4198106232,"text":"\n: With IBM Cloud Secrets Manager, you can create secrets dynamically and lease them to applications while you control access from a single location. Built on open source HashiCorp Vault, Secrets Manager helps you get the data isolation of a dedicated environment with the benefits of a public cloud.\n\nIn this release, Secrets Manager offers support for the following types of secrets:\n\n\n\n* IAM credentials, which consist of a service ID and API key that are generated dynamically on your behalf.\n* Arbitrary secrets, such as custom credentials that can be used to store any type of structured or unstructured data.\n* User credentials, such as usernames and passwords that you can use to log in to applications.\n\n\n\nTo find out more about capabilities and use cases for Secrets Manager, check out the [announcement blog](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/introducing-ibm-cloud-secrets-manager-beta).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-release-notes"},{"document_id":"ibmcld_00894-7096-9156","score":16.3270009431,"text":"\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"},{"document_id":"ibmcld_12960-7096-9156","score":16.3270009431,"text":"\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"},{"document_id":"ibmcld_12415-7-1973","score":16.1208608913,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_12422-4077-6158","score":15.8161952604,"text":"\nIf you'd like to continue to use those credentials through the end of the lease of your secret, you can set Reuse IAM credentials until lease expires to On. When you enable this option, your secret retains its current service ID, and API key values and reuses them on each read while the secret remains valid. After the secret reaches the end of its lease, the credentials are revoked automatically.\n\nIf the reuse IAM credentials option is set to Off, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. Or, if you prefer to generate both a service ID and an API key, you can assign access by choosing an access group.\n\nIn the Assign access step of the Create IAM credentials wizard, choose a scope of access for your credentials.\n\n\n\n1. To use an existing service ID, select an ID from the list.\n\nChoose this option when you need Secrets Manager to generate and manage only an API key for your IAM credentials secret, and not the service ID itself. The API key inherits the access policy of the service ID that you select from your account. Only the service IDs that you have access to are displayed.\n2. To generate both a new service ID and API key for the secret, select an access group.\n\nBy selecting an access group from your IBM Cloud account, you determine the scope of access to assign to the service ID and the API key. The API key is dynamically generated and associated with your new IAM credential. This step ensures that your IAM credentials are scoped with the preferred level of permissions in your IBM Cloud account. You can assign up to 10 access groups.\n\n\n\nIf you used an existing service ID, the API key that was generated by Secrets Manager is automatically locked.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_12428-3937-6070","score":15.7787250485,"text":"\nBy default, the service ID and API key are single-use, ephemeral values that are generated and deleted each time that an IAM credentials secret is read or accessed.\n\nIf you'd like to continue to use those credentials through the end of the lease of your secret, you can set Reuse IAM credentials until lease expires to On. When you enable this option, your secret retains its current service ID, and API key values and reuses them on each read while the secret remains valid. After the secret reaches the end of its lease, the credentials are revoked automatically.\n\nIf the reuse IAM credentials option is set to Off, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. Or, if you prefer to generate both a service ID and an API key, you can assign access by choosing an access group.\n\nIn the Assign access step of the Create IAM credentials wizard, choose a scope of access for your credentials.\n\n\n\n1. To use an existing service ID, select an ID from the list.\n\nChoose this option when you need Secrets Manager to generate and manage only an API key for your IAM credentials secret, and not the service ID itself. The API key inherits the access policy of the service ID that you select from your account. Only the service IDs that you have access to are displayed.\n2. To generate both a new service ID and API key for the secret, select an access group.\n\nBy selecting an access group from your IBM Cloud account, you determine the scope of access to assign to the service ID and the API key. The API key is dynamically generated and associated with your new IAM credential. This step ensures that your IAM credentials are scoped with the preferred level of permissions in your IBM Cloud account. You can assign up to 10 access groups.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06843-4238-6198","score":16.0665237566,"text":"\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline"},{"document_id":"ibmcld_12498-8087-10171","score":15.7074699555,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12498-9696-11699","score":14.1531975065,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_07844-4589-6711","score":13.5031988986,"text":"\nRA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n RA-5 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nSecurity categorization of information systems guides the frequency and comprehensiveness of vulnerability scans. Organizations determine the required vulnerability scanning for all information system components, ensuring that potential sources of vulnerabilities such as networked printers, scanners, and copiers are not overlooked. Vulnerability analyses for custom software applications may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_15651-3163-5570","score":13.4471264037,"text":"\nChanging the membership count of a static instance group \n\nIf you are using the static method for your instance group, the instance group works to always maintain the number of instances you have set. If any instances fail, the instance group automatically replaces those failed instances in the instance group. By maintaining the instances in the group, the availibility of the applications running in those instances is also enhanced.\n\nYou can manually scale the instances in the group at any time by editing the membership count.\n\n\n\n* On the Instance group details page, edit the membership count and specify the number of instances you desire to have in your instance group.\n\n\n\n\n\n\n\n Changing the scaling method for an instance group \n\nIf you start out with a static membership in your instance group, for example, you can change it to use the dynamic scaling method. (You can also switch from dynamic scaling method to the static scaling method.) With the dynamic scaling method, you set a minimum and maximum number of instances for the instance group. Then, you specify target policies that define the desired utilization of a metric (such as CPU) that you want the instance group to maintain.\n\nTo change an instance group from using static membership to dynamic scaling, complete the following steps:\n\n\n\n1. From the menu in the upper right-hand corner of the instance group details page, select Switch scaling method.\n2. On the Switch to dynamic page, click Switch to confirm that you want to change to the dynamic scaling method.\n3. Specify the minimum and maximum number of instances that you want to have running in your instance group at any given time. You can edit these numbers later.\n4. Specify the aggregation window. The aggregation window is the time period in seconds that the instance group manager monitors each instance and determines the average utilization.\n5. Specify the cool down period, the number of seconds to pause further scaling actions after scaling has taken place.\n6. Create one or more target policies that define a metric and target utilization that the instance group manager will use for auto scaling in your instance group. See Table 1 for more information.\n\n\n\n\n\nTable 1. Target policies selections\n\n Field Value \n\n Metric type Select the metric type that you want to associate with a target utilization value to use for adding or removing instances from your group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-instance-group"},{"document_id":"ibmcld_15214-14406-16762","score":13.3966749826,"text":"\nIf you add a placement group, the instance is placed according to the placement group policy. For more information, see [About placement groups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-placement-groups-for-vpc). \n Subnets Select the subnets where you want to create your instance group. To maximize the availability of your applications, select subnets in different zones. For the best performance of an auto scale instance group, ensure that you use a subnet size of 32 or greater. \n Use a load balancer Select this checkbox if you plan to use a load balancer to balance incoming requests across instances in your instance group. The load balancer must already be configured, attached to the subnets that you select for this instance group, and have at least one back-end pool. \n Instance template Select the instance template that you want to use for provisioning the virtual server instances in your auto-scale instance group. All virtual server instances in the group are provisioned with the same instance template. \n Scaling method Select whether you want to use a dynamic or static scaling method. With the dynamic scaling method, instances are added or removed based on the metric targets that you specify. With the static scaling method, you can specify a fixed number of instances that you always want to maintain. \n Instance group size For a static group, enter the number of instances that you want to constantly have in this instance group. For a dynamic group, enter the minimum and maximum number of instances for your group. The number of instances scale automatically within that range based on the target metrics that you define. \n Aggregation window (seconds) For a dynamic group, this value determines the time period that the instance group manager monitors each instance and determines the average utilization. \n Cooldown period (seconds) For a dynamic group, the cooldown period is the time in seconds to pause further scaling actions after scaling takes place. \n\n\n\n\n\n\n\n Creating scaling policies \n\nFor the dynamic scaling method, you define certain metrics (like CPU utilization percent) and the target utilization that you want to achieve for that metric. Together, the metric and the average target utilization, determine when your instance group needs to dynamically add or remove virtual server instances from your group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-group&interface=cli"},{"document_id":"ibmcld_15215-14405-16761","score":13.3966749826,"text":"\nIf you add a placement group, the instance is placed according to the placement group policy. For more information, see [About placement groups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-placement-groups-for-vpc). \n Subnets Select the subnets where you want to create your instance group. To maximize the availability of your applications, select subnets in different zones. For the best performance of an auto scale instance group, ensure that you use a subnet size of 32 or greater. \n Use a load balancer Select this checkbox if you plan to use a load balancer to balance incoming requests across instances in your instance group. The load balancer must already be configured, attached to the subnets that you select for this instance group, and have at least one back-end pool. \n Instance template Select the instance template that you want to use for provisioning the virtual server instances in your auto-scale instance group. All virtual server instances in the group are provisioned with the same instance template. \n Scaling method Select whether you want to use a dynamic or static scaling method. With the dynamic scaling method, instances are added or removed based on the metric targets that you specify. With the static scaling method, you can specify a fixed number of instances that you always want to maintain. \n Instance group size For a static group, enter the number of instances that you want to constantly have in this instance group. For a dynamic group, enter the minimum and maximum number of instances for your group. The number of instances scale automatically within that range based on the target metrics that you define. \n Aggregation window (seconds) For a dynamic group, this value determines the time period that the instance group manager monitors each instance and determines the average utilization. \n Cooldown period (seconds) For a dynamic group, the cooldown period is the time in seconds to pause further scaling actions after scaling takes place. \n\n\n\n\n\n\n\n Creating scaling policies \n\nFor the dynamic scaling method, you define certain metrics (like CPU utilization percent) and the target utilization that you want to achieve for that metric. Together, the metric and the average target utilization, determine when your instance group needs to dynamically add or remove virtual server instances from your group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-group&interface=ui"},{"document_id":"ibmcld_15206-14392-16748","score":13.3966749826,"text":"\nIf you add a placement group, the instance is placed according to the placement group policy. For more information, see [About placement groups](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-placement-groups-for-vpc). \n Subnets Select the subnets where you want to create your instance group. To maximize the availability of your applications, select subnets in different zones. For the best performance of an auto scale instance group, ensure that you use a subnet size of 32 or greater. \n Use a load balancer Select this checkbox if you plan to use a load balancer to balance incoming requests across instances in your instance group. The load balancer must already be configured, attached to the subnets that you select for this instance group, and have at least one back-end pool. \n Instance template Select the instance template that you want to use for provisioning the virtual server instances in your auto-scale instance group. All virtual server instances in the group are provisioned with the same instance template. \n Scaling method Select whether you want to use a dynamic or static scaling method. With the dynamic scaling method, instances are added or removed based on the metric targets that you specify. With the static scaling method, you can specify a fixed number of instances that you always want to maintain. \n Instance group size For a static group, enter the number of instances that you want to constantly have in this instance group. For a dynamic group, enter the minimum and maximum number of instances for your group. The number of instances scale automatically within that range based on the target metrics that you define. \n Aggregation window (seconds) For a dynamic group, this value determines the time period that the instance group manager monitors each instance and determines the average utilization. \n Cooldown period (seconds) For a dynamic group, the cooldown period is the time in seconds to pause further scaling actions after scaling takes place. \n\n\n\n\n\n\n\n Creating scaling policies \n\nFor the dynamic scaling method, you define certain metrics (like CPU utilization percent) and the target utilization that you want to achieve for that metric. Together, the metric and the average target utilization, determine when your instance group needs to dynamically add or remove virtual server instances from your group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-group"},{"document_id":"ibmcld_00020-4245-6252","score":13.3919747132,"text":"\n<br><br> * [Working with Spark SQL and an external metastore](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-external-metastore)<br><br><br> \n Running applications with resource overcommitment There is a quota associated with each Analytics Engine Serverless instance. When applications are submitted on an instance, they are allocated resources from the instance quota. If an application requests resources beyond the available quota, the application will either not start or will run with less than the requested resources, which might result in the application running slower than expected or, in some cases, in the application failing. You should always monitor the current resource consumption on an instance to ensure that your applications are running comfortably within the given limits. You can adjust the limits through a support ticket if required. <br><br> * [Default limits and quotas](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-limits)<br> * [Get current resource consumption](https:\/\/cloud.ibm.com\/apidocs\/ibm-analytics-engine\/ibm-analytics-engine-v3get-current-resource-consumption)<br><br><br> \n Static allocation of resources versus autoscaling When you submit applications, you can specify the number of executors upfront (static allocation) or use the autoscaling option (dynamic allocation). Before you decide whether to use static allocation or autoscaling, you might want to run a few benchmarking tests by varying different data sets with both static and autoscaling to find the right configuration. General considerations:<br><br><br><br> * If you know the number of resources (cores and memory) required by your application and it doesn't vary across different stages of the application run, it is recommended to allocate static resources for better performance.<br> * If you want to go for an optimized resource utilization, you can opt for autoscaling of executors where the executors are allotted based on the application's actual demand.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-best-practices-serverless"},{"document_id":"ibmcld_07844-3757-5369","score":12.8347296081,"text":"\nRA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00095-7-1378","score":17.7873908984,"text":"\nUsing a library set \n\nAfter you have created a library set, you can reference and consume it in your Spark applications. When you run your Spark application in the IBM Analytics Engine instance, the library set is loaded from the instance home and is made available to the Spark application.\n\nA library set is referenced in a Spark application using the \"ae.spark.librarysets\" parameter in the \"conf\" section of the Spark application submission payload.\n\nTo reference a library set when submitting a Spark application:\n\n\n\n1. Get the IAM token. See [Retrieving IAM access tokens](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-iam-token-serverless).\n2. Issue the following cURL command:\n\ncurl -X POST https:\/\/api.us-south.ae.cloud.ibm.com\/v3\/analytics_engines\/<instance_id>\/spark_applications --header \"Authorization: Bearer <IAM token>\" -H \"content-type: application\/json\" -d @submit-spark-app.json\n\nExample for submit-spark-app.json:\n\n{\n\"application_details\": {\n\"application\": \"cos:\/\/<bucket-name>.<cos-name>\/my_spark_application.py\",\n\"arguments\": [\"arg1\", \"arg2\"],\n\"conf\": {\n\"spark.hadoop.fs.cos.<cos-name>.endpoint\":\"https:\/\/s3.us-south.cloud-object-storage.appdomain.cloud\",\n\"spark.hadoop.fs.cos.<cos-name>.access.key\":\"<access_key>\",\n\"spark.hadoop.fs.cos.<cos-name>.secret.key\":\"<secret_key>\",\n\"ae.spark.librarysets\":\"my_library_set\"\n}\n}\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-use-lib-set"},{"document_id":"ibmcld_00083-2510-3893","score":16.9045277592,"text":"\n\"spark.hadoop.fs.cos.cosservicename.secret.key\": \"<CHANGEME>\"\n}\n}\n}\n\n\n\n\n\n Reading a CSV file from Object Storage using IAM API Key or different HMAC credentials \n\nThe following code samples show you how to create a Python script that reads data from a CSV file to a Python DataFrame. Both the Python script and the CSV file are located in Object Storage.\n\nThis example shows you how to access IBM Cloud Object Storage using the IAM API key.\n\nExample of the application called read-employees-iam-key-cos.py. Insert the Object Storage bucket name where the CSV file is located and the modify the endpoint path.\n\nfrom pyspark.sql import SparkSession\n\ndef init_spark():\nspark = SparkSession.builder.appName(\"read-write-cos-test\").getOrCreate()\nsc = spark.sparkContext\nhconf=sc._jsc.hadoopConfiguration()\nhconf.set(\"fs.cos.testcos.endpoint\", \"s3.direct.us-south.cloud-object-storage.appdomain.cloud\/CHANGEME-according-to-instance=\"\n(\"fs.cos.testcos.iam.api.key\",\"<CHANGEME>\")\nreturn spark,sc\n\ndef read_employees(spark,sc):\nprint(\"Hello1 \" , spark )\nemployeesDF = spark.read.option(\"header\",True).csv(\"cos:\/\/cosbucketname.cosservicename\/employees.csv\")\nprint(\"Hello2\" , employeesDF)\nemployeesDF.createOrReplaceTempView(\"empTable\")\njuniors = spark.sql(\"SELECT empTable.NAME FROM empTable WHERE empTable.BAND < 6\")\nprint(\"Hello3\", juniors)\njuniors.show()\n\ndef main():\nspark,sc = init_spark()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-batch-examples"},{"document_id":"ibmcld_00083-3554-4796","score":16.6561678185,"text":"\nemployeesDF = spark.read.option(\"header\",True).csv(\"cos:\/\/cosbucketname.cosservicename\/employees.csv\")\nprint(\"Hello2\" , employeesDF)\nemployeesDF.createOrReplaceTempView(\"empTable\")\njuniors = spark.sql(\"SELECT empTable.NAME FROM empTable WHERE empTable.BAND < 6\")\nprint(\"Hello3\", juniors)\njuniors.show()\n\ndef main():\nspark,sc = init_spark()\nread_employees(spark,sc)\n\nif __name__ == '__main__':\nmain()\nShow more\n\nThen POST the following payload JSON script called read-employees-iam-key-cos-submit.json with your access key and password. Insert the Object Storage bucket name where the CSV file is located and the modify the endpoint path.\n\n{\n\"application_details\": {\n\"application\": \"cos:\/\/cosbucketname.cosservicename\/read-employees-iam-key-cos.py\",\n\"conf\": {\n\"spark.hadoop.fs.cos.cosservicename.endpoint\": \"https:\/\/s3.direct.us-south.cloud-object-storage.appdomain.cloud\/CHANGME-according-to-instance\",\n\"spark.hadoop.fs.cos.cosservicename.access.key\": \"<CHANGEME>\",\n\"spark.hadoop.fs.cos.cosservicename.secret.key\": \"<CHANGEME>\"\n}\n}\n}\n\n\n\n\n\n Reading and writing to Object Storage using IAM in Scala \n\n\n\n1. Create an Eclipse project of the following format:\n\n\n\nZoom\n\n![Shows the Eclipse project format to use in which to develop your Scala jar.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-batch-examples"},{"document_id":"ibmcld_00029-7452-8829","score":16.5643431321,"text":"\ntablesDF=spark.sql(\"SHOW TABLES\")\ntablesDF.show()\nstatesDF=spark.sql(\"SELECT * from COUNTRIESCAPITALS\");\nstatesDF.show()\n\ndef main():\nspark,sc = init_spark()\nselect_query_data_engine(spark,sc)\n\nif __name__ == '__main__':\nmain()\nShow more\n\nNote that for the SELECT command to work, you must pass the IBM Cloud Object Storage identifiers as one of the standard Data Engine aliases, in this example, we have used ALIAS NAME. If you do not pass the expected ones, you might see the following error: Configuration parse exception: Access KEY is empty. Please provide valid access key.\n\nselect_query_data_engine_payload.json:\n\n{\n\"application_details\": {\n\"conf\": {\n\"spark.hadoop.fs.cos.ALIAS NAME.endpoint\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.access.key\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.secret.key\": \"CHANGEME\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.truststore.password\" : \"changeit\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.execution.engine\":\"spark\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.password\":\"APIKEY-WITH-ACCESS-TO-DATA-ENGINE-INSTANCE\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.uris\":\"THRIFT URL\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_00085-1355-3078","score":16.5550238604,"text":"\n* The [Analytics Engine instance UI](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverlessiae-ui)\n\n\n\n\n\n Analytics Engine REST API \n\nYou can use the Analytics Engine REST API:\n\n\n\n1. To view the status of the Spark history server\n\ncurl \"https:\/\/api.us-south.ae.cloud.ibm.com\/v3\/analytics_engines\/<instance_id>\/spark_history_server\" --header \"Authorization: bearer <iam token>\"\n2. To start the Spark history server\n\ncurl --location --request POST \"https:\/\/api.us-south.ae.cloud.ibm.com\/v3\/analytics_engines\/<instance_id>\/spark_history_server\" --header \"Authorization: bearer <iam token>\"\n3. To stop the Spark history server\n\ncurl --location --request DELETE \"https:\/\/api.us-south.ae.cloud.ibm.com\/v3\/analytics_engines\/<instance_id>\/spark_history_server\" --header \"Authorization: bearer <iam token>\"\n\n\n\n\n\n\n\n Analytics Engine instance UI \n\nYou can use the Analytics Engine instance UI:\n\n\n\n1. To view the Spark history server status:\n\n\n\n1. Open your resource list on [IBM Cloud](https:\/\/cloud.ibm.com\/resources).\n2. Click Services and software and select your instance to open the details page.\n3. Select the Spark history tab. The current status of the server is shown on this page.\n\n\n\nIf the status of the Spark history server is set to Started, you can also click View Spark history to launch the Web UI of the Spark history server in a new browser tab.\n2. To start the Spark history server:\n\n\n\n1. On the Spark history page, click Start history server.\n2. Choose the server configuration and click Start to start the Spark history server.\n\n\n\n3. To stop the Spark history server:\n\n\n\n1. On the Spark history page, click Stop history server.\n\n\n\n\n\n\n\n\n\n\n\n Opening the Spark history server Web UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverless"},{"document_id":"ibmcld_16661-2308-3705","score":16.5294883658,"text":"\nThe sample below demonstrates how to do some table maintenance operations by using Spark. For more information about the Iceberg Spark table maintenance operations, see [Table Operations](https:\/\/iceberg.apache.org\/docs\/1.2.1\/spark-procedures\/).\n\n\n\n\n\n\n\n Running the sample use case \n\nFollow the steps to run the Spark sample python file.\n\n\n\n Spark sample python file \n\nfrom pyspark.sql import SparkSession\nimport os\n\ndef init_spark():\nspark = SparkSession.builder .appName(\"lh-hms-cloud\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.endpoint\" ,\"s3.direct.us-south.cloud-object-storage.appdomain.cloud\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.access.key\" ,\"<access-key-for-source-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.secret.key\" ,\"<secret-key-for-source-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.endpoint\" ,\"s3.direct.us-south.cloud-object-storage.appdomain.cloud\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.access.key\" ,\"<access-key-for-lakehous-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.secret.key\" ,\"<secret-key-for-lakehouse-bucket>\") .enableHiveSupport() .getOrCreate()\n\nreturn spark\n\ndef main():\ntry:\nspark = init_spark()\n Create a database in lakehouse catalog\nspark.sql(\"create database if not exists lakehouse.demodb LOCATION 's3a:\/\/lakehouse-bucket\/'\")\n list the database under lakehouse catalog","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-run_samp_file"},{"document_id":"ibmcld_00085-7-1802","score":16.4333859544,"text":"\nSpark history server \n\nThe Spark applications that are submitted on an IBM Analytics Engine instance forward their Spark events to the Object Storage bucket that was defined as the instance home. The Spark history server provides a Web UI to view these Spark events. The Web UI helps you to analyze how your Spark applications ran by displaying useful information like:\n\n\n\n* A list of the stages that the application goes through when it is run\n* The number of tasks in each stage\n* The configuration details such as the running executors and memory usage\n\n\n\nSee the [Spark History server documentation](https:\/\/spark.apache.org\/docs\/latest\/monitoring.htmlviewing-after-the-fact) for more details.\n\nYou can disable forwarding Spark events from a Spark application by setting the property spark.eventLog.enabled to false in the Spark application configuration.\n\n\n\n Starting and stopping the Spark history server \n\nBefore accessing the Spark history server, you need to start the server. When you no longer need it, you should stop the server. You will be charged for the CPU cores and memory consumed by the Spark history server while it is running.\n\nThe Spark history server can be started and stopped by using:\n\n\n\n* The [Analytics Engine REST API](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverlessrest-api)\n* The [Analytics Engine instance UI](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverlessiae-ui)\n\n\n\n\n\n Analytics Engine REST API \n\nYou can use the Analytics Engine REST API:\n\n\n\n1. To view the status of the Spark history server\n\ncurl \"https:\/\/api.us-south.ae.cloud.ibm.com\/v3\/analytics_engines\/<instance_id>\/spark_history_server\" --header \"Authorization: bearer <iam token>\"\n2. To start the Spark history server","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverless"},{"document_id":"ibmcld_00096-13527-14802","score":16.3494743298,"text":"\n3. Submit the Spark application:\n\nAction\n: Enter:\n\nibmcloud ae-v3 spark-app submit --instance-id INSTANCE_ID -\u2013app APPLICATION_PATH\n\nParameter values:\n\n\n\n* INSTANCE_ID: The value of GUID from the response the of Analytics Engine instance creation call\n* APPLICATION_PATH: The file name and path to the Spark application file\n\n\n\nExample for IOS and Linux\n: Enter:\n\nibmcloud ae-v3 spark-app submit --instance-id 181ea9ee01b --app \"cos:\/\/test-cos-storage-bucket.mycos\/test-math.py\" --conf '{\"spark.hadoop.fs.cos.mycos.endpoint\": \"https:\/\/s3.direct.us-south.cloud-object-storage.appdomain.cloud\", \"spark.hadoop.fs.cos.mycos.access.key\": \"21bf1f4\", \"spark.hadoop.fs.cos.mycos.secret.key\": \"c5ad3e0a6c\"}'\n\nExample for Windows (Not Powershell). Note that on Windows, the quotes needs to be escaped.\n: Enter:\n\nibmcloud ae-v3 spark-app submit --instance-id myinstanceid --app \"cos:\/\/matrix.mycos\/test-math.py\" --conf \"{\"spark.hadoop.fs.cos.mycos.endpoint\": \"https:\/\/s3.direct.us-south.cloud-object-storage.appdomain.cloud\", \"spark.hadoop.fs.cos.mycos.access.key\": \"mykey\", \"spark.hadoop.fs.cos.mycos.secret.key\": \"mysecret\"}\"\n\nResponse\n: The example returns:\n\nid 7f7096d2-5c44-4d9a-ac01-b904c7611b7b\nstate accepted\n4. Check the details or status of the application that you submitted:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-cli"},{"document_id":"ibmcld_00086-1505-3411","score":16.3402800225,"text":"\nThe Spark UI endpoint of the running Spark application can also be obtained by invoking the following IBM Analytics Engine REST API endpoints or corresponding SDK methods:\n\n\n\n* [Retrieve the details of a given Spark application](https:\/\/cloud.ibm.com\/apidocs\/ibm-analytics-engine-v3get-application)\n* [List Spark applications](https:\/\/cloud.ibm.com\/apidocs\/ibm-analytics-engine-v3list-applications)\n\n\n\nA sample url template for the Spark UI endpoint is as below:\n\nhttps:\/\/spark-console.{REGION}.ae.cloud.ibm.com\/v3\/analytics_engines\/{INSTANCE_ID}\/spark_applications\/{APPLICATION_ID}\/spark_ui\n\nParameter values:\n\n\n\n* REGION: For applications submitted on an instance in the Dallas region, substitute the REGION with us-south and for applications submitted on an instance in the Frankfurt region, substitute the REGION in the endpoint with eu-de.\n* INSTANCE_ID: Identifier of the IBM Analytics Engine instance under which the application is running.\n* APPLICATION_ID: Identifier of the application for which Spark UI is accessed.\n\n\n\n\n\n\n\n Accessing the Spark UI REST API \n\nIn addition to the Web UI, Spark UI APIs are also exposed for programmatic consumption.\n\nFor example, enter:\n\ncurl \"https:\/\/spark-console.{REGION}.ae.cloud.ibm.com\/v3\/analytics_engines\/{INSTANCE_ID}\/spark_applications\/{APPLICATION_ID}\/spark_ui_api\/v1\/applications\" --header \"Authorization: Bearer {IAM TOKEN}\"\n\nParameter values:\n\n\n\n* REGION: For applications submitted on an instance in the Dallas region, substitute the REGION with us-south and for applications submitted on an instance in the Frankfurt region, substitute the REGION in the endpoint with eu-de.\n* INSTANCE_ID: Identifier of the IBM Analytics Engine instance under which the application is running.\n* APPLICATION_ID: Identifier of the application for which Spark UI is accessed.\n* IAM TOKEN: Ensure that you have the necessary privileges to access the service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-user-interface"},{"document_id":"ibmcld_16661-2743-3994","score":16.3027670452,"text":"\nspark = SparkSession.builder .appName(\"lh-hms-cloud\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.endpoint\" ,\"s3.direct.us-south.cloud-object-storage.appdomain.cloud\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.access.key\" ,\"<access-key-for-source-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.lakehouse-bucket.secret.key\" ,\"<secret-key-for-source-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.endpoint\" ,\"s3.direct.us-south.cloud-object-storage.appdomain.cloud\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.access.key\" ,\"<access-key-for-lakehous-bucket>\") .config(\"spark.hadoop.fs.s3a.bucket.source-bucket.secret.key\" ,\"<secret-key-for-lakehouse-bucket>\") .enableHiveSupport() .getOrCreate()\n\nreturn spark\n\ndef main():\ntry:\nspark = init_spark()\n Create a database in lakehouse catalog\nspark.sql(\"create database if not exists lakehouse.demodb LOCATION 's3a:\/\/lakehouse-bucket\/'\")\n list the database under lakehouse catalog\nspark.sql(\"show databases from lakehouse\").show()\n\n demonstration: Create a basic Iceberg table, insert some data and then query table\nspark.sql(\"create table if not exists lakehouse.demodb.testTable(id INTEGER, name VARCHAR(10), age INTEGER, salary DECIMAL(10, 2)) using iceberg\").show()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-run_samp_file"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13481-5443-6857","score":51.9835259639,"text":"\n.config(\"spark.hive.metastore.uris\", \"thrift:\/\/catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\") \n.config(\"spark.hive.metastore.client.plain.username\", '<YourDataengineCRN>') \n.config(\"spark.hive.metastore.client.plain.password\", '<YourAPIkey>') \n.config(\"spark.hive.execution.engine\", \"spark\") \n.config(\"spark.hive.stats.autogather\", \"false\") \n.config(\"spark.sql.warehouse.dir\", \"file:\/\/\/tmp\") \n only spark is allowed as the default catalog\n.config(\"metastore.catalog.default\", \"spark\") \n.enableHiveSupport() \n.getOrCreate()\nShow more\n\n\n\n\n\n Apache Hive metastore version 3.1.2 compatible client \n\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16641-2355-3755","score":51.1153575567,"text":"\nspark.sql.catalog.lakehouse.uri = <hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683)\nspark.hive.metastore.client.auth.mode = PLAIN\nspark.hive.metastore.client.plain.username = <hms-user-from-watsonx.data> (for example, ibmlhapikey)\nspark.hive.metastore.client.plain.password = <hms-password-from-watsonx.data>\nspark.hive.metastore.use.SSL = true\nspark.hive.metastore.truststore.type = JKS\nspark.hive.metastore.truststore.path = file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\nspark.hive.metastore.truststore.password = changeit\nShow more\n\n\n\nParameter value:\n\n\n\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data.\n* Hms-user-from-watsonx.Data: The watsonx.data username.\n* Hms-password-from-watsonx.Data: The watsonx.data password.\n\n\n\n\n\n\n\n Configuring Analytics Engine instance by using Analytics Engine API \n\nTo configure your IBM Analytics Engine instance from the Analytics Engine API, complete the following steps:\n\n\n\n1. Generate an IAM token to connect to the IBM Analytics Engine API. For more information about how to generate an IAM token, see [IAM token](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli).\n2. Run the following API command to invoke the Analytics Engine API by using the generated IAM token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_16641-6629-7897","score":51.1018289887,"text":"\n\"spark.sql.catalog.lakehouse.type\": \"hive\",\n\"spark.sql.catalog.lakehouse.uri\": \"<hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683) \",\n\"spark.hive.metastore.client.auth.mode\": \"PLAIN\",\n\"spark.hive.metastore.client.plain.username\": \"<hms-user-from-watsonx.data> (for example, ibmlhapikey)\",\n\"spark.hive.metastore.client.plain.password\": \"<hms-password-from-watsonx.data>\",\n\"spark.hive.metastore.use.SSL\": \"true\",\n\"spark.hive.metastore.truststore.type\": \"JKS\",\n\"spark.hive.metastore.truststore.path\": \"file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n\"spark.hive.metastore.truststore.password\": \"changeit\"\n}\nShow more\n* INSTANCE_ID: The Analytics Engine instance ID. For more information about how to retrieve an instance ID, see [Obtaining the service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli)\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data. For more information on getting the HMS credentials, see [Getting (Hive metastore) HMS Credentials](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hms).\n* Hms-user-from-watsonx.Data: The watsonx.data username.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_00029-8568-9861","score":50.8297819843,"text":"\n\"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3\n\"spark.hive.metastore.truststore.path\":\"\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n for spark 3.1, spark 3.2\n\"spark.hive.metastore.truststore.path\":\"file:\/\/\/opt\/ibm\/jdk\/jre\/lib\/security\/cacerts\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.jars\":\"\/opt\/ibm\/connectors\/data-engine\/hms-client\/\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.version\":\"3.0\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.warehouse.dir\":\"file:\/\/\/tmp\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hadoop.metastore.catalog.default\":\"spark\"\n},\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"application\": \"cos:\/\/mybucket.ALIAS NAME\/select_query_data_engine.py\"\n\u00a0\u00a0\u00a0 }\n}\nShow more\n\nParameter values:\n\n\n\n* ALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewendpoints).\n* THRIFT URL: specify the region-specific thrift URL. For example, thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_13481-4684-5710","score":50.5988110986,"text":"\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.config(\"fs.stocator.cos.scheme\", \"cos\") \n register the required Cloud Object Storage path used in our application, add endpoints for all buckets\n.config(\"spark.hadoop.fs.cos.us-geo.endpoint\", \"https:\/\/s3.us.cloud-object-storage.appdomain.cloud\") \n.config(\"spark.hadoop.fs.cos.us-geo.iam.endpoint\", \"https:\/\/iam.cloud.ibm.com\/identity\/token\") \n.config(\"spark.hadoop.fs.cos.us-geo.iam.api.key\", '<YourAPIkey>') \n.config(\"spark.sql.hive.metastore.version\", \"3.0\") \n directory where the Hive client has been placed\n.config(\"spark.sql.hive.metastore.jars\", \"\/tmp\/dataengine\/\") \n.config(\"spark.hive.metastore.uris\", \"thrift:\/\/catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16641-4554-5850","score":50.3974443873,"text":"\n\"spark.sql.catalog.lakehouse.type\": \"hive\",\n\"spark.sql.catalog.lakehouse.uri\": \"<hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683) \",\n\"spark.hive.metastore.client.auth.mode\": \"PLAIN\",\n\"spark.hive.metastore.client.plain.username\": \"<hms-user-from-watsonx.data> (for example, ibmlhapikey)\",\n\"spark.hive.metastore.client.plain.password\": \"<hms-password-from-watsonx.data>\",\n\"spark.hive.metastore.use.SSL\": \"true\",\n\"spark.hive.metastore.truststore.type\": \"JKS\",\n\"spark.hive.metastore.truststore.path\": \"file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n\"spark.hive.metastore.truststore.password\": \"changeit\"\n}\nShow more\n* BASE_URL: The Analytics Engine URL for the region where you provisioned the instance. For example, api.region.ae.ibmcloud.com.\n* INSTANCE_ID: The Analytics Engine instance ID. For more information about how to retrieve an instance ID, see [Obtaining the service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli).\n* hms-thrift-endpoint-from-watsonx.data: Specify the credentials for watsonx.data.\n* hms-user-from-watsonx.data: The watsonx.data username.\n* hms-password-from-watsonx.data: The watsonx.data password.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_00029-7452-8829","score":49.8927827913,"text":"\ntablesDF=spark.sql(\"SHOW TABLES\")\ntablesDF.show()\nstatesDF=spark.sql(\"SELECT * from COUNTRIESCAPITALS\");\nstatesDF.show()\n\ndef main():\nspark,sc = init_spark()\nselect_query_data_engine(spark,sc)\n\nif __name__ == '__main__':\nmain()\nShow more\n\nNote that for the SELECT command to work, you must pass the IBM Cloud Object Storage identifiers as one of the standard Data Engine aliases, in this example, we have used ALIAS NAME. If you do not pass the expected ones, you might see the following error: Configuration parse exception: Access KEY is empty. Please provide valid access key.\n\nselect_query_data_engine_payload.json:\n\n{\n\"application_details\": {\n\"conf\": {\n\"spark.hadoop.fs.cos.ALIAS NAME.endpoint\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.access.key\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.secret.key\": \"CHANGEME\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.truststore.password\" : \"changeit\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.execution.engine\":\"spark\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.password\":\"APIKEY-WITH-ACCESS-TO-DATA-ENGINE-INSTANCE\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.uris\":\"THRIFT URL\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_13481-7-1988","score":46.9806697099,"text":"\nConnecting Apache Spark with Data Engine \n\nIBM Cloud\u00ae Data Engine catalog provides an interface that is compatible with Apache Hive metastore. This unified metadata repository enables any Big Data engine, such as Apache Spark, to use Data Engine as metastore. The same definition for tables and views can be created once and used from any connected engine. Each instance of Data Engine exports its catalog as a database called default.\n\n\n\n Catalog usage within Data Engine \n\nThe Catalog can be used in Data Engine in read and write mode. Seamless access is configured without any configuration steps needed.\n\n\n\n\n\n Connecting Apache Spark with Data Engine \n\nWhen you use the Hive metastore compatible interface, access is limited to read only operations. Thus, existing tables and views can be used, but not modified.\n\nDepending from where you want to connect to your catalog, the steps may vary.\n\n\n\n Usage within Watson Studio Notebooks \n\nWatson Studio has the compatible Hive metastore client already included. It also includes a convenience library to configure the connection to the Hive metastore. Set the required variables (CRN and apikey) and call the helper function to connect to the Hive metastore:\n\n change the CRN and the APIkey according to your instance\ncrn='yourDataengineCRN'\napikey='yourAPIkey'\n\nfrom dataengine import SparkSessionWithDataengine\n\n call the helper function to create a session builder equipped with the correct config\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\nspark = session_builder.appName(\"Spark DataEngine integration test\").getOrCreate()\n\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_13481-6212-7871","score":45.8774039377,"text":"\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management. For user, specify the CRN and for password a valid API key with access to your Data Engine. Find the endpoint to use in the following table.\n\n\n\nTable 1. Region endpoints\n\n Region Endpoint \n\n us-south thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083 \n eu-de thrift:\/\/catalog.eu-de.dataengine.cloud.ibm.com:9083 \n\n\n\n\n\n\n\n Convenience libraries to configure Spark \n\nWhile the Data Engine catalog is compatible with the Hive metastore and can be used as any other external Hive metastore server, an SDK is provided to minimize the steps that are needed to configure Apache Spark. The SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine-spark-integration-1.4.51.jar)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16636-0-1664","score":45.0914028691,"text":"\n\n\n\n\n\n\n  Integrating Presto with Apache Hudi using a Hudi connector \n\nYou can integrate Presto with Apache Hudi by using the Hudi connector. You can query Hudi tables that are synced to Hive metastore (HMS) using Presto's SQL interface. This combination offers the benefits of fast and interactive analytics on large-scale, high-velocity data stored in Hudi. Hudi connector uses the metastore to track partition locations. It uses underlying Hudi file system and input formats to list data files.\n\n\n\n  Configuring a catalog in Presto \n\nCreate a hudi.properties file inside \/opt\/presto\/etc\/catalog directory in the presto container.\n\n hudi.properties\nconnector.name=hudi\n\n HMS thrift URI\nhive.metastore.uri=thrift:\/\/<hostname>:<port>\n\n properties to enable connection to object-storage bucket\nhive.s3.ssl.enabled=true\nhive.s3.path-style-access=true\nhive.s3.endpoint=<Bucket API Endpoint>\nhive.s3.aws-access-key=<INSERT YOUR ACCESS KEY>\nhive.s3.aws-secret-key=<INSERT YOUR SECRET KEY>\n\n properties to enable TLS connection to HMS\nhive.metastore.thrift.client.tls.enabled=true\nhive.metastore.authentication.type=PLAIN\nhive.metastore.thrift.client.tls.truststore.path=<Truststore Path>\nhive.metastore.thrift.client.tls.truststore.password=<Truststore Password>\nhive.metastore.thrift.client.tls.keystore.path=<Keystore Path>\nhive.metastore.thrift.client.tls.keystore.password=<Keystore Password>\nShow more\n\n\n\n\n\n  Limitations \n\n\n\n1.  Connector does not support DDL or DML SQL statements. Presto can query data using the Hudi connector, but cannot directly perform write operations.\n2.  Data modifications must be done through Hudi-specific tools and workflows.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hudi-conn"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.6105456989}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02597-4595-6892","score":18.3590285176,"text":"\nThrough the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.\n\nAs well as controlling which APIs a customer can use, different Plans can be used to implement rate limits. A rate limit can be implemented as a default rate across an entire Plan, or for specific operations of an API within that Plan, exempting them from the Plan rate limit. Different Plans can have differing rate limits, both between operations and for the overall limit. Applying rate limits to Plans makes it easy to offer different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute while a \"Full Plan\" might permit up to 1000 calls per minute.\n\nFinally, different Plans can be used to assign a billing cost. A Plan can be set as a free Plan, or as a Plan with billing. Plans with billing can be used with rate limits to set different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute for a cost of $5 per month, while a \"Full Plan\" might permit up to 1000 calls per minute for a cost of $20 per month.\n\nNote: Applying a rate limit at the Plan level, creates a default rate limit that applies to each operation within the Plan. If you need to set specific rate limits for specific operations, you must set them within the operations themselves and this setting overrides the setting at the Plan level.\n\nIBM API Connect also supports the implementation of multiple versions of Products. You can choose version numbers and use them to aid the development of your Products and Plans.\n\nNote: The version for a Product is distinct from the version of any APIs that are contained in the associated Plans. Plans cannot themselves have their own version, they use the version of their parent Product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_03166-23681-24372","score":17.5668384928,"text":"\nFor Lite plans, usage is measured by the number of \/message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU) \n\n\n\nFor more information about how the web chat widget tracks MAUs, see [Billing](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-billing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_03107-4-1607","score":17.4736735525,"text":"\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Managing your plan](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan). To see all documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Managing your plan \n\nThis topic provides:\n\n\n\n* A [plan information](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-information) reference\n* Steps on [upgrading your plan](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-upgrade)\n\n\n\n\n\n Plan information \n\nBilling for the use of Watson Assistant is managed through your IBM Cloud\u00ae account.\n\nThe metrics that are used for billing purposes differ based on your plan type. You can be billed based on the number of API calls made to a service instance or on the number of active users who interact with the instance.\n\nFor answers to common questions about subscriptions, see [How you're charged](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges).\n\nExplore the Watson Assistant [service plan options](https:\/\/www.ibm.com\/cloud\/watson-assistant\/pricing\/).\n\n\n\n Paid plan features \n\nThe following features are available only to users of a Plus or Enterprise plan. ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png)\n\n\n\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_16252-7-1601","score":17.2288196942,"text":"\nManaging your plan \n\nThis topic provides:\n\n\n\n* A [plan information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-information) reference\n* Steps on [upgrading your plan](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-upgrade)\n\n\n\n\n\n Plan information \n\nBilling for the use of Watson Assistant is managed through your IBM Cloud\u00ae account.\n\nThe metrics that are used for billing purposes differ based on your plan type. You can be billed based on the number of API calls made to a service instance or on the number of active users who interact with the instance.\n\nFor answers to common questions about subscriptions, see [How you're charged](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges).\n\nExplore the Watson Assistant [service plan options](https:\/\/www.ibm.com\/cloud\/watson-assistant\/pricing\/).\n\n\n\n Paid plan features \n\nThe following features are available only to users of a Plus or Enterprise plan. ![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/plus.png)\n\n\n\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone)\n* [Private endpoints](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-securingsecurity-private-endpoints)\n* [Search](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-add)\n* [v2 Logs API](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"},{"document_id":"ibmcld_03798-0-2240","score":16.8777663989,"text":"\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http:\/\/ibm.com\/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https:\/\/cloud.ibm.com\/billing\/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https:\/\/cloud.ibm.com\/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-understand-invoices"},{"document_id":"ibmcld_02597-3131-5174","score":16.0100639326,"text":"\nPlans can share APIs, but whether subscription approval is required depends upon the Plan itself. Additionally, you can enforce rate limits through Plans or through operations within a Plan's APIs that override the Plan's rate limit.\n\nPlans can also specify billing costs for customers who use your Products. For example, you can define three different Plans for a single Product. Each Plan can have a different subscription cost and a different rate limit that targets different customers.\n\n\n\n\n\n Products \n\nPlans and APIs are grouped in Products. Through Products, you can manage the availability and visibility of APIs and Plans. Use the API Designer to create, edit, and stage your Product. Use the API Manager to manage the lifecycle of your Product.\n\nThe following diagram demonstrates how Products, Plans, and APIs relate to one another. Note how Plans belong to only one Product, can possess different APIs to other Plans within the same Product, and can share APIs with Plans from any Product. Figure to show the hierarchy of Products, Plans, and APIs. ![Figure to show the hierarchy of Products, Plans, and APIs.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/images\/plan_product_hierarchy.png)\n\nYou can create Plans only within Products, and these Products are then published in a Catalog. A lifecycle manager can then control the availability and visibility of APIs and Plans through the API Manager. Through the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_16365-15662-16934","score":15.9455819509,"text":"\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs. For information about how to avoid this problem, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nFor information about how to customize the handling of user identity information for billing purposes, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nThe usage is measured differently depending on the plan type. For Lite plans, usage is measured by the number of \/message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03704-1531-3564","score":15.6144769961,"text":"\nWhat's the difference between a Pay-As-You-Go and Subscription account? \n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\n\n\n What happens if my Lite plan instance reaches the monthly quota? \n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n\n\n\n\n\n Can I use PayPal as a payment method? \n\nAs of March 31, 2023, PayPal is no longer accepted.\n\n\n\n\n\n Can I update my credit card? \n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1042894-1044946","score":15.4069105502,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1042765-1044817","score":15.4069105502,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3154648768}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03735-7-1918","score":25.959997106,"text":"\nEstimating your costs \n\nYou can use the cost estimator to estimate the cost of IBM Cloud\u00ae products by customizing plans that fit your business needs. Your account type doesn't affect your estimates. Explore the catalog to find available products to add to an estimate.\n\nEstimates can now be saved to an account. Make sure you're in the account that you want to save the estimate to. If you have existing estimates, they must be converted to a saved estimate that is attached to an account.\n\n\n\n Creating a new estimate \n\n\n\n1. In the IBM Cloud console, go to Cost estimator icon![Cost estimator icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/calculator.svg). From here, you are directed to Estimating your costs page.\n2. Click Create new estimate.\n3. Enter a name and description for the estimate.\n4. Click Create\n5. From here, you are directed to the estimate details page. Click Go to catalog to add products to the estimate.\n6. Select the product that you are interested in.\n\nDepending on the product, an interim informational page might be displayed. For example, if you select Bare Metal Servers, an informational page that describes various features is displayed. Click Continue.\n7. Select your pricing plan and enter other configuration details if needed. Then, click Add to estimate.\n\nSome products might require that you log in to add them to an estimate.\n8. Enter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_07578-806120-808288","score":25.2919352074,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-805993-808161","score":25.2919352074,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01623-6277-8255","score":24.8768959942,"text":"\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started"},{"document_id":"ibmcld_07578-807740-809746","score":24.8078574886,"text":"\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n* In terms of cost, what do I pay for?\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n* Can I change billing options after my direct link is provisioned?\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-807613-809619","score":24.8078574886,"text":"\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n* In terms of cost, what do I pay for?\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n* Can I change billing options after my direct link is provisioned?\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11857-1988-2975","score":24.0895771453,"text":"\nSatellite-enabled IBM Cloud services \n\nEach IBM Cloud service instance that you create in your Satellite location incurs charges. For more information, see [Supported Satellite-enabled IBM Cloud services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-managed-services).\n\n\n\n\n\n Can I estimate my costs? \n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n\n\n\n\n\n Can I view and control my current usage? \n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricing"},{"document_id":"ibmcld_03735-1425-3233","score":23.1647969536,"text":"\nEnter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1. Click Save and select the estimate that you'd like to add the product to, and then add the calculated cost to your estimate by clicking Save.\n2. When you're done adding products to your estimate, review the product details, and click View estimate.\n\n\n\n\n\n\n\n Updating an existing estimate \n\nYou can always update the name and description of an estimate as your needs change. To edit an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to edit.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Edit.\n3. Enter the updated name and description.\n4. Click Save\n\n\n\n\n\n\n\n Saving and sharing your estimate \n\nWhen you create an estimate, you can save each estimate's unique link to share or revisit directly through your browser. To share an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to share.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Share.\n3. Click Copy link and share the link with users in your account.\n\n\n\n\n\n\n\n Creating quotes for classic infrastructure services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_11163-81224-83154","score":23.1457011424,"text":"\n: To help you decide and analyze what services you'd like to purchase, you can use the cost estimator. Now, you can go through the console and select each service you'd like to have, and add all of the costs in an easy to use tool. You can even enter projected data usages, lookups per second, writes per second, and queries per second to get a more accurate estimation of your monthly expenditures. You can use the cost estimator with each catalog service you select, or you can click the Cost Estimator icon ![Cost Estimator icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/adcecdbe4e86955f88aac7f3c1e7ec3ff44992ef\/overview\/icons\/calculator.svg) in the console menu to get a summary of your estimated costs. For more information, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\n\n\n\n\n 01 November 2018 \n\nUpdated global location names\n: As IBM Cloud continues to expand our global availability footprint, we\u2019re updating our location naming structure to better support an understandable, consistent hierarchy of geographies, regions, and data centers around the world. If you\u2019re familiar with our current global regions, you\u2019ll recognize names like US South and Sydney. We\u2019re aligning these location names to the names of the city in which the data centers physically exist.\n\nFor now, the programmatic IDs are not changing, so there\u2019s no impact from an API perspective. The following table shows the old and new location names. For more information and a comprehensive list of data centers and regions, see [Service availability](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-services_region).\n\n\n\nTable 1. New location names\n\n Previous Location Display Name New Location Display Name Code \n\n US South Dallas us-south \n US East Washington DC us-east \n United Kingdom London eu-gb \n Germany Frankfurt eu-de \n Sydney Sydney au-syd \n AP North Tokyo jp-tok \n\n\n\n\n\n\n\n\n\n October 2018","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatsnew"},{"document_id":"ibmcld_12918-7-2258","score":23.0569590087,"text":"\nPricing \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae is priced based on the provisioned throughput capacity that you allocate for your instance, and the amount of data storage consumed. With IBM Cloudant, you can scale your provisioned throughput capacity up and down, and pay a pro-rated hourly rate. The provisioned throughput capacity is a reserved number of reads per second, writes per second, and global queries per second allocated to an instance. The throughput capacity setting is the maximum usage level for a given second. You can't exceed the reserved capacity for either reads, writes, or global queries. If you do, an HTTP 429 status code occurs that indicates the application is trying to exceed its provisioned throughput capacity allowance. IBM Cloudant usage is billed hourly.\n\nThe estimated monthly cost for a particular level of provisioned throughput and storage capacity can be determined by using the Cost Estimator on the [IBM Cloud\u00ae Catalog page](https:\/\/cloud.ibm.com\/catalog\/services\/cloudant) for IBM Cloudant.\n\nYou can use the IBM Cloud pricing calculator to see estimated costs in other currencies by clicking Add to estimate from the IBM Cloudant catalog tile. Specify storage, capacity, and select the country whose currency you want to see.\n\nClick Calculate cost and Save. Now, click Review estimate. Expand the estimate to see more details. If you save multiple estimates, you can then click Review estimate and compare them.\n\nYou can launch the IBM Cloud Dashboard. Click Resource list > Services > your instance > Manage > Capacity to view and change the provisioned throughput capacity, and see the hourly and approximate monthly costs.\n\n\n\n Changing Provisioned Throughput Capacity \n\nLet's assume you're building a mobile app with IBM Cloudant and don't yet know the capacity that you might need. In this case, the IBM Cloudant team recommends that you start with the lowest provisioned throughput capacity and increase it as needed by your application's usage over time. IBM Cloudant bills pro-rated hourly and changing the provisioned throughput capacity doesn't incur downtime.\n\nThe minimum provisioned throughput capacity for the Standard plan is 100 reads per second, 50 writes per second, and 5 global queries per second.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-pricing"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.8065735964}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03797-4528-6268","score":14.5710280785,"text":"\n[A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/example-invoice-console.png)\n\nFigure 3. New and one-time charges in the console for the month of March.\n\nThe remaining infrastructure charges of $322,806.71 USD from the recurring invoice in the console and the new and one-time charges should add up to the total IaaS final invoice charge of $324,245.93 USD.\n\n\n\n\n\n Granular view of the line item charges \n\nNow that we confirmed that the final invoice totals match the recurring and new and one time charges in the console, let\u2019s find out what the charges on the final invoice represent.\n\nOn the Excel version of your recurring invoice that you downloaded in step 2, click the Detailed Billing tab. The Detailed Billing tab provides a breakdown of all of your infrastructure and platform charges. They represent three major types of usage:\n\n\n\n* In Advance (for example, the month of March) infrastructure monthly usage charges. These are recurring charges that you incur until you cancel the service. The charge is the same every month.\n\n\n\nZoom\n\n![An example of an advanced infrastructure monthly usage charges on the detailed invoice tab from the downloaded Excel invoice.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_03729-7-2197","score":14.3353438038,"text":"\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_11408-13151-14243","score":13.9410128694,"text":"\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change. To calculate your pricing, use the [IBM cost estimator](https:\/\/cloud.ibm.com\/estimator) in IBM Cloud console.\n\n\n\n\n\n End of billing \n\nThe monthly billing cycle ends when you delete the LPAR. If you scale your infrastructure up and down in response to workload requirements, your billing follows the timing of the LPAR provision change. If you stop the LPAR, the billing process is not stopped. You must delete the LPAR to stop the billing cycle.\n\nYou are still charged if the VM is in a suspended state. When your VM is inactive, you can use Dynamic Logical Partitioning (DLPAR) to resize it to a minimal state. You can drastically decrease the price per hour by reducing the VM's core count and memory.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_03797-5893-7322","score":13.9367124073,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges. In arrears, infrastructure hourly charges are always in this format.\n\n\n\nZoom\n\n![An example of an arrears infrastructure hourly charge on the detailed invoice tab from the downloaded Excel invoice.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/arrears-hourly.png)\n\nFigure 5.In Arrears infrastructure hourly charges.\n\n\n\n* In arrears (for example, the month of January) platform service charges. These are usage-based charges from two months prior. They are labeled Platform service in column B and reference the month in which the usage was consumed.\n\n\n\nZoom\n\n![In arrears platform service charges.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/arrears-platform-service-charges.png)\n\nFigure 6. In arrears platform service charges for the month of January.\n\n\n\n\n\n Next steps \n\nTo continue your learning about your billing and usage, see [Managing payments](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage),","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_03798-0-2240","score":13.6951989695,"text":"\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http:\/\/ibm.com\/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https:\/\/cloud.ibm.com\/billing\/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https:\/\/cloud.ibm.com\/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-understand-invoices"},{"document_id":"ibmcld_11408-11687-13539","score":13.579151812,"text":"\nData volumes of 235 GB\n\nBoot volumes of 200 GB\n\nDeployed VMs of 160 GB\n\n\n\nTable 10. Account billable for storage use case\n\n Name Size State\/Description \n\n data-volume-1 20 GB Available \n data-volume-2 25 GB In-use (attached to vm-1) \n data-volume-3 100 GB In-use (attached to vm-1) \n data-volume-4 30 GB Available \n data-volume-5 60 GB In-use (attached to vm-2) \n\n\n\nTotal billable storage = 595 GB\n\n\n\n* Data volumes: 235 GB\n* Image volumes: 200 GB\n* Deployed VMs: 160 GB\n\n\n\n\n\n\n\n\n\n Pricing for VPN connection \n\nWhen you use a VPN connection, you are billed monthly.\n\nIBM charges with the base price hourly per connection. The base price varies per geography. So if you use one vpn connection that is active for a month, the monthly bill would be $base price X 24 hours X 30 days.\n\n\n\n\n\n Pricing for Power Edge Router \n\nAs a Power Systems Virtual Server user, you are charged based on the Transit Gateway connections that you use:\n\n\n\n* New Transit Gateway that you create in a PER workspace.\n* Existing Transit Gateways that add Power Systems Virtual Server workspace to their existing connection.\n\n\n\nHere are some more PER charges based on the following Transit Gateway specifics:\n\n\n\n* Routing option\n* Number of connections\n\n\n\nThe following table shows the charges based on the routing option that you select:\n\n\n\nTable 13. TGW charges based on routing\n\n Routing type Charges \n\n Local routing data transfer No charges \n Global routing data transfer $0.009405 GB \n\n\n\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_03797-3428-4809","score":13.4580979036,"text":"\n[Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/download.svg) to download the invoice directly to your device.\n5. Open the downloaded file, and click Summary tab.\n\n\n\nIn this example, the Platform Services charge matches the total on the PaaS final invoice from Figure 1: $5,566.81 USD. The remaining charges, which total $322,806.71 USD ($328,373.52 - $5566.81 = $322,806.71) represent the remaining infrastructure, nonplatform charges from this recurring invoice.\n\nZoom\n\n![An image of recurring console invoice](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/Recurring-invoice.png)\n\nFigure 2.IaaS recurring charges.\n\n\n\n\n\n Identify the new and one-time charges \n\nNext, you need to identify and find the sum of the new and one time charges. Your new and one-time charges are on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices) in the console. There are three new charges on the invoices page during this time period: A charge of $500.52, $767.10, and $171.60.\n\nZoom\n\n![A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/example-invoice-console.png)\n\nFigure 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_03797-7-1811","score":13.3381652455,"text":"\nReconciling usage for nonsubscription multi-year account invoices \n\nAs an IBM Cloud\u00ae customer with a nonsubscription multi-year account, understanding the different invoices that are available to you can help you understand your monthly cost breakdown.\n\nFinal invoice\n: The finalized compilation of charges a user receives at the end of the month.\n: Includes new and one-time charges from the 20th of the prior month to the 19th of the current month. For the examples referenced in this document, the new and one-time charges are from 20 February to 20 March.\n: Includes the recurring charges from the recurring invoice in the IBM Cloud console.\n\nRecurring invoice\n: The recurring invoice is a system generated reference invoice that's located in the IBM Cloud console. The recurring invoice provides a line item breakdown of each recurring charge. This doesn't include every charge that appears on the final monthly invoice and is not the final invoice that you are charged for.\n\nIn this tutorial, you'll see a few invoice examples:\n\n\n\n* [Figure 1](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-reconcile-invoiceIaaS-PaaS): The Infrastructure as a Service (IaaS) and Platform as a Service (PaaS) invoice for March. This invoice is sent to the email associated with the account.\n* [Figure 2](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-reconcile-invoicerecurring-console-invoice): The March recurring invoice. You can find your recurring invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices).\n* [Figure 3](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-reconcile-invoicenew-charges): A view of the invoice tab in the console with the new and one-time charges from 20 February to 19 March.\n\n\n\n\n\n Step 1: Review the totals on the final invoice","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_03776-3313-5682","score":13.0483463343,"text":"\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_07578-1183252-1185036","score":13.0436360354,"text":"\nThe user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n* How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?\n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD\/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https:\/\/cloud.ibm.com\/catalog\/services\/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.296081911,"ndcg_cut_10":0.296081911}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03729-4932-7001","score":31.4107314489,"text":"\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03776-5228-7163","score":28.7030758352,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03729-1672-3956","score":27.7053147719,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03578-7-2257","score":26.576343983,"text":"\nAbout bandwidth metering \n\nTo reduce your overall bandwidth costs, it's important to consider your bandwidth metering options. You can purchase and manage bandwidth metering for classic in two ways, through metering on individual devices, or through collective-metering when you add a device to a bandwidth pool.\n\nAll inbound and outbound bandwidth inside the IBM Cloud Classic infrastructure is unlimited and cost-free for your servers' use. Public egress bandwidth is charged on a tiered basis, with a set allocation for each month of your servers' use.\n\nBandwidth usage is measured as egress traffic on a device's public interfaces.\n\nBandwidth allocations are reserved for all public egress network usage. Devices with individual bandwidth metering and pool-based metering are all measured unless the device is ordered on the private network only.\n\nBandwidth allocation is a threshold where usage below the threshold is free or included, while usage in excess of the threshold is billed as a bandwidth overage. Bandwidth overages are billed individually per server or device, unless they participate in a bandwidth pool.\n\nDevices added to a bandwidth pool contribute both their bandwidth allocation and bandwidth usage to form aggregated totals for the pool. If the pool usage exceeds the total pool allocation, the account owner is billed a consolidated pool overage fee.\n\n\n\n About device bandwidth \n\nYou can manage each device's bandwidth allocation. When you provision certain devices, you can select the amount of bandwidth that you want to allocate to that device. For each device, you pay for a fixed amount of bandwidth allocation during a billing cycle, and receive a notification when the device is at risk of overage for the billing cycle. For more information, see [Adding Bare Metal Server bandwidth](https:\/\/cloud.ibm.com\/docs\/bandwidth-services?topic=bandwidth-services-adding-bare-metal-server-bandwidth) and [Adding virtual server instance bandwidth](https:\/\/cloud.ibm.com\/docs\/bandwidth-services?topic=bandwidth-services-adding-virtual-server-insance-bandwidth).\n\nWhen the bandwidth usage on a device reaches 85% of its total allocation, the account owner receives notifications.\n\nIBM charges for some firewall bandwidth metering.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/bandwidth-metering?topic=bandwidth-metering-about-bandwidth-metering"},{"document_id":"ibmcld_03776-3313-5682","score":25.2884410207,"text":"\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_12837-8834-10242","score":25.1952480908,"text":"\nBlock tier (up to) The total amount that is charged is established by an up to quantity that doesn't vary within the block If Q is <=Q1, T=T1<br><br>If Q1 < Q <=Q2, T=T2<br><br>If Q2 < Q <=Q3, T=T3 Q1=1000, T1=$0<br><br>Q2=2500, T2=2500<br><br>Q3=10000, T3=$4500<br><br>T=$4500 \n\n\n\nBlock tier pricing is not currently supported. If your product migrated from the resource management console, and you used block tier pricing, it is still honored. However, you can't add any new block tier pricing plans at this time.\n\n\n\n\n\n Metrics for metering models \n\nIf you created your service with Partner Center, you can choose from the following metrics and default metering models:\n\n\n\nTable 9. Partner Center metering model metrics\n\n Type Metric \n\n dailyproration_max Active User \n standard-add API call \n dailyproration_max Authorized User \n standard_add Gigabyte hour \n standard_add Gigabyte month \n monthlyproration Instance \n standard_add Terabyte hour \n standard_add Terabyte month \n dailyproration_max User \n standard_add Virtual Server \n standard_add Virtual Server Hour \n standard_add Virtual Processor Core \n\n\n\nThird-party providers that migrated from the resource management console to Partner Center can manage their metering models with Partner Center. Any information that you added or edited for pricing plans and metering models by using the resource management console can be updated in Partner Center.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-metering-integration"},{"document_id":"ibmcld_10116-1581-3594","score":23.1565318607,"text":"\nFor more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.\n\n\n\n* Shared versus dedicated: If you share the underlying hardware of the VM, the cost is less than dedicated hardware, but the physical resources are not dedicated to your VM.\n* Hourly billing only: Hourly billing offers more flexibility to order and cancel VMs quickly. You are charged an hourly rate that is metered for only the time that that the worker node is provisioned. The time is not rounded up or down to the nearest hour, but is metered in minutes and charged at the hourly rate. For example, if your worker node is provisioned for 90 minutes, you are charged the hourly rate for 1.5 hours, not 2 hours.\n* Tiered hours per month: The [pricing](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/aboutpricing) is billed hourly in [graduated tiered](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargesgraduated_tier). As your VM remains ordered for a tier of hours within a billing month, the hourly rate that you are charged lowers. The tiers of hours are as follows:\n\n\n\n* 0 - 150 hours\n* 151 - 290 hours\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_05666-1575-3588","score":23.1565318607,"text":"\nFor more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.\n\n\n\n* Shared versus dedicated: If you share the underlying hardware of the VM, the cost is less than dedicated hardware, but the physical resources are not dedicated to your VM.\n* Hourly billing only: Hourly billing offers more flexibility to order and cancel VMs quickly. You are charged an hourly rate that is metered for only the time that that the worker node is provisioned. The time is not rounded up or down to the nearest hour, but is metered in minutes and charged at the hourly rate. For example, if your worker node is provisioned for 90 minutes, you are charged the hourly rate for 1.5 hours, not 2 hours.\n* Tiered hours per month: The [pricing](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/aboutpricing) is billed hourly in [graduated tiered](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargesgraduated_tier). As your VM remains ordered for a tier of hours within a billing month, the hourly rate that you are charged lowers. The tiers of hours are as follows:\n\n\n\n* 0 - 150 hours\n* 151 - 290 hours\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_05666-7-2151","score":22.821422195,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like IBM Cloud\u00ae Kubernetes Service, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith IBM Cloud Kubernetes Service clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_10116-7-2157","score":22.7249685147,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith Red Hat OpenShift on IBM Cloud clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.703918089,"ndcg_cut_10":0.703918089}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11149-17131-19651","score":32.3386971197,"text":"\nStorage Products that support data to be created, read, updated, and deleted \n\n\n\nYou can also scope your view of the catalog by using the Provider filter to browse by individual providers and the Industry filter to view products catered for certain industries.\n\n\n\n\n\n\n\n Pricing and billing \n\nYou can view the pricing details for each service when you're browsing the catalog. If you choose a service plan with a paid plan, you can estimate your costs by using the cost estimator tool. For more information, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nIBM Cloud billing provides multiple services that ensure the IBM Cloud platform can securely manage pricing, accounts, usage, and more.\n\n\n\n Account management \n\nAccount management maintains the billing relationship with the customer. Each account is a billing entity that represents a customer. This service controls account lifecycle, subscription, user relationship, and organization.\n\n\n\n\n\n Usage metering \n\nWith usage metering, service providers can submit metrics that are collected for resource instances that are created by IBM Cloud users. Third-party service providers that deliver an integrated billing service are required to submit usage for all active service instances every hour.\n\n\n\n\n\n Usage reports \n\nUsage reports return the summary for the account for the specified month. Account billing managers are authorized to access the reports.\n\n\n\n\n\n\n\n Managing security and compliance \n\nThe IBM Cloud\u00ae Security and Compliance Center offers a single location where you can validate that your resources are meeting continuous security and compliance.\n\nYou can create profiles and config rules to ensure that specific areas of your business adhere to your defined requirements or industry regulations. From the Security and Compliance Center dashboard, you can download detailed reports that you can use to provide evidence to stakeholders or external auditors. The Security and Compliance Center also offers security insights that you can use to detect potential threats when observing your account activity. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n\n\n Creating resources \n\nThe resource controller is the next-generation IBM Cloud platform provisioning layer that manages the lifecycle of IBM Cloud resources in your account. Resources are created globally in an account scope.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatis-platform"},{"document_id":"ibmcld_02665-3418-5653","score":31.9589448682,"text":"\nFor server-side entities like microservices, when the state of a feature flag or property changes in the App Configuration, a websocket connection notifies the SDK in the microservice that a state change occurred. The microservice then calls back into the App Configuration to retrieve the update. This action is an API call.\n\nAn API call also occurs on startup to the retrieve the initial configuration state. For client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n\n\n\n\n\n How to view usage metrics for App Configuration? \n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n\n\n\n\n\n How to predict App Configuration cost? \n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage"},{"document_id":"ibmcld_03776-3313-5682","score":31.8496737338,"text":"\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_07578-506456-508701","score":30.7685617132,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-506398-508643","score":30.7685617132,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03776-5228-7163","score":30.4807253314,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_12815-5234-7392","score":29.6121294873,"text":"\nFirst, add the Export Control Classification Number and the United Nations Standard Products and Services Code that applies to your product. Next, define your pricing plan. Currently, you can choose a free or usage-based pricing plan. If you\u2019d like, you can add multiple plans for your product. [Click Pricing then click Add ECCN to add your Export Control Classification Number. Click Add UNSPSC to add the United Nations Standard Products and Services Code for your product. Click Add plan, select the plan type, add a name, select how resource instances should be deployed, and click Save.]\n\nFor usage-based plans, you must submit your tax and EFT information to set up and receive payment disbursements for usage. You\u2019ll also want to add metrics to determine how customers are charged, and submit your updates for approval. [The Payments to me page is highlighted. Click Add metrics to add your metrics to the pricing plan. In the Metering approval section, click Request approval.]\n\nBuilding one or more service brokers is needed to manage the lifecycle of your service and metering integration. A broker must be added to complete your pricing plan. Your technical team member can get started with our sample broker. Add your broker by entering a name, a URL, a username, and a password. Or, you can import brokers from your account. After you add your broker, link it to your pricing plan. [Click Brokers. In the Onboard brokers to IBM Cloud section, click OK to open the sample reference broker. Click Add broker to add your broker. Click Pricing, click the actions icon for your pricing plan, and click Edit plan to link your broker to your pricing plan.]\n\nNow that you\u2019ve defined your pricing model, review how customers would understand and experience it. After your metering updates are approved, validate that your metered plans are correctly configured by enabling and submitting a usage test. This usage test includes creating your metering JSON, calling the Usage Metering API, and submitting metering evidence. [Click Add metrics for the pricing plan you added. Click Test estimation and metering to submit your metering evidence for review.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-started"},{"document_id":"ibmcld_01623-6277-8255","score":29.5369997879,"text":"\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started"},{"document_id":"ibmcld_08067-0-1736","score":28.9141570497,"text":"\n\n\n\n\n\n\n  Viewing your support costs \n\nIf you have Advanced or Premium support, you can keep track of your monthly support costs from the Support costs page in the IBM Cloud\u00ae console.\n\n\n\n  How you're charged for support \n\nEach [IBM Cloud support plan](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans) has a minimum monthly price for providing support for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost. For details about your purchased support plan, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n  Viewing support costs \n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\nIn the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. You can view your support plan and relevant cost details:\n\n\n\n*  If your support costs are billed monthly, you can view your costs for the current month. These costs include the starting price for the plan and any additional costs from your resource usage. After each billing cycle, these charges are added to your monthly invoice.\n*  If you have a support subscription, you can view the remaining credit in your active subscriptions and any overages for the current month. Overage is charged if you run out of credit in your active subscriptions. You can also view upcoming support subscriptions, which are subscriptions that you bought but are not yet valid.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support"},{"document_id":"ibmcld_03729-7-2197","score":28.7710563097,"text":"\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03729-7-2197","score":32.3260723955,"text":"\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_07578-807740-809746","score":30.3603552121,"text":"\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n* In terms of cost, what do I pay for?\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n* Can I change billing options after my direct link is provisioned?\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-807613-809619","score":30.3603552121,"text":"\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n* In terms of cost, what do I pay for?\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n* Can I change billing options after my direct link is provisioned?\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-806120-808288","score":30.2090916524,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-805993-808161","score":30.2090916524,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03776-3313-5682","score":29.2415778351,"text":"\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_08067-0-1736","score":29.0098121092,"text":"\n\n\n\n\n\n\n  Viewing your support costs \n\nIf you have Advanced or Premium support, you can keep track of your monthly support costs from the Support costs page in the IBM Cloud\u00ae console.\n\n\n\n  How you're charged for support \n\nEach [IBM Cloud support plan](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans) has a minimum monthly price for providing support for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost. For details about your purchased support plan, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n  Viewing support costs \n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n\nIn the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. You can view your support plan and relevant cost details:\n\n\n\n*  If your support costs are billed monthly, you can view your costs for the current month. These costs include the starting price for the plan and any additional costs from your resource usage. After each billing cycle, these charges are added to your monthly invoice.\n*  If you have a support subscription, you can view the remaining credit in your active subscriptions and any overages for the current month. Overage is charged if you run out of credit in your active subscriptions. You can also view upcoming support subscriptions, which are subscriptions that you bought but are not yet valid.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support"},{"document_id":"ibmcld_05666-7-2151","score":28.5578785215,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like IBM Cloud\u00ae Kubernetes Service, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith IBM Cloud Kubernetes Service clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_10116-7-2157","score":28.4939797673,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith Red Hat OpenShift on IBM Cloud clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_11857-1988-2975","score":27.9836439983,"text":"\nSatellite-enabled IBM Cloud services \n\nEach IBM Cloud service instance that you create in your Satellite location incurs charges. For more information, see [Supported Satellite-enabled IBM Cloud services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-managed-services).\n\n\n\n\n\n Can I estimate my costs? \n\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n\n\n\n\n\n Can I view and control my current usage? \n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-sat-pricing"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3333333333}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03776-5228-7163","score":28.0636153598,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03765-2725-4571","score":25.8703812311,"text":"\n[Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Set as default.\n2. Confirm that you want to make this payment method the default. The default payment method is charged for recurring payments\n\n\n\n\n\n\n\n Managing payment methods for all other accounts \n\nThe steps to update your credit card apply to the following types of accounts:\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nAmerican Express can't be used as a payment method for India, Singapore, and South Africa based accounts that are billed in US dollars.\n\n\n\n Updating your payment methods \n\nIf you're using a payment method that's not a credit card, complete the following steps to switch to your payment method:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. Click Payment method.\n3. In the Add Payment Method section, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\n\n\nSome payment methods aren't accepted as recurring payment methods. You must manually submit the payment each month.\n\n\n\n\n\n India-based customers with accounts that are billed in US Dollars","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03704-3030-4892","score":25.4058317274,"text":"\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1044428-1046278","score":25.3332127658,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1044299-1046149","score":25.3332127658,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03765-4100-6125","score":25.3106350909,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n2. Click Payment method.\n3. In the Add Payment Method section, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\n\n\nSome payment methods aren't accepted as recurring payment methods. You must manually submit the payment each month.\n\n\n\n\n\n India-based customers with accounts that are billed in US Dollars \n\nDue to current banking regulations, recurring credit card transactions might be unsuccessful for India-based customers with accounts that are billed in US Dollars. You can use one of the following methods to make a payment:\n\n\n\n* [Make a one-time payment](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagemakepayment)\n* Request to migrate your account to be billed in India Rupees. To make a request, provide a credit card that is billed in India Rupees on the [Payment Method](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. Specify that India Rupees are in the Payment Currency section. Additional information might be requested through a Support case during the migration process.\n\n\n\n\n\n\n\n Making a one-time payment \n\nYou can use a credit card to make a one-time payment at any time for any amount, whether it's for the full balance or a partial sum. The details that you enter for the one-time payment aren't recorded for future use, and aren't populated with a default amount.\n\nTo make a one-time payment, in the IBM Cloud console, go to Manage > Billing and usage, and select Payments. Click Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03765-5710-7263","score":25.1903252031,"text":"\nClick Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console \n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/) and log in with your IBMid and password. You are also required to enter the temporary passcode that's emailed to you.\n\nTo add a payment method, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your payment information, and click Register. A temporary passcode is emailed to you after the registration process is complete.\n\n\n\nAfter you register a payment method, when you click Manage payment method, you can view the Manage my wallet page to update or delete your payment methods by clicking the Edit icon ![Edit icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/edit-tagging.svg).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03793-7-1857","score":24.0147792711,"text":"\nHow do I add a credit card when the option isn't available through the console? \n\nIf your payments are managed outside of the console, you can't use [Billing and usage](https:\/\/cloud.ibm.com\/billing) to add a credit card.\n\n What\u2019s happening \n\nYou want to enter a credit card to pay for IBM Cloud services, but the option doesn't appear.\n\nWhen you try to enter your credit card information, you see the following message:\n\nYour payments are managed through IBM.com. To view your payments and maintain your billing, you can visit the IBM.com portal which contains everything for your IBMid account.\n\nYou click Explore to access the ibm.com website, but you don't see a location to enter your credit card information.\n\n Why it\u2019s happening \n\nCredit card transactions are securely processed through the IBM Cloud console. However, in some countries, extra steps are taken to ensure the integrity of the credit card data. Those credit card requests are completed through the IBM.com website. Both methods ensure that your credit card information is securely processed.\n\n How to fix it \n\nTo provide your credit card information for payment, complete the following steps:\n\n\n\n1. Go to [IBM.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nThe information is verified and added to your IBM Cloud account as your payment method for any charges.\n\nTo replace an existing credit card, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm"},{"document_id":"ibmcld_03704-4411-6289","score":23.6872584996,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n\n\n\n\n\n Can I delete my credit card? \n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1045891-1047755","score":23.6872584996,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.296081911,"ndcg_cut_10":0.296081911}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03771-1594-3365","score":28.2160964045,"text":"\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices):\n\n\n\n* Invoiced: You received the latest invoice from IBM Cloud.\n* Paid: Your payment for the charges on your latest invoice was received.\n* Unpaid: The charges on your latest invoice have not been paid.\n* Pending: Your payment for your latest charges has not been applied due to a payment processing error. In this case, you can contact IBM Cloud Support for more details about the error.\n\n\n\nTurning a resource \"off\" doesn't cancel the resource in your account. You will receive invoices for resources in your account until you cancel them. For more information, see [Cancelling your billing items](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cancel-billing-items).\n\n\n\n\n\n Viewing and downloading your invoice \n\nView and download your invoice from the IBM console by clicking the Download icon ![Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/download.svg)> PDF invoice next to each invoice. For some accounts, invoices are available through the [Invoices@IBM](http:\/\/ibm.com\/invoices) website. See the [Viewing and downloading invoices for all other accounts](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_03771-7-2029","score":27.7063649009,"text":"\nViewing your invoices \n\nTo manage and view your invoices, visit the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console. If your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices.\n\nIn these situations, visit the [Invoices@IBM](http:\/\/ibm.com\/invoices) website to see your invoices.\n\n\n\n Before you begin \n\nTo view your invoices, you need to be assigned the operator role or higher on the billing account management service. For more information, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n\n\n\n\n\n Viewing invoices for new US-based Pay-As-You-Go accounts with credit card billing \n\nNew IBM Cloud Pay-As-You-Go accounts for US customers with credit card billing can now view all classic infrastructure and platform services on one invoice. In the IBM Cloud console, go to Manage > Billing and usage, and select Invoices.\n\nThe new invoice hierarchy highlights the most important details. By showcasing when the usage is measured, you can view each invoice\u2019s billing period in a clarified and comprehensive manner. The adjustments section on your invoice provides details about credits and adjustments from previous billing periods that might be included on an invoice from a different month.\n\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices):","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_03764-2220-3440","score":24.8734078423,"text":"\n[Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n\n\n\n\n\n Is paperless invoicing available? \n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n\n\n\n\n\n What are the adjustments that are shown on my invoice? \n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n\n\n\n\n\n How do I know if my invoice is paid? \n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-invoice-faq"},{"document_id":"ibmcld_07578-1065299-1067188","score":24.6521402408,"text":"\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1066874-1068548","score":24.1738287889,"text":"\n[Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet. In some cases, you are redirected to the [IBM Invoices website](https:\/\/www.ibm.com\/invoices) where you can download your invoices. From the Invoices page, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n* Is paperless invoicing available?\n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1064084-1065746","score":23.6905877617,"text":"\nFor more information, see [Managing migrated SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How can I download my invoice?\n\nTo download your invoice, go to Manage > Billing and usage, and select Invoices. Then, click the Download icon ![Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet. In some cases, you are redirected to the [IBM Invoices website](https:\/\/www.ibm.com\/invoices) where you can download your invoices. From the Invoices page, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/icons\/action-menu-icon.svg) and select the invoice format. You can download an invoice as a simplified PDF, a detailed PDF, or as an excel spreadsheet.\n* Is paperless invoicing available?\n\nYes, you can switch to paperless invoices by submitting a request on the [IBM Customer Support site](https:\/\/www.ibm.com\/support\/customer\/zz\/en\/selectcountrylang.html). For more information, see [Requesting paperless invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesrequest-paperless-invoices).\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1064600-1066235","score":22.6358486648,"text":"\n* How do I add a new commitment?\n\nContact your [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative to add a new commitment to your account.\n* Why am I getting invoiced for a commitment I didn\u2019t use?\n\nSince you committed to a certain amount for a certain period of time and you didn't reach it, IBM Cloud\u00ae have the rights to charge you with the remaining amount.\n* Can I convert my US-based USD Pay-As-You-Go to a Subscription account? If so, what kind of impact does the commitment model have?\n\nYes, you can convert your account from US-based USD Pay-As-You-Go to an Enterprise Savings Plan, but it will be only effective after the term end of your former plan.\n* Where can I access my invoice?\n\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https:\/\/www.ibm.com\/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices) for more information.\n* Why does my usage not match my invoice?\n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16727-1068047-1069909","score":22.628052941,"text":"\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03798-0-2240","score":22.6074581974,"text":"\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http:\/\/ibm.com\/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https:\/\/cloud.ibm.com\/billing\/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https:\/\/cloud.ibm.com\/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-understand-invoices"},{"document_id":"ibmcld_03797-1449-2926","score":22.5815057649,"text":"\nYou can find your recurring invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices).\n* [Figure 3](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-reconcile-invoicenew-charges): A view of the invoice tab in the console with the new and one-time charges from 20 February to 19 March.\n\n\n\n\n\n Step 1: Review the totals on the final invoice \n\nYou receive an IaaS and PaaS invoice each month.\n\nFor this example, reference Figure 1. The IaaS invoice total is $324,245.93 USD and the PaaS invoice total is $5566.81 USD. To understand what these totals represent, you must view the recurring console invoice. The recurring invoice in the console provides a line item breakdown of each charge.\n\nZoom\n\n![An image of IaaS and PaaS invoice for the month](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/official-march-invoice.png)\n\nFigure 1.IaaS and PaaS invoice for the month of March.\n\nZoom\n\n![An image of IaaS and PaaS invoice for the month](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/official-invoice-2.png)\n\nFigure 1.IaaS and PaaS invoice for the month of March.\n\n\n\n\n\n Step 2: Identify the recurring charges \n\nFigure 2 represents the recurring charges. To locate these recurring charges, complete the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Invoices.\n2. Click the invoice number.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.75,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.787702057,"ndcg_cut_10":0.787702057}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03787-5002-7004","score":29.0385510328,"text":"\nA subscription is inactive if its term expires or all of its credit is spent.\n\n\n\nYou can use the spending and usage information on the Subscriptions page to evaluate whether your subscriptions suit your usage needs. For example, if you consistently have overages, you might increase your monthly spending commitment to save money on that usage. To buy new subscriptions or change future subscription amounts, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Support subscriptions \n\nTo view support subscription usage, in the console, go to Manage > Billing and usage, and select Support costs. You can view the remaining credit in your active support subscriptions and any upcoming subscriptions that aren't yet valid. For more information, see [Viewing your support costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-support).\n\n\n\n\n\n\n\n Subscription credit \n\nAfter you buy a subscription for platform or support credit, you add the credit to your account by applying a subscription code. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nFor more information, see [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Expiring subscriptions \n\nYou are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After the subscription expires, your account is converted to a Pay-As-You Go account, which means you pay only for billable services that you use with no contracts or commitments. The discounts that are associated with the subscription account won't apply to the Pay-As-You-Go account. The IBM Sales team is happy to help extend your subscription before you reach its expiration date. If you extend your subscription within 30 days from the expiration date, you won't get charged at the Pay-As-You-Go account rate. After 30 days, you are invoiced as a Pay-As-You-Go account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions"},{"document_id":"ibmcld_03704-10459-12479","score":28.7460267222,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n How do I apply a feature code? \n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Why did my account get billed for additional services charges? \n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1051890-1053900","score":28.7460267222,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1051761-1053771","score":28.7460267222,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03785-7-2010","score":28.4592516848,"text":"\nFAQs for subscription accounts \n\nFAQs for subscription accounts include entries about subscription credit, subscription terms, and other subscription-related self-help information.\n\n\n\n How do I add subscription credit to my account? \n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\n\n\n\n\n What does the IN_PROGRESS status mean when I apply a subscription code? \n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n\n\n\n\n\n Can I pay the total spending commitment up-front or quarterly? \n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Can I spend more or less than my monthly commitment? \n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n\n\n\n\n\n What happens if I spend my entire subscription amount before my term ends? \n\nYou're required to continue paying your monthly charges until the end of your term.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription-account"},{"document_id":"ibmcld_07578-1065299-1067188","score":28.1579458586,"text":"\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03704-8977-10890","score":27.5102793114,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n\n\n\n\n\n Why did I get invoiced when I have remaining promotion credits? \n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1050413-1052321","score":27.5102793114,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1050284-1052192","score":27.5102793114,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12597-0-804","score":27.1057467923,"text":"\n\n\n\n\n\n\n  Why can't I apply a subscription code to my account in an enterprise? \n\nA subscription code can't be added to the account because of specific access that is required.\n\n  What\u2019s happening \n\nYou can't add a subscription code to your IBM Cloud\u00ae account because you don't have the correct access.\n\n  Why it\u2019s happening \n\nBecause your account is a child account on the enterprise, you can't apply subscription codes. Subscription codes must be applied at the enterprise level.\n\n  How to fix it \n\nContact the owner or the administrator of the enterprise to add the subscription code. When the subscription code is added, it applies to all accounts in the enterprise. For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-troubleshoot-promo-enterprise"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>10","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03732-0-1673","score":19.8377521334,"text":"\n\n\n\n\n\n\n  Applying feature codes \n\nYou can apply feature codes to take advantage of extra IBM Cloud\u00ae resources or capabilities. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.\n\nAre you looking for details about adding subscription credit to your account? See [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions) for more information.\n\nYou must have the Editor role or higher for all account management services to apply a feature code. The extra resources or capabilities that are provided vary depending on the particular code but include one or more of the following items in general:\n\n\n\n*  Increase the memory quota to a number of GB that is specified by the code\n*  Add one organization with a memory quota that is specified by the code\n*  Add an unlimited number of organizations\n*  Upload an extra number of SSL certificates, as specified by the code\n*  Use premium service plans\n*  Convert a Lite account to a trial account, which provides access to more services but only within a limited trial period\n\n\n\nComplete the following steps to apply a feature code to your existing account:\n\nIf you don't have an account yet, you can add your feature code when you [register](https:\/\/cloud.ibm.com\/registration) for a new account by clicking Register with a code instead of entering your credit card information.\n\n\n\n1.  In the IBM Cloud console, go to Manage > Account, and select Account settings.\n2.  Click Apply code.\n3.  Enter the feature code, which is typically a random alphanumeric value such as a1b2c3def456.\n4.  Click Apply.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-codes"},{"document_id":"ibmcld_03704-7496-9340","score":19.2870789993,"text":"\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\n\n\n\n\n Where can I get a promo code? \n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/account?topic=billing-usage-applying-promo-codes).\n\n\n\n\n\n Where can I get a feature code? \n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n\n\n\n\n\n How do I apply a promo code? \n\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1048947-1050776","score":19.2870789993,"text":"\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1048818-1050647","score":19.2870789993,"text":"\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03785-7-2010","score":17.7239913523,"text":"\nFAQs for subscription accounts \n\nFAQs for subscription accounts include entries about subscription credit, subscription terms, and other subscription-related self-help information.\n\n\n\n How do I add subscription credit to my account? \n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n\n\n\n\n\n What does the IN_PROGRESS status mean when I apply a subscription code? \n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n\n\n\n\n\n Can I pay the total spending commitment up-front or quarterly? \n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Can I spend more or less than my monthly commitment? \n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n\n\n\n\n\n What happens if I spend my entire subscription amount before my term ends? \n\nYou're required to continue paying your monthly charges until the end of your term.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription-account"},{"document_id":"ibmcld_16727-1068047-1069909","score":17.7065713208,"text":"\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1065299-1067188","score":17.703469787,"text":"\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03709-0-1479","score":17.7028269192,"text":"\n\n\n\n\n\n\n  Why can't I apply a feature code? \n\nTo successfully apply a feature code, make sure the code is valid and that you have the correct account type.\n\n  What\u2019s happening \n\nWhen you try to apply a feature code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error for any of the following reasons:\n\n\n\n*  Your account doesn't meet the requirements for the feature code.\n*  You don't have the required access in the account.\n*  The code expired.\n\n\n\n  How to fix it \n\nUse the following steps to successfully apply a feature code:\n\n\n\n*  Verify that you have the correct account type. For example, some feature codes for educational promotions are only for Lite accounts. To view your account type, in the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n*  If you are unable to apply a feature code that you received from an educational provider, contact that educational provider for further assistance.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-feature-code"},{"document_id":"ibmcld_03704-8977-10890","score":17.5410388322,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n\n\n\n\n\n Why did I get invoiced when I have remaining promotion credits? \n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1050413-1052321","score":17.5410388322,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.3154648768}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>11","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-1710-3705","score":33.5053562696,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-3269-5168","score":30.6892522797,"text":"\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7-2194","score":29.6504646475,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7896-8949","score":26.5464012673,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-4689-6647","score":26.475998506,"text":"\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03704-3030-4892","score":25.3868949055,"text":"\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1044428-1046278","score":25.3546593044,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1044299-1046149","score":25.3546593044,"text":"\nGo to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n* How do I change my payment method?\n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n* Why didn't my credit card process?\n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1069800-1071727","score":23.9013249765,"text":"\nThis credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?\n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https:\/\/watson.service-now.com\/x_ibmwc_open_case_app.do!\/create).\n* Why is a VAT ID required when I create an account?\n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03776-5228-7163","score":23.7311975078,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.9047172295,"ndcg_cut_10":0.9047172295}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>12","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-3269-5168","score":65.306273654,"text":"\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-1710-3705","score":60.7688142893,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7-2194","score":57.0048553499,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-4689-6647","score":44.4079063746,"text":"\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-6236-8279","score":39.3041859133,"text":"\nFor more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03782-0-720","score":36.0538689977,"text":"\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-section-error"},{"document_id":"ibmcld_03713-7896-8949","score":34.2718127559,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03793-7-1857","score":32.0731627979,"text":"\nHow do I add a credit card when the option isn't available through the console? \n\nIf your payments are managed outside of the console, you can't use [Billing and usage](https:\/\/cloud.ibm.com\/billing) to add a credit card.\n\n What\u2019s happening \n\nYou want to enter a credit card to pay for IBM Cloud services, but the option doesn't appear.\n\nWhen you try to enter your credit card information, you see the following message:\n\nYour payments are managed through IBM.com. To view your payments and maintain your billing, you can visit the IBM.com portal which contains everything for your IBMid account.\n\nYou click Explore to access the ibm.com website, but you don't see a location to enter your credit card information.\n\n Why it\u2019s happening \n\nCredit card transactions are securely processed through the IBM Cloud console. However, in some countries, extra steps are taken to ensure the integrity of the credit card data. Those credit card requests are completed through the IBM.com website. Both methods ensure that your credit card information is securely processed.\n\n How to fix it \n\nTo provide your credit card information for payment, complete the following steps:\n\n\n\n1. Go to [IBM.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nThe information is verified and added to your IBM Cloud account as your payment method for any charges.\n\nTo replace an existing credit card, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm"},{"document_id":"ibmcld_07578-1068305-1070191","score":30.4790670313,"text":"\nYou can request to cancel your subscription before the end of the term, but whether the subscription can be canceled is at the discretion of IBM. Any remaining credit on your subscription might be forfeited. For more information, contact [Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter). Make sure that you provide details about why you need to cancel your subscription.\n\nTo close a Pay-As-You-Go account or a Lite account, see [Can I cancel my account?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqscancelaccount).\n\n\n\nManaging your account, resources, and access\n\n\n\n* How do I create an IBM Cloud account?\n\nYou can create an account by [registering](https:\/\/cloud.ibm.com\/registration) your email address. For identity verification, a credit card is required when you create a new account. New accounts are created as Pay-As-You-Go accounts, except purchased subscriptions. For more information, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\nFeature codes aren't supported in some countries. For more information, see [personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n* How is my credit card authorized?\n\nA credit card is required to create a new IBM Cloud account unless you have a subscription or feature code. As part of the authorization process, you might see a temporary hold on your credit card for verification and security when creating an account. This credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03776-5228-7163","score":29.8978836621,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
